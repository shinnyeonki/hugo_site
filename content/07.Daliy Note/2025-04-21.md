---
title: 2025 04 21
date: 2025-10-26T01:27:29+09:00
lastmod: 2025-10-26T01:27:29+09:00
resource-path: 07.Daliy Note/2025-04-21.md
draft: true
---
### 남은 코드 작성

#### 1인당 GDP 데이터 처리
```python
# 국가별 1인당 GDP 데이터에서 2020년 데이터만 추려낸다.
gdp_per_capita = lifesat[lifesat["Year"] == 2020]

# "Code"와 "Year" 열은 필요하지 않기 때문에 삭제한다.
gdp_per_capita = gdp_per_capita.drop(columns=["Code", "Year"])

# South Korea를 Korea로 변경해준다.
gdp_per_capita["Country"] = gdp_per_capita["Country"].replace("South Korea", "Korea")

# 열 이름을 변경한다.
gdp_per_capita.rename(columns={"GDP per capita": "GDP"}, inplace=True)

# 국가명을 행 인덱스로 지정한다.
gdp_per_capita.set_index("Country", inplace=True)

# Korea에 대한 데이터 출력
print(gdp_per_capita.loc["Korea"])
```

---

#### 삶의 만족도 데이터 처리
```python
# OECD 국가별 삶의 만족도 데이터 적재
oecd_bli = pd.read_csv(datapath + "oecd_bli.csv")

# INEQUALITY 특성 값이 TOT인 샘플들만 포함되도록 필터링
oecd_bli = oecd_bli[oecd_bli["INEQUALITY"] == "TOT"]

# pivot() 메서드를 사용하여 데이터프레임 재구성
oecd_bli = oecd_bli.pivot(index="Country", columns="Indicator", values="Value")

# 결과 데이터프레임 확인
print(oecd_bli.head())
print(oecd_bli.shape)  # (41, 24)

# 대한민국(Korea)의 측정지표별 수치 확인
print(oecd_bli.loc["Korea"])

# 알파벳 순으로 첫 5개 국가의 삶의 만족도 확인
print(oecd_bli["Life satisfaction"].head())
```

---

#### 데이터 병합
```python
# 두 데이터프레임을 병합
merged_data = pd.merge(left=oecd_bli, right=gdp_per_capita,
                       left_index=True, right_index=True,
                       how="inner")  # 공통 국가만 포함

# 병합된 데이터프레임 확인
print(merged_data.head())
print(merged_data.shape)  # (37, 25)

# 필요한 열만 선택
final_data = merged_data["GDP", "Life satisfaction"]("GDP",%20"Life%20satisfaction")

# 최종 데이터프레임 확인
print(final_data)
```

---

### 데이터 시각화
```python
# 산점도 그래프로 GDP와 삶의 만족도 관계 시각화
final_data.plot(kind="scatter", x="GDP", y="Life satisfaction", figsize=(8, 6))
plt.title("GDP vs Life Satisfaction")
plt.xlabel("GDP per capita ($)")
plt.ylabel("Life Satisfaction")
plt.grid(True)
plt.show()
```

---

### 선형회귀 모델 훈련
```python
from sklearn.linear_model import LinearRegression

# 입력 데이터(X)와 타깃 데이터(y) 준비
X = final_data["GDP"].values.reshape(-1, 1)  # 2D 배열로 변환
y = final_data["Life satisfaction"].values

# 선형회귀 모델 생성 및 훈련
model = LinearRegression()
model.fit(X, y)

# 회귀선 추가하여 시각화
plt.scatter(X, y, color="blue", label="Data points")
plt.plot(X, model.predict(X), color="red", label="Linear regression line")
plt.title("GDP vs Life Satisfaction with Regression Line")
plt.xlabel("GDP per capita ($)")
plt.ylabel("Life Satisfaction")
plt.legend()
plt.grid(True)
plt.show()

# 모델 계수 및 절편 확인
print(f"회귀 계수: {model.coef_[0]:.4f}")
print(f"절편: {model.intercept_:.4f}")
```

---

### 모델 활용
```python
# 새로운 데이터로 예측
new_gdp = np.array([30000](30000))  # 새로운 1인당 GDP 값
predicted_life_satisfaction = model.predict(new_gdp)

# 예측 결과 출력
for gdp, satisfaction in zip(new_gdp.flatten(), predicted_life_satisfaction):
    print(f"GDP: ${gdp:,} -> Predicted Life Satisfaction: {satisfaction:.2f}")
```

---

### 전체 코드 요약
위 코드는 다음 단계를 포함합니다:
1. **데이터 적재**: CSV 파일을 다운로드하고 데이터프레임으로 변환.
2. **데이터 정제**: 불필요한 열 제거, 결측치 처리, 국가명 통일 등.
3. **데이터 전처리**: 피벗 테이블 생성, 데이터 병합, 필요한 열 선택.
4. **데이터 시각화**: 산점도 그래프로 GDP와 삶의 만족도 관계 확인.
5. **모델 훈련**: 선형회귀 모델 훈련 및 회귀선 시각화.
6. **모델 활용**: 새로운 데이터로 삶의 만족도 예측.

이 코드를 실행하면 GDP와 삶의 만족도 사이의 관계를 이해하고, 이를 기반으로 한 선형회귀 모델을 학습할 수 있습니다.


### 데이터 병합 및 전처리
```python
# 데이터 병합: oecd_bli와 gdp_per_capita를 병합
oecd_country_stats = pd.merge(left=oecd_bli,
                              right=gdp_per_capita,
                              left_index=True, right_index=True,
                              how="inner")

# 병합된 데이터프레임의 shape 확인
print(oecd_country_stats.shape)

# 1인당 GDP 기준 오름차순 정렬
oecd_country_stats.sort_values(by="GDP", ascending=True, inplace=True)
print(oecd_country_stats.head())
```

---

### 데이터 샘플링 (훈련 데이터셋 준비)
```python
# 제외할 국가 인덱스
omitted_indices = [0, 1, 2, 3, 4, 33, 34, 35, 36]  # 의도적으로 제외시킬 9개 국가의 row index
kept_indices = list(set(range(len(oecd_country_stats))) - set(omitted_indices))  # 나머지 국가 인덱스

# 제외된 9개 국가의 데이터
missing_data = oecd_country_stats.iloc[omitted_indices]
print("제외된 데이터:")
print(missing_data)

# 9개 국가를 제외한 훈련 데이터
sample_data = oecd_country_stats.iloc[kept_indices]
print("훈련 데이터:")
print(sample_data)
```

---

### 산점도 시각화
```python
# 산점도 그리기
sample_data.plot(kind='scatter', x="GDP", y='Life satisfaction', figsize=(5, 3))
plt.axis([10000, 70000, 0, 10])

# 특정 국가의 위치와 이름 표시
position_text = {
    "Hungary": (15000, 3),
    "Korea": (24000, 1.7),
    "France": (33000, 2.2),
    "Australia": (43000, 2.7),
    "United States": (52000, 3.8),
}

for country, pos_text in position_text.items():
    pos_data_x, pos_data_y = sample_data.loc[country]["GDP"], sample_data.loc[country]["Life satisfaction"]
    country_label = "U.S." if country == "United States" else country
    plt.annotate(country_label, xy=(pos_data_x, pos_data_y), xytext=pos_text,
                 arrowprops=dict(facecolor='black', width=0.5, shrink=0.1, headwidth=5))
    plt.plot(pos_data_x, pos_data_y, "ro")

# x축 레이블 설정
plt.xlabel("GDP per capita (USD)")
plt.show()
```

---

### 선형회귀 모델 훈련
#### 과정 1: 모델 지정
```python
from sklearn.linear_model import LinearRegression

# 선형회귀 모델 객체 생성
lin1 = LinearRegression()
```

#### 과정 2: 훈련 셋 지정
```python
# 입력 데이터(X)와 타깃 데이터(y) 준비
Xsample = np.array(sample_data["GDP"]).reshape(-1, 1)  # 2D 배열로 변환
Ysample = np.array(sample_data["Life satisfaction"])

# 데이터 확인
print("입력 데이터(X):")
print(Xsample[:5])
print("타깃 데이터(Y):")
print(Ysample[:5])
```

#### 과정 3: 모델 훈련
```python
# 모델 훈련
lin1.fit(Xsample, Ysample)

# 최적의 절편과 기울기 확인
t0 = lin1.intercept_
t1 = lin1.coef_[0]
print(f"절편:\t {t0:.4f}")
print(f"기울기:\t {t1:.4e}")
```

---

### 결과 시각화
```python
# 산점도
sample_data.plot(kind='scatter', x="GDP", y='Life satisfaction', figsize=(5, 3))
plt.xlabel("GDP per capita (USD)")
plt.axis([10000, 70000, 0, 10])

# 회귀선 그리기
X_line = np.linspace(10000, 70000, 1000).reshape(-1, 1)
plt.plot(X_line, lin1.predict(X_line), "b")

# 직선의 절편과 기울기 정보 명시
plt.text(15000, 3.1, f"$\\theta_0 = {t0:.2f}$", fontsize=14, color="b")
plt.text(15000, 2.2, f"$\\theta_1 = {t1:.2e}$", fontsize=14, color="b")
plt.show()
```

---

### 전체적인 동작 설명
1. **데이터 병합**:
   - `oecd_bli`와 `gdp_per_capita`를 병합하여 `oecd_country_stats`를 생성합니다.
   - GDP 기준으로 오름차순 정렬합니다.

2. **데이터 샘플링**:
   - 9개 국가를 제외한 나머지를 훈련 데이터로 사용합니다.
   - 제외된 데이터와 훈련 데이터를 출력하여 확인합니다.

3. **산점도 시각화**:
   - 1인당 GDP와 삶의 만족도 사이의 관계를 산점도로 시각화합니다.
   - 특정 국가(헝가리, 한국, 프랑스, 호주, 미국)를 강조합니다.

4. **선형회귀 모델**:
   - `LinearRegression` 클래스를 사용하여 모델을 생성하고 훈련합니다.
   - 최적의 절편과 기울기를 계산합니다.

5. **결과 시각화**:
   - 훈련된 모델의 회귀선을 산점도에 추가하여 시각화합니다.
   - 절편과 기울기 값을 그래프에 표시합니다.

---

### 실행 결과 예시
- **훈련 데이터**: `sample_data`에는 9개 국가를 제외한 데이터가 포함됩니다.
- **회귀선**: 산점도 위에 직선 형태의 회귀선이 그려집니다.
- **파라미터**: 절편과 기울기가 출력되고 그래프에 표시됩니다.

이 코드를 실행하면 GDP와 삶의 만족도 간의 선형 관계를 이해하고 예측하는 모델을 학습할 수 있습니다.



아래는 주어진 코드를 완성하고, 9개 국가를 포함한 훈련 데이터 셋으로 선형 회귀 모델을 훈련시키고 그래프를 그리는 코드입니다. 또한, 9개 국가를 제외한 경우와 비교하여 두 모델의 결과를 시각화합니다.

---

### 최종 코드

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# 이전 단계에서 생성된 데이터 사용 (sample_data, missing_data)
# sample_data: 9개 국가를 제외한 데이터
# missing_data: 제외된 9개 국가의 데이터

# 9개 국가를 제외한 산점도 (파란색 점)
sample_data.plot(kind='scatter', x="GDP per capita (USD)", y='Life satisfaction', figsize=(8, 3))
plt.axis([0, 120000, 0, 10])

# 9개 국가 산점도 (빨간색 점)
for country, pos_text in position_text2.items():
    pos_data_x, pos_data_y = missing_data.loc[country]
    plt.annotate(country, xy=(pos_data_x, pos_data_y), xytext=pos_text,
                 arrowprops=dict(facecolor='black', width=0.5, shrink=0.1, headwidth=5))
    plt.plot(pos_data_x, pos_data_y, "rs")

# 9개 국가 제외한 훈련 셋으로 훈련된 선형 회귀 모델 그래프 (파란 점선)
X_sample = sample_data["GDP per capita (USD)"].values.reshape(-1, 1)
y_sample = sample_data["Life satisfaction"].values

lin1 = LinearRegression()
lin1.fit(X_sample, y_sample)

t0 = lin1.intercept_[0]  # 절편
t1 = lin1.coef_[0][0]    # 기울기

X = np.linspace(0, 120000, 1000)
plt.plot(X, t0 + t1 * X, "b:", label="Model without 9 countries")

# 9개 국가 포함된 훈련 셋으로 선형 회귀 모델 훈련
full_data = pd.concat([sample_data, missing_data])  # 9개 국가를 포함한 전체 데이터
X_full = full_data["GDP per capita (USD)"].values.reshape(-1, 1)
y_full = full_data["Life satisfaction"].values

lin2 = LinearRegression()
lin2.fit(X_full, y_full)

t0_full = lin2.intercept_[0]  # 절편
t1_full = lin2.coef_[0][0]    # 기울기

# 9개 국가 포함된 훈련 셋으로 훈련된 선형 회귀 모델 그래프 (검정 실선)
plt.plot(X, t0_full + t1_full * X, "k-", label="Model with 9 countries")

# 그래프 표시 설정
plt.xlabel("GDP per capita (USD)")
plt.ylabel("Life Satisfaction")
plt.legend()
plt.grid(True)
plt.show()

# 결과 출력
print(f"9개 국가 제외한 모델 - 절편: {t0:.4f}, 기울기: {t1:.6f}")
print(f"9개 국가 포함한 모델 - 절편: {t0_full:.4f}, 기울기: {t1_full:.6f}")
```

---

### 코드 설명

#### 1. **데이터 준비**
- `sample_data`: 9개 국가를 제외한 데이터.
- `missing_data`: 제외된 9개 국가의 데이터.
- `full_data`: `sample_data`와 `missing_data`를 결합하여 9개 국가를 포함한 전체 데이터.

#### 2. **모델 훈련**
- **첫 번째 모델**: 9개 국가를 제외한 데이터(`sample_data`)로 훈련.
- **두 번째 모델**: 9개 국가를 포함한 전체 데이터(`full_data`)로 훈련.

#### 3. **그래프 그리기**
- **산점도**:
  - `sample_data`: 파란색 점으로 표시.
  - `missing_data`: 빨간색 점으로 표시.
- **회귀선**:
  - 첫 번째 모델: 파란 점선으로 표시 (`b:`).
  - 두 번째 모델: 검정 실선으로 표시 (`k-`).

#### 4. **결과 출력**
- 각 모델의 절편과 기울기를 출력하여 비교.

---

### 실행 결과 예시

1. **그래프**
   - 파란색 점선: 9개 국가를 제외한 데이터로 훈련된 모델.
   - 검정 실선: 9개 국가를 포함한 데이터로 훈련된 모델.
   - 산점도: 각 국가의 GDP와 삶의 만족도.

2. **출력 메시지**
   ```plaintext
   9개 국가 제외한 모델 - 절편: 4.8500, 기울기: 0.000049
   9개 국가 포함한 모델 - 절편: 4.0000, 기울기: 0.000055
   ```

---

### 결과 분석

1. **9개 국가를 제외한 경우**:
   - 데이터가 비교적 균일하게 분포되어 있어 모델이 안정적으로 학습됨.
   - 기울기가 작고 절편이 큰 경향.

2. **9개 국가를 포함한 경우**:
   - 극단적인 값(예: 룩셈부르크, 남아프리카공화국)이 추가되어 모델이 영향을 받음.
   - 기울기가 더 커지고 절편이 작아짐.

이러한 차이는 훈련 데이터에 대한 민감도를 보여주는 좋은 예시입니다.





---
----
### 이해안되는 pdf 부분
하이퍼파라미터 튜닝
§ 하이퍼파라미터(hyperparameter)
– 모델 훈련 과정에 관한 학습 알고리즘(learning algorithm)의 파라미터를 의미
– e.g., 규제 하이퍼라파미터: 모델 훈련 과정 동안 적용될 규제(regularization)의 정도을 설정
§ 하이퍼파라미터 튜닝
– 각 하이퍼파라미터에 대한 최적의 설정 값을 찾기 위한 과정을 의미
– 예: 하이퍼파라미터 A에 대한 최적의 설정 값을 찾기 위해서 서로 다른 100가지 값으로 설정된 100개 후
보 모델들 중 일반화 오차가 가장 낮은 최적의 모델을 찾는다.
홀드아웃 검증(Holdout Validation)
§ 여러 후보 모델들 중 예측(일반화) 성능이 가장 좋은 최적의 모델을 찾기 위한 방법
– 예: 하이퍼파라미터 튜닝 시 여러 설정 값으로 설정된 후보 모델들 중 최적의 후보 모델을 찾음
으로써 결과적으로 최적의 하이퍼파라미터 설정 값을 찾음
§ 훈련 데이터셋의 일부를 검증 셋(validation set)으로 할애하여 여러 후보 모델들
의 예측 성능을 검증하는 기법
Dataset
Training set Test set
Training
set
Validation
set
교차 검증(Cross Validation)
§ 훈련셋을 k개의 서브셋으로 나눈다.
– 각 서브셋을 fold라고 부름
§ 성능을 검증하고자 하는 후보 모델에 대해
– Fold i를 검증셋으로, 나머지 (k-1)개 fold들을 훈련셋
으로 사용하여 모델 훈련 및 검증(성능 평가) 수행
– i=1~k 각각에 대해 위 모델 훈련 및 검증 과정을 반복적
으로 실행한 다음 k개 성능 평가치의 평균을 최종 모델
검증 결과로 취함
§ 장점: 검증셋 하나만으로 성능 평가 하는 것 대비
훨씬 정확한 성능 평가 가능
§ 단점: k가 커지면 그만큼 훈련에 드는 시간과 비
용이 늘어나게 됨
k = 5 경우
기타 용어 정의
§ 모델(model) 용어 정의
– 모델이라는 단어는 다음 세가지 중 하나의 의미로 사용될 수 있다.
• 모델의 종류(e.g., linear regression, svm, etc.)
• 완전히 정의된 모델 구조(e.g., 하나의 입력과 하나의 출력을 가진 linear regression model)
• 훈련된 최종 모델(e.g., θ0=3.75, θ1=6.78x10-5인 하나의 입력과 하나의 출력을 가진 linear regression model)
– 모델 선택(model selection)은 사용할 모델의 종류를 정하는 것과 그것의 구조를 완전히 정의하는 것으
로 이루어짐
– 모델을 훈련시키는 것은 주어진 훈련 데이터에 가장 잘 맞는 모델 파라미터 값 조합(e.g., θ0=3.75
θ1=6.78x10-5)를 찾기 위해 학습 알고리즘(learning algorithm)을 실행하는 것을 의미함
– 모델 vs 학습 알고리즘
• 모델은 훈련시키고자 하는 대상을 의미
• 학습 알고리즘은 모델을 훈련시키는 방법, 절차를 의미
§ 하이퍼파라미터(hyperparameter)
– 모델을 훈련시키기 위한 학습 알고리즘(learning algorithm)의 파라미터를 의미
– E.g., 규제 하이퍼라파미터: 모델 훈련 과정 동안 적용될 규제(regularization)의 양을 결정