<!DOCTYPE html>

<html lang="ko-KR"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    
    
    
    
    <title>mjuecs 2 | My Test Site</title>
    

    
    
    <meta name="description" content="컨테이너 기반 컴퓨팅 제공 서비스 프로젝트 설계서 1. 개요 본 문서는 AWS ECS(Elastic Container Service)와 유사한 사용자 맞춤형 컨테이너 기반 컴퓨팅 자원 제공 서비스를 구축하기 위한 상세 설계안을 기술한다. 사용자는 본 서비스를 통해 독립 …">

    
    
    <meta name="robots" content="index, follow">
    

    
    <link rel="canonical" href="http://localhost:1313/06.university/mju_ecs-project/mjuecs-2/">

    
    
    
    <meta property="og:title" content="mjuecs 2">
    <meta property="og:description" content="컨테이너 기반 컴퓨팅 제공 서비스 프로젝트 설계서 1. 개요 본 문서는 AWS ECS(Elastic Container Service)와 유사한 사용자 맞춤형 컨테이너 기반 컴퓨팅 자원 제공 서비스를 구축하기 위한 상세 설계안을 기술한다. 사용자는 본 서비스를 통해 독립 …">
    <meta property="og:url" content="http://localhost:1313/06.university/mju_ecs-project/mjuecs-2/">
    <meta property="og:site_name" content="My Test Site">
    
    <meta property="og:type" content="blog">
    

    
    
    

    
    
    
    <meta name="twitter:card" content="summary_large_image">
    
    <meta name="twitter:title" content="mjuecs 2">
    <meta name="twitter:description" content="컨테이너 기반 컴퓨팅 제공 서비스 프로젝트 설계서 1. 개요 본 문서는 AWS ECS(Elastic Container Service)와 유사한 사용자 맞춤형 컨테이너 기반 컴퓨팅 자원 제공 서비스를 구축하기 위한 상세 설계안을 기술한다. 사용자는 본 서비스를 통해 독립 …">
    

    
    
    

    
    <script src="https://cdn.tailwindcss.com?plugins=typography"></script>

</head><body>
    
     
    <header class="site-header">
        <div class="site-title">
            <a href="http://localhost:1313/">My Test Site</a>
        </div>
    </header>
    
    <nav class="site-nav">
        <ul>
            
        </ul>
    </nav>
    
    <main>
        
        
<article class="prose prose-sm lg:prose-base max-w-3xl mx-auto dk:prose-stone">
    <h1>mjuecs 2 **page.html**</h1>
    <h2 id="컨테이너-기반-컴퓨팅-제공-서비스-프로젝트-설계서">컨테이너 기반 컴퓨팅 제공 서비스 프로젝트 설계서</h2>
<h3 id="1-개요">1. 개요</h3>
<p>본 문서는 AWS ECS(Elastic Container Service)와 유사한 사용자 맞춤형 컨테이너 기반 컴퓨팅 자원 제공 서비스를 구축하기 위한 상세 설계안을 기술한다. 사용자는 본 서비스를 통해 독립된 Docker 컨테이너 환경을 할당받아 원하는 애플리케이션을 실행할 수 있다.</p>
<p>본 서비스의 가장 큰 기술적 특징은 데이터베이스(DB)의 역할을 <strong>사용자 인증 정보 관리에만 국한</strong>하고, 컨테이너의 생성, 상태, 소유권 등 모든 운영 정보는 각 Docker 호스트로부터 실시간으로 조회하여 <strong>메인 API 서버(Python Flask)의 인메모리 캐시에 저장 및 관리</strong>하는 것이다. 컨테이너와 사용자의 매핑은 <strong>엄격한 컨테이너 네이밍 규칙</strong>을 통해 이루어진다. 이는 Docker 호스트의 실제 상태를 시스템의 유일한 진실 공급원(Source of Truth)으로 삼아 DB와 실제 상태 간의 불일치 가능성을 원천적으로 제거하려는 설계 의도를 반영한다.</p>
<p><strong>주요 기능:</strong></p>
<ul>
<li>사용자 가입 및 인증</li>
<li>사용자별 Docker 컨테이너 생성, 조회, 시작, 중지, 삭제</li>
<li>컨테이너 자원 제한 (CPU, 메모리)</li>
<li>컨테이너 자동 배치 (스케줄링)</li>
<li>사용자별 컨테이너 생성 개수 제한</li>
<li>주기적인 컨테이너 상태 검사 및 정책 기반 관리</li>
</ul>
<hr>
<h3 id="2-시스템-아키텍처">2. 시스템 아키텍처</h3>
<p><strong>2.1. 구성 요소</strong></p>
<ul>
<li><strong>물리적/가상 머신 구성 (최초 제안 기반):</strong>
<ul>
<li><strong>컴퓨터 1 (제어 플레인):</strong>
<ul>
<li><strong>사용자 인증 데이터베이스:</strong> PostgreSQL 또는 MySQL 사용. 사용자 계정 정보만 저장.</li>
<li><strong>메인 API 서버:</strong> Python Flask 기반으로 개발. 모든 비즈니스 로직, Docker 호스트 연동, 인메모리 캐시 관리 수행.</li>
<li><strong>웹 서버/리버스 프록시:</strong> Nginx 사용. SSL/TLS 종료, 로드 밸런싱(단일 Flask 인스턴스 환경에서는 주로 정적 파일 서빙 및 리버스 프록시 역할), 요청 포워딩.</li>
</ul>
</li>
<li><strong>컴퓨터 2, 3, 4 &hellip; (데이터 플레인 - Docker 호스트):</strong>
<ul>
<li>Docker Engine 설치 및 실행. 실제 사용자 컨테이너들이 구동되는 환경.</li>
<li>host 상태를 주기적으로 확인 및 전송할 수 있는 서비스( <code>Grafana</code>, <code>Prometheus</code>, <code>node-exporter</code>)</li>
<li>필요에 따라 수평적으로 확장 가능.</li>
</ul>
</li>
</ul>
</li>
<li><strong>소프트웨어 스택:</strong>
<ul>
<li>OS: Linux</li>
<li>백엔드: Python (Flask 프레임워크)</li>
<li>웹 서버: Nginx</li>
<li>컨테이너 기술: Docker Engine</li>
<li>데이터베이스: PostgreSQL 또는 MySQL</li>
<li>라이브러리: <code>docker</code> (Python Docker SDK), <code>APScheduler</code> (백그라운드 작업), <code>bcrypt</code> (비밀번호 해시), JWT 관련 라이브러리 (예: <code>PyJWT</code>).</li>
</ul>
</li>
</ul>
<p><strong>2.2. 데이터 흐름</strong></p>
<ol>
<li><strong>사용자 요청:</strong> 클라이언트(웹 UI 또는 API 클라이언트)가 서비스 API를 호출한다.</li>
<li><strong>Nginx:</strong> 요청을 수신하여 필요한 경우 SSL/TLS 처리를 수행하고, Flask API 서버로 요청을 전달한다.</li>
<li><strong>Flask API 서버 (인증):</strong> 인증이 필요한 요청의 경우, 요청 헤더의 JWT 토큰을 검증한다. 로그인/가입 시에는 DB의 사용자 테이블을 조회/수정한다.</li>
<li><strong>Flask API 서버 (컨테이너 관련 요청):</strong>
<ul>
<li><strong>조회/상태 확인:</strong> 관리 중인 컨테이너 정보는 자체 인메모리 캐시에서 조회한다.</li>
<li><strong>생성/삭제/제어:</strong> 스케줄링 로직에 따라 대상 Docker 호스트를 결정하고, 해당 호스트의 Docker Engine API를 직접 호출하여 작업을 수행한다. 작업 결과 및 최신 상태는 즉시 인메모리 캐시에 반영된다.</li>
</ul>
</li>
<li><strong>Docker 호스트:</strong> Flask API 서버의 요청에 따라 컨테이너를 생성, 시작, 중지, 삭제하고 그 결과를 반환한다.</li>
<li><strong>응답:</strong> Flask API 서버는 처리 결과를 Nginx를 통해 클라이언트에게 반환한다.</li>
</ol>
<p><strong>2.3. 네트워크 구성</strong></p>
<ul>
<li>
<p>Flask API 서버</p>
<ul>
<li>
<p>모든 docker host 의 ip 와 접근가능한 포트를 구성파일에 기록해둔다</p>
</li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;server1&#34;</span>:{
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;ip&#34;</span> : <span style="color:#e6db74">&#34;192.168.0.56&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;port_range&#34;</span> : [ <span style="color:#ae81ff">10000</span>, <span style="color:#ae81ff">11999</span> ]
</span></span><span style="display:flex;"><span>    },
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;server2&#34;</span>:{
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;ip&#34;</span> : <span style="color:#e6db74">&#34;192.168.0.57&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;port_range&#34;</span> : [ <span style="color:#ae81ff">12000</span>, <span style="color:#ae81ff">13999</span> ]
</span></span><span style="display:flex;"><span>    },
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;server3&#34;</span>:{
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;ip&#34;</span> : <span style="color:#e6db74">&#34;192.168.0.58&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;port_range&#34;</span> : [ <span style="color:#ae81ff">14000</span>, <span style="color:#ae81ff">15999</span> ]
</span></span><span style="display:flex;"><span>    },
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;server4&#34;</span>:{
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;ip&#34;</span> : <span style="color:#e6db74">&#34;192.168.0.56&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;port_range&#34;</span> : [ <span style="color:#ae81ff">16000</span>, <span style="color:#ae81ff">17999</span> ]
</span></span><span style="display:flex;"><span>    },
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;server5&#34;</span>:{
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;ip&#34;</span> : <span style="color:#e6db74">&#34;192.168.0.56&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;port_range&#34;</span> : [ <span style="color:#ae81ff">18000</span>, <span style="color:#ae81ff">19999</span> ]
</span></span><span style="display:flex;"><span>    },
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;server6&#34;</span>:{
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;ip&#34;</span> : <span style="color:#e6db74">&#34;192.168.0.56&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;port_range&#34;</span> : [ <span style="color:#ae81ff">20000</span>, <span style="color:#ae81ff">11999</span> ]
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div></li>
</ul>
</li>
<li>
<p><strong>Flask API 서버 - Docker 호스트 간 통신:</strong></p>
<ul>
<li>Docker Engine API는 기본적으로 TCP 포트(예: 2375 - 비암호화, 2376 - TLS 암호화)를 통해 노출된다. <strong>TLS를 사용한 암호화 통신을 강력히 권장</strong>한다.</li>
<li>각 Docker 호스트의 방화벽에서 Flask API 서버의 IP 주소에서만 Docker API 포트로의 접근을 허용하도록 설정한다.</li>
</ul>
</li>
<li>
<p><strong>사용자 - 생성된 컨테이너 간 접근:</strong></p>
<ul>
<li>사용자는 원하는 컨테이너 특정 내부포트를 정할 수 있고 개수의 경우 규칙을 따른다(max 4개)</li>
<li>컨테이너 생성 시 docker host port_range 중에서 임의로 특정 포트를 컨테이너 내부 포트에 매핑한다 (예: 호스트 포트 30001 -&gt; 컨테이너 포트 80).</li>
<li>사용자는 <code>[호스트IP]:[매핑된_호스트포트]</code> 와 같은 방식으로 컨테이너에 접근한다.</li>
<li>포트 충돌 방지를 위해 동적 포트 할당이 필요하다.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="3-데이터베이스-설계-사용자-인증-전용">3. 데이터베이스 설계 (사용자 인증 전용)</h3>
<ul>
<li><strong>데이터베이스 시스템:</strong> PostgreSQL, MySQL, sqlite</li>
<li><strong>테이블 정의:</strong>
<ul>
<li><code>users</code> 테이블:
<ul>
<li><code>user_id</code> (VARCHAR(255), Primary Key): 사용자가 직접 입력하는 ID (평문 저장).</li>
<li><code>hashed_password</code> (VARCHAR(255), Not Null): <code>bcrypt</code> 또는 <code>Argon2</code>를 사용해 해시된 비밀번호.</li>
<li><code>last_login</code> (TIMESTAMP, Default CURRENT_TIMESTAMP): 마지막 login 시간.</li>
</ul>
</li>
<li><code>template</code> 테이블
<ul>
<li><code>template_id</code> (VARCHAR(255), Primary Key)</li>
<li><code>user_id</code> : 만든 사용자</li>
<li><code>is_administrator</code> : 관리자 유무</li>
<li><code>json 파일</code> :</li>
</ul>
</li>
</ul>
</li>
<li><strong>DB 사용 원칙:</strong>
<ul>
<li>오직 사용자 가입 여부 확인 및 비밀번호 검증을 통한 인증 처리에만 사용된다.</li>
<li>컨테이너 관련 정보(ID, 상태, 소유권, 설정 등)는 이 DB에 <strong>일절 저장하지 않는다.</strong></li>
</ul>
</li>
</ul>
<hr>
<h3 id="4-api-서버-설계-python-flask">4. API 서버 설계 (Python Flask)</h3>
<p><strong>4.1. 주요 기능 및 책임</strong></p>
<ul>
<li><strong>사용자 인증 관리:</strong> JWT 기반 토큰 인증 시스템 (가입, 로그인, 로그아웃, 토큰 검증).</li>
<li><strong>Docker 호스트 연동:</strong> <code>docker</code> Python SDK를 사용하여 각 Docker 호스트의 API와 통신. 컨테이너 생명주기 관리(생성, 시작, 중지, 삭제, 정보 조회, 로그 조회 등) 수행.</li>
<li><strong>인메모리 캐시 관리:</strong> 모든 Docker 호스트로부터 컨테이너 및 호스트 상태 정보를 주기적으로 수집하여 자체 메모리에 캐싱. 이 캐시를 서비스 운영의 주 데이터 소스로 활용.</li>
<li><strong>컨테이너 스케줄링:</strong> 사용자에게 전적으로 부여 , 생성시 원하는 host 를 선택할 수 있도록 함</li>
<li><strong>자원 및 정책 관리:</strong> 사용자별 컨테이너 생성 개수 제한(예: 사용자당 2개), 컨테이너별 자원 할당(예: CPU 2개, 메모리 3GB) 등의 정책 시행.</li>
<li><strong>컨테이너 터미널</strong> : 컨테이너 터미널의 접근을 위해 websocket + xtermjs 을 사용하여 터미널접속이 사이트 내에서 가능하도록 한다</li>
<li><strong>백그라운드 작업:</strong> <code>APScheduler</code> 등을 사용하여 주기적인 작업(예: 호스트 상태 폴링, 비활성 컨테이너 정리 등) 수행.</li>
</ul>
<p><strong>4.2. 인메모리 캐시 전략</strong></p>
<ul>
<li>
<p><strong>캐시 내용:</strong></p>
<ul>
<li><strong>컨테이너 정보:</strong> 각 Docker 호스트에 있는 모든 컨테이너의 상세 정보.
<ul>
<li><code>host_name</code> (실행 중인 Docker 호스트 식별자)</li>
<li><code>docker_container_id</code> (Docker가 부여한 ID)</li>
<li><code>name</code> (컨테이너 이름 - <code>[user_id]_[사용자가 원하는 이름]</code> 형식)</li>
<li><code>owner_user_id</code> (컨테이너 이름에서 파싱한 소유자 ID)</li>
<li><code>image_name</code> (사용된 이미지)</li>
<li><code>status</code> (<code>running</code>, <code>exited</code>, <code>paused</code> 등)</li>
<li><code>ports</code> (매핑 정보)</li>
<li><code>created_at_docker</code> (Docker가 기록한 컨테이너 생성 시간)</li>
<li><code>cpu_usage_percent</code>, <code>memory_usage_mb</code> (실시간 자원 사용량 - <code>stats</code> API 기반)</li>
<li><code>last_polled_at</code> (캐시 정보 갱신 시간)</li>
</ul>
</li>
<li><strong>호스트 정보:</strong> 각 Docker 호스트의 현재 상태.
<ul>
<li><code>host_name</code> (식별자)</li>
<li><code>ip_address</code></li>
<li><code>total_cpu</code>, <code>available_cpu</code></li>
<li><code>total_memory_mb</code>, <code>available_memory_mb</code></li>
<li><code>num_containers</code> (해당 호스트에서 실행 중인 컨테이너 수)</li>
<li><code>is_reachable</code> (폴링 성공 여부)</li>
<li><code>last_polled_at</code></li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>캐시 갱신:</strong></p>
<ul>
<li>설정된 주기(예: 3초 ~ 10초, 시스템 부하에 따라 조절 가능)마다 모든 등록된 Docker 호스트에 병렬적/순차적으로 API를 호출하여 정보를 가져와 캐시를 업데이트한다.</li>
<li>컨테이너 생성/삭제 등 주요 상태 변경 작업 시에는 즉시 해당 정보를 캐시에 반영한다.</li>
</ul>
</li>
<li>
<p><strong>캐시 구조:</strong> Python의 <code>dict</code>를 중첩하여 사용하거나, 필요시 직접 정의한 클래스 객체들을 저장.Python</p>
<pre tabindex="0"><code># 예시:
# self.all_containers_cache = {&#34;docker_id_1&#34;: ContainerInfo(...), &#34;docker_id_2&#34;: ContainerInfo(...)}
# self.host_status_cache = {&#34;host_A&#34;: HostInfo(...), &#34;host_B&#34;: HostInfo(...)}
</code></pre></li>
<li>
<p><strong>애플리케이션 재시작 시 캐시 복구 (&ldquo;웜업&rdquo;):</strong></p>
<ul>
<li>Flask 애플리케이션 시작 시, 인메모리 캐시는 비어있는 상태이다.</li>
<li>시작 루틴에서 설정된 모든 Docker 호스트에 접속하여 현재 실행 중인 모든 컨테이너 정보와 호스트 상태를 조회하고, 이를 파싱하여 전체 인메모리 캐시를 재구성한다.</li>
<li>이 과정은 호스트 및 컨테이너 수에 따라 시간이 소요될 수 있으며, 완료 전까지 서비스는 불완전한 정보를 제공할 수 있다.</li>
</ul>
</li>
</ul>
<p><strong>4.3. 컨테이너-사용자 매핑 (라벨 기반)</strong></p>
<ul>
<li><strong>규칙:</strong> 모든 사용자가 소유한 컨테이너에는 <code>owner_user_id=[user_id]</code> 형식의 라벨이 반드시 포함되어야 한다.</li>
<li><code>[user_id]</code>는 컨테이너를 생성한 사용자의 ID이다. API 서버는 컨테이너 생성 시 인증된 사용자의 <code>user_id</code>를 사용하여 이 라벨을 자동으로 추가한다.</li>
<li><strong>소유권 판단:</strong>
<ul>
<li>API 서버는 Docker 호스트로부터 가져온 컨테이너 목록에서 각 컨테이너의 라벨(Docker API 응답의 <code>Labels</code> 필드)을 확인한다.</li>
<li><code>owner_user_id</code> 라벨 값을 해당 컨테이너의 <code>owner_user_id</code>로 간주한다.</li>
<li>사용자 관련 API 요청(예: 내 컨테이너 목록 조회) 처리 시, 인증된 사용자의 <code>user_id</code>와 캐시된 컨테이너의 <code>owner_user_id</code> (라벨에서 추출)를 비교하여 필터링한다.</li>
</ul>
</li>
<li><strong>컨테이너 이름:</strong> 컨테이너 이름은 사용자가 원하는 이름</li>
</ul>
<p><strong>4.4. API 엔드포인트 (예시)</strong></p>
<ul>
<li><strong>인증 API (<code>/api/auth</code>):</strong>
<ul>
<li><code>POST /register</code>: 사용자 가입</li>
<li><code>POST /login</code>: 로그인 (JWT 토큰 발급)</li>
<li><code>POST /logout</code>: 로그아웃 (토큰 무효화 - 클라이언트 측에서 토큰 삭제 또는 서버 측 블랙리스트 관리)</li>
</ul>
</li>
<li><strong>컨테이너 API (<code>/api/containers</code>):</strong>
<ul>
<li><code>GET /</code>: 현재 인증된 사용자의 모든 컨테이너 목록 조회.</li>
<li><code>POST /</code>: 새 컨테이너 생성 요청.
<ul>
<li>Request Body: <code>{ &quot;image&quot;: &quot;ubuntu:latest&quot;, &quot;name_suffix&quot;: &quot;my_server&quot;, &quot;ports&quot;: {&quot;80/tcp&quot;: null} }</code> (포트는 null로 주면 동적 할당)</li>
</ul>
</li>
<li><code>GET /&lt;container_full_name_or_id&gt;</code>: 특정 컨테이너 상세 정보 조회. (이름은 <code>[user_id]_[name_suffix]</code> 형태)</li>
<li><code>DELETE /&lt;container_full_name_or_id&gt;</code>: 특정 컨테이너 삭제.</li>
<li><code>POST /&lt;container_full_name_or_id&gt;/start</code>: 중지된 컨테이너 시작.</li>
<li><code>POST /&lt;container_full_name_or_id&gt;/stop</code>: 실행 중인 컨테이너 중지.</li>
</ul>
</li>
<li><strong>관리자용 API (<code>/api/admin</code> - 별도 인증 필요):</strong>
<ul>
<li><code>GET /hosts/status</code>: 모든 Docker 호스트의 현재 상태 및 캐시 정보 조회.</li>
<li><code>GET /cache/inspect</code>: Flask API 서버의 전체 인메모리 캐시 내용 조회 (디버깅용).</li>
<li><code>POST /cache/refresh</code>: 강제로 전체 캐시 갱신 수행.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="5-컨테이너-관리-로직">5. 컨테이너 관리 로직</h3>
<p><strong>5.1. 컨테이너 생성 (사용자 요청 처리 상세)</strong></p>
<ol>
<li><strong>사용자 인증:</strong> API 요청 헤더의 JWT 토큰을 검증하여 유효한 사용자인지 확인한다.</li>
<li><strong>생성 개수 제한 검사:</strong> 인증된 사용자의 <code>user_id</code>를 기준으로, 현재 인메모리 캐시에 있는 컨테이너 중 해당 사용자가 소유한 (이름 접두사 일치) 컨테이너 수를 센다. 설정된 최대 개수(예: 2개)를 초과했는지 확인한다.</li>
<li><strong>요청 자원 확인:</strong> 사용자가 요청한 이미지, 포트 매핑, 이름 접미사 등을 파싱한다. 기본 자원 할당량(CPU 2개, 메모리 3GB)을 설정한다.</li>
<li><strong>스케줄링 (호스트 선택):</strong> 사용자가 원하는 host 에 컨테이너를 생성할 수 있도록 한다</li>
<li><strong>고유 컨테이너 이름 생성:</strong> <code>[인증된_user_id]_[사용자요청_name_suffix]</code> 형식으로 기본 이름을 구성한다. 만약 <code>name_suffix</code>가 제공되지 않거나, 동일 사용자 내에서는 이름을 중복할 수 없다 중복되게 생성한다면 적절한 오류 메세지를 반환한다</li>
<li><strong>Docker API 호출 (컨테이너 생성):</strong> 선택된 호스트의 Docker Engine API (<code>/containers/create</code>, 이후 <code>/containers/{id}/start</code>)를 호출한다.
<ul>
<li>파라미터: 생성된 컨테이너 이름, 사용할 이미지, 포트 매핑 설정, CPU 및 메모리 제한 (<code>HostConfig</code> 내 <code>CpuQuota</code>, <code>CpuPeriod</code>, <code>Memory</code> 등) 등을 포함한다.</li>
</ul>
</li>
<li><strong>결과 처리 및 캐시 업데이트:</strong>
<ul>
<li>Docker API로부터 생성 성공/실패 응답을 받는다.</li>
<li>성공 시: 사용자에게 적절한 성공 메세지를 반환한다</li>
<li>실패 시: 사용자에게 적절한 오류 메시지를 반환한다.</li>
</ul>
</li>
<li><strong>동시 생성 요청 제어:</strong> 한 사용자가 동시에 여러 생성 요청을 보내는 것을 방지하기 위해, 사용자별로 &ldquo;생성 진행 중&rdquo; 플래그를 관리한다 (Flask 세션, 또는 간단한 인메모리 딕셔너리 활용. 분산 환경에서는 Redis 등의 외부 Lock 필요).</li>
</ol>
<p><strong>5.2. 컨테이너 자원 제한</strong></p>
<ul>
<li><strong>CPU:</strong> Docker 생성 시 <code>HostConfig</code>의 <code>CpuPeriod</code>와 <code>CpuQuota</code>를 설정한다. 예를 들어, 2개의 CPU 코어 효과를 내려면 <code>CpuPeriod=100000</code> (기본값), <code>CpuQuota=200000</code> (2 * 100000)으로 설정할 수 있다.</li>
<li><strong>메모리:</strong> <code>HostConfig</code>의 <code>Memory</code> (바이트 단위)를 설정한다 (예: <code>3 * 1024 * 1024 * 1024</code> for 3GB). <code>MemorySwap</code>을 <code>Memory</code>와 동일하게 설정하여 스왑 사용을 제한할 수 있다.</li>
<li><strong>디스크 (50GB - 가이드라인):</strong>
<ul>
<li>Docker 자체만으로 컨테이너별 엄격한 디스크 사용량 쿼터를 적용하는 것은 스토리지 드라이버 및 OS 설정에 따라 복잡하다.</li>
<li>본 설계에서는 &ldquo;50GB&quot;를 <strong>사용 가능한 총 이미지 크기 + 컨테이너의 쓰기 가능한 레이어에서 사용할 수 있는 예상 작업 공간의 가이드라인</strong>으로 간주한다.</li>
<li>또는, 컨테이너 생성 시 특정 크기의 Docker 볼륨을 생성하여 마운트하는 방식을 고려할 수 있으나, 이는 볼륨 관리 기능 추가 및 스토리지 플러그인 연동이 필요할 수 있다.</li>
<li>초기에는 명시적 제한보다는 사용량 모니터링 및 가이드라인 제공에 초점을 맞춘다.</li>
</ul>
</li>
</ul>
<p><strong>5.3. 일일 검사 및 정책 적용</strong></p>
<ul>
<li><code>APScheduler</code>를 사용하여 매일 특정 시간에 백그라운드 작업 실행.</li>
<li>작업 내용:
<ol>
<li>인메모리 캐시의 모든 컨테이너 정보를 순회한다.</li>
<li>각 컨테이너에 대해 정의된 규칙을 검사한다:
<ul>
<li>예: 7일 이상 <code>exited</code> 상태로 방치된 컨테이너.</li>
<li>예: 관리자가 정의한 특정 금지된 이미지를 사용한 컨테이너 (이미지 이름 검사).</li>
<li>예: 과도한 네트워크 트래픽을 유발하는 것으로 의심되는 컨테이너 (별도 모니터링 데이터 연동 필요 - 고급).</li>
</ul>
</li>
<li>규칙에 해당하는 컨테이너에 대해 자동 조치(예: 중지, 사용자에게 경고 알림)를 수행하거나 관리자에게 보고한다. 조치 내역은 상세히 로깅한다.</li>
</ol>
</li>
</ul>
<hr>
<h3 id="6-docker-호스트-관리">6. Docker 호스트 관리</h3>
<ul>
<li><strong>호스트 목록 관리:</strong> Flask 애플리케이션의 설정 파일(<code>config.py</code>)이나 환경 변수를 통해 관리할 Docker 호스트의 목록(IP 주소, API 포트, TLS 인증서 경로 등)을 정의한다.</li>
<li><strong>상태 폴링:</strong> <code>APScheduler</code>를 이용한 백그라운드 작업으로, 설정된 주기마다 각 호스트에 대해 다음 Docker API 엔드포인트를 호출하여 정보를 수집하고 인메모리 캐시를 갱신한다.
<ul>
<li><code>GET /info</code>: 호스트 전체 정보 (OS, CPU/메모리 총량, Docker 버전 등).</li>
<li><code>GET /containers/json?all=true</code>: 해당 호스트의 모든 컨테이너 목록 (간략 정보).</li>
<li>(필요시) <code>GET /containers/{id}/stats?stream=false</code>: 개별 컨테이너의 실시간 자원 사용량.</li>
</ul>
</li>
<li><strong>호스트 장애 감지:</strong> 폴링 시 특정 호스트로부터 응답이 없거나 오류가 발생하면, 해당 호스트를 &ldquo;unreachable&rdquo; 상태로 캐시에 표시하고, 이 호스트에서 실행 중이던 컨테이너들도 접근 불가능 상태임을 인지한다. 사용자에게 해당 컨테이너가 일시적으로 사용할 수 없음을 알릴 수 있다. 자동 장애 복구(다른 호스트로 컨테이너 이전)는 본 설계의 초기 범위에는 포함되지 않는다 (복잡도 매우 높음).</li>
</ul>
<hr>
<h3 id="7-보안-고려-사항">7. 보안 고려 사항</h3>
<ul>
<li><strong>API 인증 및 권한 부여:</strong> 모든 API 엔드포인트는 JWT 토큰을 통해 인증된 사용자만 접근 가능하도록 하며, 자신의 자원에만 접근할 수 있도록 철저한 권한 검사를 수행한다.</li>
<li><strong>입력값 검증:</strong> SQL Injection, Command Injection, XSS 등의 공격을 방지하기 위해 모든 사용자 입력(API 파라미터, 요청 본문)에 대해 Flask 레벨에서 또는 Pydantic, Marshmallow 같은 라이브러리를 사용하여 엄격한 유효성 검사를 수행한다.</li>
<li><strong>Docker Daemon API 보안:</strong>
<ul>
<li>반드시 TLS를 활성화하여 Flask API 서버와 Docker 호스트 간의 모든 통신을 암호화한다.</li>
<li>Docker 호스트의 방화벽에서 Flask 서버의 IP 주소에서만 Docker API 포트(일반적으로 TCP 2376)로의 접근을 허용한다.</li>
</ul>
</li>
<li><strong>컨테이너 격리 강화:</strong>
<ul>
<li>컨테이너 내부에서 실행되는 애플리케이션은 가능한 최소한의 권한을 가진 사용자(non-root user)로 실행되도록 Dockerfile을 작성한다.</li>
<li>컨테이너에 불필요한 Linux capabilities를 제거한다 (<code>--cap-drop=ALL</code>). 필요한 최소한의 capability만 선택적으로 추가한다 (<code>--cap-add=...</code>).</li>
<li>(고급) AppArmor 또는 Seccomp 프로필을 적용하여 컨테이너가 수행할 수 있는 시스템 콜을 제한하고 파일 시스템 접근을 제어하여 보안 계층을 강화할 수 있다.</li>
</ul>
</li>
<li><strong>이미지 보안:</strong>
<ul>
<li>서비스에서 사용할 수 있는 Docker 이미지 목록을 관리자가 사전에 승인하고 제공하는 방식(Curated List)을 강력히 권장한다.</li>
<li>만약 사용자가 임의의 이미지를 지정할 수 있게 한다면, 이미지 스캔 도구(예: Trivy, Clair)를 사용하여 알려진 보안 취약점을 검사하는 프로세스를 도입하거나, 위험성을 사용자에게 명확히 고지해야 한다.</li>
</ul>
</li>
<li><strong>네이밍 규칙 악용 방지:</strong>
<ul>
<li>컨테이너 이름 생성 시, 시스템은 인증된 사용자의 <code>user_id</code>를 이름의 접두사로 강제한다.</li>
<li>API를 통해 컨테이너 정보를 조회하거나 조작할 때, 항상 인증된 사용자의 <code>user_id</code>를 기준으로 필터링하므로, 다른 사용자가 악의적으로 유사한 이름의 컨테이너를 생성하더라도 타인의 컨테이너에 접근하거나 영향을 줄 수 없다.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="8-확장성-및-안정성">8. 확장성 및 안정성</h3>
<ul>
<li><strong>API 서버 (Flask):</strong>
<ul>
<li><strong>단일 인스턴스 제약:</strong> 현재 설계(모든 상태를 Flask 앱 메모리에 저장)는 <strong>단일 Flask 인스턴스 환경에 최적화</strong>되어 있다. Gunicorn이나 uWSGI를 사용하여 여러 워커 프로세스를 실행할 수 있지만, 이는 단일 머신 내에서의 병렬 처리 능력 향상이며, 여러 머신으로 Flask 앱을 확장하는 것과는 다르다.</li>
<li><strong>확장 시 문제점:</strong> 여러 Flask 인스턴스로 확장할 경우, 각 인스턴스가 자신만의 독립된 인메모리 캐시를 가지게 되어 상태 불일치가 발생하고 서비스가 오작동할 수 있다. 이를 해결하려면 Redis와 같은 외부 공유 분산 캐시 시스템을 도입해야 하며, 이는 &ldquo;DB 외에 다른 저장소를 사용하지 않겠다&quot;는 초기 설계 원칙과 상충될 수 있다. <strong>따라서 본 설계는 단일 API 서버 인스턴스 운영을 기본 전제로 한다.</strong></li>
</ul>
</li>
<li><strong>데이터베이스:</strong> 사용자 인증용으로만 사용되므로 상대적으로 부하가 적어 초기에는 단일 인스턴스로 충분하다. 사용자 수가 매우 많아질 경우 DB 읽기 복제 등을 고려할 수 있다.</li>
<li><strong>Docker 호스트:</strong> 필요에 따라 더 많은 Docker 호스트 머신을 추가하여 수평적으로 쉽게 확장할 수 있다. Flask API 서버 설정에 새 호스트 정보를 추가하면 된다.</li>
<li><strong>애플리케이션 재시작 및 장애:</strong>
<ul>
<li>Flask API 서버가 재시작되면 인메모리 캐시가 모두 소실되므로, 모든 Docker 호스트를 스캔하여 캐시를 재구축하는 &ldquo;웜업&rdquo; 과정이 필요하다. 이 시간 동안 서비스 응답이 지연되거나 불완전할 수 있다.</li>
<li>Docker 호스트 자체의 장애는 폴링 메커니즘을 통해 감지된다. 해당 호스트의 컨테이너는 &ldquo;unreachable&rdquo; 상태로 처리된다. 자동화된 컨테이너 재배치(self-healing)는 구현 복잡도가 높아 현재 설계 범위에는 포함되지 않는다.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="9-로깅-및-모니터링">9. 로깅 및 모니터링</h3>
<ul>
<li><strong>로깅:</strong> <strong>컨테이너 정보를 DB에 저장하지 않으므로, 모든 활동에 대한 상세한 로깅이 시스템의 상태 추적 및 문제 해결에 매우 중요하다.</strong>
<ul>
<li><strong>Flask API 서버 로깅:</strong> 모든 API 요청(엔드포인트, 파라미터, 사용자 ID), 응답(성공/실패, 상태 코드), 주요 내부 동작(캐시 업데이트, 스케줄링 결정, Docker API 호출 내역), 오류 및 예외 상황 등을 파일 또는 표준 출력으로 상세히 기록한다.</li>
<li><strong>컨테이너 이벤트 로깅:</strong> 컨테이너 생성, 삭제, 시작, 중지 등의 주요 이벤트 발생 시 관련 정보(사용자 ID, 컨테이너 이름, 호스트 등)를 명확히 로깅한다.</li>
<li><strong>주기적 작업 로깅:</strong> 호스트 상태 폴링 결과, 일일 검사 및 정책 적용 결과 등을 로깅한다.</li>
<li><strong>중앙 집중식 로깅 시스템 고려:</strong> 운영 규모가 커지면 ELK Stack(Elasticsearch, Logstash, Kibana) 또는 Grafana Loki 같은 중앙 집중식 로깅 시스템을 도입하여 로그를 효율적으로 수집, 검색, 분석하는 것을 고려한다.</li>
</ul>
</li>
<li><strong>모니터링:</strong>
<ul>
<li><strong>API 서버 성능:</strong> Flask 애플리케이션의 응답 시간, RPS(requests per second), 오류율, CPU/메모리 사용량 등을 모니터링한다. (예: Prometheus <code>flask_exporter</code>)</li>
<li><strong>Docker 호스트 상태:</strong> 각 Docker 호스트의 CPU/메모리/디스크/네트워크 사용량, 실행 중인 컨테이너 수 등을 모니터링한다. (예: Prometheus <code>node_exporter</code>, <code>cAdvisor</code>)</li>
<li><strong>인메모리 캐시 상태:</strong> 캐시 크기, 갱신 빈도, 웜업 시간 등을 모니터링할 수 있는 내부 메트릭을 노출할 수 있다.</li>
<li><strong>시각화 및 알림:</strong> 수집된 메트릭은 Grafana를 사용하여 시각화하고, 주요 지표에 대한 임계치 기반 알림(Alerting)을 설정하여 문제 발생 시 신속하게 대응한다.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="10-사용자-인터페이스-ui">10. 사용자 인터페이스 (UI)</h3>
<ul>
<li>사용자가 서비스를 편리하게 이용할 수 있도록 웹 기반 UI를 제공</li>
<li>UI는 별도의 프론트엔드 프로젝트(예: React, Vue.js, Angular 사용)로 개발하여 API를 호출한다</li>
<li><strong>UI 주요 기능:</strong>
<ul>
<li>회원가입, 로그인</li>
<li>컨테이너 목록 보기 (이름, 상태, 포트 등)</li>
<li>새 컨테이너 생성 폼 (이미지 선택, 이름 접미사 입력, 포트 설정 등)</li>
<li>컨테이너 제어 버튼 (시작, 중지, 삭제)</li>
<li>컨테이너 터미널 연결</li>
<li>컨테이너 로그 보기 (옵션)</li>
</ul>
</li>
</ul>
<hr>
<h3 id="11-주요-도전-과제-및-한계점-본-설계-방식-채택-시">11. 주요 도전 과제 및 한계점 (본 설계 방식 채택 시)</h3>
<ul>
<li><strong>전적인 메모리 의존성 및 상태 유실 위험:</strong> Flask API 서버의 인메모리 캐시에 모든 컨테이너 운영 상태가 의존한다. 서버 장애 또는 재시작 시 모든 캐시 정보가 유실되며, Docker 호스트를 전수 조사하여 상태를 재구성하는 &ldquo;웜업&rdquo; 과정이 필수적이다. 이 과정 동안 서비스의 일시적 불안정성이 발생할 수 있다.</li>
<li><strong>단일 인스턴스 확장성 제약:</strong> 현재 아키텍처는 API 서버의 수평적 확장이 어렵다. 여러 인스턴스가 각자의 메모리 캐시를 가지면 상태 불일치가 발생하므로, 고가용성 및 부하 분산을 위한 일반적인 웹 서비스 확장 전략 적용에 한계가 있다. (외부 공유 캐시 도입 시 설계 원칙 변경) 하지만 본 프로젝트는 1개의 망에서만 동작하며 동시접속자 수나 사용자 수가 300 명 이내 설계이므로 상관없다</li>
<li><strong>데이터 영속성 및 감사 추적의 어려움:</strong> 컨테이너가 시스템에서 삭제되면, 해당 컨테이너의 과거 존재 이력이나 상세 설정 정보가 메모리에서 완전히 사라진다. 문제 발생 시 과거 상태를 추적하거나 정교한 감사 로그를 확보하기 위해서는 매우 철저하고 별도의 로깅 시스템에 의존해야 한다.</li>
<li><strong>성능 병목 가능성:</strong> 관리하는 Docker 호스트 및 전체 컨테이너 수가 크게 증가할 경우, 주기적인 전체 상태 폴링, 대규모 캐시 관리, 메모리 내에서의 빈번한 필터링 작업 등이 Flask API 서버의 성능 병목 지점이 될 수 있다.</li>
</ul>
<hr>
<p>본 설계는 &ldquo;DB에는 최소한의 정보만, 모든 운영 상태는 실시간 조회 및 메모리 캐시&quot;라는 핵심 원칙 하에 작성되었다. 이로 인해 얻는 실시간성과 단순함의 이면에는 위에서 언급된 도전 과제들이 존재함을 명확히 인지하고, 시스템 개발 및 운영 단계에서 이에 대한 면밀한 고려와 대비가 필요하다.</p>
<h2 id="컨테이너-기반-컴퓨팅-제공-서비스-프로젝트-설계서-분석-및-제언-보고서">컨테이너 기반 컴퓨팅 제공 서비스 프로젝트 설계서 분석 및 제언 보고서</h2>
<h3 id="1-서론">1. 서론</h3>
<p>본 보고서는 제시된 &ldquo;컨테이너 기반 컴퓨팅 제공 서비스 프로젝트 설계서&rdquo;(이하 설계서)에 대한 심층 분석을 제공하고, 잠재적인 문제점, 개선 방안, 그리고 추가적으로 고려해야 할 사항들을 다각적으로 제시하는 것을 목적으로 합니다. 설계서의 핵심은 AWS ECS와 유사한 컨테이너 관리 플랫폼을 구축하되, 데이터베이스의 역할을 사용자 인증 정보 관리에만 국한하고, 컨테이너 관련 모든 운영 정보는 Docker 호스트로부터 실시간으로 조회하여 API 서버의 인메모리 캐시에 저장 및 관리하는 것입니다. 이 방식은 Docker 호스트를 시스템의 &lsquo;단일 진실 공급원(Source of Truth)&lsquo;으로 삼아 데이터 불일치 가능성을 원천적으로 제거하려는 독창적인 접근 방식을 취하고 있습니다.</p>
<p>본 보고서는 설계서의 주요 특징과 장점을 먼저 살펴본 후, 아키텍처, 데이터 관리, 보안, 확장성, 안정성 등 다양한 측면에서 발생할 수 있는 도전 과제와 한계점을 분석할 것입니다. 이를 바탕으로 시스템의 완성도와 지속 가능성을 높이기 위한 구체적인 개선 방안과 추가 고려 사항을 제안하여, 성공적인 프로젝트 구현에 기여하고자 합니다. 특히, &ldquo;단일 API 서버 인스턴스&rdquo; 및 &ldquo;300명 이내 사용자&quot;라는 초기 운영 규모 제약을 고려하여 현실적인 분석과 제안을 드리도록 하겠습니다.</p>
<h3 id="2-설계서-주요-특징-및-장점-분석">2. 설계서 주요 특징 및 장점 분석</h3>
<p>설계서는 몇 가지 주목할 만한 특징과 그에 따른 장점을 가지고 있습니다.</p>
<ul>
<li><strong>Source of Truth로서의 Docker 호스트 및 실시간 상태 반영:</strong> 컨테이너의 실제 상태 정보를 각 Docker 호스트에서 직접 가져와 인메모리 캐시에 반영하는 방식은 이론적으로 데이터베이스와 실제 상태 간의 불일치 문제를 원천적으로 방지할 수 있습니다. 이는 시스템 상태의 정확성과 신뢰성을 높이는 데 기여합니다. DB는 오직 사용자 인증이라는 명확하고 제한된 역할만 수행하므로, 시스템의 복잡도가 낮아지고 특정 컴포넌트에 대한 의존성이 줄어듭니다.</li>
<li><strong>간결한 데이터 모델 및 DB 부하 최소화:</strong> 사용자 인증 정보만을 DB에 저장함으로써, DB 스키마가 매우 단순해지고 DB 관련 작업 부하가 현저히 줄어듭니다. 컨테이너의 빈번한 상태 변경, 생성, 삭제 등의 이벤트가 DB 트랜잭션을 유발하지 않으므로 DB 성능 병목 현상 발생 가능성을 최소화합니다.</li>
<li><strong>엄격한 네이밍 규칙 및 라벨 기반 소유권 관리:</strong> 컨테이너 이름에 <code>[user_id]</code>를 포함하고, <code>owner_user_id</code> 라벨을 통해 소유권을 명확히 하는 방식은 직관적이며, 사용자별 자원 격리 및 관리를 용이하게 합니다. 이는 인메모리 캐시에서 사용자별 컨테이너를 필터링하고 제어하는 로직을 단순화합니다.</li>
<li><strong>Python Flask 및 Docker SDK 활용:</strong> 검증된 기술 스택인 Python Flask와 <code>docker</code> SDK를 활용함으로써 개발 생산성을 높이고, 풍부한 라이브러리 생태계를 활용할 수 있습니다. Nginx, PostgreSQL/MySQL 등 표준적인 오픈소스 기술을 채택하여 비용 효율적인 시스템 구축이 가능합니다.</li>
<li><strong>명확한 역할 분담:</strong> 제어 플레인(API 서버, DB, 웹 서버)과 데이터 플레인(Docker 호스트)의 역할이 비교적 명확하게 구분되어 있어, 각 구성 요소의 독립적인 관리 및 확장이 용이한 구조의 기반을 마련하고 있습니다.</li>
</ul>
<p>이러한 특징들은 특히 초기 개발 단계에서 빠른 프로토타이핑과 구현을 가능하게 하며, 소규모 환경에서는 충분히 효과적으로 운영될 수 있는 잠재력을 가지고 있습니다.</p>
<h3 id="3-설계서의-잠재적-문제점-및-한계점-심층-분석">3. 설계서의 잠재적 문제점 및 한계점 심층 분석</h3>
<p>설계서의 독창적인 접근 방식은 여러 장점을 제공하지만, 동시에 몇 가지 중요한 잠재적 문제점과 한계점을 내포하고 있습니다.</p>
<p><strong>3.1. 인메모리 캐시 의존성의 위험 및 상태 유실</strong></p>
<ul>
<li><strong>단일 장애점 (Single Point of Failure):</strong> API 서버의 인메모리 캐시는 시스템의 모든 운영 상태를 담고 있는 핵심 요소입니다. 만약 API 서버(Flask 애플리케이션)에 장애가 발생하거나 재시작될 경우, 캐시된 모든 정보가 유실됩니다. 이는 서비스 전체의 즉각적인 중단 또는 심각한 기능 장애로 이어집니다. &ldquo;단일 API 서버 인스턴스&quot;를 전제로 하므로, 이 서버의 안정성이 전체 시스템의 안정성과 직결됩니다.</li>
<li><strong>웜업(Warm-up) 시간 및 서비스 불안정성:</strong> API 서버 재시작 시, 모든 Docker 호스트에 접속하여 현재 실행 중인 컨테이너 정보를 수집하고 캐시를 재구성하는 &ldquo;웜업&rdquo; 과정이 필수적입니다. 관리하는 호스트 및 컨테이너 수가 증가함에 따라 이 웜업 시간은 길어질 수 있으며, 이 시간 동안 API 서버는 불완전한 정보를 제공하거나 정상적인 서비스 처리가 불가능할 수 있습니다. 300명 사용자 규모에서는 컨테이너 수가 수백 개에 이를 수 있으며, 각 컨테이너 정보를 상세히 가져오는 과정은 수십 초에서 수 분이 소요될 가능성이 있습니다.</li>
<li><strong>데이터 영속성 부재:</strong> 인메모리 캐시는 휘발성이므로, 컨테이너가 삭제된 후에는 해당 컨테이너의 과거 설정, 상태 변화 이력, 통계 정보 등이 시스템에서 완전히 사라집니다. 이는 감사 추적, 장애 원인 분석, 사용량 기반 과금 정책 수립 등에 심각한 제약을 초래합니다. 로깅에 전적으로 의존해야 하지만, 로그 데이터만으로는 정형화된 과거 상태 조회가 어렵습니다.</li>
</ul>
<p><strong>3.2. 확장성 제약</strong></p>
<ul>
<li><strong>API 서버 수평 확장 불가:</strong> 현재 설계는 API 서버가 모든 상태 정보를 자체 메모리에 가지므로, 여러 인스턴스로 수평 확장(scale-out)하는 것이 불가능합니다. 각 인스턴스가 독립적인 캐시를 가지면 상태 불일치가 발생하여 시스템이 오작동하게 됩니다. 사용자가 300명 이내로 제한되어 있고 단일 망에서 동작한다고 언급되었지만, 향후 서비스 성장에 따른 트래픽 증가나 처리 용량 증설 요구에 유연하게 대응하기 어렵습니다. 단일 인스턴스의 처리 용량을 넘어서는 요청이 발생하면 성능 저하 및 서비스 장애로 이어질 수 있습니다.</li>
<li><strong>폴링 부하 증가:</strong> Docker 호스트 및 컨테이너 수가 증가할수록, 주기적인 상태 폴링 작업은 API 서버와 Docker 호스트 모두에 상당한 부하를 유발할 수 있습니다. 특히, 각 컨테이너의 실시간 자원 사용량(<code>stats</code> API)까지 주기적으로 수집한다면 네트워크 트래픽과 API 서버의 처리 부담이 크게 늘어납니다. 폴링 주기가 너무 길면 정보의 실시간성이 떨어지고, 너무 짧으면 시스템 부하가 가중되는 트레이드오프가 존재합니다.</li>
</ul>
<p><strong>3.3. 데이터 관리 및 감사 추적의 어려움</strong></p>
<ul>
<li><strong>상세 로깅의 중요성 및 부담:</strong> 설계서에서도 언급했듯이, 컨테이너 정보를 DB에 저장하지 않으므로 모든 활동에 대한 상세한 로깅이 필수적입니다. 이는 로깅 시스템 설계, 로그 데이터 저장 및 관리, 검색 및 분석에 대한 추가적인 부담으로 작용합니다. 로그 데이터의 양이 방대해질 수 있으며, 필요한 정보를 효율적으로 추출하고 분석하기 위한 별도의 시스템(예: ELK Stack) 구축 및 운영이 요구됩니다.</li>
<li><strong>이력 추적의 한계:</strong> 로깅만으로는 특정 시점의 시스템 전체 스냅샷, 특정 컨테이너의 상세한 생명주기 이력, 설정 변경 이력 등을 체계적으로 추적하고 분석하기 어렵습니다. 이는 운영 중 문제 해결이나 사용자 지원 시 어려움으로 작용할 수 있습니다.</li>
</ul>
<p><strong>3.4. 네트워크 구성 및 포트 관리</strong></p>
<ul>
<li><strong>동적 포트 할당 및 충돌 방지 로직의 복잡성:</strong> 사용자가 요청한 컨테이너 내부 포트를 Docker 호스트의 특정 포트 범위 내에서 동적으로 매핑할 때, 사용 가능한 포트를 정확히 찾아 할당하고 중복 할당을 방지하는 로직이 API 서버 내에 견고하게 구현되어야 합니다. 여러 컨테이너가 동시에 생성 요청될 경우 경쟁 조건(race condition)이 발생하여 포트 충돌이 일어날 수 있습니다. 이에 대한 정교한 동기화 메커니즘이 필요합니다.</li>
<li><strong>IP 주소 변경 및 호스트 관리의 번거로움:</strong> Docker 호스트의 IP 주소가 변경되거나 호스트가 추가/삭제될 때마다 API 서버의 구성 파일을 수동으로 업데이트해야 합니다. 이는 운영 편의성을 저해하고 오류 발생 가능성을 높입니다.</li>
</ul>
<p><strong>3.5. 보안 고려 사항 심층 분석</strong></p>
<ul>
<li><strong>Docker API 접근 제어의 중요성:</strong> Flask API 서버만이 Docker 호스트의 API에 접근할 수 있도록 방화벽 설정을 하는 것은 기본이지만, API 서버 자체가 공격자에게 침해당할 경우 모든 Docker 호스트에 대한 통제권을 탈취당할 수 있는 위험이 있습니다. TLS 통신은 필수적이며, 인증서 관리 또한 중요합니다.</li>
<li><strong>컨테이너 이름 및 라벨 의존성의 잠재적 취약점:</strong> 현재 컨테이너 이름(<code>[user_id]_[name_suffix]</code>)과 라벨(<code>owner_user_id</code>)을 통해 소유권을 판단합니다. 만약 이름 생성 규칙이나 라벨 주입 과정에 논리적 허점이 있거나, 사용자가 <code>name_suffix</code>에 특수문자나 예상치 못한 패턴을 입력하여 파싱 오류를 유발할 수 있다면, 의도치 않은 접근이나 정보 노출이 발생할 가능성을 배제할 수 없습니다. 입력값 검증이 매우 중요합니다.</li>
<li><strong>이미지 보안 관리:</strong> 사용자가 임의의 Docker 이미지를 사용할 수 있도록 허용한다면, 악성 코드가 포함된 이미지나 보안 취약점이 있는 이미지를 통해 시스템 전체 또는 다른 사용자의 컨테이너에 영향을 미칠 위험이 있습니다. 이미지 검증 프로세스나 승인된 이미지 목록 사용 정책이 강력히 권장됩니다.</li>
</ul>
<p><strong>3.6. 장애 시나리오 및 복구 전략의 구체성</strong></p>
<ul>
<li><strong>Docker 호스트 장애:</strong> 호스트 장애 시 해당 호스트의 컨테이너가 &ldquo;unreachable&quot;로 표시되는 것은 좋으나, 해당 컨테이너에 의존하는 사용자 서비스는 중단됩니다. 자동 복구(다른 호스트로 이전)는 초기 범위에 없다고 명시되었지만, 장애 발생 시 수동 복구 절차나 사용자 알림, 데이터 복구(만약 컨테이너 내부에 중요한 데이터가 있었다면) 방안에 대한 구체적인 계획이 부족합니다.</li>
<li><strong>네트워크 장애:</strong> API 서버와 Docker 호스트 간, 또는 Nginx와 API 서버 간 네트워크 문제 발생 시 시스템 전체가 불안정해질 수 있습니다. 이에 대한 감지 및 대응 방안이 필요합니다.</li>
</ul>
<p><strong>3.7. 컨테이너 자원 관리의 세부 사항</strong></p>
<ul>
<li><strong>디스크 사용량 제한의 모호성:</strong> &ldquo;50GB 가이드라인&quot;은 실제 강제적인 제한이 아니므로, 특정 사용자가 과도한 디스크 공간을 점유하여 호스트 전체의 디스크 부족을 유발할 수 있습니다. Docker 볼륨을 사용한 크기 제한은 관리 복잡성을 증가시키지만, 보다 명확한 통제가 가능합니다. 스토리지 드라이버 수준의 쿼터 설정은 환경에 따라 적용 가능성이 다릅니다.</li>
<li><strong>컨테이너 자동 배치(스케줄링)의 제한:</strong> 사용자가 직접 호스트를 선택하는 방식은 단순하지만, 호스트의 현재 부하 상태나 자원 가용성을 고려하지 않아 특정 호스트에 부하가 집중될 수 있습니다. 이는 시스템 전체의 효율성을 저해할 수 있습니다.</li>
</ul>
<h3 id="4-개선-제안">4. 개선 제안</h3>
<p>앞서 분석된 문제점과 한계점을 보완하고 시스템의 안정성과 효율성을 높이기 위한 몇 가지 개선 방안을 제안합니다.</p>
<p><strong>4.1. 상태 관리 및 데이터 영속성 강화</strong></p>
<ul>
<li><strong>경량 외부 캐시/저장소 도입 고려 (원칙 수정 가능성 검토):</strong> &ldquo;DB 외 다른 저장소 사용 안 함&quot;이라는 원칙이 시스템의 핵심 제약사항이라면 이를 존중해야 합니다. 그러나 API 서버의 단일 장애점 및 상태 유실 위험을 완화하기 위해, Redis와 같은 인메모리 키-값 저장소를 <strong>캐시의 보조 저장소 또는 짧은 주기의 스냅샷 저장 용도</strong>로 사용하는 방안을 신중히 검토해볼 수 있습니다.
<ul>
<li><strong>장점:</strong> API 서버 재시작 시 Redis로부터 빠르게 상태를 복구하여 웜업 시간을 대폭 단축할 수 있습니다. 또한, 분산 락(Distributed Lock) 구현이 용이해져 동시성 제어 로직을 단순화할 수 있습니다.</li>
<li><strong>트레이드오프:</strong> 초기 설계 원칙에서 벗어나며, Redis 관리 포인트가 추가됩니다.</li>
<li><strong>대안 (원칙 유지 시):</strong> API 서버 시작 시 병렬/비동기 웜업 로직을 고도화하고, 웜업 진행 중임을 명확히 API 응답에 표시하여 사용자 혼란을 줄입니다. 주기적으로 인메모리 캐시의 스냅샷을 파일 시스템에 백업하고, 재시작 시 이 스냅샷을 우선 로드 후 Docker 호스트와 동기화하는 방안도 고려할 수 있습니다. (단, 파일 I/O 성능 및 일관성 문제 고려 필요)</li>
</ul>
</li>
<li><strong>이벤트 소싱(Event Sourcing) 패턴의 경량화된 적용:</strong> 컨테이너 생성, 삭제, 상태 변경 등의 주요 이벤트를 단순 로그 이상의 구조화된 형태로 파일 또는 경량 메시지 큐(예: SQLite를 활용한 로컬 큐)에 기록합니다. 이는 완전한 이벤트 소싱 시스템은 아니지만, 장애 발생 시 특정 컨테이너의 이력을 추적하거나 상태를 재구성하는 데 도움이 될 수 있습니다.</li>
</ul>
<p><strong>4.2. 안정성 및 가용성 향상 (단일 인스턴스 환경 내에서)</strong></p>
<ul>
<li><strong>API 서버 프로세스 관리 강화:</strong> Gunicorn 또는 uWSGI 사용 시 워커 프로세스 수를 적절히 설정하고, 워커 프로세스 비정상 종료 시 자동 재시작 등의 기능을 활성화하여 단일 머신 내에서의 안정성을 최대한 확보합니다.</li>
<li><strong>정교한 헬스 체크 엔드포인트:</strong> API 서버 자체의 상태(예: <code>/health/live</code>), 주요 서브시스템(예: Docker 호스트 연결성, 캐시 상태 - <code>/health/ready</code>)을 확인할 수 있는 상세한 헬스 체크 엔드포인트를 구현합니다. 이는 모니터링 시스템과의 연동을 통해 빠른 장애 감지 및 대응을 가능하게 합니다.</li>
<li><strong>비동기 처리 적극 도입:</strong> Flask 자체는 동기 방식이지만, 오래 걸리는 I/O 작업(특히 다수의 Docker 호스트에 API 호출)은 비동기적으로 처리하여 API 서버의 응답성을 향상시킬 수 있습니다. Flask 내에서 <code>gevent</code>나 <code>asyncio</code>와 함께 사용할 수 있는 라이브러리를 활용하거나, 오래 걸리는 작업은 Celery와 같은 별도의 태스크 큐 시스템으로 분리하는 것을 고려할 수 있습니다. (단, 태스크 큐 도입은 관리 포인트 증가)</li>
</ul>
<p><strong>4.3. 로깅 및 모니터링 시스템 고도화</strong></p>
<ul>
<li><strong>구조화된 로깅 (Structured Logging):</strong> JSON이나 key-value 형태의 구조화된 로그를 사용하여 로그 파싱 및 분석의 효율성을 높입니다. 로그 내용에는 타임스탬프, 사용자 ID, 컨테이너 ID, 요청 ID, 이벤트 유형, 성공/실패 여부, 오류 메시지 등을 명확히 포함합니다.</li>
<li><strong>중앙 집중식 로깅 시스템 도입:</strong> 설계서에서 언급된 ELK Stack 또는 Grafana Loki + Promtail 조합은 300명 사용자 규모에서도 장기적으로 로그 관리의 효율성을 크게 높여줍니다. 초기에는 파일 기반 로깅으로 시작하더라도, 향후 확장을 염두에 두고 로그 포맷을 표준화하는 것이 좋습니다.</li>
<li><strong>인메모리 캐시 모니터링 지표 추가:</strong> 캐시 크기(항목 수, 메모리 점유량), 웜업 소요 시간, 캐시 적중률(만약 캐시 미스가 발생할 수 있는 로직이 있다면), 폴링 주기별 처리 시간 등의 내부 메트릭을 Prometheus 등을 통해 노출하여 캐시 동작 상태를 면밀히 관찰합니다.</li>
</ul>
<p><strong>4.4. 네트워크 및 포트 관리 개선</strong></p>
<ul>
<li><strong>포트 할당 데이터베이스화 (경량):</strong> API 서버의 인메모리 캐시 내에 각 호스트별로 할당된 포트와 사용 중인 포트 목록을 실시간으로 관리하고, 컨테이너 삭제 시 즉시 반환 처리합니다. 포트 할당 로직에는 사용자 ID 또는 컨테이너 ID 기반의 락(Lock)을 적용하여 동시 요청 시에도 충돌을 방지합니다. (예: <code>threading.Lock</code> 사용, 분산 환경 고려 시 외부 락 필요)</li>
<li><strong>호스트 정보 외부 설정 및 동적 로딩:</strong> Docker 호스트 목록을 JSON 설정 파일에서 읽어오되, API 서버가 특정 신호(예: SIGHUP)를 받거나 관리자 API를 통해 이 설정을 다시 로드할 수 있도록 하여, API 서버 재시작 없이 호스트 정보를 업데이트할 수 있는 유연성을 확보합니다.</li>
</ul>
<p><strong>4.5. 보안 강화</strong></p>
<ul>
<li><strong>API 서버 보안 강화:</strong>
<ul>
<li>모든 API 엔드포인트에 대해 입력값 유효성 검증(길이, 타입, 허용 문자 등)을 철저히 수행합니다. (Pydantic, Marshmallow 등 활용)</li>
<li>요청 속도 제한(Rate Limiting) 및 악의적 요청 패턴 감지/차단 기능을 Nginx 또는 API 게이트웨이(만약 도입한다면) 수준에서 적용합니다.</li>
<li>JWT 토큰 탈취에 대비한 짧은 만료 시간 설정 및 리프레시 토큰 메커니즘 도입을 고려합니다. (로그아웃 시 서버 측 토큰 블랙리스트 관리는 단일 인스턴스에서는 가능하나, 복잡도 증가)</li>
</ul>
</li>
<li><strong>컨테이너 격리 강화 심화:</strong>
<ul>
<li><code>--cap-drop=ALL</code> 외에, <code>no-new-privileges</code> 옵션을 컨테이너 실행 시 추가하여 컨테이너 내부 프로세스가 추가적인 권한을 획득하는 것을 방지합니다.</li>
<li>읽기 전용 루트 파일시스템 (<code>--read-only</code>) 옵션을 적용하고, 필요한 경로만 쓰기 가능한 볼륨으로 마운트하는 방안을 고려합니다.</li>
<li>AppArmor/Seccomp 프로필은 설정 및 관리가 복잡할 수 있으나, 높은 수준의 보안이 필요하다면 검토할 가치가 있습니다. 초기에는 적용하지 않더라도 향후 강화 방안으로 남겨둘 수 있습니다.</li>
</ul>
</li>
<li><strong>비밀(Secrets) 관리:</strong> Docker API 접근을 위한 TLS 인증서/키, DB 패스워드 등의 민감 정보는 코드나 설정 파일에 하드코딩하지 않고, 환경 변수, 또는 HashiCorp Vault와 같은 외부 비밀 관리 도구를 통해 안전하게 주입합니다. (단일 서버 환경에서는 환경 변수나 암호화된 설정 파일이 현실적일 수 있음)</li>
</ul>
<p><strong>4.6. 컨테이너 관리 로직 심화</strong></p>
<ul>
<li><strong>스케줄링 유연성 확보:</strong> 사용자가 호스트를 직접 선택하는 기능 외에, &ldquo;자동 선택&rdquo; 옵션을 제공하여 API 서버가 호스트의 현재 자원 가용성(CPU, 메모리, 실행 중인 컨테이너 수 등 - 캐시된 정보 기반)을 고려하여 최적의 호스트를 추천하거나 자동으로 배치하는 기능을 추가할 수 있습니다. 이는 사용자 편의성을 높이고 시스템 자원 활용 효율을 개선합니다.</li>
<li><strong>디스크 사용량 제한의 현실적 접근:</strong>
<ul>
<li><strong>주기적 모니터링 및 알림:</strong> <code>docker system df</code> 또는 개별 컨테이너의 <code>docker exec &lt;container_id&gt; df -h</code> 결과를 주기적으로 수집/분석하여, 특정 컨테이너나 사용자가 과도한 디스크를 사용하는 경우 관리자 및 사용자에게 알림을 보냅니다.</li>
<li><strong>Docker 스토리지 드라이버 옵션 활용 (주의):</strong> 일부 스토리지 드라이버(예: <code>overlay2</code>)는 프로젝트 쿼터와 유사한 크기 제한 옵션(<code>size</code>)을 제공할 수 있으나, 이는 Docker 버전 및 시스템 환경에 따라 지원 여부나 안정성이 다를 수 있어 충분한 테스트가 필요합니다.</li>
<li><strong>이미지 크기 사전 고지:</strong> 컨테이너 생성 시 사용될 이미지의 크기를 사용자에게 미리 알려주고, 남은 예상 작업 공간을 안내하는 것도 도움이 됩니다.</li>
</ul>
</li>
</ul>
<p><strong>4.7. 사용자 경험(UX) 개선 사항</strong></p>
<ul>
<li><strong>실시간 알림:</strong> 컨테이너 생성 완료, 시작/중지, 오류 발생 등의 주요 이벤트 발생 시 웹 UI를 통해 사용자에게 실시간으로 알림을 제공합니다. (WebSockets 활용)</li>
<li><strong>컨테이너 생성 템플릿:</strong> 자주 사용되는 애플리케이션 유형(예: 웹 서버, DB)에 대한 사전 정의된 컨테이너 설정 템플릿을 제공하여 사용자가 더 쉽게 컨테이너를 생성할 수 있도록 지원합니다.</li>
<li><strong>상세한 오류 메시지 및 문제 해결 가이드:</strong> API 오류 발생 시, 단순한 HTTP 상태 코드 외에 사용자 친화적인 오류 메시지와 가능한 해결 방법을 안내합니다.</li>
</ul>
<h3 id="5-추가-고려-사항">5. 추가 고려 사항</h3>
<ul>
<li><strong>라이선스 및 비용:</strong> 사용되는 모든 오픈소스 소프트웨어의 라이선스를 확인하고 준수해야 합니다. 향후 클라우드 환경으로 확장하거나 상용 솔루션을 도입할 경우 관련 비용을 고려해야 합니다.</li>
<li><strong>개발 및 운영 인력의 기술 스택:</strong> 현재 설계는 Python, Docker, Linux 등에 대한 숙련도를 요구합니다. 팀원의 기술 역량을 고려하여 현실적인 기술 선택과 교육 계획이 필요합니다.</li>
<li><strong>테스트 전략:</strong> 단위 테스트, 통합 테스트, API 테스트, 부하 테스트 등 각 단계별 테스트 전략을 수립하고 자동화하여 시스템의 안정성을 확보해야 합니다. 특히 인메모리 캐시 로직, Docker 호스트 연동 로직, 동시성 제어 로직 등은 철저한 테스트가 필요합니다.</li>
<li><strong>향후 기능 확장 로드맵:</strong> 초기 버전 출시 이후 고려할 수 있는 기능들(예: 영구 볼륨 관리, 사용자 정의 네트워크, CI/CD 연동, 고급 모니터링 대시보드, 과금 시스템 연동 등)에 대한 장기적인 로드맵을 구상해두는 것이 좋습니다. 이는 현재 아키텍처 설계 시 미래의 확장성을 어느 정도 고려해야 할지 판단하는 데 도움이 됩니다.</li>
</ul>
<h3 id="6-결론">6. 결론</h3>
<p>제시된 &ldquo;컨테이너 기반 컴퓨팅 제공 서비스 프로젝트 설계서&quot;는 Docker 호스트를 단일 진실 공급원으로 삼고 API 서버의 인메모리 캐시를 적극적으로 활용하는 독창적이고 흥미로운 접근 방식을 제시합니다. 이 설계는 데이터 일관성 확보와 DB 의존성 최소화라는 명확한 장점을 가지며, 특히 명시된 &ldquo;단일 API 서버 인스턴스, 300명 이내 사용자&quot;라는 제한된 초기 운영 환경에서는 충분히 실현 가능하고 효율적일 수 있습니다.</p>
<p>하지만, 인메모리 캐시에 대한 높은 의존성은 API 서버 장애 시 상태 유실, 웜업 시간, 수평 확장 제약 등의 본질적인 한계를 내포하고 있습니다. 또한, 데이터 영속성 부재로 인한 감사 추적의 어려움, 폴링 부하 관리, 보안 강화 등은 신중하게 다뤄야 할 도전 과제입니다.</p>
<p>본 보고서에서 제안된 개선 방안들은 이러한 문제점들을 완화하고 시스템의 안정성, 효율성, 보안성, 그리고 사용자 경험을 향상시키는 데 초점을 맞추고 있습니다. 특히, 경량 외부 캐시/저장소의 제한적 도입 고려, 비동기 처리 강화, 정교한 로깅 및 모니터링 시스템 구축, 보안 계층 심화, 그리고 보다 유연한 컨테이너 관리 로직 추가 등은 시스템의 완성도를 높이는 데 기여할 수 있을 것입니다.</p>
<p>가장 중요한 것은 설계의 핵심 원칙과 현실적인 제약 조건 사이에서 균형을 찾는 것입니다. 초기 설계의 단순함과 명확성을 유지하면서도, 잠재적인 위험 요소를 최소화하고 향후 성장에 대비할 수 있는 유연성을 확보하는 방향으로 설계를 발전시켜 나가는 것이 바람직합니다. 철저한 테스트와 점진적인 기능 개선을 통해 안정적이고 사용자 친화적인 컨테이너 서비스를 성공적으로 구축할 수 있기를 기대합니다.</p>

</article>


        
        <footer class="site-footer">
            
            <address>
                
            </address>
            <p>&copy; 2025 My Test Site. All rights reserved.</p>
        </footer>
    </main>

    
    <aside class="sidebar">
        <h3>최근 글</h3>
        <ul>
            
            <li><a href="http://localhost:1313/02.inbox/di-%EC%9D%98%EC%A1%B4%EC%84%B1-%EC%A3%BC%EC%9E%85-%EC%9D%98-%ED%83%80-%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC-%EC%A0%91%EA%B7%BC-%EC%9C%A0%ED%8A%9C%EB%B8%8C-%EB%8C%93%EA%B8%80/">di (의존성 주입) 의 타 프레임워크 접근 유튜브 댓글</a></li>
            
            <li><a href="http://localhost:1313/%EB%AC%B4%EC%A0%9C-12/">무제 12</a></li>
            
            <li><a href="http://localhost:1313/temp/tmux/">tmux</a></li>
            
            <li><a href="http://localhost:1313/02.inbox/doxyzen-%ED%82%A4%EC%9B%8C%EB%93%9C/">Doxyzen 키워드</a></li>
            
            <li><a href="http://localhost:1313/university-algorizm/">university algorizm</a></li>
            
        </ul>

        <h3>태그</h3>
        
        
    </aside>
</body>
</html>