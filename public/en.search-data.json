{"/%EA%B0%9C%EC%9D%B8-%EB%B8%94%EB%A1%9C%EA%B7%B8-%EC%82%AC%EC%9D%B4%ED%8A%B8-%ED%9B%84%EA%B8%B0/":{"data":{"":"","-1-문서-전체-구조-document-outline#🧱 1. \u003cstrong\u003e문서 전체 구조\u003c/strong\u003e (Document Outline)":"","-10-상호작용-및-상태-표현-태그#🧩 10. \u003cstrong\u003e상호작용 및 상태 표현 태그\u003c/strong\u003e":"","-11-진행-상태-및-측정-태그#📊 11. \u003cstrong\u003e진행 상태 및 측정 태그\u003c/strong\u003e":"","-2-콘텐츠-단위#📝 2. \u003cstrong\u003e콘텐츠 단위\u003c/strong\u003e":"","-3-탐색-및-보조-콘텐츠#🔗 3. \u003cstrong\u003e탐색 및 보조 콘텐츠\u003c/strong\u003e":"","-4-텍스트-의미-강조#📚 4. \u003cstrong\u003e텍스트 의미 강조\u003c/strong\u003e":"","-5-기타-유용한-의미론적-태그#📌 5. \u003cstrong\u003e기타 유용한 의미론적 태그\u003c/strong\u003e":"태그 용도 블로그 활용 예 + 접고 펼치는 콘텐츠 FAQ, 코드 설명 토글 모달/팝업 대화상자 구독 팝업, 알림 계산 결과 표시 폼 입력 결과 (드물게 사용) 진행률 읽기 진행률 바 스코어/비율 만족도, 점수","-6-인용-및-출처-관련-태그#📚 6. \u003cstrong\u003e인용 및 출처 관련 태그\u003c/strong\u003e":"","-7-코드-및-기술-콘텐츠-태그#📝 7. \u003cstrong\u003e코드 및 기술 콘텐츠 태그\u003c/strong\u003e":"","-8-목록-및-정의-관련-태그#🗂️ 8. \u003cstrong\u003e목록 및 정의 관련 태그\u003c/strong\u003e":"","-9-시간-및-이벤트-관련-태그#📅 9. \u003cstrong\u003e시간 및 이벤트 관련 태그\u003c/strong\u003e":"","-블로그-구조-예시-의미론적-태그만-사용#✅ 블로그 구조 예시 (의미론적 태그만 사용)":"\u003cbody\u003e \u003cheader\u003e ... \u003c/header\u003e \u003cmain\u003e \u003carticle\u003e \u003cheader\u003e \u003ch1\u003e의미론적 HTML이란?\u003c/h1\u003e \u003ctime datetime=\"2025-10-20\"\u003e2025-10-20\u003c/time\u003e \u003c/header\u003e \u003cp\u003e...\u003c/p\u003e \u003cfigure\u003e \u003cimg src=\"...\" alt=\"...\"\u003e \u003cfigcaption\u003e의미론적 태그 구조\u003c/figcaption\u003e \u003c/figure\u003e \u003c/article\u003e \u003c/main\u003e \u003caside\u003e \u003ch2\u003e프로필\u003c/h2\u003e \u003caddress\u003e...\u003c/address\u003e \u003c/aside\u003e \u003cfooter\u003e \u003cp\u003e© 2025\u003c/p\u003e \u003c/footer\u003e \u003c/body\u003e 물론입니다! 아래는 의미론적 HTML 태그를 동일한 포맷으로 추가로 소개한 내용입니다.\n기존 내용과 일관된 스타일을 유지하며, 블로그나 기술 문서에서 유용하게 쓰이는 태그들을 중심으로 정리했습니다.","-요약-의미론적-태그-선택-가이드#✅ 요약: 의미론적 태그 선택 가이드":"콘텐츠 유형 추천 태그 독립 포스트 섹션/챕터 + 사이드바 네비게이션 코드 조각 , , , , 인용 , , 정의 , , 시간 강조(참고) 접기 콘텐츠 , 의미론적 HTML은 검색엔진이 콘텐츠를 더 정확히 이해하도록 도와주며,\n접근성 기준(WCAG)을 충족하는 데도 필수적입니다.\nHugo 템플릿(layouts/)을 작성할 때 위 태그들을 적극 활용하시면,\nSEO 친화적이고 유지보수 쉬운 블로그를 만들 수 있습니다.\n필요하시면, Hugo shortcodes로 의미론적 태그를 자동 생성하는 방법도 알려드릴 수 있어요!","-피해야-할-일반적인-오해#❌ 피해야 할 일반적인 오해":"잘못된 사용 올바른 대안 을 스타일용 div처럼 남발 제목이 없다면 사용 없이 만 사용 독립 콘텐츠면 우선 에 SNS 아이콘만 넣음 주요 이동 경로가 아니면","address#\u003ccode\u003e\u0026lt;address\u0026gt;\u003c/code\u003e":"용도: 문서 또는 article의 연락처 정보 블로그 예시: 저자 이메일, 프로필 링크 범위: 안에 있으면 글 저자, 문서 루트에 있으면 사이트 운영자 \u003caddress\u003e 작성자: \u003ca href=\"mailto:shinnk@example.com\"\u003e신년기\u003c/a\u003e \u003c/address\u003e","article#\u003ccode\u003e\u0026lt;article\u0026gt;\u003c/code\u003e":"용도: 독립적으로 배포/재사용 가능한 콘텐츠 단위 블로그 예시: 블로그 포스트, 댓글, 뉴스 기사 핵심: 하나만 떼서 RSS나 피드에 넣어도 의미 있음 ✅ 비의미론적 대체: ❌ \u003carticle\u003e \u003ch2\u003e마크다운 문법 정리\u003c/h2\u003e \u003cp\u003e...\u003c/p\u003e \u003c/article\u003e","aside#\u003ccode\u003e\u0026lt;aside\u0026gt;\u003c/code\u003e":"용도: 주 콘텐츠와 간접적으로 관련된 보조 정보 블로그 예시: 사이드바(태그 클라우드, 프로필, 최근 글), 인용문 핵심: 를 제거해도 본문 의미 손실 없음 ✅ 비의미론적 대체: ❌ \u003caside\u003e \u003ch3\u003e태그\u003c/h3\u003e \u003cul\u003e...\u003c/ul\u003e \u003c/aside\u003e 💡 안에 를 넣어 포스트 관련 참고자료도 표현 가능","blockquote#\u003ccode\u003e\u0026lt;blockquote\u0026gt;\u003c/code\u003e":"용도: 다른 출처에서 인용한 긴 문장 블로그 예시: 명언, 다른 글 인용 권장: 로 출처 명시 \u003cblockquote\u003e \u003cp\u003e삶이 있는 한 희망은 있다.\u003c/p\u003e \u003ccite\u003e— 키케로\u003c/cite\u003e \u003c/blockquote\u003e","cite#\u003ccode\u003e\u0026lt;cite\u0026gt;\u003c/code\u003e":"용도: 작품, 문서, 사람 이름 등 출처를 명시할 때 사용 블로그 예시: 책 제목, 논문, 영화, 인용된 저자 이름 주의: 인용 문구 전체가 아니라 출처 자체에만 적용 ✅ 비의미론적 대체: ❌ \u003cp\u003e이 아이디어는 \u003ccite\u003e클린 코드\u003c/cite\u003e에서 영감을 받았습니다.\u003c/p\u003e 💡 안에서 를 사용해 출처를 명확히 할 수 있음","code#\u003ccode\u003e\u0026lt;code\u0026gt;\u003c/code\u003e":"용도: 짧은 코드 조각, 함수 이름, 명령어 등을 인라인으로 표시 블로그 예시: console.log(), git commit, 변수명 ✅ 비의미론적 대체: ❌ \u003cp\u003e\u003ccode\u003eArray.prototype.map()\u003c/code\u003e은 새로운 배열을 반환합니다.\u003c/p\u003e 💡 블록 전체 코드는 ... 조합 사용","details--summary#\u003ccode\u003e\u0026lt;details\u0026gt;\u003c/code\u003e + \u003ccode\u003e\u0026lt;summary\u0026gt;\u003c/code\u003e":"용도: 접고 펼칠 수 있는 콘텐츠 제공 블로그 예시: 해설 코드, 정답 보기, 추가 정보 장점: JavaScript 없이 순수 HTML로 구현 가능 \u003cdetails\u003e \u003csummary\u003e정답 보기\u003c/summary\u003e \u003cp\u003e정답은 42입니다.\u003c/p\u003e \u003c/details\u003e","dialog#\u003ccode\u003e\u0026lt;dialog\u0026gt;\u003c/code\u003e":"용도: 대화 상자(modal, popup)를 의미론적으로 표현 블로그 예시: 구독 유도 팝업, 쿠키 동의 창 (JavaScript와 함께 사용) 주의: 아직 모든 브라우저에서 완벽 지원은 아님 \u003cdialog open\u003e \u003cp\u003e이 글이 도움이 되셨나요?\u003c/p\u003e \u003cbutton\u003e네\u003c/button\u003e \u003cbutton\u003e아니요\u003c/button\u003e \u003c/dialog\u003e","dl-dt-dd#\u003ccode\u003e\u0026lt;dl\u0026gt;\u003c/code\u003e, \u003ccode\u003e\u0026lt;dt\u0026gt;\u003c/code\u003e, \u003ccode\u003e\u0026lt;dd\u0026gt;\u003c/code\u003e":"용도: 정의 목록(definition list) — 용어와 설명 쌍 블로그 예시: 용어 사전, 설정 설명, FAQ 형식 ✅ 비의미론적 대체: 용어: 설명 ❌ \u003cdl\u003e \u003cdt\u003eSEO\u003c/dt\u003e \u003cdd\u003e검색 엔진 최적화(Search Engine Optimization)의 약자입니다.\u003c/dd\u003e \u003cdt\u003eHugo\u003c/dt\u003e \u003cdd\u003e빠르고 확장 가능한 정적 사이트 생성기입니다.\u003c/dd\u003e \u003c/dl\u003e 💡 Hugo의 Goldmark는 기본적으로 정의 목록 확장 문법 지원 (definitionList: true)","figure--figcaption#\u003ccode\u003e\u0026lt;figure\u0026gt;\u003c/code\u003e + \u003ccode\u003e\u0026lt;figcaption\u0026gt;\u003c/code\u003e":"용도: 이미지, 코드 블록, 수식 등에 캡션 추가 블로그 예시: 다이어그램 + 설명, 코드 예제 + 설명 장점: 콘텐츠와 캡션이 논리적으로 묶임 \u003cfigure\u003e \u003cpre\u003e\u003ccode\u003econsole.log(\"Hello\");\u003c/code\u003e\u003c/pre\u003e \u003cfigcaption\u003eJavaScript 출력 예제\u003c/figcaption\u003e \u003c/figure\u003e","footer#\u003ccode\u003e\u0026lt;footer\u0026gt;\u003c/code\u003e":"용도: 페이지나 섹션의 꼬리말(closing content) 블로그 예시: 저작권, 연락처, 관련 링크 특징: 처럼 여러 번 사용 가능 ✅ 비의미론적 대체: ❌ \u003cfooter\u003e \u003cp\u003e© 2025 신년기. All rights reserved.\u003c/p\u003e \u003c/footer\u003e","header#\u003ccode\u003e\u0026lt;header\u0026gt;\u003c/code\u003e":"용도: 페이지나 섹션의 머리말(introductory content) 블로그 예시: 사이트 로고, 네비게이션, 검색창 특징: 문서 전체에 하나만 있을 필요 없음 → 각 섹션마다 가능 ✅ 비의미론적 대체: ❌ \u003cheader\u003e \u003ch1\u003e\u003ca href=\"/\"\u003e내 블로그\u003c/a\u003e\u003c/h1\u003e \u003cnav\u003e...\u003c/nav\u003e \u003c/header\u003e","kbd#\u003ccode\u003e\u0026lt;kbd\u0026gt;\u003c/code\u003e":"용도: 키보드 입력 또는 사용자 조작을 표현 블로그 예시: 단축키, 명령 입력 안내 ✅ 비의미론적 대체: Ctrl+C ❌ \u003cp\u003e복사하려면 \u003ckbd\u003eCtrl\u003c/kbd\u003e + \u003ckbd\u003eC\u003c/kbd\u003e를 누르세요.\u003c/p\u003e","layout-템플릿-종류#layout 템플릿 종류":"기본 템플릿 (Base Templates): 모든 페이지의 공통적인 뼈대를 제공합니다. 페이지 종류 템플릿 (Page Kind Templates): 홈페이지, 목록 페이지, 상세 페이지 등 페이지의 ‘종류’에 따라 다른 템플릿을 적용합니다. 콘텐츠 타입별 템플릿 (Content Type-Specific Templates): ‘책’, ‘영화’ 등 특정 콘텐츠 타입에만 적용되는 전용 템플릿입니다. 콘텐츠 뷰 (Content Views): 한 페이지를 여러 방식으로 (카드 형태, 리스트 형태 등) 렌더링할 때 사용됩니다. 부분 템플릿 (Partials): 헤더, 푸터처럼 여러 템플릿에서 재사용되는 코드 조각입니다. 숏코드 (Shortcodes): 마크다운 콘텐츠 파일 안에서 직접 호출하여 사용하는 템플릿 조각입니다. 렌더링 훅 (Render Hooks): 마크다운이 HTML로 변환될 때 기본 동작(예: 이미지, 링크 렌더링)을 재정의합니다.","main#\u003ccode\u003e\u0026lt;main\u0026gt;\u003c/code\u003e":"용도: 문서의 주요 콘텐츠(unique content) 블로그 예시: 글 본문, 포스트 목록 규칙: 페이지당 오직 하나만 사용해야 함 ✅ 비의미론적 대체: ❌ \u003cmain\u003e \u003carticle\u003e...\u003c/article\u003e \u003c/main\u003e","mark#\u003ccode\u003e\u0026lt;mark\u0026gt;\u003c/code\u003e":"용도: 참고 목적으로 강조된 텍스트 블로그 예시: 검색 키워드 하이라이트, 중요한 문장 강조 주의: 이나 과 다름 → 의미 강조가 아니라 시각적/참고 강조 \u003cp\u003e이 함수는 \u003cmark\u003e매우 중요\u003c/mark\u003e합니다.\u003c/p\u003e","meter#\u003ccode\u003e\u0026lt;meter\u0026gt;\u003c/code\u003e":"용도: 범위 내 값(score, disk usage 등) 표시 블로그 예시: 만족도 평가, 성능 점수 \u003cp\u003eCPU 사용률: \u003cmeter min=\"0\" max=\"100\" value=\"65\"\u003e65%\u003c/meter\u003e\u003c/p\u003e 💡 는 “진행 중”, 는 “정적인 측정값”","nav#\u003ccode\u003e\u0026lt;nav\u0026gt;\u003c/code\u003e":"용도: 주요 탐색 링크 모음 블로그 예시: 상단 메뉴, 사이드바 목록, 페이지네이션 주의: 모든 링크에 쓰지 말 것 → 주요 이동 경로만 ✅ 비의미론적 대체: ❌ \u003cnav\u003e \u003cul\u003e \u003cli\u003e\u003ca href=\"/posts\"\u003e글 목록\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"/tags\"\u003e태그\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e \u003c/nav\u003e","progress#\u003ccode\u003e\u0026lt;progress\u0026gt;\u003c/code\u003e":"용도: 작업 진행률 시각화 블로그 예시: 강의 완료율, 읽기 진행률 (JavaScript로 동적 제어) \u003cp\u003e현재 글 읽기 진행률: \u003cprogress value=\"70\" max=\"100\"\u003e70%\u003c/progress\u003e\u003c/p\u003e","q#\u003ccode\u003e\u0026lt;q\u0026gt;\u003c/code\u003e":"용도: 짧은 인용문(inline quotation)을 표현 블로그 예시: 문장 중간에 다른 사람 말 인용 자동 처리: 브라우저가 자동으로 따옴표(“”)를 추가 ✅ 비의미론적 대체: \"...\" 또는 ❌ \u003cp\u003e그는 이렇게 말했다: \u003cq\u003e성공은 실패를 거듭한 뒤 오는 것이다.\u003c/q\u003e\u003c/p\u003e 💡 긴 인용문은 사용, 짧은 인용문은 사용","samp#\u003ccode\u003e\u0026lt;samp\u0026gt;\u003c/code\u003e":"용도: 프로그램의 출력 결과를 표시 블로그 예시: 터미널 출력, 오류 메시지 ✅ 비의미론적 대체: 는 입력, 는 출력 \u003cp\u003e명령어 실행 결과: \u003csamp\u003eFile not found\u003c/samp\u003e\u003c/p\u003e","section#\u003ccode\u003e\u0026lt;section\u0026gt;\u003c/code\u003e":"용도: 테마별로 묶인 콘텐츠 그룹 블로그 예시: 소개 섹션, 관련 글 섹션, 댓글 섹션 주의: 은 항상 제목(heading)과 함께 사용해야 함 ✅ 비의미론적 대체: ❌ \u003csection\u003e \u003ch2\u003e관련 글\u003c/h2\u003e \u003cul\u003e...\u003c/ul\u003e \u003c/section\u003e 💡 안에 이 들어가거나, 그 반대도 가능\n예: 블로그 포스트() 안에 “요약”, “코드 예제” 섹션()","template-문법#template 문법":"","time#\u003ccode\u003e\u0026lt;time\u0026gt;\u003c/code\u003e":"용도: 날짜/시간을 기계가 읽을 수 있게 표시 블로그 예시: 포스트 작성일, 이벤트 일정 속성: datetime에 ISO 형식 사용 \u003ctime datetime=\"2025-10-20\"\u003e2025년 10월 20일\u003c/time\u003e","time-추가-활용#\u003ccode\u003e\u0026lt;time\u0026gt;\u003c/code\u003e (추가 활용)":"용도 확장: 이벤트 일정, 업데이트 시간, 읽는 데 걸리는 시간 등 SEO 효과: 구조화된 데이터로 검색 결과에 리치 스니펫 가능 \u003carticle\u003e \u003cheader\u003e \u003ch1\u003e새로운 기능 출시\u003c/h1\u003e \u003cp\u003e게시일: \u003ctime datetime=\"2025-10-20\"\u003e2025년 10월 20일\u003c/time\u003e\u003c/p\u003e \u003cp\u003e업데이트: \u003ctime datetime=\"2025-10-21T14:30:00+09:00\"\u003e오늘 오후 2시 30분\u003c/time\u003e\u003c/p\u003e \u003c/header\u003e \u003c/article\u003e","var#\u003ccode\u003e\u0026lt;var\u0026gt;\u003c/code\u003e":"용도: 변수, 수학 기호, 플레이스홀더 이름을 표현 블로그 예시: 알고리즘 설명, 수식 변수 ✅ 비의미론적 대체: 나 은 의미 없음 \u003cp\u003e피타고라스 정리: \u003cvar\u003ea\u003c/var\u003e\u003csup\u003e2\u003c/sup\u003e + \u003cvar\u003eb\u003c/var\u003e\u003csup\u003e2\u003c/sup\u003e = \u003cvar\u003ec\u003c/var\u003e\u003csup\u003e2\u003c/sup\u003e\u003c/p\u003e","검색엔진-최적화를-위한-의미론적-태그-구조#검색엔진 최적화를 위한 의미론적 태그 구조":"의미론적(semantic) HTML 태그는 콘텐츠의 구조와 의미를 명확히 전달하는 데 사용됩니다.\n이는 접근성(스크린 리더 호환), SEO, 유지보수성, 코드 가독성 모두에 큰 도움이 됩니다.\n블로그 사이트에서 자주 쓰이는 의미론적 태그들을 용도별로 분류해 자세히 설명합니다.","메모-관리#메모 관리":"나는 평소 공부나 여러가지 들을 기록하는 습관이 있다 노트들을 엄청 이동한 경험이 있다\n현재 나는 obsidian 으로 순수한 markdown 을 통해 내가 혼자 공부했던 것들이나 메모할 것들을 적어두고 있다 원래는 onenote, notion 같은 것들을 사용했지만 데이터의 소유권을 온전히 가질 수 없다는 느낌이 들었다 특히 export 할 때 pdf 로 받거나 html 로 받거나 할 때 노트를 이동하거나 할 때 깨지거나 하는 문제가 발생했다 이러한 느낌이 들고 난 후 그냥 순수한 마크다운을 편집하는 것에 익숙해지는 것이 장기적으로 일관성 있도록 이러한 메모를 정리할 수 있다는 생각이 들었다","백엔드를-두고-싶지-않아#백엔드를 두고 싶지 않아":"사이트를 만들되 초기에는 단순히 공유 목적으로 사용하려고 했다 그래서 백엔드를 두는 것이 관리 측면에서 비효율 적이라고 느꼈다 그래서 생각해낸 방식이 이것이다\n블로그 사이트 이지만 실제 모든 처리는 브라우저 내(사용자)에서 처리된다.\nmarkdown =\u003e html\n코드 하이라이팅, latex 렌더링 등등 모든 것을 사용자 브라우저에서 해결한다 단\n현재 블로그에서 어떤 파일이 존재하는지는 미리 알려주어야 한다 이를 위해\nindex.html 에 진입시 사전에 생성된 JSON 파일을 데이터 소스로 활용하여 동작하도록 설계하였다\n데이터 소스는\n1. file_index.json ---------\u003e .src/js/ui/file-tree.js (파일 트리) 2. search_index.json ---------\u003e .src/js/core/search.js (검색 엔진) 3. graph_index.json ---------\u003e (그래프 뷰 기능) 4. recent_index.json ---------\u003e (최근 문서 탭 기능) 5. tag_index.json ---------\u003e (태그 클라우드/목록 기능) 이런식으로 미리 python 스크립트를 만들어 전체 문서를 적절히 인덱싱해서 보여주는 방식이다\n이러한 방식으로 사이트를 구성하면서 웹 표준을 모두 지키려고 했지만 결국 아쉬운 문제가 발생했다\n블로그 사이트의 경우 정말 seo 가 가장 중요하다 하지만 spa 방식으로 만들어진 이 사이트는 seo 에서 별로 좋지 않은 성능을 가져온다\nHTML5 History API 등등 여러가지 방식으로 spa 에서도 seo 를 향상 시키는 여러 방법들이 있지만 코드를 계속 건드리다 보니 이럴거면","사이트-관리#사이트 관리":"obsidian 으로 관리하는 markdown 은 [[]] 같은 특수 문법을 사용하지 않고 frontmatter 만 도입해서 최대한 markdown systex 에 적혀 있는 사양대로 사용중이다\n이렇게 사용하다 보니 언젠가 부터 원하는 파일을 적절히 다른 사람들에게 보여주고 싶다는 생각이 들었다\nbranch, 티스토리, 네이버 등등 여러 방식으로 할 수 있지만 나만의 사이트로 처리하고 싶다는 생각이 들었다(광고도 적당히 붙히고)","핵심-개념-파일명-규칙과-우선순위#\u003cstrong\u003e핵심 개념: 파일명 규칙과 우선순위\u003c/strong\u003e":"[KIND|TYPE]/[LAYOUT|SINGLE|LIST].[OUTPUTFORMAT].[LANG].[SUFFIX]\n가장 중요한 규칙: 더 구체적인 경로와 파일명이 일반적인 것보다 우선합니다. layouts/docs/page.html는 layouts/page.html보다 우선순위가 높습니다. layouts/term.mylayout.html는 layouts/term.html보다 우선순위가 높습니다.","휴고-문법#휴고 문법":"","휴고-테마#휴고 테마":"https://themes.gohugo.io/themes/hextra/"},"title":"개인 블로그 사이트 후기"},"/%EB%AC%B4%EC%A0%9C-1/":{"data":{"":"pub/sub 아키텍쳐와 promise 기능 javascript 이벤트 위임의 효과와 그 기능"},"title":"무제 1"},"/%EB%AC%B4%EC%A0%9C-10/":{"data":{"":"분열 1: ┌─────────────────────────────────────────┐ │ 56 30 46 64 69 37 87 41 19 43 │ └─────────────────────────────────────────┘ ↓ 분열 2: ┌─────────────────────┐ ┌─────────────────────┐ │ 56 30 46 64 69 │ │ 37 87 41 19 43 │ └─────────────────────┘ └─────────────────────┘ ↓ ↓ 분열 3: ┌───────────┐ ┌───────┐ ┌───────────┐ ┌───────┐ │ 56 30 46 │ │ 64 69 │ │ 37 87 41 │ │ 19 43 │ └───────────┘ └───────┘ └───────────┘ └───────┘ ↓ ↓ 분열 4: ┌────┐ ┌──────┐ ┌──┐ ┌──┐ ┌──┐ ┌──────┐ ┌──┐ ┌──┐ │ 56 │ │ 30 46│ │64│ │69│ │37│ │87 41 │ │19│ │43│ └────┘ └──────┘ └──┘ └──┘ └──┘ └──────┘ └──┘ └──┘ ↓ ↓ 분열 5: ┌──┐ ┌──┐ ┌──┐ ┌──┐ │30│ │46│ │87│ │41│ └──┘ └──┘ └──┘ └──┘ ─────────────────────────────────────────────────────── ↑ (이제 합병 시작) ─────────────────────────────────────────────────────── 합병 6: ┌────────┐ ┌────────┐ │30 46 │ │41 87 │ └────────┘ └────────┘ 합병 7: ┌───────────┐ ┌────────┐ ┌───────────┐ ┌────────┐ │30 46 56 │ │64 69 │ │37 41 87 │ │19 43 │ └───────────┘ └────────┘ └───────────┘ └────────┘ 합병 9: ┌───────────────────┐ ┌────────────────────┐ │30 46 56 64 69 │ │19 37 41 43 87 │ └───────────────────┘ └────────────────────┘ 합병14: ┌───────────────────────────────────────┐ │19 30 37 41 43 46 56 64 69 87 │ └───────────────────────────────────────┘ 초기 : 56 30 46 64 69 37 87 41 19 43 분할1 : 56 30 46 64 69 | 37 87 41 19 43 분할2 : 56 30 | 46 64 69 | 37 87 | 41 19 43 분할3 : 56 | 30 | 46 | 64 69 | 37 | 87 | 41 | 19 43 분할4 : 56 | 30 | 46 | 64 | 69 | 37 | 87 | 41 | 19 | 43 병합1 : 30 56 | 46 | 64 69 | 37 | 87 | 41 | 19 43 병합2 : 30 56 | 46 64 69 | 37 87 | 41 | 19 43 병합3 : 30 56 | 46 64 69 | 37 87 | 19 41 43 병합4 : 30 46 56 64 69 | 19 37 41 43 87 병합5 : 19 30 37 41 43 46 56 64 69 87 dct, cvt도 자동변속기로 분류되지만, 작동원리와 승차감은 좀 다릅니다. dct는 수동변속기의 클러치를 두개 넣어서 자동으로 변속하게 한건데, 사용법이 자동변속기랑 같을뿐, 승차감은 수동에 가까운 변속기 입니다. cvt는 원뿔모양의 도르레 두개를 체인으로 연결한건데, 체인이 연속된 원뿔을 왔다갔다하므로, 유체변속기처럼 끊김없이 부드러운 승차감을 주는 동시에, 물리적으로 연결되어있어서 정속주행시 연비도 뛰어납니다. 다만, cvt는 이 체인이 갑작스런 변속시 미끄러질수 있어서, 내구성의 문제가 있죠. 같은 자동변속기 범주에 있지만, 물리적으로 완전히 다른 변속기들입니다."},"title":"무제 10"},"/%EB%AC%B4%EC%A0%9C-11/":{"data":{"":"├── build // 빌드 결과 파일 프로젝트 경로와 완전히 일치 │ ├── src │ │ ├── binary_tree │ │ │ ├── binary_tree.d │ │ │ ├── binary_tree.o │ │ | ├── test │ │ | │ └── test.h │ │ │ ├── test.d │ │ │ ├── test.o │ │ │ └── test // /src/binary_tree/test.cpp 를 보고 있을때 f5 를 눌러서 생기는 파일 │ │ └── data_structure │ │ ├── data_structure.d │ │ ├── data_structure.o │ │ ├── test │ │ │ └── test.h │ │ ├── test.d │ │ ├── test.o │ │ └── test // /src/data_structure/test.cpp 를 보고 있을때 f5 를 눌러서 생기는 파일 │ ├── test // /test.cpp 를 보고 있을때 f5 를 눌러서 생기는 파일 │ ├── test.d │ └── test.o ├── Makefile ├── src │ ├── binary_tree │ │ ├── binary_tree.cpp │ │ ├── binary_tree.h │ │ ├── test │ │ │ └── test.h │ │ ├── test.cpp │ │ └── test2.h │ ├── data_structure │ │ ├── data_structure.cpp │ │ ├── data_structure.h │ │ ├── test │ │ │ └── test.h │ │ ├── test.cpp │ │ └── test2.h │ └── graph └── test.cpp { \"version\": \"2.0.0\", \"tasks\": [ { \"label\": \"(내가 만든) Build active file with Makefile\", \"type\": \"shell\", \"command\": \"make\", \"args\": [ \"MAIN_SRC=${relativeFile}\" ], \"group\": { \"kind\": \"build\", \"isDefault\": true }, \"problemMatcher\": [ \"$gcc\" ], \"detail\": \"Makefile을 사용하여 현재 활성화된 C++ 파일을 빌드합니다.\" } ] } CC=\u003c컴파일러\u003e CFLAGS=\u003c컴파일 옵션\u003e LDFLAGS=\u003c링크 옵션\u003e LDLIBS=\u003c링크 라이브러리 목록\u003e OBJS=\u003cObject 파일 목록\u003e TARGET=\u003c빌드 대상 이름\u003e all: $(TARGET) clean: rm -f *.o rm -f $(TARGET) $(TARGET): $(OBJS) $(CC) -o $@ $(OBJS) 이것은 큰 틀로 해서 확장\n{ \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"(내가 만든) Launch C++ file with Makefile\", \"type\": \"cppdbg\", \"request\": \"launch\", \"program\": \"${workspaceFolder}/build/${relativeFileDirname}/${fileBasenameNoExtension}\", \"args\": [], \"stopAtEntry\": false, \"cwd\": \"${workspaceFolder}\", \"environment\": [], \"externalConsole\": false, \"MIMode\": \"lldb\", \"setupCommands\": [ { \"description\": \"gdb 또는 lldb에 자동 서식 지정 사용\", \"text\": \"-enable-pretty-printing\", \"ignoreFailures\": true } ], \"preLaunchTask\": \"Build active file with Makefile\" } ] } manual 이 존재하는 이유 =\u003e MAIN_SRC 를 넘겨서 어떤 파일을 기준으로 컴파일 하는지 알려주어야해 그리고 그것을 기준으로 컴파일 프로젝트 전체에 여러개의 main 이 존재할 수 있으므로 컴파일러 자체의 의존성 분석 기능(g++ -MM)을 활용해서 적절한 파일만 적절히 링크\n@.src/js/core/router.js\n현재 file 파라미터를 HTML5 History API 를 사용하여 path 기반으로 처리하고 싶은데 계획을 세워줘 최상위 경로는 실제 raw 파일을 접근할때 필요하므로 다른 url 구조를 원해 먼저 어떻게 url 구조를 설계할지 부터 말해줘 아직 코드는 수정하지마\n✦ 안녕하세요! 현재 ?file= 쿼리 파라미터를 사용하는 URL 구조를 HTML5 History API를 활용한 경로 기반 방식으로 변경하는 계획에 대해 문의주셨군요. 최상위 경로를 다른 용도로 사용하고 싶어하시는 점까지 고려하여 다음과 같은 URL 구조를 제안합니다.\n제안하는 URL 구조\n기존 URL 구조를 보다 의미 있고 현대적인 방식으로 개선하기 위해, 애플리케이션의 페이지를 표시하는 모든 URL에 /view/ 라는 접두사를 사용하는 것을 제안합니다.\n기본 경로(Base Path): /view/ 노트 내용을 보여주는 모든 페이지는 이 경로 아래에 위치합니다. 이렇게 하면 말씀하신 대로, 웹사이트의 최상위 경로 (/)는 원본 파일(raw file) 접근 등 다른 목적으로 자유롭게 사용할 수 있습니다. 파일 경로: /view/ 접두사 뒤에 표시할 파일의 경로를 그대로 사용합니다. 예시: notes/project-a.md 파일을 보려면 URL은 /view/notes/project-a.md가 됩니다. 부가 정보 (해시, 하이라이트 등): 제목 링크를 위한 해시(#)나 검색어 하이라이트를 위한 쿼리 파라미터는 기존 구조와 동일하게 유지합니다. 예시: /view/notes/project-a.md?highlightTerm=important#section-2 홈 화면 (초기 페이지): 파일이 선택되지 않은 초기 화면은 /view/ URL로 접근합니다. 기존 구조와 새 구조 비교\n┌────────────────────┬──────────────────────────────────────┬─────────────────────────────────────┐ │ 상황 │ 현재 URL 구조 (?file=…) │ 제안하는 URL 구조 (/view/…) │ ├────────────────────┼──────────────────────────────────────┼─────────────────────────────────────┤ │ 노트 보기 │ /?file=notes/project-a.md │ /view/notes/project-a.md │ │ 특정 제목으로 이동 │ /?file=notes/a.md#heading-1 │ /view/notes/a.md#heading-1 │ │ 검색어 하이라이트 │ /?file=notes/a.md\u0026highlightTerm=test │ /view/notes/a.md?highlightTerm=test │ │ 초기 화면 │ / 또는 /?file= │ /view/ │ └────────────────────┴──────────────────────────────────────┴─────────────────────────────────────┘\n이 구조의 장점\n직관적인 URL: URL만 봐도 어떤 콘텐츠를 보고 있는지 명확하게 알 수 있습니다. 경로 충돌 방지: 최상위 경로를 다른 목적으로 사용할 수 있도록 하여 유연성을 확보합니다. 표준적인 방식: 많은 최신 단일 페이지 애플리케이션(SPA)에서 사용하는 검증된 방식입니다. 이 URL 구조 설계에 동의하시면, 다음 단계로 이 구조를 실제로 코드에 적용하기 위한 구체적인 계획을 세워드리겠습니다.\n참고: 이 변경을 적용하려면, 개발 및 실제 운영 환경에서 /view/로 시작하는 모든 요청을 index.html 파일로 전달하도록 서버 설정 변경이 필요할 수 있습니다. 이 부분은 구현 단계에서 다시 한번 자세히 안내해 드리겠습니다.\n하이라이트의 경우는 프래그먼트 식별자로 처리하는 것이 더 웹에 어울려 https://example.com#:~:text=[prefix-,]textStart[,textEnd][,-suffix] /view/notes 로 처리하는 이유가 있어? 그냥 실제 없을 거 같은 이름의 경로로 하면 될거 같은데 어떻게 생각해 github page 에서도 동작하게 하고 싶어 따로 웹서버 설정을 만지지 않고 처리할려면 어떻게 해야 하는 거야 seo 친화적이고 싶은데 임시로 경로의 markdown 파일의 내용을 index.html 에 넣고 검색엔진이 인덱싱 처리를 할 수 있도록 하는 것은 어때? 전반적인 계획을 다시 제시해줘\n✦ 네, 좋은 질문들입니다! 웹 표준, GitHub Pages 배포, SEO까지 고려한 덕분에 훨씬 더 완성도 높은 계획을 세울 수 있겠습니다. 주신 의견들을 모두 반영하여 전반적인 계획을 다시 제시해 드립니다.\n새로운 계획: URL 구조, GitHub Pages 배포, SEO\nURL 구조: 경로 기반 및 웹 표준 하이라이트 핵심: GitHub Pages에서 서버 설정 없이도 동작하고, 웹 표준을 최대한 활용하는 ‘깨끗한 URL(Clean URL)’ 구조를 채택합니다.\n라우팅 방식: 기존의 ?file= 이나 제안했던 /view/ 대신, 파일 경로 자체를 URL 경로로 사용합니다.\n예시: notes/project-a.md 파일을 보기 위한 URL은 https://.github.io//notes/project-a.md가 됩니다. 하이라이트 방식: 쿼리 파라미터(?highlightTerm=…) 대신, 웹 표준인 텍스트 프래그먼트(Text Fragments)를 사용합니다. 이는 브라우저가 URL의 일부로 특정 텍스트를 찾아 하이라이트하는 기능입니다.\n구조: #:~:text=[접두사-,]시작텍스트[,끝텍스트][,-접미사] 예시: …/notes/project-a.md#:~:text=중요한 내용 최종 URL 구조 비교\n┌───────────────────┬─────────────────────────────┬────────────────────────────────────────────────┐ │ 상황 │ 기존 │ 새로운 제안 │ ├───────────────────┼─────────────────────────────┼────────────────────────────────────────────────┤ │ 노트 보기 │ /?file=notes/a.md │ /notes/a.md │ │ 특정 제목 이동 │ /?file=notes/a.md#heading-1 │ /notes/a.md#heading-1 (변경 없음, 가장 이상적) │ │ 텍스트 하이라이트 │ /?file=notes/a.md\u0026h=test │ /notes/a.md#:~:text=test (웹 표준) │ └───────────────────┴─────────────────────────────┴────────────────────────────────────────────────┘\nGitHub Pages 배포 전략: ‘404.html’ 트릭 말씀하신 대로 GitHub Pages는 Apache의 .htaccess나 Nginx의 rewrite 같은 서버 설정을 지원하지 않습니다. 이 문제를 해결하기 위해 SPA(단일 페이지 애플리케이션)에서 널리 사용되는 영리한 방법인 ‘404.html 트릭’을 사용합니다.\n동작 원리:\n사용자가 https://…/notes/project-a.md에 접속하면, GitHub Pages 서버에는 실제로 해당 경로에 파일이 없으므로 404 Not Found 오류가 발생합니다. 이때, 서버는 우리가 미리 만들어 둔 맞춤 404.html 파일을 사용자에게 보여줍니다. 우리는 index.html의 모든 내용을 그대로 복사해서 404.html을 만듭니다. 404.html 안의 스크립트(router.js)는 현재 URL(…/notes/project-a.md)을 읽어서, 이것이 404 페이지가 아니라 특정 노트를 보여달라는 요청임을 파악합니다. 라우터는 해당 경로의 마크다운 파일을 동적으로 불러와 화면에 렌더링합니다. 결과: 사용자는 404 페이지를 전혀 보지 못하고, 마치 서버가 해당 URL을 직접 처리한 것처럼 자연스럽게 노트 내용을 보게 됩니다. 이 방법으로 서버 설정 없이 ‘깨끗한 URL’을 사용할 수 있습니다.\nSEO 전략: 정적 사이트 생성(SSG)을 통한 사전 렌더링 검색 엔진은 JavaScript를 실행하지 않고 HTML 내용만 보는 경우가 많습니다. 이 문제를 해결하고 SEO를 극대화하기 위해, 웹사이트를 게시하기 전에 모든 마크다운 파일을 각각의 HTML 파일로 미리 만들어두는 ‘정적 사이트 생성(Static Site Generation)’ 방식을 도입합니다.\n구현 계획:\n빌드 스크립트 생성: Python이나 Shell 스크립트로 build.py 같은 빌드 자동화 스크립트를 만듭니다. 스크립트의 역할: 프로젝트 내의 모든 마크다운 파일 (.md)을 찾습니다. 각 마크다운 파일을 HTML로 변환합니다. 미리 정의된 HTML 템플릿(헤더, 푸터, 그리고 변환된 HTML 내용이 들어갈 공간)에 변환된 내용을 삽입하여 완전한 HTML 페이지를 생성합니다. 생성된 HTML 파일들을 dist와 같은 배포용 폴더에 원본과 동일한 경로 구조로 저장합니다. (예: notes/a.md → dist/notes/a.md/index.html 또는 dist/notes/a.md.html) 배포: GitHub Pages의 배포 소스를 dist 폴더로 지정합니다. 기대 효과:\n검색 엔진은 각 URL에 대해 내용이 모두 채워진 HTML 파일을 크롤링하므로 SEO가 극대화됩니다. 사용자가 처음 페이지에 접속할 때는 이 정적 HTML을 먼저 받으므로 초기 로딩 속도가 매우 빠릅니다. 페이지가 로드된 후에는 기존의 SPA 스크립트가 동작하여, 페이지 이동이나 검색 등 모든 상호작용을 동적으로 부드럽게 처리합니다. 종합 실행 계획\n1단계: 라우터 리팩토링 (router.js)\nURL 파싱 로직을 location.search(?file=…)에서 location.pathname을 읽도록 변경합니다. URL 생성 로직(navigate, updateURLOnly)이 새로운 ‘깨끗한 URL’ 구조를 사용하도록 수정합니다. 하이라이트 관련 쿼리 파라미터 로직을 제거합니다. (텍스트 프래그먼트는 브라우저가 처리) 2단계: GitHub Pages 배포 설정\nindex.html을 복사하여 404.html 파일을 생성하고 프로젝트 루트에 둡니다. 3단계 (선택적이지만 강력 추천): SEO를 위한 빌드 스크립트 작성\n모든 마크다운 파일을 HTML로 사전 렌더링하여 dist 폴더에 저장하는 빌드 스크립트를 작성합니다. GitHub Actions를 설정하여, 코드가 변경될 때마다 이 빌드 스크립트가 자동으로 실행되고 dist 폴더의 내용이 GitHub Pages에 배포되도록 자동화할 수 있습니다. 이 계획은 제안해주신 아이디어들을 모두 통합하여, 현대적이고 효율적이며 검색 엔진에도 친화적인 솔루션을 제공합니다. 이 계획대로 진행할까요?"},"title":"무제 11"},"/%EB%AC%B4%EC%A0%9C-2/":{"data":{"":"다음은 요청하신 문서의 마크다운 버전입니다.\n검사 결과 보고서 1111"},"title":"무제 2"},"/%EB%AC%B4%EC%A0%9C-3/":{"data":{"":"┌───────────────────────────┐ │ CPU │ │ (Intel SoC / Host Bridge) │ │ [00:00.0] │ └───────┬─────┬─────────────┘ │ │ │ │ ┌───────────────────┴─┐ ┌─┴────────────────────────┐ │ Integrated Memory │ │ Integrated Devices (On-chip) │ │ Controller (IMC) │ └─┬────────────────────────┘ └─────────┬───────────┘ │ │ ├─ Integrated Graphics (iGPU) [00:02.0] ↓ │ ┌───┐ ├─ RAM Memory (Management) [00:14.2] │RAM│ │ └───┘ └─ PCIe Root Complex (CPU의 PCIe 레인 관리자) │ │ ┌─────────────────────┴────────────────────────────────┐ │ DMI/OPI Link (CPU와 칩셋을 연결하는 전용 고속도로) │ └─────────────────────┬────────────────────────────────┘ │ ↓ ┌───────────────────────────────────┐ │ PCH (Platform Controller Hub) │ │ (메인보드 칩셋) │ └─────────────────┬─────────────────┘ │ ┌─────────────────────────┴──────────────────────────┐ │ PCH 내장 기능 (Relatively Slower I/O) │ ├─ SATA Controller (HDD/SSD) [00:17.0] │ ├─ USB Controller [00:14.0] │ ├─ Audio Device (HD Audio) [00:1f] │ ├─ SMBus Controller [00:1f] │ ├─ Communication Controller (Intel ME) [00:16.0] │ ├─ ISA Bridge (Legacy) [00:1f] │ ├─ Serial Bus Controllers [00:19.0, 00:19.1, 00:1f] │ │ │ │ PCH 자체의 PCIe 레인을 통한 확장 │ └─┬──────────────────────────────────────────────────┘ │ ├─ PCI Bridge [00:1c] ───▶ Bus 01 ─▶ Ethernet Controller #1 [01:00.0] (Realtek RTL8111) │ (첫 번째 유선 랜카드) │ ├─ PCI Bridge [00:1d] ───▶ Bus 02 ─▶ Network Controller [02:00.0] (Realtek RTL8821CE Wi-Fi) │ (무선 랜카드) │ └─ PCI Bridge [00:1d] ───▶ Bus 03 ─▶ Ethernet Controller #2 [03:00.0] (Realtek RTL8111) (두 번째 유선 랜카드) graph TD subgraph CPU 와 직접 연결 CPU[\"CPU\u003cbr/\u003e(Intel SoC / Host Bridge)\u003cbr/\u003e[00:00.0]\"] IMC[\"Integrated Memory Controller\"] RAM[\"RAM\"] iGPU[\"Integrated Graphics (iGPU)\u003cbr/\u003e[00:02.0]\"] RAM_Mgmt[\"RAM Memory (Management)\u003cbr/\u003e[00:14.2]\"] RootComplex[\"PCIe Root Complex\"] CPU --\u003e IMC --\u003e RAM CPU --\u003e iGPU CPU --\u003e RAM_Mgmt CPU --\u003e RootComplex end DMI[\"DMI/OPI Link\u003cbr/\u003e(CPU-칩셋 연결 버스)\"] PCH[\"PCH\u003cbr/\u003e(Platform Controller Hub)\u003cbr/\u003e메인보드 칩셋\"] RootComplex --\u003e DMI --\u003e PCH subgraph PCH 내장 기능 direction LR SATA[\"SATA Controller\u003cbr/\u003e[00:17.0]\"] USB[\"USB Controller\u003cbr/\u003e[00:14.0]\"] Audio[\"Audio Device\u003cbr/\u003e[00:1f]\"] SMBus[\"SMBus Controller\u003cbr/\u003e[00:1f]\"] Comm[\"Communication Controller\u003cbr/\u003e[00:16.0]\"] ISA[\"ISA Bridge\u003cbr/\u003e[00:1f]\"] Serial[\"Serial Bus Controllers\u003cbr/\u003e[00:19.0, 00:19.1, 00:1f]\"] end subgraph PCH PCIe 확장 Bridge1[\"PCI Bridge\u003cbr/\u003e[00:1c]\"] LAN1[\"Ethernet Controller #1\u003cbr/\u003eRealtek RTL8111\u003cbr/\u003e[01:00.0]\"] Bridge2[\"PCI Bridge\u003cbr/\u003e[00:1d]\"] WiFi[\"Network Controller (Wi-Fi)\u003cbr/\u003eRealtek RTL8821CE\u003cbr/\u003e[02:00.0]\"] Bridge3[\"PCI Bridge\u003cbr/\u003e[00:1d]\"] LAN2[\"Ethernet Controller #2\u003cbr/\u003eRealtek RTL8111\u003cbr/\u003e[03:00.0]\"] Bridge1 --\u003e LAN1 Bridge2 --\u003e WiFi Bridge3 --\u003e LAN2 end %% PCH에서 각 하위 장치로의 연결을 명확하게 정의 PCH --\u003e SATA PCH --\u003e USB PCH --\u003e Audio PCH --\u003e SMBus PCH --\u003e Comm PCH --\u003e ISA PCH --\u003e Serial PCH --\u003e Bridge1 PCH --\u003e Bridge2 PCH --\u003e Bridge3 %% 스타일링 classDef cpu fill:#cde4ff,stroke:#555,stroke-width:2px; classDef pch fill:#d5e8d4,stroke:#555,stroke-width:2px; classDef device fill:#f8cecc,stroke:#555,stroke-width:1px; classDef bridge fill:#fff2cc,stroke:#555,stroke-width:1px; class CPU cpu; class PCH pch; class LAN1,WiFi,LAN2,SATA,USB,Audio,SMBus,Comm,ISA,Serial,iGPU,RAM,RAM_Mgmt device; class Bridge1,Bridge2,Bridge3 bridge;"},"title":"무제 3"},"/%EB%AC%B4%EC%A0%9C-4/":{"data":{"":"# 서버 -\u003e 로컬로 동기화 (서버의 최신 변경사항을 로컬로 가져옴) rsync -avz --delete user@your_server_ip:/path/to/remote/dir/ /path/to/local/dir/ # 로컬 -\u003e 서버로 동기화 (로컬의 최신 변경사항을 서버로 보냄) rsync -avz --delete /path/to/local/dir/ user@your_server_ip:/path/to/remote/dir/ ./rstnc.sh push pull 2개의 기능"},"title":"무제 4"},"/%EB%AC%B4%EC%A0%9C-5/":{"data":{"":"shinnyeonki: 파일에서 사용자가 마우스로 클릭을 했을때 기존 타이머를 정지시키는 코드가 뭐야?\nGitHub Copilot: 사용자가 마우스로 클릭했을 때 기존 타이머를 정지시키는 코드를 찾기 위해 관련 파일들을 살펴보겠습니다. 이제 content.js 파일에서 클릭 이벤트 처리 코드를 더 자세히 살펴보겠습니다: 찾았습니다! content.js 파일에서 사용자가 마우스로 클릭했을 때 기존 타이머를 정지시키는 코드는 다음과 같습니다:\n$(document).click((function(e){ chrome.storage.local.get({data:[]},(function(e){ var t=e.data; for(let[e,r]of Object.entries(t)) null!=t[e]\u0026\u0026(null!=t[e]\u0026\u0026!0===t[e].stop_refresh_check||\"true\"===t[e].stop_refresh_check)\u0026\u0026 chrome.runtime.sendMessage({ tabId:\"\", action:\"pause_refresh_active_tab\", tab_url:t[e].tab_url, from:\"content_script\" },(function(e){ null!=e\u0026\u0026\"YES\"==e.status\u0026\u0026$(\"#show_visual_timer\").remove() })) })) })); 이 코드의 동작 방식:\n$(document).click: 문서 전체에서 클릭 이벤트를 감지합니다.\n스토리지 확인: chrome.storage.local.get을 통해 저장된 데이터를 가져옵니다.\n조건 확인: 저장된 데이터에서 stop_refresh_check 옵션이 true로 설정된 항목들을 찾습니다.\n메시지 전송: 조건에 맞는 경우 백그라운드 스크립트(worker.js)에 pause_refresh_active_tab 액션을 보냅니다.\n타이머 제거: 응답이 “YES\"인 경우 화면에서 시각적 타이머(#show_visual_timer)를 제거합니다.\n즉, 이 코드는 사용자가 웹페이지의 아무 곳이나 클릭했을 때, 만약 “클릭 시 새로고침 정지” 옵션이 활성화되어 있다면 자동 새로고침 타이머를 일시정지시키는 기능을 담당합니다.\nshinnyeonki: 타이머 변수는 어디에 저장되어 있는지 알려줘 일반 javascirpt 변수 인지 extension strage 에 저장되어 있는지\nGitHub Copilot: 코드를 분석해보니 타이머와 관련된 데이터는 여러 곳에 저장되어 있습니다:","1-extension-storage-chromestoragelocal#1. Extension Storage (chrome.storage.local)":"주요 타이머 설정 데이터가 여기에 저장됩니다: 이제 worker.js에서 실제 타이머 인터벌을 찾아보겠습니다: 이제 sessionStorage 관련 코드도 확인해보겠습니다: 이제 전체적인 타이머 변수 저장 위치를 정리해드리겠습니다:","1-extension-storage-chromestoragelocal-1#1. \u003cstrong\u003eExtension Storage (chrome.storage.local)\u003c/strong\u003e":"주요 타이머 설정 데이터가 여기에 영구적으로 저장됩니다 저장되는 데이터: mili_seconds: 새로고침 간격 (밀리초) btn_start: 타이머 시작/정지 상태 custom_refresh: 커스텀 새로고침 여부 dynamic_limit_input: 동적 제한 입력값 show_visual_timer_check: 시각적 타이머 표시 여부 stop_refresh_check: 클릭 시 정지 옵션 hard_refresh_check: 하드 새로고침 여부 tab_url, tabId 등","2-javascript-변수-workerjs#2. \u003cstrong\u003eJavaScript 변수 (worker.js)\u003c/strong\u003e":"var htvg = []; // 실제 setInterval 타이머들을 저장하는 배열 var vgb = []; // 타이머 설정 데이터를 임시 저장하는 배열 htvg 배열: 실제 setInterval 객체들이 저장됨\nvar v = setInterval((function(){ chrome.tabs.sendMessage(e, {action:\"refresh\", ...}) }), s); // s는 밀리초 간격 t.push({ tabId: e, intervals: v, // 실제 타이머 ID mili_seconds: s, // ... 기타 설정들 });","3-session-storage#3. \u003cstrong\u003eSession Storage\u003c/strong\u003e":"카운터 정보만 임시 저장:\nsessionStorage.setItem(\"counterObj\", JSON.stringify({ counter: ++n, // 새로고침 횟수 tabId: e.tabId }));","4-dom-요소#4. \u003cstrong\u003eDOM 요소\u003c/strong\u003e":"시각적 타이머 UI:\n$(\"#timer_iframe_arte\").contents().find(\"body\").append( '' );","요약#요약":"실제 타이머 변수는 여러 곳에 분산 저장됩니다:\n실제 타이머 인터벌: worker.js의 htvg 배열 (JavaScript 변수) 타이머 설정: chrome.storage.local (Extension Storage) 새로고침 카운터: sessionStorage (브라우저 세션 스토리지) UI 타이머: DOM 요소 클릭 시 타이머를 정지시키는 코드는 Extension Storage에서 설정을 확인한 후, JavaScript 변수에 저장된 실제 setInterval ID를 사용하여 clearInterval()로 타이머를 정지시킵니다.","타이머-변수-저장-위치-분석#타이머 변수 저장 위치 분석":""},"title":"무제 5"},"/%EB%AC%B4%EC%A0%9C-6/":{"data":{"":"네, 직접 매우 단순한 WSGI 애플리케이션과 이를 실행할 수 있는 매우 단순한 WSGI 서버를 만들어 보겠습니다. 이를 통해 WSGI 인터페이스가 어떻게 동작하는지 직관적으로 이해할 수 있을 겁니다.","1-매우-단순한-wsgi-애플리케이션-my_simple_apppy#1. 매우 단순한 WSGI 애플리케이션 (\u003ccode\u003emy_simple_app.py\u003c/code\u003e)":"이것은 우리가 만들 웹 “애플리케이션\"입니다. 웹 프레임워크 없이 순수 WSGI 규약에 맞춰 작성됩니다.\n# my_simple_app.py import sys def my_simple_app(environ, start_response): \"\"\" 이것은 WSGI 규약을 따르는 매우 단순한 웹 애플리케이션입니다. Args: environ (dict): 웹 서버로부터 받은 요청 정보(환경 변수). 예: 'REQUEST_METHOD', 'PATH_INFO', 'QUERY_STRING' 등 'wsgi.input', 'wsgi.errors' 등 WSGI 관련 정보도 포함. start_response (callable): 서버가 제공하는 함수로, 애플리케이션이 HTTP 응답 상태 코드와 헤더를 서버에 전달할 때 사용합니다. 시그니처: start_response(status, headers, exc_info=None) Returns: iterable: 응답 본문(body)을 포함하는 바이트 문자열의 이터러블. \"\"\" status = '200 OK' # HTTP 상태 코드 headers = [ ('Content-type', 'text/plain; charset=utf-8'), ('X-Powered-By', 'MySimpleWSGIApp') # 커스텀 헤더도 가능 ] # start_response 함수를 호출하여 상태 코드와 헤더를 서버에게 전달합니다. start_response(status, headers) # 요청 경로를 확인하여 다른 응답을 줄 수 있습니다. path = environ.get('PATH_INFO', '/') if path == '/': response_body = b\"Hello from My Simple WSGI App! (Homepage)\\n\" elif path == '/hello': response_body = b\"Hello, specific page!\\n\" elif path == '/info': response_body = b\"Environment info:\\n\" # environ 딕셔너리의 내용을 응답 본문에 추가 for key, value in sorted(environ.items()): response_body += f\"{key}: {value}\\n\".encode('utf-8') else: status = '404 Not Found' headers = [('Content-type', 'text/plain; charset=utf-8')] start_response(status, headers) # 404 상태로 다시 호출 response_body = b\"404 Not Found: This page does not exist.\\n\" # 응답 본문은 바이트 문자열의 이터러블이어야 합니다. # 단순화를 위해 여기서는 하나의 바이트 문자열을 리스트에 담아 반환합니다. return [response_body] # 이 파일이 직접 실행될 경우 (예: 개발 서버용) if __name__ == '__main__': # 이 부분은 실제 WSGI 서버(Gunicorn, uWSGI)가 하는 일을 매우 간소화한 것입니다. # 실제 서버가 애플리케이션을 로드하여 실행합니다. print(\"This is a WSGI application module. It needs a WSGI server to run.\") print(\"Try running `python simple_wsgi_server.py` and access http://localhost:8000/\")","2-매우-단순한-wsgi-서버-simple_wsgi_serverpy#2. 매우 단순한 WSGI 서버 (\u003ccode\u003esimple_wsgi_server.py\u003c/code\u003e)":"이것은 클라이언트의 HTTP 요청을 받아 우리 my_simple_app WSGI 애플리케이션을 호출하고, 그 결과를 클라이언트에게 다시 HTTP 응답으로 보내는 역할을 하는 서버입니다. 실제 Gunicorn이나 uWSGI와 비교할 수 없을 정도로 단순하며, 한 번에 하나의 요청만 처리합니다.\n# simple_wsgi_server.py import socket import sys import os # PATH_INFO에 필요한 모듈 # 우리가 만든 WSGI 애플리케이션을 임포트합니다. from my_simple_app import my_simple_app class SimpleWSGIServer: def __init__(self, host, port, application): self.host = host self.port = port self.application = application self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # 개발 시 재시작할 때 주소가 이미 사용 중인 문제를 방지 self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) def serve_forever(self): self.socket.bind((self.host, self.port)) self.socket.listen(1) # 한 번에 하나의 연결만 대기 print(f\"Serving WSGI app on http://{self.host}:{self.port}/...\") print(\"Try accessing /hello, /info, or /nonexistent_page\") while True: client_connection, client_address = self.socket.accept() print(f\"Accepted connection from {client_address}\") self.handle_request(client_connection) def handle_request(self, client_connection): # 1. 클라이언트 요청 데이터 수신 및 파싱 request_data = client_connection.recv(1024).decode('utf-8') request_lines = request_data.split('\\r\\n') if not request_lines: client_connection.close() return request_line = request_lines[0] try: method, path, version = request_line.split(' ') except ValueError: # 유효하지 않은 요청 라인 처리 client_connection.sendall(b\"HTTP/1.1 400 Bad Request\\r\\n\\r\\nBad Request\") client_connection.close() return # 2. `environ` 딕셔너리 생성 (매우 간소화된 버전) # 실제 WSGI 서버는 이 딕셔너리를 훨씬 더 풍부하게 채웁니다. environ = { 'REQUEST_METHOD': method, 'PATH_INFO': path.split('?')[0], # 쿼리 스트링 분리 'QUERY_STRING': path.split('?')[1] if '?' in path else '', 'SERVER_NAME': self.host, 'SERVER_PORT': str(self.port), 'SERVER_PROTOCOL': version, 'wsgi.version': (1, 0), 'wsgi.url_scheme': 'http', 'wsgi.input': client_connection.makefile('rb', -1), # 요청 본문 스트림 (여기에선 사용 안함) 'wsgi.errors': sys.stderr, # 에러 로그 스트림 'wsgi.multithread': False, # 이 서버는 단일 쓰레드 'wsgi.multiprocess': False, # 이 서버는 단일 프로세스 'wsgi.run_once': False, # 계속 실행됨 } # 3. `start_response` 콜러블 정의 # 이 함수는 애플리케이션이 호출하여 응답 상태 및 헤더를 서버에게 알려줍니다. headers_set = [] # 애플리케이션이 설정할 상태 및 헤더를 저장할 리스트 response_started = False def start_response(status, headers, exc_info=None): nonlocal response_started if response_started: raise RuntimeError(\"start_response() already called!\") response_started = True headers_set.append(status) headers_set.extend(headers) # exc_info는 에러 처리 시 사용되지만, 여기서는 생략합니다. # print(f\"[Server] App called start_response: Status={status}, Headers={headers}\") return None # WSGI 스펙에 따라 None 반환 # 4. WSGI 애플리케이션 호출 try: app_body_iterable = self.application(environ, start_response) # 5. HTTP 응답 구성 및 전송 response_status = headers_set[0] response_headers = headers_set[1:] response_line = f\"HTTP/1.1 {response_status}\\r\\n\" response_headers_str = \"\" for header_name, header_value in response_headers: response_headers_str += f\"{header_name}: {header_value}\\r\\n\" # 최종 헤더 full_response_headers = (response_line + response_headers_str + \"\\r\\n\").encode('utf-8') client_connection.sendall(full_response_headers) # 애플리케이션이 반환한 이터러블로부터 본문을 읽어 전송 for data in app_body_iterable: client_connection.sendall(data) # data는 이미 바이트 문자열이어야 합니다. except Exception as e: # 애플리케이션 내부에서 발생한 예상치 못한 오류 처리 print(f\"Error handling request: {e}\", file=sys.stderr) error_response = b\"HTTP/1.1 500 Internal Server Error\\r\\nContent-Type: text/plain\\r\\n\\r\\nInternal Server Error\" client_connection.sendall(error_response) finally: # 요청 처리 완료 후 클라이언트 연결 닫기 client_connection.close() print(f\"Connection from {client_address} closed.\") # 서버 실행 if __name__ == '__main__': HOST = '127.0.0.1' # localhost PORT = 8000 server = SimpleWSGIServer(HOST, PORT, my_simple_app) server.serve_forever()","wsgi의-핵심-원리-callable호출-가능한-객체#WSGI의 핵심 원리: Callable(호출 가능한 객체)":"WSGI의 가장 중요한 부분은 “애플리케이션\"이 application(environ, start_response) 이라는 시그니처를 가진 **호출 가능한 객체(callable)**여야 한다는 것입니다.\nenviron: 웹 서버로부터 받은 요청 정보(HTTP 헤더, 경로, 쿼리 파라미터 등)를 담은 딕셔너리입니다. start_response: 애플리케이션이 웹 서버에게 HTTP 응답 상태 코드(예: “200 OK”)와 응답 헤더를 보내기 위해 호출해야 하는 함수입니다. 웹 서버가 이 함수를 제공합니다. 애플리케이션은 이 두 인자를 받아 처리하고, 응답 본문(body)을 포함하는 이터러블(iterable) 객체를 반환해야 합니다.","실행-방법#실행 방법":"위 코드들을 각각 my_simple_app.py와 simple_wsgi_server.py 파일로 저장합니다.\n터미널을 열고 simple_wsgi_server.py 파일이 있는 디렉토리로 이동합니다.\n다음 명령어를 실행합니다:\npython simple_wsgi_server.py 콘솔에 “Serving WSGI app on http://127.0.0.1:8000/…” 메시지가 나타나면, 웹 브라우저를 열고 다음 주소들을 방문해 보세요:\nhttp://127.0.0.1:8000/ http://127.0.0.1:8000/hello http://127.0.0.1:8000/info (environ 딕셔너리 내용을 볼 수 있습니다) http://127.0.0.1:8000/nonexistent_page (404 에러를 확인)","코드-설명-및-wsgi-이해#코드 설명 및 WSGI 이해":"이 예제를 통해 WSGI의 핵심을 이해할 수 있습니다:\n애플리케이션(App)과 서버(Server)의 분리:\nmy_simple_app.py는 오직 WSGI 규약에 맞춰 application이라는 함수를 구현합니다. 이 함수는 HTTP 요청/응답에 대한 지식은 거의 없고, 오직 environ 딕셔너리와 start_response 함수를 다루는 방법만 압니다. simple_wsgi_server.py는 HTTP 프로토콜(소켓 통신, 요청 파싱, 응답 전송)을 처리하고, my_simple_app을 호출하기 위한 environ과 start_response를 준비합니다. 이러한 분리 덕분에, 개발자는 my_simple_app과 같은 WSGI 애플리케이션을 한 번 작성하면, 어떤 WSGI 호환 서버(Gunicorn, uWSGI 등)에서도 실행할 수 있습니다. 반대로, 서버 개발자는 어떤 WSGI 호환 애플리케이션이라도 실행할 수 있습니다. environ 딕셔너리:\n서버는 클라이언트의 HTTP 요청을 파싱하여 다양한 정보를 environ 딕셔너리에 담아 애플리케이션에 전달합니다. PATH_INFO, REQUEST_METHOD, QUERY_STRING 등이 대표적입니다. 또한 wsgi.version, wsgi.input (요청 본문을 읽기 위한 파일 객체), wsgi.errors (에러 로그를 위한 파일 객체)와 같은 WSGI 자체의 환경 변수도 포함됩니다. start_response 콜러블:\n애플리케이션은 응답 본문을 반환하기 전에 반드시 이 start_response 함수를 호출해야 합니다. 이 호출을 통해 서버는 HTTP 상태 코드(예: “200 OK”)와 응답 헤더(예: Content-Type)를 알게 되고, 실제 응답의 첫 부분을 클라이언트에게 보낼 준비를 합니다. 반환 값: 이터러블 본문:\n애플리케이션은 응답 본문을 바이트 문자열의 이터러블로 반환합니다. 이 예제에서는 [b\"Hello...\"]와 같이 하나의 리스트에 담았지만, 큰 파일 전송의 경우 제너레이터를 사용하여 메모리 효율적으로 데이터를 스트리밍할 수도 있습니다. 이 간단한 예제를 통해 WSGI가 웹 서버와 Python 웹 애플리케이션 사이에 어떻게 표준화된 인터페이스 역할을 하는지 이해할 수 있을 것입니다. 실제 Gunicorn 같은 WSGI 서버는 이 기본적인 원리 위에 멀티프로세싱/멀티스레딩, 로깅, 설정 관리 등 훨씬 더 복잡한 기능들을 추가하여 프로덕션 환경에 적합하도록 만듭니다."},"title":"무제 6"},"/%EB%AC%B4%EC%A0%9C-7/":{"data":{"":"rsync(1) 사용자 명령어 rsync(1) NAME rsync - 빠르고, 다용도이며, 원격(및 로컬) 파일 복사 도구 SYNOPSIS 로컬: rsync [OPTION...] SRC... [DEST] 원격 셸을 통한 접근: 가져오기 (Pull): rsync [OPTION...] [USER@]HOST:SRC... [DEST] 보내기 (Push): rsync [OPTION...] SRC... [USER@]HOST:DEST rsync 데몬을 통한 접근: 가져오기 (Pull): rsync [OPTION...] [USER@]HOST::SRC... [DEST] rsync [OPTION...] rsync://[USER@]HOST[:PORT]/SRC... [DEST] 보내기 (Push): rsync [OPTION...] SRC... [USER@]HOST::DEST rsync [OPTION...] SRC... rsync://[USER@]HOST[:PORT]/DEST) 단일 SRC 인자만 있고 DEST 인자가 없는 사용법은 파일을 복사하는 대신 소스 파일을 나열합니다. 이 맨페이지의 온라인 버전(주제 간 상호 링크 포함)은 https://download.samba.org/pub/rsync/rsync.1 에서 확인할 수 있습니다. DESCRIPTION Rsync는 빠르고 매우 다용도의 파일 복사 도구입니다. 로컬에서, 모든 원격 셸을 통해 다른 호스트로/로부터, 또는 원격 rsync 데몬으로/로부터 파일을 복사할 수 있습니다. 이 도구는 동작의 모든 측면을 제어하고 복사할 파일 집합을 매우 유연하게 지정할 수 있는 수많은 옵션을 제공합니다. Rsync는 소스 파일과 대상에 있는 기존 파일 간의 차이점만 전송하여 네트워크를 통해 전송되는 데이터 양을 줄이는 델타-전송 알고리즘으로 유명합니다. Rsync는 백업 및 미러링에 널리 사용되며, 일상적인 사용을 위한 개선된 복사 명령어로도 활용됩니다. Rsync는 \"빠른 검사(quick check)\" 알고리즘(기본값)을 사용하여 전송해야 할 파일을 찾는데, 이 알고리즘은 크기 또는 최종 수정 시간이 변경된 파일을 찾습니다. (옵션으로 요청된) 다른 보존된 속성의 변경사항은 빠른 검사가 파일 데이터 업데이트가 필요 없다고 판단할 때 대상 파일에 직접 적용됩니다. rsync의 추가 기능 중 일부는 다음과 같습니다: o 링크, 장치, 소유자, 그룹 및 권한 복사 지원 o GNU tar와 유사한 exclude 및 exclude-from 옵션 o CVS가 무시하는 파일과 동일한 파일을 무시하는 CVS exclude 모드 o ssh 또는 rsh를 포함한 모든 투명한 원격 셸 사용 가능 o 슈퍼유저 권한 불필요 o 지연 시간 비용을 최소화하기 위한 파일 전송 파이프라이닝 o 익명 또는 인증된 rsync 데몬 지원 (미러링에 이상적) GENERAL Rsync는 원격 호스트로/로부터, 또는 현재 호스트의 로컬에서 파일을 복사합니다 (두 개의 원격 호스트 간 파일 복사는 지원하지 않습니다). rsync가 원격 시스템에 접속하는 두 가지 방법이 있습니다: 원격-셸 프로그램(예: ssh 또는 rsh)을 전송 수단으로 사용하거나, TCP를 통해 rsync 데몬에 직접 접속하는 것입니다. 원격-셸 전송은 소스 또는 대상 경로에 호스트 사양 뒤에 단일 콜론(:) 구분자가 포함될 때 사용됩니다. rsync 데몬에 직접 접속하는 경우는 소스 또는 대상 경로에 호스트 사양 뒤에 이중 콜론(::) 구분자가 포함되거나, OR rsync:// URL이 지정될 때 발생합니다 (후자 규칙의 예외는 USING RSYNC-DAEMON FEATURES VIA A RE‐ MOTE-SHELL CONNECTION 섹션 참조). 특별한 경우로, 대상 없이 단일 소스 인자만 지정되면, 파일은 \"ls -l\"과 유사한 출력 형식으로 나열됩니다. 예상대로, 소스 또는 대상 경로 모두 원격 호스트를 지정하지 않으면 로컬 복사가 발생합니다 (--list-only 옵션 참조). Rsync는 로컬 측을 클라이언트(client)로, 원격 측을 서버(server)로 지칭합니다. 서버와 rsync 데몬을 혼동하지 마십시오. 데몬은 항상 서버이지만, 서버는 데몬 또는 원격-셸에서 실행된 프로세스일 수 있습니다. SETUP 설치 지침은 README.md 파일을 참조하십시오. 설치 후, 원격 셸을 통해 접근할 수 있는 모든 머신(및 rsync 데몬 모드 프로토콜을 사용하여 접근할 수 있는 일부 머신)에 rsync를 사용할 수 있습니다. 원격 전송의 경우, 최신 rsync는 통신을 위해 ssh를 사용하지만, 기본적으로 rsh 또는 remsh와 같은 다른 원격 셸을 사용하도록 구성되었을 수도 있습니다. -e 명령줄 옵션을 사용하거나 RSYNC_RSH 환경 변수를 설정하여 원하는 원격 셸을 지정할 수도 있습니다. rsync는 소스 및 대상 머신 모두에 설치되어야 합니다. USAGE rsync는 rcp를 사용하는 것과 동일한 방식으로 사용합니다. 소스와 대상을 지정해야 하며, 그 중 하나는 원격일 수 있습니다. 구문을 설명하는 가장 좋은 방법은 몇 가지 예시를 드는 것입니다: rsync -t *.c foo:src/ 이것은 현재 디렉토리에서 패턴 *.c와 일치하는 모든 파일을 머신 foo의 src 디렉토리로 전송합니다. 만약 파일 중 일부가 원격 시스템에 이미 존재한다면, rsync 원격-업데이트 프로토콜은 데이터의 차이점만을 전송하여 파일을 업데이트하는 데 사용됩니다. 명령줄 와일드카드(*.c)가 파일 목록으로 확장되는 것은 rsync 자체가 아닌 셸에 의해 처리됩니다 (다른 모든 Posix-스타일 프로그램과 정확히 동일합니다). rsync -avz foo:src/bar /data/tmp 이것은 머신 foo의 src/bar 디렉토리에서 로컬 머신의 /data/tmp/bar 디렉토리로 모든 파일을 재귀적으로 전송합니다. 파일은 아카이브 모드로 전송되어 심볼릭 링크, 장치, 속성, 권한, 소유권 등이 전송 시 보존됩니다. 또한, 압축이 사용되어 전송되는 데이터 부분의 크기를 줄입니다. rsync -avz foo:src/bar/ /data/tmp 소스에 있는 후행 슬래시(trailing slash)는 대상에 추가 디렉토리 수준이 생성되는 것을 방지하도록 이 동작을 변경합니다. 소스의 후행 /를 \"이 디렉토리의 내용을 복사하라\"는 의미로 생각할 수 있으며, 이는 \"디렉토리 이름으로 복사하라\"는 것과 대조됩니다. 하지만 두 경우 모두 포함하는 디렉토리의 속성은 대상의 포함하는 디렉토리로 전송됩니다. 다시 말해, 다음 명령들은 /dest/foo의 속성 설정을 포함하여 동일한 방식으로 파일을 복사합니다: rsync -av /src/foo /dest rsync -av /src/foo/ /dest/foo 또한 호스트 및 모듈 참조는 기본 디렉토리의 내용을 복사하기 위해 후행 슬래시를 필요로 하지 않습니다. 예를 들어, 다음 두 가지 모두 원격 디렉토리의 내용을 \"/dest\"로 복사합니다: rsync -av host: /dest rsync -av host::module /dest 소스 또는 대상 경로에 ':'가 없는 로컬 전용 모드로 rsync를 사용할 수도 있습니다. 이 경우, rsync는 개선된 복사 명령처럼 동작합니다. 마지막으로, 모듈 이름을 생략하면 특정 rsync 데몬에서 사용 가능한 모든 (나열 가능한) 모듈을 나열할 수 있습니다: rsync somehost.mydomain.com:: COPYING TO A DIFFERENT NAME 디렉토리를 다른 이름으로 복사하려면, 소스 디렉토리에 후행 슬래시를 사용하여 디렉토리의 내용을 원하는 대상 디렉토리에 넣으십시오: rsync -ai foo/ bar/ Rsync는 단일 항목을 복사할 때 대상 파일의 이름을 사용자 정의하는 기능도 가지고 있습니다. 이에 대한 규칙은 다음과 같습니다: o 전송 목록은 단일 항목(파일 또는 빈 디렉토리)으로 구성되어야 합니다. o 대상 경로의 마지막 요소가 디렉토리로 존재해서는 안 됩니다. o 대상 경로가 후행 슬래시로 지정되지 않아야 합니다. 이러한 상황에서 rsync는 대상의 단일 항목 이름을 대상 경로의 마지막 요소로 설정합니다. 이러한 구문은 파일을 복사할 때만 사용하고, 디렉토리를 복사할 때는 위에 언급된 후행 슬래시 구문을 사용하는 것이 가장 좋습니다. 다음 예시는 foo.c 파일을 save 디렉토리 내에서 bar.c로 복사합니다 (bar.c가 디렉토리가 아니라고 가정): rsync -ai src/foo.c save/bar.c 단일 항목 복사 규칙은 사용자가 알지 못하는 사이에 단일 항목을 복사하고 존재하지 않는 대상 디렉토리를 지정할 때 (후행 슬래시 없이) 실수로 문제를 일으킬 수 있습니다. 예를 들어, src/*.c가 하나의 파일과 일치하고 save/dir이 존재하지 않으면, 대상 파일의 이름을 save/dir로 지정하여 혼란을 줄 수 있습니다: rsync -ai src/*.c save/dir 이러한 사고를 방지하려면 대상 디렉토리가 존재하는지 확인하거나 후행 슬래시를 사용하여 대상 경로를 지정하십시오: rsync -ai src/*.c save/dir/ SORTED TRANSFER ORDER Rsync는 항상 지정된 파일 이름을 내부 전송 목록으로 정렬합니다. 이것은 동일한 이름의 디렉토리 내용을 병합하고, 중복 파일 이름을 쉽게 제거할 수 있도록 합니다. 그러나 파일이 명령줄에 주어진 순서와 다른 순서로 전송될 때 혼란을 줄 수 있습니다. 특정 파일을 다른 파일보다 먼저 전송해야 하는 경우, 파일을 별도의 rsync 호출로 분리하거나, --delay-updates (정렬된 전송 순서에는 영향을 주지 않지만, 최종 파일 업데이트 단계를 훨씬 빠르게 만듭니다)를 사용하는 것을 고려하십시오. MULTI-HOST SECURITY Rsync는 전송에서 공유되는 파일 요청이 다양한 보안 문제로부터 보호되도록 조치를 취합니다. 잠재적인 문제의 대부분은 수신 측에서 발생하며, rsync는 전송되는 파일 목록이 요청된 범위 내에 있도록 조치를 취합니다. 이를 위해 rsync 3.1.2 이상 버전은 파일 목록에 전송 상단을 벗어나려는 절대 또는 상대 경로가 포함될 경우 중단됩니다. 또한, 버전 3.2.5부터 rsync는 파일 목록에 대한 두 가지 안전 점검을 추가로 수행합니다. (1) 클라이언트가 요청한 것 외에 추가 소스 인자가 전송에 추가되지 않았는지 확인하고, (2) 파일 목록이 전송자에게 보낸 제외 규칙을 준수하는지 확인합니다. 아직 3.2.5 클라이언트 rsync를 가지고 있지 않거나(또는 추가로 조심하고 싶은 사람들을 위해), 원격 호스트를 신뢰하지 않을 때는 원격 파일을 위한 전용 대상 디렉토리로 복사하는 것이 가장 안전합니다. 예를 들어, 홈 디렉토리로 rsync 복사를 수행하는 대신: rsync -aiv host1:dir1 ~ 원격 콘텐츠를 위한 \"host1-files\" 디렉토리를 전용으로 사용하십시오: rsync -aiv host1:dir1 ~/host1-files 자세한 내용은 --trust-sender 옵션을 참조하십시오. 주의: rsync를 사용하여 대소문자 구별 파일 시스템에서 대소문자 무시 파일 시스템으로 파일을 복사하는 것은 특별히 안전하지 않습니다. 이러한 복사를 수행해야 하는 경우, --no-links를 통해 심볼릭 링크를 비활성화하거나 --munge-links를 통해 심볼릭 링크의 변형을 활성화해야 합니다 (그리고 올바른 로컬 또는 원격 옵션을 사용해야 합니다). 이는 심볼릭 링크 이름이 파일 또는 디렉토리와 겹칠 경우 rsync가 잠재적으로 위험한 작업을 수행하는 것을 방지합니다. 그러나 모든 파일의 완전한 복사를 보장하지는 않습니다 (이름이 겹치는 경우 불가능할 수 있기 때문입니다). 더 나은 해결책은 모든 소스 파일을 나열하고 --files-from 옵션에 전달할 안전한 파일 이름 목록을 만드는 것입니다. 이름이 충돌하는 파일은 여러 번의 복사를 사용하여 다른 대상 디렉토리로 복사해야 합니다. 대소문자 무시 파일 시스템에서 대소문자 무시 파일 시스템으로의 복사는 상당히 잘 작동할 수 있지만, --delete-during 또는 --delete-before 옵션이 활성화되어 있지 않으면, rsync는 수신 측의 기존 파일을 업데이트하면서 파일 이름의 대소문자를 전송자와 일치하도록 변경해야 한다는 것을 인지하지 못할 수 있습니다. ADVANCED USAGE 원격 호스트에서 여러 파일을 요청하는 구문은 첫 번째와 동일한 스타일로 추가 원격-호스트 인자를 지정하거나 호스트 이름을 생략하여 수행됩니다. 예를 들어, 다음 모두 작동합니다: rsync -aiv host:file1 :file2 host:file{3,4} /dest/ rsync -aiv host::modname/file{1,2} host::modname/extra /dest/ rsync -aiv host::modname/first ::extra-file{1,2} /dest/ 데몬 연결은 한 복사 명령당 하나의 모듈만 액세스할 수 있으므로, 후속 경로의 시작이 첫 번째 경로의 모듈 이름으로 시작하지 않으면 해당 모듈 내의 경로로 간주됩니다 (예: 위에 가져온 extra-file1 및 extra-file2). 아주 오래된 rsync 버전(2.6.9 이하)은 단일 원격-소스 인자만 허용했으므로, 일부 사람들은 대신 원격 셸이 공백 분할을 수행하여 인자를 여러 경로로 나눌 것에 의존했습니다. 그러한 직관적이지 않은 동작은 더 이상 기본적으로 지원되지 않습니다 (하지만 아래 설명된 대로 요청할 수 있습니다). 3.2.4부터 파일 이름은 원격 셸에 전달될 때 사용자가 제공한 문자를 보존하는 방식으로 전달됩니다. 따라서, 이름에 공백이 있는 파일을 요청하면 원격 rsync는 해당 파일을 찾습니다: rsync -aiv host:'a simple file.pdf' /dest/ 원격 rsync 인자에 수동으로 추가 인용(quoting)을 적용하거나 원격 인자 분할을 요구하도록 작성된 스크립트를 사용하는 경우, rsync에게 스크립트가 추가 이스케이핑을 처리하도록 요청할 수 있습니다. 이는 스크립트의 rsync 실행에 --old-args 옵션을 추가하거나 (새로운 rsync 필요) RSYNC_OLD_ARGS=1 및 RSYNC_PROTECT_ARGS=0을 내보내면 됩니다 (이것은 오래된 또는 새로운 rsync 버전 모두에서 작동합니다). CONNECTING TO AN RSYNC DAEMON 원격 셸을 전송 수단으로 사용하지 않고 rsync를 사용하는 것도 가능합니다. 이 경우 일반적으로 TCP 포트 873을 사용하여 원격 rsync 데몬에 직접 연결합니다. (이는 당연히 데몬이 원격 시스템에서 실행 중이어야 하므로, 이에 대한 정보는 아래의 STARTING AN RSYNC DAEMON TO ACCEPT CONNECTIONS 섹션을 참조하십시오.) 이러한 방식으로 rsync를 사용하는 것은 원격 셸과 함께 사용하는 것과 동일하지만 다음을 제외합니다: o 단일 콜론(원격 셸) 구문 대신 이중 콜론 구문 또는 rsync:// URL 구문을 사용하십시오. o \"경로\"의 첫 번째 요소는 실제 모듈 이름입니다. o 추가 원격 소스 인자는 ADVANCED USAGE에서 논의된 바와 같이 호스트 이름 및/또는 모듈 이름을 생략하는 축약된 구문을 사용할 수 있습니다. o 원격 데몬은 연결 시 \"오늘의 메시지(message of the day)\"를 출력할 수 있습니다. o 호스트만 지정하고 (모듈이나 경로 없이) 지정하면 데몬에서 접근 가능한 모듈 목록이 출력됩니다. o 원격 소스 경로를 지정했지만 대상을 지정하지 않으면 원격 데몬에서 일치하는 파일 목록이 출력됩니다. o --rsh (-e) 옵션은 소켓 연결 방식에서 USING RSYNC-DAEMON FEATURES VIA A REMOTE-SHELL CONNECTION 방식으로 연결 스타일이 변경되는 것을 방지하기 위해 생략해야 합니다. \"src\"라는 이름의 원격 모듈의 모든 파일을 복사하는 예: rsync -av host::src /dest 원격 데몬의 일부 모듈은 인증을 요구할 수 있습니다. 이 경우 연결 시 암호 프롬프트가 나타납니다. 환경 변수 RSYNC_PASSWORD를 사용하려는 암호로 설정하거나 --password-file 옵션을 사용하여 암호 프롬프트를 피할 수 있습니다. 이는 rsync를 스크립트화할 때 유용할 수 있습니다. 경고: 일부 시스템에서는 환경 변수가 모든 사용자에게 보일 수 있습니다. 해당 시스템에서는 --password-file 사용을 권장합니다. 환경 변수 RSYNC_PROXY를 웹 프록시를 가리키는 hostname:port 쌍으로 설정하여 웹 프록시를 통해 연결을 설정할 수 있습니다. 웹 프록시의 구성은 포트 873으로의 프록시 연결을 지원해야 합니다. 또한 환경 변수 RSYNC_CONNECT_PROG를 직접 소켓 연결을 수행하는 대신 실행할 명령어로 설정하여 프로그램을 프록시로 사용하여 데몬 연결을 설정할 수 있습니다. 이 문자열에는 rsync 명령에 지정된 호스트 이름을 나타내는 이스케이프 \"%H\"가 포함될 수 있습니다 (따라서 문자열에 단일 \"%\"가 필요한 경우 \"%%\"를 사용하십시오). 예: export RSYNC_CONNECT_PROG='ssh proxyhost nc %H 873' rsync -av targethost1::module/src/ /dest/ rsync -av rsync://targethost2/module/src/ /dest/ 위에 지정된 명령은 ssh를 사용하여 프록시 호스트에서 nc (netcat)를 실행하고, 모든 데이터를 대상 호스트(%H)의 포트 873 (rsync 데몬)으로 전달합니다. 또한 RSYNC_SHELL 환경 변수가 설정되면, 해당 프로그램이 system() 호출의 기본 셸을 사용하는 대신 RSYNC_CONNECT_PROG 명령을 실행하는 데 사용됩니다. USING RSYNC-DAEMON FEATURES VIA A REMOTE-SHELL CONNECTION 실제로 시스템에 새로운 소켓 연결을 허용하지 않고(원격 셸 액세스에 이미 필요한 것 외에) rsync 데몬의 다양한 기능(예: 명명된 모듈)을 사용하는 것이 유용할 때가 있습니다. Rsync는 원격 셸을 사용하여 호스트에 연결한 다음, 원격 사용자의 홈 디렉토리에서 구성 파일을 읽을 것으로 예상되는 단일 사용 \"데몬\" 서버를 스폰(spawn)하는 것을 지원합니다. 이는 데몬 스타일 전송의 데이터를 암호화하려는 경우 유용할 수 있지만, 데몬이 원격 사용자에 의해 새로 시작되므로 chroot와 같은 기능을 사용하거나 데몬이 사용하는 uid를 변경하지 못할 수 있습니다. (데몬 전송을 암호화하는 또 다른 방법으로는 ssh를 사용하여 로컬 포트를 원격 머신으로 터널링하고, 해당 원격 호스트의 일반 rsync 데몬이 \"localhost\"에서만 연결을 허용하도록 구성하는 것을 고려하십시오.) 사용자 관점에서, 원격-셸 연결을 통한 데몬 전송은 일반 rsync-데몬 전송과 거의 동일한 명령줄 구문을 사용하며, 유일한 예외는 --rsh=COMMAND 옵션을 사용하여 명령줄에서 원격 셸 프로그램을 명시적으로 설정해야 한다는 것입니다. (환경에서 RSYNC_RSH을 설정하는 것은 이 기능을 켜지 않습니다.) 예를 들어: rsync -av --rsh=ssh host::module /dest 다른 원격-셸 사용자를 지정해야 하는 경우, 호스트 앞의 user@ 접두사는 rsync-user 값(사용자 기반 인증이 필요한 모듈의 경우)을 지정한다는 점을 명심하십시오. 이는 원격-셸을 지정할 때 ssh에 '-l user' 옵션을 제공해야 함을 의미하며, 예를 들어 --rsh 옵션의 짧은 버전을 사용하는 다음과 같습니다: rsync -av -e \"ssh -l ssh-user\" rsync-user@host::module /dest \"ssh-user\"는 ssh 수준에서 사용되고, \"rsync-user\"는 \"module\"에 로그인하는 데 사용됩니다. 이 설정에서는 시스템에 접속하는 ssh 명령에 의해 데몬이 시작됩니다 (원하는 경우 ~/.ssh/authorized_keys 파일을 통해 강제할 수 있습니다). 그러나 데몬에 직접 접속할 때는 미리 시작되어야 합니다. STARTING AN RSYNC DAEMON TO ACCEPT CONNECTIONS rsync 데몬에 연결하려면 원격 시스템에 데몬이 이미 실행 중이거나 (또는 특정 포트에서 들어오는 연결에 대해 rsync 데몬을 스폰(spawn)하도록 inetd와 같은 것을 구성해야 합니다). 들어오는 소켓 연결을 처리할 데몬을 시작하는 방법에 대한 전체 정보는 rsyncd.conf(5) 맨페이지를 참조하십시오. 이 파일은 데몬의 구성 파일이며, 데몬을 실행하는 방법에 대한 전체 세부 정보(독립형 및 inetd 구성 포함)를 포함합니다. 전송에 원격 셸 전송을 사용하는 경우, 수동으로 rsync 데몬을 시작할 필요가 없습니다. EXAMPLES 다음은 rsync가 어떻게 사용될 수 있는지 보여주는 몇 가지 예시입니다. 대용량 MS Word 파일 및 메일 폴더로 구성된 홈 디렉토리를 백업하려면, 각 사용자별 cron 작업을 사용하여 매일 다음을 실행할 수 있습니다: rsync -aiz . bkhost:backup/joe/ 원격 호스트에서 로컬 호스트로 일부 파일을 이동하려면 다음을 실행할 수 있습니다: rsync -aiv --remove-source-files rhost:/tmp/{file1,file2}.c ~/src/ OPTION SUMMARY 다음은 rsync에서 사용 가능한 옵션에 대한 간략한 요약입니다. 각 옵션에는 이 맨페이지에서 자세한 설명이 있습니다. --verbose, -v 상세 정보 출력 증가 --info=FLAGS 세분화된 정보 출력 상세도 --debug=FLAGS 세분화된 디버그 출력 상세도 --stderr=e|a|c 표준 오류 출력 모드 변경 (기본값: errors) --quiet, -q 오류가 아닌 메시지 억제 --no-motd 데몬 모드 MOTD 억제 --checksum, -c 수정 시간 및 크기 대신 체크섬 기반으로 건너뛰기 --archive, -a 아카이브 모드는 -rlptgoD (--no-A,-X,-U,-N,-H) --no-OPTION 암시된 OPTION 끄기 (예: --no-D) --recursive, -r 디렉토리 재귀적으로 복사 --relative, -R 상대 경로 이름 사용 --no-implied-dirs --relative 사용 시 암시된 디렉토리 전송 안 함 --backup, -b 백업 생성 (--suffix \u0026 --backup-dir 참조) --backup-dir=DIR DIR 내에 계층 구조 기반으로 백업 생성 --suffix=SUFFIX 백업 접미사 (기본값: ~ --backup-dir 없음) --update, -u 수신자 측이 더 새로운 파일 건너뛰기 --inplace 대상 파일 제자리에서 업데이트 --append 짧은 파일에 데이터 추가 --append-verify --append에 기존 데이터 체크섬 확인 포함 --dirs, -d 재귀 없이 디렉토리 전송 --old-dirs, --old-d 오래된 rsync와 통신할 때 --dirs처럼 작동 --mkpath 대상에 없는 경로 구성 요소 생성 --links, -l 심볼릭 링크를 심볼릭 링크로 복사 --copy-links, -L 심볼릭 링크를 참조 파일/디렉토리로 변환 --copy-unsafe-links \"안전하지 않은\" 심볼릭 링크만 변환 --safe-links 트리 외부를 가리키는 심볼릭 링크 무시 --munge-links 심볼릭 링크를 안전하고 사용할 수 없게 변형 --copy-dirlinks, -k 디렉토리로의 심볼릭 링크를 참조 디렉토리로 변환 --keep-dirlinks, -K 수신자 측의 심볼릭 링크된 디렉토리를 실제 디렉토리로 처리 --hard-links, -H 하드 링크 보존 --perms, -p 권한 보존 --executability, -E 실행 권한 보존 --chmod=CHMOD 파일 및/또는 디렉토리 권한에 영향 --acls, -A ACL 보존 (--perms 암시) --xattrs, -X 확장 속성 보존 --owner, -o 소유자 보존 (슈퍼유저 전용) --group, -g 그룹 보존 --devices 장치 파일 보존 (슈퍼유저 전용) --copy-devices 장치 내용을 일반 파일로 복사 --write-devices 장치에 파일처럼 쓰기 (--inplace 암시) --specials 특수 파일 보존 -D --devices --specials와 동일 --times, -t 수정 시간 보존 --atimes, -U 접근 (사용) 시간 보존 --open-noatime 열린 파일의 atime 변경 방지 --crtimes, -N 생성 시간 (새로움) 보존 --omit-dir-times, -O --times에서 디렉토리 제외 --omit-link-times, -J --times에서 심볼릭 링크 제외 --super 수신자가 슈퍼유저 활동 시도 --fake-super 확장 속성을 사용하여 특권 속성 저장/복구 --sparse, -S 널 시퀀스를 스파스 블록으로 전환 --preallocate 쓰기 전에 대상 파일 미리 할당 --dry-run, -n 변경 없이 시범 실행 --whole-file, -W 파일 전체 복사 (델타-전송 알고리즘 없이) --checksum-choice=STR 체크섬 알고리즘 선택 (일명 --cc) --one-file-system, -x 파일 시스템 경계를 넘지 않음 --block-size=SIZE, -B 고정된 체크섬 블록 크기 강제 적용 --rsh=COMMAND, -e 사용할 원격 셸 지정 --rsync-path=PROGRAM 원격 머신에서 실행할 rsync 지정 --existing 수신자 측에 새 파일 생성 건너뛰기 --ignore-existing 수신자 측에 이미 존재하는 파일 업데이트 건너뛰기 --remove-source-files 전송자가 동기화된 파일 제거 (비디렉토리) --del --delete-during의 별칭 --delete 대상 디렉토리에서 불필요한 파일 삭제 --delete-before 수신자가 전송 전에 삭제, 전송 중 아님 --delete-during 수신자가 전송 중에 삭제 --delete-delay 전송 중에 삭제 사항 찾고, 전송 후에 삭제 --delete-after 수신자가 전송 후에 삭제, 전송 중 아님 --delete-excluded 제외된 파일도 대상 디렉토리에서 삭제 --ignore-missing-args 오류 없이 누락된 소스 인자 무시 --delete-missing-args 누락된 소스 인자를 대상에서 삭제 --ignore-errors I/O 오류가 있더라도 삭제 --force 비어 있지 않더라도 디렉토리 강제 삭제 --max-delete=NUM NUM개 이상의 파일 삭제 금지 --max-size=SIZE SIZE보다 큰 파일 전송 금지 --min-size=SIZE SIZE보다 작은 파일 전송 금지 --max-alloc=SIZE 메모리 할당 관련 제한 변경 --partial 부분적으로 전송된 파일 유지 --partial-dir=DIR 부분적으로 전송된 파일을 DIR에 저장 --delay-updates 모든 업데이트된 파일을 마지막에 배치 --prune-empty-dirs, -m 파일 목록에서 빈 디렉토리 체인 정리 --numeric-ids 사용자/그룹 이름으로 uid/gid 값 매핑 안 함 --usermap=STRING 사용자 이름 사용자 정의 매핑 --groupmap=STRING 그룹 이름 사용자 정의 매핑 --chown=USER:GROUP 간단한 사용자 이름/그룹 이름 매핑 --timeout=SECONDS I/O 타임아웃을 초 단위로 설정 --contimeout=SECONDS 데몬 연결 타임아웃을 초 단위로 설정 --ignore-times, -I 크기 및 시간 일치 파일 건너뛰지 않음 --size-only 크기만 일치하는 파일 건너뛰기 --modify-window=NUM, -@ 수정 시간 비교 정확도 설정 --temp-dir=DIR, -T 임시 파일을 DIR 디렉토리에 생성 --fuzzy, -y 대상 파일이 없으면 유사한 파일 찾기 --compare-dest=DIR DIR에 상대적인 대상 파일도 비교 --copy-dest=DIR ... 그리고 변경되지 않은 파일의 복사본 포함 --link-dest=DIR 변경되지 않은 파일은 DIR의 파일에 하드 링크 --compress, -z 전송 중 파일 데이터 압축 --compress-choice=STR 압축 알고리즘 선택 (일명 --zc) --compress-level=NUM 명시적으로 압축 수준 설정 (일명 --zl) --skip-compress=LIST LIST에 접미사가 있는 파일 압축 건너뛰기 --cvs-exclude, -C CVS와 동일한 방식으로 파일 자동 무시 --filter=RULE, -f 파일 필터링 RULE 추가 -F --filter='dir-merge /.rsync-filter'와 동일 반복 사용 시: --filter='- .rsync-filter' --exclude=PATTERN PATTERN과 일치하는 파일 제외 --exclude-from=FILE FILE에서 제외 패턴 읽기 --include=PATTERN PATTERN과 일치하는 파일 제외하지 않음 --include-from=FILE FILE에서 포함 패턴 읽기 --files-from=FILE FILE에서 소스 파일 이름 목록 읽기 --from0, -0 모든 *-from/filter 파일은 0으로 구분됨 --old-args 최신 인자 보호 관용구 비활성화 --secluded-args, -s 프로토콜을 사용하여 인자를 안전하게 전송 --trust-sender 원격 전송자의 파일 목록 신뢰 --copy-as=USER[:GROUP] 복사 작업에 사용자 및 선택적 그룹 지정 --address=ADDRESS 데몬으로 나가는 소켓의 바인딩 주소 --port=PORT 이중 콜론 대체 포트 번호 지정 --sockopts=OPTIONS 사용자 정의 TCP 옵션 지정 --blocking-io 원격 셸에 블로킹 I/O 사용 --outbuf=N|L|B 출력 버퍼링을 None, Line, Block으로 설정 --stats 파일 전송 통계 제공 --8-bit-output, -8 출력에서 높은 비트 문자 이스케이프 안 함 --human-readable, -h 숫자를 사람이 읽기 쉬운 형식으로 출력 --progress 전송 중 진행 상황 표시 -P --partial --progress와 동일 --itemize-changes, -i 모든 업데이트에 대한 변경 요약 출력 --remote-option=OPT, -M OPT를 원격 측으로만 전송 --out-format=FORMAT 지정된 FORMAT을 사용하여 업데이트 출력 --log-file=FILE 지정된 FILE에 작업 내용 기록 --log-file-format=FMT 지정된 FMT을 사용하여 업데이트 기록 --password-file=FILE FILE에서 데몬-액세스 암호 읽기 --early-input=FILE 데몬의 초기 exec 입력에 FILE 사용 --list-only 파일 복사 대신 나열 --bwlimit=RATE 소켓 I/O 대역폭 제한 --stop-after=MINS MINS분 경과 후 rsync 중지 --stop-at=y-m-dTh:m 지정된 시간에 rsync 중지 --fsync 모든 쓰여진 파일 fsync --write-batch=FILE FILE에 일괄 업데이트 기록 --only-write-batch=FILE --write-batch와 유사하지만 대상 업데이트 안 함 --read-batch=FILE FILE에서 일괄 업데이트 읽기 --protocol=NUM 이전 프로토콜 버전 강제 사용 --iconv=CONVERT_SPEC 파일 이름의 문자셋 변환 요청 --checksum-seed=NUM 블록/파일 체크섬 시드 설정 (고급) --ipv4, -4 IPv4 선호 --ipv6, -6 IPv6 선호 --version, -V 버전 및 기타 정보 출력 후 종료 --help, -h (*) 이 도움말 표시 (* -h는 단독 사용 시에만 도움말) Rsync는 데몬으로 실행될 수도 있으며, 이 경우 다음 옵션이 허용됩니다: --daemon rsync 데몬으로 실행 --address=ADDRESS 지정된 주소에 바인딩 --bwlimit=RATE 소켓 I/O 대역폭 제한 --config=FILE 대체 rsyncd.conf 파일 지정 --dparam=OVERRIDE, -M 전역 데몬 구성 매개변수 재정의 --no-detach 부모로부터 분리하지 않음 --port=PORT 대체 포트 번호로 수신 --log-file=FILE \"로그 파일\" 설정 재정의 --log-file-format=FMT \"로그 형식\" 설정 재정의 --sockopts=OPTIONS 사용자 정의 TCP 옵션 지정 --verbose, -v 상세 정보 출력 증가 --ipv4, -4 IPv4 선호 --ipv6, -6 IPv6 선호 --help, -h 이 도움말 표시 (--daemon과 함께 사용 시) OPTIONS Rsync는 긴 옵션(이중 대시 + 단어)과 짧은 옵션(단일 대시 + 문자)을 모두 허용합니다. 사용 가능한 모든 옵션 목록은 아래에 설명되어 있습니다. 옵션을 두 가지 이상의 방법으로 지정할 수 있는 경우, 선택 사항은 쉼표로 구분됩니다. 일부 옵션은 긴 변형만 있고 짧은 변형은 없습니다. 옵션에 매개변수가 필요한 경우, 매개변수는 긴 변형 뒤에만 나열되어 있지만, 짧은 변형에도 지정되어야 합니다. 매개변수를 지정할 때는 --option=param, --option param, -o=param, -o param 또는 -oparam 형식을 사용할 수 있습니다 (후자의 선택은 옵션에 짧은 변형이 있다고 가정합니다). 매개변수는 셸의 명령줄 파싱을 통과하기 위해 어떤 식으로든 인용(quote)되어야 할 수 있습니다. 또한 경로 이름의 선행 틸데(~)는 셸에 의해 치환되므로, 로컬 셸이 이를 확장하도록 하려면 옵션 이름과 경로 이름 사이에 공백을 사용하여 구분해야 합니다. --help 도움말 rsync에서 사용 가능한 옵션에 대한 짧은 도움말 페이지를 출력하고 종료합니다. 다른 옵션 없이 사용될 때 -h를 --help 대신 사용할 수도 있습니다 (일반적으로 --human-readable을 의미하기 때문입니다). --version, -V rsync 버전 및 기타 정보를 출력하고 종료합니다. 반복해서 사용하면 정보가 여전히 읽기 쉬운 JSON 형식으로 출력됩니다 (클라이언트 측만). 출력에는 컴파일된 기능 목록, 최적화 목록, 기본 체크섬 알고리즘 목록, 기본 압축 알고리즘 목록, 기본 데몬 인증 다이제스트 목록, rsync 웹 사이트 링크 및 몇 가지 다른 항목이 포함됩니다. --verbose, -v 이 옵션은 전송 중에 제공되는 정보의 양을 늘립니다. 기본적으로 rsync는 조용히 작동합니다. 단일 -v는 어떤 파일이 전송되는지에 대한 정보와 마지막에 간략한 요약을 제공합니다. 두 개의 -v 옵션은 어떤 파일이 건너뛰어지는지에 대한 정보와 마지막에 약간 더 많은 정보를 제공합니다. 두 개 이상의 -v 옵션은 rsync를 디버깅하는 경우에만 사용해야 합니다. 실행 종료 요약은 원격 rsync로 전송된 바이트 수(로컬 복사 시 수신 측), 원격 호스트로부터 수신된 바이트 수, 그리고 rsync 실행 전체 기간 동안 계산된 전송된 데이터의 초당 평균 바이트 수를 알려줍니다. 두 번째 줄은 rsync가 전송을 고려한 모든 파일 크기의 합계인 총 크기(바이트 단위)를 보여줍니다. 또한 \"속도 향상(speedup)\" 값도 보여주는데, 이는 총 파일 크기를 전송 및 수신된 바이트의 합계로 나눈 비율입니다 (이는 단순히 기분 좋은 \"더 클수록 좋다\"는 숫자입니다). 이러한 바이트 값은 --human-readable (또는 --no-human-readable) 옵션을 사용하여 더 (또는 덜) 사람이 읽기 쉽게 만들 수 있습니다. 최신 rsync에서 -v 옵션은 --info 및 --debug 옵션 그룹 설정과 동일합니다. -v 사용에 추가하거나 대신 이러한 새로운 옵션을 사용할 수 있으며, 모든 세분화된 설정은 -v의 암시된 설정을 재정의합니다. --info와 --debug 모두 상세도 증가에 따라 어떤 플래그가 설정되는지 정확히 알려주는 도움말 요청 방법이 있습니다. 그러나 데몬의 \"최대 상세도(max verbosity)\" 설정은 데몬 측에서 다양한 개별 플래그를 설정할 수 있는 수준을 제한한다는 점을 명심하십시오. 예를 들어, 최대값이 2이면, -vv에 의해 설정되는 값보다 높은 값으로 설정된 모든 정보 및/또는 디버그 플래그는 데몬 로깅에서 -vv 수준으로 다운그레이드됩니다. --info=FLAGS 이 옵션을 사용하면 보고 싶은 정보 출력에 대해 세분화된 제어를 할 수 있습니다. 개별 플래그 이름 뒤에는 레벨 번호가 올 수 있으며, 0은 해당 출력을 침묵시키고, 1은 기본 출력 레벨이며, 더 높은 숫자는 해당 플래그의 출력을 증가시킵니다 (더 높은 레벨을 지원하는 플래그의 경우). 사용 가능한 모든 플래그 이름, 출력 내용 및 상세도 증가에 따라 추가되는 플래그 이름을 보려면 --info=help를 사용하십시오. 몇 가지 예시: rsync -a --info=progress2 src/ dest/ rsync -avv --info=stats2,misc1,flist0 src/ dest/ --info=name의 출력은 --out-format 및 --itemize-changes (-i) 옵션에 영향을 받습니다. 출력 내용 및 시기에 대한 자세한 정보는 해당 옵션을 참조하십시오. 이 옵션은 3.1.0에 추가되었으므로, 서버 측의 오래된 rsync는 세분화된 제어 시도를 거부할 수 있습니다 (하나 이상의 플래그를 서버로 보내야 하고 서버가 이를 이해하기에는 너무 오래된 경우). 데몬을 다룰 때 위에 언급된 \"최대 상세도(max verbosity)\" 주의사항도 참조하십시오. --debug=FLAGS 이 옵션을 사용하면 보고 싶은 디버그 출력에 대해 세분화된 제어를 할 수 있습니다. 개별 플래그 이름 뒤에는 레벨 번호가 올 수 있으며, 0은 해당 출력을 침묵시키고, 1은 기본 출력 레벨이며, 더 높은 숫자는 해당 플래그의 출력을 증가시킵니다 (더 높은 레벨을 지원하는 플래그의 경우). 사용 가능한 모든 플래그 이름, 출력 내용 및 상세도 증가에 따라 추가되는 플래그 이름을 보려면 --debug=help를 사용하십시오. 몇 가지 예시: rsync -avvv --debug=none src/ dest/ rsync -avA --del --debug=del2,acl src/ dest/ 특히 I/O 및 버퍼 디버깅과 관련된 일부 디버그 메시지는 --stderr=all 옵션이 지정된 경우에만 출력됩니다. 3.2.0부터 이 옵션은 더 이상 서버 측으로 자동 전달되지 않습니다. 이는 전송의 각 측에 대해 다른 디버그 값을 지정하고, rsync 버전 중 하나에만 존재하는 새로운 디버그 옵션을 지정할 수 있도록 하기 위함입니다. 양쪽에 동일한 옵션을 복제하려면 괄호 확장을 사용하여 타이핑을 줄일 수 있습니다. 이는 zsh 및 bash에서 작동합니다: rsync -aiv {-M,}--debug=del2 src/ dest/ --stderr=errors|all|client 이 옵션은 어떤 프로세스가 stderr로 출력하고 정보 메시지도 stderr로 변경되는지 제어합니다. 모드 문자열은 약어로 지정할 수 있으므로 단일 문자 값을 사용해도 됩니다. 가능한 3가지 선택은 다음과 같습니다: o errors - (기본값) 모든 rsync 프로세스가 오류를 stderr로 직접 보냅니다. 프로세스가 전송의 원격 측에 있더라도 마찬가지입니다. 정보 메시지는 프로토콜 스트림을 통해 클라이언트 측으로 전송됩니다. stderr를 사용할 수 없는 경우 (즉, 소켓을 통해 데몬에 직접 연결할 때) 오류는 프로토콜 스트림을 통해 전송되는 것으로 대체됩니다. o all - 모든 rsync 메시지(정보 및 오류)가 모든 (가능한) 프로세스에서 stderr로 직접 쓰여지도록 합니다. 이로 인해 stderr가 라인-버퍼링되고 (원시 버퍼링 대신) 정보 및 오류 메시지를 파일 핸들별로 분할하는 기능이 사라집니다. 디버깅을 하거나 여러 수준의 상세도를 사용하는 경우 이 옵션은 전송 스트림이 막히는 것을 방지하여 (교착 상태 버그가 발생하는 것을 방지해야 합니다) 도움이 될 수 있습니다. 또한 --debug가 일부 추가 I/O 관련 메시지를 활성화하도록 허용합니다. o client - 모든 rsync 메시지가 프로토콜 스트림을 통해 클라이언트 측으로 전송되도록 합니다. 하나의 클라이언트 프로세스가 모든 메시지를 출력하며, 오류는 stderr로, 정보 메시지는 stdout으로 출력됩니다. 이는 이전 rsync 버전의 기본값이었지만, 많은 전송 데이터가 메시지보다 앞에 있을 때 오류 지연을 유발할 수 있습니다. 오래된 rsync로 파일을 푸시하는 경우, --stderr=all을 사용하는 것이 좋습니다. 이 구문은 여러 릴리스 동안 사용되었습니다. 이 옵션은 rsync 3.2.3에 추가되었습니다. 이 버전은 또한 비기본 설정이 원격 측으로 전달되기 시작했으며, rsync는 이전 버전과의 호환성을 위해 --msgs2stderr 및 --no-msgs2stderr 옵션을 각각 all 및 client 설정으로 나타냅니다. 새로운 rsync는 호환성을 유지하기 위해 이러한 이전 옵션 이름을 계속 허용합니다. --quiet, -q 이 옵션은 전송 중에 제공되는 정보의 양을 줄이며, 특히 원격 서버의 정보 메시지를 억제합니다. 이 옵션은 cron에서 rsync를 호출할 때 유용합니다. --no-motd 이 옵션은 데몬 전송 시작 시 클라이언트가 출력하는 정보에 영향을 줍니다. 이것은 오늘의 메시지(MOTD) 텍스트를 억제하지만, 데몬이 \"rsync host::\" 요청에 응답하여 보내는 모듈 목록에도 영향을 미칩니다 (rsync 프로토콜의 제한 때문입니다). 따라서 데몬에서 모듈 목록을 요청하려면 이 옵션을 생략하십시오. --ignore-times, -I 일반적으로 rsync는 이미 동일한 크기이며 동일한 수정 타임스탬프를 가진 파일을 건너뜁니다. 이 옵션은 이 \"빠른 검사\" 동작을 끄고, 모든 파일이 업데이트되도록 합니다. 이 옵션은 --ignore-existing 및 --ignore-non-existing과 비교할 때 혼란스러울 수 있습니다. 이들은 rsync가 더 적은 파일을 전송하도록 하는 반면, 이 옵션은 rsync가 더 많은 파일을 전송하도록 합니다. --size-only 이것은 전송해야 할 파일을 찾는 rsync의 \"빠른 검사\" 알고리즘을 수정하여, (기본적으로) 크기 또는 최종 수정 시간이 변경된 파일을 전송하는 대신 크기가 변경된 파일만 찾도록 변경합니다. 이는 타임스탬프를 정확하게 보존하지 못할 수 있는 다른 미러링 시스템을 사용한 후 rsync를 사용하기 시작할 때 유용합니다. --modify-window=NUM, -@ 두 타임스탬프를 비교할 때, rsync는 타임스탬프가 modify-window 값 이하로 차이가 나는 경우 동일한 것으로 간주합니다. 기본값은 0이며, 정수 초 단위로만 일치합니다. 음수 값을 지정하면 (수신자가 3.1.3 버전 이상인 경우) 나노초도 고려됩니다. 1을 지정하는 것은 MS Windows FAT 파일 시스템으로/로부터 복사할 때 유용합니다. FAT는 시간을 2초 해상도로 나타내므로 (원래 시간과 최대 1초 차이 허용) 그렇습니다. 모든 전송의 기본값이 나노초 비교를 사용하도록 하려면, ~/.popt 파일을 생성하고 다음 줄을 추가할 수 있습니다: rsync alias -a -a@-1 rsync alias -t -t@-1 이것이 기본값으로 설정되면, 나노초를 무시하도록 재정의하려면 --modify-window=0 (일명 -@0)을 지정해야 합니다. 예를 들어, ext3와 ext4 사이를 복사하거나 수신 rsync가 3.1.3보다 오래된 경우에 그렇습니다. --checksum, -c 이것은 rsync가 파일이 변경되었고 전송이 필요한지 확인하는 방식을 변경합니다. 이 옵션이 없으면 rsync는 (기본적으로) 전송자와 수신자 간에 각 파일의 크기와 최종 수정 시간이 일치하는지 확인하는 \"빠른 검사\"를 사용합니다. 이 옵션은 일치하는 크기를 가진 각 파일에 대해 128비트 체크섬을 비교하도록 변경합니다. 체크섬을 생성한다는 것은 양쪽 모두 전송 중인 모든 파일의 데이터를 읽는 데 많은 디스크 I/O를 소모한다는 것을 의미하므로, 이로 인해 속도가 상당히 느려질 수 있습니다 (그리고 이는 변경된 파일을 전송하기 위해 수행될 모든 읽기 작업 전에 발생합니다). 보내는 측은 사용 가능한 파일 목록을 생성하는 파일 시스템 스캔을 수행하는 동안 체크섬을 생성합니다. 수신 측은 변경된 파일을 스캔할 때 체크섬을 생성하며, 해당 보내는 측 파일과 동일한 크기를 가진 모든 파일의 체크섬을 확인합니다. 크기가 변경되었거나 체크섬이 변경된 파일은 전송 대상으로 선택됩니다. rsync는 항상 전송된 각 파일이 수신 측에서 올바르게 재구성되었는지 확인하기 위해 파일 전송 중 생성되는 전체 파일 체크섬을 확인하지만, 이 자동 전송 후 확인은 이 옵션의 전송 전 \"이 파일을 업데이트해야 하는가?\" 확인과는 관련이 없습니다. 사용되는 체크섬은 클라이언트와 서버 간에 자동 협상되지만, --checksum-choice (--cc) 옵션 또는 해당 옵션 섹션에서 논의된 환경 변수를 사용하여 재정의할 수 있습니다. --archive, -a 이것은 -rlptgoD와 동일합니다. 재귀와 거의 모든 것을 보존하려는 경우에 빠르게 지정할 수 있는 방법입니다. ACL(-A), 확장 속성(-X), 접근 시간(-U), 생성 시간(-N), 하드 링크 찾기 및 보존(-H)은 포함되지 않는다는 점에 유의하십시오. 위 등가성(equivalence)의 유일한 예외는 --files-from이 지정될 때입니다. 이 경우 -r은 암시되지 않습니다. --no-OPTION 옵션 이름 앞에 \"no-\"를 붙여 하나 이상의 암시된 옵션을 끌 수 있습니다. 모든 긍정 옵션이 부정 옵션을 가지는 것은 아니지만, 많은 옵션이 그러하며, 여기에는 암시된 옵션을 비활성화하는 데 사용될 수 있는 옵션(--no-D, --no-perms 등)이나 다양한 상황에서 다른 기본값을 가지는 옵션(--no-whole-file, --no-blocking-io, --no-dirs 등)이 포함됩니다. 모든 유효한 부정 옵션은 \"no-\" 접두사 뒤에 짧은 옵션 이름과 긴 옵션 이름을 모두 허용합니다(예: --no-R은 --no-relative와 동일합니다). 예를 들어, --archive (-a)를 사용하고 싶지만 --owner (-o)는 사용하고 싶지 않다면, -a를 -rlptgD로 변환하는 대신 -a --no-o (일명 --archive --no-owner)를 지정할 수 있습니다. 옵션의 순서가 중요합니다: --no-r -a를 지정하면 -r 옵션이 결국 켜지게 되며, 이는 -a --no-r과 반대입니다. 또한 --files-from 옵션의 부작용은 위치에 영향을 받지 않습니다. 이 옵션은 여러 옵션의 기본 상태에 영향을 미치고 -a의 의미를 약간 변경합니다 (--files-from 옵션에서 자세한 내용을 참조하십시오). --recursive, -r 이것은 rsync에게 디렉토리를 재귀적으로 복사하도록 지시합니다. 단일 디렉토리 스캔을 허용하는 옵션에 대해서는 --dirs (-d)도 참조하십시오. 전송할 파일 목록을 생성하기 위한 증분 재귀에 대한 설명은 --inc-recursive 옵션을 참조하십시오. --inc-recursive, --i-r 이 옵션은 파일 스캔 시 증분 재귀를 명시적으로 활성화합니다. 이는 --recursive 옵션을 사용하고 전송 양쪽이 rsync 3.0.0 이상을 실행 중일 때 기본적으로 활성화됩니다. 증분 재귀는 비증분 방식보다 훨씬 적은 메모리를 사용하며, 전송을 더 빨리 시작합니다 (전체 전송 계층 구조를 스캔할 필요 없이 파일을 전송하기 시작하므로). 소스 파일에 재귀가 활성화되어 있지 않으면 이 옵션은 효과가 없습니다. 일부 옵션은 rsync가 전체 파일 목록을 알아야 하므로 이러한 옵션은 증분 재귀 모드를 비활성화합니다. 여기에는 다음이 포함됩니다: o --delete-before (--delete의 이전 기본값) o --delete-after o --prune-empty-dirs o --delay-updates --delete를 증분 재귀와 호환시키기 위해 rsync 3.0.0은 --delete-during을 기본 삭제 모드로 만들었습니다 (이는 2.6.4에 처음 추가되었습니다). 증분 재귀의 한 가지 부작용은 재귀적으로 스캔된 디렉토리 내의 누락된 하위 디렉토리가 (기본적으로) 하위 디렉토리로 재귀하기 전에 생성된다는 것입니다. 이러한 조기 생성 지점(비증분 재귀와 비교하여)은 rsync가 완료된 디렉토리의 수정 시간을 즉시 설정할 수 있도록 합니다 (많은 재귀적 복사가 완료될 때까지 기다릴 필요 없이). 그러나 이러한 초기 디렉토리는 아직 완료된 모드, mtime 또는 소유권이 설정되지 않았습니다. 하위 디렉토리 복사가 실제로 시작될 때까지는 더 제한적인 권한을 가집니다. 이러기 조기-생성 관용구는 --omit-dir-times 옵션을 사용하여 피할 수 있습니다. 증분 재귀는 --no-inc-recursive (--no-i-r) 옵션을 사용하여 비활성화할 수 있습니다. --no-inc-recursive, --no-i-r --recursive 옵션의 새로운 증분 재귀 알고리즘을 비활성화합니다. 이렇게 하면 rsync는 파일 전송을 시작하기 전에 전체 파일 목록을 스캔합니다. 자세한 내용은 --inc-recursive를 참조하십시오. --relative, -R 상대 경로를 사용합니다. 즉, 명령줄에 지정된 전체 경로 이름이 파일 이름의 마지막 부분만 전송되는 대신 서버로 전송됩니다. 이는 여러 디렉토리를 동시에 전송하려는 경우에 특히 유용합니다. 예를 들어, 다음 명령을 사용했다면: rsync -av /foo/bar/baz.c remote:/tmp/ 원격 머신의 /tmp/에 baz.c라는 이름의 파일이 생성됩니다. 대신 다음을 사용했다면: rsync -avR /foo/bar/baz.c remote:/tmp/ 그러면 원격 머신에 /tmp/foo/bar/baz.c라는 이름의 파일이 생성되어 전체 경로가 보존됩니다. 이러한 추가 경로 요소는 \"암시된 디렉토리\"(즉, 위 예시에서 \"foo\" 및 \"foo/bar\" 디렉토리)라고 불립니다. rsync 3.0.0부터 rsync는 이러한 암시된 디렉토리를 항상 파일 목록에 실제 디렉토리로 보냅니다. 경로 요소가 보내는 측에서 실제로 심볼릭 링크인 경우에도 마찬가지입니다. 이는 경로에 심볼릭 링크가 포함되어 있다는 것을 알지 못하고 파일의 전체 경로를 복사할 때 발생하는 예상치 못한 동작을 방지합니다. 서버 측 심볼릭 링크를 복제하려면 심볼릭 링크는 경로를 통해 포함하고, 참조 디렉토리는 실제 경로를 통해 포함하십시오. 오래된 rsync를 보내는 측에서 다루는 경우, --no-implied-dirs 옵션을 사용해야 할 수도 있습니다. 또한 각 경로에 대해 암시된 디렉토리로 전송되는 경로 정보의 양을 제한할 수도 있습니다. 보내는 측에 최신 rsync(2.6.7부터)가 있는 경우, 소스 경로에 점과 슬래시를 삽입할 수 있습니다: rsync -avR /foo/./bar/baz.c remote:/tmp/ 그러면 원격 머신에 /tmp/bar/baz.c가 생성됩니다. (점 뒤에는 슬래시가 와야 하므로 \"/foo/.\"는 축약되지 않습니다.) 오래된 rsync 버전의 경우, 소스 경로를 제한하기 위해 chdir을 사용해야 합니다. 예를 들어, 파일을 푸시할 때: (cd /foo; rsync -avR bar/baz.c remote:/tmp/) (괄호는 두 명령을 서브 셸에 넣으므로 \"cd\" 명령이 향후 명령에 영향을 미치지 않습니다.) 오래된 rsync에서 파일을 가져오는 경우, 이 구문을 사용하십시오 (단, 데몬이 아닌 전송에만 해당): rsync -avR --rsync-path=\"cd /foo; rsync\" \\ remote:bar/baz.c /tmp/ --no-implied-dirs 이 옵션은 --relative 옵션의 기본 동작에 영향을 줍니다. 이 옵션이 지정되면, 소스 이름에서 암시된 디렉토리의 속성은 전송에 포함되지 않습니다. 이는 대상 시스템의 해당 경로 요소가 존재하는 경우 변경되지 않고 유지되며, 누락된 암시된 디렉토리는 기본 속성으로 생성됨을 의미합니다. 이는 이러한 암시된 경로 요소가 수신 측에서 디렉토리에 대한 심볼릭 링크와 같이 큰 차이를 가질 수도 있게 합니다. 예를 들어, 명령줄 인자 또는 files-from 항목이 rsync에게 \"path/foo/file\" 파일을 전송하도록 지시했고, --relative를 사용하면 \"path\" 및 \"path/foo\" 디렉토리가 암시됩니다. 만약 \"path/foo\"가 대상 시스템에서 \"bar\"에 대한 심볼릭 링크인 경우, 수신 rsync는 일반적으로 \"path/foo\"를 삭제하고, 디렉토리로 다시 생성하고, 새 디렉토리로 파일을 수신합니다. --no-implied-dirs를 사용하면 수신 rsync는 기존 경로 요소를 사용하여 \"path/foo/file\"을 업데이트합니다. 이는 파일이 결국 \"path/bar\"에 생성됨을 의미합니다. 이러한 링크 보존을 달성하는 또 다른 방법은 --keep-dirlinks 옵션을 사용하는 것입니다 (이는 전송의 나머지 부분에 있는 디렉토리에 대한 심볼릭 링크에도 영향을 미칩니다). rsync 3.0.0보다 오래된 rsync에서 파일을 가져올 때, 보내는 측에서 요청한 경로에 심볼릭 링크가 있고 암시된 디렉토리가 일반 디렉토리로 전송되기를 원한다면 이 옵션을 사용해야 할 수도 있습니다. --backup, -b 이 옵션을 사용하면 각 파일이 전송되거나 삭제될 때 기존 대상 파일의 이름이 바뀝니다. --backup-dir 및 --suffix 옵션을 사용하여 백업 파일이 저장될 위치와 (있다면) 어떤 접미사가 추가될지 제어할 수 있습니다. --backup-dir을 지정하지 않으면: 1. --omit-dir-times 옵션이 강제 적용됩니다. 2. --delete (단, --delete-excluded 없음)를 사용하면 rsync는 백업 접미사에 대한 \"보호\" 필터 규칙을 기존 모든 필터 끝에 추가합니다. 이 규칙은 이전에 백업된 파일이 삭제되는 것을 방지합니다. 규칙은 다음과 같습니다: -f \"P *~\". 자신만의 필터 규칙을 제공하는 경우, 필터 목록의 더 높은 위치에 자신만의 제외/보호 규칙을 수동으로 삽입하여 효과를 발휘할 수 있는 충분히 높은 우선순위를 가지도록 해야 할 수도 있습니다 (예: 규칙에 후행 포함/제외 *가 지정된 경우 자동 추가된 규칙은 도달되지 않습니다). --backup-dir=DIR 이것은 --backup 옵션을 암시하며, rsync에게 모든 백업을 수신 측의 지정된 디렉토리에 저장하도록 지시합니다. 이는 증분 백업에 사용할 수 있습니다. --suffix 옵션을 사용하여 백업 접미사를 추가로 지정할 수 있습니다 (그렇지 않으면 지정된 디렉토리에 백업된 파일은 원래 파일 이름을 유지합니다). 상대 경로를 지정하면 백업 디렉토리가 대상 디렉토리에 상대적이므로, 절대 경로 또는 \"../\"로 시작하는 경로를 지정하는 것이 좋습니다. rsync 데몬이 수신자인 경우, 백업 디렉토리가 모듈의 경로 계층을 벗어날 수 없으므로, 삭제하거나 그 안에 복사하지 않도록 특별히 주의하십시오. --suffix=SUFFIX 이 옵션을 사용하면 --backup (-b) 옵션과 함께 사용되는 기본 백업 접미사를 재정의할 수 있습니다. --backup-dir이 지정되지 않은 경우 기본 접미사는 ~이며, 그렇지 않으면 빈 문자열입니다. --update, -u 이것은 rsync가 대상에 존재하고 소스 파일보다 수정 시간이 더 새로운 파일을 건너뛰도록 강제합니다. (기존 대상 파일의 수정 시간이 소스 파일의 수정 시간과 동일하다면, 크기가 다른 경우 업데이트됩니다.) 이는 디렉토리, 심볼릭 링크 또는 기타 특수 파일의 복사에는 영향을 미치지 않습니다. 또한, 보내는 측과 받는 측 간의 파일 형식 차이는 날짜에 관계없이 항상 업데이트할 만큼 중요하게 간주됩니다. 다시 말해, 소스에 디렉토리가 있고 대상에 파일이 있는 경우, 타임스탬프와 관계없이 전송이 발생합니다. 이 옵션은 TRANSFER RULE이므로, 어떤 제외 부작용도 기대하지 마십시오. --inplace와 --update를 결합하기로 선택한 사람들을 위한 주의사항: 중단된 전송은 매우 최근 수정 시간을 가진 부분 파일을 수신 측에 남겨두므로, 전송을 다시 실행해도 중단된 파일이 계속 진행되지 않을 수 있습니다. 따라서, 중단된 진행 중인 파일을 처리하기 위한 수동 단계를 구현하지 않는 한, 일반적으로 이 옵션을 --inplace와 결합하는 것을 피하는 것이 가장 좋습니다. --inplace 이 옵션은 데이터 업데이트가 필요한 파일을 rsync가 전송하는 방식을 변경합니다. 파일의 새 복사본을 생성하고 완료 시 제자리로 이동하는 기본 방식 대신, rsync는 업데이트된 데이터를 대상 파일에 직접 씁니다. 이것은 여러 가지 효과를 가집니다: o 하드 링크가 끊어지지 않습니다. 이는 새 데이터가 대상 파일에 대한 다른 하드 링크를 통해서도 보이게 된다는 의미입니다. 또한, 다중 링크된 대상 파일에 다른 소스 파일을 복사하려고 하면 대상 데이터가 계속해서 바뀌는 \"줄다리기\"가 발생할 수 있습니다. o 사용 중인 바이너리는 업데이트할 수 없습니다 (OS가 이를 방지하거나, 데이터를 스왑인하려고 시도하는 바이너리가 오작동하거나 충돌합니다). o 파일의 데이터는 전송 중에 일관성 없는 상태로 유지되며, 전송이 중단되거나 업데이트에 실패하면 그 상태로 남게 됩니다. o rsync가 쓸 수 없는 파일은 업데이트할 수 없습니다. 슈퍼유저는 어떤 파일이든 업데이트할 수 있지만, 일반 사용자는 파일 열기 및 쓰기 권한이 부여되어야 성공적으로 쓸 수 있습니다. o 대상 파일의 일부 데이터가 파일의 나중에 위치한 데이터를 복사하기 전에 덮어쓰여지면 rsync의 델타-전송 알고리즘 효율성이 저하될 수 있습니다. --backup을 사용하는 경우에는 해당되지 않습니다. rsync는 백업 파일을 전송의 기본 파일로 사용하는 데 충분히 똑똑하기 때문입니다. 경고: 이 옵션을 사용하여 다른 사용자가 액세스하는 파일을 업데이트해서는 안 되므로, 복사 시 이 옵션을 사용하기로 선택할 때는 주의하십시오. 이 옵션은 블록 기반 변경 또는 추가된 데이터가 있는 대용량 파일을 전송하는 데 유용하며, 네트워크가 아닌 디스크에 바인딩된 시스템에서도 유용합니다. 또한 사소한 변경만 있는 파일의 전체 내용을 복사-온-쓰기 파일 시스템 스냅샷이 분기하는 것을 방지하는 데 도움이 될 수 있습니다. 이 옵션은 --partial을 암시하지만 (중단된 전송은 파일을 삭제하지 않으므로), --partial-dir 및 --delay-updates와 충돌합니다. rsync 2.6.4 이전에는 --inplace가 --compare-dest 및 --link-dest와도 호환되지 않았습니다. --append 이 특별한 복사 모드는 수신 측의 기존 내용이 전송 측의 내용과 동일하다고 알려진, 크기가 계속 증가하는 파일을 효율적으로 업데이트할 때만 작동합니다. 전송되는 모든 파일이 공유되고 증가하는 파일인지 100% 확신하지 못하는 경우 --append를 사용하는 것은 위험할 수 있습니다. 따라서 이 기준에 맞지 않는 파일을 걸러내기 위해 필터 규칙을 사용해야 합니다. Rsync는 파일의 기존 내용을 확인하지 않고 (추가하는 내용만 확인) 이러한 증가하는 파일을 제자리에서 업데이트합니다. rsync는 수신 측에 존재하고 보내는 측의 관련 파일보다 짧지 않은 파일은 건너뜁니다 (이는 새 파일은 전송됨을 의미합니다). 또한 전송 협상 중에 보내는 측의 파일 크기가 줄어드는 파일은 건너뜁니다 (이러한 경우 rsync는 \"줄어든\" 파일에 대해 경고합니다). 파일 전송이 필요 없는 경우 파일의 내용이 아닌 속성(예: 권한, 소유권 등) 업데이트를 방해하지 않으며, 디렉토리나 비정규 파일의 업데이트에도 영향을 미치지 않습니다. --append-verify 이 특별한 복사 모드는 --append와 유사하게 작동하지만, 파일의 모든 데이터가 체크섬 검증에 포함됩니다 (효율성은 떨어지지만 잠재적으로 더 안전합니다). 전송되는 모든 파일이 공유되고 증가하는 파일인지 100% 확신하지 못하는 경우 이 옵션을 사용하는 것은 위험할 수 있습니다. 자세한 내용은 --append 옵션을 참조하십시오. 참고: rsync 3.0.0 이전에는 --append 옵션이 --append-verify처럼 작동했습니다. 따라서 이전 rsync와 상호 작용하는 경우 (또는 전송이 30 이전 프로토콜을 사용하는 경우) 두 append 옵션 중 하나를 지정하면 --append-verify 전송이 시작됩니다. --dirs, -d 보내는 측에게 발견되는 모든 디렉토리를 포함하도록 지시합니다. --recursive와 달리, 디렉토리 이름이 \".\"으로 지정되었거나 후행 슬래시로 끝나는 경우(예: \".\", \"dir/.\", \"dir/\", 등)를 제외하고는 디렉토리의 내용은 복사되지 않습니다. 이 옵션이나 --recursive 옵션이 없으면 rsync는 발견하는 모든 디렉토리를 건너뜁니다 (그리고 각 디렉토리에 대해 해당 메시지를 출력합니다). --dirs와 --recursive를 모두 지정하면 --recursive가 우선합니다. --dirs 옵션은 --files-from 옵션 또는 --list-only 옵션(암시된 --list-only 사용 포함)에서 --recursive가 지정되지 않았을 경우 암시됩니다 (그래서 디렉토리가 목록에 보이게 됩니다). 이를 끄고 싶다면 --no-dirs (또는 --no-d)를 지정하십시오. 오래된 rsync가 재귀 없이 단일 디렉토리를 나열하도록 하기 위해 -r --exclude='/*/*' 해킹을 사용하도록 rsync에 지시하는 역방향 호환성 도우미 옵션인 --old-dirs (--old-d)도 있습니다. --mkpath 대상 경로의 누락된 모든 경로 구성 요소를 생성합니다. 기본적으로 rsync는 대상 경로의 마지막 구성 요소만 존재하지 않을 수 있도록 허용합니다. 이는 대상 경로의 유효성을 검사하는 데 도움이 되기 위한 시도입니다. 이 옵션을 사용하면 rsync는 mkdir -p $DEST_PATH가 수신 측에서 실행된 것처럼 누락된 모든 대상 경로 구성 요소를 생성합니다. 대상 경로를 지정할 때 후행 슬래시를 포함하면 파일 목록에 단일 항목이 있더라도 전체 경로가 생성될 디렉토리 이름으로 처리됩니다. rsync가 최종 대상 경로 구성 요소를 디렉토리로 생성해야 할지 여부를 결정하는 방법에 대한 자세한 내용은 COPYING TO A DIFFERENT NAME 섹션을 참조하십시오. 새로 생성된 대상 디렉토리가 보내는 측의 디렉토리와 일치하도록 하려면 --mkpath 대신 --relative (-R)를 사용해야 합니다. 예를 들어, 다음 두 명령은 동일한 대상 트리를 생성하지만, 두 번째 명령만 \"some/extra/path\" 구성 요소가 보내는 측의 디렉토리와 일치하도록 보장합니다: rsync -ai --mkpath host:some/extra/path/*.c some/extra/path/ rsync -aiR host:some/extra/path/*.c ./ --links, -l 각 심볼릭 링크에 대해 \"비정규 파일\" 경고를 시끄럽게 무시하는 대신, 전송된 파일에 심볼릭 링크를 추가합니다. --info=nonreg0을 지정하여 경고를 억제할 수도 있습니다. 심볼릭 링크의 기본 처리는 수신 측에서 각 심볼릭 링크의 변경되지 않은 값을 다시 생성하는 것입니다. 다중 옵션 정보는 SYMBOLIC LINKS 섹션을 참조하십시오. --copy-links, -L 보내는 측은 전송에서 발견된 각 심볼릭 링크를 참조 항목으로 변환하고, 심볼릭 링크 체인을 따라 참조하는 파일 또는 디렉토리로 이동합니다. 심볼릭 링크 체인이 끊어지면 오류가 출력되고 파일은 전송에서 제외됩니다. 이 옵션은 전송에서 심볼릭 링크가 남지 않으므로, 심볼릭 링크에 영향을 미치는 다른 옵션보다 우선합니다. 이 옵션은 수신 측의 기존 심볼릭 링크 처리를 변경하지 않습니다. 이는 rsync 2.6.3 이전 버전과 달리 수신 측에게도 심볼릭 링크를 따르도록 지시하는 부작용이 있었던 것과 다릅니다. 최신 rsync는 이 옵션을 원격 수신자에게 전달하지 않으므로 (보내는 측만 알면 되므로), 이 주의사항은 rsync 클라이언트가 2.6.7보다 오래된 버전(이때 -L이 수신자에게 전달되지 않게 됨)을 사용하는 경우에만 영향을 미칩니다. 디렉토리에 대한 심볼릭 링크가 수신 측에서 실제 디렉토리로 처리되도록 해야 하는 경우 --keep-dirlinks (-K)를 참조하십시오. 다중 옵션 정보는 SYMBOLIC LINKS 섹션을 참조하십시오. --copy-unsafe-links 이것은 rsync에게 복사된 트리 외부를 가리키는 심볼릭 링크의 참조 대상을 복사하도록 지시합니다. 절대 심볼릭 링크도 일반 파일처럼 처리되며, --relative를 사용할 때는 소스 경로 자체에 있는 심볼릭 링크도 마찬가지입니다. 참고로, 차단 지점은 전송의 최상단입니다. 이는 rsync가 자세한 출력에서 언급하지 않는 경로의 일부입니다. 만약 \"/src/subdir\"를 \"/dest/\"로 복사한다면, \"subdir\" 디렉토리는 전송 트리 내부의 이름이지 전송의 최상단(/src)이 아니므로, 생성된 상대 심볼릭 링크가 /src 및 /dest 디렉토리 내부의 다른 이름을 참조하는 것은 합법적입니다. 대신 \"/src/subdir/\" (후행 슬래시 포함)를 \"/dest/subdir\"로 복사한다면, \"subdir\" 외부의 어떤 파일에도 심볼릭 링크를 허용하지 않습니다. 안전한 심볼릭 링크는 --links가 지정되거나 암시된 경우에만 복사됩니다. --copy-unsafe-links 옵션은 --copy-links와 결합될 때 추가적인 효과가 없습니다. 다중 옵션 정보는 SYMBOLIC LINKS 섹션을 참조하십시오. --safe-links 이것은 수신 rsync에게 복사된 트리 외부를 가리키는 전송의 모든 심볼릭 링크를 무시하도록 지시합니다. 모든 절대 심볼릭 링크도 무시됩니다. 이 무시는 수신 측에서 발생하므로, 보내는 측이 심볼릭 링크를 변형했더라도 (--munge-links를 사용할 때) 여전히 효과적입니다. 심볼릭 링크가 안전하지 않은 것으로 간주되어 건너뛰어질 때, 전송에 파일이 존재하면 수신 측의 일치하는 파일이 삭제되는 것을 방지하므로 삭제에도 영향을 미칩니다. 이 옵션은 --links (또는 --archive)와 함께 사용되어야 전송에서 심볼릭 링크가 조건부로 무시될 수 있습니다. 그 효과는 --copy-unsafe-links에 의해 재정의됩니다. --relative와 함께 이 옵션을 사용하면 예상치 못한 결과가 발생할 수 있습니다. 다중 옵션 정보는 SYMBOLIC LINKS 섹션을 참조하십시오. --munge-links 이 옵션은 전송의 한쪽에만 영향을 미치며, rsync에게 파일을 수신할 때 심볼릭 링크 값을 변형하거나 파일을 보낼 때 심볼릭 링크 값을 복원하도록 지시합니다. 변형된 값은 심볼릭 링크를 디스크에서 사용할 수 없게 만들지만, 심볼릭 링크의 원래 내용을 복구할 수 있도록 합니다. 서버 측 rsync는 클라이언트의 지식 없이 이 옵션을 종종 활성화합니다. 예를 들어 rsync 데몬의 구성 파일에서 또는 rrsync (제한된 rsync) 스크립트에 주어진 옵션에 의해 그렇습니다. 클라이언트 측에서 지정할 경우, 클라이언트 측이 변형된 심볼릭 링크를 가지고 있거나 필요로 한다면 옵션을 정상적으로 지정하거나, -M--munge-links를 사용하여 서버가 변형된 심볼릭 링크를 가지고 있거나 필요로 할 때 서버에 옵션을 제공하십시오. 로컬 전송의 경우, 클라이언트가 보내는 측이므로, 옵션을 직접 지정하면 심볼릭 링크가 복원되고, 원격 옵션으로 지정하면 심볼릭 링크가 변형됩니다. 이 옵션은 --remote-option을 통해 데몬으로 전송될 때 효과가 없습니다. 데몬은 \"munge symlinks\" 매개변수를 통해 변형된 심볼릭 링크를 원하는지 구성하기 때문입니다. 심볼릭 링크 값은 전송 시 변형/복원되므로, 심볼릭 링크를 비심볼릭 링크로 변환하는 모든 옵션은 --safe-links를 제외하고 변형/복원보다 먼저 발생합니다. --safe-links는 수신자가 내리는 결정이므로, 변형/복원된 값을 기반으로 결정을 내립니다. 이는 수신자가 변형을 활성화한 경우, --safe-links를 사용하면 모든 심볼릭 링크가 무시됨을 의미합니다 (모두 절대 경로이므로). rsync가 심볼릭 링크를 변형하는 방법은 각 값 앞에 문자열 \"/rsyncd-munged/\"를 붙이는 것입니다. 이는 디렉토리가 존재하지 않는 한 링크를 사용할 수 없게 합니다. 이 옵션이 활성화되면, rsync는 해당 경로가 디렉토리이거나 디렉토리에 대한 심볼릭 링크이면 실행을 거부합니다 (시작 시에만 확인합니다). 제자리에서 하나 이상의 심볼릭 링크를 변형/복원하는 방법은 소스 코드의 support 디렉토리에 있는 \"munge-symlinks\" python 스크립트도 참조하십시오. --copy-dirlinks, -k 이 옵션은 보내는 측이 디렉토리에 대한 심볼릭 링크를 실제 디렉토리처럼 처리하도록 합니다. 이는 --copy-links를 사용할 때처럼 비디렉토리 심볼릭 링크가 영향을 받지 않도록 하려는 경우에 유용합니다. 이 옵션이 없으면, 보내는 측이 디렉토리를 디렉토리에 대한 심볼릭 링크로 교체한 경우, 받는 측은 새 심볼릭 링크를 방해하는 모든 것을 삭제합니다. 디렉토리 계층 구조도 포함합니다 (--force 또는 --delete가 적용 중인 한). 수신 측에 대한 유사한 옵션은 --keep-dirlinks를 참조하십시오. --copy-dirlinks는 소스에 있는 디렉토리에 대한 모든 심볼릭 링크에 적용됩니다. 지정된 몇몇 심볼릭 링크만 따르려면, 후행 슬래시와 함께 추가 소스 인자로 전달하고, --relative를 사용하여 경로가 올바르게 일치하도록 하는 트릭을 사용할 수 있습니다. 예를 들어: rsync -r --relative src/./ src/./follow-me/ dest/ 이것이 작동하는 이유는 rsync가 주어진 소스 인자에 lstat(2)를 호출하고, 후행 슬래시가 lstat(2)가 심볼릭 링크를 따르도록 하여 파일 목록에 디렉토리가 생성되고, 이는 \"src/./\" 스캔 중에 발견된 심볼릭 링크를 재정의하기 때문입니다. 다중 옵션 정보는 SYMBOLIC LINKS 섹션을 참조하십시오. --keep-dirlinks, -K 이 옵션은 수신 측이 디렉토리에 대한 심볼릭 링크를 실제 디렉토리처럼 처리하도록 하지만, 보내는 측의 실제 디렉토리와 일치하는 경우에만 그렇습니다. 이 옵션이 없으면 수신자의 심볼릭 링크는 삭제되고 실제 디렉토리로 교체됩니다. 예를 들어, \"file\"을 포함하는 디렉토리 \"foo\"를 전송한다고 가정해 봅시다. 그러나 \"foo\"는 수신자 측에서 디렉토리 \"bar\"에 대한 심볼릭 링크입니다. --keep-dirlinks가 없으면 수신자는 심볼릭 링크 \"foo\"를 삭제하고, 디렉토리로 다시 생성하고, 새 디렉토리로 파일을 수신합니다. --keep-dirlinks를 사용하면 수신자는 심볼릭 링크를 유지하고 \"file\"은 \"bar\"에 저장됩니다. 주의할 점: --keep-dirlinks를 사용하는 경우, 복사본의 모든 심볼릭 링크를 신뢰하거나 수신 측에서 --munge-links 옵션을 활성화해야 합니다! 신뢰할 수 없는 사용자가 실제 디렉토리에 대한 자신만의 심볼릭 링크를 생성할 수 있는 경우, 해당 사용자는 (후속 복사 시) 심볼릭 링크를 실제 디렉토리로 교체하고 심볼릭 링크가 참조하는 디렉토리의 내용에 영향을 미칠 수 있습니다. 백업 복사의 경우, 수신 계층 구조를 수정하기 위해 심볼릭 링크 대신 바인드 마운트와 같은 것을 사용하는 것이 좋습니다. 보내는 측에 대한 유사한 옵션은 --copy-dirlinks를 참조하십시오. 다중 옵션 정보는 SYMBOLIC LINKS 섹션을 참조하십시오. --hard-links, -H 이것은 rsync에게 소스에서 하드 링크된 파일을 찾아 대상에서 해당 파일을 함께 링크하도록 지시합니다. 이 옵션이 없으면 소스의 하드 링크된 파일은 별개의 파일처럼 처리됩니다. 이 옵션은 대상의 하드 링크 패턴이 소스의 패턴과 정확히 일치하도록 반드시 보장하지는 않습니다. 대상이 추가 하드 링크로 끝날 수 있는 경우는 다음과 같습니다: o 대상이 불필요한 하드 링크를 포함하는 경우 (소스 파일 목록에 있는 것보다 더 많은 링크), 복사 알고리즘은 명시적으로 링크를 끊지 않습니다. 그러나 하나 이상의 경로에 내용 차이가 있는 경우, 일반 파일 업데이트 프로세스는 해당 추가 링크를 끊습니다 (--inplace 옵션을 사용하지 않는 한). o 하드 링크를 포함하는 --link-dest 디렉토리를 지정하는 경우, 대상 파일을 --link-dest 파일과 링크하는 것은 --link-dest 연결로 인해 대상의 일부 경로가 함께 링크될 수 있습니다. rsync는 전송 집합 내에 있는 파일 간의 하드 링크만 감지할 수 있습니다. rsync가 전송 외부 파일에 추가 하드 링크 연결이 있는 파일을 업데이트하면 해당 링크는 끊어집니다. 이러한 손상을 피하기 위해 --inplace 옵션을 사용하려는 경우, 의도하지 않은 변경이 남은 하드 링크로 인해 발생하지 않도록 파일이 업데이트되는 방식을 신중하게 파악해야 합니다 (--inplace 옵션에 대한 추가 주의사항 참조). 증분 재귀가 활성화된 경우 (--inc-recursive 참조), rsync는 계층 구조의 다른 곳에 해당 내용에 대한 다른 링크가 존재한다는 것을 발견하기 전에 누락된 하드 링크된 파일을 전송할 수 있습니다. 이는 전송의 정확성(즉, 어떤 파일이 하드 링크되어 있는지)에는 영향을 미치지 않지만, 효율성(즉, 나중에 전송에서 하드 링크된 파일 집합의 다른 구성원에서 발견될 수 있었던 하드 링크된 파일의 새, 초기 복사본에 대한 데이터 복사)에는 영향을 미칩니다. 이러한 비효율성을 피하는 한 가지 방법은 --no-inc-recursive 옵션을 사용하여 증분 재귀를 비활성화하는 것입니다. --perms, -p 이 옵션은 수신 rsync가 대상 권한을 소스 권한과 동일하게 설정하도록 합니다. (--chmod 옵션은 rsync가 소스 권한으로 간주하는 것을 수정하는 방법을 참조하십시오.) 이 옵션이 꺼져 있으면 권한은 다음과 같이 설정됩니다: o 기존 파일 (업데이트된 파일 포함)은 기존 권한을 유지하지만, --executability 옵션은 파일의 실행 권한만 변경할 수 있습니다. o 새 파일은 수신 프로세스의 umask 또는 대상 디렉토리의 기본 ACL을 통해 지정된 권한과 함께 소스 파일의 권한이 마스킹되어 \"일반\" 권한 비트가 설정되고, 새 디렉토리가 부모 디렉토리에서 setgid 비트를 상속하는 경우를 제외하고는 특수 권한 비트는 비활성화됩니다. 따라서 --perms와 --executability가 모두 비활성화되면 rsync의 동작은 cp(1) 및 tar(1)와 같은 다른 파일 복사 유틸리티와 동일합니다. 요약하자면: 대상 파일(기존 파일과 새 파일 모두)에 소스 권한을 부여하려면 --perms를 사용하십시오. 새 파일에 대상 기본 권한을 부여하려면(기존 파일은 변경하지 않고), --perms 옵션이 꺼져 있는지 확인하고 --chmod=ugo=rwX를 사용하십시오(모든 비마스킹된 비트가 활성화되도록 보장합니다). 이 후자의 동작을 더 쉽게 타이핑하고 싶다면, 다음과 같이 ~/.popt 파일에 이 줄을 추가하여 popt 별칭을 정의할 수 있습니다(다음은 -Z 옵션을 정의하며, 대상 디렉토리의 기본 그룹을 사용하기 위해 --no-g를 포함합니다): rsync alias -Z --no-p --no-g --chmod=ugo=rwX 그런 다음 이 새로운 옵션을 다음과 같은 명령에 사용할 수 있습니다: rsync -avZ src/ dest/ (주의: -a가 -Z 뒤에 오지 않도록 하십시오. 그렇지 않으면 위에 언급된 두 --no-* 옵션이 다시 활성화됩니다.) --perms가 꺼져 있을 때 새로 생성된 디렉토리의 대상 setgid 비트 보존은 rsync 2.6.7에 추가되었습니다. 오래된 rsync 버전은 --perms가 꺼져 있을 때 새로 생성된 파일에 대해 세 가지 특수 권한 비트를 잘못 보존했으며, 새로 생성된 디렉토리의 대상 setgid 비트 설정을 재정의했습니다. 기본 ACL 준수는 rsync 2.6.7용 ACL 패치에 추가되었으므로, 오래된 (또는 ACL이 활성화되지 않은) rsync는 기본 ACL이 존재하더라도 umask를 사용합니다. (이러한 동작에 영향을 미치는 것은 수신 rsync의 버전임을 명심하십시오.) --executability, -E 이 옵션은 --perms가 활성화되지 않았을 때 rsync가 일반 파일의 실행 가능성(또는 비실행 가능성)을 보존하도록 합니다. 일반 파일은 권한에 'x' 중 하나 이상이 켜져 있으면 실행 가능한 것으로 간주됩니다. 기존 대상 파일의 실행 가능성이 해당 소스 파일과 다를 때, rsync는 대상 파일의 권한을 다음과 같이 수정합니다: o 파일을 비실행 가능하게 만들려면 rsync는 모든 'x' 권한을 끕니다. o 파일을 실행 가능하게 만들려면 rsync는 해당 'r' 권한이 활성화된 모든 'x' 권한을 켭니다. --perms가 활성화되면 이 옵션은 무시됩니다. --acls, -A 이 옵션은 rsync가 대상 ACL을 소스 ACL과 동일하게 업데이트하도록 합니다. 이 옵션은 또한 --perms를 암시합니다. 이 옵션이 제대로 작동하려면 소스 및 대상 시스템이 호환 가능한 ACL 항목을 가지고 있어야 합니다. 호환되지 않는 ACL을 백업하고 복원하는 방법에 대해서는 --fake-super 옵션을 참조하십시오. --xattrs, -X 이 옵션은 rsync가 대상 확장 속성을 소스 확장 속성과 동일하게 업데이트하도록 합니다. 확장-속성 네임스페이스를 지원하는 시스템의 경우, 슈퍼유저가 수행하는 복사는 system.*를 제외한 모든 네임스페이스를 복사합니다. 일반 사용자는 user.* 네임스페이스만 복사합니다. 일반 사용자로 비-user 네임스페이스를 백업하고 복원하려면 --fake-super 옵션을 참조하십시오. 위 이름 필터링은 x 수정자와 함께 하나 이상의 필터 옵션을 사용하여 재정의할 수 있습니다. xattr에 영향을 미치는 필터 규칙을 지정하면 rsync는 자체 시스템/사용자 필터링은 물론, 어떤 xattr 이름을 복사하고 어떤 이름을 삭제할 수 있는지에 대한 추가 필터링을 수행하도록 요구합니다. 예를 들어, system 네임스페이스를 건너뛰려면 다음과 같이 지정할 수 있습니다: --filter='-x system.*' user 네임스페이스를 제외한 모든 네임스페이스를 건너뛰려면 다음과 같이 부정-user 일치를 지정할 수 있습니다: --filter='-x! user.*' 어떤 속성도 삭제되지 않도록 하려면 모든 이름을 제외하는 수신자 전용 규칙을 지정할 수 있습니다: --filter='-xr *' -X 옵션은 --fake-super에 사용되는 것과 같은 rsync의 특수 xattr 값을 복사하지 않습니다 (옵션을 반복하지 않는 한, 예: -XX). 이 \"모든 xattrs 복사\" 모드는 --fake-super와 함께 사용할 수 없습니다. --chmod=CHMOD 이 옵션은 rsync에게 전송 중인 파일의 권한에 하나 이상의 쉼표로 구분된 \"chmod\" 모드를 적용하도록 지시합니다. 결과 값은 보내는 측이 파일에 제공한 권한인 것처럼 처리됩니다. 이는 --perms가 활성화되지 않은 경우 이 옵션이 기존 파일에 영향을 미 미치지 않는 것처럼 보일 수 있다는 의미입니다. chmod(1) 맨페이지에 지정된 일반적인 파싱 규칙 외에도, 디렉토리에만 적용되어야 하는 항목은 'D'를 접두사로 붙여 지정할 수 있고, 파일에만 적용되어야 하는 항목은 'F'를 접두사로 붙여 지정할 수 있습니다. 예를 들어, 다음은 모든 디렉토리가 set-gid로 표시되고, 어떤 파일도 다른 사용자가 쓸 수 없으며, 둘 다 사용자-쓰기 가능하고 그룹-쓰기 가능하며, 모든 비트에 걸쳐 일관된 실행 가능성을 갖도록 보장합니다: --chmod=Dg+s,ug+w,Fo-w,+X 8진수 모드 숫자 사용도 허용됩니다: --chmod=D2775,F664 여러 --chmod 옵션을 지정하는 것도 합법적입니다. 각 추가 옵션은 만들 변경 목록에 단순히 추가됩니다. 결과 권한 값이 전송 중인 파일에 어떻게 적용될 수 있는지에 대한 내용은 --perms 및 --executability 옵션을 참조하십시오. --owner, -o 이 옵션은 rsync가 대상 파일의 소유자를 소스 파일과 동일하게 설정하도록 하지만, 수신 rsync가 슈퍼유저로 실행되는 경우에만 그렇습니다 (--super 및 --fake-super 옵션도 참조). 이 옵션이 없으면 새 파일 및/또는 전송된 파일의 소유자는 수신 측의 호출 사용자로 설정됩니다. 소유권 보존은 기본적으로 일치하는 이름을 연결하지만, 일부 상황에서는 ID 번호를 사용하는 것으로 대체될 수 있습니다 (--numeric-ids 옵션에서 자세한 내용을 참조하십시오). --group, -g 이 옵션은 rsync가 대상 파일의 그룹을 소스 파일과 동일하게 설정하도록 합니다. 수신 프로그램이 슈퍼유저로 실행되지 않거나 (--no-super가 지정된 경우) 수신 측의 호출 사용자가 구성원인 그룹만 보존됩니다. 이 옵션이 없으면 그룹은 수신 측의 호출 사용자의 기본 그룹으로 설정됩니다. 그룹 정보 보존은 기본적으로 일치하는 이름을 연결하지만, 일부 상황에서는 ID 번호를 사용하는 것으로 대체될 수 있습니다 (--numeric-ids 옵션에서 자세한 내용을 참조하십시오). --devices 이 옵션은 rsync가 문자 및 블록 장치 파일을 원격 시스템으로 전송하여 이러한 장치를 다시 생성하도록 합니다. 수신 rsync가 슈퍼유저로 실행되지 않는 경우, rsync는 장치 파일 생성을 조용히 건너뜁니다 (--super 및 --fake-super 옵션도 참조). 기본적으로 rsync는 이 옵션이 설정되지 않았을 때 발견되는 각 장치 파일에 대해 \"비정규 파일 건너뛰기\" 경고를 생성합니다. --info=nonreg0을 지정하여 경고를 억제할 수 있습니다. --specials 이 옵션은 rsync가 명명된 소켓 및 FIFO와 같은 특수 파일을 전송하도록 합니다. 수신 rsync가 슈퍼유저로 실행되지 않는 경우, rsync는 특수 파일 생성을 조용히 건너뜁니다 (--super 및 --fake-super 옵션도 참조). 기본적으로 rsync는 이 옵션이 설정되지 않았을 때 발견되는 각 특수 파일에 대해 \"비정규 파일 건너뛰기\" 경고를 생성합니다. --info=nonreg0을 지정하여 경고를 억제할 수 있습니다. -D -D 옵션은 \"--devices --specials\"와 동일합니다. --copy-devices 이것은 rsync에게 보내는 측의 장치를 일반 파일처럼 처리하도록 지시하여, 일반 대상 파일로 (또는 --write-devices도 지정된 경우 다른 장치로) 복사할 수 있도록 합니다. 이 옵션은 rsync 데몬에 의해 기본적으로 거부됩니다. --write-devices 이것은 rsync에게 받는 측의 장치를 일반 파일처럼 처리하도록 지시하여, 파일 데이터를 장치에 쓸 수 있도록 합니다. 이 옵션은 --inplace 옵션을 암시합니다. 특히 rsync를 root로 실행할 때 전송의 받는 측에 어떤 장치가 있는지 알아야 하므로 이 옵션을 사용할 때 주의해야 합니다. 이 옵션은 rsync 데몬에 의해 기본적으로 거부됩니다. --times, -t 이것은 rsync에게 파일과 함께 수정 시간을 전송하고 원격 시스템에서 업데이트하도록 지시합니다. 이 옵션을 사용하지 않으면 수정되지 않은 파일을 제외하는 최적화가 효과적일 수 없습니다. 다시 말해, -t (또는 -a)가 없으면 다음 전송은 --ignore-times (-I)를 사용한 것처럼 동작하여 모든 파일이 업데이트됩니다 (비록 rsync의 델타-전송 알고리즘은 파일이 실제로 변경되지 않았다면 업데이트를 상당히 효율적으로 만들겠지만, -t를 사용하는 것이 훨씬 좋습니다). 전송 프로토콜 30 또는 31을 사용하는 최신 rsync는 최대 8바이트를 사용하여 수정 시간을 전달합니다. rsync가 이전 프로토콜을 사용하도록 강제되면 (아마도 원격 rsync가 3.0.0보다 오래되었기 때문에) 4바이트를 사용하여 수정 시간을 전달합니다. 3.2.7 이전에는 이러한 짧은 값들이 1901년 12월 13일부터 2038년 1월 19일까지의 날짜 범위를 전달할 수 있었습니다. 3.2.7부터 이러한 4바이트 값은 이제 1970년 1월 1일부터 2106년 2월 7일까지의 날짜 범위를 전달합니다. 1970년 이전 날짜의 파일이 있다면, 날짜의 전체 범위를 전달할 수 있도록 rsync 실행 파일을 업그레이드했는지 확인하십시오. --atimes, -U 이것은 rsync에게 대상 파일의 접근(사용) 시간을 소스 파일과 동일하게 설정하도록 지시합니다. 반복해서 사용하면 --open-noatime 옵션도 설정됩니다. 이는 파일을 전송한 후 rsync를 한 번 더 실행할 필요 없이 보내는 시스템과 받는 시스템이 전송된 파일에 대해 동일한 접근 시간을 가지도록 돕습니다. 일부 오래된 rsync 버전(3.2.0 이전)은 이 옵션을 반복할 때 --open-noatime을 암시하지 않는 사전 릴리스 --atimes 패치로 빌드되었을 수 있다는 점에 유의하십시오. --open-noatime 이것은 rsync에게 O_NOATIME 플래그(이를 지원하는 시스템에서)로 파일을 열어 전송 중인 파일의 접근 시간을 변경하지 않도록 지시합니다. 운영 체제가 O_NOATIME 플래그를 지원하지 않으면 rsync는 이 옵션을 조용히 무시합니다. 또한 일부 파일 시스템은 O_NOATIME 플래그가 설정되지 않아도 읽기 접근 시 atime 업데이트를 피하도록 마운트된다는 점에 유의하십시오. --crtimes, -N 이것은 rsync에게 대상 파일의 생성 시간(새로움)을 소스 파일과 동일하게 설정하도록 지시합니다. --omit-dir-times, -O 이것은 rsync에게 수정, 접근 및 생성 시간을 보존할 때 디렉토리를 생략하도록 지시합니다. NFS가 수신 측에서 디렉토리를 공유하는 경우 -O를 사용하는 것이 좋습니다. 이 옵션은 --backup을 --backup-dir 없이 사용하면 추론됩니다. 이 옵션은 또한 --inc-recursive 섹션에서 논의된 바와 같이 증분 재귀가 활성화되었을 때 누락된 하위 디렉토리의 조기 생성을 피하는 부작용이 있습니다. --omit-link-times, -J 이것은 rsync에게 수정, 접근 및 생성 시간을 보존할 때 심볼릭 링크를 생략하도록 지시합니다. --super 이것은 수신 rsync가 슈퍼유저가 실행한 것이 아니더라도 슈퍼유저 활동을 시도하도록 지시합니다. 이러한 활동에는 다음이 포함됩니다: --owner 옵션을 통한 사용자 보존, --group 옵션을 통한 모든 그룹 보존(현재 사용자의 그룹뿐만 아니라), --devices 옵션을 통한 장치 복사. 이것은 슈퍼유저가 아니어도 그러한 활동을 허용하는 시스템에 유용하며, 수신 측이 슈퍼유저로 실행되지 않는 경우 오류를 얻는 데도 유용합니다. 슈퍼유저 활동을 끄려면 슈퍼유저는 --no-super를 사용할 수 있습니다. --fake-super 이 옵션이 활성화되면 rsync는 특수 확장 속성(필요에 따라 각 파일에 첨부됨)을 통해 특권 속성을 저장/복원하여 슈퍼유저 활동을 시뮬레이션합니다. 여기에는 파일의 소유자 및 그룹(기본값이 아닌 경우), 파일의 장치 정보(장치 및 특수 파일은 빈 텍스트 파일로 생성됨), 실제 파일에 설정되지 않을 권한 비트(예: 실제 파일은 안전을 위해 u-s,g-s,o-t를 가짐) 또는 소유자의 접근을 제한하는 권한 비트(실제 슈퍼유저는 항상 파일에 접근/변경할 수 있으므로, 우리가 생성하는 파일은 항상 생성 사용자가 접근/변경할 수 있음)가 포함됩니다. 이 옵션은 ACL(--acls가 지정된 경우) 및 비-사용자 확장 속성(--xattrs가 지정된 경우)도 처리합니다. 이것은 슈퍼유저를 사용하지 않고 데이터를 백업하고, 호환되지 않는 시스템의 ACL을 저장하는 좋은 방법입니다. --fake-super 옵션은 옵션이 사용된 측에만 영향을 미칩니다. 원격-셸 연결의 원격 측에 영향을 미치려면 --remote-option (-M) 옵션을 사용하십시오: rsync -av -M--fake-super /src/ host:/dest/ 로컬 복사의 경우, 이 옵션은 소스 및 대상 모두에 영향을 미칩니다. 로컬 복사에서 이 옵션을 대상 파일에만 활성화하려면 -M--fake-super를 지정하십시오. 로컬 복사에서 이 옵션을 소스 파일에만 활성화하려면 --fake-super를 -M--super와 결합하십시오. 이 옵션은 --super 및 --no-super 모두에 의해 재정의됩니다. 데몬의 rsyncd.conf 파일에 있는 fake super 설정도 참조하십시오. --sparse, -S 스파스 파일을 효율적으로 처리하여 대상에서 공간을 덜 차지하도록 합니다. --inplace와 결합하면 일부 커널 버전 및/또는 파일 시스템 유형 조합에서는 생성된 파일이 스파스 블록으로 끝나지 않을 수 있습니다. --whole-file이 적용되는 경우(예: 로컬 복사의 경우) rsync가 업데이트된 버전을 쓰기 전에 파일을 잘라내므로 항상 작동합니다. rsync 3.1.3 이전 버전은 --sparse와 --inplace의 조합을 거부한다는 점에 유의하십시오. --preallocate 이것은 수신자에게 데이터를 파일에 쓰기 전에 각 대상 파일을 최종 크기로 할당하도록 지시합니다. Rsync는 Linux의 fallocate(2) 시스템 호출 또는 Cygwin의 posix_fallocate(3)가 제공하는 실제 파일 시스템 수준의 사전 할당 지원만 사용하며, 각 블록에 널 바이트를 쓰는 느린 glibc 구현은 사용하지 않습니다. 이 옵션이 없으면 큰 파일은 파일 시스템에서 완전히 연속적이지 않을 수 있지만, 이 옵션을 사용하면 rsync가 더 느리게 복사될 수 있습니다. 대상이 익스텐트(extent)를 지원하는 파일 시스템(예: ext4, xfs, NTFS 등)이 아니면 이 옵션은 전혀 긍정적인 효과를 내지 못할 수 있습니다. --sparse와 결합하면, 할당된 데이터에 구멍을 생성하는 커널 버전 및 파일 시스템 유형이 지원하는 경우에만 파일에 스파스 블록(할당된 널 바이트 시퀀스 대신)이 생성됩니다. --dry-run, -n 이것은 rsync가 변경 사항을 만들지 않는 시범 실행을 수행하도록 합니다 (실제 실행과 대부분 동일한 출력을 생성합니다). 가장 일반적으로 --verbose (-v) 및/또는 --itemize-changes (-i) 옵션과 함께 사용하여 rsync 명령이 실제로 실행되기 전에 무엇을 할지 확인하는 데 사용됩니다. --itemize-changes의 출력은 드라이 런과 후속 실제 실행에서 정확히 동일해야 합니다 (의도적인 속임수 및 시스템 호출 실패 제외). 만약 동일하지 않다면 버그입니다. 다른 출력은 대부분 변경되지 않아야 하지만, 일부 영역에서 다를 수 있습니다. 특히, 드라이 런은 파일 전송을 위한 실제 데이터를 보내지 않으므로, --progress는 효과가 없고, \"전송된 바이트\", \"수신된 바이트\", \"리터럴 데이터\", \"일치하는 데이터\" 통계가 너무 작으며, \"속도 향상\" 값은 파일 전송이 필요 없는 실행과 동일합니다. --whole-file, -W 이 옵션은 rsync의 델타-전송 알고리즘을 비활성화하여, 전송되는 모든 파일이 통째로 보내지도록 합니다. 소스와 대상 머신 간의 대역폭이 디스크 대역폭보다 높은 경우 (특히 \"디스크\"가 실제로 네트워크 파일 시스템인 경우) 이 옵션을 사용하면 전송이 더 빨라질 수 있습니다. 이는 소스와 대상이 모두 로컬 경로로 지정될 때의 기본값이지만, 일괄 쓰기(batch-writing) 옵션이 적용되지 않는 경우에만 해당합니다. --no-whole-file, --no-W 로컬 전송에 대해 기본적으로 전체 파일 업데이트가 활성화된 경우 이를 비활성화합니다. 이는 일반적으로 rsync 속도를 늦추지만, 대상 파일에 대한 쓰기를 최소화하려는 경우(--inplace와 결합 시) 또는 체크섬 기반 업데이트 알고리즘을 테스트하는 데 유용할 수 있습니다. --whole-file 옵션도 참조하십시오. --checksum-choice=STR, --cc=STR 이 옵션은 체크섬 알고리즘을 재정의합니다. 하나의 알고리즘 이름이 지정되면, 전송 체크섬과 ( --checksum이 지정되었다고 가정하면) 전송 전 체크섬 모두에 사용됩니다. 두 개의 쉼표로 구분된 이름이 제공되면, 첫 번째 이름은 전송 체크섬에 영향을 미치고, 두 번째 이름은 전송 전 체크섬(-c)에 영향을 미칩니다. 사용할 수 있는 체크섬 옵션은 다음과 같습니다: o auto (기본 자동 선택) o xxh128 o xxh3 o xxh64 (일명 xxhash) o md5 o md4 o sha1 o none rsync --version을 실행하여 자신의 버전에 컴파일된 기본 체크섬 목록을 확인하십시오 (위 목록과 다를 수 있습니다). 첫 번째 (또는 유일한) 이름에 \"none\"이 지정되면, --whole-file 옵션이 강제 적용되고 전송된 데이터에 대한 체크섬 검증이 수행되지 않습니다. 두 번째 (또는 유일한) 이름에 \"none\"이 지정되면, --checksum 옵션을 사용할 수 없습니다. \"auto\" 옵션은 기본값이며, rsync는 클라이언트와 서버 간의 협상에 따라 알고리즘을 선택합니다: 전송의 양쪽이 최소 3.2.0 버전인 경우, rsync는 클라이언트의 선택 목록에 있는 첫 번째 알고리즘 중에서 서버의 선택 목록에도 있는 것을 선택합니다. 공통 체크섬 선택이 발견되지 않으면 rsync는 오류로 종료됩니다. 원격 rsync가 너무 오래되어 체크섬 협상을 지원하지 않으면, 프로토콜 버전에 따라 값이 선택됩니다 (프로토콜 기간에 따라 MD5와 다양한 MD4 버전 중 하나를 선택합니다). 기본 순서는 환경 변수 RSYNC_CHECKSUM_LIST를 허용되는 체크섬 이름의 공백으로 구분된 목록으로 설정하여 사용자 정의할 수 있습니다. 문자열에 \"\u0026\" 문자가 포함된 경우 \"클라이언트 문자열 \u0026 서버 문자열\"로 분리되고, 그렇지 않으면 동일한 문자열이 둘 다에 적용됩니다. 문자열(또는 문자열 부분)에 공백이 아닌 문자가 없으면 기본 체크섬 목록이 사용됩니다. 유효하지 않은 이름만 있는 목록은 협상 실패로 이어집니다. --checksum-choice 옵션을 사용하면 이 환경 목록이 재정의됩니다. --one-file-system, -x 이것은 rsync에게 재귀할 때 파일 시스템 경계를 넘지 않도록 지시합니다. 이는 사용자가 여러 파일 시스템에서 복사할 항목을 지정하는 능력을 제한하지 않고, 사용자가 지정한 각 디렉토리 계층 구조 내에서 rsync의 재귀만 제한하며, 삭제 시 수신 측에서도 유사한 재귀를 제한합니다. 또한 rsync는 동일한 장치에 대한 \"바인드\" 마운트를 동일한 파일 시스템에 있는 것으로 처리한다는 점을 명심하십시오. 이 옵션을 반복하면 rsync는 모든 마운트 지점 디렉토리를 복사에서 제외합니다. 그렇지 않으면, 발견되는 각 마운트 지점에 빈 디렉토리를 포함합니다 (마운트된 디렉토리의 속성을 사용하며, 기본 마운트 지점 디렉토리의 속성은 접근할 수 없습니다). rsync가 심볼릭 링크를 축소하도록 지시받은 경우 (--copy-links 또는 --copy-unsafe-links를 통해), 다른 장치에 대한 디렉토리 심볼릭 링크는 마운트 지점처럼 처리됩니다. 비디렉토리 심볼릭 링크는 이 옵션의 영향을 받지 않습니다. --ignore-non-existing, --existing 이것은 rsync에게 대상에 아직 존재하지 않는 파일(디렉토리 포함) 생성을 건너뛰도록 지시합니다. 이 옵션을 --ignore-existing 옵션과 결합하면 어떤 파일도 업데이트되지 않습니다 (이는 불필요한 파일만 삭제하려는 경우 유용할 수 있습니다). 이 옵션은 TRANSFER RULE이므로, 어떤 제외 부작용도 기대하지 마십시오. --ignore-existing 이것은 rsync에게 대상에 이미 존재하는 파일 업데이트를 건너뛰도록 지시합니다 (기존 디렉토리는 무시하지 않으므로, 아무것도 수행되지 않을 것입니다). --ignore-non-existing도 참조하십시오. 이 옵션은 TRANSFER RULE이므로, 어떤 제외 부작용도 기대하지 마십시오. 이 옵션은 중단된 백업 실행을 계속해야 할 때 --link-dest 옵션을 사용하여 백업을 수행하는 사람들에게 유용할 수 있습니다. --link-dest 실행이 새 디렉토리 계층으로 복사되므로 (제대로 사용될 때), --ignore-existing을 사용하면 이미 처리된 파일이 수정되지 않도록 보장합니다 (하드 링크된 파일의 권한 변경을 방지합니다). 이는 이 옵션이 대상 계층 자체의 기존 파일만 본다는 것을 의미합니다. --info=skip2가 사용될 때 rsync는 \"FILENAME exists (INFO)\" 메시지를 출력하며, 여기서 INFO는 \"type change\", \"sum change\" (-c 필요), \"file change\" (빠른 검사 기반), \"attr change\", 또는 \"uptodate\" 중 하나를 나타냅니다. --info=skip1 (2개의 -v 옵션으로도 암시됨)을 사용하면 INFO 접미사 없이 exists 메시지를 출력합니다. --remove-source-files 이것은 rsync에게 전송의 일부이며 수신 측에서 성공적으로 복제된 파일 (비디렉토리 의미)을 보내는 측에서 제거하도록 지시합니다. 이 옵션은 정지(quiescent)된 소스 파일에만 사용해야 합니다. 특정 디렉토리에 나타나는 파일을 다른 호스트로 이동하는 데 이 옵션을 사용하는 경우, 완성된 파일이 소스 디렉토리에 직접 쓰이는 것이 아니라 소스 디렉토리로 이름이 변경되도록 하십시오. 이렇게 하면 rsync가 아직 완전히 쓰여지지 않은 파일을 전송할 가능성을 막을 수 있습니다. 파일을 먼저 다른 디렉토리에 쓸 수 없다면, rsync가 아직 완성되지 않은 파일을 전송하는 것을 피할 수 있는 명명 관용구(예: 파일이 쓰여질 때 \"foo.new\"로 이름 지정, 완료되면 \"foo\"로 이름 변경, 그리고 rsync 전송에 --exclude='*.new' 옵션 사용)를 사용해야 합니다. 3.1.0부터 rsync는 파일의 크기 또는 수정 시간이 변경되지 않은 경우 보내는 측에서의 제거를 건너뛰고 (오류를 출력합니다). 3.2.6부터 로컬 rsync 복사는 사용자가 실수로 소스 및 대상 디렉토리를 동일한 경로로 지정한 경우와 같이, 수신자가 방금 확인한 파일을 보내는 측이 제거하지 않도록 합니다. --delete 이것은 rsync에게 수신 측에서 불필요한 파일(보내는 측에 없는 파일)을 삭제하도록 지시하지만, 동기화되는 디렉토리에 대해서만 그렇습니다. 와일드카드를 사용하여 디렉토리의 내용(예: \"dir/*\")을 지정하지 않고 rsync에게 전체 디렉토리(예: \"dir\" 또는 \"dir/\")를 보내도록 요청해야 합니다. 와일드카드는 셸에 의해 확장되고 rsync는 개별 파일을 전송하도록 요청받기 때문입니다. 전송에서 제외된 파일도 --delete-excluded 옵션을 사용하거나 규칙을 보내는 측에서만 일치하도록 표시하지 않으면 삭제에서 제외됩니다 (FILTER RULES 섹션의 포함/제외 수정자 참조). rsync 2.6.7 이전에는 이 옵션이 --recursive가 활성화되지 않으면 효과가 없었습니다. 2.6.7부터는 --dirs (-d)가 활성화될 때도 삭제가 발생하지만, 내용이 복사되는 디렉토리에 대해서만 그렇습니다. 이 옵션은 잘못 사용하면 위험할 수 있습니다! --dry-run (-n) 옵션을 사용하여 어떤 파일이 삭제될 것인지 먼저 확인하는 것이 매우 좋습니다. 보내는 측에서 I/O 오류가 감지되면 대상의 파일 삭제가 자동으로 비활성화됩니다. 이는 보내는 측의 일시적인 파일 시스템 오류(예: NFS 오류)가 대상의 대량 파일 삭제를 유발하는 것을 방지하기 위함입니다. --ignore-errors 옵션으로 이를 재정의할 수 있습니다. --delete 옵션은 --delete-WHEN 옵션 중 하나와 충돌 없이 결합될 수 있으며, --delete-excluded와도 결합될 수 있습니다. 그러나 --delete-WHEN 옵션 중 어느 것도 지정되지 않은 경우, rsync 3.0.0 이상과 통신할 때는 --delete-during 알고리즘을, 오래된 rsync와 통신할 때는 --delete-before 알고리즘을 선택합니다. --delete-delay 및 --delete-after도 참조하십시오. --delete-before 전송 시작 전에 수신 측에서 파일 삭제를 수행하도록 요청합니다. 파일 삭제에 대한 자세한 내용은 --delete (암시됨)를 참조하십시오. 전송 전에 삭제하는 것은 파일 시스템 공간이 부족하여 불필요한 파일을 제거하는 것이 전송을 가능하게 하는 데 도움이 될 때 유용합니다. 그러나 전송 시작 전에 지연이 발생하며, 이 지연으로 인해 전송이 타임아웃될 수 있습니다 (--timeout이 지정된 경우). 또한 rsync가 전송의 모든 파일을 한 번에 메모리로 스캔해야 하는 오래된 비증분 재귀 알고리즘을 사용하도록 강제합니다 (--recursive 참조). --delete-during, --del 전송 중에 수신 측에서 파일 삭제를 점진적으로 수행하도록 요청합니다. 디렉토리별 삭제 스캔은 각 디렉토리가 업데이트를 위해 검사되기 직전에 수행되므로, 더 효율적인 --delete-before처럼 작동하며, 디렉토리별 필터 파일이 업데이트되기 전에 삭제를 수행합니다. 이 옵션은 rsync 버전 2.6.4에 처음 추가되었습니다. 파일 삭제에 대한 자세한 내용은 --delete (암시됨)를 참조하십시오. --delete-delay 수신 측에서 파일 삭제가 전송 중에 계산된 후 (--delete-during처럼) 전송 완료 후에 제거되도록 요청합니다. 이는 --delay-updates 및/또는 --fuzzy와 결합할 때 유용하며, --delete-after를 사용하는 것보다 효율적입니다 (그러나 --delete-after는 모든 업데이트가 완료된 후 별도의 패스에서 삭제를 계산하므로 다르게 작동할 수 있습니다). 제거된 파일 수가 내부 버퍼를 초과하면 수신 측에 이름을 저장할 임시 파일이 생성됩니다 (열려 있는 동안 제거되므로 전송 중에는 보이지 않습니다). 임시 파일 생성이 실패하면 rsync는 --delete-after를 사용하는 것으로 대체하려고 시도합니다 (그러나 --recursive가 증분 스캔을 수행하는 경우에는 불가능합니다). 파일 삭제에 대한 자세한 내용은 --delete (암시됨)를 참조하십시오. --delete-after 전송이 완료된 후에 수신 측에서 파일 삭제를 수행하도록 요청합니다. 이는 전송의 일부로 새로운 디렉토리별 병합 파일을 보내고 해당 제외가 현재 전송의 삭제 단계에 영향을 미치도록 하려는 경우에 유용합니다. 또한 rsync가 전송의 모든 파일을 한 번에 메모리로 스캔해야 하는 오래된 비증분 재귀 알고리즘을 사용하도록 강제합니다 (--recursive 참조). 파일 삭제에 대한 자세한 내용은 --delete (암시됨)를 참조하십시오. 전송이 끝날 때 삭제가 발생하기를 원하는 사람들에게 더 빠른 선택일 수 있는 --delete-delay 옵션도 참조하십시오. --delete-excluded 이 옵션은 불확정적인 제외/포함 규칙을 수신자의 삭제에 영향을 미치지 않는 서버 측 규칙으로 전환합니다. 기본적으로 제외 또는 포함은 서버 측 효과(서버의 파일 목록을 생성할 때 파일을 \"숨기거나\" \"표시함\")와 수신자 측 효과(삭제가 발생할 때 파일을 \"보호하거나\" \"위험에 노출시킴\")를 모두 가집니다. 어떤 측에서 실행될지 지정하는 수정자가 없는 모든 규칙은 대신 서버 측 규칙으로만 처리되어 규칙의 \"보호\" 효과를 피합니다. 이 옵션이 지정되더라도 규칙에 전송자와 수신자 수정자 문자(예: -f'-sr foo')가 모두 주어지면 규칙은 여전히 양쪽에 적용될 수 있습니다. 수신자 측 보호/위험 규칙은 삭제를 제한하기 위해 명시적으로 지정될 수도 있습니다. 이것은 많은 -f'- foo' 규칙을 -f'-s foo' (일명 -f'H foo') 규칙으로 편집하는 수고를 덜어줍니다 (해당 포함 규칙은 말할 것도 없습니다). 자세한 내용은 FILTER RULES 섹션을 참조하십시오. 삭제에 대한 자세한 내용은 --delete (암시됨)를 참조하십시오. --ignore-missing-args rsync가 명시적으로 요청된 소스 파일(예: 명령줄 인자 또는 --files-from 항목)을 처음 처리할 때, 파일을 찾을 수 없으면 일반적으로 오류가 발생합니다. 이 옵션은 해당 오류를 억제하고 파일을 전송하려고 시도하지 않습니다. 이는 파일이 처음에 존재한다고 발견되었지만 나중에 더 이상 존재하지 않는 경우의 후속 파일 사라짐 오류에는 영향을 미치지 않습니다. --delete-missing-args 이 옵션은 (암시된) --ignore-missing-args 옵션의 동작을 한 단계 더 나아갑니다: 각 누락된 인자는 수신 측의 해당 대상 파일에 대한 삭제 요청이 됩니다 (존재하는 경우). 대상 파일이 비어 있지 않은 디렉토리인 경우, --force 또는 --delete가 적용되어야만 성공적으로 삭제됩니다. 그 외에는 이 옵션은 다른 유형의 삭제 처리와는 무관합니다. 누락된 소스 파일은 --list-only 출력에서 \"*missing\" 항목으로 표시되는 특수 파일-목록 항목으로 표현됩니다. --ignore-errors I/O 오류가 있을 때도 파일을 삭제하도록 --delete에게 지시합니다. --force 이 옵션은 rsync에게 비어 있지 않은 디렉토리를 비디렉토리로 교체할 때 삭제하도록 지시합니다. 이는 삭제가 활성화되어 있지 않을 때만 관련됩니다 (--delete에서 자세한 내용을 참조하십시오). 오래된 rsync 버전 참고: --force는 --delete-after를 사용할 때도 필요했으며, --recursive 옵션도 활성화되지 않으면 작동하지 않았습니다. --max-delete=NUM 이것은 rsync에게 NUM개 이상의 파일이나 디렉토리를 삭제하지 않도록 지시합니다. 이 제한을 초과하면 나머지 모든 삭제는 전송이 끝날 때까지 건너뛰어집니다. 마지막에 rsync는 경고(건너뛴 삭제 수 포함)를 출력하고 오류 코드 25로 종료합니다 (더 중요한 다른 오류 조건이 발생하지 않은 경우). 버전 3.0.0부터 --max-delete=0을 지정하여 대상에 있는 모든 불필요한 파일에 대한 경고를 받을 수 있지만 아무것도 제거하지는 않습니다. 오래된 클라이언트는 이것을 \"무제한\"으로 해석했으므로, 클라이언트 버전을 모르는 경우, 어떤 삭제도 허용되지 않도록 지정하는 역방향 호환성 방법으로 덜 명확한 --max-delete=-1을 사용할 수 있습니다 (그러나 아주 오래된 버전은 제한을 초과했을 때 경고하지 않았습니다). --max-size=SIZE 이것은 rsync에게 지정된 SIZE보다 큰 파일은 전송하지 않도록 지시합니다. 숫자 값 뒤에 단위 문자열을 붙이거나, 접미사 없이 바이트를 지정할 수 있습니다. --max-size=1.5m와 같이 분수 값을 단위와 함께 자유롭게 사용하십시오. 이 옵션은 TRANSFER RULE이므로, 어떤 제외 부작용도 기대하지 마십시오. 단위 문자열의 첫 글자는 B (바이트), K (킬로), M (메가), G (기가), T (테라), P (페타)일 수 있습니다. 문자열이 단일 문자이거나 \"ib\"가 추가된 경우 (예: \"G\" 또는 \"GiB\") 단위는 1024의 배수입니다. \"B\"로 끝나는 두 글자 접미사 (예: \"kb\")를 사용하면 1000의 배수 단위가 됩니다. 문자열의 문자는 원하는 대로 대소문자를 혼합할 수 있습니다. 마지막으로, 문자열이 \"+1\" 또는 \"-1\"로 끝나면 지정된 방향으로 1바이트만큼 오프셋됩니다. 가능한 가장 큰 값은 일반적으로 8192P-1입니다. 예: --max-size=1.5mb-1은 1499999 바이트이고, --max-size=2g+1은 2147483649 바이트입니다. rsync 3.1.0 이전 버전은 --max-size=0을 허용하지 않았다는 점에 유의하십시오. --min-size=SIZE 이것은 rsync에게 지정된 SIZE보다 작은 파일은 전송하지 않도록 지시합니다. 이는 작고 쓸모없는 파일을 전송하지 않는 데 도움이 될 수 있습니다. SIZE 및 기타 정보에 대한 설명은 --max-size 옵션을 참조하십시오. rsync 3.1.0 이전 버전은 --min-size=0을 허용하지 않았다는 점에 유의하십시오. --max-alloc=SIZE 기본적으로 rsync는 개별 malloc/realloc을 약 1GB로 제한합니다. 대부분의 사람들에게 이 제한은 잘 작동하며 프로토콜 오류로 인해 rsync가 엄청난 양의 메모리를 요청하는 것을 방지합니다. 그러나 전송할 파일이 수백만 개, 서버 메모리가 매우 많고, 전송을 여러 부분으로 나누고 싶지 않다면, 할당당 제한을 더 크게 늘릴 수 있으며 rsync는 더 많은 메모리를 소비할 것입니다. 이것은 할당된 총 메모리 크기에 대한 제한이 아니라는 점을 명심하십시오. 각 개별 할당에 대한 건전성 검사 값입니다. SIZE를 지정하는 방법에 대한 설명은 --max-size 옵션을 참조하십시오. 접미사가 제공되지 않으면 기본값은 바이트입니다. 3.2.3부터 0 값은 제한 없음(no limit)을 지정합니다. 환경 변수 RSYNC_MAX_ALLOC을 이 옵션이 지원하는 SIZE 값과 동일하게 사용하여 기본값을 설정할 수 있습니다. 원격 rsync가 --max-alloc 옵션을 이해하지 못하는 경우, --max-alloc=1g를 지정하여 환경 값을 재정의할 수 있습니다. 이렇게 하면 rsync는 원격 측으로 옵션을 보내지 않습니다 ( \"1G\"가 기본값이기 때문입니다). --block-size=SIZE, -B 이것은 rsync의 델타-전송 알고리즘에 사용되는 블록 크기를 고정된 값으로 강제합니다. 일반적으로 업데이트되는 각 파일의 크기에 따라 선택됩니다. 자세한 내용은 기술 보고서를 참조하십시오. 3.2.3부터 SIZE는 --max-size 옵션에 자세히 설명된 접미사와 함께 지정될 수 있습니다. 이전 버전은 바이트 수만 허용했습니다. --rsh=COMMAND, -e 이 옵션을 사용하면 로컬 rsync 복사본과 원격 rsync 복사본 간의 통신에 사용할 대체 원격 셸 프로그램을 선택할 수 있습니다. 일반적으로 rsync는 기본적으로 ssh를 사용하도록 구성되지만, 로컬 네트워크에서는 rsh를 사용하는 것을 선호할 수 있습니다. 이 옵션이 [user@]host::module/path와 함께 사용되면, 원격 셸 COMMAND는 원격 호스트에서 rsync 데몬을 실행하는 데 사용되며, 모든 데이터는 실행 중인 원격 rsync 데몬에 대한 직접 소켓 연결을 통하는 대신 해당 원격 셸 연결을 통해 전송됩니다. 위의 USING RSYNC-DAEMON FEATURES VIA A REMOTE-SHELL CONNECTION 섹션을 참조하십시오. rsync 3.2.0부터, 데몬 연결이 원격-셸 연결을 통해 이루어질 때 RSYNC_PORT 환경 변수가 설정됩니다. 기본 데몬 포트가 가정되면 0으로 설정되거나, --port 옵션 또는 rsync:// URL의 비어 있지 않은 포트 값을 통해 지정된 rsync 포트 값으로 설정됩니다. 이를 통해 스크립트는 비기본 포트가 요청되는지 여부를 식별하여, SSL 또는 stunnel 도우미 스크립트가 기본 또는 대체 포트에 연결하는 것과 같은 작업을 수행할 수 있도록 합니다. COMMAND가 단일 인자로 rsync에 제시되는 한, COMMAND에서 명령줄 인자가 허용됩니다. 명령과 인자를 서로 분리하려면 공백(탭 또는 다른 공백 문자 아님)을 사용해야 하며, 인자 내 공백을 보존하기 위해 단일 또는 이중 따옴표를 사용할 수 있습니다 (단, 역슬래시는 안 됨). 단일 따옴표로 묶인 문자열 내에서 단일 따옴표를 두 번 사용하면 단일 따옴표가 됩니다. 이중 따옴표도 마찬가지입니다 (어떤 따옴표를 셸이 파싱하고 어떤 따옴표를 rsync가 파싱하는지 주의해야 합니다). 몇 가지 예시: -e 'ssh -p 2234' -e 'ssh -o \"ProxyCommand nohup ssh firewall nc -w1 %h %p\"' (ssh 사용자는 .ssh/config 파일에서 사이트별 연결 옵션을 사용자 정의할 수도 있습니다.) RSYNC_RSH 환경 변수를 사용하여 원격 셸 프로그램을 선택할 수도 있으며, 이 변수는 -e와 동일한 범위의 값을 허용합니다. 이 옵션에 영향을 받는 --blocking-io 옵션도 참조하십시오. --rsync-path=PROGRAM 원격 머신에서 rsync를 시작하기 위해 실행할 프로그램을 지정하는 데 사용합니다. rsync가 기본 원격 셸의 경로에 없는 경우(예: --rsync-path=/usr/local/bin/rsync) 종종 사용됩니다. PROGRAM은 셸의 도움을 받아 실행되므로, rsync가 통신에 사용하는 표준 입력 및 표준 출력을 손상시키지 않는 한 모든 프로그램, 스크립트 또는 명령 시퀀스가 될 수 있습니다. 한 가지 까다로운 예는 --relative 옵션과 함께 사용하기 위해 원격 머신에서 다른 기본 디렉토리를 설정하는 것입니다. 예를 들어: rsync -avR --rsync-path=\"cd /a/b \u0026\u0026 rsync\" host:c/d /e/ --remote-option=OPTION, -M 이 옵션은 전송의 한쪽에만 특정 효과를 제한하려는 고급 상황에 사용됩니다. 예를 들어, --log-file=FILE 및 --fake-super를 원격 시스템에 전달하려면 다음과 같이 지정하십시오: rsync -av -M --log-file=foo -M--fake-super src/ dest/ 옵션이 일반적으로 양쪽에 영향을 미치지만, 로컬 측에만 영향을 미치도록 하려면 원격 측에 해당 옵션의 부정을 보내십시오. 예: rsync -av -x -M--no-x src/ dest/ 이 옵션을 사용할 때는 주의하십시오. rsync가 소켓을 통해 다음에 어떤 데이터를 예상해야 하는지에 대해 다른 개념을 갖게 하는 옵션을 토글할 수 있으며, 이는 알 수 없는 방식으로 실패하게 만들 것입니다. 전달하려는 원격 옵션마다 별도의 -M 옵션을 사용해야 합니다. 오래된 rsync 버전에서는 remote-option 인자에 공백이 있으면 별도의 원격 인자로 분할될 수 있었지만, 최신 rsync에서는 --old-args를 사용해야 합니다. 로컬 전송을 수행할 때 \"로컬\" 측은 전송자이고 \"원격\" 측은 수신자입니다. popt 옵션 파싱 라이브러리의 일부 버전에는 짧은 옵션 문자 옆에 등호가 있는 인자(--log-file=/tmp/foo와 같은)를 사용할 수 없게 하는 버그가 있다는 점에 유의하십시오. 이 버그가 popt 버전에 영향을 미치는 경우, rsync에 포함된 popt 버전을 사용할 수 있습니다. --cvs-exclude, -C 이것은 시스템 간에 전송하고 싶지 않은 광범위한 파일을 제외하는 데 유용한 약식입니다. CVS와 유사한 알고리즘을 사용하여 파일을 무시해야 하는지 여부를 결정합니다. 제외 목록은 다음 항목을 제외하도록 초기화됩니다 (이 초기 항목은 소멸성으로 표시됩니다 -- FILTER RULES 섹션 참조): RCS SCCS CVS CVS.adm RCSLOG cvslog.* tags TAGS .make.state .nse_depinfo *~ #* .#* ,* _$* *$ *.old *.bak *.BAK *.orig *.rej .del-* *.a *.olb *.o *.obj *.so *.exe *.Z *.elc *.ln core .svn/ .git/ .hg/ .bzr/ 그런 다음, $HOME/.cvsignore에 나열된 파일이 목록에 추가되고, CVSIGNORE 환경 변수에 나열된 모든 파일이 추가됩니다 (모든 cvsignore 이름은 공백으로 구분됩니다). 마지막으로, .cvsignore 파일과 동일한 디렉토리에 있고 그 안에 나열된 패턴 중 하나와 일치하는 모든 파일은 무시됩니다. rsync의 필터/제외 파일과 달리, 이러한 패턴은 공백으로 분할됩니다. 자세한 내용은 cvs(1) 매뉴얼을 참조하십시오. -C를 자신만의 --filter 규칙과 결합하는 경우, 이러한 CVS 제외는 명령줄에서 -C가 어디에 배치되었는지와 관계없이 자신만의 규칙 끝에 추가된다는 점을 유의해야 합니다. 이것은 명시적으로 지정한 규칙보다 우선순위가 낮다는 의미입니다. 이러한 CVS 제외가 필터 규칙에 삽입되는 위치를 제어하려면, 명령줄 옵션으로 -C를 생략하고 --filter=:C 및 --filter=-C 조합을 사용해야 합니다 (명령줄에서 또는 다른 규칙과 함께 필터 파일에 \":C\" 및 \"-C\" 규칙을 넣어서). 첫 번째 옵션은 .cvsignore 파일에 대한 디렉토리별 스캔을 켭니다. 두 번째 옵션은 위에 언급된 CVS 제외를 한 번 가져옵니다. --filter=RULE, -f 이 옵션을 사용하면 전송할 파일 목록에서 특정 파일을 선택적으로 제외하는 규칙을 추가할 수 있습니다. 이것은 재귀적 전송과 함께 사용할 때 가장 유용합니다. 명령줄에서 원하는 만큼 많은 --filter 옵션을 사용하여 제외할 파일 목록을 만들 수 있습니다. 필터에 공백이 포함되어 있으면 셸이 규칙을 rsync에 단일 인자로 전달하도록 반드시 인용(quote)하십시오. 아래 텍스트에는 규칙과 그 인자를 구분하는 공백 대신 밑줄을 사용할 수 있다는 내용도 언급되어 있습니다. 이 옵션에 대한 자세한 정보는 FILTER RULES 섹션을 참조하십시오. -F -F 옵션은 명령에 두 가지 --filter 규칙을 추가하는 약식입니다. 처음 사용될 때는 다음 규칙의 약식입니다: --filter='dir-merge /.rsync-filter' 이것은 rsync에게 계층 구조에 흩어져 있는 디렉토리별 .rsync-filter 파일을 찾아 전송 중인 파일을 필터링하는 데 그 규칙을 사용하도록 지시합니다. -F를 반복하면 다음 규칙의 약식입니다: --filter='exclude .rsync-filter' 이것은 .rsync-filter 파일 자체를 전송에서 필터링합니다. 이 옵션들이 어떻게 작동하는지에 대한 자세한 정보는 FILTER RULES 섹션을 참조하십시오. --exclude=PATTERN 이 옵션은 --filter 옵션의 단순화된 형태로, 제외 규칙을 지정하며 일반 필터 규칙의 전체 규칙 파싱 구문을 허용하지 않습니다. 이는 -f'- PATTERN'을 지정하는 것과 동일합니다. 이 옵션에 대한 자세한 정보는 FILTER RULES 섹션을 참조하십시오. --exclude-from=FILE 이 옵션은 --exclude 옵션과 관련이 있지만, 제외 패턴(줄당 하나)이 포함된 FILE을 지정합니다. 파일의 빈 줄은 무시되며, ';' 또는 '#'으로 시작하는 전체 줄 주석도 무시됩니다 (이러한 문자를 포함하는 파일 이름 규칙은 영향을 받지 않습니다). 줄이 \"- \" (대시, 공백) 또는 \"+ \" (플러스, 공백)으로 시작하면, 규칙 유형이 명시적으로 제외 또는 포함으로 지정된 것입니다. 이러한 접두사가 없는 모든 규칙은 제외로 간주됩니다. 줄이 단지 \"!\"로 구성되면, 추가 규칙을 추가하기 전에 현재 필터 규칙이 지워집니다. FILE이 '-'이면 목록은 표준 입력에서 읽힙니다. --include=PATTERN 이 옵션은 --filter 옵션의 단순화된 형태로, 포함 규칙을 지정하며 일반 필터 규칙의 전체 규칙 파싱 구문을 허용하지 않습니다. 이는 -f'+ PATTERN'을 지정하는 것과 동일합니다. 이 옵션에 대한 자세한 정보는 FILTER RULES 섹션을 참조하십시오. --include-from=FILE 이 옵션은 --include 옵션과 관련이 있지만, 포함 패턴(줄당 하나)이 포함된 FILE을 지정합니다. 파일의 빈 줄은 무시되며, ';' 또는 '#'으로 시작하는 전체 줄 주석도 무시됩니다 (이러한 문자를 포함하는 파일 이름 규칙은 영향을 받지 않습니다). 줄이 \"- \" (대시, 공백) 또는 \"+ \" (플러스, 공백)으로 시작하면, 규칙 유형이 명시적으로 제외 또는 포함으로 지정된 것입니다. 이러한 접두사가 없는 모든 규칙은 포함으로 간주됩니다. 줄이 단지 \"!\"로 구성되면, 추가 규칙을 추가하기 전에 현재 필터 규칙이 지워집니다. FILE이 '-'이면 목록은 표준 입력에서 읽힙니다. --files-from=FILE 이 옵션을 사용하면 전송할 파일의 정확한 목록을 지정할 수 있습니다 (지정된 FILE 또는 표준 입력에서 '-'로 읽음). 또한 rsync의 기본 동작을 조정하여 지정된 파일과 디렉토리만 더 쉽게 전송할 수 있도록 합니다: o --relative (-R) 옵션이 암시됩니다. 이는 파일의 각 항목에 대해 지정된 경로 정보를 보존합니다 (--no-relative 또는 --no-R을 사용하여 끄고 싶다면). o --dirs (-d) 옵션이 암시됩니다. 이는 목록에 지정된 디렉토리를 시끄럽게 건너뛰는 대신 대상에 생성합니다 (--no-dirs 또는 --no-d를 사용하여 끄고 싶다면). o --archive (-a) 옵션의 동작은 --recursive (-r)를 암시하지 않으므로, 원한다면 명시적으로 지정하십시오. o 이러한 부작용은 rsync의 기본 상태를 변경하므로, 명령줄에서 --files-from 옵션의 위치는 다른 옵션이 파싱되는 방식에 영향을 미치지 않습니다 (예: -a는 --files-from 앞이나 뒤에서 동일하게 작동하며, --no-R 및 다른 모든 옵션도 마찬가지입니다). FILE에서 읽은 파일 이름은 모두 소스 디렉토리에 상대적입니다. 선행 슬래시는 제거되며 \"..\" 참조는 소스 디렉토리보다 상위로 이동할 수 없습니다. 예를 들어, 이 명령을 살펴보십시오: rsync -a --files-from=/tmp/foo /usr remote:/backup 만약 /tmp/foo에 \"bin\" (또는 \"/bin\")이라는 문자열이 포함되어 있다면, /usr/bin 디렉토리가 원격 호스트에 /backup/bin으로 생성됩니다. 만약 \"bin/\" (후행 슬래시 주의)이 포함되어 있다면, 디렉토리의 즉각적인 내용도 전송됩니다 (파일에 명시적으로 언급할 필요 없이 -- 이것은 버전 2.6.4부터 시작되었습니다). 두 경우 모두, -r 옵션이 활성화된 경우, 해당 디렉토리의 전체 계층 구조도 전송됩니다 ( -r은 --files-from과 함께 명시적으로 지정되어야 하며, -a에 의해 암시되지 않는다는 점을 명심하십시오. 또한 (기본적으로 활성화된) -r 옵션의 효과는 파일에서 읽은 경로 정보만 복제하는 것이며, 소스-지정 경로(이 경우 /usr)의 복제를 강제하지는 않습니다). 또한, --files-from 파일은 파일 앞에 \"host:\"를 지정하면 로컬 호스트 대신 원격 호스트에서 읽을 수 있습니다 (호스트는 전송의 한쪽 끝과 일치해야 합니다). 간단히, \":\" 접두사만 지정하여 \"전송의 원격 끝을 사용하라\"는 의미로 사용할 수 있습니다. 예를 들어: rsync -a --files-from=:/path/file-list src:/ /tmp/copy 이것은 원격 \"src\" 호스트에 있는 /path/file-list 파일에 지정된 모든 파일을 복사합니다. --iconv 및 --secluded-args 옵션이 지정되고 --files-from 파일 이름이 한 호스트에서 다른 호스트로 전송되는 경우, 파일 이름은 보내는 호스트의 문자셋에서 받는 호스트의 문자셋으로 번역됩니다. 참고: --files-from 입력에서 파일 목록을 정렬하면 rsync의 효율성이 향상됩니다. 인접 항목 간에 공유되는 경로 요소를 다시 방문하는 것을 피할 수 있기 때문입니다. 입력이 정렬되지 않으면 일부 경로 요소(암시된 디렉토리)가 여러 번 스캔될 수 있으며, rsync는 파일 목록 요소로 변환된 후 결국 중복을 제거합니다. --from0, -0 이것은 rsync에게 파일에서 읽는 규칙/파일 이름이 NL, CR 또는 CR+LF가 아닌 널('\\0') 문자로 끝난다고 알려줍니다. 이는 --exclude-from, --include-from, --files-from 및 --filter 규칙에 지정된 모든 병합 파일에 영향을 미칩니다. --cvs-exclude에는 영향을 미치지 않습니다 ( .cvsignore 파일에서 읽은 모든 이름은 공백으로 분할되기 때문입니다). --old-args 이 옵션은 rsync에게 원격 측의 인자 값이 의도치 않은 단어 분할이나 기타 오해로부터 보호하려는 시도를 중단하도록 지시합니다. 또한 클라이언트가 빈 인자를 오류를 생성하는 대신 \".\"으로 처리하도록 허용합니다. 최신 rsync의 기본값은 \"셸-활성\" 문자(공백 포함)가 원격 셸로 전송되는 인자에서 역슬래시로 이스케이프되는 것입니다. 와일드카드 문자 *, ?, [, \u0026 ]는 파일 이름 인자에서는 이스케이프되지 않지만 (여러 파일 이름으로 확장될 수 있도록 허용), --usermap과 같은 옵션 인자에서는 보호됩니다. 파일 이름에서 이전 스타일 인자 분할을 사용하려는 스크립트가 있다면 이 옵션을 한 번 지정하십시오. 원격 셸에 역슬래시 이스케이프에 문제가 있다면 이 옵션을 두 번 지정하십시오. RSYNC_OLD_ARGS 환경 변수를 통해서도 이 설정을 제어할 수 있습니다. 이 변수가 \"1\" 값이라면 rsync는 단일 옵션 설정으로 기본값이 지정됩니다. \"2\" (또는 그 이상) 값이라면 rsync는 반복 옵션 설정으로 기본값이 지정됩니다. \"0\"이라면 기본 이스케이프 동작을 얻게 됩니다. 환경 변수는 항상 수동으로 지정된 긍정 또는 부정 옵션에 의해 재정의됩니다 (부정은 --no-old-args입니다). 이 옵션은 원격 전송자가 요청하지 않은 추가 최상위 항목을 파일 목록에 포함하지 않도록 보장하는 3.2.5에 추가된 추가 안전 점검도 비활성화합니다. 원격 셸이 인자를 해석할 때 어떤 이름을 예상해야 할지 확실히 알 수 없으므로 이 부작용은 필요합니다. 이 옵션은 --secluded-args 옵션과 충돌합니다. --secluded-args, -s 이 옵션은 모든 파일 이름과 대부분의 옵션을 프로토콜을 통해 원격 rsync로 보냅니다 (원격 셸 명령줄이 아님). 이는 원격 셸이 이들을 수정하는 것을 방지합니다. 와일드카드는 셸 대신 rsync에 의해 원격 호스트에서 확장됩니다. 이는 3.2.4에 추가된 인자의 기본 역슬래시 이스케이핑과 유사합니다 (--old-args 참조). 즉, 공백 분할 및 원치 않는 특수 문자 부작용과 같은 것을 방지합니다. 그러나 오래된 rsync 버전(3.0.0 이전)과 호환되지 않고, 안전을 위해 모든 옵션 값을 검사하려는 제한된 셸에 의해 거부될 수 있다는 단점이 있습니다. 이 옵션은 인자의 문자셋이 원격 호스트에 맞게 변환되어야 하는 경우, 원격 셸이 기본 역슬래시 이스케이프 방식과 호환되지 않는 경우, 또는 대부분의 옵션과 인자가 원격 셸의 명령줄을 우회하도록 하려는 다른 이유가 있는 경우에 유용합니다. 이 옵션을 --iconv와 결합하면 원격 측과 관련된 인자는 로컬 문자셋에서 원격 문자셋으로 번역됩니다. 번역은 와일드카드가 확장되기 전에 발생합니다. --files-from 옵션도 참조하십시오. RSYNC_PROTECT_ARGS 환경 변수를 통해서도 이 설정을 제어할 수 있습니다. 이 변수가 0이 아닌 값을 가지면 이 설정은 기본적으로 활성화되고, 그렇지 않으면 기본적으로 비활성화됩니다. 어떤 상태든 이 옵션의 수동으로 지정된 긍정 또는 부정 버전으로 재정의됩니다 (--no-s 및 --no-secluded-args는 부정 버전입니다). 이 환경 변수는 0이 아닌 RSYNC_OLD_ARGS 내보내기로도 재정의됩니다. 이 옵션은 --old-args 옵션과 충돌합니다. 이 옵션은 이전에 --protect-args (3.2.6 이전)라고 불렸으며, 그 이전 이름도 여전히 사용할 수 있습니다 (그러나 -s로 지정하는 것이 항상 가장 쉽고 호환성이 높습니다). --trust-sender 이 옵션은 로컬 클라이언트가 원격 전송자가 생성한 파일 목록에 대해 수행하는 두 가지 추가 유효성 검사(--multi-host-security 섹션에 자세히 설명됨)를 비활성화합니다. 이 옵션은 전송자가 파일 목록에 악의적인 것을 넣지 않을 것이라고 신뢰하는 경우에만 사용해야 합니다 (수정된 rsync, 수정된 셸 또는 유사한 조작을 통해 발생할 수 있습니다). 일반적으로 rsync 클라이언트(버전 3.2.5 기준)는 원격 rsync에서 파일을 가져올 때 두 가지 추가 유효성 검사를 실행합니다: o 전송 상단에 추가 인자 항목이 추가되지 않았는지 확인합니다. o 파일 목록의 항목 중 제외되었어야 할 이름이 없는지 확인합니다 (필터 규칙이 지정된 경우). 다양한 옵션은 유효성 검사와 충돌하는 경우 이러한 확인 중 하나 또는 둘 다를 비활성화할 수 있습니다. 예를 들어: o 디렉토리별 필터 파일을 사용하면 서버만 아는 필터 규칙을 읽으므로 필터 검사가 비활성화됩니다. o --old-args 옵션을 사용하면 전송자가 요청된 인자를 조작할 수 있으므로 인자 검사가 비활성화됩니다. o 서버 측에서 files-from 목록을 읽으면 클라이언트가 인자 목록을 알 수 없으므로 인자 검사가 비활성화됩니다. o --read-batch를 사용하면 배치 파일의 내용이 생성될 때 이미 확인되었으므로 두 검사 모두 비활성화됩니다. 이 옵션은 추가 패턴 일치가 대규모 전송에서 속도를 늦출 때 성능이 낮은 클라이언트 서버에 도움이 될 수 있습니다. 또한 신뢰할 수 있는 전송자로부터의 전송에 대한 검증 로직의 현재 알려지지 않은 버그를 해결하는 데 사용될 수도 있습니다. 이 옵션을 사용할 때는 MULTI-HOST SECURITY 섹션에서 설명된 대로 전용 대상 디렉토리를 지정하는 것이 좋습니다. --copy-as=USER[:GROUP] 이 옵션은 rsync에게 복사 작업에 USER와 (콜론 뒤에 지정된 경우) GROUP을 사용하도록 지시합니다. 이는 rsync를 실행하는 사용자가 사용자 변경 권한을 가지고 있는 경우에만 작동합니다. 그룹이 지정되지 않으면 사용자의 기본 그룹이 사용됩니다. 이 옵션은 루트 권한으로 실행되는 rsync가 실시간 변경이 발생할 수 있는 디렉토리로/로부터 실행될 때 시스템 파일에 대한 루트 수준 읽기 또는 쓰기 작업이 불가능하도록 보장하여 위험을 줄이는 데 도움이 될 수 있습니다. 대신 rsync 전체를 지정된 사용자로 실행할 수도 있지만, 때로는 루트 수준 호스트 액세스 자격 증명을 사용해야 할 때가 있으므로, 이 옵션을 사용하면 원격-셸 또는 데몬 연결이 설정된 후 rsync가 작업의 복사 부분에 대해 루트 권한을 포기할 수 있습니다. 이 옵션은 전송이 로컬인 경우를 제외하고는 전송의 한쪽에만 영향을 미칩니다. 로컬인 경우에는 양쪽에 영향을 미칩니다. 원격 측에 영향을 미치려면 -M--copy-as=joe와 같이 --remote-option을 사용하십시오. 로컬 전송의 경우, lsh (또는 lsh.sh) 지원 파일은 \"localhost:\" 또는 \"lh:\" 호스트-지정을 설정할 필요 없이 원격 셸을 사용하지 않고도 지정할 수 있는 로컬-셸 도우미 스크립트를 제공합니다. 이를 통해 호스트-지정을 사용하는 전송 측에 영향을 미치는 원격 옵션을 지정할 수 있습니다 (호스트 이름 \"lh\"를 사용하면 원격 디렉토리가 사용자의 홈 디렉토리로 재정의되는 것을 피할 수 있습니다). 예를 들어, 다음 rsync는 로컬 파일을 사용자 \"joe\"로 씁니다: sudo rsync -aiv --copy-as=joe host1:backups/joe/ /home/joe/ 이렇게 하면 모든 파일이 사용자 \"joe\"의 소유가 되고, 그룹은 해당 사용자가 사용할 수 있는 그룹으로 제한되며, joe 사용자가 경로를 시기적절하게 악용하여 joe 사용자가 변경 권한이 없는 파일을 변경하는 것이 불가능해집니다. 다음 명령은 \"joe\" 사용자로 \"dest/\" 디렉토리로 로컬 복사를 수행합니다 (PATH에 support/lsh가 설치되어 있다고 가정): sudo rsync -aive lsh -M--copy-as=joe src/ lh:dest/ --temp-dir=DIR, -T 이 옵션은 rsync에게 수신 측에서 전송된 파일의 임시 복사본을 만들 때 DIR을 스크래치 디렉토리로 사용하도록 지시합니다. 기본 동작은 각 임시 파일을 해당 대상 파일과 동일한 디렉토리에 만드는 것입니다. rsync 3.1.1부터 지정된 DIR 내의 임시 파일 이름은 추가 점(.)으로 접두사가 붙지 않습니다 (하지만 여전히 임의의 접미사가 추가됩니다). 이 옵션은 대부분 수신 디스크 파티션에 전송에서 가장 큰 파일의 복사본을 보관할 충분한 여유 공간이 없는 경우에 사용됩니다. 이 경우 (즉, 스크래치 디렉토리가 다른 디스크 파티션에 있는 경우) rsync는 수신된 각 임시 파일의 이름을 해당 대상 파일 위에 덮어쓸 수 없으며, 대신 제자리로 복사해야 합니다. rsync는 파일을 대상 파일 위에 복사하여 이를 수행합니다. 이는 이 복사 중에 대상 파일에 잘린 데이터가 포함됨을 의미합니다. 이러한 방식으로 수행되지 않으면 (대상 파일이 먼저 제거되고, 데이터가 로컬로 대상 디렉토리의 임시 파일로 복사된 다음, 제자리로 이름이 변경되더라도) 이전 파일이 디스크 공간을 계속 차지할 수 있고 (누군가 파일을 열어둔 경우), 따라서 디스크에 새 버전을 동시에 저장할 충분한 공간이 없을 수 있습니다. 디스크 공간 부족 이외의 이유로 이 옵션을 사용하는 경우, --delay-updates 옵션과 결합하는 것을 고려할 수 있습니다. 이 옵션은 복사된 모든 파일이 대상 계층 구조의 하위 디렉토리에 배치되어 전송이 끝날 때까지 기다리도록 보장합니다. 대상 파티션에 도착하는 모든 파일을 복제할 충분한 공간이 없는 경우, rsync에게 디스크 공간에 대해 지나치게 걱정하지 않아도 된다고 알리는 또 다른 방법은 상대 경로와 함께 --partial-dir 옵션을 사용하는 것입니다. 이는 rsync에게 대상 계층의 하위 디렉토리에 단일 파일의 복사본을 저장해도 괜찮다고 알립니다. rsync는 partial-dir을 스테이징 영역으로 사용하여 복사된 파일을 가져온 다음, 거기서부터 제자리로 이름을 변경합니다. (절대 경로와 함께 --partial-dir을 지정하는 것은 이러한 부작용이 없습니다.) --fuzzy, -y 이 옵션은 rsync에게 누락된 대상 파일에 대한 기준 파일을 찾도록 지시합니다. 현재 알고리즘은 대상 파일과 동일한 디렉토리에서 동일한 크기와 수정 시간을 가진 파일 또는 유사한 이름의 파일을 찾습니다. 찾으면 rsync는 퍼지 기준 파일을 사용하여 전송 속도를 높이려고 합니다. 옵션을 반복하면 --compare-dest, --copy-dest 또는 --link-dest를 통해 지정된 일치하는 대체 대상 디렉토리에서도 퍼지 스캔이 수행됩니다. --delete 옵션을 사용하면 잠재적인 퍼지 일치 파일이 제거될 수 있으므로, 이를 방지해야 하는 경우 --delete-after를 사용하거나 일부 파일 이름 제외를 지정하십시오. --compare-dest=DIR 이 옵션은 rsync에게 전송을 수행할 때 (파일이 대상 디렉토리에 없는 경우) 대상 머신의 DIR을 대상 파일을 비교할 추가 계층 구조로 사용하도록 지시합니다. DIR에서 보내는 측의 파일과 동일한 파일이 발견되면, 해당 파일은 대상 디렉토리로 전송되지 않습니다. 이는 이전 백업에서 변경된 파일만으로 구성된 스파스 백업을 생성하는 데 유용합니다. 이 옵션은 일반적으로 비어 있는 (또는 새로 생성된) 디렉토리로 복사할 때 사용됩니다. 버전 2.6.4부터 여러 --compare-dest 디렉토리를 제공할 수 있으며, 이 경우 rsync는 정확한 일치를 찾기 위해 지정된 순서대로 목록을 검색합니다. 속성만 다른 일치 항목이 발견되면 로컬 복사본이 생성되고 속성이 업데이트됩니다. 일치 항목이 발견되지 않으면 전송 속도를 높이기 위해 DIR 중 하나에서 기준 파일이 선택됩니다. DIR이 상대 경로인 경우, 대상 디렉토리에 상대적입니다. --copy-dest 및 --link-dest도 참조하십시오. 참고: 버전 3.1.0부터 rsync는 대상 계층 구조가 비어 있지 않은 경우, 비교-대상 계층 구조 중 하나에서 정확한 일치 항목이 발견되면 파일을 제거합니다 (최종 결과가 새 복사본과 더 가깝게 일치하도록 함). --copy-dest=DIR 이 옵션은 --compare-dest처럼 작동하지만, rsync는 DIR에서 발견된 변경되지 않은 파일을 로컬 복사를 사용하여 대상 디렉토리로 복사합니다. 이는 기존 파일을 손상시키지 않고 새로운 대상으로 전송을 수행한 다음, 모든 파일이 성공적으로 전송되면 즉시 전환(flash-cutover)을 수행하는 데 유용합니다. 여러 --copy-dest 디렉토리를 제공할 수 있으며, rsync는 변경되지 않은 파일을 찾기 위해 지정된 순서대로 목록을 검색합니다. 일치 항목이 발견되지 않으면 전송 속도를 높이기 위해 DIR 중 하나에서 기준 파일이 선택됩니다. DIR이 상대 경로인 경우, 대상 디렉토리에 상대적입니다. --compare-dest 및 --link-dest도 참조하십시오. --link-dest=DIR 이 옵션은 --copy-dest처럼 작동하지만, 변경되지 않은 파일은 DIR에서 대상 디렉토리로 하드 링크됩니다. 파일이 링크되려면 보존된 모든 속성(예: 권한, 경우에 따라 소유권)이 동일해야 합니다. 예: rsync -av --link-dest=$PWD/prior_dir host:src_dir/ new_dir/ 파일이 링크되지 않는다면 속성을 다시 확인하십시오. 또한 rsync의 제어 밖에서 강제되는 속성이 없는지 확인하십시오. 예를 들어, root를 단일 사용자로 압축하는 마운트 옵션이나 일반적인 소유권으로 이동식 드라이브를 마운트하는 경우(OS X의 \"이 볼륨의 소유권 무시\" 옵션과 같은). 버전 2.6.4부터 여러 --link-dest 디렉토리를 제공할 수 있으며, 이 경우 rsync는 정확한 일치를 찾기 위해 지정된 순서대로 목록을 검색합니다 (이러한 디렉토리는 20개로 제한됩니다). 속성만 다른 일치 항목이 발견되면 로컬 복사본이 생성되고 속성이 업데이트됩니다. 일치 항목이 발견되지 않으면 전송 속도를 높이기 위해 DIR 중 하나에서 기준 파일이 선택됩니다. 이 옵션은 비어 있는 대상 계층 구조로 복사할 때 가장 잘 작동합니다. 기존 파일의 속성이 수정될 수 있으며, 이는 하드 링크를 통해 대체 대상 파일에 영향을 미칠 수 있기 때문입니다. 또한, 변경 사항을 항목화하는 것이 다소 복잡해질 수 있습니다. 버전 3.1.0 이전에는 대상 파일이 이미 존재할 때 대체 디렉토리에서 정확한 일치 항목이 발견되지 않았습니다(대상으로 링크되지도 않았습니다). 이 옵션을 --ignore-times와 결합하면 rsync는 어떤 파일도 링크하지 않습니다. 파일을 전송하는 대신 동일한 파일을 함께 링크하는 것을 대체 수단으로만 사용하고, 파일 업데이트 후 추가 검사로는 사용하지 않기 때문입니다. DIR이 상대 경로인 경우, 대상 디렉토리에 상대적입니다. --compare-dest 및 --copy-dest도 참조하십시오. rsync 2.6.1 이전 버전에는 --owner (-o)가 지정되었을 때 (또는 암시되었을 때) 비-슈퍼유저에 대해 --link-dest가 제대로 작동하지 않을 수 있는 버그가 있었습니다. 이 버그를 해결하려면 오래된 rsync로 보낼 때 -o 옵션을 피하거나 (--no-o를 사용하십시오). --compress, -z 이 옵션을 사용하면 rsync는 파일 데이터를 대상 머신으로 보낼 때 압축하여 전송되는 데이터 양을 줄입니다. 이는 느린 연결에서 유용합니다. Rsync는 여러 압축 방법을 지원하며, --compress-choice (--zc) 옵션을 사용하여 선택을 강제하지 않는 한 자동으로 하나를 선택합니다. rsync --version을 실행하여 자신의 버전에 컴파일된 기본 압축 목록을 확인하십시오. 전송의 양쪽이 최소 3.2.0 버전인 경우, rsync는 클라이언트의 선택 목록에 있는 첫 번째 알고리즘 중에서 서버의 선택 목록에도 있는 것을 선택합니다. 공통 압축 선택이 발견되지 않으면 rsync는 오류로 종료됩니다. 원격 rsync가 너무 오래되어 체크섬 협상을 지원하지 않으면, 해당 목록은 \"zlib\"라고 가정됩니다. 기본 순서는 환경 변수 RSYNC_COMPRESS_LIST를 허용되는 압축 이름의 공백으로 구분된 목록으로 설정하여 사용자 정의할 수 있습니다. 문자열에 \"\u0026\" 문자가 포함된 경우 \"클라이언트 문자열 \u0026 서버 문자열\"로 분리되고, 그렇지 않으면 동일한 문자열이 둘 다에 적용됩니다. 문자열(또는 문자열 부분)에 공백이 아닌 문자가 없으면 기본 압축 목록이 사용됩니다. 알려지지 않은 압축 이름은 목록에서 제거되지만, 유효하지 않은 이름만 있는 목록은 협상 실패로 이어집니다. 일부 오래된 rsync 버전은 -z 옵션을 거부하고 -zz 사용을 요구하도록 구성되었습니다. 이는 압축 라이브러리가 기본 zlib 압축 방식과 호환되지 않았기 때문입니다. rsync 서버가 불평하며 -zz를 지정하도록 지시하지 않는 한, 이 이상한 점은 일반적으로 무시해도 됩니다. --compress-choice=STR, --zc=STR 이 옵션은 --compress가 사용될 때 발생하는 압축 알고리즘의 자동 협상을 재정의하는 데 사용할 수 있습니다. \"none\"이 지정되지 않은 한 --compress를 암시하며, \"none\"이 지정되면 --no-compress를 암시합니다. 사용할 수 있는 압축 옵션은 다음과 같습니다: o zstd o lz4 o zlibx o zlib o none rsync --version을 실행하여 자신의 버전에 컴파일된 기본 압축 목록을 확인하십시오 (위 목록과 다를 수 있습니다). --old-compress 또는 --new-compress라는 옵션에 대한 오류가 표시되는 경우, 이는 rsync가 --compress-choice=zlib 또는 --compress-choice=zlibx 옵션을 더 많은 rsync 버전이 이해하는 역방향 호환 방식으로 보내려고 시도하는 것입니다. 이 오류는 서버의 오래된 rsync 버전이 압축 유형을 강제하는 것을 허용하지 않음을 나타냅니다. \"zlibx\" 압축 알고리즘은 압축 스트림에서 일치하는 데이터를 제외한 \"zlib\" 알고리즘입니다 (외부 zlib 구현과 더 호환되도록 시도하기 위함입니다). --compress-level=NUM, --zl=NUM 기본값으로 두는 대신 사용할 압축 수준을 명시적으로 설정합니다 (--compress, -z 참조). 선택된 수준이 적용 중인 압축 알고리즘에 대해 \"압축 안 함\" 수준이 아닌 한 --compress 옵션이 암시됩니다 (예: zlib 압축은 수준 0을 \"해제\"로 처리합니다). 수준 값은 적용되는 체크섬에 따라 다릅니다. rsync는 기본적으로 체크섬 선택을 협상하므로 (원격 rsync가 충분히 최신인 경우), 이 옵션을 --compress-choice (--zc) 옵션과 결합하는 것이 좋습니다. (어떤 선택이 적용되는지 확실하지 않은 경우). 예를 들어: rsync -aiv --zc=zstd --zl=22 host:src/ dest/ zlib 및 zlibx 압축의 경우 유효한 값은 1에서 9까지이며 기본값은 6입니다. --zl=0을 지정하면 압축이 꺼지고, --zl=-1을 지정하면 기본 수준인 6이 선택됩니다. zstd 압축의 경우 유효한 값은 -131072에서 22까지이며 기본값은 3입니다. 0을 지정하면 기본값인 3이 선택됩니다. lz4 압축의 경우 수준이 없으므로 값은 항상 0입니다. 너무 크거나 너무 작은 값을 지정하면 해당 숫자는 유효한 값으로 조용히 제한됩니다. 이를 통해 --zl=999999999와 같이 지정하여 어떤 알고리즘이 선택되든 최대 압축 수준을 얻을 수 있습니다. 적용 중인 압축 수준을 알고 싶다면 --debug=nstr을 지정하여 \"negotiated string\" 결과를 확인하십시오. 이는 \"Client compress: zstd (level 3)\"와 같이 보고됩니다 (적용 중인 체크섬 선택과 함께). --skip-compress=LIST 참고: 현재 어떤 압축 방법도 파일별 압축 변경을 지원하지 않으므로 이 옵션은 효과가 없습니다. 가능한 한 적게 압축될 파일 접미사 목록을 재정의합니다. Rsync는 파일의 접미사에 따라 파일별로 압축 수준을 설정합니다. 압축 알고리즘에 \"해제(off)\" 수준이 있는 경우 해당 파일에 대해서는 압축이 수행되지 않습니다. 스트리밍 수준을 즉시 변경하는 것을 지원하는 다른 알고리즘은 일치하는 파일에 대해 CPU 사용량을 최대한 줄이기 위해 수준이 최소화됩니다. LIST는 슬래시(/)로 구분된 하나 이상의 파일 접미사(점 없이)여야 합니다. 어떤 파일도 건너뛰지 않도록 빈 문자열을 지정할 수 있습니다. 간단한 문자 클래스 일치가 지원됩니다: 각 클래스는 대괄호 안에 문자 목록으로 구성되어야 합니다 (예: \"[:alpha:]\"와 같은 특수 클래스는 지원되지 않으며, '-'는 특수 의미가 없습니다). 별표(*)와 물음표(?) 문자는 특수 의미가 없습니다. 다음은 건너뛸 6개의 접미사를 지정하는 예입니다 (5개 규칙 중 1개가 2개의 접미사와 일치하기 때문입니다): --skip-compress=gz/jpg/mp[34]/7z/bz2 이 rsync 버전의 skip-compress 목록에 있는 기본 파일 접미사는 다음과 같습니다: 3g2 3gp 7z aac ace apk avi bz2 deb dmg ear f4v flac flv gpg gz iso jar jpeg jpg lrz lz lz4 lzma lzo m1a m1v m2a m2ts m2v m4a m4b m4p m4r m4v mka mkv mov mp1 mp2 mp3 mp4 mpa mpeg mpg mpv mts odb odf odg odi odm odp ods odt oga ogg ogm ogv ogx opus otg oth otp ots ott oxt png qt rar rpm rz rzip spx squashfs sxc sxd sxg sxm sxw sz tbz tbz2 tgz tlz ts txz tzo vob war webm webp xz z zip zst 이 목록은 한 가지 상황을 제외하고는 사용자 정의한 --skip-compress 목록으로 대체됩니다. 데몬 rsync로부터의 복사는 건너뛴 접미사를 압축하지 않는 파일 목록에 추가합니다 (그리고 해당 목록은 다른 기본값으로 구성될 수 있습니다). --numeric-ids 이 옵션을 사용하면 rsync는 사용자 및 그룹 이름을 사용하는 대신 숫자 그룹 및 사용자 ID를 전송하고 양쪽에서 매핑합니다. 기본적으로 rsync는 파일에 어떤 소유권을 부여할지 결정하기 위해 사용자 이름과 그룹 이름을 사용합니다. 특수 uid 0 및 특수 그룹 0은 --numeric-ids 옵션이 지정되지 않았더라도 사용자/그룹 이름으로 매핑되지 않습니다. 사용자 또는 그룹이 소스 시스템에 이름이 없거나 대상 시스템에 일치하는 이름이 없으면, 소스 시스템의 숫자 ID가 대신 사용됩니다. chroot 설정이 rsync가 사용자 및 그룹의 이름을 조회하는 능력에 어떻게 영향을 미치는지, 그리고 이에 대해 무엇을 할 수 있는지에 대한 몇 가지 의견은 rsyncd.conf 맨페이지의 use chroot 설정을 참조하십시오. --usermap=STRING, --groupmap=STRING 이 옵션은 수신 측에서 다른 값으로 매핑되어야 하는 사용자 및 그룹을 지정할 수 있도록 합니다. STRING은 쉼표로 구분된 하나 이상의 FROM:TO 값 쌍입니다. 전송자로부터의 일치하는 FROM 값은 수신자로부터의 TO 값으로 대체됩니다. FROM 및 TO 값에 사용자 이름 또는 사용자 ID를 지정할 수 있으며, FROM 값은 와일드카드 문자열일 수도 있습니다. 이것은 전송자의 이름과 일치합니다 (와일드카드는 ID 번호와 일치하지 않지만, 아래에서 '*'가 모든 것을 일치시키는 이유를 참조하십시오). 포함 범위: LOW-HIGH를 통해 ID 번호 범위를 지정할 수도 있습니다. 예를 들어: --usermap=0-99:nobody,wayne:admin,*:normal --groupmap=usr:1,1:usr 목록의 첫 번째 일치 항목이 사용됩니다. 단일 --usermap 옵션을 사용하여 모든 사용자 매핑을 지정하고, 단일 --groupmap 옵션을 사용하여 모든 그룹 매핑을 지정해야 합니다. 사용자 0 및 그룹 0에 대한 보내는 측의 이름은 받는 측으로 전송되지 않으므로, 이 값은 0을 사용하여 일치시키거나, 받는 측에서 사용 중인 이름(일반적으로 \"root\")을 사용해야 합니다. 다른 모든 FROM 이름은 보내는 측에서 사용 중인 이름과 일치합니다. 모든 TO 이름은 받는 측에서 사용 중인 이름과 일치합니다. 보내는 측에 이름이 없는 모든 ID는 일치 목적을 위해 빈 이름을 가진 것으로 처리됩니다. 이를 통해 \"*\" 또는 빈 이름을 사용하여 일치시킬 수 있습니다. 예를 들어: --usermap=:nobody --groupmap=*:nobody --numeric-ids 옵션이 사용될 때, 보내는 측은 어떤 이름도 보내지 않으므로 모든 ID는 빈 이름을 가진 것으로 처리됩니다. 이는 이름 없는 ID를 다른 값으로 매핑하려면 숫자 FROM 값을 지정해야 함을 의미합니다. --usermap 옵션이 작동하려면 수신자는 슈퍼유저로 실행되어야 합니다 (--super 및 --fake-super 옵션도 참조). --groupmap 옵션이 작동하려면 수신자는 해당 그룹을 설정할 권한이 있어야 합니다. rsync 3.2.4부터 --usermap 옵션은 --owner (-o) 옵션을 암시하며, --groupmap 옵션은 --group (-g) 옵션을 암시합니다 (매핑 옵션이 작동하려면 rsync가 해당 옵션을 활성화해야 하므로). 오래된 rsync 클라이언트는 와일드카드 문자에 대한 불만을 피하기 위해 -s를 사용해야 할 수도 있지만, 최신 rsync는 이를 자동으로 처리합니다. --chown=USER:GROUP 이 옵션은 모든 파일이 USER가 소유하고 GROUP에 속하도록 강제합니다. 이는 --usermap 및 --groupmap을 직접 사용하는 것보다 간단한 인터페이스이지만, 내부적으로 해당 옵션을 사용하여 구현되므로 혼합하여 사용할 수 없습니다. USER 또는 GROUP이 비어 있으면 생략된 사용자/그룹에 대한 매핑은 발생하지 않습니다. GROUP이 비어 있으면 후행 콜론을 생략할 수 있지만, USER가 비어 있으면 선행 콜론을 제공해야 합니다. \"--chown=foo:bar\"를 지정하는 것은 \"--usermap=*:foo --groupmap=*:bar\"를 지정하는 것과 정확히 동일하며, 더 쉽습니다 (그리고 동일한 암시된 --owner 및/또는 --group 옵션을 가집니다). 오래된 rsync 클라이언트는 와일드카드 문자에 대한 불만을 피하기 위해 -s를 사용해야 할 수도 있지만, 최신 rsync는 이를 자동으로 처리합니다. --timeout=SECONDS 이 옵션을 사용하면 최대 I/O 타임아웃을 초 단위로 설정할 수 있습니다. 지정된 시간 동안 데이터가 전송되지 않으면 rsync가 종료됩니다. 기본값은 0이며, 이는 타임아웃이 없음을 의미합니다. --contimeout=SECONDS 이 옵션은 rsync가 rsync 데몬에 연결하는 데 성공할 때까지 기다릴 시간을 설정할 수 있도록 합니다. 타임아웃에 도달하면 rsync는 오류로 종료됩니다. --address=ADDRESS 기본적으로 rsync는 rsync 데몬에 연결할 때 와일드카드 주소에 바인딩합니다. --address 옵션을 사용하면 특정 IP 주소(또는 호스트 이름)에 바인딩하도록 지정할 수 있습니다. --address 옵션의 데몬 버전도 참조하십시오. --port=PORT 이것은 기본값 873 대신 사용할 대체 TCP 포트 번호를 지정합니다. 이는 이중 콜론(::) 구문을 사용하여 rsync 데몬에 연결할 때만 필요합니다 (URL 구문에는 URL의 일부로 포트를 지정하는 방법이 있기 때문입니다). --port 옵션의 데몬 버전도 참조하십시오. --sockopts=OPTIONS 이 옵션은 시스템을 최대한 튜닝하는 것을 좋아하는 사람들에게 끝없는 재미를 제공할 수 있습니다. 전송 속도를 높이거나(또는 늦출 수 있는) 모든 종류의 소켓 옵션을 설정할 수 있습니다. 설정할 수 있는 일부 옵션에 대한 자세한 내용은 setsockopt() 시스템 호출 맨페이지를 참조하십시오. 기본적으로 특수 소켓 옵션은 설정되지 않습니다. 이것은 원격 rsync 데몬에 대한 직접 소켓 연결에만 영향을 미칩니다. --sockopts 옵션의 데몬 버전도 참조하십시오. --blocking-io 이것은 rsync에게 원격 셸 전송을 시작할 때 블로킹 I/O를 사용하도록 지시합니다. 원격 셸이 rsh 또는 remsh인 경우, rsync는 기본적으로 블로킹 I/O를 사용하며, 그렇지 않으면 논블로킹 I/O를 사용합니다. (ssh는 논블로킹 I/O를 선호합니다.) --outbuf=MODE 이것은 출력 버퍼링 모드를 설정합니다. 모드는 None (일명 Unbuffered), Line, 또는 Block (일명 Full)이 될 수 있습니다. 모드의 경우 한 글자만 지정할 수 있으며, 대소문자를 구분하지 않습니다. 이 옵션의 주요 용도는 rsync의 출력이 파일이나 파이프로 전달될 때 전체 버퍼링을 라인 버퍼링으로 변경하는 것입니다. --itemize-changes, -i 각 파일에 적용되는 변경 사항, 속성 변경 사항을 포함한 간단한 항목별 목록을 요청합니다. 이것은 --out-format='%i %n%L'을 지정하는 것과 정확히 동일합니다. 옵션을 반복하면 변경되지 않은 파일도 출력되지만, 수신 rsync가 2.6.7 버전 이상인 경우에만 그렇습니다 (이전 rsync 버전에서는 -vv를 사용할 수 있지만, 이는 다른 상세 메시지 출력도 켭니다). \"%i\" 이스케이프는 11글자의 암호 같은 출력을 가집니다. 일반적인 형식은 YXcstpoguax와 같으며, Y는 수행되는 업데이트 유형으로 대체되고, X는 파일 유형으로 대체되며, 다른 글자는 수정될 수 있는 속성을 나타냅니다. Y를 대체하는 업데이트 유형은 다음과 같습니다: o A \u003c는 파일이 원격 호스트로 전송되고 있음을 의미합니다 (보냄). o A \u003e는 파일이 로컬 호스트로 전송되고 있음을 의미합니다 (받음). o A c는 항목에 대한 로컬 변경/생성이 발생하고 있음을 의미합니다 (예: 디렉토리 생성 또는 심볼릭 링크 변경 등). o A h는 항목이 다른 항목에 대한 하드 링크임을 의미합니다 (--hard-links 필요). o A .는 항목이 업데이트되지 않고 있음을 의미합니다 (하지만 속성이 수정될 수 있음). o A *는 항목별 출력 영역의 나머지 부분에 메시지가 포함되어 있음을 의미합니다 (예: \"deleting\"). X를 대체하는 파일 유형은 다음과 같습니다: 파일의 경우 f, 디렉토리의 경우 d, 심볼릭 링크의 경우 L, 장치의 경우 D, 특수 파일(예: 명명된 소켓 및 FIFO)의 경우 S. 문자열의 다른 글자는 파일의 일부 속성이 변경되었는지 여부를 나타내며, 다음과 같습니다: o \".\" - 속성이 변경되지 않았습니다. o \"+\" - 파일이 새로 생성되었습니다. o \" \" - 모든 속성이 변경되지 않았습니다 (모든 점이 공백으로 바뀝니다). o \"?\" - 변경 사항을 알 수 없습니다 (원격 rsync가 오래된 경우). o 문자는 속성이 업데이트되고 있음을 나타냅니다. 각 문자와 관련된 속성은 다음과 같습니다: o c는 일반 파일의 체크섬이 다르거나 (--checksum 필요) 심볼릭 링크, 장치 또는 특수 파일의 값이 변경되었음을 의미합니다. rsync 3.0.1 이전 버전으로 파일을 보내는 경우, 이 변경 플래그는 체크섬이 다른 일반 파일에만 나타납니다. o s는 일반 파일의 크기가 다르며 파일 전송에 의해 업데이트될 것임을 의미합니다. o t는 수정 시간이 다르며 전송자의 값으로 업데이트되고 있음을 의미합니다 (--times 필요). 대체 값 T는 수정 시간이 전송 시간으로 설정됨을 의미합니다. 이는 파일/심볼릭 링크/장치가 --times 없이 업데이트될 때, 그리고 심볼릭 링크가 변경되고 수신자가 시간을 설정할 수 없을 때 발생합니다. (참고: rsync 3.0.0 클라이언트를 사용할 때, 이 시간 설정 실패에 대해 적절한 T 플래그 대신 s 플래그가 t와 결합된 것을 볼 수 있습니다.) o p는 권한이 다르며 전송자의 값으로 업데이트되고 있음을 의미합니다 (--perms 필요). o o는 소유자가 다르며 전송자의 값으로 업데이트되고 있음을 의미합니다 (--owner 및 슈퍼유저 권한 필요). o g는 그룹이 다르며 전송자의 값으로 업데이트되고 있음을 의미합니다 (--group 및 그룹 설정 권한 필요). o o u|n|b는 다음 정보를 나타냅니다: u 접근(사용) 시간이 다르며 전송자의 값으로 업데이트되고 있음을 의미합니다 (--atimes 필요) o n 생성 시간(새로움)이 다르며 전송자의 값으로 업데이트되고 있음을 의미합니다 (--crtimes 필요) o b 접근 시간과 생성 시간 모두 업데이트되고 있음을 의미합니다 o a는 ACL 정보가 변경되고 있음을 의미합니다. o x는 확장 속성 정보가 변경되고 있음을 의미합니다. 또 다른 출력이 가능합니다: 파일을 삭제할 때, \"%i\"는 제거되는 각 항목에 대해 \"*deleting\" 문자열을 출력합니다 (충분히 최신 rsync와 통신하여 삭제를 상세 메시지로 출력하는 대신 로그에 기록하는 경우). --out-format=FORMAT 이것은 rsync 클라이언트가 사용자에게 업데이트별로 정확히 무엇을 출력할지 지정할 수 있도록 합니다. 형식은 퍼센트(%) 문자로 시작하는 내장된 단일 문자 이스케이프 시퀀스를 포함하는 텍스트 문자열입니다. --info=name 또는 -v가 지정되면 \"%n%L\"의 기본 형식이 가정됩니다 (이는 파일 이름과, 항목이 링크인 경우 가리키는 위치만 알려줍니다). 가능한 이스케이프 문자의 전체 목록은 rsyncd.conf 맨페이지의 log format 설정을 참조하십시오. --out-format 옵션을 지정하면 --info=name 옵션이 암시됩니다. 이 옵션은 상당한 방식으로 업데이트되는 각 파일, 디렉토리 등을 언급합니다 (전송된 파일, 재구성된 심볼릭 링크/장치, 또는 터치된 디렉토리). 또한, 항목별 변경 이스케이프(%i)가 문자열에 포함된 경우 (예: --itemize-changes 옵션이 사용된 경우), 이름 로깅은 어떤 식으로든 변경된 모든 항목을 언급하도록 증가합니다 (수신 측이 최소 2.6.4 버전인 한). \"%i\" 출력에 대한 설명은 --itemize-changes 옵션을 참조하십시오. rsync는 파일 전송 전에 out-format 문자열을 출력합니다. 단, 전송 통계 이스케이프 중 하나가 요청된 경우에는 파일 전송이 끝날 때 로깅이 수행됩니다. 이 후반 로깅이 적용되고 --progress도 지정되면, rsync는 진행 정보 앞에 전송 중인 파일의 이름도 출력합니다 (물론 out-format 출력 뒤에). --log-file=FILE 이 옵션은 rsync가 수행하는 작업을 파일에 기록하도록 합니다. 이는 데몬이 수행하는 로깅과 유사하지만, 클라이언트 측 및/또는 비데몬 전송의 서버 측에 대해 요청할 수 있습니다. 클라이언트 옵션으로 지정하면, 기본 형식인 \"%i %n%L\"로 전송 로깅이 활성화됩니다. 이를 재정의하려면 --log-file-format 옵션을 참조하십시오. 다음은 원격 측에서 발생하는 일을 기록하도록 요청하는 명령의 예시입니다: rsync -av --remote-option=--log-file=/tmp/rlog src/ dest/ 연결이 예기치 않게 종료되는 이유를 디버깅해야 할 때 매우 유용합니다. --log-file 옵션의 데몬 버전도 참조하십시오. --log-file-format=FORMAT 이것은 --log-file 옵션으로 지정된 파일에 어떤 업데이트별 로깅이 기록될지 정확히 지정할 수 있도록 합니다 (--log-file 옵션도 이 옵션이 효과를 가지려면 지정되어야 합니다). 빈 문자열을 지정하면 업데이트된 파일은 로그 파일에 언급되지 않습니다. 가능한 이스케이프 문자의 목록은 rsyncd.conf 맨페이지의 log format 설정을 참조하십시오. --log-file이 지정되고 이 옵션이 지정되지 않은 경우 사용되는 기본 FORMAT은 '%i %n%L'입니다. --log-file-format 옵션의 데몬 버전도 참조하십시오. --stats 이것은 rsync에게 파일 전송에 대한 자세한 통계 집합을 출력하도록 지시하여, 데이터에 대한 rsync의 델타-전송 알고리즘이 얼마나 효과적인지 알 수 있도록 합니다. 이 옵션은 0 또는 1개의 -v 옵션과 결합하면 --info=stats2와 동일하며, 2개 이상의 -v 옵션과 결합하면 --info=stats3와 동일합니다. 현재 통계는 다음과 같습니다: o Number of files (파일 수)는 디렉토리, 심볼릭 링크 등을 포함한 모든 \"파일\"(일반적인 의미에서)의 개수입니다. 총 개수 뒤에는 파일 유형별 개수 목록이 표시됩니다 (총 개수가 0이 아닌 경우). 예: \"(reg: 5, dir: 3, link: 2, dev: 1, special: 1)\"는 일반 파일, 디렉토리, 심볼릭 링크, 장치 및 특수 파일의 총 개수를 나열합니다. 값이 0인 경우 목록에서 완전히 생략됩니다. o Number of created files (생성된 파일 수)는 생성된 (업데이트된 것과 반대되는) \"파일\"(일반적인 의미에서)의 개수입니다. 총 개수 뒤에는 파일 유형별 개수 목록이 표시됩니다 (총 개수가 0이 아닌 경우). o Number of deleted files (삭제된 파일 수)는 삭제된 \"파일\"(일반적인 의미에서)의 개수입니다. 총 개수 뒤에는 파일 유형별 개수 목록이 표시됩니다 (총 개수가 0이 아닌 경우). 이 줄은 삭제가 적용 중일 때만 출력되며, 프로토콜 31이 사용 중일 때만 출력됩니다 (rsync 3.1.x의 기본값). o Number of regular files transferred (전송된 일반 파일 수)는 rsync의 델타-전송 알고리즘을 통해 업데이트된 일반 파일의 개수입니다. 이는 디렉토리, 심볼릭 링크 등을 포함하지 않습니다. rsync 3.1.0부터 이 제목에 \"regular\"라는 단어가 추가되었습니다. o Total file size (총 파일 크기)는 전송에서 모든 파일 크기의 총합입니다. 이는 디렉토리나 특수 파일의 크기는 계산하지 않지만, 심볼릭 링크의 크기는 포함합니다. o Total transferred file size (총 전송 파일 크기)는 전송된 파일만의 모든 파일 크기의 총합입니다. o Literal data (리터럴 데이터)는 업데이트된 파일을 재구성하기 위해 수신자에게 보내야 했던 일치하지 않는 파일 업데이트 데이터의 양입니다. o Matched data (일치하는 데이터)는 업데이트된 파일을 재구성할 때 수신자가 로컬에서 얻은 데이터의 양입니다. o File list size (파일 목록 크기)는 전송자가 수신자에게 보낼 때 파일 목록 데이터의 크기였습니다. 이는 rsync가 목록을 보낼 때 중복 데이터를 압축하기 때문에 파일 목록의 메모리 내 크기보다 작습니다. o File list generation time (파일 목록 생성 시간)은 전송자가 파일 목록을 생성하는 데 소요된 시간(초)입니다. 이것이 존재하려면 보내는 측에 최신 rsync가 필요합니다. o File list transfer time (파일 목록 전송 시간)은 전송자가 수신자에게 파일 목록을 보내는 데 소요된 시간(초)입니다. o Total bytes sent (총 보낸 바이트)는 rsync가 클라이언트 측에서 서버 측으로 보낸 모든 바이트의 개수입니다. o Total bytes received (총 받은 바이트)는 rsync가 클라이언트 측에서 서버 측으로부터 수신한 비메시지 바이트의 총 개수입니다. \"비메시지\" 바이트는 서버가 우리에게 보낸 상세 메시지의 바이트를 계산하지 않는다는 의미이며, 이는 통계를 더 일관성 있게 만듭니다. --8-bit-output, -8 이것은 rsync에게 모든 높은 비트 문자를 현재 로케일에서 유효한지 테스트하고 유효하지 않은 문자를 이스케이프하려고 시도하는 대신, 출력에서 이스케이프되지 않은 채로 두도록 지시합니다. 이 옵션 설정과 관계없이 모든 제어 문자(탭은 제외)는 항상 이스케이프됩니다. 2.6.7부터 시작된 이스케이프 관용구는 리터럴 역슬래시(\\)와 해시(#)를 출력한 다음 정확히 3개의 8진수 숫자를 출력하는 것입니다. 예를 들어, 새 줄은 \"\\#012\"로 출력됩니다. 파일 이름에 있는 리터럴 역슬래시는 해시와 3개의 숫자(0-9)가 뒤따르지 않는 한 이스케이프되지 않습니다. --human-readable, -h 숫자를 사람이 읽기 쉬운 형식으로 출력합니다. 가능한 수준은 3가지입니다: 1. 세 자리마다 구분 기호(소수점이 마침표 또는 쉼표로 표시되는지에 따라 쉼표 또는 마침표)를 사용하여 숫자를 출력합니다. 2. 1000 단위로 숫자를 출력합니다 (더 큰 단위에는 문자 접미사 사용 -- 아래 참조). 3. 1024 단위로 숫자를 출력합니다. 기본값은 사람이 읽기 쉬운 수준 1입니다. 각 -h 옵션은 수준을 1씩 증가시킵니다. --no-human-readable (--no-h) 옵션을 지정하여 수준을 0으로 낮출 수 있습니다 (순수 숫자로 출력). 수준 2와 3에서 추가되는 단위 문자는 다음과 같습니다: K (킬로), M (메가), G (기가), T (테라), P (페타). 예를 들어, 1234567바이트 파일은 수준 2에서 1.23M으로 출력됩니다 (마침표가 로컬 소수점이라고 가정). 하위 호환성 참고: rsync 3.1.0 이전 버전은 사람이 읽기 쉬운 수준 1을 지원하지 않으며, 기본적으로 수준 0을 사용합니다. 따라서 하나 또는 두 개의 -h 옵션을 지정하는 것은 하나 이상의 -h 옵션 이전에 --no-h 옵션을 지정하지 않는 한 이전 및 새 버전에서 유사한 방식으로 작동합니다. 한 가지 차이점에 대해서는 --list-only 옵션을 참조하십시오. --partial 기본적으로 rsync는 전송이 중단되면 부분적으로 전송된 파일을 삭제합니다. 어떤 경우에는 부분적으로 전송된 파일을 유지하는 것이 더 바람직합니다. --partial 옵션을 사용하면 rsync는 부분 파일을 유지하도록 지시하여 후속 파일 전송을 훨씬 빠르게 할 수 있습니다. --partial-dir=DIR 이 옵션은 --partial 옵션의 동작을 수정하는 동시에 이 옵션이 활성화되도록 암시합니다. 이 향상된 부분 파일 방식은 부분적으로 전송된 모든 파일을 대상 파일로 직접 쓰는 대신 지정된 DIR에 저장합니다. 다음 전송 시 rsync는 이 디렉토리에서 발견된 파일을 데이터로 사용하여 전송 재개 속도를 높이고, 역할을 다하면 삭제합니다. --whole-file이 지정되었거나 (또는 암시되었을 때), 업데이트되는 파일에 대해 발견된 partial-dir 파일은 단순히 제거됩니다 (rsync는 rsync의 델타-전송 알고리즘을 사용하지 않고 파일을 보내기 때문입니다). Rsync는 DIR이 누락된 경우 생성하지만, 마지막 디렉토리만 생성하며 전체 경로는 생성하지 않습니다. 이는 상대 경로(예: \"--partial-dir=.rsync-partial\")를 사용하여 rsync가 필요할 때 대상 파일의 디렉토리에 부분 디렉토리를 생성한 다음, 부분 파일이 삭제될 때 다시 제거하도록 하는 것을 쉽게 만듭니다. 이 디렉토리 제거는 상대 경로에 대해서만 수행됩니다. 절대 경로는 partial-dir 작업 전용 디렉토리로 예상되기 때문입니다. partial-dir 값이 절대 경로가 아닌 경우, rsync는 기존 모든 제외 규칙 끝에 제외 규칙을 추가합니다. 이것은 보내는 측에 존재할 수 있는 partial-dir 파일 전송을 방지하고, 수신 측에서 partial-dir 항목이 시기적절하게 삭제되는 것을 방지합니다. 예: 위 --partial-dir 옵션은 다른 필터 규칙 끝에 이와 동등한 \"소멸성\" 제외 규칙을 추가합니다: -f '-p .rsync-partial/' 자신만의 제외 규칙을 제공하는 경우, 다음 이유로 인해 partial-dir에 대한 자신만의 제외/숨김/보호 규칙을 추가해야 할 수도 있습니다: 4. 자동 추가된 규칙이 다른 규칙의 끝에서는 효과적이지 않을 수 있거나, 5. rsync의 제외 선택을 재정의하고 싶을 수 있기 때문입니다. 예를 들어, rsync가 남아 있는 partial-dir을 정리하도록 하려면 --delete-after를 지정하고 \"위험\" 필터 규칙을 추가해야 합니다. 예: -f 'R .rsync-partial/'. --delete-before 또는 --delete-during 사용은 현재 실행 중에 rsync가 남아 있는 partial-dir 데이터를 사용할 필요가 없는 경우가 아니면 피하십시오. 중요: --partial-dir은 다른 사용자가 쓸 수 없어야 합니다. 그렇지 않으면 보안 위험이 있습니다! 예: \"/tmp\"는 피하십시오! RSYNC_PARTIAL_DIR 환경 변수에 partial-dir 값을 설정할 수도 있습니다. 환경에 이것을 설정하는 것은 부분 전송이 활성화되도록 강제하지 않지만, --partial이 지정되었을 때 부분 파일이 어디로 가는지에 영향을 미칩니다. 예를 들어, --progress와 함께 --partial-dir=.rsync-tmp를 사용하는 대신, 환경에 RSYNC_PARTIAL_DIR=.rsync-tmp를 설정하고 -P 옵션을 사용하여 부분 전송에 .rsync-tmp 디렉토리 사용을 켤 수 있습니다. --partial 옵션이 이 환경 값을 찾지 않는 유일한 경우는 다음과 같습니다: 6. --inplace가 지정되었을 때 (--inplace는 --partial-dir과 충돌하므로), 그리고 7. --delay-updates가 지정되었을 때 (아래 참조). 최신 rsync가 partial-dir의 파일 전송을 재개할 때, 해당 부분 파일은 이제 또 다른 임시 파일 복사본을 만드는 대신 제자리에서 업데이트됩니다 (따라서 dest + partial + tmp 대신 dest + tmp에서 최대화됩니다). 이는 전송의 양쪽 끝이 최소 버전 3.2.0이어야 합니다. 데몬-구성의 \"refuse options\" 설정 목적상, --partial-dir은 --partial을 암시하지 않습니다. 이는 --partial 옵션의 거부가 부분 전송으로 대상 파일을 덮어쓰는 것을 허용하지 않으면서도 --partial-dir이 제공하는 더 안전한 관용구를 허용할 수 있도록 하기 위함입니다. --delay-updates 이 옵션은 각 업데이트된 파일의 임시 파일을 전송이 끝날 때까지 보류 디렉토리에 넣은 다음, 모든 파일의 이름이 순식간에 제자리로 변경되도록 합니다. 이는 파일 업데이트를 좀 더 원자적으로 만들기 위한 시도입니다. 기본적으로 파일은 각 파일의 대상 디렉토리 내에 .~tmp~라는 디렉토리에 배치되지만, --partial-dir 옵션을 지정한 경우 해당 디렉토리가 대신 사용됩니다. .~tmp~ 디렉토리가 전송에서 제외되는 방법과 rsync가 남아 있을 수 있는 오래된 .~tmp~ 디렉토리를 정리하도록 하려면 --partial-dir 섹션의 설명을 참조하십시오. --inplace 및 --append와 충돌합니다. 이 옵션은 끝에서 반복할 수 있도록 전체 파일 목록이 메모리에 있어야 하므로 --no-inc-recursive를 암시합니다. 이 옵션은 수신 측에서 더 많은 메모리(전송된 파일당 1비트)를 사용하며, 업데이트된 모든 파일의 추가 복사본을 저장할 수 있는 충분한 여유 디스크 공간이 수신 측에 필요합니다. 또한 --partial-dir에 절대 경로를 사용해서는 안 됩니다. 다음 경우를 제외하고는: 8. 전송되는 파일 중 이름이 같은 파일이 있을 가능성이 전혀 없을 때 (경로가 절대 경로인 경우 모든 업데이트된 파일이 단일 디렉토리에 배치되므로), 그리고 9. 계층 구조에 마운트 지점이 없을 때 (지연된 업데이트가 제자리로 이름이 변경되지 않으면 실패하므로). \"atomic-rsync\" python 스크립트도 \"support\" 하위 디렉토리에 있습니다. 이 스크립트는 훨씬 더 원자적인 업데이트 알고리즘을 사용합니다 (--link-dest 및 파일의 병렬 계층 구조 사용). --prune-empty-dirs, -m 이 옵션은 수신 rsync에게 파일 목록에서 빈 디렉토리, 비디렉토리 자식이 없는 중첩된 디렉토리를 포함하여 제거하도록 지시합니다. 이는 보내는 rsync가 포함/제외/필터 규칙을 사용하여 파일 계층 구조를 재귀적으로 스캔할 때 쓸모없는 디렉토리가 많이 생성되는 것을 방지하는 데 유용합니다. 이 옵션은 TRANSFER_RULES를 사용하는 경우 수신 측에 빈 디렉토리를 남길 수도 있습니다. 파일 목록이 실제로 정리되고 있기 때문에 이 옵션은 삭제가 활성화되었을 때 어떤 디렉토리가 삭제될지에도 영향을 미칩니다. 그러나 제외된 파일 및 디렉토리가 소스 파일을 숨기고 대상 파일을 보호하는 두 가지 이유로 기존 항목이 삭제되는 것을 방지할 수 있다는 점을 명심하십시오. 이를 피하는 방법에 대해서는 소멸성 필터 규칙 옵션을 참조하십시오. 글로벌 \"보호\" 필터를 사용하여 파일 목록에서 특정 빈 디렉토리가 정리되는 것을 방지할 수 있습니다. 예를 들어, 이 옵션은 \"emptydir\" 디렉토리가 파일 목록에 유지되도록 보장합니다: --filter 'protect emptydir/' 다음은 계층 구조에 있는 모든 .pdf 파일을 복사하고, .pdf 파일을 보관하는 데 필요한 대상 디렉토리만 생성하며, 대상의 불필요한 파일 및 디렉토리가 제거되도록 하는 예시입니다 (비디렉토리를 숨기는 필터가 제외 대신 사용됨을 주의하십시오): rsync -avm --del --include='*.pdf' -f 'hide,! */' src/ dest 불필요한 대상 파일을 제거하고 싶지 않다면, --include='*/' --exclude='*'라는 더 오래된 옵션이 hide-filter 대신 잘 작동할 것입니다 (더 자연스럽게 느껴진다면). --progress 이 옵션은 rsync에게 전송 진행 상황을 보여주는 정보를 출력하도록 지시합니다. 이는 지루한 사용자에게 볼거리를 제공합니다. 최신 rsync에서는 --info=flist2,name,progress를 지정하는 것과 동일하지만, 해당 정보 플래그에 대한 사용자 제공 설정이 우선합니다 (예: --info=flist0 --progress). rsync가 일반 파일을 전송하는 동안, 다음과 같은 진행 상황 줄을 업데이트합니다: 782448 63% 110.64kB/s 0:00:04 이 예시에서 수신자는 보내는 측 파일의 782448바이트 또는 63%를 재구성했으며, 초당 110.64킬로바이트의 속도로 재구성되고 있으며, 현재 속도가 유지되면 4초 후에 전송이 완료될 것입니다. rsync의 델타-전송 알고리즘이 사용 중인 경우 이러한 통계는 오해의 소지가 있을 수 있습니다. 예를 들어, 보내는 측 파일이 기준 파일과 추가 데이터로 구성된 경우, 수신자가 리터럴 데이터에 도달하면 보고된 속도가 극적으로 떨어질 수 있으며, 파일의 일치하는 부분을 완료할 때 수신자가 예상한 것보다 전송 완료 시간이 훨씬 오래 걸릴 수 있습니다. 파일 전송이 완료되면 rsync는 진행 상황 줄을 다음과 같은 요약 줄로 바꿉니다: 1,238,099 100% 146.38kB/s 0:00:08 (xfr#5, to-chk=169/396) 이 예시에서 파일의 총 길이는 1,238,099바이트였고, 전체 파일의 평균 전송 속도는 완료하는 데 걸린 8초 동안 초당 146.38킬로바이트였습니다. 이것은 현재 rsync 세션 동안 일반 파일의 5번째 전송이었고, 파일 목록의 총 396개 파일 중 수신자가 확인해야 할 파일은 169개 남아 있습니다 (최신 상태인지 여부를 확인하기 위해). 증분 재귀 스캔에서 rsync는 스캔이 끝날 때까지 파일 목록의 총 파일 수를 알지 못하지만, 스캔 중에 파일을 전송하기 시작하므로 목록의 전체 크기를 알 때까지 \"to-chk\" 대신 \"ir-chk\"(증분 재귀 확인) 텍스트가 포함된 줄을 표시합니다. 따라서 \"ir-chk\"를 보면 파일 목록의 총 파일 수가 계속 증가할 것임을 알 수 있습니다 (그리고 그럴 때마다 확인해야 할 파일 수는 목록에 추가된 파일 수만큼 증가합니다). -P -P 옵션은 \"--partial --progress\"와 동일합니다. 그 목적은 중단될 수 있는 긴 전송에 대해 이 두 옵션을 지정하는 것을 훨씬 쉽게 만드는 것입니다. 전체 전송을 기반으로 통계를 출력하는 --info=progress2 옵션도 있습니다. 파일 이름 없이 이 플래그를 사용하십시오 (예: -v를 피하거나 --info=name0을 지정하십시오). 화면을 많은 이름으로 스크롤하지 않고 전송이 어떻게 진행되고 있는지 보고 싶다면. (--info=progress2를 사용하기 위해 --progress 옵션을 지정할 필요는 없습니다.) 마지막으로, SIGINFO 또는 SIGVTALRM 신호를 rsync에 보내면 즉시 진행 보고서를 받을 수 있습니다. BSD 시스템에서는 Ctrl+T를 입력하여 SIGINFO가 생성됩니다 (Linux는 현재 SIGINFO 신호를 지원하지 않습니다). 클라이언트 측 프로세스가 이러한 신호 중 하나를 받으면 단일 진행 보고서를 출력하기 위한 플래그를 설정하고, 현재 파일 전송이 완료될 때 출력됩니다 (따라서 신호가 도착할 때 큰 파일이 처리 중이면 약간의 시간이 걸릴 수 있습니다). 파일 이름이 출력된 후 (필요한 경우) --info=progress2 형식의 진행 정보가 출력됩니다. 3개의 rsync 프로세스 중 어느 것이 클라이언트 프로세스인지 모르는 경우, 모든 프로세스에 신호를 보내도 괜찮습니다 (비클라이언트 프로세스는 신호를 무시합니다). 주의: 오래된 rsync (3.2.0 이전)에 SIGVTALRM을 보내면 종료됩니다. --password-file=FILE 이 옵션을 사용하면 파일 또는 표준 입력(-)을 통해 rsync 데몬에 액세스할 때 암호를 제공할 수 있습니다. 파일은 첫 줄에 암호만 포함해야 합니다 (다른 모든 줄은 무시됩니다). FILE이 전 세계적으로 읽을 수 있거나 root로 실행되는 rsync 명령이 root 소유가 아닌 파일을 발견하면 rsync는 오류와 함께 종료됩니다. 이 옵션은 ssh와 같은 원격 셸 전송에 암호를 제공하지 않습니다. 이를 수행하는 방법은 원격 셸의 설명서를 참조하십시오. 원격 셸을 전송으로 사용하여 rsync 데몬에 액세스할 때, 이 옵션은 원격 셸이 인증을 마친 후에만 적용됩니다 (즉, 데몬의 구성 파일에도 암호를 지정한 경우). --early-input=FILE 이 옵션을 사용하면 rsync가 \"early exec\" 스크립트의 표준 입력으로 최대 5K의 데이터를 보낼 수 있습니다. 이 데이터의 한 가지 가능한 용도는 스크립트에 암호화된 파일 시스템을 마운트하는 데 사용할 수 있는 비밀을 제공하는 것입니다 (\"post-xfer exec\" 스크립트에서 마운트 해제해야 합니다). 데몬은 최소 3.2.1 버전이어야 합니다. --list-only 이 옵션은 소스 파일이 전송되는 대신 나열되도록 합니다. 이 옵션은 단일 소스 인자가 있고 대상이 지정되지 않은 경우 추론되므로, 주요 용도는 다음과 같습니다: 10. 대상 인자를 포함하는 복사 명령을 파일 목록 명령으로 전환하거나, 11. 두 개 이상의 소스 인자를 지정할 수 있도록 합니다. 참고: 대상을 반드시 포함하십시오. 주의: 와일드카드가 있는 소스 인자는 셸에 의해 여러 인자로 확장되므로, 이 옵션을 추론하기 위해 단일 와일드카드 인자를 지정하는 것은 안전하지 않습니다. 안전한 예시는 다음과 같습니다: rsync -av --list-only foo* dest/ 이 옵션은 항상 다음과 유사한 출력 형식을 사용합니다: drwxrwxr-x 4,096 2022/09/30 12:53:11 support -rw-rw-r-- 80 2005/01/11 10:37:37 support/Makefile 이 출력 스타일에 영향을 미치는 유일한 옵션은 (3.1.0 기준) --human-readable (-h) 옵션입니다. 기본값은 숫자 구분 기호가 있는 바이트 수(14자 너비 열)로 크기를 출력하는 것입니다. 하나 이상의 -h 옵션을 지정하면 크기가 단위 접미사와 함께 출력됩니다. 숫자 구분 기호가 없는 이전 스타일 바이트 수 크기(11자 너비 열)를 원하면 --no-h를 사용하십시오. 호환성 참고: rsync 2.6.3 이하 버전에서 원격 파일 목록을 요청할 때 비재귀적 목록을 요청하면 오류가 발생할 수 있습니다. 이는 파일 목록이 --recursive 없이 --dirs 옵션을 암시하고, 오래된 rsync에는 해당 옵션이 없기 때문입니다. 이 문제를 피하려면 --no-dirs 옵션을 지정하거나 (디렉토리 내용을 확장할 필요가 없는 경우), 재귀를 켜고 하위 디렉토리 내용을 제외하십시오: -r --exclude='/*/*'. --bwlimit=RATE 이 옵션은 소켓을 통해 전송되는 데이터의 최대 전송 속도를 초당 단위로 지정할 수 있도록 합니다. RATE 값 뒤에는 크기 승수를 나타내는 문자열을 붙일 수 있으며, 분수 값일 수도 있습니다 (예: --bwlimit=1.5m). 접미사가 지정되지 않으면 값은 1024바이트 단위로 가정됩니다 (마치 \"K\" 또는 \"KiB\"가 추가된 것처럼). 사용 가능한 모든 접미사에 대한 설명은 --max-size 옵션을 참조하십시오. 0 값은 제한 없음을 지정합니다. 하위 호환성을 위해 속도 제한은 가장 가까운 KiB 단위로 반올림되므로, 초당 1024바이트보다 작은 속도는 불가능합니다. Rsync는 소켓을 통해 데이터를 블록 단위로 기록하며, 이 옵션은 rsync가 쓰는 블록의 크기를 제한하고 요청된 제한에서 평균 전송 속도를 유지하려고 합니다. rsync가 데이터 블록을 쓰고 평균 속도를 준수하기 위해 잠시 대기하는 경우 일부 버스티니스(burstiness)가 나타날 수 있습니다. 내부적인 데이터 버퍼링으로 인해 --progress 옵션은 데이터 전송 속도를 정확하게 반영하지 못할 수 있습니다. 일부 파일은 데이터가 빠르게 버퍼링될 때 빠르게 전송되는 것처럼 보일 수 있고, 다른 파일은 출력 버퍼 플러싱이 발생할 때 매우 느리게 전송되는 것처럼 보일 수 있기 때문입니다. 이것은 향후 버전에서 수정될 수 있습니다. --bwlimit 옵션의 데몬 버전도 참조하십시오. --stop-after=MINS, (--time-limit=MINS) 이 옵션은 rsync에게 지정된 시간이 경과하면 복사를 중지하도록 지시합니다. 최대한의 유연성을 위해 rsync는 이 옵션을 원격 rsync에 통신하지 않습니다. 연결의 한쪽이 지정된 대로 종료하는 것으로 충분하기 때문입니다. 이를 통해 연결의 한쪽만 이 옵션을 지원하는 경우에도 사용할 수 있습니다. 필요하다면 --remote-option (-M)을 사용하여 원격 측에 시간 제한을 알릴 수 있습니다. --time-limit 버전의 이 옵션은 더 이상 사용되지 않습니다. --stop-at=y-m-dTh:m 이 옵션은 rsync에게 지정된 시간에 복사를 중지하도록 지시합니다. 날짜 및 시간은 로컬 시간대에서 연-월-일Th시:분 (예: 2000-12-31T23:59)의 숫자 형식으로 완전히 지정할 수 있습니다. 날짜 숫자를 대시 대신 슬래시로 구분해도 됩니다. 값은 또한 2자리 연도를 지정하거나 다양한 값을 생략하는 등 여러 가지 방식으로 축약될 수 있습니다. 모든 경우에 이 값은 제공된 정보와 일치하는 다음 가능한 시간 지점으로 간주됩니다. 값이 현재 시간 또는 과거 시간을 지정하면 rsync는 오류와 함께 종료됩니다. 예를 들어, \"1-30\"은 다음 1월 30일 (로컬 자정)을 지정하고, \"14:00\"은 다음 오후 2시를 지정하며, \"1\"은 다음 달 1일 자정을 지정하고, \"31\"은 다음 달 중 31일에 멈출 수 있는 다음 달을 지정하며, \":59\"는 시간당 다음 59분을 지정합니다. 최대한의 유연성을 위해 rsync는 이 옵션을 원격 rsync에 통신하지 않습니다. 연결의 한쪽이 지정된 대로 종료하는 것으로 충분하기 때문입니다. 이를 통해 연결의 한쪽만 이 옵션을 지원하는 경우에도 사용할 수 있습니다. 필요하다면 --remote-option (-M)을 사용하여 원격 측에 시간 제한을 알릴 수 있습니다. 원격 호스트가 로컬 호스트와 다른 기본 시간대를 가질 수 있다는 점을 명심하십시오. --fsync 수신 측에서 각 완료된 파일을 fsync하도록 합니다. 이는 전송 속도를 늦출 수 있지만, 중요한 파일을 업데이트할 때 안심할 수 있도록 도움이 됩니다. --write-batch=FILE 나중에 --read-batch로 다른 동일한 대상에 적용할 수 있는 파일을 기록합니다. 자세한 내용은 \"BATCH MODE\" 섹션을 참조하고, --only-write-batch 옵션도 참조하십시오. 이 옵션은 협상된 체크섬 및 압축 목록을 재정의하며 항상 구식 md5/md4/zlib 선택을 기반으로 선택을 협상합니다. 더 현대적인 선택을 원한다면 --checksum-choice (--cc) 및/또는 --compress-choice (--zc) 옵션을 사용하십시오. --only-write-batch=FILE --write-batch처럼 작동하지만, 배치를 생성할 때 대상 시스템에 업데이트를 수행하지 않습니다. 이를 통해 다른 수단을 통해 변경 사항을 대상 시스템으로 전송한 다음, --read-batch를 통해 변경 사항을 적용할 수 있습니다. 배치 파일을 휴대용 미디어에 직접 쓰는 것이 자유롭다는 점에 유의하십시오. 만약 이 미디어가 전송이 끝나기 전에 용량을 채우면, 해당 부분 전송을 대상에 적용하고 전체 프로세스를 반복하여 나머지 변경 사항을 얻을 수 있습니다 (다중 업데이트 주기가 진행되는 동안 부분적으로 업데이트된 대상 시스템이 있어도 괜찮다면). 또한 원격 시스템에 변경 사항을 푸시할 때만 대역폭을 절약할 수 있습니다. 이는 배치된 데이터를 보내는 측에서 배치 파일로 전환하여 수신자에게 유선을 통해 흐르도록 할 필요 없이 만들 수 있기 때문입니다 (가져올 때, 보내는 측이 원격에 있으므로 배치를 쓸 수 없습니다). --read-batch=FILE FILE에 저장된 모든 변경 사항을 적용합니다. FILE은 이전에 --write-batch에 의해 생성된 파일입니다. FILE이 '-'이면 배치 데이터는 표준 입력에서 읽힙니다. 자세한 내용은 \"BATCH MODE\" 섹션을 참조하십시오. --protocol=NUM 이전 프로토콜 버전을 강제로 사용합니다. 이는 이전 버전의 rsync와 호환되는 배치 파일을 생성하는 데 유용합니다. 예를 들어, rsync 2.6.4가 --write-batch 옵션과 함께 사용되지만, rsync 2.6.3이 --read-batch 옵션을 실행하는 데 사용될 예정이라면, 배치 파일 생성 시 \"--protocol=28\"을 사용하여 배치 파일에서 이전 프로토콜 버전이 사용되도록 강제해야 합니다 (읽기 시스템의 rsync를 업그레이드할 수 없다고 가정할 때). --iconv=CONVERT_SPEC Rsync는 이 옵션을 사용하여 문자셋 간에 파일 이름을 변환할 수 있습니다. CONVERT_SPEC으로 \".\"을 사용하면 rsync에게 로케일 설정을 통해 기본 문자셋을 찾도록 지시합니다. 또는 --iconv=LOCAL,REMOTE와 같이 쉼표로 구분된 로컬 및 원격 문자셋을 순서대로 지정하여 변환할 내용을 완전히 지정할 수 있습니다. 예를 들어 --iconv=utf8,iso88591. 이 순서는 파일을 푸시하든 풀링하든 옵션이 동일하게 유지되도록 보장합니다. 마지막으로, --no-iconv 또는 CONVERT_SPEC으로 \"-\"를 지정하여 모든 변환을 끌 수 있습니다. 이 옵션의 기본 설정은 사이트별로 다르며, RSYNC_ICONV 환경 변수를 통해서도 영향을 받을 수 있습니다. 로컬 iconv 라이브러리가 지원하는 문자셋 이름 목록을 보려면 \"iconv --list\"를 실행하십시오. --secluded-args (-s) 옵션을 지정하면 rsync는 명령줄에 지정된 파일 이름 중 원격 호스트로 전송되는 파일 이름을 번역합니다. --files-from 옵션도 참조하십시오. rsync는 필터 파일(포함/제외 파일 포함)의 이름을 변환하지 않는다는 점에 유의하십시오. 전송의 양쪽에서 일치할 수 있는 규칙을 지정하는 것은 사용자에게 달려 있습니다. 예를 들어, 양쪽에 파일 이름 차이가 있어 처리해야 하는 경우 추가 포함/제외 규칙을 지정할 수 있습니다. --iconv 옵션을 허용하는 rsync 데몬에 전달할 때, 데몬은 실제로 전달하는 원격 문자셋과 관계없이 \"charset\" 구성 매개변수에 지정된 문자셋을 사용합니다. 따라서 데몬 전송의 경우 로컬 문자셋만 지정해도 됩니다 (예: --iconv=utf8). --ipv4, -4 또는 --ipv6, -6 rsync에게 소켓을 생성하거나 ssh를 실행할 때 IPv4/IPv6를 선호하도록 지시합니다. 이는 rsync가 직접 제어하는 소켓, 예를 들어 rsync 데몬에 직접 연결할 때 나가는 소켓, 그리고 ssh가 원격 셸로 사용된다는 것을 rsync가 추론할 수 있을 때 ssh에 -4 또는 -6 옵션을 전달하는 것에 영향을 미칩니다. 다른 원격 셸의 경우 \"--rsh SHELL -4\" 옵션 (또는 해당 셸이 사용하는 IPv4/IPv6 힌트 옵션)을 직접 지정해야 합니다. 이 옵션의 데몬 버전도 참조하십시오. rsync가 IPv6 지원 없이 컴파일된 경우, --ipv6 옵션은 효과가 없습니다. rsync --version 출력에 \"no IPv6\"가 포함되어 있으면 이러한 경우입니다. --checksum-seed=NUM 체크섬 시드를 정수 NUM으로 설정합니다. 이 4바이트 체크섬 시드는 각 블록 및 MD4 파일 체크섬 계산에 포함됩니다 (더 현대적인 MD5 파일 체크섬은 시드를 사용하지 않습니다). 기본적으로 체크섬 시드는 서버에 의해 생성되며 현재 시간()으로 기본값이 지정됩니다. 이 옵션은 특정 체크섬 시드를 설정하는 데 사용되며, 반복 가능한 블록 체크섬을 원하는 애플리케이션이나 사용자가 더 무작위적인 체크섬 시드를 원하는 경우에 유용합니다. NUM을 0으로 설정하면 rsync는 체크섬 시드에 대해 기본값인 time()을 사용합니다. DAEMON OPTIONS rsync 데몬을 시작할 때 허용되는 옵션은 다음과 같습니다: --daemon 이것은 rsync에게 데몬으로 실행하도록 지시합니다. 실행 중인 데몬은 host::module 또는 rsync://host/module/ 구문을 사용하여 rsync 클라이언트로 접근할 수 있습니다. 표준 입력이 소켓인 경우 rsync는 inetd를 통해 실행 중이라고 가정하고, 그렇지 않으면 현재 터미널에서 분리되어 백그라운드 데몬이 됩니다. 데몬은 클라이언트가 연결할 때마다 구성 파일(rsyncd.conf)을 읽고 요청에 따라 응답합니다. 자세한 내용은 rsyncd.conf(5) 맨페이지를 참조하십시오. --address=ADDRESS 기본적으로 rsync는 --daemon 옵션으로 데몬으로 실행될 때 와일드카드 주소에 바인딩합니다. --address 옵션을 사용하면 특정 IP 주소(또는 호스트 이름)에 바인딩하도록 지정할 수 있습니다. 이는 --config 옵션과 함께 가상 호스팅을 가능하게 합니다. rsyncd.conf 맨페이지의 address 전역 옵션과 --address 옵션의 클라이언트 버전도 참조하십시오. --bwlimit=RATE 이 옵션은 데몬이 소켓을 통해 보내는 데이터의 최대 전송 속도를 지정할 수 있도록 합니다. 클라이언트는 여전히 더 작은 --bwlimit 값을 지정할 수 있지만, 더 큰 값은 허용되지 않습니다. 몇 가지 추가 세부 사항은 --bwlimit 옵션의 클라이언트 버전을 참조하십시오. --config=FILE 이것은 기본값 대신 대체 구성 파일을 지정합니다. 이는 --daemon이 지정된 경우에만 관련됩니다. 데몬이 원격 셸 프로그램을 통해 실행되고 원격 사용자가 슈퍼유저가 아닌 경우를 제외하고 기본값은 /etc/rsyncd.conf입니다. 이 경우 기본값은 현재 디렉토리(일반적으로 $HOME)의 rsyncd.conf입니다. --dparam=OVERRIDE, -M 이 옵션은 데몬 모드에서 rsync를 시작할 때 데몬-구성 매개변수를 설정하는 데 사용될 수 있습니다. 이는 첫 번째 모듈 정의 이전에 전역 설정 끝에 매개변수를 추가하는 것과 동일합니다. 매개변수 이름은 원하는 경우 공백 없이 지정할 수 있습니다. 예를 들어: rsync --daemon -M pidfile=/path/rsync.pid --no-detach 데몬으로 실행할 때, 이 옵션은 rsync에게 자신을 분리하여 백그라운드 프로세스가 되지 않도록 지시합니다. 이 옵션은 Cygwin에서 서비스로 실행할 때 필요하며, daemontools 또는 AIX의 System Resource Controller와 같은 프로그램에 의해 rsync가 감독될 때도 유용할 수 있습니다. --no-detach는 rsync가 디버거에서 실행될 때도 권장됩니다. 이 옵션은 rsync가 inetd 또는 sshd에서 실행될 때 효과가 없습니다. --port=PORT 이것은 데몬이 기본값 873 대신 수신할 대체 TCP 포트 번호를 지정합니다. --port 옵션의 클라이언트 버전과 rsyncd.conf 맨페이지의 port 전역 설정도 참조하십시오. --log-file=FILE 이 옵션은 rsync 데몬에게 구성 파일의 \"log file\" 설정 대신 주어진 로그-파일 이름을 사용하도록 지시합니다. --log-file 옵션의 클라이언트 버전도 참조하십시오. --log-file-format=FORMAT 이 옵션은 rsync 데몬에게 구성 파일의 \"log format\" 설정 대신 주어진 FORMAT 문자열을 사용하도록 지시합니다. 또한 문자열이 비어 있지 않으면 \"전송 로깅\"을 활성화하고, 문자열이 비어 있으면 전송 로깅을 끕니다. --log-file-format 옵션의 클라이언트 버전도 참조하십시오. --sockopts 이것은 rsyncd.conf 파일의 소켓 옵션 설정을 재정의하며, 구문은 동일합니다. --sockopts 옵션의 클라이언트 버전도 참조하십시오. --verbose, -v 이 옵션은 데몬이 시작 단계에서 기록하는 정보의 양을 늘립니다. 클라이언트가 연결되면 데몬의 상세도 수준은 클라이언트가 사용한 옵션과 모듈 구성 섹션의 \"max verbosity\" 설정에 의해 제어됩니다. --verbose 옵션의 클라이언트 버전도 참조하십시오. --ipv4, -4 또는 --ipv6, -6 rsync 데몬이 연결을 수신하기 위해 사용하는 수신 소켓을 생성할 때 IPv4/IPv6를 선호하도록 지시합니다. 이 옵션 중 하나는 Linux의 오래된 버전에서 커널의 IPv6 버그를 해결하기 위해 필요할 수 있습니다 (다른 아무것도 포트를 사용하고 있지 않은데 \"address already in use\" 오류가 발생하면 데몬을 시작할 때 --ipv6 또는 --ipv4를 지정해 보십시오). 이 옵션의 클라이언트 버전도 참조하십시오. rsync가 IPv6 지원 없이 컴파일된 경우, --ipv6 옵션은 효과가 없습니다. rsync --version 출력에 \"no IPv6\"가 포함되어 있으면 이러한 경우입니다. --help, -h --daemon 다음에 지정되면 rsync 데몬을 시작하는 데 사용할 수 있는 옵션을 설명하는 짧은 도움말 페이지를 출력합니다. FILTER RULES 필터 규칙은 파일 처리 방식의 여러 측면을 사용자 정의로 제어할 수 있도록 합니다: o 보내는 측이 전송 계층 구조를 설명하는 파일 목록에 어떤 파일을 넣을지 제어합니다. o 삭제 시, 파일이 전송자의 파일 목록에 없을 때 받는 측이 어떤 파일을 삭제로부터 보호할지 제어합니다. o xattrs를 복사할 때 어떤 확장 속성 이름을 건너뛸지 제어합니다. 규칙은 옵션 인자를 통해 직접 지정되거나, 하나 이상의 파일에서 읽어올 수 있습니다. 필터-규칙 파일은 복사되는 파일 계층 구조의 일부일 수 있으며, 트리의 다른 부분에 다른 방식으로 영향을 미칠 수 있습니다. SIMPLE INCLUDE/EXCLUDE RULES 먼저 포함 및 제외 규칙이 전송되는 파일에 어떤 영향을 미치는지 기본적인 사항을 다루고, 삭제 부작용은 무시하겠습니다. 필터 규칙은 주로 rsync가 \"재귀적으로\" 들어가는 디렉토리의 내용에 영향을 미치지만, 인자로 지정된 전송의 최상위 항목에도 영향을 미칠 수 있습니다. 일치하지 않는 모든 파일/디렉토리의 기본값은 전송에 포함되는 것이며, 이는 파일/디렉토리를 보내는 측의 파일 목록에 넣습니다. 제외 규칙을 사용하면 일치하는 하나 이상의 파일/디렉토리가 보내는 측의 파일 목록에서 제외됩니다. 포함 규칙은 너무 많은 파일과 일치하는 제외 규칙의 영향을 제한하는 데 사용될 수 있습니다. 규칙의 순서가 중요합니다. 첫 번째로 일치하는 규칙이 적용되기 때문입니다. 따라서, 초기 규칙이 파일을 제외하면 그 뒤에 오는 포함 규칙은 아무런 효과도 가질 수 없습니다. 이는 포함 재정의를 의도한 제외 규칙보다 앞서 어딘가에 배치해야 한다는 것을 의미합니다. 디렉토리가 제외되면 해당 내용과 하위 내용도 모두 제외됩니다. 보내는 측은 어떤 내용도 전혀 스캔하지 않으므로, 불필요한 큰 하위 트리를 건너뛸 때 많은 시간을 절약할 수 있습니다. 또한 포함/제외 규칙은 보내는 측이 재귀하는 모든 파일 및 디렉토리에 적용된다는 것을 이해하는 것이 중요합니다. 따라서 특정 깊은 파일을 포함하려면, 해당 파일로 가는 경로에서 반드시 거쳐야 할 디렉토리 중 어느 것도 제외되지 않았는지 확인해야 합니다. 그렇지 않으면 파일이 포함될 것으로 발견되지 않을 것입니다. 예를 들어, \"a/path\" 디렉토리가 전송 인자로 주어졌고 \"a/path/down/deep/wanted.txt\" 파일이 전송의 일부가 되도록 하려면, 보내는 측은 파일 트리를 스캔하면서 \"a/path\", \"a/path/down\", \"a/path/down/deep\" 디렉토리를 제외해서는 안 됩니다. 규칙 작업을 할 때, rsync에게 무엇이 제외/포함되고 왜 그런지 알려달라고 요청하는 것이 도움이 될 수 있습니다. --debug=FILTER 또는 (파일을 가져올 때) -M--debug=FILTER를 지정하면 FILTER 디버그 정보의 수준 1이 켜지고, 파일이나 디렉토리가 포함되거나 제외될 때마다 어떤 규칙과 일치했는지 메시지가 출력됩니다. 3.2.4부터는 필터 규칙에 후행 공백이 있는 경우에도 경고합니다. \"foo \" (후행 공백 포함) 제외는 \"foo\"라는 파일을 제외하지 않기 때문입니다. 제외 및 포함 규칙은 파일 접미사 또는 파일 이름의 일부와 같은 것을 일치시킬 수 있는 와일드카드 PATTERN MATCHING RULES (셸 와일드카드와 유사)를 지정할 수 있습니다. 규칙은 파일 이름 뒤에 후행 슬래시를 붙여 디렉토리에만 영향을 미치도록 제한할 수 있습니다. SIMPLE INCLUDE/EXCLUDE EXAMPLE 보내는 측에 다음 파일 트리가 생성되었다고 가정합니다: mkdir x/ touch x/file.txt mkdir x/y/ touch x/y/file.txt touch x/y/zzz.txt mkdir x/z/ touch x/z/file.txt 그러면 다음 rsync 명령은 \"x/y/file.txt\" 파일과 해당 파일을 보관하는 데 필요한 디렉토리를 전송하여 원격 호스트에 \"/tmp/x/y/file.txt\" 경로가 존재하도록 합니다: rsync -ai -f'+ x/' -f'+ x/y/' -f'+ x/y/file.txt' -f'- *' x host:/tmp/ 참고: 이 복사는 -R 옵션을 사용하여도 달성할 수 있었습니다 (단, 삭제가 활성화된 경우 두 명령은 다르게 작동합니다): rsync -aiR x/y/file.txt host:/tmp/ 다음 명령은 \"x\" 디렉토리가 전송의 일부가 아니므로 (후행 슬래시 주의) 포함할 필요가 없습니다. 이 명령을 실행하면 \"y\" 및 \"z\" 디렉토리가 제외되므로 \"/tmp/x/file.txt\"만 복사됩니다: rsync -ai -f'+ file.txt' -f'- *' x/ host:/tmp/x/ 이 명령은 \"zzz.txt\" 파일을 제외하고 \"x\"와 그 안에 포함된 모든 것을 복사합니다: rsync -ai -f'- zzz.txt' x host:/tmp/ FILTER RULES WHEN DELETING 삭제 옵션이 없으면 디렉토리별 규칙은 보내는 측에만 관련되므로, 병합 파일 자체를 제외해도 전송에 영향을 주지 않습니다. 이를 쉽게 하기 위해 'e' 수정자가 이 제외를 자동으로 추가합니다. 다음 두 가지 동등한 명령에서 볼 수 있습니다: rsync -av --filter=': .excl' --exclude=.excl host:src/dir /dest rsync -av --filter=':e .excl' host:src/dir /dest 그러나 수신 측에서 삭제를 수행하고 일부 파일을 삭제에서 제외하고 싶다면, 수신 측이 어떤 파일을 제외해야 하는지 알아야 합니다. 가장 쉬운 방법은 디렉토리별 병합 파일을 전송에 포함하고 --delete-after를 사용하는 것입니다. 이는 삭제를 시도하기 전에 수신 측이 보내는 측과 동일한 모든 제외 규칙을 받도록 보장하기 때문입니다: rsync -avF --delete-after host:src/dir /dest 그러나 병합 파일이 전송의 일부가 아닌 경우, 전역 제외 규칙을 지정하거나 (즉, 명령줄에 지정), 수신 측에서 자체 디렉토리별 병합 파일을 유지해야 합니다. 첫 번째 예시는 다음과 같습니다 (원격 .rules 파일이 자신을 제외한다고 가정): rsync -av --filter=': .rules' --filter='. /my/extra.rules' --delete host:src/dir /dest 위 예시에서 extra.rules 파일은 전송의 양쪽에 영향을 미칠 수 있지만, (보내는 측에서는) 디렉토리별 병합 규칙 이후에 지정되었으므로 .rules 파일에서 병합된 규칙보다 하위입니다. 마지막 예시로, 원격 측은 전송에서 .rsync-filter 파일을 제외하고 있지만, 수신 측에서 무엇이 삭제될지 제어하기 위해 자체 .rsync-filter 파일을 사용하고 싶습니다. 이를 위해 디렉토리별 병합 파일을 명시적으로 제외하고 (삭제되지 않도록), 로컬 파일에 다른 무엇이 삭제되지 않아야 하는지 제어하는 규칙을 추가해야 합니다. 다음 명령 중 하나와 같이: rsync -av --filter=':e /.rsync-filter' --delete \\ host:src/dir /dest rsync -avFF --delete host:src/dir /dest FILTER RULES IN DEPTH Rsync는 이전 스타일 포함/제외 규칙과 새로운 스타일 필터 규칙을 지원합니다. 이전 규칙은 --include 및 --exclude뿐만 아니라 --include-from 및 --exclude-from을 사용하여 지정됩니다. 이들은 동작이 제한적이지만 \"-\" 또는 \"+\" 접두사가 필요하지 않습니다. 이전 스타일 제외 규칙은 \"- name\" 필터 규칙(수정자 없음)으로 변환되고, 이전 스타일 포함 규칙은 \"+ name\" 필터 규칙(수정자 없음)으로 변환됩니다. Rsync는 명령줄에 지정되었거나 파일에서 읽어온 필터 규칙의 순서 있는 목록을 빌드합니다. 새로운 스타일 필터 규칙은 다음 구문을 가집니다: RULE [PATTERN_OR_FILENAME] RULE,MODIFIERS [PATTERN_OR_FILENAME] 아래 설명된 짧은 또는 긴 RULE 이름을 선택하여 사용할 수 있습니다. 짧은 이름의 규칙을 사용하는 경우 RULE과 MODIFIERS를 구분하는 ','는 선택 사항입니다. 그 뒤에 오는 PATTERN 또는 FILENAME (존재하는 경우)은 단일 공백 또는 밑줄(_) 뒤에 와야 합니다. 추가 공백 및/또는 밑줄은 패턴 이름의 일부로 간주됩니다. 사용 가능한 규칙 접두사는 다음과 같습니다: exclude, '-' 숨김(hide)과 보호(protect)를 모두 수행하는 제외 패턴을 지정합니다 (기본값). include, '+' 표시(show)와 위험(risk)을 모두 수행하는 포함 패턴을 지정합니다 (기본값). merge, '.' 더 많은 규칙을 읽을 클라이언트 측의 병합 파일(merge-file)을 지정합니다. dir-merge, ':' 디렉토리별 병합 파일(per-directory merge-file)을 지정합니다. 이러한 종류의 필터 규칙을 사용하려면 보내는 측의 필터 확인을 신뢰해야 하므로, --trust-sender 옵션에 언급된 부작용이 있습니다. hide, 'H' 전송에서 파일을 숨기기 위한 패턴을 지정합니다. 보내는 측 전용 제외와 동일하므로 -f'H foo'는 -f'-s foo'로도 지정할 수 있습니다. show, 'S' 패턴과 일치하는 파일은 숨겨지지 않습니다. 보내는 측 전용 포함과 동일하므로 -f'S foo'는 -f'+s foo'로도 지정할 수 있습니다. protect, 'P' 삭제로부터 파일을 보호하기 위한 패턴을 지정합니다. 받는 측 전용 제외와 동일하므로 -f'P foo'는 -f'-r foo'로도 지정할 수 있습니다. risk, 'R' 패턴과 일치하는 파일은 보호되지 않습니다. 받는 측 전용 포함과 동일하므로 -f'R foo'는 -f'+r foo'로도 지정할 수 있습니다. clear, '!' 현재 포함/제외 목록을 지웁니다 (인자를 받지 않습니다). 규칙이 파일에서 읽어올 때 (merge 또는 dir-merge 사용), 빈 줄은 무시되며, '#'으로 시작하는 전체 줄 주석도 무시됩니다 (해시 문자를 포함하는 파일 이름 규칙은 영향을 받지 않습니다). 또한 --filter, --include 및 --exclude 옵션은 각각 하나의 규칙/패턴만 받습니다. 여러 개를 추가하려면 명령줄에서 옵션을 반복하거나, --filter 옵션의 병합 파일 구문을 사용하거나, --include-from / --exclude-from 옵션을 사용하십시오. PATTERN MATCHING RULES 위에 언급된 대부분의 규칙은 규칙이 무엇과 일치해야 하는지 지정하는 인자를 받습니다. rsync가 디렉토리 계층을 재귀적으로 탐색하는 경우, 각 패턴은 rsync가 보낼 파일 이름을 찾으면서 하위 경로의 모든 디렉토리 이름과 일치하는지 확인된다는 점을 명심하십시오. 패턴 인자에 대한 일치 규칙은 여러 형태를 가집니다: o 패턴에 / (후행 슬래시 제외) 또는 \"**\" (슬래시와 일치할 수 있음)가 포함된 경우, 패턴은 전송 내의 모든 선행 디렉토리를 포함한 전체 경로 이름과 일치합니다. 패턴에 (후행이 아닌) / 또는 \"**\"가 포함되어 있지 않으면, 파일 이름 또는 경로 이름의 마지막 구성 요소와만 일치합니다. 예를 들어, foo는 최종 경로 구성 요소가 \"foo\"여야 함을 의미하며, foo/bar는 경로의 마지막 두 요소와 일치합니다 (두 요소 모두 전송 내에 있는 한). o /로 끝나는 패턴은 디렉토리만 일치시키고, 일반 파일, 심볼릭 링크 또는 장치는 일치시키지 않습니다. o /로 시작하는 패턴은 전송 경로의 끝이 아닌 시작에 고정됩니다. 예를 들어, /foo/** 또는 /foo/bar/**는 경로의 선행 요소만 일치시킵니다. 규칙이 디렉토리별 필터 파일에서 읽힌 경우, 일치하는 전송 경로는 전송의 최상단이 아닌 필터 파일 수준에서 시작됩니다. 전송의 루트에서 일치하는 패턴을 지정하는 방법에 대한 전체 논의는 ANCHORING INCLUDE/EXCLUDE PATTERNS 섹션을 참조하십시오. Rsync는 패턴에 다음 세 가지 와일드카드 문자 중 하나가 포함되어 있는지 확인하여 간단한 문자열 일치와 와일드카드 일치 중 하나를 선택합니다: '*', '?', '[' : o '?'는 슬래시(/)를 제외한 모든 단일 문자와 일치합니다. o '*'는 슬래시가 아닌 0개 이상의 문자와 일치합니다. o '**'는 슬래시를 포함하여 0개 이상의 문자와 일치합니다. o '['는 문자 클래스(예: [a-z] 또는 [[:alpha:]])를 도입하며, 한 문자와 일치해야 합니다. o 패턴의 후행 ***는 디렉토리와 그 모든 내용을 단일 규칙으로 일치시킬 수 있는 약식입니다. 예를 들어, \"dir_name/***\"를 지정하면 \"dir_name\" 디렉토리(마치 \"dir_name/\"이 지정된 것처럼)와 디렉토리 내의 모든 내용(마치 \"dir_name/**\"이 지정된 것처럼)을 모두 일치시킵니다. o 역슬래시는 와일드카드 문자를 이스케이프하는 데 사용할 수 있지만, 일치 패턴에 와일드카드 문자가 하나 이상 있는 경우에만 이스케이프 문자로 해석됩니다. 예를 들어, 패턴 \"foo\\bar\"는 단일 역슬래시를 리터럴로 일치시키지만, 패턴 \"foo\\bar*\"는 \"\\b\"가 단순히 \"b\"가 되는 것을 피하기 위해 \"foo\\\\bar*\"로 변경되어야 합니다. 다음은 제외/포함 일치 예시입니다: o 옵션 -f'- *.o'는 .o로 끝나는 모든 파일 이름을 제외합니다. o 옵션 -f'- /foo'는 전송-루트 디렉토리의 foo라는 파일(또는 디렉토리)을 제외합니다. o 옵션 -f'- foo/'는 foo라는 모든 디렉토리를 제외합니다. o 옵션 -f'- foo/*/bar'는 foo라는 디렉토리 아래 두 단계에 있는 bar라는 파일/디렉토리를 제외합니다 (foo가 전송에 포함된 경우). o 옵션 -f'- /foo/**/bar'는 최상위 디렉토리 foo 아래 두 단계 이상에 있는 bar라는 파일/디렉토리를 제외합니다 (단, /foo/bar는 이것에 의해 제외되지 않습니다). o 옵션 -f'+ */' -f'+ *.c' -f'- *'는 모든 디렉토리와 .c 소스 파일만 포함하고 다른 것은 포함하지 않습니다. o 옵션 -f'+ foo/' -f'+ foo/bar.c' -f'- *'는 foo 디렉토리와 foo/bar.c만 포함합니다 (foo 디렉토리는 명시적으로 포함되어야 합니다. 그렇지 않으면 \"- *\"에 의해 제외됩니다). FILTER RULE MODIFIERS 다음 수정자는 포함(+) 또는 제외(-) 규칙 뒤에 허용됩니다: o /는 포함/제외 규칙이 현재 항목의 절대 경로 이름과 일치해야 함을 지정합니다. 예를 들어, -f'-/ /etc/passwd'는 전송이 \"/etc\" 디렉토리에서 파일을 보낼 때마다 passwd 파일을 제외하며, \"-/ subdir/foo\"는 \"foo\"가 \"subdir\"라는 디렉토리에 있을 때 항상 \"foo\"를 제외합니다. \"foo\"가 현재 전송의 루트에 있더라도 마찬가지입니다. o !는 패턴이 일치하지 않을 때 포함/제외가 적용되어야 함을 지정합니다. 예를 들어, -f'-! */'는 모든 비디렉토리를 제외합니다. o C는 모든 전역 CVS-제외 규칙이 \"-C\" 대신 제외로 삽입되어야 함을 나타내는 데 사용됩니다. 인자가 뒤따르지 않습니다. o s는 규칙이 보내는 측에 적용됨을 나타내는 데 사용됩니다. 규칙이 보내는 측에 영향을 미칠 때, 이는 보내는 측의 파일 목록에 어떤 파일이 포함될지에 영향을 미칩니다. 기본값은 규칙이 양쪽에 영향을 미치는 것이지만, --delete-excluded가 지정된 경우 기본 규칙은 보내는 측에만 적용됩니다. 보내는 측의 포함/제외를 지정하는 다른 방법인 hide (H) 및 show (S) 규칙도 참조하십시오. o r은 규칙이 수신 측에 적용됨을 나타내는 데 사용됩니다. 규칙이 수신 측에 영향을 미칠 때, 이는 파일이 삭제되는 것을 방지합니다. 자세한 내용은 s 수정자를 참조하십시오. 수신 측의 포함/제외를 지정하는 다른 방법인 protect (P) 및 risk (R) 규칙도 참조하십시오. o p는 규칙이 소멸성(perishable)임을 나타냅니다. 즉, 삭제되는 디렉토리에서는 무시됩니다. 예를 들어, --cvs-exclude (-C) 옵션의 \"CVS\" 및 \"*.o\"와 같은 것을 제외하는 기본 규칙은 소멸성으로 표시되며, 소스에서 제거된 디렉토리가 대상에서 삭제되는 것을 방지하지 않습니다. o x는 규칙이 xattr 복사/삭제 작업에서 xattr 이름에 영향을 미치고 (따라서 파일/디렉토리 이름과 일치할 때는 무시됩니다) 있음을 나타냅니다. xattr-일치 규칙이 지정되지 않으면 기본 xattr 필터링 규칙이 사용됩니다 (--xattrs 옵션 참조). MERGE-FILE FILTER RULES 병합(.) 또는 디렉토리 병합(:) 필터 규칙을 지정하여 전체 파일을 필터 규칙에 병합할 수 있습니다 (위의 FILTER RULES 섹션에서 소개됨). 병합 파일에는 단일-인스턴스('.')와 디렉토리별(':') 두 가지 종류가 있습니다. 단일-인스턴스 병합 파일은 한 번 읽히며, 그 규칙은 \".\" 규칙 위치의 필터 목록에 통합됩니다. 디렉토리별 병합 파일의 경우, rsync는 탐색하는 모든 디렉토리에서 명명된 파일을 스캔하고, 파일이 존재할 때 그 내용을 현재 상속된 규칙 목록에 병합합니다. 이러한 디렉토리별 규칙 파일은 보내는 측에서 생성되어야 합니다. 보내는 측이 전송할 수 있는 파일을 스캔하기 때문입니다. 또한, 삭제되지 않아야 할 파일에 영향을 미치려면 이러한 규칙 파일을 수신 측으로 전송해야 할 수도 있습니다 (아래 PER-DIRECTORY RULES AND DELETE 참조). 몇 가지 예시: merge /etc/rsync/default.rules . /etc/rsync/default.rules dir-merge .per-dir-filter dir-merge,n- .non-inherited-per-dir-excludes :n- .non-inherited-per-dir-excludes 다음 수정자는 병합 또는 디렉토리 병합 규칙 뒤에 허용됩니다: o -는 파일이 오직 제외 패턴으로만 구성되어야 하며, 인-파일 주석을 제외하고는 다른 규칙 파싱은 없어야 함을 지정합니다. o +는 파일이 오직 포함 패턴으로만 구성되어야 하며, 인-파일 주석을 제외하고는 다른 규칙 파싱은 없어야 함을 지정합니다. o C는 파일이 CVS 호환 방식으로 읽혀야 함을 지정하는 방법입니다. 이것은 'n', 'w', '-'를 켜지만, 목록 지우기 토큰(!)도 지정할 수 있도록 합니다. 파일 이름이 제공되지 않으면 \".cvsignore\"가 가정됩니다. o e는 병합 파일 이름을 전송에서 제외합니다. 예: \"dir-merge,e .rules\"는 \"dir-merge .rules\"와 \"- .rules\"와 같습니다. o n은 규칙이 하위 디렉토리에 상속되지 않음을 지정합니다. o w는 규칙이 일반적인 줄 분할 대신 공백으로 단어 분할됨을 지정합니다. 이것은 또한 주석을 끕니다. 참고: 접두사와 규칙을 분리하는 공백은 특별하게 처리되므로, \"- foo + bar\"는 두 개의 규칙으로 파싱됩니다 (접두사 파싱도 비활성화되지 않았다고 가정할 때). o \"+\" 또는 \"-\" 규칙 (위 참조)에 대한 수정자 중 하나를 지정할 수도 있습니다. 이는 파일에서 읽어온 규칙이 해당 수정자가 설정된 것으로 기본값을 갖도록 하기 위함입니다 (유용하지 않을 ! 수정자는 제외). 예를 들어, \"merge,-/ .excl\"은 .excl의 내용을 절대 경로 제외로 처리하고, \"dir-merge,s .filt\" 및 \":sC\"는 각각 디렉토리별 규칙을 보내는 측에만 적용되도록 합니다. 병합 규칙이 영향을 미칠 측면을 지정하는 경우 (s 또는 r 수정자 또는 둘 다를 통해), 파일의 규칙은 측면을 지정해서는 안 됩니다 (수정자 또는 hide와 같은 규칙 접두사를 통해). 디렉토리별 규칙은 'n' 수정자가 사용되지 않는 한 병합 파일이 발견된 디렉토리의 모든 하위 디렉토리에서 상속됩니다. 각 하위 디렉토리의 규칙은 부모로부터 상속된 디렉토리별 규칙 앞에 추가되어, 최신 규칙이 상속된 규칙보다 높은 우선순위를 가집니다. 전체 dir-merge 규칙 집합은 병합 파일이 지정된 위치에 함께 그룹화되므로, 전역 규칙 목록에서 이전에 지정된 규칙을 통해 dir-merge 규칙을 재정의할 수 있습니다. 디렉토리별 파일에서 목록 지우기 규칙(\"!\")이 읽히면 현재 병합 파일에 대한 상속된 규칙만 지워집니다. dir-merge 파일의 단일 규칙이 상속되는 것을 막는 또 다른 방법은 선행 슬래시로 고정하는 것입니다. 디렉토리별 병합 파일의 고정된 규칙은 병합 파일의 디렉토리에 상대적이므로, 패턴 \"/foo\"는 dir-merge 필터 파일이 발견된 디렉토리의 \"foo\" 파일만 일치시킬 것입니다. 다음은 --filter=\". file\"을 통해 지정할 수 있는 예시 필터 파일입니다: merge /home/user/.global-filter - *.gz dir-merge .rules + *.[ch] - *.o - foo* 이것은 목록 시작 부분에 /home/user/.global-filter 파일의 내용을 병합하고, \".rules\" 파일 이름을 디렉토리별 필터 파일로 전환합니다. 디렉토리 스캔 시작 이전에 읽어온 모든 규칙은 전역 고정 규칙을 따릅니다 (즉, 선행 슬래시는 전송의 루트와 일치합니다). 디렉토리별 병합 파일이 첫 번째 전송 디렉토리의 상위 디렉토리 경로로 지정된 경우, rsync는 해당 시작 지점에서 전송 디렉토리까지의 모든 상위 디렉토리에서 지정된 디렉토리별 파일을 스캔합니다. 예를 들어, 다음은 일반적인 필터입니다 (-F 참조): --filter=': /.rsync-filter' 그 규칙은 rsync에게 정상적인 디렉토리 스캔이 시작되기 전에 루트부터 전송의 상위 디렉토리까지의 모든 디렉토리에서 .rsync-filter 파일을 스캔하도록 지시합니다. (참고: rsync 데몬의 경우, 루트는 항상 모듈의 \"path\"와 동일합니다.) 디렉토리별 파일에 대한 사전 스캔의 몇 가지 예시: rsync -avF /src/path/ /dest/dir rsync -av --filter=': ../../.rsync-filter' /src/path/ /dest/dir rsync -av --filter=': .rsync-filter' /src/path/ /dest/dir 위의 처음 두 명령은 정상 스캔이 \"/src/path\" 및 그 하위 디렉토리에서 파일을 찾기 시작하기 전에 \"/\" 및 \"/src\"에서 \".rsync-filter\"를 찾을 것입니다. 마지막 명령은 상위 디렉토리 스캔을 피하고 전송의 일부인 각 디렉토리에서만 \".rsync-filter\" 파일을 찾습니다. 패턴에 \".cvsignore\"의 내용을 포함하려면, \":C\" 규칙을 사용해야 합니다. 이것은 .cvsignore 파일의 dir-merge를 생성하지만, CVS 호환 방식으로 파싱됩니다. 이것을 사용하여 --cvs-exclude (-C) 옵션의 디렉토리별 .cvsignore 파일 포함 위치를 필터 규칙 내에서 원하는 위치에 배치하여 제어할 수 있습니다. 그렇지 않으면 rsync는 .cvsignore 파일에 대한 dir-merge 규칙을 다른 모든 규칙의 끝에 추가합니다 (명령줄 규칙보다 낮은 우선순위를 부여합니다). 예를 들어: cat \u003c\u003cEOT | rsync -avC --filter='. -' a/ b + foo.o :C - *.old EOT rsync -avC --include=foo.o -f :C --exclude='*.old' a/ b 위의 두 rsync 명령은 동일합니다. 각 명령은 모든 디렉토리별 .cvsignore 규칙을 목록의 끝이 아닌 중간에 병합합니다. 이를 통해 해당 디렉토리별 규칙이 :C 이후의 규칙을 재정의할 수 있게 되며, 모든 규칙에 종속되지 않습니다. 다른 CVS 제외 규칙(즉, 기본 제외 목록, $HOME/.cvsignore의 내용, $CVSIGNORE 값)에 영향을 미치려면 -C 명령줄 옵션을 생략하고 대신 필터 규칙에 \"-C\" 규칙을 삽입해야 합니다. 예를 들어 \"--filter=-C\"와 같이요. LIST-CLEARING FILTER RULE \"!\" 필터 규칙을 사용하여 현재 포함/제외 목록을 지울 수 있습니다 (위 FILTER RULES 섹션에서 소개됨). \"현재\" 목록은 전역 규칙 목록(필터 옵션을 파싱하는 동안 규칙이 발견된 경우) 또는 디렉토리별 규칙 집합(자체 하위 목록으로 상속되므로 하위 디렉토리에서 이를 사용하여 부모의 규칙을 지울 수 있음)입니다. ANCHORING INCLUDE/EXCLUDE PATTERNS 앞서 언급했듯이, 전역 포함/제외 패턴은 \"전송의 루트\"에 고정됩니다 (디렉토리별 패턴은 병합 파일의 디렉토리에 고정됩니다). 전송을 보내는 측에서 받는 측으로 전송되는 이름의 서브트리라고 생각한다면, 전송 루트는 트리가 대상 디렉토리에서 복제되기 시작하는 곳입니다. 이 루트는 슬래시로 시작하는 패턴이 어디에서 일치하는지 지배합니다. 일치가 전송 루트에 상대적이기 때문에, 소스 경로의 후행 슬래시를 변경하거나 --relative 옵션 사용을 변경하면 일치에 사용해야 하는 경로에 영향을 미칩니다 (파일 트리의 얼마나 많은 부분이 대상 호스트에 복제되는지 변경하는 것 외에도). 다음 예시는 이를 보여줍니다. 두 개의 소스 파일, 하나는 \"/home/me/foo/bar\"의 절대 경로를 가지고 있고 다른 하나는 \"/home/you/bar/baz\"의 경로를 가지고 있다고 가정해 봅시다. 2-소스 전송에 대한 다양한 명령 선택 사항은 다음과 같이 다릅니다: 예시 명령: rsync -a /home/me /home/you /dest +/- 패턴: /me/foo/bar +/- 패턴: /you/bar/baz 대상 파일: /dest/me/foo/bar 대상 파일: /dest/you/bar/baz 예시 명령: rsync -a /home/me/ /home/you/ /dest +/- 패턴: /foo/bar (\"me\"가 누락됨에 주의) +/- 패턴: /bar/baz (\"you\"가 누락됨에 주의) 대상 파일: /dest/foo/bar 대상 파일: /dest/bar/baz 예시 명령: rsync -a --relative /home/me/ /home/you /dest +/- 패턴: /home/me/foo/bar (전체 경로 주의) +/- 패턴: /home/you/bar/baz (동일) 대상 파일: /dest/home/me/foo/bar 대상 파일: /dest/home/you/bar/baz 예시 명령: cd /home; rsync -a --relative me/foo you/ /dest +/- 패턴: /me/foo/bar (지정된 경로에서 시작) +/- 패턴: /you/bar/baz (동일) 대상 파일: /dest/me/foo/bar 대상 파일: /dest/you/bar/baz 필터링해야 할 이름을 확인하는 가장 쉬운 방법은 --verbose를 사용하여 출력되는 이름을 보고 이름 앞에 /를 붙이는 것입니다 (--dry-run 옵션을 사용하면 아직 파일을 복사할 준비가 되지 않은 경우에 유용합니다). PER-DIRECTORY RULES AND DELETE 삭제 옵션이 없으면 디렉토리별 규칙은 보내는 측에만 관련되므로, 병합 파일 자체를 제외해도 전송에 영향을 주지 않습니다. 이를 쉽게 하기 위해 'e' 수정자가 이 제외를 자동으로 추가합니다. 다음 두 가지 동등한 명령에서 볼 수 있습니다: rsync -av --filter=': .excl' --exclude=.excl host:src/dir /dest rsync -av --filter=':e .excl' host:src/dir /dest 그러나 수신 측에서 삭제를 수행하고 일부 파일을 삭제에서 제외하고 싶다면, 수신 측이 어떤 파일을 제외해야 하는지 알아야 합니다. 가장 쉬운 방법은 디렉토리별 병합 파일을 전송에 포함하고 --delete-after를 사용하는 것입니다. 이는 삭제를 시도하기 전에 수신 측이 보내는 측과 동일한 모든 제외 규칙을 받도록 보장하기 때문입니다: rsync -avF --delete-after host:src/dir /dest 그러나 병합 파일이 전송의 일부가 아닌 경우, 전역 제외 규칙을 지정하거나 (즉, 명령줄에 지정), 수신 측에서 자체 디렉토리별 병합 파일을 유지해야 합니다. 첫 번째 예시는 다음과 같습니다 (원격 .rules 파일이 자신을 제외한다고 가정): rsync -av --filter=': .rules' --filter='. /my/extra.rules' --delete host:src/dir /dest 위 예시에서 extra.rules 파일은 전송의 양쪽에 영향을 미칠 수 있지만, (보내는 측에서는) 디렉토리별 병합 규칙 이후에 지정되었으므로 .rules 파일에서 병합된 규칙보다 하위입니다. 마지막 예시로, 원격 측은 전송에서 .rsync-filter 파일을 제외하고 있지만, 수신 측에서 무엇이 삭제될지 제어하기 위해 자체 .rsync-filter 파일을 사용하고 싶습니다. 이를 위해 디렉토리별 병합 파일을 명시적으로 제외하고 (삭제되지 않도록), 로컬 파일에 다른 무엇이 삭제되지 않아야 하는지 제어하는 규칙을 추가해야 합니다. 다음 명령 중 하나와 같이: rsync -av --filter=':e /.rsync-filter' --delete \\ host:src/dir /dest rsync -avFF --delete host:src/dir /dest TRANSFER RULES 보내는 측과 (삭제 시) 받는 측에서 파일 목록을 생성하는 재귀적 파일 스캔에 영향을 미치는 FILTER RULES 외에도 전송 규칙이 있습니다. 이러한 규칙은 제외 필터 규칙의 부작용 없이 생성기가 전송해야 한다고 결정하는 파일에 영향을 미칩니다. 전송 규칙은 파일에만 영향을 미치고 디렉토리에는 영향을 미치지 않습니다. 전송 규칙은 보내는 측 (및 받는 측)의 파일 목록에 포함되는 항목에 영향을 미치지 않으므로, 받는 측에서 삭제되는 파일에 어떤 영향도 미칠 수 없습니다. 예를 들어, \"foo\" 파일이 보내는 측 목록에 있지만 크기 때문에 전송 규칙에 의해 생략되는 경우, 받는 측은 파일을 요청하지 않습니다. 그러나 파일 목록에 파일이 존재한다는 것은 삭제 패스가 받는 측에서 \"foo\"라는 이름의 일치하는 파일을 제거하지 않을 것임을 의미합니다. 반면에, 서버 측에서 \"foo\" 파일을 제외(숨김)하면 파일이 서버의 파일 목록에서 제외되고, 받는 측 제외(보호)가 없으면 삭제가 요청될 경우 받는 측은 \"foo\"라는 이름의 일치하는 파일을 제거할 것입니다. 파일이 여전히 보내는 측의 파일 목록에 있다는 점을 감안할 때, --prune-empty-dirs 옵션은 전송 규칙이 생략한 파일만 포함하더라도 디렉토리를 비어 있다고 판단하지 않을 것입니다. 마찬가지로, 전송 규칙은 수신 측에서 삭제되는 파일에 추가적인 영향을 미치지 않으므로, 전송에 대한 최대 파일 크기를 설정한다고 해서 큰 파일이 삭제되는 것을 막지는 못합니다. 전송 규칙의 예시로는 기본 \"빠른 검사\" 알고리즘(크기 및 수정 시간 비교), --update 옵션, --max-size 옵션, --ignore-non-existing 옵션 및 기타 몇 가지가 있습니다. BATCH MODE 배치 모드는 동일한 업데이트 집합을 여러 동일한 시스템에 적용하는 데 사용할 수 있습니다. 소스 트리가 여러 호스트에 복제되어 있다고 가정해 봅시다. 이제 이 소스 트리에 변경 사항이 생겼고, 이 변경 사항을 다른 호스트에 전파해야 한다고 가정해 봅시다. 배치 모드를 사용하여 이를 수행하려면, write-batch 옵션으로 rsync를 실행하여 소스 트리에 대한 변경 사항을 대상 트리 중 하나에 적용합니다. write-batch 옵션은 rsync 클라이언트가 이 작업을 다른 동일한 대상 트리에 대해 반복하는 데 필요한 모든 정보를 \"배치 파일\"에 저장하도록 합니다. 배치 파일을 한 번 생성하면 여러 대상 트리를 업데이트할 때 파일 상태, 체크섬 및 데이터 블록 생성을 한 번 이상 수행할 필요가 없습니다. 멀티캐스트 전송 프로토콜을 사용하여 동일한 데이터를 각 호스트에 개별적으로 보내는 대신 배치 업데이트 파일을 여러 호스트에 동시에 병렬로 전송할 수 있습니다. 기록된 변경 사항을 다른 대상 트리에 적용하려면, read-batch 옵션으로 rsync를 실행하고, 동일한 배치 파일 이름과 대상 트리를 지정하십시오. Rsync는 배치 파일에 저장된 정보를 사용하여 대상 트리를 업데이트합니다. 편의를 위해, write-batch 옵션이 사용될 때 스크립트 파일도 생성됩니다. 이 스크립트 파일은 배치 파일과 동일한 이름에 \".sh\"가 추가됩니다. 이 스크립트 파일에는 연관된 배치 파일을 사용하여 대상 트리를 업데이트하는 데 적합한 명령줄이 포함되어 있습니다. Bourne (또는 Bourne과 유사한) 셸을 사용하여 실행할 수 있으며, 선택적으로 대체 대상 트리 경로 이름을 전달할 수 있습니다. 이 경우 원래 대상 경로 대신 해당 경로가 사용됩니다. 이는 현재 호스트의 대상 트리 경로가 배치 파일을 생성하는 데 사용된 경로와 다른 경우에 유용합니다. 예: $ rsync --write-batch=foo -a host:/source/dir/ /adest/dir/ $ scp foo* remote: $ ssh remote ./foo.sh /bdest/dir/ $ rsync --write-batch=foo -a /source/dir/ /adest/dir/ $ ssh remote rsync --read-batch=- -a /bdest/dir/ \u003cfoo 이 예시에서 rsync는 /source/dir/에서 /adest/dir/를 업데이트하는 데 사용되며, 이 작업을 반복하는 정보는 \"foo\"와 \"foo.sh\"에 저장됩니다. 호스트 \"remote\"는 배치된 데이터가 디렉토리 /bdest/dir로 이동하면서 업데이트됩니다. 두 예시의 차이점은 배치를 처리하는 방식에 있어 사용 가능한 유연성을 보여줍니다: o 첫 번째 예시는 초기 복사가 로컬일 필요가 없음을 보여줍니다. 원하는 대로 원격 셸 구문 또는 rsync 데몬 구문을 사용하여 원격 호스트로/로부터 데이터를 푸시하거나 가져올 수 있습니다. o 첫 번째 예시는 생성된 \"foo.sh\" 파일을 사용하여 원격 호스트에서 read-batch 명령을 실행할 때 올바른 rsync 옵션을 얻습니다. o 두 번째 예시는 표준 입력을 통해 배치 데이터를 읽으므로 배치 파일을 먼저 원격 머신으로 복사할 필요가 없습니다. 이 예시는 수정된 --read-batch 옵션을 사용해야 했기 때문에 foo.sh 스크립트를 피하지만, 원한다면 스크립트 파일을 편집할 수 있습니다 (--exclude-from=- 옵션과 같이 다른 옵션이 표준 입력을 사용하려고 하지 않는지 확인하십시오). 주의사항: read-batch 옵션은 업데이트하는 대상 트리가 배치 업데이트 파일셋을 생성하는 데 사용된 대상 트리와 동일하다고 예상합니다. 대상 트리 간의 차이가 발견되면 업데이트는 경고와 함께 폐기될 수 있거나 (파일이 이미 최신 상태인 것처럼 보이면), 파일-업데이트가 시도된 후 파일이 확인에 실패하면 오류와 함께 업데이트가 폐기될 수 있습니다. 이는 명령이 중단된 경우 read-batch 작업을 다시 실행해도 안전해야 함을 의미합니다. 파일의 크기 및 날짜와 관계없이 배치 업데이트를 항상 시도하도록 강제하려면 -I 옵션(배치를 읽을 때)을 사용하십시오. 오류가 발생하면 대상 트리는 부분적으로 업데이트된 상태가 될 것입니다. 이 경우 rsync는 일반(비배치) 작동 모드에서 대상 트리를 수정하는 데 사용할 수 있습니다. 모든 대상에서 사용되는 rsync 버전은 배치 파일을 생성하는 데 사용된 버전보다 최신이어야 합니다. 배치 파일의 프로토콜 버전이 배치-읽기 rsync가 처리하기에는 너무 새로운 경우 rsync는 오류와 함께 종료됩니다. 이전 rsync가 이해할 수 있는 배치 파일을 생성하는 방법은 --protocol 옵션도 참조하십시오. (배치 파일은 버전 2.6.3에서 형식이 변경되었으므로, 그보다 오래된 버전과 새로운 버전을 혼합하면 작동하지 않습니다.) 배치 파일을 읽을 때 rsync는 배치 파일의 데이터와 일치하도록 특정 옵션의 값을 강제합니다. 배치-쓰기 명령과 동일하게 설정하지 않은 경우에 그렇습니다. 다른 옵션은 변경할 수 있습니다 (그리고 변경해야 합니다). 예를 들어, --write-batch는 --read-batch로 변경되고, --files-from은 삭제되며, --filter / --include / --exclude 옵션은 --delete 옵션 중 하나가 지정되지 않는 한 필요하지 않습니다. BATCH.sh 파일을 생성하는 코드는 모든 필터/포함/제외 옵션을 셸 스크립트 파일에 \"여기 문서\"로 추가되는 단일 목록으로 변환합니다. 고급 사용자는 이를 사용하여 --delete에 의해 삭제되는 내용을 변경하고 싶을 때 제외 목록을 수정할 수 있습니다. 일반 사용자는 이 세부 사항을 무시하고 셸 스크립트를 배치된 데이터에 대한 적절한 --read-batch 명령을 실행하는 쉬운 방법으로 사용할 수 있습니다. SYMBOLIC LINKS rsync가 소스 디렉토리에서 심볼릭 링크를 발견할 때 세 가지 기본적인 동작이 가능합니다. 기본적으로 심볼릭 링크는 전혀 전송되지 않습니다. 존재하는 모든 심볼릭 링크에 대해 \"비정규 파일 건너뛰기\" 메시지가 발생합니다. --links가 지정되면 심볼릭 링크가 전송에 추가되고 (시끄럽게 무시하는 대신), 기본 처리는 대상에서 동일한 대상을 가리키도록 다시 생성하는 것입니다. --archive는 --links를 암시합니다. --copy-links가 지정되면 심볼릭 링크는 심볼릭 링크 자체가 아닌 참조 대상을 복사하여 \"축소\"됩니다. Rsync는 또한 \"안전한\" 심볼릭 링크와 \"안전하지 않은\" 심볼릭 링크를 구별할 수 있습니다. 이것이 사용될 수 있는 예시는 복사되는 rsync 모듈이 사이트의 공개 섹션에 /etc/passwd에 대한 심볼릭 링크를 포함하지 않도록 하려는 웹 사이트 미러입니다. --copy-unsafe-links를 사용하면 모든 링크가 대상에서 가리키는 파일로 복사됩니다. --safe-links를 사용하면 안전하지 않은 링크가 수신자에 의해 생략됩니다. ( --safe-links가 효과를 가지려면 --links를 지정하거나 암시해야 한다는 점에 유의하십시오.) 심볼릭 링크는 절대 심볼릭 링크( '/'로 시작), 비어 있거나, 전송의 최상단에서 벗어날 만큼 충분한 \"..\" 구성 요소를 포함하는 경우 안전하지 않은 것으로 간주됩니다. 다음은 심볼릭 링크 옵션이 어떻게 해석되는지에 대한 요약입니다. 목록은 우선순위 순서이므로, 옵션 조합이 언급되지 않았다면, 옵션의 완전한 하위 집합인 첫 번째 줄을 사용하십시오: --copy-links 모든 심볼릭 링크를 일반 파일 및 디렉토리로 전환합니다 (다른 옵션이 영향을 미칠 심볼릭 링크를 전송에 남기지 않습니다). --copy-dirlinks 디렉토리에 대한 심볼릭 링크만 실제 디렉토리로 전환하고, 다른 모든 심볼릭 링크는 아래 설명된 대로 처리되도록 둡니다. --links --copy-unsafe-links 모든 안전하지 않은 심볼릭 링크를 파일로 전환하고, 모든 안전한 심볼릭 링크를 생성합니다. --copy-unsafe-links 모든 안전하지 않은 심볼릭 링크를 파일로 전환하고, 모든 안전한 심볼릭 링크는 시끄럽게 건너뜁니다. --links --safe-links 수신자는 전송에서 발견된 안전하지 않은 심볼릭 링크 생성을 건너뛰고 안전한 심볼릭 링크를 생성합니다. --links 모든 심볼릭 링크를 생성합니다. --munge-links의 효과에 대해서는 해당 옵션 섹션의 설명을 참조하십시오. --keep-dirlinks 옵션은 전송의 심볼릭 링크에는 영향을 미치지 않고, 대신 rsync가 수신 측에 이미 존재하는 디렉토리에 대한 심볼릭 링크를 처리하는 방식에 영향을 미친다는 점에 유의하십시오. 해당 옵션 섹션의 경고를 참조하십시오. DIAGNOSTICS Rsync는 때때로 다소 이해하기 어려운 오류 메시지를 생성합니다. 가장 혼란을 야기하는 메시지는 \"protocol version mismatch -- is your shell clean?\"입니다. 이 메시지는 일반적으로 시작 스크립트 또는 원격 셸 기능이 rsync가 전송에 사용하는 스트림에 원치 않는 쓰레기 데이터를 생성할 때 발생합니다. 이 문제를 진단하는 방법은 다음과 같이 원격 셸을 실행하는 것입니다: ssh remotehost /bin/true \u003e out.dat 그런 다음 out.dat 파일을 확인하십시오. 모든 것이 올바르게 작동하면 out.dat는 0 길이 파일이어야 합니다. rsync에서 위 오류가 발생하면 out.dat에 일부 텍스트 또는 데이터가 포함되어 있을 것입니다. 내용을 살펴보고 무엇이 이를 생성하는지 파악해 보십시오. 가장 흔한 원인은 비대화형 로그인에 대한 출력 문을 포함하는 잘못 구성된 셸 시작 스크립트(.cshrc 또는 .profile과 같은)입니다. 필터 패턴을 디버깅하는 데 문제가 있다면 -vv 옵션을 지정해 보십시오. 이 상세도 수준에서는 rsync가 각 개별 파일이 포함되거나 제외되는 이유를 보여줍니다. EXIT VALUES o 0 - 성공 o 1 - 구문 또는 사용 오류 o 2 - 프로토콜 비호환성 o 3 - 입력/출력 파일, 디렉토리 선택 오류 o o 4 - 요청된 작업이 지원되지 않습니다. 다음 중 하나일 수 있습니다: 64비트 파일을 지원할 수 없는 플랫폼에서 64비트 파일을 조작하려는 시도 o 클라이언트에서 지원하지만 서버에서는 지원하지 않는 옵션이 지정됨 o 5 - 클라이언트-서버 프로토콜 시작 오류 o 6 - 데몬이 로그 파일에 추가할 수 없음 o 10 - 소켓 I/O 오류 o 11 - 파일 I/O 오류 o 12 - rsync 프로토콜 데이터 스트림 오류 o 13 - 프로그램 진단 오류 o 14 - IPC 코드 오류 o 20 - SIGUSR1 또는 SIGINT 수신 o 21 - waitpid()에서 반환된 일부 오류 o 22 - 코어 메모리 버퍼 할당 오류 o 23 - 오류로 인한 부분 전송 o 24 - 사라진 소스 파일로 인한 부분 전송 o 25 - --max-delete 제한으로 삭제 중지 o 30 - 데이터 송수신 타임아웃 o 35 - 데몬 연결 대기 타임아웃 ENVIRONMENT VARIABLES CVSIGNORE CVSIGNORE 환경 변수는 .cvsignore 파일의 무시 패턴을 보완합니다. 자세한 내용은 --cvs-exclude 옵션을 참조하십시오. RSYNC_ICONV 이 환경 변수를 사용하여 기본 --iconv 설정을 지정합니다. 3.0.0부터 처음 지원됩니다. RSYNC_OLD_ARGS --old-args 옵션을 기본적으로 활성화하려면 \"1\"을 지정하고, 반복 옵션 상태로 활성화하려면 \"2\" (또는 그 이상)를 지정하거나, 기본적으로 비활성화되도록 하려면 \"0\"을 지정하십시오. 이 환경 변수가 0이 아닌 값으로 설정되면 RSYNC_PROTECT_ARGS 변수를 재정의합니다. 이 변수는 --old-args, --no-old-args 또는 --secluded-args가 명령줄에 지정된 경우 무시됩니다. 3.2.4부터 처음 지원됩니다. RSYNC_PROTECT_ARGS --secluded-args 옵션을 기본적으로 활성화하려면 0이 아닌 숫자 값을 지정하고, 기본적으로 비활성화되도록 하려면 0 값을 지정하십시오. 이 변수는 --secluded-args, --no-secluded-args 또는 --old-args가 명령줄에 지정된 경우 무시됩니다. 3.1.0부터 처음 지원됩니다. 3.2.4부터 이 변수는 RSYNC_OLD_ARGS가 0이 아닌 값으로 설정되면 무시됩니다. RSYNC_RSH 이 환경 변수를 사용하면 rsync의 전송으로 사용되는 기본 셸을 재정의할 수 있습니다. --rsh (-e) 옵션과 마찬가지로 명령 이름 뒤에 명령줄 옵션이 허용됩니다. RSYNC_PROXY 이 환경 변수를 사용하면 rsync 데몬에 연결할 때 rsync 클라이언트가 웹 프록시를 사용하도록 리디렉션할 수 있습니다. RSYNC_PROXY를 hostname:port 쌍으로 설정해야 합니다. RSYNC_PASSWORD 이 환경 변수를 사용하면 rsync 데몬 연결에 대한 암호를 설정하여 암호 프롬프트를 피할 수 있습니다. 이는 ssh와 같은 원격 셸 전송에 암호를 제공하지 않는다는 점에 유의하십시오 (이를 수행하는 방법은 해당 설명서를 참조하십시오). USER or LOGNAME USER 또는 LOGNAME 환경 변수는 rsync 데몬으로 전송되는 기본 사용자 이름을 결정하는 데 사용됩니다. 둘 다 설정되지 않으면 사용자 이름은 \"nobody\"로 기본값이 지정됩니다. 둘 다 설정된 경우 USER가 우선합니다. RSYNC_PARTIAL_DIR 이 환경 변수는 부분 전송이 활성화되도록 암시하지 않고 --partial 전송에 사용할 디렉토리를 지정합니다. 자세한 내용은 --partial-dir 옵션을 참조하십시오. RSYNC_COMPRESS_LIST 이 환경 변수를 사용하면 대체 순서 또는 축소된 이름 목록을 지정하여 압축 알고리즘 협상을 사용자 정의할 수 있습니다. 사용 가능한 압축 이름을 확인하려면 rsync --version 명령을 사용하십시오. 자세한 내용은 --compress 옵션을 참조하십시오. RSYNC_CHECKSUM_LIST 이 환경 변수를 사용하면 대체 순서 또는 축소된 이름 목록을 지정하여 체크섬 알고리즘 협상을 사용자 정의할 수 있습니다. 사용 가능한 체크섬 이름을 확인하려면 rsync --version 명령을 사용하십시오. 자세한 내용은 --checksum-choice 옵션을 참조하십시오. RSYNC_MAX_ALLOC 이 환경 변수는 --max-alloc 옵션을 사용한 것처럼 할당 최대값을 설정합니다. RSYNC_PORT 이 환경 변수는 rsync에 의해 읽히지 않지만, rsync가 원격 셸을 데몬 연결과 함께 실행할 때 하위 환경에 설정됩니다. 이를 통해 rsync-ssl과 같은 스크립트가 명령줄에 사용자가 지정한 포트 번호를 알 수 있습니다. HOME 이 환경 변수는 사용자의 기본 .cvsignore 파일을 찾는 데 사용됩니다. RSYNC_CONNECT_PROG 이 환경 변수는 주로 디버그 설정에서 데몬 연결을 할 때 사용할 프로그램을 설정하는 데 사용됩니다. 자세한 내용은 CONNECTING TO AN RSYNC DAEMON을 참조하십시오. RSYNC_SHELL 이 환경 변수는 주로 디버그 설정에서 RSYNC_CONNECT_PROG에 의해 지정된 프로그램을 실행하는 데 사용할 프로그램을 설정하는 데 사용됩니다. 자세한 내용은 CONNECTING TO AN RSYNC DAEMON을 참조하십시오. FILES /etc/rsyncd.conf 또는 rsyncd.conf SEE ALSO rsync-ssl(1), rsyncd.conf(5), rrsync(1) BUGS o 시간은 *nix time_t 값으로 전송됩니다. o FAT 파일 시스템으로 전송할 때 rsync가 수정되지 않은 파일을 다시 동기화할 수 있습니다. --modify-window 옵션에 대한 설명을 참조하십시오. o 파일 권한, 장치 등은 원시 숫자 값으로 전송됩니다. o --delete 옵션에 대한 설명도 참조하십시오. 버그를 보고해 주십시오! 웹 사이트 https://rsync.samba.org/를 참조하십시오. VERSION 이 맨페이지는 rsync 버전 3.2.7에 대한 것입니다. INTERNAL OPTIONS --server 및 --sender 옵션은 rsync 내부적으로 사용되며, 정상적인 상황에서는 사용자가 직접 입력해서는 안 됩니다. 이러한 옵션에 대한 인식이 특정 시나리오, 예를 들어 rsync 명령만 실행할 수 있는 로그인을 설정할 때 필요할 수 있습니다. 예를 들어, rsync 배포판의 support 디렉토리에는 rrsync (제한된 rsync)라는 예시 스크립트가 있으며, 제한된 ssh 로그인과 함께 사용할 수 있습니다. CREDITS Rsync는 GNU General Public License에 따라 배포됩니다. 자세한 내용은 COPYING 파일을 참조하십시오. rsync 웹 사이트는 https://rsync.samba.org/에서 사용할 수 있습니다. 이 사이트에는 이 설명서 페이지에서 다루지 않은 질문에 답할 수 있는 FAQ-O-Matic이 포함되어 있습니다. rsync github 프로젝트는 https://github.com/WayneD/rsync입니다. 이 프로그램을 좋아하신다면 기꺼이 여러분의 의견을 듣겠습니다. rsync@lists.samba.org 메일링 리스트로 연락주십시오. 이 프로그램은 Jean-loup Gailly와 Mark Adler가 작성한 훌륭한 zlib 압축 라이브러리를 사용합니다. THANKS 특별히 John Van Essen, Matt McCutchen, Wesley W. Terpstra, David Dykstra, Jos Backus, Sebastian Krahmer, Martin Pool, 그리고 우리를 떠났지만 잊혀지지 않을 동지 J.W. Schultz에게 감사드립니다. Richard Brent, Brendan Mackay, Bill Waite, Stephen Rothwell, David Bell에게도 감사드립니다. 몇몇 분들을 놓쳤을 수도 있습니다. 죄송합니다. AUTHOR Rsync는 원래 Andrew Tridgell과 Paul Mackerras가 작성했습니다. 많은 사람들이 나중에 기여했습니다. 현재 Wayne Davison이 유지 관리하고 있습니다. 지원 및 개발을 위한 메일링 리스트는 https://lists.samba.org/에서 사용할 수 있습니다. rsync 3.2.7 2022년 10월 20일 rsync(1)"},"title":"무제 7"},"/%EB%AC%B4%EC%A0%9C-9/":{"data":{"":"generate_file_structure.py 로 파일 구조를 만들었어 클라이언트 사이드 렌더링 방식으로 github page 에 정적파일을 호스팅 하고 싶어 md 들이 잘 보이도록 index.html style.css script.js generate_file_structure.py file_structure.json (파이썬으로 만들어짐) 이렇게 4개의 파일을 만들어줘\n디자인 : tailwind 를 사용해 디자인은 너가 알아서 정해 멋진데 가독성이 좋도록 단 좌측은\n마크다운 렌더링 : 라이브러리는 자율롭게 사용하되 현재 모든 마크다운은 상단에 frontmatter 가 위치하고 있어\n기능 : 검색기능\nsprin"},"title":"무제 9"},"/%EB%AC%B4%EC%A0%9C/":{"data":{"":"","1-학교-서버-부하-및-ip-차단-가능성#1. 학교 서버 부하 및 IP 차단 가능성":"가장 먼저 고려해야 할 문제입니다. 사용자가 페이지에 머무는 동안 계속해서 새로고침 요청을 보내는 것은 학교 서버에 상당한 부하를 줄 수 있습니다.\n문제 상세: 짧은 주기로(예: 1초마다) 페이지를 계속 새로고침하면, 학교 서버는 비정상적인 트래픽(DDoS 공격 등)으로 간주할 수 있습니다. 이로 인해 해당 사용자의 IP가 일시적 또는 영구적으로 차단될 위험이 있습니다. 해결 방안: 요청 주기 조절: 새로고침 주기를 너무 짧지 않게 설정하는 것이 중요합니다. 3~5초 정도의 ‘안전한’ 기본값을 설정하고, 사용자가 직접 주기를 조절할 수 있도록 하되 너무 짧게 설정할 경우 경고 메시지를 띄워주는 것이 좋습니다. 랜덤한 요청 간격: 매번 고정된 시간(예: 정확히 3초)으로 요청을 보내기보다는, 약간의 무작위 시간(예: 3초~4초 사이)을 추가하여 좀 더 사람처럼 보이게 만들 수 있습니다. 탭 활성화 시에만 작동: 크롬 확장 프로그램의 기능 중, 해당 탭이 활성화( 보고 있는) 상태일 때만 새로고침을 실행하고, 다른 탭을 보고 있을 때는 중지시키는 로직을 추가하여 불필요한 요청을 줄일 수 있습니다.","2-크롤링스크래핑의-기술적-문제#2. 크롤링(스크래핑)의 기술적 문제":"수강신청 페이지의 구조는 생각보다 복잡할 수 있습니다.\n문제 상세: 요즘 웹사이트는 JavaScript를 통해 동적으로 데이터를 불러오는 경우가 많습니다. 단순히 페이지를 새로고침하고 HTML을 분석하는 것만으로는 원하는 데이터를 얻지 못할 수 있습니다. 학교 측에서 크롤링을 막기 위한 기술(예: Captcha, 특정 패턴의 접근 차단 등)을 적용했을 수 있습니다. 해결 방안: DOM 직접 분석: 크롬 확장 프로그램은 현재 페이지의 DOM(Document Object Model)에 직접 접근할 수 있다는 막강한 장점이 있습니다. 페이지를 새로고침한 후, content script를 이용해 렌더링이 완료된 페이지의 특정 요소(원하는 과목의 인원 표시 부분 등)를 직접 찾아 읽는 방식이 가장 안정적입니다. document.querySelector 와 같은 표준 기술을 사용하면 됩니다. MutationObserver 사용: 페이지 전체를 새로고침하는 대신, 특정 부분의 변화만 감지하는 MutationObserver API를 활용할 수도 있습니다. 이는 서버 부하를 줄이면서 더 효율적으로 변화를 감지하는 방법이 될 수 있지만, 수강신청 페이지 구조에 따라 적용 가능 여부가 달라집니다.","3-사용자-경험ux-측면의-문제#3. 사용자 경험(UX) 측면의 문제":"이 서비스는 사용자의 특정 행동을 전제로 작동합니다.\n문제 상세: 사용자가 컴퓨터를 켜고, 크롬 브라우저를 열고, 수강신청 페이지에 접속해 있어야만 알림을 받을 수 있습니다. 24시간 감시가 불가능한 명확한 한계가 있습니다. 알림 방식이 명확하지 않으면 사용자가 빈자리가 난 것을 놓칠 수 있습니다. 해결 방안: 명확한 한계 고지: 확장 프로그램 설명에 “이 프로그램은 수강신청 페이지를 열어두고 있을 때만 작동합니다” 와 같이 서비스의 제약 조건을 명확히 알려주어 사용자의 기대를 관리해야 합니다. 효과적인 알림: 브라우저의 Notification API를 사용하여 PC 알림을 띄우는 것이 효과적입니다. 이 API는 브라우저가 실행 중이기만 하면 다른 창을 보고 있더라도 알림을 표시할 수 있습니다. 소리 알림을 추가하는 것도 좋은 방법입니다. 직관적인 UI: 사용자가 감시할 과목을 쉽게 추가/삭제하고, 감시 시작/중지 버튼, 현재 작동 상태 등을 명확히 볼 수 있는 간단하고 직관적인 UI를 제공해야 합니다.","기획의-적절성-평가#기획의 적절성 평가":"결론부터 말씀드리면, 매우 적절하고 현실적인 기획입니다.","나의-질문#나의 질문":"https://github.com/allcll/allcll-backend 해당 프로젝트는 사이트의 수강 상태를 크롤링 해서 사용자에게 변경사항이 있을 때 알림을 보내는 프로젝트야 [학교 수강신청 서버] -\u003e [크롤링] -\u003e [백엔드] -\u003e [client] 이렇게 구성되어 있고 각 서버간 통신에서 데이터 정합성을 유지하는 것이 매우 어려워 하지만 해당 프로젝트의 필요성이 느껴저 내가 보기에는 해당 문제로 풀면 너무 복잡하므로 크롬 확장 프로그램을 사용하여 원하는 과목을 지정하고 사용자가 해당 페이지에 있을 때는 계속 갱신하면서 원하는 과목의 빈자리가 생기면 사용자에게 알림을 주는 서비스를 기획하고 싶어 해당 기획이 예상되는 또는 진행하면서 발생할 수 있는 문제가 있을 거 같다면 문제를 이야기해주고 문제를 어떻게 피하는 것이 좋을지 말해줘 또한 기획의 적절성 또한 평가해줘","단점#단점":"제한적인 작동 환경: 앞서 언급했듯, PC가 켜져 있고 브라우저의 특정 페이지가 열려 있어야만 한다는 명확한 한계가 있습니다. 확장성 부재: 다수의 사용자에게 통합된 서비스를 제공하기보다는 ‘개인용 편의 도구’의 성격이 강합니다. 학교 정책에 대한 의존성: 만약 학교에서 수강신청 페이지 구조를 변경하거나 강력한 차단 정책을 도입하면, 확장 프로그램이 무력화될 수 있습니다. 지속적인 유지보수가 필요합니다.","답변-google-gemini#답변 (Google gemini)":"안녕하세요! 제안해주신 아이디어에 대해 말씀드리겠습니다.\n먼저, 기존 백엔드 크롤링 방식의 어려움(특히 데이터 정합성 문제)을 정확히 파악하고, 이를 해결하기 위해 크롬 확장 프로그램이라는 대안을 떠올리신 것은 매우 훌륭한 접근입니다. 기획의 방향성이 매우 현실적이고 영리하다고 생각합니다.\n제안해주신 ‘크롬 확장 프로그램을 이용한 수강신청 빈자리 알림 서비스’에 대한 분석과 발생 가능한 문제, 그리고 해결 방안 및 기획의 적절성을 아래와 같이 정리해 드립니다.","예상되는-문제-및-해결-방안#예상되는 문제 및 해결 방안":"","장점#장점":"높은 개발 타당성 및 속도: 복잡한 백엔드, 데이터베이스, 사용자 관리 시스템을 구축할 필요가 없습니다. 순수하게 프론트엔드(JavaScript, HTML, CSS) 기술만으로 핵심 기능을 빠르게 구현할 수 있습니다. 이는 MVP(최소 기능 제품)를 만들기에 매우 적합합니다. 서버 유지비용 없음: 자체 서버를 운영하지 않으므로, 서버 비용과 관리에 대한 부담이 전혀 없습니다. 데이터 정합성 문제 해결: 사용자의 브라우저가 직접 학교 서버와 통신하므로, 중간 서버에서 발생하는 데이터 불일치(정합성) 문제가 원천적으로 사라집니다. 사용자는 항상 가장 최신 정보를 보게 됩니다.","총평-및-제언#총평 및 제언":"최초에 구상하셨던 백엔드 기반의 서비스는 기능적으로는 더 강력하지만, 개인이 만들고 유지하기에는 기술적, 비용적 부담이 매우 큽니다. 반면, 크롬 확장 프로그램으로의 전환은 핵심 문제(빈자리 알림)에 집중하면서도 개발 및 유지보수 부담을 극적으로 낮추는 스마트한 결정입니다.\n이 기획은 ‘개인용 혹은 소수 그룹을 위한 편리한 도구’로서 매우 큰 가치를 가지며, 성공적으로 구현할 가능성 또한 매우 높습니다.\n먼저 이 버전으로 빠르게 개발하여 사용자들의 반응을 살핀 후, 만약 더 큰 서비스로 확장할 필요성이 느껴진다면 그때 원래 구상하셨던 백엔드 아키텍처 도입을 다시 고려해보는 단계적인 접근 방식을 추천해 드립니다."},"title":"무제"},"/%EB%B0%94%EC%9D%B4%EB%B8%8C-%EC%BD%94%EB%94%A9/":{"data":{"":"본 글은 바이브 코딩뿐만 아니라 모든 ai가 코드에 개입하는 상황과 여러 프로젝트를 경험해보고 느낀 글이다\n소프트웨어 물리적 개입 분류 실시간 ai 자동완성 ex) cursor ex) gemini cli, claude code 개입 정도 따른 분류 초창기 ai 는 autocomplete 형태로 개입되었다(초창기 copliot, TabNine) 2023년 정도 시점\n하지만 시간이 지나면서 cursor 가 나오게 되고 claude code 과 같은 터미널 베이스 로 개입이 되고 있다\n각각 autocomplete,","-선택적-추가-팁#💡 선택적 추가 팁":"SOLID 원칙 전체를 강조하려면, 현재 목록에 OCP, LSP, ISP를 추가하는 것이 자연스럽습니다 (SRP, DIP는 이미 있음). 테스트 용이성, 병렬 처리, 마이크로서비스 아키텍처와 관련된 개념이라면 불변성, DI, Bounded Context가 특히 유용합니다. 함수형 프로그래밍과 접목한다면 CQS, 불변성, 명시적 인터페이스가 중요해집니다.","autocomplete-기반-개입--최소-개입#autocomplete 기반 개입 : 최소 개입":"최소 개입","관련-링크#관련 링크":"이해 부채: LLM이 만든 코드가 남기는 시한폭탄\n=\u003e https://news.hada.io/topic?id=23384\nAI 에이전트를 위한 효과적 컨텍스트 엔지니어링 =\u003e https://news.hada.io/topic?id=23483","단순히-어떤-앱을-만들어라고-명령-전부-llm#단순히 어떤 앱을 만들어라고 명령 전부 llm":"ai 가 생성한 코드가 이상하더라도 치명적일 수 없도록 권한을 통제한다\n생성시 정확한 가이드라인을 제시 생성시","소프트-웨어-공학-용어들#소프트 웨어 공학 용어들":"SSoT (Single Source of Truth, 단일 진실 공급원)\n정의: 시스템 내 특정 데이터는 오직 하나의 권위 있는 출처에서만 관리되고 갱신된다.\n목적: 데이터 중복, 불일치, 오류를 방지하고 일관성과 신뢰성을 확보한다.\n응집도 (Cohesion)\n정의: 모듈 내부 요소들이 하나의 목적 또는 책임을 위해 얼마나 긴밀하게 연결되어 있는가.\n목적: 유지보수성, 재사용성, 테스트 용이성을 높이기 위해 응집도를 최대화한다.\n결합도 (Coupling)\n정의: 두 모듈 간의 의존 정도, 즉 한 모듈이 다른 모듈의 변경에 얼마나 영향을 받는가.\n목적: 결합도를 낮춰(느슨한 결합) 시스템의 유연성과 유지보수성을 향상시킨다.\n관심사의 분리 (Separation of Concerns, SoC)\n정의: 시스템을 서로 다른 책임 또는 관심사 단위로 분리하여 설계하는 원칙.\n목적: 각 구성 요소의 역할을 명확히 해 가독성, 확장성, 재사용성을 높인다.\n단일 책임 원칙 (Single Responsibility Principle, SRP)\n정의: 클래스나 함수는 오직 하나의 변경 이유만 가져야 한다.\n목적: 변경의 영향 범위를 좁혀 코드의 안정성과 유지보수성을 높인다.\nDRY 원칙 (Don’t Repeat Yourself)\n정의: 동일한 지식, 로직, 정보를 시스템 내에서 중복하지 말라.\n목적: 중복으로 인한 오류와 유지보수 비용을 줄이고 일관성을 유지한다.\nKISS 원칙 (Keep It Simple, Stupid)\n정의: 시스템은 가능한 한 단순하게 설계되어야 한다.\n목적: 불필요한 복잡도를 제거해 이해와 유지보수를 쉽게 한다.\nYAGNI 원칙 (You Aren’t Gonna Need It)\n정의: 현재 필요하지 않은 기능은 구현하지 말라.\n목적: 과도한 설계(Over-engineering)를 방지하고 개발 속도와 유연성을 높인다.\n의존성 역전 원칙 (Dependency Inversion Principle, DIP)\n정의: 상위 모듈은 하위 모듈에 의존하지 않고, 양쪽 모두 추상화(인터페이스)에 의존해야 한다.\n목적: 결합도를 낮추고, 테스트 용이성 및 확장성을 높인다.\n횡단 관심사 (Cross-cutting Concerns)\n정의: 로깅, 보안, 트랜잭션 등 여러 모듈에 걸쳐 반복되는 공통 기능.\n목적: SoC를 유지하기 위해 AOP, 데코레이터, 미들웨어 등을 활용해 분리한다.\n모듈화 (Modularity)\n정의: 시스템을 독립적이고 교체 가능한 단위(모듈)로 분할하는 설계 방식.\n목적: 재사용성, 병렬 개발, 테스트 용이성 및 유지보수성을 향상시킨다.\n명령-쿼리 분리 원칙 (Command-Query Separation, CQS)\n정의: 메서드는 명령(상태를 변경) 또는 쿼리(값을 반환) 중 하나만 수행해야 하며, 둘 다 하면 안 된다.\n목적: 부작용을 명확히 분리해 코드의 예측 가능성과 테스트 용이성을 높인다.\n의존성 주입 (Dependency Injection, DI)\n정의: 객체가 스스로 의존성을 생성하지 않고, 외부에서 주입받는 설계 패턴.\n목적: 결합도를 낮추고, 유닛 테스트와 모듈 교체를 쉽게 하며 DIP를 실현한다.\n계약에 의한 설계 (Design by Contract, DbC)\n정의: 함수나 메서드가 사전조건(Precondition), 사후조건(Postcondition), 불변조건(Invariant)을 명시적으로 정의하는 방식.\n목적: 인터페이스의 명확한 계약을 통해 오류를 조기에 발견하고 신뢰성을 높인다.\n정보 은닉 (Information Hiding)\n정의: 모듈 내부 구현 세부사항을 외부에 노출하지 않고, 인터페이스만 공개하는 원칙.\n목적: 구현 변경이 외부에 영향을 주지 않도록 하여 유지보수성과 안정성을 확보한다.\n리스코프 치환 원칙 (Liskov Substitution Principle, LSP)\n정의: 서브타입은 언제나 기반 타입으로 대체 가능해야 하며, 프로그램의 정확성을 해쳐서는 안 된다.\n목적: 상속 구조의 안정성과 예측 가능성을 보장하여 다형성을 안전하게 사용할 수 있게 한다.\n인터페이스 분리 원칙 (Interface Segregation Principle, ISP)\n정의: 클라이언트는 자신이 사용하지 않는 인터페이스 메서드에 의존하지 않아야 한다.\n목적: 불필요한 의존을 줄이고, 인터페이스를 작고 목적에 맞게 분리해 유연한 설계를 가능하게 한다.\n불변성 (Immutability)\n정의: 객체가 생성된 후 상태를 변경할 수 없도록 설계하는 원칙.\n목적: 동시성 안정성, 부작용 방지, 디버깅 용이성, 캐시 가능성 향상.\n명시적 인터페이스 (Explicit Interface)\n정의: 의도를 명확히 드러내는 이름과 시그니처를 가진 인터페이스를 설계하는 방식.\n목적: 코드의 자기 문서화(self-documenting)를 통해 가독성과 협업 효율성을 높인다.\n컨텍스트 경계 (Bounded Context) — 도메인 주도 설계(DDD)에서\n정의: 도메인 모델이 일관된 의미와 규칙을 갖는 하나의 경계된 영역.\n목적: 복잡한 시스템에서 모델의 명확성과 일관성을 유지하고, 마이크로서비스 간 경계를 정의한다.","틀을-사람이-짜고-각-컴포넌트와-같은-것을-llm-으로#틀을 사람이 짜고 각 컴포넌트와 같은 것을 llm 으로":"웹 프론트의 (router.js, eventBus.js), 웹 백엔드 (application.propertices, interface) 와 같은 어플리케이션에 광범위한 영향을 줄수 있는 것을 사람이 통제한다","틀을-자연어-문서markdown-로-만들고-전부-llm-으로#틀을 자연어 문서(markdown) 로 만들고 전부 llm 으로":""},"title":"바이브 코딩"},"/%EC%88%98%EC%8B%9D-%ED%85%8C%EC%8A%A4%ED%8A%B8/":{"data":{"복잡한-수식#복잡한 수식":"오일러의 공식:\n$$ e^{i\\pi} + 1 = 0 $$\n리만 제타 함수:\n$$ \\zeta(s) = \\sum_{n=1}^{\\infty} \\frac{1}{n^s} $$","블록-수식#블록 수식":"가우스 정규분포:\n$$ f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2} $$\n적분:\n$$ \\int_{-\\infty}^{\\infty} e^{-x^2} dx = \\sqrt{\\pi} $$\n행렬:\n$$ \\begin{pmatrix} a \u0026 b \\ c \u0026 d \\end{pmatrix} $$","수식-테스트-문서#수식 테스트 문서":"수식 테스트 문서이 문서는 KaTeX 수식 렌더링을 테스트하기 위한 문서입니다.","수식과-텍스트의-혼합#수식과 텍스트의 혼합":"변수 $x$가 주어졌을 때, 함수 $f(x) = x^2 + 2x + 1$의 도함수는 다음과 같습니다:\n$$ f’(x) = \\frac{d}{dx}(x^2 + 2x + 1) = 2x + 2 $$\n따라서 $x = 1$에서의 기울기는 $f’(1) = 4$입니다.","인라인-수식#인라인 수식":"여기서 $x = 2$ 는 간단한 인라인 수식입니다.\n피타고라스 정리: $a^2 + b^2 = c^2$\n제곱근: $\\sqrt{x + y}$\n분수: $\\frac{x}{y}$","특수-기호#특수 기호":"그리스 문자: $\\alpha, \\beta, \\gamma, \\delta, \\epsilon, \\zeta, \\eta, \\theta$\n화살표: $\\rightarrow, \\leftarrow, \\leftrightarrow, \\Rightarrow, \\Leftarrow, \\Leftrightarrow$\n집합 기호: $\\in, \\notin, \\subset, \\supset, \\cup, \\cap, \\emptyset$\n논리 기호: $\\land, \\lor, \\neg, \\forall, \\exists$","화학식-katex-확장-기능#화학식 (KaTeX 확장 기능)":"물의 화학식: $\\ce{H2O}$\n메탄 연소 반응: $\\ce{CH4 + 2O2 -\u003e CO2 + 2H2O}$"},"title":"수식 테스트"},"/%EC%8B%A4%EC%8A%B5%EC%9C%BC%EB%A1%9C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EB%A6%AC%EB%88%85%EC%8A%A4-%EA%B5%AC%EC%A1%B0/%EB%A6%AC%EB%88%85%EC%8A%A4-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EA%B8%B0%EB%B3%B8/":{"data":{"":"운영 체제 레벨의 패키지 관리자로는 아래와 같은 것들이 있습니다:\ndnf: Fedora 리눅스에서 사용되는 패키지 관리자로, yum의 최신 버전입니다. pacman: Arch 리눅스에서 사용되는 패키지 관리자입니다. zypper: openSUSE에서 사용되는 패키지 관리자입니다. apt yum brew 프로그래밍 언어 레벨의 패키지 관리자로는 아래와 같은 것들이 있습니다:\ngem: Ruby 언어의 패키지 관리자입니다. composer: PHP 언어의 패키지 관리자입니다. nuget: .NET 언어의 패키지 관리자입니다. maven과 gradle: Java 언어의 패키지 관리자입니다. pip, cargo, npm 시스템 콜의 종류\n﻿﻿프로세스 생성, 삭제 ﻿﻿메모리 확보, 해제 ﻿﻿프로세스 간 통신(IPC) ﻿﻿네트워크 ﻿﻿파일시스템 다루기 ﻿﻿파일 다루기(디바이스 접근) strace : 시스템 호출 목록 확인 os 제공\n﻿﻿시스템 초기화 : init ﻿﻿OS의 동작을 바꿈 : sysctl, nice, Sync ﻿﻿파일 관련 : touch.mkdir ﻿﻿텍스트 데이터 가공 : grep, sort, uniq ﻿﻿성능 측정 : sar, iostat ﻿﻿컴파일러 : gcC ﻿﻿스크립트 언어 실행 환경 : perl, python, ruby ﻿﻿셸 : bash ﻿﻿윈도우 시스템 : X"},"title":"리눅스 시스템 기본"},"/%EC%8B%A4%EC%8A%B5%EC%9C%BC%EB%A1%9C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EB%A6%AC%EB%88%85%EC%8A%A4-%EA%B5%AC%EC%A1%B0/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EA%B5%AC%EC%A1%B0-%ED%8C%8C%EC%95%85%ED%95%98%EA%B8%B0/":{"data":{"":"프로그램의 실행파일로 프로세스를 생성해 프로그램을 돌리는 과정에서 각 과정에서 메모리 구조를 확인할 수 있다","elf-포맷-리눅스-유닉스-계열#ELF 포맷 (리눅스, 유닉스 계열)":"readelf: ELF 포맷의 실행 파일, 오브젝트 파일, 공유 라이브러리 등의 정보를 표시하는 프로그램입니다. 헤더, 섹션 헤더, 프로그램 헤더, 심볼 테이블 등 다양한 정보를 확인할 수 있습니다. 예시 명령어: readelf -h [파일명] (ELF 파일의 헤더 정보 표시) 예시 명령어: readelf -S [파일명] (섹션 헤더 정보 표시) objdump: 오브젝트 파일, 실행 파일, 공유 라이브러리의 정보를 보여주는 프로그램입니다. readelf보다 더 다양한 정보를 제공할 수 있으며, 디스어셈블리 결과도 확인할 수 있습니다. 예시 명령어: objdump -h [파일명] (섹션 헤더 정보 표시) 예시 명령어: objdump -D [파일명] (전체 디스어셈블리)","mach-o-포맷-macos#Mach-O 포맷 (macOS)":"otool: macOS에 포함된 도구로, Mach-O 파일의 정보를 표시합니다. 헤더, 로드 명령, 섹션 정보 등을 확인할 수 있습니다. 예시 명령어: otool -h [파일명] (Mach-O 파일의 헤더 정보 표시) 예시 명령어: otool -l [파일명] (로드 명령 및 섹션 정보 표시)","pe-포맷-windows#PE 포맷 (Windows)":"dumpbin: Microsoft Visual Studio에 포함된 도구로, PE 포맷의 실행 파일, 오브젝트 파일, DLL 등의 정보를 표시합니다. 헤더, 섹션, 익스포트, 임포트 정보 등을 확인할 수 있습니다. 예시 명령어: dumpbin /headers [파일명] (헤더 정보 표시) 예시 명령어: dumpbin /sections [파일명] (섹션 정보 표시) PEview: 그래픽 사용자 인터페이스(GUI)를 제공하는 도구로, PE 파일의 헤더 및 섹션 정보를 쉽게 검토할 수 있습니다.","실행파일#실행파일":"먼저 실행파일이다 실행 파일은 운영체제별 포메멧 별로 다르게 사용되는데 이때 code section 과 data section 은 동일하다 이를 확인하기 위한 방법이 size 명령어이다 하지만 실행 파일의 헤더 및 기타 섹션을 확인하기 위한 방법은 운영 체제와 해당 실행 파일의 포맷(예: ELF, PE, Mach-O 등)에 따라 달라진다 리눅스, 유닉스 계열 시스템에서는 주로 ELF(Executable and Linkable Format) 포맷이 사용되며, Windows에서는 PE(Portable Executable) 포맷, macOS에서는 Mach-O 포맷이 사용된다","프로세스#프로세스":"실행 파일의 code 섹션, data 섹션 크기는 정적으로 미리 정해져 있다 이를 확인하는 것은 size 명령어를 사용하여 정적으로 분석할 수 있습니다. 하지만 프로세스의 코드, 데이터, 힙, 스택 영역을 실시간으로 확인하려면 다른 접근 방법이 필요합니다. 여기서는 리눅스 기반 시스템에서 이를 확인하는 방법을 중심으로 설명하겠습니다.\n/proc 파일 시스템 사용하기: 리눅스에서는 실행 중인 프로세스의 정보를 /proc 파일 시스템을 통해 접근할 수 있습니다. 각 프로세스는 /proc/[pid] 디렉토리에 해당하며, 여기에서는 메모리 맵, 스택, 환경 변수 등 다양한 정보를 확인할 수 있습니다.\n/proc/[pid]/maps: 이 파일은 프로세스의 메모리 맵을 보여줍니다. 코드, 데이터, 힙, 스택 영역의 주소 범위와 권한을 확인할 수 있습니다.\n/proc/[pid]/stat: 프로세스의 상태, 메모리 사용량 등 다양한 통계 정보를 제공합니다.\n사용 예:\ncat /proc/[pid]/maps # 메모리 맵 확인 cat /proc/[pid]/stat # 프로세스 상태 확인 시스템 모니터링 도구 사용하기: top, htop, ps, pmap 등 다양한 시스템 모니터링 도구를 사용하여 프로세스의 메모리 사용량과 상태를 실시간으로 확인할 수 있습니다.\ntop 또는 htop: 시스템에서 실행 중인 프로세스의 목록을 실시간으로 보여주며, CPU와 메모리 사용량을 확인할 수 있습니다. ps: 프로세스의 스냅샷을 보여줍니다. 특정 프로세스의 정보를 확인할 때 사용합니다. pmap [pid]: 특정 프로세스의 메모리 맵을 보여줍니다. 코드, 데이터, 힙, 스택 영역의 메모리 사용량을 확인할 수 있습니다. 디버깅 도구 사용하기: gdb 같은 디버거를 사용하여 프로세스를 분석할 수도 있습니다. 프로세스를 디버깅 세션에 연결하면, 코드, 데이터, 힙, 스택 영역의 상세 정보를 실시간으로 확인하고 분석할 수 있습니다.\n사용 예:\ngdb -p [pid] # 실행 중인 프로세스에 대한 디버깅 세션 시작 디버깅 세션 내에서는 다양한 명령어를 사용하여 메모리의 내용을 확인하고 분석할 수 있습니다.\n%20image%2020240328041330.png)"},"title":"프로그램 메모리 구조 파악하기"},"/%EC%8B%A4%EC%8A%B5%EC%9C%BC%EB%A1%9C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EB%A6%AC%EB%88%85%EC%8A%A4-%EA%B5%AC%EC%A1%B0/%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4-%EC%83%9D%EC%84%B1/":{"data":{"":"프로세스는 두가지 목적으로 생성한다\nfork() : 다중 프로세스 프로그램 사용 =\u003e 현재 프로세스의 메모리 복사 다른 프로세스로 등록 execve() : 다른 프로그램 실행용( bash 에서 실행할 때 ) =\u003e 현재 프로세스의 메모리를 새로운 프로세스의 메모리로 덮어 쓴다 프로세스가 운영체제에게 부여받은 메모리 구조","실행파일#실행파일":"실행파일은 리눅스에서는 ELF (excutable linkable format) 형식이며 \breadelf -h {실행파일 명} readelf -S {실행파일 명} 으로 사용 가능하다"},"title":"프로세스 생성"},"/%EC%8B%A4%EC%8A%B5%EC%9C%BC%EB%A1%9C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EB%A6%AC%EB%88%85%EC%8A%A4-%EA%B5%AC%EC%A1%B0/05.%EB%A9%94%EB%AA%A8%EB%A6%AC-%EA%B4%80%EB%A6%AC/":{"data":{"":"","free#free":"%20image%2020240919163385.png) 강제로 프로세스를 종료하여 메모리를 확보하는 OOM-Killer 라는 기능이 있다 서버에는 위의 일이 일어나지 않도록 sysctl 의 vm.panic_on_oom 파라미터의 기본값을 변경하여 메모리 부족시 시스템을 종료하게 하는 방법이 있다"},"title":"05.메모리 관리"},"/%EC%98%81%EC%96%B4-%ED%8C%8C%ED%8A%B8%EB%84%88-%EC%B1%97-%EC%A7%88%EB%AC%B8%EC%A7%80-%EB%AA%A9%EB%A1%9D/":{"data":{"":"What is something you are mad about?\nI really enjoy getting enough sleep. why\nif i get enough sleep and wake up I feel great the next day. What kind of person are you?\nActually, I’m not sure exactly what kind of person I am yet, but I know that what I want to be, i went to be easygoing! because Being too serious feels exhausting. sometime i asked for me Could I become more relaxed? It might take time, but I think it’s worth it. When was the last time you felt happy or angry? Can you tell me about it?\nYesterday! It was the weekend, so I spent the whole day sleeping. I felt happy just being lazy. Thank goodness for rest—I think that’s something we all need. What’s it gonna take for the good life?\nI hate having to hurry because of unexpected things. i think good life means staying calm and peaceful most of the time, without constant interruptions.\nI don’t think money is directly but it still seems like a pretty important factor. what do you think about that?\nmoney isn’t everything, but having at least the minimum is essential. but It doesn’t create happiness, it helps avoid stress—so it matters, just not as the main thing.\nIs there someone you know who seems to be living a really good life? If so, tell me about them!\nYes! It’s my friend. He’s really good at keeping stress low because he sees himself objectively—never letting emotions take over. Happiness just seems to come easily to him. I don’t want to be exactly, but I’d love to have that mindset—and honestly, it’s something that can be learned."},"title":"영어 파트너 챗 질문지 목록"},"/%EC%BD%94%EC%96%B4-%EB%8D%A4%ED%94%84core-dump/":{"data":{"":"","1-코어core-라는-이름의-유래#1. \u0026ldquo;코어(Core)\u0026rdquo; 라는 이름의 유래":"이름이 조금 생소할 수 있습니다. “코어\"라는 단어는 현대의 CPU 코어를 의미하는 것이 아닙니다. 이는 아주 오래전, 컴퓨터의 주기억장치로 **자기 코어 메모리(Magnetic Core Memory)**를 사용하던 시절에서 유래했습니다. 당시 메모리의 내용을 파일로 ‘쏟아낸다(dump)‘는 의미에서 ‘코어 덤프’라는 용어가 탄생했고, 메모리 기술이 반도체로 바뀐 지금까지도 그 이름이 그대로 사용되고 있습니다.","2-코어-덤프는-언제-생성되나요#2. 코어 덤프는 언제 생성되나요?":"코어 덤프는 주로 프로그램이 심각한 오류를 만나 더 이상 실행을 계속할 수 없을 때, 운영체제(커널)에 의해 생성됩니다. 앞서 살펴본 신호(Signal) 목록에서 “Default Action\"이 create core image 또는 Core로 표시된 신호를 받았을 때가 바로 그 경우입니다.\n대표적인 예시는 다음과 같습니다.\nSIGSEGV (Segmentation Violation): 허용되지 않은 메모리 영역에 접근하려고 할 때 (가장 흔한 원인). SIGILL (Illegal Instruction): CPU가 이해할 수 없는 잘못된 명령어를 실행하려고 할 때. SIGFPE (Floating-Point Exception): 0으로 나누는 등 잘못된 부동소수점 연산을 수행할 때. SIGABRT (Abort): 프로그램이 스스로 abort() 함수를 호출하여 비정상 종료를 선택했을 때. SIGQUIT (Quit): 사용자가 의도적으로 디버깅을 위해 Ctrl+\\ 키를 눌러 코어 덤프를 생성하며 종료시키고자 할 때. 반면, SIGTERM이나 SIGINT(Ctrl+C) 같은 신호는 프로그램에게 “정리하고 정상적으로 종료하라\"고 요청하는 신호이므로, 기본적으로는 코어 덤프를 생성하지 않습니다.","3-코어-덤프-파일에는-무엇이-들어있나요#3. 코어 덤프 파일에는 무엇이 들어있나요?":"코어 덤프 파일은 단순한 텍스트 파일이 아니라, 특정 구조를 가진 바이너리 파일입니다. 여기에는 오류 분석에 필요한 거의 모든 정보가 담겨 있습니다.\n프로세스 메모리 이미지 (Process Memory Image):\n스택(Stack): 함수 호출 기록, 지역 변수 등의 정보가 담겨 있습니다. 충돌이 발생한 지점까지 어떤 함수들이 어떤 순서로 호출되었는지 추적하는 데 결정적입니다. 힙(Heap): 동적으로 할당된 메모리 영역의 데이터가 들어있습니다. 전역 변수(Global Variables) 및 정적 변수(Static Variables): 프로그램 전역에서 사용되는 변수들의 마지막 상태를 알 수 있습니다. CPU 레지스터 상태 (CPU Registers Status):\n프로그램 카운터 (Program Counter, PC 또는 IP): 오류가 발생한 정확한 코드 라인(기계어 명령어 주소)을 가리킵니다. 스택 포인터 (Stack Pointer, SP): 현재 스택의 최상단 위치를 가리킵니다. 범용 레지스터 (General-Purpose Registers): 연산에 사용되던 값들이 그대로 저장되어 있어, 오류 직전의 계산 상태를 파악할 수 있습니다. 프로세스 상태 정보:\n프로세스 ID(PID), 사용자 ID(UID) 등 프로세스 기본 정보. 코어 덤프를 유발한 신호(Signal)의 번호.","4-코어-덤프의-주된-용도-사후-분석-디버깅-post-mortem-debugging#4. 코어 덤프의 주된 용도: 사후 분석 디버깅 (Post-mortem Debugging)":"코어 덤프의 존재 이유는 단 하나, **“사후 분석 디버깅”**을 위해서입니다.\n프로그램이 고객 환경이나 운영 서버처럼 개발 환경이 아닌 곳에서 예기치 않게 죽었을 때, 개발자는 실시간으로 디버깅을 할 수 없습니다. 이때 서버에 남겨진 코어 덤프 파일을 가져오면, 마치 프로그램이 방금 죽은 그 순간으로 시간을 되돌려 현장을 조사하는 것처럼 디버깅을 할 수 있습니다.\n주로 **gdb(GNU Debugger, Linux에서 주로 사용)**나 **lldb(LLVM Debugger, macOS에서 주로 사용)**와 같은 디버거를 사용하여 코어 덤프 파일을 분석합니다.\n예를 들어, 다음과 같은 명령어로 분석을 시작할 수 있습니다.\n# gdb \u003c실행 파일\u003e \u003c코어 덤프 파일\u003e gdb ./my_program core 디버거로 코어 덤프를 열면 개발자는 다음과 같은 강력한 분석을 할 수 있습니다.\n백트레이스(Backtrace) 확인: bt 명령어를 통해 프로그램이 어떤 함수 호출 순서를 거치다가 죽었는지 한눈에 파악할 수 있습니다. (가장 먼저 하는 일) 변수 값 확인: 특정 시점의 변수들이 어떤 값을 가지고 있었는지 확인할 수 있습니다. 메모리 상태 조사: 특정 메모리 주소에 어떤 데이터가 있었는지 직접 들여다볼 수 있습니다. 레지스터 값 확인: CPU 레지스터 값을 통해 저수준의 연산 상태를 분석할 수 있습니다.","5-실용적인-정보-및-주의사항#5. 실용적인 정보 및 주의사항":"파일 크기: 코어 덤프는 프로세스가 사용하던 메모리 전체를 저장하므로, 파일 크기가 매우 클 수 있습니다 (수백 MB ~ 수십 GB). 이 때문에 기본적으로 시스템에서 코어 덤프 생성이 비활성화되어 있는 경우가 많습니다. 활성화 방법: 쉘에서 ulimit -c unlimited 명령어를 사용하면 현재 세션에서 코어 덤프 파일 크기 제한을 풀어 생성을 활성화할 수 있습니다. (ulimit -c 0은 비활성화) 보안: 코어 덤프 파일에는 메모리의 모든 내용, 즉 비밀번호, 개인 키, 고객 정보 등 매우 민감한 데이터가 평문으로 포함될 수 있습니다. 따라서 코어 덤프 파일은 매우 신중하게 관리해야 하며, 외부 유출에 각별히 주의해야 합니다. 파일 이름 및 위치: 생성되는 코어 덤프 파일의 이름은 보통 core 또는 core.[PID] 형식이며, 파일의 이름과 저장 위치는 운영체제 설정을 통해 변경할 수 있습니다 (Linux의 경우 /proc/sys/kernel/core_pattern).","요약#요약":"코어 덤프는 프로그램의 비정상 종료 시점의 메모리 상태, 레지스터 값 등을 담고 있는 파일로, ‘사후 분석 디버깅’을 위한 핵심적인 단서입니다. 이를 통해 개발자는 재현하기 어려운 버그의 원인을 정확하고 효율적으로 찾아낼 수 있습니다.","코어-덤프core-dump란-무엇인가---프로세스의-마지막-순간을-담은-사진#코어 덤프(Core Dump)란 무엇인가? - \u0026ldquo;프로세스의 마지막 순간을 담은 사진\u0026rdquo;":"코어 덤프(Core Dump)는 프로그래밍과 시스템 관리에서 매우 중요한 개념입니다. 가장 쉽게 비유하자면, **코어 덤프는 특정 프로그램(프로세스)이 비정상적으로 종료되는 바로 그 순간의 메모리 상태를 그대로 찍어 저장한 “스냅샷 파일”**입니다. 마치 비행기 사고 시 원인 분석을 위해 블랙박스를 회수하는 것과 같습니다."},"title":"코어 덤프(Core Dump)"},"/%ED%81%B4%EB%9D%BC%EC%9D%B4%EC%96%B8%ED%8A%B8-%EC%96%B4%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%EA%B5%AC%EC%A1%B0-%EB%B3%80%ED%99%94/":{"data":{"":"","1-핵심-구조#\u003cstrong\u003e1. 핵심 구조\u003c/strong\u003e":"이 시대의 구조는 ‘구조가 없는 것’이 특징입니다. 구성 요소는 단 두 가지뿐입니다.\nUI 요소 (View): CreateWindow(), gtk_button_new() 같은 API를 통해 프로그래밍 방식으로 생성된 버튼, 텍스트 상자 등의 화면 요소. 콜백 함수 (Callback Function): 특정 UI 요소에서 특정 이벤트(클릭, 키 입력 등)가 발생했을 때 운영체제나 GUI 시스템에 의해 호출되도록 등록된 함수. 사실상 모든 로직이 이 함수 안에 담깁니다. 이 구조에는 역할 분리라는 개념이 존재하지 않습니다. 모든 것은 ‘이벤트가 발생하면 이 함수를 실행하라’는 단순한 명제로 귀결됩니다.","1-핵심-구조-1#\u003cstrong\u003e1. 핵심 구조\u003c/strong\u003e":"Model: 애플리케이션의 데이터와 비즈니스 로직을 담당합니다. 데이터가 무엇인지, 어떻게 저장되고 처리되는지에 대한 규칙을 포함합니다. (예: User 객체, AuthService 클래스) View: 사용자에게 보여지는 UI 요소를 담당합니다. (예: iOS의 UIView, 안드로이드의 XML Layout과 View 객체들) 사용자의 입력을 감지하여 Controller에게 전달하는 역할을 합니다. Controller: Model과 View 사이의 중재자입니다. View로부터 사용자 입력을 받아 Model에 변경을 요청하고, Model의 데이터가 변경되면 그 결과를 가져와 View에 어떻게 표시할지 결정합니다.","1-핵심-구조-2#\u003cstrong\u003e1. 핵심 구조\u003c/strong\u003e":"Model: MVC와 동일합니다. View: 이제 완전히 수동적이고 ‘멍청한(Dumb)’ 존재가 됩니다. 자신의 역할은 오직 화면을 그리고, 사용자 이벤트를 Presenter에게 전달하는 것뿐입니다. View는 로직을 갖지 않습니다. 중요한 점은, View가 지켜야 할 규칙(인터페이스/프로토콜)을 구현한다는 것입니다. (안드로이드의 Activity/Fragment, iOS의 UIViewController가 이 역할을 수행합니다.) Presenter: View와 Model 사이의 진정한 중재자. 모든 프레젠테이션 로직(데이터를 어떻게 보여줄지 결정하는 로직)을 담당합니다. 가장 큰 특징은 Presenter가 View의 구체적인 클래스를 전혀 알지 못하고, 오직 View가 구현한 인터페이스에만 의존한다는 것입니다. 이 덕분에 Presenter는 UI 프레임워크로부터 완벽하게 독립될 수 있습니다.","1-핵심-구조-3#\u003cstrong\u003e1. 핵심 구조\u003c/strong\u003e":"Model: MVC, MVP와 동일합니다. View: 화면 UI를 담당합니다. 가장 큰 특징은 더 이상 수동적으로 명령을 기다리지 않고, ViewModel의 상태(State)를 구독(Observe)하고 있다가, 상태가 변경되면 스스로 UI를 갱신한다는 점입니다. ViewModel: ‘View를 위한 Model’이라는 의미로, View와 Model 사이의 중재자입니다. View에 표시될 모든 상태(예: 사용자 이름 텍스트, 버튼 활성화 여부)와 View가 실행할 로직(커맨드, 예: 로그인 버튼 클릭 시 실행할 로직)을 가집니다. 가장 혁신적인 부분은 ViewModel은 View의 존재 자체를 전혀 알지 못한다는 것입니다. ViewModel은 그저 자신의 상태를 변경할 뿐, 이 변화가 어떻게 UI에 반영될지는 신경 쓰지 않습니다.","2-동작-방식#\u003cstrong\u003e2. 동작 방식\u003c/strong\u003e":"개발자는 화면에 필요한 UI 요소들을 코드로 생성하고 배치합니다. 각 UI 요소의 특정 이벤트(예: login_button의 clicked 이벤트)에 처리 함수(on_login_button_clicked)를 직접 연결(등록)합니다. 사용자가 버튼을 클릭하면, GUI 시스템은 등록된 콜백 함수를 호출합니다. (문제의 지점) 호출된 콜백 함수 내부에서 관련된 모든 작업이 순서 없이, 구분 없이 일어납니다. 다른 View에서 데이터 읽기: 아이디 입력창(email_entry)과 비밀번호 입력창(password_entry)에서 텍스트 값을 직접 가져옵니다. 비즈니스 로직 수행: 가져온 값으로 유효성을 검사하거나, 데이터베이스에 접근하거나, 네트워크 요청을 보내는 등의 핵심 로직을 실행합니다. 다른 View의 상태 변경: 로직 처리 결과에 따라, 상태 메시지를 표시하는 레이블(status_label)의 텍스트를 바꾸거나, 다른 버튼을 비활성화시키는 등 화면의 다른 부분들을 직접 제어합니다.","2-동작-방식-1#\u003cstrong\u003e2. 동작 방식\u003c/strong\u003e":"사용자가 View(예: 로그인 버튼)를 터치합니다. View는 이벤트를 감지하고 이를 Controller에게 전달합니다. (예: @IBAction 메소드 호출) Controller는 이벤트에 맞는 로직을 수행하기 위해 Model에게 데이터 처리를 요청합니다. (예: authService.login(...) 호출) Model은 비즈니스 로직을 수행하고, 그 결과를 Controller에게 돌려줍니다. (예: 로그인 성공/실패 결과 반환) (문제의 지점) Controller는 Model로부터 받은 데이터를 가공하여 직접 View 객체의 속성을 변경함으로써 화면을 업데이트합니다. (예: nameLabel.text = \"홍길동\", loginButton.isEnabled = true)","2-동작-방식-2#\u003cstrong\u003e2. 동작 방식\u003c/strong\u003e":"사용자가 View(버튼)를 터치합니다. View는 어떤 로직도 수행하지 않고, 자신이 소유한 Presenter의 메소드를 호출하여 이벤트를 그대로 전달합니다. (presenter.loginButtonTapped()) Presenter는 Model에게 데이터를 요청하고 결과를 받습니다. Presenter는 받은 데이터를 가공하여 View에 어떻게 표시할지 결정합니다. Presenter는 자신이 알고 있는 View 인터페이스의 메소드를 호출하여 View에게 **“무엇을 그릴지 명령”**합니다. (view.enableLoginButton(), view.showLoginError(message: \"에러 발생\")) View는 이 명령에 따라 실제 UI를 업데이트합니다.","2-동작-방식-3#\u003cstrong\u003e2. 동작 방식\u003c/strong\u003e":"View는 시작 시점에 자신의 UI 속성들을 ViewModel의 상태 프로퍼티에 **바인딩(Binding)**합니다. (예: loginButton.isEnabled 속성을 viewModel.isLoginEnabled 상태에 바인딩) 사용자가 View와 상호작용합니다. (예: 텍스트 필드에 이메일 입력) (양방향 바인딩) View에 입력된 값은 데이터 바인딩을 통해 자동으로 ViewModel의 상태 프로퍼티에 반영됩니다. (viewModel.email = \"test@test.com\") ViewModel은 자신의 프로퍼티가 변경될 때마다, 관련된 다른 상태 프로퍼티를 비즈니스 로직에 따라 업데이트합니다. (예: email과 password 상태가 변경되면, isLoginEnabled 상태가 true 또는 false로 자동 계산됨) (단방향 바인딩) View는 ViewModel의 isLoginEnabled 상태를 구독(바인딩)하고 있으므로, 이 값이 true로 바뀌는 것을 감지하고 스스로 버튼을 활성화시킵니다. ViewModel이 view.enableButton()과 같은 명령을 전혀 하지 않습니다.","3-mvc-패턴을-구성하는-핵심-기술들#\u003cstrong\u003e3. MVC 패턴을 구성하는 핵심 기술들\u003c/strong\u003e":"MVC는 객체 지향 프로그래밍의 개념을 기반으로, 플랫폼별로 다음과 같은 기술을 통해 구현됩니다.\n객체 지향 프로그래밍 (OOP): MVC 자체가 역할과 책임을 객체 단위로 나눈 고전적인 디자인 패턴입니다. 각 구성 요소를 클래스로 정의하고 메시지를 통해 상호작용하는 OOP의 기본 원칙을 따릅니다. 타겟-액션 (Target-Action) 매커니즘 (iOS): 콜백 방식보다 조금 더 구조화된 이벤트 처리 방식입니다. 이벤트가 발생한 객체(예: UIButton)가 지정된 ‘타겟’(Target, 주로 Controller)에게 ‘액션’(Action, 특정 메소드)을 실행하라는 메시지를 보냅니다. @IBAction은 이 매커니즘을 시각적으로 연결해주는 기능입니다. XML 레이아웃과 ID 참조 (Android): 안드로이드에서는 XML로 View의 구조를 정의하고, 각 View 요소에 고유한 ID를 부여합니다. Controller 역할을 하는 Activity나 Fragment는 findViewById 또는 최신의 View Binding 같은 기술을 사용하여 ID를 통해 View 객체에 대한 직접적인 참조를 얻어와 제어합니다.","3-mvp-패턴을-완성하는-핵심-기술들#\u003cstrong\u003e3. MVP 패턴을 완성하는 핵심 기술들\u003c/strong\u003e":"MVP의 정수는 특정 프레임워크 기능이 아닌, 소프트웨어 공학 원칙의 적용에 있습니다.\n인터페이스 (Interfaces) / 프로토콜 (Protocols): MVP를 가능하게 하는 가장 핵심적인 기술입니다. Presenter가 View의 구체적인 클래스(LoginViewController)에 의존하는 대신, 추상적인 규칙의 집합(LoginView 프로토콜)에 의존하게 만듭니다. 이는 ‘의존성 역전 원칙(Dependency Inversion Principle)‘의 대표적인 예시로, 이로 인해 Presenter와 View의 결합이 끊어지고 Presenter를 UI 프레임워크로부터 완전히 분리할 수 있게 됩니다. 모의 객체 (Mock Objects)와 의존성 주입 (Dependency Injection): 인터페이스 덕분에 단위 테스트가 가능해집니다. 테스트 코드에서는 실제 View(LoginViewController) 대신, LoginView 프로토콜을 따르는 가짜 객체(MockLoginView)를 만들어 Presenter에 주입(Injection)할 수 있습니다. 이 모의 객체는 Presenter가 자신에게 내린 명령(enableLoginButton이 호출되었는가?)을 기록하고, 테스트는 이 기록을 검증함으로써 Presenter의 로직이 올바른지 확인할 수 있습니다.","3-mvvm을-완성하는-핵심-기술들#\u003cstrong\u003e3. MVVM을 완성하는 핵심 기술들\u003c/strong\u003e":"MVVM 패턴은 프레임워크나 라이브러리의 강력한 지원을 통해 진정으로 완성됩니다.\n데이터 바인딩 (Data Binding): View와 ViewModel을 연결하는 ‘마법의 접착제’입니다. ViewModel의 데이터(상태)가 변경되면, 데이터 바인딩 라이브러리가 이를 감지하고 View의 UI 속성을 자동으로 업데이트합니다. 이를 통해 textView.setText(...) 와 같은 모든 UI 조작 코드가 사라지고, View는 “이 UI 속성은 저 상태와 같다\"고 선언만 하면 됩니다. 반응형 프로그래밍 (Reactive Programming) 라이브러리: 데이터의 ‘흐름(Stream)‘을 다루는 프로그래밍 패러다임입니다. 데이터가 단일 값이 아닌, 시간의 흐름에 따라 계속 변하는 스트림이라고 보고, 이 스트림을 구독(Subscribe)하거나, 여러 스트림을 조합(Combine), 변환(Map)하는 등의 작업을 통해 상태 변화를 효과적으로 전파합니다. AAC (Android Architecture Components): 구글은 MVVM 패턴을 공식적으로 지원하기 위해 AAC를 발표했습니다. ViewModel: 생명주기를 고려하여 UI 관련 데이터를 저장하고 관리합니다. 화면 회전과 같이 Activity가 재생성되는 상황에서도 데이터를 안전하게 보존하여 상태 유지를 쉽게 만듭니다. LiveData: 관찰 가능한(Observable) 데이터 홀더 클래스입니다. 안드로이드의 생명주기를 인지하여, View가 활성 상태(STARTED, RESUMED)일 때만 데이터를 업데이트하여 메모리 누수나 비정상 종료를 방지하는 안정적인 반응형 데이터 타입입니다. SwiftUI \u0026 Combine (iOS): Apple은 SwiftUI와 Combine 프레임워크를 통해 MVVM 패턴을 네이티브 차원에서 강력하게 지원합니다. SwiftUI: UI 자체를 상태의 함수로 정의하는 선언적 UI 프레임워크입니다. 데이터(상태)가 변경되면 UI가 자동으로 다시 그려지는 구조를 가지고 있어 MVVM에 매우 적합합니다. Combine: 데이터의 변경을 처리하고 전파하기 위한 Apple의 공식 반응형 프로그래밍 프레임워크입니다. ViewModel은 @Published 프로퍼티 래퍼를 통해 데이터의 변화를 외부에 알리고(Publish), View는 이를 구독(onReceive)하여 UI를 갱신합니다.","3-콜백-방식을-구성하는-핵심-기술들#\u003cstrong\u003e3. 콜백 방식을 구성하는 핵심 기술들\u003c/strong\u003e":"이 원시적인 방식은 프레임워크의 가장 기본적인 기능들에 의존합니다.\n이벤트 루프 (Event Loop): 모든 GUI 시스템의 심장입니다. 운영체제로부터 마우스 클릭, 키보드 입력, 타이머 등의 이벤트를 지속적으로 받아와 큐에 저장하고, 이를 순차적으로 처리하여 적절한 콜백 함수를 호출하는 무한 루프입니다. 개발자가 직접 제어하기보다는 시스템이 제공하는 기반 위에서 동작합니다. 함수 포인터 (Function Pointers) / 시그널과 슬롯 (Signals \u0026 Slots)의 원형: 이벤트와 처리 함수를 연결하는 ‘접착제’ 역할을 합니다. C언어에서는 함수 포인터를 직접 전달하여 “이 이벤트가 발생하면, 이 메모리 주소에 있는 함수를 실행해\"라고 알려줍니다. GTK의 g_signal_connect는 이러한 함수 포인터 기반의 연결을 더 체계적으로 만든 원시적인 시그널-슬롯 시스템으로 볼 수 있습니다.","4-실제-프레임워크-예시-gtk-gimp-toolkit#\u003cstrong\u003e4. 실제 프레임워크 예시: GTK (GIMP Toolkit)\u003c/strong\u003e":"GTK는 C언어 기반의 대표적인 GUI 툴킷으로, 초기 콜백 방식의 문제점을 명확하게 보여줍니다. 아래는 로그인 버튼 클릭 시의 동작을 콜백 함수로 구현한 상세 예시입니다.\n#include // 데이터베이스나 파일에서 사용자 정보를 검증하는 순수한 비즈니스 로직 함수 (가정) gboolean perform_login(const gchar *email, const gchar *password) { // 실제로는 파일 I/O, DB 조회 등의 로직이 들어감 if (g_strcmp0(email, \"test@example.com\") == 0 \u0026\u0026 g_strcmp0(password, \"password123\") == 0) { return TRUE; } return FALSE; } // 로그인 버튼이 클릭되었을 때 호출될 콜백 함수 // 이 함수 하나에 모든 책임이 집중되어 있습니다. void on_login_button_clicked(GtkButton *button, gpointer user_data) { // user_data를 통해 메인 윈도우의 다른 위젯(UI 요소)들에 접근합니다. // 이는 이 함수가 다른 UI 요소들의 존재와 구조를 모두 알아야 함을 의미합니다. (강한 결합) GtkWidget *email_entry = GTK_WIDGET(g_hash_table_lookup(GTK_HASH_TABLE(user_data), \"email_entry\")); GtkWidget *password_entry = GTK_WIDGET(g_hash_table_lookup(GTK_HASH_TABLE(user_data), \"password_entry\")); GtkWidget *status_label = GTK_WIDGET(g_hash_table_lookup(GTK_HASH_TABLE(user_data), \"status_label\")); // 1. 다른 View(위젯)에서 직접 데이터를 읽어옴 const gchar *email = gtk_entry_get_text(GTK_ENTRY(email_entry)); const gchar *password = gtk_entry_get_text(GTK_ENTRY(password_entry)); // 2. 비즈니스 로직을 직접 호출하여 수행 gboolean is_login_successful = perform_login(email, password); // 3. 비즈니스 로직의 결과에 따라 다른 View(위젯)의 상태를 직접 변경 if (is_login_successful) { gtk_label_set_text(GTK_LABEL(status_label), \"Login Successful! Welcome.\"); gtk_widget_set_sensitive(GTK_WIDGET(button), FALSE); // 로그인 버튼 비활성화 } else { gtk_label_set_text(GTK_LABEL(status_label), \"Error: Invalid email or password.\"); } } int main(int argc, char *argv[]) { // ... GTK 초기화 및 윈도우, 버튼, 입력창 등 위젯 생성 코드 ... // 이벤트와 콜백 함수를 직접 연결하는 부분 // \"login_button\"에서 \"clicked\" 시그널(이벤트)이 발생하면, // G_CALLBACK 매크로를 통해 on_login_button_clicked 함수를 호출하도록 설정합니다. g_signal_connect(login_button, \"clicked\", G_CALLBACK(on_login_button_clicked), app_widgets_hashtable); // ... } 이 방식의 치명적인 문제점은 명확합니다.\n스파게티 코드 (Spaghetti Code): on_login_button_clicked 함수는 UI 데이터 접근, 비즈니스 로직, UI 상태 업데이트라는 세 가지 다른 종류의 책임을 모두 떠안고 있습니다. 애플리케이션이 복잡해지면 수십 개의 콜백 함수가 서로의 상태를 읽고 변경하면서 거미줄처럼 얽히게 되어, 코드의 흐름을 추적하는 것이 불가능에 가까워집니다. 재사용 불가능성: ‘로그인’이라는 핵심 비즈니스 로직은 on_login_button_clicked라는 특정 UI 이벤트 처리 함수 내부에 갇혀 있습니다. 만약 다른 곳(예: 자동 로그인)에서 이 로직을 재사용하려면 코드를 복사-붙여넣기 하거나, 로직을 분리하기 위해 복잡한 리팩토링을 거쳐야 합니다. 테스트 불가능성: perform_login 함수 자체는 테스트할 수 있을지 몰라도, 이메일/비밀번호 형식에 따라 로그인 버튼이 활성화/비활성화되는 로직을 테스트하려면 어떻게 해야 할까요? 이 로직은 gtk_entry_get_text나 gtk_label_set_text 같은 GTK UI 함수에 직접적으로 의존하므로, GUI 환경을 실제로 실행하지 않고서는 단위 테스트를 작성하는 것이 거의 불가능합니다. 이러한 문제들은 필연적으로 아키텍처의 필요성을 낳았고, 그 첫 번째 대답이 바로 MVC였습니다.","4-실제-프레임워크-예시-ios의-massive-view-controller#\u003cstrong\u003e4. 실제 프레임워크 예시: iOS의 Massive View Controller\u003c/strong\u003e":"iOS의 UIViewController는 이름 그대로 Controller의 역할을 하지만, 실제로는 View의 생명주기(viewDidLoad, viewWillAppear 등)를 관리하고 View 객체들을 직접 소유(@IBOutlet)하는 등 View의 역할도 겸합니다. 이로 인해 View와 Controller의 분리가 모호해지고 모든 책임이 UIViewController로 집중되는 ‘거대 뷰 컨트롤러’ 문제가 발생합니다.\n아래는 iOS MVC 패턴의 문제점을 보여주는 상세한 코드 예시입니다.\n// iOS의 Massive View Controller 예시 import UIKit // Model 레이어 (가정) class AuthService { func login(email: String, password: String, completion: (Result) -\u003e Void) { // 실제로는 네트워크 통신이 일어남 if email == \"test@example.com\" \u0026\u0026 password.count \u003e= 8 { completion(.success(true)) } else { completion(.failure(NSError(domain: \"AuthError\", code: 401))) } } } class LoginViewController: UIViewController { // View 요소들을 Controller가 직접 소유하고 있습니다. (View와 Controller의 강한 결합) @IBOutlet weak var emailTextField: UITextField! @IBOutlet weak var passwordTextField: UITextField! @IBOutlet weak var loginButton: UIButton! // Model(Service)을 Controller가 직접 소유 let authService = AuthService() // View의 생명주기 관리 책임 override func viewDidLoad() { super.viewDidLoad() // View의 초기 상태를 Controller가 직접 설정 loginButton.isEnabled = false loginButton.backgroundColor = .gray } // View의 이벤트를 Controller가 직접 처리 @IBAction func emailDidChange(_ sender: UITextField) { validateInput() } @IBAction func passwordDidChange(_ sender: UITextField) { validateInput() } // 이 함수 하나에 프레젠테이션 로직과 View 제어 로직이 뒤섞여 있습니다. private func validateInput() { // 1. 프레젠테이션 로직 (어떻게 보여줄지를 결정하는 로직) let isEmailValid = emailTextField.text?.contains(\"@\") ?? false let isPasswordValid = (passwordTextField.text?.count ?? 0) \u003e= 8 // 2. View 제어 로직 (Controller가 View를 직접 제어) if isEmailValid \u0026\u0026 isPasswordValid { loginButton.isEnabled = true loginButton.backgroundColor = .blue } else { loginButton.isEnabled = false loginButton.backgroundColor = .gray } } // View의 이벤트를 처리하며 비즈니스 로직과 화면 전환 로직까지 담당합니다. @IBAction func loginButtonTapped(_ sender: UIButton) { // 1. 비즈니스 로직 호출 authService.login(email: emailTextField.text!, password: passwordTextField.text!) { [weak self] result in DispatchQueue.main.async { // UI 업데이트는 메인 스레드에서 // 2. Controller가 직접 View를 제어 (화면 전환, 얼럿 표시 등) switch result { case .success: // 화면 전환 로직... print(\"로그인 성공, 메인 화면으로 이동합니다.\") case .failure: // 얼럿(Alert)을 띄우는 View 로직... let alert = UIAlertController(title: \"로그인 실패\", message: \"아이디나 비밀번호를 확인해주세요.\", preferredStyle: .alert) alert.addAction(UIAlertAction(title: \"확인\", style: .default)) self?.present(alert, animated: true) } } } } } 이 구조는 콜백 지옥보다 역할이 조금 분리되었을 뿐, 본질적인 문제들은 그대로 남아있습니다.\n과도한 책임 (Overloaded Responsibility): LoginViewController는 View의 생명주기 관리, 사용자 입력 처리, 입력값 유효성 검사(프레젠테이션 로직), View의 속성 업데이트(View 제어), 비즈니스 로직 호출, 화면 전환, 에러 처리(얼럿 표시) 등 너무나 많은 책임을 집니다. 클래스가 수백, 수천 줄로 비대해져 유지보수가 재앙에 가까워집니다. 강한 결합 (Tight Coupling): Controller는 @IBOutlet을 통해 View의 구체적인 클래스(UITextField, UIButton)를 직접 알고 그 속성(text, isEnabled)을 변경합니다. 만약 디자이너가 UIButton을 커스텀 View로 교체한다면, Controller의 코드까지 수정해야 합니다. View와 Controller가 한 몸처럼 묶여있어 분리가 불가능합니다. 테스트의 어려움: validateInput 함수의 로직, 즉 “이메일에 @가 포함되고 비밀번호가 8자 이상이면 로그인 버튼이 활성화된다\"는 중요한 정책을 테스트하고 싶다고 가정해 봅시다. 이 로직은 emailTextField.text와 loginButton.isEnabled 같은 UIKit 프레임워크의 구체적인 컴포넌트에 의존합니다. 따라서 이 로직을 검증하려면 iOS 시뮬레이터를 띄우고 UI 테스트를 실행해야만 합니다. 순수한 로직만 분리하여 빠르게 실행할 수 있는 단위 테스트(Unit Test)가 거의 불가능합니다. 결국 MVC는 ‘테스트’와 ‘역할 분리’라는 과제를 남겼고, 이를 해결하기 위해 MVP가 등장하게 됩니다.","4-실제-프레임워크-예시-rxswiftcombine을-활용한-ios의-mvvm#\u003cstrong\u003e4. 실제 프레임워크 예시: RxSwift/Combine을 활용한 iOS의 MVVM\u003c/strong\u003e":"아래는 반응형 라이브러리인 RxSwift를 사용하여 MVVM 패턴을 구현한 상세 예시입니다.\nimport UIKit import RxSwift import RxCocoa // Model 레이어는 동일 (AuthService) // 1. ViewModel (UI 프레임워크 코드 없음! -\u003e 순수한 로직) // ViewModel은 View의 존재를 전혀 모릅니다. 오직 상태만 외부에 노출합니다. class LoginViewModel { // --- 입력 (View로부터 받는 데이터 스트림) --- // BehaviorRelay는 값을 가질 수 있고, 그 값의 변화를 스트림으로 외부에 알립니다. let email = BehaviorRelay(value: \"\") let password = BehaviorRelay(value: \"\") // --- 출력 (View가 구독할 상태 스트림) --- let isLoginEnabled: Observable // 버튼 활성화 여부 상태 let loginResult: PublishSubject","4-실제-프레임워크-예시-swift를-이용한-mvp-구현#\u003cstrong\u003e4. 실제 프레임워크 예시: Swift를 이용한 MVP 구현\u003c/strong\u003e":"MVP 패턴의 정수는 인터페이스를 통한 역할 분리에 있습니다. 아래 코드는 MVC 예제를 MVP로 리팩토링한 상세 버전입니다.\nimport UIKit // Model 레이어는 동일 (AuthService) // --- MVP의 핵심: View와 Presenter 사이의 계약(Contract) 정의 --- // 1. View가 따라야 할 규칙 (인터페이스/프로토콜) // Presenter가 View에게 내릴 수 있는 명령들의 목록입니다. protocol LoginView: AnyObject { func enableLoginButton() func disableLoginButton() func showLoginError(message: String) func navigateToMainScreen() func showLoadingIndicator() func hideLoadingIndicator() } // 2. Presenter (UI 프레임워크 코드 없음! -\u003e import UIKit 불필요) // 이 클래스는 순수한 Swift 코드로만 작성되어 단위 테스트가 매우 용이합니다. class LoginPresenter { // Presenter는 구체적인 ViewController가 아닌, LoginView 프로토콜에만 의존합니다. private weak var view: LoginView? private let authService = AuthService() init(view: LoginView) { self.view = view } // 프레젠테이션 로직이 Controller에서 Presenter로 이동했습니다. func validateInput(email: String?, password: String?) { let isEmailValid = email?.contains(\"@\") ?? false let isPasswordValid = (password?.count ?? 0) \u003e= 8 if isEmailValid \u0026\u0026 isPasswordValid { // View에게 \"버튼을 활성화하라\"고 명령합니다. view?.enableLoginButton() } else { // View에게 \"버튼을 비활성화하라\"고 명령합니다. view?.disableLoginButton() } } func loginButtonTapped(email: String?, password: String?) { guard let email = email, let password = password else { return } view?.showLoadingIndicator() // 로딩 시작 명령 authService.login(email: email, password: password) { [weak self] result in self?.view?.hideLoadingIndicator() // 로딩 종료 명령 switch result { case .success: self?.view?.navigateToMainScreen() // 화면 전환 명령 case .failure: self?.view?.showLoginError(message: \"로그인 실패\") // 에러 표시 명령 } } } } // 3. View (이제 훨씬 단순해지고, Presenter의 명령을 수행하는 역할만 합니다.) class LoginViewController: UIViewController, LoginView { // Presenter를 소유 var presenter: LoginPresenter! @IBOutlet weak var emailTextField: UITextField! @IBOutlet weak var passwordTextField: UITextField! @IBOutlet weak var loginButton: UIButton! // ... 로딩 스피너 등 추가 UI ... override func viewDidLoad() { super.viewDidLoad() // 자기 자신(LoginView를 구현한 ViewController)을 Presenter에 주입하여 생성 presenter = LoginPresenter(view: self) } // View는 이벤트를 받으면 생각하지 않고 Presenter에게 전달합니다. @IBAction func emailDidChange(_ sender: UITextField) { presenter.validateInput(email: sender.text, password: passwordTextField.text) } @IBAction func passwordDidChange(_ sender: UITextField) { presenter.validateInput(email: emailTextField.text, password: sender.text) } @IBAction func loginButtonTapped(_ sender: UIButton) { presenter.loginButtonTapped(email: emailTextField.text, password: passwordTextField.text) } // --- Presenter의 명령을 수행하는 메소드들 (LoginView 프로토콜 구현) --- func enableLoginButton() { loginButton.isEnabled = true loginButton.backgroundColor = .blue } func disableLoginButton() { loginButton.isEnabled = false loginButton.backgroundColor = .gray } func showLoginError(message: String) { let alert = UIAlertController(title: \"에러\", message: message, preferredStyle: .alert) alert.addAction(UIAlertAction(title: \"확인\", style: .default)) present(alert, animated: true) } func navigateToMainScreen() { print(\"메인 화면으로 이동합니다.\") // 화면 전환 코드 구현 } func showLoadingIndicator() { /* 로딩 스피너 보이기 */ } func hideLoadingIndicator() { /* 로딩 스피너 숨기기 */ } } MVP가 이뤄낸 성과와 새로운 문제는 다음과 같습니다.\n해결된 점 (장점):\n최고의 테스트 용이성: LoginPresenter는 import UIKit이 필요 없는 순수한 Swift 클래스입니다. 따라서 가짜 MockLoginView 객체를 만들어 주입하면, “validateInput을 호출했을 때 view.enableLoginButton이 정확히 호출되는가?“와 같은 모든 로직을 시뮬레이터 없이 수 밀리초 만에 검증하는 단위 테스트가 완벽하게 가능해졌습니다. 명확한 역할 분리: Controller의 비대화 문제가 해결되었습니다. View는 UI 코드만, Presenter는 프레젠테이션 로직만 담당하게 되어 코드의 가독성과 유지보수성이 크게 향상되었습니다. 새로운 문제점:\nView와 Presenter의 1:1 강한 결합: 비록 인터페이스를 통해 분리했지만, 결국 Presenter는 View가 어떤 기능들을 가지고 있는지(enableLoginButton, showLoginError 등) 속속들이 알아야만 합니다. 화면이 복잡해져 View에 기능이 추가될수록, LoginView 프로토콜과 LoginPresenter는 함께 비대해지며 서로에게 강하게 묶이는 경향이 있습니다. 반복적인 코드 (Boilerplate) 증가: showLoading(), hideLoading(), updateText(text: String), showImage(image: UIImage) 등, 모든 사소한 UI 변경 작업을 위해 개발자는 ①프로토콜에 메소드 선언, ②Presenter에서 해당 메소드 호출, ③View에서 메소드 구현이라는 3단계의 반복적인 작업을 계속해야 합니다. 이는 개발의 피로도를 높이는 원인이 됩니다. 결국 MVP는 ‘테스트’라는 큰 산을 넘었지만, ‘반복적인 명령’이라는 새로운 과제를 남겼습니다. 이 문제를 해결하기 위해, 아키텍처는 ‘명령’이 아닌 ‘상태’에 집중하기 시작합니다. 바로 MVVM의 등장입니다.","제1장-원시-시대의-혼돈-콜백-지옥-callback-hell#제1장: 원시 시대의 혼돈, 콜백 지옥 (Callback Hell)":"GUI 프로그래밍의 가장 초기 형태는 아키텍처라는 개념 없이, 단순히 이벤트와 그 이벤트를 처리할 함수를 직접 연결하는 방식이었습니다. C/C++ 기반의 순수 Win32 API나 초기 GTK, X-Window 프로그래밍이 이에 해당하며, 이는 모바일 시대의 ‘거대 뷰 컨트롤러’가 겪는 문제의 원형과 정확히 일치합니다.","제2장-최초의-질서와-거대해진-중재자-mvc-model-view-controller#제2장: 최초의 질서와 거대해진 중재자, MVC (Model-View-Controller)":"MVC 패턴은 애플리케이션의 구성 요소를 세 가지 역할(Model, View, Controller)로 분리하려는 최초의 체계적인 시도였습니다. Apple과 Google이 초기에 iOS와 안드로이드 개발의 기본 패턴으로 제시하면서 모바일 개발의 시작을 열었지만, 이론의 우아함과 달리 실제 환경에서는 콜백 지옥의 문제가 다른 형태로 나타나는 한계를 보였습니다.","제3장-테스트-가능성을-향한-여정-mvp-model-view-presenter#제3장: 테스트 가능성을 향한 여정, MVP (Model-View-Presenter)":"MVP(Model-View-Presenter) 패턴은 MVC의 ‘거대 컨트롤러’와 ‘테스트 불가’ 문제를 정면으로 해결하기 위해 등장했습니다. 그 핵심 철학은 View와 로직의 완벽한 분리에 있으며, 이를 위해 ‘인터페이스(프로토콜)‘를 통한 의존성 역전 원칙을 사용합니다.","제4장-상태-관리의-자동화와-선언형-패러다임의-완성-mvvm-model-view-viewmodel#제4장: 상태 관리의 자동화와 선언형 패러다임의 완성, MVVM (Model-View-ViewModel)":"MVP의 반복적인 명령과 1:1 결합 문제를 해결하기 위해 등장한 MVVM(Model-View-ViewModel)은 클라이언트 아키텍처의 패러다임을 근본적으로 바꾸었습니다. 핵심은 데이터 바인딩(Data Binding) 메커니즘을 통해, Presenter의 ‘수동 명령’을 ‘상태 변화에 대한 자동 반응’으로 전환한 것입니다.","클라이언트-아키텍처의-위대한-진화-콜백-지옥에서-선언형-ui까지#클라이언트 아키텍처의 위대한 진화: 콜백 지옥에서 선언형 UI까지":"클라이언트 애플리케이션, 즉 사용자와 직접 상호작용하는 모든 소프트웨어(데스크톱 프로그램, 모바일 앱)의 개발 역사는 본질적으로 **‘상태(State)와의 전쟁’**의 역사입니다. 사용자의 예측 불가능한 입력, 네트워크의 비동기적 응답, 시스템의 예기치 않은 이벤트 속에서 화면은 끊임없이 변화해야 합니다. 로딩 중, 에러 발생, 데이터 목록의 유무, 버튼의 활성화/비활성화 등, 복잡하게 얽히고설킨 상태를 어떻게 하면 ▲안정적이고 ▲테스트 가능하며 ▲유지보수하기 쉽게 관리할 수 있을까?\n이 거대한 질문에 답하기 위해 아키텍처는 수십 년에 걸쳐 놀랍도록 유사한 궤적을 그리며 진화해왔습니다. 데스크톱 GUI 프로그래밍의 오랜 역사와 모바일 앱 개발의 역사는 사용하는 기술과 용어는 다를지라도, 근본적으로 같은 문제를 해결하기 위한 여정이었으며, 이는 특정 플랫폼을 넘어선 소프트웨어 공학의 보편적 원리가 존재함을 증명합니다.\n이 진화의 과정은 크게 네 단계로 나눌 수 있습니다.\n제1단계: 원시 시대의 혼돈, 콜백 지옥 (Callback Hell) 제2단계: 최초의 질서와 거대해진 중재자, MVC (Model-View-Controller) 제3단계: 테스트 가능성을 향한 여정, MVP (Model-View-Presenter) 제4단계: 상태 관리의 자동화와 선언형 패러다임의 완성, MVVM (Model-View-ViewModel) 이제 각 단계를 심층적으로 탐험해 보겠습니다."},"title":"클라이언트 어플리케이션 구조 변화"},"/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-%EC%A3%BC%EC%A0%9C/":{"data":{"":"세종대 allcll 프로젝트 여러명이 있을 때 블루투스 스피커가 없음 근데 크게 듣고 싶음 =\u003e 각 기기 동기화 시켜서 동일한 음원 정확하게 같은 시간에 트는거 유튜브 재생목록 받아서 구현( 대형을 보고 스피커 형태 구현하면 더 좋다 =\u003e 좌우 전후 등등) universal clipboard 클립보드 완전 동기화 (android, window, mac, ios, linux … )"},"title":"프로젝트 주제"},"/00.-home/":{"data":{"":"개인 기록 저장 보관소\n일반적인 폴더 트리 구조로도 볼수 있지만 태그별로 기록을 관리하고 있음 단 주제가 밀접하다면 폴더에 묶어있음\nTABLE length(rows) AS \"File Count\" FROM \"\" FLATTEN file.tags AS Tag WHERE Tag AND !contains(file.path, \"05.clipping\") AND !contains(file.path, \"89.Obsidian\") GROUP BY Tag SORT length(rows) desc mermaid 와 dataview 는 사용 필수"},"title":"00. Home"},"/00.data-view-and-bases/%EB%94%B0%EB%9D%BCit/":{"data":{"":"TABLE index WHERE source = \"따라IT Network\" sort index"},"title":"따라IT"},"/00.data-view-and-bases/%EC%9D%B4%EA%B2%83%EC%9D%B4-%EC%BD%94%EB%94%A9%ED%85%8C%EC%8A%A4%ED%8A%B8%EB%8B%A4-with-python/":{"data":{"":"TABLE index WHERE source = \"이것이 코딩테스트다 with python\" SORT index"},"title":"이것이 코딩테스트다 with python"},"/00.data-view-and-bases/05.-share-note/":{"data":{"":"TABLE WITHOUT ID link(file.path, truncate(file.name, 28)) as Note, dateformat(share_updated, \"yyyy-MM-dd\") as \"Shared on\", elink(share_link, regexreplace(share_link, \"^.*?(\\w+)(#.+?|)$\", \"$1\")) as Link, choice(regextest(\"#\", share_link), \"🔒\", \"\") as \"\" WHERE share_link"},"title":"05. Share Note"},"/00.data-view-and-bases/11.-data-view-all-tag/":{"data":{"":"TABLE WITHOUT ID tag AS Tags, length(rows.file.link) AS \"File Count\" FROM \"\" WHERE file.tags FLATTEN file.tags AS tag GROUP BY tag SORT length(rows.file.link) DESC TABLE WITHOUT ID (tag + \"(\" + length(rows.file.link) + \")\") AS Tags, join(rows.file.link, \" \") AS Files FROM \"\" WHERE file.tags FLATTEN file.tags AS tag GROUP BY tag SORT length(rows.file.link) DESC"},"title":"11. Data View all tag"},"/00.data-view-and-bases/12.-data-view-recent-modified/":{"data":{"":"table modified as \"최근 수정 일시\", created as \"생성일\" from \"\" where modified sort modified desc"},"title":"12. Data View recent modified"},"/01.publish/c-%EC%84%A0%EC%96%B8%EB%B6%80-%EB%AC%B8%EB%B2%95-%EC%9D%BD%EA%B8%B0/":{"data":{"":"","결론#결론":"char *(*(**foo[][8])())[]; //??? 처음에 보았던 난해한 선언이다\nfoo : 변수 foo foo[] : 배열 foo foo[][8] : 개수가 8인 배열을 원소로 가지는 배열 foo *foo[][8] : 메모리 주소를 저장하는 개수가 8일 배열을 원소로 가지는 배열 foo **foo[][8] : 메모리 주소를 저장하는 포인터형 변수의 메모리 주소를 저장하는 개수가 8인 배열을 원소로 가지는 배열 foo *(**foo[][8])() : 반환값이 메모리 주소를 저장하고 인수가 없는 함수의 메모리 주소를 저장하는 포인터형 변수의 메모리 주소를 저장하는 개수가 8일 배열을 원소로 가지는 배열 foo (*(**foo[][8])())[] : 크기가 정해지지 않은 배열의 메모리 주소를 저장하는 포인터형 변수를 반환값으로 가지고 인수가 없는 함수의 메모리 주소를 저장하는 포인터형 변수의 메모리 주소를 저장하는 개수가 8일 배열을 원소로 가지는 배열 foo char *(*(**foo[][8])())[] : char를 저장하는 크기가 정해지지 않은 배열의 메모리 주소를 저장하는 포인터형 변수를 반환값으로 가지고 인수가 없는 함수의 메모리 주소를 저장하는 포인터형 변수의 메모리 주소를 저장하는 개수가 8일 배열을 원소로 가지는 배열 foo foo는 아무 인자를 받지 않고 문자 포인터의 배열을 반환하는 함수를 가리키는 이중 포인터들의 2차원 배열\n쉽지 않네…","규칙#규칙":"","다차원-배열#다차원 배열":"","배열-포인터#배열 포인터":"","이중-포인터#이중 포인터":"","포인터-배열#포인터 배열":"","포인터-배열과-배열-포인터#포인터 배열과 배열 포인터":"","함수포인터#함수포인터":"쉬운 선언\nint foo[5]; // foo는 5개의 정수로 구성된 배열입니다.\nchar *foo; // foo는 char에 대한 포인터입니다.\ndouble foo(); // foo는 double을 반환하는 함수입니다.\n그러나 선언이 좀 더 복잡해지면 보고 있는 내용을 정확히 아는 것이 더 어려워진다\nchar *(*(**foo[][8])())[]; //??? 위의 구문처럼 코딩을 하는 경우는 잘 없지만 하나하나 해석하면서 선언부 문법을 완벽하게 이해해 보자\n규칙 long **foo[7]; 어떤 영문 자료에서 확인한 자료이다\n언제나 먼저 변수 이름으로 시작합니다 =\u003e foo 는 …\n언제나 마지막은 type 입니다 =\u003e foo 는 char 입니다\n가운데는 “go right when you can, go left when you must”\n갈 수 있다면 오른쪽으로 왼쪽으로는 가야할때만!!\n[!참조] c, cpp 연산자 우선순위 를 참고 * 보다 [] 이 우선한다\n5가지 c 언어에서 어렵다고 소문난 내용을 이해해 보자\n포인터 배열과 배열 포인터 int (*a)[7] int *a[7] 의 차이\n포인터 배열 int *a[7] a : 변수 a a[7] : 개수가 7인 배열 a *a[7] : 메모리 주소를 저장하는 크기가 7인 배열 a int *a[7] : int 형 메모리 주소를 저장하는 개수가 7인 배열 a 배열 포인터 int (*a)[7] a : 변수 a (*a) : 메모리 주소를 저장하는 a (*a)[7] : 개수가 7인 배열의 메모리 주소를 저장하는 a int (*a)[7] : int 형 변수를 저장하는 개수가 7인 배열의 메모리 주소를 저장하는 a 이중 포인터 int **a a : 변수 a *a : 메모리 주소를 저장하는 변수 a **a : 메모리 주소를 저장하는 포인터형 변수의 메모리 주소를 저장하는 변수 a int **a : int형 변수의 메모리 주소를 저장하는 포인터형 변수의 메모리 주소를 저장하는 변수 a 다차원 배열 int a[5][7]; a : 변수 a a[5] : 개수가 5인 배열 a a[5][7] : 개수가 7인 배열을 원소로 가지는 크기가 5인 배열 a int a[5][7] : int형 변수를 원소로 가지는 크기가 7인 배열을 원소로 가지는 크기가 5인 배열 a 함수포인터 int(*a)(int,int); a : 변수 a (*a) : 메모리 주소를 저장하는 포인터 변수 a (*a)(int,int) : 두 개의 int형 변수를 인자로 받는 함수의 메모리 주소를 저장하는 포인터 변수 a int(*a)(int,int) : int 형 값을 반환하고 두 개의 int형 변수를 인자로 받는 함수의 메모리 주소를 저장하는 포인터 변수 a"},"title":"c 선언부 문법 읽기"},"/02.inbox/%EA%B0%80%EB%B3%80%EC%9D%B8%EC%9E%90variadic/":{"data":{"":"가변 인자 매크로의 모든 것 - 개론 가변 인자 매크로의 모든 것 - 과거 가변 인자 매크로의 모든 것 - 현재 #1 가변 인자 매크로의 모든 것 - 현재 #2 가변 인자 매크로의 모든 것 - 현재 #3 가변 인자 매크로의 모든 것 - 미래 가변 인자 매크로의 모든 것 - 구현 가변 인자 매크로의 모든 것 - 보충 여러개의 데이터를 묶어 하나의 변수에 대입 (패킹) vs 컬랙션 속의 요소들을 여러 개의 변수에 나누어 대입(언패킹) 컬랙션 (list tuple dictionary set)…\n기본 구분\nnumbers = (1, 2, 3, 4, 5) # 패킹 a, b, c, d, e = numbers # 언패킹 필요없는 요소 생략\na, _, _, d, e = numbers # 필요 없는 요소를 _ 변수에 대입 \u003e\u003e\u003e a, b, *rest = numbers # 1, 2를 제외한 나머지를 rest에 대입 \u003e\u003e\u003e print(a, b, rest) 1 2 [3, 4, 5] \u003e\u003e\u003e a, *rest, e = numbers # 1, 5를 제외한 나머지를 rest에 대입 \u003e\u003e\u003e print(rest) [2, 3, 4] 무조건 리스트로 반환 \u003e\u003e\u003e x = [10, 20, 30] \u003e\u003e\u003e print_numbers(*x) 10 20 30 num_dict = {'a':1,'b':2,'c':3,'d':4,'e':5} num_set = {1,2,3,4,5} a3,b3,*rest3 = num_dict a4,b4,*rest4 = num_set print(a3, b3, rest3) # a b ['c', 'd', 'e'] print(a4, b4, rest4) # 1 2 [3, 4, 5]","위치-가변-인자-args#위치 가변 인자 *args":"언패킹 방식을 함수의 인자에 사용 위치를 사용하므로 위치 가변 인자라고 한다 함수인자의 언패킹 방식과 일반 언패킹 방식은 리스트와 튜플로 다르다\nnum_tuple = (1,2,3,4,5) num_list = [1,2,3,4,5] a1,b1,*rest1 = num_list a2,b2,*rest2 = num_tuple print(a1, b1, rest1) # 1 2 [3, 4, 5] print(a2, b2, rest2) # 1 2 [3, 4, 5] # 그냥 언패킹은 무조건 리스트 def unpacking1(a3,b3,*rest3): # 1 2 (3, 4, 5) 함수내부에서의 언패킹은 무조건 튜플 print(a3,b3,rest3) unpacking1(1,2,3,4,5)","키워드-가변-인자-kwargs#키워드 가변 인자 **kwargs":"함수는 임의의 개수의 키워드 인자도 받을 수 있다. 예:\ndef f(x, y, **kwargs): ... 함수 호출.\nf(2, 3, flag=True, mode='fast', header='debug') 추가적인 키워드를 딕셔너리로 전달한다.\ndef f(x, y, **kwargs): # x -\u003e 2 # y -\u003e 3 # kwargs -\u003e { 'flag': True, 'mode': 'fast', 'header': 'debug' }","튜플과-딕셔너리를-전달하기#튜플과 딕셔너리를 전달하기":"튜플을 가변 인자로 확장할 수 있다.\nnumbers = (2,3,4) f(1, *numbers) # f(1,2,3,4)와 같음 마찬가지로 딕셔너리를 키워드 인자로 확장할 수 있다.\noptions = { 'color' : 'red', 'delimiter' : ',', 'width' : 400 } f(data, **options)","함수-인자#함수 인자":"함수의 인자를 보내는 방식을 2가지 위치로 매핑 하는 방법과 키워드로 매핑하는 방법 위치로 매칭하는 방법\nfunc('py', 'thon') #호출시 키워드로 매칭하는 방법\nfunc(b='thon', a='py') #호출시 print(a,b,sep=\" 그리고 \")"},"title":"가변인자(variadic)"},"/02.inbox/%EA%B3%84%EC%B8%B5-%EA%B8%B0%EB%B0%98-%ED%8F%B4%EB%8D%94-%EA%B5%AC%EC%A1%B0-vs-%EC%84%9C%EB%B9%84%EC%8A%A4-%EB%8B%A8%EC%9C%84-%EA%B8%B0%EB%B0%98-%ED%8F%B4%EB%8D%94-%EA%B5%AC%EC%A1%B0/":{"data":{"":"좋은 질문입니다. DTO, Repository, Domain, Service 와 같은 계층 기반 폴더 구조(Layered Architecture)와 서비스 단위 기반 폴더 구조(Vertical Slice / Feature-based Architecture) 중 어느 것이 더 나은지는 프로젝트의 규모, 팀 구조, 유지보수성, 확장성 등에 따라 달라집니다.\n아래에서 두 방식의 특징과 장단점을 비교하고, 어떤 상황에서 어떤 방식이 적합한지 정리해 드릴게요.","-1-계층-기반-구조-layered--horizontal-architecture#✅ 1. \u003cstrong\u003e계층 기반 구조 (Layered / Horizontal Architecture)\u003c/strong\u003e":"src/ ├── dto/ │ ├── UserRequestDto.java │ └── UserResponseDto.java ├── domain/ │ ├── User.java │ └── UserStatus.java ├── repository/ │ └── UserRepository.java ├── service/ │ └── UserService.java ├── controller/ │ └── UserController.java └── config/ └── DatabaseConfig.java","-2-서비스기능-단위-구조-vertical-slice--feature-based-architecture#✅ 2. \u003cstrong\u003e서비스(기능) 단위 구조 (Vertical Slice / Feature-based Architecture)\u003c/strong\u003e":"src/ ├── user/ │ ├── User.java │ ├── UserRepository.java │ ├── UserService.java │ ├── UserController.java │ ├── UserRequestDto.java │ └── UserResponseDto.java ├── order/ │ ├── Order.java │ ├── OrderService.java │ └── OrderController.java └── common/ ├── config/ └── exception/","-결론-어떤-걸-선택해야-할까#✅ 결론: 어떤 걸 선택해야 할까?":"프로젝트 유형 추천 구조 작은 프로젝트, 학습용, MVP ✅ 계층 기반 구조 (간단하고 직관적) 중대형 프로젝트, 장기 운영, 팀 개발 ✅ 서비스/기능 단위 구조 (유지보수성 ↑) 도메인 중심 설계(DDD) 적용 ✅ 기능 단위 + bounded context 기반 구성 마이크로서비스 아키텍처 ✅ 각 서비스 내부는 기능 단위 구조 권장","-단점#❌ 단점":"변경이 어렵다: 하나의 기능을 수정할 때 여러 패키지를 왔다갔다 해야 함 (예: 유저 생성 기능 수정 시 controller → service → repository → dto 모두 확인). 결합도 증가: 모든 기능이 동일한 계층에 몰려 있어, 관련 없는 기능들끼리 묶임. 대규모 프로젝트에서 관리 어려움: 기능이 많아질수록 파일 수가 많아지고, 관련 코드를 찾기 어려워짐.","-단점-1#❌ 단점":"중복 가능성: 공통 로직(예: DTO, 유틸)이 각 폴더에 중복될 수 있음 → common 또는 shared 패키지로 해결 필요. 초기 설계가 중요: 공통 모듈과 기능 모듈의 경계를 잘 설정해야 함. 익숙하지 않은 구조: 전통적인 계층 구조에 익숙한 개발자에게는 어색할 수 있음.","-보완-전략-하이브리드-접근#🔁 보완 전략 (하이브리드 접근)":"실제로는 하이브리드로 구성하는 경우도 많습니다:\nsrc/ ├── user/ │ ├── controller/ │ ├── service/ │ ├── repository/ │ └── dto/ ├── order/ │ ├── controller/ │ └── service/ ├── common/ │ ├── dto/ │ ├── exception/ │ └── util/ └── config/ → 기능 단위로 묶되, 내부는 계층 구조를 유지.\n이 방식은 유지보수성과 일관성을 동시에 잡을 수 있어 실무에서 많이 사용됩니다.","-장점#✅ 장점":"일관성 있는 구조: 모든 개발자가 동일한 위치에서 동일한 타입의 클래스를 찾을 수 있음. 초기 개발이 쉬움: 특히 작은 프로젝트나 학습용 프로젝트에 적합. Spring Boot 등의 프레임워크와 자연스럽게 맞음: MVC 패턴과 잘 어울림.","-장점-1#✅ 장점":"기능 단위로 코드가 묶여 있어 유지보수 용이: 유저 관련 기능은 user/ 폴더 안에 모두 있음. 변경이 쉬움: 기능 하나를 수정할 때 관련된 모든 코드를 한 폴더에서 찾을 수 있음. 팀 기반 개발에 유리: 팀이 기능 단위로 분업하기 쉬움 (예: A팀은 user, B팀은 order 담당). 확장성 좋음: 새 기능 추가 시 폴더 하나 생성하면 됨.","-참고-아키텍처-패턴#📚 참고 아키텍처 패턴":"Vertical Slice Architecture Clean Architecture Domain-Driven Design (DDD)","-추천#✅ 추천":"🔔 “기능 단위 기반 구조 + 내부 계층 분리” 를 추천합니다.\n예:\ncom.example.app.user ├── User.java ├── UserController.java ├── UserService.java ├── UserRepository.java ├── UserCreateRequest.java └── UserResponse.java 이렇게 하면:\n기능 단위로 코드를 찾기 쉽고, 각 기능 내부는 역할에 따라 분리되어 있어 체계적입니다."},"title":"계층 기반 폴더 구조 vs 서비스 단위 기반 폴더 구조"},"/02.inbox/%EA%B7%B8%EB%9E%98%EC%84%9C-%EC%BB%B4%ED%93%A8%ED%84%B0%EB%8A%94-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%8F%99%EC%9E%91%ED%95%98%EB%82%98%EC%9A%94/%EA%B7%B8%EB%9E%98%EC%84%9C-%EC%BB%B4%ED%93%A8%ED%84%B0%EB%8A%94-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%8F%99%EC%9E%91%ED%95%98%EB%82%98%EC%9A%94-1/":{"data":{"":"WORD : CPU 에 의해 한번에 처리될 수 있는 비트 수","123단계--명령어-가져오기-실행해야할-작업-목록#1,2,3단계  명령어 가져오기 실행해야할 작업 목록":"IAR에 담긴 주소를 이용해 RAM에서 현재 실행할 명령어를 꺼낸다 IR 에 저장한다 IAR 값을 1 증가시킨다 자세한 접근\n현재 상태 : IAR 에는 현재 실행해야 할 명령을 가리키는 주소가 들어있다 / BUS 에 IAR 값이 흐를 때 다음 접근 명령 주소를 미리 계산해야 한다 IAR 값을 enable 시켜서 MAR 에 set(저장) 시킨다 또한 다음 싸이클에 IAR 이 접근해야할 메모리 주소 +1 을 해야 하므로 bus1 을 enable 시킨다 그리고 +1 한 값을 3단계에서 IAR 에 집어넣어야 하기 때문에 임시 보관 용도로 ACC 를 set 시킨다 RAM 을 Enable 시켜서 MAR 에 들어있는 현재 명령값이 BUS 로 흐르게 된다 또한 그 BUS 로 흐른 값이 IR 로 들어가게 set 한다 ACC 를 enable 시켜서 IAR + 1 한 값이 BUS 로 흐르게 하고 그것은 IAR 을 Set 시켜서 다음 명령 주소값을 저장한다 stapper ACC BUS1(s) IAR IR MAR RAM BUS 1 set enable enable set IAR (현재 실행중 명령 주소) 2 3 enable set ACC(현재 실행 IAR+1)","18강-레지스터-상태변화-47-단계#18강 레지스터 상태변화 4~7 단계":"stapper ACC R0 R1 TMP(s) BUS 초기 값 Err 5 8 Err Err 4 enable(8) set(8) R1(8) 5 set(5) enable(5) R0(5) 6 enable(13) set(13) ACC(13) 7","20강-명령어-가져오기-단계1--3에서의-레지스터-상태-변화#20강 명령어 가져오기 단계(1 ~ 3)에서의 레지스터 상태 변화":"stapper ACC BUS1(s) IAR IR MAR RAM BUS 1 set enable enable set IAR (현재 실행중 명령 주소) 2 set enable RAM(접근한 명령값) 3 enable set ACC(현재 실행 IAR+1) stapper ACC RA RB TMP(s) BUS 1 2 3 4 enable set RB 5 set enable disable unset RA 6 enable disable ACC 7 reset reset reset reset reset reset reset reset A = 127 B = 29 C = 88 D = A - B - C = 10 :aa \u003c- 7f // 1단계 :ab \u003c- 1d // 2단계 :ac \u003c- 58 // 3단계 :c3 \u003c- ([:aa] - [:ab]) - [:ac] //4단계 뺄때는 2의 보수법을 사용하여 음수를 더하는 개념으로 ALU 에서 - 가 구현되지 않았지만 동작하게 할 수 있다 이 경우 HW 로 구현한 것이 아닌 SW 로 구현한 것이 된다 즉 어셈블리어 단계에서 이 방식을 미리 SW 에서 구현해주어야 한다 아래는 음수로 하고 +1 을 하는 방식이다 명령어 갯수 : 13개\nStepper module : \" \" =\u003e 클럭, step 생성 클럭 신호 스텝퍼 처리 IR code module : IR code =\u003e ALU 의 어떤 기능 사용 op_out, IR code 해석 모듈 Instruction fetch module : 1~3 단계 명령 가져오기 모듈 ALU instruction condition : 4~6 단계 ALU 관련 명령 조건 (ex IR_0 가 1일때) ALU instruction module : 4~6 단계 단계에 어떤 레지스터 조건이 필요한지 Resgister selection module : IR 뒷자리 4개가 어떤 범용 레지스터 선택했는지 초깃값 문재 power on reset 또는 preset","456-단계-clf-명령일-때-실행해야-할-작업-목록-op--0110#4,5,6 단계 CLF 명령일 때 실행해야 할 작업 목록 (op = 0110)":"현재까지 Flags set 신호 Ctmp enable 신호만 만들고 Ctmp 신호의 set 신호의 경우 ALU 연산실행시 무조건 set 되는 TMP 신호를 중복 활용하여 사용했다 또한 Flags 의 enable 신호는 따로 만들지 않았기 때문에 Flags 레시스터를 이후 연산에 사용되지 않도록 clear 0000으로 만드는 Clear Flag instruction 이 필요하다 ((c_out)=0 -\u003e 0 , (a\u003eb) -\u003e 0, (a=b) -\u003e 0, (Zero) -\u003e 0) 인 상황을 강제로 만들기 위해 BUS1 을 Enable 하면 ALU b 입력으로 1이 들어가고 A 입력은 default 값이 0 이 들어가므로 Flags 레지스터를 set 만 한다면 Flags 비트가 0000으로 초기화 된다 4. BUS1 enable, Flages set","456-단계-data-명령일-때-실행해야할-작업-목록op--0010#4,5,6 단계 DATA 명령일 때 실행해야할 작업 목록(op = 0010)":"IAR 의 값을 MAR 로 저장, BUS1 을 enable 하여 ALU 값을 실행하여 ACC 에 미리 다음 명령을 준비 MAR 에 의해 읽어낸 RAM 의 값을 RB 로 저장 ACC 의 값을 IAR 에 저장 자세한 접근\n예를 들어서 설명 현재 명령어 위치 주소는 26 이지만 명령어 가져오기 단계에서 IAR 에 이미 27 다음 단계의 명령어 위치 주소가 기다리고 있다 또한 DATA 명령에서는 27 주소(다음 명령 주소 위치)에는 명령어가 아닌 data 값이 들어 있으므로 4단계에서 IAR 의 값을 MAR 에 주면 데이터를 꺼내올수 있다 물론 앞단계에서 +1 을 하여 다음 명령을 대비한 것은 무효화 했으므로 +1 해서 다시 IAR 에 저장해야 한다 그렇게 하기 위해 bus 에 흐르는 IAR 값(2바이트 명령어 data 부분)을 ALU 로 보내고 BUS1 또한 enable 하여 ALU 에 계산된 값을 임시저장하기 위해 ACC 를 set 한다 즉 IAR enable, MAR set, BUS1 enable, ACC set RAM enable 하여 원하는 2개의 바이트로 이루어진 명령의 2번째 바이트의 명령(실제는 data) 가 버스로 흐르게 된다 버스로 흐르는 RB 에 저장하기 위해 RB 를 set ACC 에 임시 저장된 값(다음 명령어 주소 29)를 IAR 에 저장하기 위해 enable 하고 IAR 은 set 한다","456-단계-jcaez-jump-condition-명령일-때-실행해야할-작업-목록-op--0101#4,5,6 단계 J(C,A,E,Z) JUMP CONDITION 명령일 때 실행해야할 작업 목록 (op = 0101)":"c: Carry (자리올림) a: Greater than (a \u003e b) e: Equal (a = b) z: Zero (결과가 0) 일반 Jump 와 동일하게 IAR 을 MAR 에 저장 5단계에서는 분기하지 않는 상황을 처리 acc 에 있는 6단계에서는 분기하는 상황을 처리 자세한 접근 전제 조건\n5단계에서는 분기하지 않는 상황을 처리 6단계에서는 분기하는 상황을 처리 ALU 는 항상 flag 를 출력하는데 이때 BUS1 같은 상황에서 플래그 비트를 저장하지 말하야 한다 그렇다면 ALU 실행중에서만 명령에서 자리올림을 받기 위해 일반적인 ALU 연산에서는 4단계에서 TMP 레지스터를 set 하고 5단계에서 ACC 레지스터를 set 한다 이때 TMP set 의 신호가 Ctmp 와 함께 set 되며 이전에 자리올림되었던 값을 적용 시킨다 또한 이전의 ALU 명령에서 flag 레지스터를 저장하기 위해 5단계 ALU 명령에서 ACC set 신호와 함께 flags ALU set 신호를 함께 준다 각각의 IR의 4,5,6,7 번 플래그와 ALU(Flags 레지스터)를 각각 플레그를 비교하여 UPDATE IAR 을 할지 판단한다 IAR enable, MAR set, BUS1 enable 일반 JUMP 와 동일하게 IAR 을 MAR 에 저장 또한 분기 하지 않을 수 있으므로 BUS1 또한 enable bus1 enable, acc enable, IAR set 5단계에서는 분기 하지 않을 상황을 처리 미리 IAR 을 분기 하지 않을 상황으로 가정하고 BUS1 으로 계산된 +1 (조건이 맞지 않는 상황) ACC 값을 IAR 에 저장 6단계에서는 분기할 상황을 처리하므로 MAR 을 통해 접근할 주소를 얻기 위해 RAM 을 Enable, IAR 을 조건에 따라 SET","456-단계-jmp-addr-명령일-때-실행해야할-작업-목록op--0011#4,5,6 단계 JMP Addr 명령일 때 실행해야할 작업 목록(op = 0011)":"IAR 을 MAR 에 저장 RAM 에 출력을 IAR 로 저장 자세한 접근\nIAR enable, MAR set : 현재 IAR 에는 다음 명령의 주소가 지금 명령의 +1 해서 들어있다 즉 주소데이터에 분기할 주소가 적혀 있다 RAM enable, IAR set : 분기 명령이므로 IAR 의 값을 두번째 바이트의 값으로 바꿔 주어야 한다 즉 현재 저장된 주소값에 저장된 메모리에 접근해서 분기할 주소값을 가져와 IAR 에 넣어주어야 한다","456-단계-jmpr-rb-명령일-때-실행해야할-작업-목록op--0011#4,5,6 단계 JMPR RB 명령일 때 실행해야할 작업 목록(op = 0011)":"단순히 RB 에 들어있는 것을 IAR 에 저장 RB enable, IAR set : RB 를 enable 하여 bus 로 보낸다 그리고 IAR 을 set 시켜 bus 흐른 값을 저장 시켜 다음 명령에는 RB 에 들어있는 주소가 바로 실행되게 한다","456-단계-nop-명령일-때-실행해야할-작업-목록#4,5,6 단계 NOP 명령일 때 실행해야할 작업 목록":"프로그램을 멈추기 위해 inscruction fetch 모듈에서 명령을 가져오지 못하게 하면 프로그램이 멈추게 된다 된다","456단계-alu-명령일-때-실행해야할-작업-목록op_0--1#4,5,6단계 ALU 명령일 때 실행해야할 작업 목록(op_0 = 1)":"자세한 접근\n현재 RB 에 값을 bus 보내기 위해 enable 한다 ALU 는 2개의 값이 필요하므로 임시로 TMP 를 set 시켜서 bus 의 값을 임시 저장시킨다 RA 를 bus로 보내기 위해 enable 시킨다 또한 동시에 ALU 는 계산된 값을 내보내며 이것은 임시 저장하기 위해 ACC 를 set 시킨다 ACC 값을 enable 시켜서 bus 로 흐르게 한다 bus로 흐른 값이 RB 로 저장하기 위해 RB 를 set 한다 단 여기서 ALU 비교연산(OP 명령 1111)에서는 RB 로 저장하지 않는다 %% 4. RB 값 TMP 저장 5. RA 와 TMP을 ALU를 통해 계산할 것을 ACC 에 저장 6. ACC 의 값을 RB 로 저장 단 비교 연산은 제외 %%","456단계-load-store-명령일-때-실행해야할-작업-목록op--0000-op--0001#4,5,6단계 LOAD, STORE 명령일 때 실행해야할 작업 목록(op = 0000), (op = 0001)":"LOAD 4. RA 에 들어있는 RAM 주소를 MAR 에 저장 5. MAR을 통해 RAM의 데이터를 RB 에 저장\nSTORE\nRA 에 들어있는 RAM 주소를 MAR 에 저장' RB 의 데이터를 RAM 에 저장","8비트-컴퓨터-명령어-구조#8비트 컴퓨터 명령어 구조":"14 : 4비트는 명령어의 종류 선택하는 OPCODE 이다 56 : 2비트는 레지스터 선택자(RA)로 00 부터 11 까지 각각 R0, R1, R2, R3 레지스터에 매핑되어 있다 7~8 : 2비트는 레지스터 2비트는 레지스터 선택자(RB)로 00 부터 11 까지 각각 R0, R1, R2, R3 레지스터에 매핑되어 있다\n후술한 cpu 는 8비트 컴퓨터로 여러가지 제약사항이 있다\n실제 컴퓨터는 rising edge 에 set(저장) 을 하는 것이 일반적인 방식이지만 지금은 1일때 set 하는 방식으로 만들었다 ROM에 제어방식(어떤 OPCODE 일때 어떤 동작을 수행(일반적으로 레지스터 쓰기 읽기))을 적는 마이크로코드 방식이 아닌 하드웨어 기반 제어방식으로 서술 되어있다 상대적으로 적은 step 을 사용하는 명령의 경우 END_INST 비트가 있다면 남은 스텝을 밟지 않고 다시 처음 step 부터 시작할 수 있지만 opcode 의 비트수가 4개밖에 없으므로 남은 step 은 아무 실행도 하지 않지만 step 은 밟아야 한다 이를 위해 링카운터를 사용한다 (다른 종류는 리플 카운터가 있다)","alu#ALU":"아래의 조합회로들로 ALU 를 구성한다 세부적인 설계는 최적화 여부에 따라 많이 달라질 수 있다\nadder shift right shift left not ander orer ALU 는 아래의 in 그리고 out 을 가진다\nin a (첫번째 피연산자) b (두번째 피연산자) c_in ( carry in ) op (operation code) 명령어가 들어간다 out 연산 결과 c_out (carry out) a \u003e b a = b zero 결국 위의 부품을 통해 아래의 레지스터에 임시적으로 저장된다\n누산기(Accumulator): 연산 결과를 일시적으로 저장하는 레지스터입니다. ALU의 주요 연산 결과가 이곳에 저장됩니다. 피연산자 레지스터(Operand Registers): 연산에 사용되는 데이터를 저장하는 레지스터입니다. 예를 들어, 소스 레지스터(Source Register)와 대상 레지스터(Destination Register)가 있습니다. 상태 레지스터(Status Register) 또는 플래그 레지스터(Flag Register): 연산 결과에 따른 상태 정보(예: 오버플로우, 제로, 부호 등)를 저장합니다. 이는 이후 연산이나 조건 분기에 사용됩니다. flag register 의 각 비트에 이러한 bit 를 정해 위에서 나온 out 결과를 저장한다 프로그램 카운터(Program Counter): 다음에 실행할 명령어의 주소를 저장하는 레지스터로, ALU가 프로그램의 흐름을 제어하는 데 중요한 역할을 합니다.","alu-selection-module#ALU Selection module":"모든 ALU 명령은 RB 를 먼저 가져와 TMP 에 먼저 저장 그다음에 RA 를 가져와 ALU 계산을 통해 ACC 저장 ACC 저장 값을 다시 RB 에 저장하는 형태이다(비교연산을 제외하고) 즉 $RB = RA\\ (산술\\ 연산)\\ RB$ 와 같이 표현되며 ALU Selection moudle 에서는 입력 클럭 사용은 RB 에만 적용된다","d-flip-flop#D flip flop":"D latch 의 확장판\nQ 는 오직 클럭이 0 에서 1로 바뀌는 시점의 data 를 저장한다 즉 RISING EDGE 에서만 저장 허용 클럭에 사용할 수 있다 Clock Edge D Q (다음 상태) 상승/하강 0 0 상승/하강 1 1 레지스터 set = 저장 활성화 여부 enabler = 출력 활성화 여부","d-latch#D latch":"sr latch 의 확장판\n불안정 상태 즉 q = ¬Q 인 상황 제거 clk 주기에 컨트롤 가능하게 한다 clk 가 1이면 data 저장 clk 가 0 이면 data 저장하지 않는다 gate or enable Data Q 다음상태 0 0 Q (이전 상태) 0 1 Q (이전 상태) 1 0 0 1 1 1","instructio-decode-stepper-단계마다-실행해야할-작업-목록#INSTRUCTIO DECODE (Stepper 단계마다 실행해야할 작업 목록)":"아래는 ROM에 제어방식을 적는 마이크로코드 방식이 아닌 하드웨어 기반 제어방식으로 서술 되어있다\n어떤 명령이든 1,2,3 단계인 ram 에서 명령어를 꺼내와서 IR 에 저장하고 IAR 에 +1 을 하여 다시 IAR 에 저장하는 단계는 동일하다","ram#RAM":"ram은 크게 저장된 위치를 나타내는 address bus 와 data 를 저장하거나 출력해 볼 수 있는 data bus 2개로 이루어져있다 여기서 조금 더 들어가서","sr-latch#SR latch":"NOR 게이트를 사용한 SR 래치는 기본적인 SR 래치로, 아래와 같이 작동합니다.\n두 개의 NOR 게이트를 교차 연결합니다. 입력은 S(Set)와 R(Reset)입니다 S R Q (다음 상태) ¬Q (다음 상태) 0 0 Q (이전 상태) ¬Q (이전 상태) 0 1 0 1 1 0 1 0 1 1 불안정 불안정 NAND 게이트를 사용한 SR 래치는 약간 다르게 동작합니다. 이 경우에는 입력을 보통 S’와 R’으로 표기합니다.\n입력은 S’(Set)와 R’(Reset)입니다. 여기서 S’와 R’은 각각 S와 R의 부정 입력입니다. S' R' Q (다음 상태) ¬Q (다음 상태) 0 0 불안정 불안정 0 1 1 0 1 0 0 1 1 1 Q (이전 상태) ¬Q (이전 상태) \\","사용되는-레지스터#사용되는 레지스터":"범용 레지스터 실제 인스턴스 R0, R1, R2, R3 범용 레지스터 IAR(PC) : 다음 실행할 명령어의 주소를 저장하는 레지스터 IR : 현재 실행중인 명령어 그 자체를 보유 TMP : ALU 는 2개의 피연산자가 필요한데 첫번째로 bus로 흐르는 값을 임시 저장하는 레지스터 BUS1 : 다음에 실행할 명령어는 일반적으로 1 이며 이것을 회로 단에서 쉽게 계산하기 위한 TMP 와 ALU 사이에 있는 1 레지스터 ACC : ALU 로 부터 계산된 값은 임시적으로 저장하는 레지스터 MAR : 메모리 특정 위치의 값을 가리키는 레지스터 CTMP : carry out 이 발생한 것을 다시 carry in 하기위한 임시 저장 레지스터","상태-레지스터의-플래그-예시#상태 레지스터의 플래그 예시":"제로 플래그(Zero Flag, ZF): 연산 결과가 0일 때 설정됩니다. 결과가 0이 아닌 경우에는 클리어됩니다. 부호 플래그(Sign Flag, SF): 연산 결과의 최상위 비트가 1일 경우 설정됩니다. 이는 결과가 음수임을 나타냅니다. 캐리 플래그(Carry Flag, CF): 덧셈에서 자리올림이 발생하거나, 뺄셈에서 자리내림이 발생할 때 설정됩니다. 이는 또한 unsigned 연산의 오버플로우를 나타냅니다. 오버플로우 플래그(Overflow Flag, OF): 부호 있는 연산에서 오버플로우가 발생할 때 설정됩니다. 이는 결과가 표현할 수 있는 범위를 초과했음을 나타냅니다. 패리티 플래그(Parity Flag, PF): 연산 결과의 하위 8비트의 1의 개수가 짝수일 때 설정됩니다. 보조 캐리 플래그(Auxiliary Carry Flag, AF): 4비트 경계에서 자리올림이나 자리내림이 발생할 때 설정됩니다. 이는 주로 BCD(Binary-Coded Decimal) 연산에서 사용됩니다. 트랩 플래그(Trap Flag, TF): 설정되면 프로세서가 한 명령어를 실행한 후 인터럽트를 발생시킵니다. 주로 디버깅 목적으로 사용됩니다. 인터럽트 플래그(Interrupt Flag, IF): 설정되면 마스크 가능한 인터럽트를 허용합니다. 클리어되면 인터럽트가 무시됩니다. 디렉션 플래그(Direction Flag, DF): 문자열 처리 명령어에서 증가 또는 감소 방향을 설정합니다. 설정되면 감소 방향으로, 클리어되면 증가 방향으로 처리됩니다.","클럭의-종류#클럭의 종류":"원본 클럭 01010101 반복 출력 제어 011101110111 반복 enable 출력 입력 제어 001000100010 반복 set 저장"},"title":"그래서 컴퓨터는 어떻게 동작하나요 1"},"/02.inbox/%EA%B7%B8%EB%9E%98%EC%84%9C-%EC%BB%B4%ED%93%A8%ED%84%B0%EB%8A%94-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%8F%99%EC%9E%91%ED%95%98%EB%82%98%EC%9A%94/%EA%B7%B8%EB%9E%98%EC%84%9C-%EC%BB%B4%ED%93%A8%ED%84%B0%EB%8A%94-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%8F%99%EC%9E%91%ED%95%98%EB%82%98%EC%9A%94-2/":{"data":{"":"여기서 부터는 32 비트로 설계하게 된다 즉 word 가 32 비트 이다","instruction-set#Instruction set":"8비트\n0~3 4~5 6~7 OPCODE 레지스터 선택자 RA 레시스터 선택자 RB 14 : 4비트는 명령어의 종류 선택하는 OPCODE 이다 56 : 2비트는 레지스터 선택자(RA)로 00 부터 11 까지 각각 R0, R1, R2, R3 레지스터에 매핑되어 있다 7~8 : 2비트는 레지스터 2비트는 레지스터 선택자(RB)로 00 부터 11 까지 각각 R0, R1, R2, R3 레지스터에 매핑되어 있다\n32 비트","ram#RAM":"RAM 의 경우 data bit size 는 32가 가능하지만 address bit width 의 경우 32 비트가 가능하지 않다(logisim 의 한계 4기가의 메모리는 감당하지 못한다) 그러므로 address bit width 의 경우 24 비트로 한다\n현대 컴퓨터에 사용하는 RAM 과 ㄱ","ram-1#RAM":"메모리 최대 크기 위를 참고하자 Logisim에서 구현한 컴퓨터의 경우는 메인 CPU 클럭을 RAM의 클럭으로 그대로 사용한다 이러한 설계는 실제 현재 컴퓨터와 비교했을 때 훨씬 간단하게 구현이 가능하지만 현대 컴퓨터의 경우에는 다른 점이 여러가지가 있다 하지만 여기에서는 2가지 차이와 그로 인한 문제(?)에 대해 이야기 해본다\ndata bit width 의 크기가 현대 RAM 의 경우는 8bit(1Byte) 하지만 Logisim 으로 구현한 RAM 의 경우에는 32bit(4Byte) 현대 컴퓨터의 경우에는 RAM 이 CPU의 클럭을 그대로 사용하지 않는다 하지만 Logisim 으로 구현한 컴퓨터의 경우에는 RAM 이 CPU 의 클럭을 그대로 사용한다 실제 cpu는 MMU 메모리 실제 주소 변경 유닛 과 같은 것이 있지만 이 cpu 에서는 없다 현대 cpu 의 경우 주소 버스, 데이터 버스, 제어 버스와 같은 것들이 구분되어 있지만 여기서는 모든 버스를 구분해서 사용하지는 않는다 초기에는 controll unit 에서 실제 어떠한 동작을 하는지 각각의 배선을 따로 만들었지만 지금은 ROM 을 이용해서 각 명령어 마다 행동해야할 행동을 ROM 에 저장할 수 있다 이를 전문 용어로 제어메트릭스에서 마이크로 코드 방식으로 변경한다 라고 이야기한다","register#Register":"IAR INSTRUCTION ADDRESS REGISTER 을 PC PROGRAM COUTER 로 표기한다 레지스터의 경우 7비트에서는 2개가 존재했다","변경점#변경점":""},"title":"그래서 컴퓨터는 어떻게 동작하나요 2"},"/02.inbox/%EA%B7%B8%EB%9E%98%EC%84%9C-%EC%BB%B4%ED%93%A8%ED%84%B0%EB%8A%94-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%8F%99%EC%9E%91%ED%95%98%EB%82%98%EC%9A%94/risc-v-%EB%AA%85%EB%A0%B9%EC%96%B4-%EA%B5%AC%EC%A1%B0/":{"data":{"":"RISC-V emulator RV32I 를 코드로 구현하기 위해 먼저 RISC-V 공식 문서를 확인하여 구현할 명령의 구조를 공부한다\nRISC V 의 경우 32비트인지 64 비트인지 128비트인지에 따라 RV32, RV64, RV128 로 나누어지며 기본적인 명령인 integer instruction set 을 구현하면 RV32I, RV64I, RV128I 라고 불리운다 또한 아래의 4가지 확장을 추가하여 자유롭게 가능한 명령을 추가 할 수 있다 또한 문서는 2가지로 privilige 명령과 non privilige 명령 문서가 있으며 아래는 non privilige 명령만을 설명한다\n1권, 권한 없는 사양 버전 20240411 PDF, GitHub 2권, 권한 사양 버전 20240411 PDF, GitHub non privilige 의 확장 명령 종류\nM : multifly 정수 곱셈 및 나눗셈 확장 A : atomic 원자적 연산 확장 멀티 코어의 공유 자원 접근을 위한 명령) F : Single-Precision Floating-Point 단정밀도 부동소수점에 대한 표준 확장 D : Double-Precision Floating-Point 배정밀로 부동소수점에 대한 표준 확장 Q : Quad-Precision Floating-Point 쿼드정밀도 부동소수점에 대한 표준 확장 L : Decimal Floating-Point 10진수 부동소수점에 대한 표준 확장 C : Compressed Instructions 압축 명령어용 명령 B : Bit Manipulation 비트 조작 명령 J : Dynamically Translated Languages 동적 번역용 언어 T : Transactional Memory 트랜잭션 메모리용 확장 P : Packed-SIMD Instructions V : Vector Operations 벡터 확장 N : Standard Extension for User-Level Interrupts 유저 레벨 인터럽트","risc-v-register-종류#RISC-V Register 종류":"Register ABI Name Description Saver x0 zero Hard-wired zero — x1 ra Return address Caller x2 sp Stack pointer Callee x3 gp Global pointer — x4 tp Thread pointer — x5 t0 Temporary/alternate link register Caller x6–7 t1–2 Temporaries Caller x8 s0/fp Saved register/frame pointer Callee x9 s1 Saved register Callee x10–11 a0–1 Function arguments/return values Caller x12–17 a2–7 Function arguments Caller x18–27 s2–11 Saved registers Callee x28–31 t3–6 Temporaries Caller ==== ==== F, D등의 부동소수점 확장 시에만 ==== f0–7 ft0–7 FP (Floating Point) temporaries Caller f8–9 fs0–1 FP saved registers Callee f10–11 fa0–1 FP arguments/return values Caller f12–17 fa2–7 FP arguments Caller f18–27 fs2–11 FP saved registers Callee f28–31 ft8–11 FP temporaries Caller","rv32i-세부-명령-종류#RV32I 세부 명령 종류":"Type Instruction Description 한글 설명 명령어 예시 명령어 설명 R-type ADD Add 덧셈 add x1, x2, x3 x1 = x2 + x3 R-type SUB Subtract 뺄셈 sub x1, x2, x3 x1 = x2 - x3 R-type SLL Shift Left Logical 논리적 왼쪽 시프트 sll x1, x2, x3 x1 = x2 « x3 R-type SLT Set Less Than 작음 설정 slt x1, x2, x3 x1 = (x2 \u003c x3) ? 1 : 0 R-type SLTU Set Less Than Unsigned 부호 없는 작음 설정 sltu x1, x2, x3 x1 = (x2 \u003c x3) ? 1 : 0 (부호 없음) R-type XOR Exclusive OR 배타적 논리합 xor x1, x2, x3 x1 = x2 ^ x3 R-type SRL Shift Right Logical 논리적 오른쪽 시프트 srl x1, x2, x3 x1 = x2 » x3 (논리적) R-type SRA Shift Right Arithmetic 산술적 오른쪽 시프트 sra x1, x2, x3 x1 = x2 » x3 (산술적) R-type OR OR 논리합 or x1, x2, x3 x1 = x2 | x3 R-type AND AND 논리곱 and x1, x2, x3 x1 = x2 \u0026 x3 I-type ADDI Add Immediate 즉시값 덧셈 addi x1, x2, 10 x1 = x2 + 10 I-type SLTI Set Less Than Immediate 즉시값 작음 설정 slti x1, x2, 10 x1 = (x2 \u003c 10) ? 1 : 0 I-type SLTIU Set Less Than Immediate Unsigned 부호 없는 즉시값 작음 설정 sltiu x1, x2, 10 x1 = (x2 \u003c 10) ? 1 : 0 (부호 없음) I-type XORI Exclusive OR Immediate 즉시값 배타적 논리합 xori x1, x2, 0xFF x1 = x2 ^ 0xFF I-type ORI OR Immediate 즉시값 논리합 ori x1, x2, 0xFF x1 = x2 | 0xFF I-type ANDI AND Immediate 즉시값 논리곱 andi x1, x2, 0xFF x1 = x2 \u0026 0xFF I-type SLLI Shift Left Logical Immediate 즉시값 논리적 왼쪽 시프트 slli x1, x2, 2 x1 = x2 « 2 I-type SRLI Shift Right Logical Immediate 즉시값 논리적 오른쪽 시프트 srli x1, x2, 2 x1 = x2 » 2 (논리적) I-type SRAI Shift Right Arithmetic Immediate 즉시값 산술적 오른쪽 시프트 srai x1, x2, 2 x1 = x2 » 2 (산술적) I-type LB Load Byte 바이트 로드 lb x1, 0(x2) x1 = MEM[x2 + 0] (1 byte) I-type LH Load Halfword 하프워드 로드 lh x1, 2(x2) x1 = MEM[x2 + 2] (2 bytes) I-type LW Load Word 워드 로드 lw x1, 4(x2) x1 = MEM[x2 + 4] (4 bytes) I-type LBU Load Byte Unsigned 부호 없는 바이트 로드 lbu x1, 0(x2) x1 = MEM[x2 + 0] (1 byte, 부호 없음) I-type LHU Load Halfword Unsigned 부호 없는 하프워드 로드 lhu x1, 2(x2) x1 = MEM[x2 + 2] (2 bytes, 부호 없음) I-type JALR Jump and Link Register 레지스터로 점프 및 링크 jalr x1, 0(x2) x1 = PC + 4; PC = x2 + 0 S-type SB Store Byte 바이트 저장 sb x1, 0(x2) MEM[x2 + 0] = x1 (1 byte) S-type SH Store Halfword 하프워드 저장 sh x1, 2(x2) MEM[x2 + 2] = x1 (2 bytes) S-type SW Store Word 워드 저장 sw x1, 4(x2) MEM[x2 + 4] = x1 (4 bytes) B-type BEQ Branch if Equal 같으면 분기 beq x1, x2, label if (x1 == x2) PC = label B-type BNE Branch if Not Equal 다르면 분기 bne x1, x2, label if (x1 != x2) PC = label B-type BLT Branch if Less Than 작으면 분기 blt x1, x2, label if (x1 \u003c x2) PC = label B-type BGE Branch if Greater Than or Equal 크거나 같으면 분기 bge x1, x2, label if (x1 \u003e= x2) PC = label B-type BLTU Branch if Less Than Unsigned 부호 없이 작으면 분기 bltu x1, x2, label if (x1 \u003c x2) PC = label (부호 없음) B-type BGEU Branch if Greater Than or Equal Unsigned 부호 없이 크거나 같으면 분기 bgeu x1, x2, label if (x1 \u003e= x2) PC = label (부호 없음) U-type LUI Load Upper Immediate 상위 즉시값 로드 lui x1, 0x12345 x1 = 0x12345000 U-type AUIPC Add Upper Immediate to PC PC에 상위 즉시값 더하기 auipc x1, 0x12345 x1 = PC + 0x12345000 J-type JAL Jump and Link 점프 및 링크 jal x1, label x1 = PC + 4; PC = label I-type FENCE Fence 펜스 fence 메모리 순서 보장 I-type FENCE.I Fence Instruction 명령어 펜스 fence.i 명령어 캐시 동기화 I-type ECALL Environment Call 환경 호출 ecall 시스템 콜 I-type EBREAK Environment Break 환경 중단 ebreak 디버그 중단점 I-type CSRRW Atomic Read/Write CSR 원자적 CSR 읽기/쓰기 csrrw x1, csr, x2 t = CSR; CSR = x2; x1 = t I-type CSRRS Atomic Read and Set Bits in CSR 원자적 CSR 읽기 및 비트 설정 csrrs x1, csr, x2 t = CSR; CSR = t | x2; x1 = t I-type CSRRC Atomic Read and Clear Bits in CSR 원자적 CSR 읽기 및 비트 클리어 csrrc x1, csr, x2 t = CSR; CSR = t \u0026 ~x2; x1 = t I-type CSRRWI Atomic Read/Write CSR (Immediate) 원자적 CSR 읽기/쓰기 (즉시값) csrrwi x1, csr, 5 t = CSR; CSR = 5; x1 = t I-type CSRRSI Atomic Read and Set Bits in CSR (Immediate) 원자적 CSR 읽기 및 비트 설정 (즉시값) csrrsi x1, csr, 5 t = CSR; CSR = t | 5; x1 = t I-type CSRRCI Atomic Read and Clear Bits in CSR (Immediate) 원자적 CSR 읽기 및 비트 클리어 (즉시값) csrrci x1, csr, 5 t = CSR; CSR = t \u0026 ~5; x1 = t","명령어-기본-구조#명령어 기본 구조":"Bits 31 - 25 24 - 20 19 - 15 14 - 12 11 - 7 6 - 0 R-type funct7 rs2 rs1 funct3 rd opcode I-type imm[11:0] '' rs1 funct3 rd opcode S-type imm[11:5] rs2 rs1 funct3 imm[4:0] opcode B-type imm[12|10:5] rs2 rs1 funct3 imm[4:1| 11] opcode U-type imm[31:12] '' '' '' rd opcode J-type imm[20|10:1|11|19:12] '' '' '' rd opcode"},"title":"RISC V 명령어 구조"},"/02.inbox/%EB%82%A0%EC%A7%9C-%ED%98%95%EC%8B%9D-%ED%8F%AC%EB%A9%A7/":{"data":{"":"https://momentjs.com/docs/#/displaying/format/\nToken Output Month M 1 2 … 11 12 Mo 1st 2nd … 11th 12th MM 01 02 … 11 12 MMM Jan Feb … Nov Dec MMMM January February … November December Quarter Q 1 2 3 4 Qo 1st 2nd 3rd 4th Day of Month D 1 2 … 30 31 Do 1st 2nd … 30th 31st DD 01 02 … 30 31 Day of Year DDD 1 2 … 364 365 DDDo 1st 2nd … 364th 365th DDDD 001 002 … 364 365 Day of Week d 0 1 … 5 6 do 0th 1st … 5th 6th dd Su Mo … Fr Sa ddd Sun Mon … Fri Sat dddd Sunday Monday … Friday Saturday Day of Week (Locale) e 0 1 … 5 6 Day of Week (ISO) E 1 2 … 6 7 Week of Year w 1 2 … 52 53 wo 1st 2nd … 52nd 53rd ww 01 02 … 52 53 Week of Year (ISO) W 1 2 … 52 53 Wo 1st 2nd … 52nd 53rd WW 01 02 … 52 53 Year YY 70 71 … 29 30 YYYY 1970 1971 … 2029 2030 YYYYYY -001970 -001971 … +001907 +001971 Note: (Covering the full time value range of approximately 273,790 years forward or backward from 01 January, 1970) Y 1970 1971 … 9999 +10000 +10001 Note: This complies with the ISO 8601 standard for dates past the year 9999 Era Year y 1 2 … 2020 … Era N, NN, NNN BC AD Note: Abbr era name NNNN Before Christ, Anno Domini Note: Full era name NNNNN BC AD Note: Narrow era name Week Year gg 70 71 … 29 30 gggg 1970 1971 … 2029 2030 Week Year (ISO) GG 70 71 … 29 30 GGGG 1970 1971 … 2029 2030 AM/PM A AM PM a am pm Hour H 0 1 … 22 23 HH 00 01 … 22 23 h 1 2 … 11 12 hh 01 02 … 11 12 k 1 2 … 23 24 kk 01 02 … 23 24 Minute m 0 1 … 58 59 mm 00 01 … 58 59 Second s 0 1 … 58 59 ss 00 01 … 58 59 Fractional Second S 0 1 … 8 9 SS 00 01 … 98 99 SSS 000 001 … 998 999 SSSS … SSSSSSSSS 000[0..] 001[0..] … 998[0..] 999[0..] Time Zone z or zz EST CST … MST PST Note: as of 1.6.0, the z/zz format tokens have been deprecated from plain moment objects. Read more about it here. However, they do work if you are using a specific time zone with the moment-timezone addon. Z -07:00 -06:00 … +06:00 +07:00 ZZ -0700 -0600 … +0600 +0700 Unix Timestamp X 1360013296 Unix Millisecond Timestamp x 1360013296123"},"title":"날짜 형식 포멧"},"/02.inbox/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EA%B4%80%EB%A0%A8-%EB%AA%85%EB%A0%B9%EC%96%B4-%EB%AA%A8%EC%9D%8C/":{"data":{"":"","ip#ip":"ip route ip addr","linux#linux":"ss -ltan : -l listen, -a all, -t tcp, -n numeric","unix-공통#unix 공통":"ifconfig netstat ping traceroute : 지나간 네트워크 대역 확인 nc(netcat) : nmap : route : 라우팅 테이블? arp : 동일 네트워크 맥주소 확인 프로토콜 telnet","window#window":"ipconfig netstat ping arp : 동일 네트워크 맥주소 확인 프로토콜 tracert\n================= mac 맥 환경에서, 잘모르는 프레임웍 이용한 서버 동작시, 특정프로그램 이용시, 내가 사용하는 것 외 데이터가 세어나가는지, 내가 모르는 포트를 열어놓은 프로세스가 있는지 (찾아서 kill하려고), 혹은 방화벽 제외 / NAT환경에서의 포트포워딩 정책에 SNAT, DNAT등에 포트 값을 알아내야 할 경우 lsof와 netstast과 다음과 같은 옵션으로 찾으면 된다. (기타 : linux의 경우 netstat -anp | grep 포트번호 or LISTEN or EST등의 소켓 상태로 필터링해서 사용해왔음)\nlsof (list open files) 이용시 $ sudo lsof -iTCP -sTCP:LISTEN -n -P"},"title":"네트워크 관련 명령어 모음"},"/02.inbox/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EC%9D%B8%ED%84%B0%ED%8E%98%EC%9D%B4%EC%8A%A4/":{"data":{"":"","linux#Linux":"enp0s1: | | | v | | en| | --\u003e ethernet v | p0| --\u003e bus number (0) v s1 --\u003e slot number (1) * Two character prefixes based on the type of interface: * en — Ethernet * sl — serial line IP (slip) * wl — wlan * ww — wwan * * Type of names: * b — BCMA bus core number * c — CCW bus group name, without leading zeros [s390] * o[d] — on-board device index number * s[f][d] — hotplug slot index number * x — MAC address * [P]ps[f][d] * — PCI geographical location * [P]ps[f][u][..][c][i] * — USB port number chain 1. 온보드 장치에 대해 펌웨어/BIOS 제공 인덱스 번호를 통합한 이름(예: eno1) 2. 펌웨어/BIOS 제공 PCI Express 핫플러그 슬롯 인덱스 번호를 포함하는 이름(예: ens1) 3. 하드웨어 커넥터의 물리적/지리적 위치를 통합한 이름(예: enp2s0) 4. 인터페이스의 MAC 주소를 통합한 이름(예: enx78e7d1ea46da) 5. 예측할 수 없는 고전적인 커널 기반 ethX 이름 지정(예: eth0)","mac-os#mac OS":"ap1: 액세스 포인트. MacBook을 연결을 공유하는 무선 호스트로 사용하는 경우에 사용됩니다. awdl0: Apple Wireless Direct 링크. AirDrop, Airplay 등을 위한 WIFI p2p 연결. Bluetooth에도 사용됩니다. llw0: 대기 시간이 짧은 WLAN 인터페이스. Skywalk 시스템에서 사용됩니다. utun0: 터널링 인터페이스. 터널 트래픽에 대한 VPN 연결이나 Back To My Mack와 같은 소프트웨어에 사용됩니다. utun1: utun01과 동일 lo0: 루프백(localhost) gif0: 소프트웨어 네트워크 인터페이스 stf0: 6to4 터널 인터페이스 en0: 물리적 무선 en1: 썬더볼트 1 en2: 썬더볼트 2 en3: 썬더볼트 3 en4: 썬더볼트 4 en5: iBridge / Apple T2 컨트롤러 en6: 블루투스 팬 en8: 아이폰 USB en9: VM 네트워크 인터페이스 en10: 아이패드 bridge0: Thunderbolt 브리지"},"title":"네트워크 인터페이스"},"/02.inbox/%EB%8C%80%EC%86%8C%EB%AC%B8%EC%9E%90-%EA%B5%AC%EB%B6%84-%EB%B6%88%EA%B0%80-%EB%AC%B8%EC%A0%9C/":{"data":{"":"window os(NTFS), mac os(APFS) 파일 시스템의 경우 대소문자 구분이 되지 않는다 위의 두 os는 사람들이 많이 쓰는 os 이므로 이 문제에 관해 git 은 대소문자 구분을 하지 않는 것을 기본으로 설정한다\n이에 대해 두가지 방법이 있다\n설정 자제를 변경(한프로젝트 에서만 동작)(global 은 따로 설정) git config core.ignorecase false # default true git rm -r --cached . # 캐쉬 삭제 git 의 기능을 사용한다( 전체 config 변경에 따른 사이드 이팩트 원천 봉쇄) git mv test Test"},"title":"대소문자 구분 불가 문제"},"/02.inbox/%EB%8C%80%EC%B9%AD%ED%82%A4-%EB%B9%84%EB%8C%80%EC%B9%AD%EA%B8%B0-%EC%95%94%ED%98%B8%ED%99%94/":{"data":{"":"단방향 암호화 : 일종의 해시 단일문자 대응 암호 블록 암호화 PGP TLS IPsec , SHA-256, SHA-1, MD5 등 db 에 비밀번호를 저장할 떄는 단방향 암호화 데이터 무결성 검증 (예: 파일 해시 비교, TCP UDP 의 checksum) 양방향 암호화 대칭키: 암호화와 복호화에 동일한 키를 사용하는 암호 방식이다. $K_{a} = K_{b}$ AES, DES 비대칭키: 개인키(비밀) 공개키(공개)로 키가 나뉘며 1개의 키로 암호화 1개의 키로 복호화 하는 방법 $K_{a} \\neq K_{b}$ server or client: $A, B$ 공개키: $K^{+}{A,B}$ , 개인키: $K^{-}{A,B}$ public key 암호화 =\u003e 종단간 암호화 $K^{+}{A}(K^{-}{A}(m)) = m$ private key 암호화 =\u003e 인증 $K^{-}{A}(K^{+}{A}(m)) = m$ 기밀성\n메세지 무결성\n종단점 인증\n운영보안\n운영보안 블럭 암호화\nk == 64 이면 64 비트블록으로 쪼개어 각 블록을 독립적으로 암호화 한다","cacertification-authority로부터-얻는-것#CA(Certification Authority)로부터 얻는 것":"CA는 신뢰할 수 있는 제3자 기관으로, 엔터티(사람, 서버, 라우터 등)의 신원을 검증하고 해당 엔터티의 공개 키에 대한 **인증서(Certificate)**를 발급하는 역할을 합니다. CA로부터 받는 주요 정보는 다음과 같습니다:\n인증서 (Certificate): 인증서는 특정 엔터티의 공개 키와 해당 엔터티의 식별 정보(예: 웹 서버의 도메인 이름, 조직 이름, IP 주소 등)를 묶어서 CA가 디지털 서명한 것입니다. 이 인증서는 송신자(예: 웹 서버)가 자신의 공개 키를 수신자(예: 클라이언트)에게 안전하게 제공할 수 있도록 합니다. 클라이언트는 CA의 공개 키를 사용하여 서버 인증서의 유효성을 검증합니다. 만약 인증서가 CA에 의해 올바르게 서명되었고 유효 기간 내에 있다면, 클라이언트는 해당 인증서에 포함된 공개 키가 주장된 엔터티(서버)에게 실제로 속한다고 신뢰할 수 있습니다. 이는 Trudy와 같은 공격자가 Bob으로 가장하여 자신의 공개 키를 Alice에게 보내는 신원 위조(masquerading) 공격을 방지하는 데 필수적입니다.","private-key로-암호화-하는-경우#Private Key로 암호화 하는 경우":"Private Key의 소유자가 Private Key로 data를 암호화하고 Public Key와 함께 전달한다.\n이 과정에서 Public Key와 data를 획득한 사람은 Public key를 이용하여 복호화가 가능하다. 이런 위험에도 불구하고 이 방법을 사용하는 이유는 data 보호의 목적 보다는 Public Key data 제공자의 신원을 보장해주기 때문이다. 암호화된 data가 Public Key로 복호화 된다는 것은 Public Key와 쌍을 이루는 Private Key에 의해서 암호화 되었다는 것을 의미한다. 즉 data 제공자의 신원 확인이 보장된다는 것이다.\n이 방법이 공인인증체계의 기본 바탕이 되는 전자 서명이라는 것이다. #ModificationRequired\nHTTPS와 비대칭 키 초기 설정부터 데이터 전송까지의 모든 과정 simulation","public-key로-암호화-하는-경우#Public Key로 암호화 하는 경우":"상대방의 Public key로 data를 암호화 하고 전송하면, data를 수신한 사람은 자신의 Private key로 data를 복호화 한다.\nA 키로 암호화 한다면, B키로 복호화가 가능하고, B키로 암호화를 한다면 A키로 복호화가 가능한 것이다. Public Key는 널리 배포될 수 있기 때문에 많은 사람들이 한 명의 Private Key 소유자에게 data를 보낼 수 있다.","rsa-알고리즘#RSA 알고리즘":"덧셈: $[(a \\mod n) + (a \\mod n)] = (a + b) \\mod n$ 뺄셈: $[(a \\mod n) - (a \\mod n)] = (a - b) \\mod n$ 곱셈: $[(a \\mod n) \\cdot (a \\mod n)] = (a \\cdot b) \\mod n$","대칭키#대칭키":"대칭키의 경우 키를 미리 공유되어 있다는 가정이 있어야 한다","비대칭키--공개키-암호화#비대칭키 = 공개키 암호화":""},"title":"대칭키 비대칭기 암호화"},"/02.inbox/%EB%8C%80%ED%95%99%EA%B5%90-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/":{"data":{"":"cpu 동작 과정 cpu 구조 주요 부품\n레지스터 PC 프로그램 카운터 (progam counter) : 다음에 실행될 메모리 주소를 저장 MAR 메모리 주소 레지스터 (memory Address registor) : pc 에서 주소를 넘겨 받아 메인 메모리에 접근해 데이터를 MBR (memory buffer registor)에 저장하는 역할 MBR 메모리 버퍼 레지스터 (memory buffer registor) : MBR 을 통해 가져온 데이터를 임시 저장, 명령 부분은 IR(Instruction Register) 에 저장, 연산에 사용될 데이터는 AC(Accumulator) 누산기 레지스터에 저장, 메모리에 저장될 데이터를 임시 저장 IR 명령어 레지스터 (Instruction Register) : 현재 실행되고 있는 명령을 저장하는 레지스터 AC 누산기 (Accumulator) : ALU 연산을 위한 레지스터로서 연산해야 할 값 또는 연산 결과를 임시 저장 coutrol 제어장치 : 명령어 레지스터 IR 에 있는 명령을 받아 해석하고 장치들을 제어 ALU : 산술 논리 연산 장치 추가 부품\nBR(Base Register): 명령의 시작 주소를 기억하는 레지스터 MSR(Major Status Register): CPU의 주 상태를 저장하는 레지스터 플래그 레지스터(Flag Register): 상태를 기억하는 레지스터(오버플로우, 언더플로, 캐리, 인터럽트 등의 PSW를 기억) PSW(Program Status Word)는 시스템 내부의 순간순간의 상태를 기록하고 있는 정보를 말합니다. 상태 플래그 커널모드 사용자 모드 비트가 들어감 (플래그 레지스터 인가 MSR 레시스터인가) 명령 동작과정 기계어 로 적힌 프로그램은 각각의 몇 비트 컴퓨터 인지에 따라 명령어의 크기 + 데이터의 크기 == n 비트 컴퓨터 이다\nA = B + C ===== LOAD [10] //10 주소의 데이터를 레지스터로 로드 ADD [11] //11 주소의 데이터와 더함 STORE [12] //12 주소에 저장 100 주소가 현재 pc 에 저장되어 있다\npc 의 값을 MAR 에 저장 MAR 의 값을 참조하여 메모리의 데이터를 로드하여 MBR 에 저장 MBR 의 명령어와 데이터중 명령어만을 IR 에 저장 ==\u003e 인출\nPC 값을 증가시켜 다음 명령의 주소를 저장(n 비트 크기 만큼) 명령어 레지스터의 값을 제어장치로 해석한다 제어장치는 10 주소를 MAR에 저장, 메모리 주소에 접근하여 데이터를 MBR 에 저장한다 ==\u003e 해석\nPC값을 MAR로 복사, MAR의 메모리 주소를 참조해 명령과 데이터 주소를 MBR,IR에 저장 ==\u003e 인출 PC 값 증가 IR 의 값을 제어장치가 해석하는데 add 이므로 누산기에 저장된 이전 값을 ALU 전송 11 주소의 값을 MAR 저장, 11 주소의 데이터를 MBR 에 저장 =\u003e 인출 제어장치는 MBR 의 값을 누산기에 저장, 누산기에 저장된 값을 ALU 로 전송 ALU 의 계산된 값을 누산기로 저장 ==\u003e실행\nPC 값을 MAR 로 복사, MAR 의 메모리 주소를 참조하여 명령 및 데이터 주소를 MBR, IR 에 저장 PC 값 증가 MBR 의 값을 제어장치가 해석하여 12 주소를 MAR 에 저장, 누산기의 값을 MBR 에 저장 제어장치가 MBR 을 MAR 에 저장된 주소값에 저장 ==\u003e 저장\n인터럽트 인터럽트는 컴퓨터 하드웨어나 소프트웨어가 CPU에게 어떤 사건이 발생했음을 알리는 방법 기준에 따라 분류\n기준의 분류","1-fcfs-first-come-first-served#1. FCFS (First Come First Served)":"요청이 들어온 순서대로 디스크 요청을 처리합니다. 디스크 헤드의 이동 거리가 길어질 수 있습니다. 요청 처리 시간이 길어질 수 있습니다, 특히 요청이 분산되어 있을 때.","2-sstf-shortest-seek-time-first#2. SSTF (Shortest Seek Time First)":"현재 디스크 헤드 위치에서 가장 가까운 트랙의 요청을 먼저 처리합니다.\n디스크 헤드 이동 거리를 최소화하려는 알고리즘입니다.\n평균 응답 시간이 짧아질 수 있습니다.\n특정 요청이 계속해서 뒤로 밀리는 “기아” 현상이 발생할 수 있습니다.","3-scan#3. SCAN":"디스크 헤드가 한쪽 끝에서 시작하여 다른 쪽 끝으로 이동하면서 모든 요청을 처리합니다.\n끝에 도달하면 반대 방향으로 이동하며 요청을 처리합니다.\n엘리베이터 알고리즘이라고도 불립니다.\n요청이 고르게 처리됩니다.\n디스크 헤드의 이동이 일정합니다.\n양방향으로 이동하므로, 끝에서 끝으로 이동하는 시간이 길어질 수 있습니다.","4-c-scan-circular-scan#4. C-SCAN (Circular SCAN)":"SCAN 알고리즘과 비슷하지만, 한쪽 끝에서 다른 쪽 끝으로 이동한 후, 다시 처음으로 돌아가서 요청을 처리합니다.\n디스크 헤드는 항상 한 방향으로만 이동합니다.\n요청 처리 순서가 균일합니다.\n디스크 헤드가 한쪽 방향으로만 이동하므로 SCAN보다 예측이 쉽습니다.\n단점:\n끝에서 처음으로 돌아가는 동안의 이동 시간은 비효율적일 수 있습니다. 이러한 디스크 스케쥴링 알고리즘은 각각의 특성과 장단점을 가지고 있으며, 시스템의 요구사항과 환경에 따라 선택될 수 있습니다.","5-c-look#5. c LOOK":"c-scan 과 비슷하지만 끝가지 이동하는 것이 아닌 최소 최대 요청 블록 까지만 이동합니다","cpu-구조#cpu 구조":"","cpu-동작-과정#cpu 동작 과정":"","ipc-inter-process-communication#IPC (Inter-process communication)":"공유 메모리(Shared memory), 메시지 전달(Message passing)\ndata transfer byte stream pipe named pipe(fifo) socket(stream) message posix message queue sysV message queue socket(datagram) shared memory file memory mapping anonymous mapping file mapping shared memory sysV shared memory posix shared memory synchronization semaphore posix memaphore sysV semaphore file lock file lock record lock","교착상태#교착상태":"","교착상태-조건-모두-만족해야-교착-가능성#교착상태 조건 모두 만족해야 교착 가능성":"상호배제(Mutual exclusion) 한번에 오직 한 프로세스만이 자원을 사용할 수 있다. 점유와 대기(Hold and wait) 프로세스가 적어도 하나의 자원을 점유하면서 다른 프로세스가 점유하고 있는 자 원을 추가로 얻기위해 대기한다. 비선점(No preemption) 점유된 자원은 강제로 반환될 수 없고, 점유하고 있는 프로세스가 작업을 마치고 자원을 자발적으로 반환한다. 순환대기(Circular wait) 대기하고 있는 프로세스 집합 {P0 , P1 , …, Pn }에서 P0 은 P1이 점유한 자원을 대기하 고, P1은 P2가 점유한 자원을 대기하고, Pn–1 은 계속해 Pn을 대기하며, Pn은 P0이 점유한 자원을 대기한다.","메모리-관리#메모리 관리":"주소 바인딩 컴파일 시간 : 적재 위치를 변경하고 싶으면 다시 컴파일 해야함 적재시간 : 적재 할 때 결정 실행시간 : 적재후 실행시간에도 실시간으로 위치가 변경할 수 있음 지금은 적재시간과 실행시간 주소 바인딩을 섞어서 사용한다 주소의 종류 논리주소 : 프로세스가 실행하면서 cpu가 생성하는 주소 \u0026 컴파일러가 생성한 주소 물리주소 : 기억장치가 나타내는 주소 주소변환 장치 : MMU 주소변환 하드웨어 장치 MMU relocation register : 주소 변환을 할 변위값 레지스터 relocation register 에 연속할당 기법의 경우 프로세스의 절대 주소가 담기지만 페이징에서는 PT(페이지 테이블) 에 담긴 주소를 담는다 4가지 할당 기법 먼저 알아햐 할 것 외부 단편화 : 가용 공간의 합은 충분한데 공간에 연속되지 않았을 때 생기는 문제 내부 단편화 : 할당된 기억공간 대비 프로세스가 사용하지 않는 문제 연속 할당 기법 : (MS-DOS) 빈공간을 찾아서 프로세스를 생성해야 한다 최초 적합 : 충분한 것 중에서 첫번째 가용 공간에 할당 최적 적합 : 중분 한 것 중에서 가장 작은 가용 공간에 할당 최악 적합 : 충분한 것 중에서 가장 작은 가용 공간에 할당 외부 단편화 문제만 발생 : 프로세스의 크기만큼 바이트 단위로 할당하기 때문에 없다 페이징 : 페이지 라는 단위로 쪼개는 방식 프레임(512B ~ 4KB) 페이지크기 = 프레임크기 페이지 테이블 = 페이지 매핑 테이블 = 페이지 맵 테이블 : 어떤 페이지를 점유하고 있는가를 각각의 프로세스 마다 기록됨 즉 PCB 에 담겨짐 페이지 번호 + offset(페이지 내부에서 위치) K = 2^10 M = 2^20 G 2^30 TLB : 하드웨어 캐쉬 MMU 내부에 있음 병렬 검색 가능 TLB 검색후 있으면 hit 판정 없으면 페이지 테이블 검색 페이지 보호 : 페이지마다 보호용 비트를 두고 MMU 가 보호용 비트를 검사한다 읽기 전용 페이지에 대해 쓰기를 하면 MMU 는 인터럽트를 발생시킴 공유 페이지 : 하나의 동일한 실행파일을 여러사람이 사용하면 프로세스마다 동일한 코드와 데이터 부분의 메모리를 사용하게 된다 이때 코드의 부분은 읽기 전용 파일이기 때문에 프로세스 2개 이상에서 동일마게 유지된다 그러면 우리는 2개 이상 생성하지 않고 1개의 코드부분을 공유하면 된다 현대의 페이지 테이블 졸라 크다 거이 32 비트 컴퓨터는 페이지크기가 4k 이면 2^20 1M 이고 각 항목이 4B 라면 4MB 이다 64 비트 컴퓨터는 어마어마 해진다 모든 프로세스마다 이만큼 먹고 있는 것이다 즉 해결방법 계층적 테이블 : 사용하지 않는 페이지들이 존재하므로 단계를 나누어 outer table 만들어 사용한다 해쉬된 페이지 테이블 : 해쉬함수를 이용하여 접근에 필요한 가짓수를 빠르게 줄인다 역 페이지 테이블 : ???","메모리-구조#메모리 구조":"메모리\nROM (비휘발성) 부트로더 RAM (휘발성) IVT 인터럽트 백터 테이블 os(os 내부에 인터럽트 실제 데이터 존재) 응용프로그램","명령-동작과정#명령 동작과정":"","문제#문제":"프로세서에서 산술, 논리 연산을 수행하는 장치는 무엇인가? =\u003e ALU 프로세서의 산술 연산의 결과, 프로세서 동작 모드 등을 저장하는 레지스터는 무엇인가? =\u003e 상태 레지스터 프로세서의 모드 중에서 제한 없이 모든 명령어를 사용할 수 있는 모드는 =\u003e 커널 모드 refresh가 필요한 RAM은 무엇인가 =\u003e dram ROM의 종류로서 데이터를 삭제하고 기록할 수 있는 ROM은 무엇인가? =\u003e eprom(자외선 삭제,전류 기록), eeprom(전류 삭제, 전류 기록) 저장장치 계층을 구분하는 성질 3가지는 무엇인가? =\u003e 속도, 가격, 휘발성 저장장치 계층의 저장장치 중에서 CPU와의 데이터 전송이 하드웨어적으로 이루어지는 것은 무엇인가? 하드웨어 인터럽트의 예를 2가지 들어보시오. =\u003e cpu 타이머 인터럽트, io 인터럽트 소프트웨어 인터럽트 예를 2가지 들어보시오. =\u003e systemcall, trap 예외 인터럽트 인터럽트가 발생하면 수행되는 운영체제의 코드를 무엇이라 하는가? =\u003e isr 인터럽트 벡터 테이블이란 무엇인가? =\u003e isr 의 처리 코드의 주소가 적혀있는 테이블 인터럽트 처리 과정 중, 하드웨어적인 처리 과정을 적으시오. =\u003e 상태 레지스터 저장 프로세서 모드 커널모드로 변경 현제 저장된 pc 레지스터 저장 발생된 isr 주소를 pc 레지스터로 저장 마이크로 커널 구조의 장단점을 설명하시오. 다음은 C 언어로 작성한 프로그램이다. #include main() { printf(\"hello, world \\n\"); } (가) 이 프로그램의 수행을 라이브러리와 시스템 호출 관점에서 설명하시오. =\u003e printf 는 stdio.h 에 속한 라이브러리 함수로서 리눅스에선는 write 시스템 콜이 호출되면서 사용자가 원하는 동작을 수행하게 된다 (나) 리눅스와 윈도우즈가 제공하는 시스템 호출은 서로 다르다. 이 C 프로그램을 리눅스에서 컴파일하여 수행이 가능한가? 윈도우즈에서 컴파일하여 수행이 가능한가? =\u003e printf 라는 표준 c 라이브러리는 내부적으로 각 os 에 시스템콜에 대응되게 수행한다 (다) 위 (나)에서 작성한 답안에 대하여 그 이유를 설명하시오. =\u003e stdio.h 는 표준 c 라이브러리로서 각 컴파일러 제조사들은 각 운영체제에 맞게 라이브러리를 제공한다 프로세스의 상태 중에서, CPU를 할당받기를 기다리는 상태는 무엇인가? =\u003e ready 프로세스의 상태가 실행 상태에서 준비 상태로 전이하게 하는 사건은 무엇인가 =\u003e interrupt PCB에서 레지스터 저장 영역의 용도는 무엇인가? =\u003e 프로세스의 상태변화시에 cpu 에 이 레지스터 값을 세팅하게 된다 문맥교환(context switching)에 하드웨어 지원이 미치는 영향을 논하시오. =\u003e 문맥교환시 cpu 레지스터를 pcb(process control block) 에 저장하게 되는데 모든 레지스터를 한번에 저장할 수 있는 명령어를 하드웨어 제조사에서 제공하게 된다면 소프트웨어로 구현한 문맥교환 보다 빠르게 동작을 수행 할 수 있게 된다 I/O bound 프로세스와 CPU bound 프로세스가 적절히 혼합되어 수행되는 것이 좋은 이유를 설명하시오. =\u003e cpu bound 프로세스가 실행되고 있을 때 io bound 프로세스가 io 작업을 실행하고 있을 수 있다 즉 cpu, io 자원을 유휴 상태를 최대한 줄일 수 있다 장기 중기 단기 스케줄러를 설명하시오 =\u003e 장기 스케줄러 : 어떤 프로세스를 ready queue 로 보낼지 결정하는 스케줄러 즉 메인 메모리와 보조 메모리의 스케줄링 메인 메모리는 한정(상대적으로 보조메모리에 비해 적다)되어 있기 때문에, 실행할 수 있는 프로세스보다 많은 프로세스가 메모리에 올라오면 대용량 메모리(일반적으로 하드디스크)에 임시로 저장된다. 장기 스케줄러는 하드디스크의 프로세스 중 하나를 선택하여 메모리를 할당하고 Ready Queue로 보내는 역할을 한다. 중기 스케줄러(Swapper) : 우선순위가 낮은 프로세스 일정시간동안 활성화 되지 않은 프로세스들을 내린다 단기 스케줄러 : 현제 어떤 프로세스를 실행할 것이가에 대한 문제 최대한 컴퓨터 자원을 잘 활용해야 한다 프로세스간 통신을 위한 메시지 전달 방법에서 직접통신과 간접통신의 특징을 비교하여 설명 하시오. =\u003e 직접통신의 경우 보내는 측의 관점에서는 받는 측의 pid 를 직접 적고 받는 측에서는 보내는 측의 pid 를 직접 적어서 메세지를 받게 된다 하지만 이와 달리 간접통신에서는 보내는 측에서는 mailbox 혹은 포트라는 추상적인 객체를 통해 전달하고 받는 측은 여러개가 될 수 있다 int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine) (void *), void *arg); 함수의 매개변수들을 설명하시오. =\u003e 쓰레드 id, 쓰레드 정보, 쓰레드 시작 함수, 쓰레드 함수의 매개변수 쓰레드의 장점 4가지를 설명하시오. =\u003e 빠른 응답성, 자원 공유, 경제성, 멀티 프로세서 활용 쓰레드 구현 방식 2가지는 무엇인가? =\u003e 사용자 수준의 쓰레드 라이브러리, 커널 쓰레드 다중 쓰레딩 모델 중에서 many-to-one 모델의 특징을 설명하시오. =\u003e 많은 사용자 수준의 쓰레드를 생성해도 실제로는 하나의 커널 쓰레드와 대응된다 교착상태가 발생하는 4가지 조건과 그 의미를 쓰시오. 프로세스와 자원 간의 관계를 나타내는 그래프는 무엇인가? 다음은 교착상태 발생 조건 중 어떤 조건을 제거하기 위한 것인가? 프로세스가 수행되기 전에 필요한 모든 자원을 할당시켜 준다. 자원이 점유되지 않은 상태에서만 자원을 요구하도록 한다. 가. 상호배제 나. 점유와 대기 다. 비선점 라. 순환대기 교착상태 예방방법의 문제점은 무엇인가? 교착상태의 해결 방법 중 은행가 알고리즘(banker’s algorithm)과 관계되는 것은? 가. Avoidance 나. Prevention 다. Detection 라. Recovery 외부 단편화 문제 : 내부 단편화 문제 : 실행파일로 부터 생성된 프로세스의 크기(code segment ~ stack segment) 보다 더 큰 공간을 할당 받을 때 생기는 문제 즉 더 큰 공간을 할당하는 방법을 사용할 때 생긴다 페이징방법을 사용할 때 더 큰 공간을 할당하게 된다 페이징 페이지 테이블 프로세스마다 하나씩 페이지 테이블을 가지고 있다 TLB 페이지 테이블 의 캐쉬용 하드웨어\nframe = page page 가 4KB 라고 가정하면\n프레임이 4KB(킬로바이트)인 경우, 우리는 이를 페이지 크기와 동일하다고 가정할 수 있습니다. 4KB는 2의 12승 바이트(1KB = 2^10 바이트이므로, 4KB = 2^2 * 2^10 = 2^12 바이트)입니다. 이는 메모리 주소에서 하위 12비트가 페이지 내에서의 위치, 즉 페이지 변위(offset)를 나타낸다는 것을 의미합니다. 따라서 주소의 앞쪽 비트들은 페이지 번호를 나타내게 됩니다.\n예를 들어, 32비트 시스템에서 메모리 주소는 총 32비트로 표현됩니다. 여기서 하위 12비트가 페이지 변위를 나타낸다면, 남은 상위 20비트는 페이지 번호를 나타내는 데 사용됩니다. 따라서, 프레임이 4KB인 경우, 주소의 앞쪽 20비트가 페이지 번호를 나타내고, 뒤쪽 12비트가 페이지 내 변위를 나타냅니다.\nTLB 는 문맥교환 대상인가?? -\u003e 아니다 문맥교환 대상이 아닌경우 문맥교환시 TLB 를 다 지워야하지 않나?? -\u003e 문맥교환시 계속 flush(모든 비트를 0으로 만들어야 한다)","발생-원인에-따른-분류#발생 원인에 따른 분류":"하드웨어 인터럽트: 외부 하드웨어 장치로부터 오는 신호에 의해 발생합니다. 예를 들어, 키보드 입력, 마우스 클릭, 네트워크 패킷 수신 등이 있습니다. 하드웨어 인터럽트는 특정 하드웨어 장치가 데이터 처리 준비가 완료되었거나, 데이터 전송이 필요한 상황 등을 CPU에 알립니다. 소프트웨어 인터럽트: 프로그램 내부에서 명령을 통해 의도적으로 발생시키는 인터럽트입니다. 이는 주로 운영체제의 서비스를 요청할 때 사용되며, 시스템 호출이 이에 해당합니다.","부팅-과정#부팅 과정":"IR 값에 기본적으로 0 저장되어 있음 주소 0 의 명령을 IR 로 가져오고 실행(부트로더가 실행됨)(커널모드) 부트로더가 OS 를 메모리에 적제 및 시작 메모리 주소를 PC 에 저장 제어장치는 PC 에 저장된 메모리 주소를 참고하여 IR 에 명령을 저장 계속 실행 ….\n운영체제는 인터럽트에 의해 구동되는 프로그램 타이머 인터럽트 : 주기적 인터럽트 발생 응용프로그램 시스템 호출을 수행 입출력 장치 : 입출력을 마치면 인터럽트를 발생시킴","세그멘테이션--페이지-테이블이랑-비슷-단-나누는-단위를-코드-수준에서-나온다-그래서-외부-단편화-문재가-발생할-수-있게-된다#세그멘테이션 : 페이지 테이블이랑 비슷 단 나누는 단위를 코드 수준에서 나온다 그래서 외부 단편화 문재가 발생할 수 있게 된다":"페이지화 된 세그멘테이션 : 현재 cpu 외부 단편화 문제 해결 인텔 386","요구-페이지#요구 페이지":"모든걸 미리 담지 않고 유효비트를 참조하여 1이면 그냥 원래대로 실행 0이면 인터럽트후 위의 과정으로 적재를 시킨 후에 계속 실행\n페이지 교체 새 페이지를 적재할 때, 비어있는 프레임이 없다면 사용 중인 프레임을 하나 선택하여 디스크로 스왑 아웃시키고 새 페이지를 적재시키는 것 이때, 선택된 페이지 프레임을 희생(victim) 프레임이라 부름 페이지 교체 알고리즘\nFIFO (First-in First-out)\nOPT (Optimal algorithm)\nLRU (Least Recently Used)\nSecond chance\nLFU (Least Frequently Used)\nMFU (Most Frequently Used)\n1단계 디렉토리\n이름(Naming) 문제 : 같은 이름을 가진 파일을 여러 개 만들 수 없다 그룹핑(Grouping) 문제 : 파일들을 여러개씩 그룹화하여 관리할 수 없다 2단계 디렉토리\n공유 문제 : 여러 사용자가 한 파일을 공유할 수 없음 이름 문제 : 한 사용자는 같은 파일 이름을 여러 개 사용할 수 없다 그룹핑 문제 : 한 사용자는 파일들을 여러개씩 그룹화하여 관리할 수 없다 트리구조\n그룹핑 기능이 좋음 비순환 그래프 \b디랙토리","용도에-따른-분류#용도에 따른 분류":"벡터 인터럽트: 인터럽트 발생 시 처리할 인터럽트 서비스 루틴(ISR)의 주소가 인터럽트 벡터에 의해 직접 지정됩니다. 이 방식은 처리해야 할 ISR을 빠르게 찾을 수 있게 해줍니다. 논벡터 인터럽트: 모든 인터럽트가 공통의 인터럽트 서비스 루틴을 호출하고, ISR 내에서 실제 발생한 인터럽트의 종류를 판단하여 적절한 처리를 하는 방식입니다. 이는 벡터 인터럽트에 비해 처리 속도가 느릴 수 있습니다.","인터럽트#인터럽트":"","인터럽트-처리과정#인터럽트 처리과정":"하드웨어적 처리 상태 레지스터 값을 저장 프로세서 모드를 커널 모드로 변경 (모드 비트를 변경) PC 레지스터 값을 저장 발생된 인터럽트의 벡터 값(ISR 주소)을 PC 레지스터에 저장 (OS 내의 인터럽트 서비 스 루틴을 수행하게 됨) 소프트웨어적 처리 (OS가 수행함) CPU 레지스터들의 값을 저장 (메모리에 저장) 인터럽트 처리 코드를 수행 CPU 레지스터 값을 복원 (저장된 값들을 CPU 레지스터에 load) 상태 레지스터 값을 복원 (프로세서 모드가 이전 모드로 변경됨) PC 레지스터 값을 복원 (인터럽트가 발생하여 중단된 곳으로 돌아가게 됨)","처리-방식에-따른-분류#처리 방식에 따른 분류":"마스커블 인터럽트 (Maskable Interrupt): 이 인터럽트는 일시적으로 차단(마스크)할 수 있습니다. 우선순위에 따라 처리할 수 있으며, 더 중요한 작업을 우선적으로 처리하기 위해 일시적으로 차단될 수 있습니다. 논마스커블 인터럽트 (Non-Maskable Interrupt, NMI): 이 인터럽트는 차단할 수 없습니다. 시스템에 중대한 오류나 긴급 상황이 발생했을 때 사용되며, 반드시 즉시 처리되어야 합니다.","프로세스-상태#프로세스 상태":"admitted :허가 / 파일의 소유권을 확인후 허가여부를 판단 new -\u003e ready scheduler dispatch : 스케줄러가 실행한다 i/o or event wait : 입출력을 기다림 io or event completion : 입출력 exit : 시스템 콜을 통한 정상적인 프로세스 종료\nprocectin\nPCB process control block TCP Thread control block\n프로세스 레지스터등 모든 자원이 분리 쓰레드 Code Data 공유, stack register(당연) 분리 CPU 사용률 (utilization) 단위시간당 CPU 사용시간의 비율 (0~100%) 처리량 (Throughput) 단위시간당 완료된 프로세스의 개수 반환시간 (Turnaround time) 특정 프로세스를 실행하는데 걸린 총 시간 대기시간 (Waiting time) 프로세스가 준비 큐에서 대기하면서 기다린 시간의 합 응답시간 (Response time) 작업을 요청한 후 첫번째 응답이 나올 때까지의 시간 (응답이 시작되는 데까지 걸린 시간이며 응답을 출력하는데 걸리는 시간은 아님)","프로세스-스케줄링#프로세스 스케줄링":"선점식과 비선점식 선점식 cpu 사용시간 통제 주체 =\u003e 프로그램 비선점식 cpu 사용시간 통제 주체 =\u003e os 스케줄러 인터럽트 기준\nCPU 사용률 (utilization) : 단위시간당 CPU 사용시간의 비율 (0~100%)\n처리량 (Throughput) : 단위시간당 완료된 프로세스의 개수\n반환시간 (Turnaround time) : 특정 프로세스를 실행하는데 걸린 총 시간\n대기시간 (Waiting time) : 프로세스가 준비 큐에서 대기하면서 기다린 시간의 합\n응답시간 (Response time) : 작업을 요청한 후 첫번째 응답이 나올 때까지의 시간 (응답이 시작되는 데까지 걸린 시간이며 응답을 출력하는데 걸리는 시간은 아님)\nFCFS (First-Come First-Served) : 먼저온 순서대로\n운좋게 짧은 응답시간의 프로세스가 먼저 들어갈 수록 대기시간이 짧다 비선점식 SJF (Shortest Job First) : 가장 빨리 끝나는 놈 먼저\n비선점식 : 다음프로세스를 진행 할 때 큐에서 가장 적은 cpu burst 크기를 가진 프로세스를 선택하여 실행 선점식 : 프로세스 진행중에 남은 cpu burst 크기보다 작은 cpu burst 가 나타나면 프로세스를 뺏아 작은 cpu burst 프로세스를 실행 지수평균 : 이전 cpu burst 크기를 이용해 지수 평균을 방법을 사용해 추청함 비슷하게 우선순위 알고리즘이 있다 위의 경우는 cpu burst 시간이 우선순위로 설정되는 경우이다 즉 우선순위에 따라 cpu 를 점유할 수 있게 한다 선점식 비선점식 모두 가능 하지만 문제는 위와 동일하게 기아상태가 발생할수 있다는 것이다 RR (Round Robin) : 단위시간을 process 에게 cpu를 선점하도록 허용(시분할)\n준비큐는 fcfs, 선점방식, 80%(cpu burst \u003c 시간할당량) 가 좋다 MQ (Multi-level Queue) : 준비 큐를 여러 개의 큐로 나눈다\n전면 작업 (foreground job, 대화식) : 빠른 응답시간을 요구함 =\u003e round robin 처리 후면 작업 (background job, 일괄처리) =\u003e fcfs 처리 전면작업이 무조건 먼저 수행된다 우선순위, sjf(short job first) 와 마찬가지로 기아상태의 우려가 있다 MFQ (Multi-level Feedback Queue)\nMQ 업글 버전 다단계 큐 스케줄링(MQ)과 다르게 다단계 피드백 큐 스케줄링(MFQ)은 프로세스가 큐 사이를 이동함 CPU를 많이 사용하는 프로세스는 낮은 우선순위 큐로 이동시킴 입출력 중심의 프로세스와 대화식 프로세스들을 높은 우선순위의 큐에 이동시킴  낮은 우선순위의 큐에서 오래 대기하는 프로세스들을 높은 우선순위의 큐로 이동 (기아 상태를 예방, 에이징) 새로운 프로세스는 Q0 에 들어가서 FCFS로 처리됨 CPU를 할당받으면 8 밀리 초 동안 실행되고 이 시간동안 완료되지 않는다면 Q1으로 이동됨. 이 시간동안 CPU 버스트를 끝내고 I/O 버스트로 가면 계속 Q0 에 위치함 Q1 에서 다시 FCFS로 CPU를 할당받고, 16 밀리 초동안 실행되고 이 시간동안 완 료되지 않는다면 Q2로 이동됨 이 예에서, CPU 버스트가 8 밀리초 이하인 프로세스가 제일 높은 우선순위를 가 지게 되고, 8 밀리 이상 16 밀리초 이하인 프로세스가 다음의 우선순위를 가짐. 이보다 긴 프로세스는 자동적으로 Q2 로 이동되어 낮은 우선순위를 가짐 그러므로 처음에 이야기한 cpu burst 가 큰 프로세스는 낮은 우선순위 큐로 자동적으로 천천히 이동되고 io 가 많은 프로세스는 최대한 Q0 와 가까이 위치함 HRN (Highest Response-rate Next) : 가변적 우선순위의 비선점식 + shj\nSJF의 약점인 긴 프로세스와 짧은 프로세스의 불평등을 보완 $우선순위 = \\frac {대기시간 + CPU burst } {CPU burst}$ cpu burst 를 기준으로 했던 sjf 에서 대기시간의 가중치를 만들어줌 간트 차트를 통해 프로세스 스케줄링을 시각적으로 표현할 수 있다"},"title":"대학교 운영체제"},"/02.inbox/%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B2%84%EB%8A%94-%EC%BB%A4%EB%84%90%EC%9D%B8%EA%B0%80/":{"data":{"":"“모든 드라이버는 커널의 일부로 간주되는가?”\n✅ 하드웨어 제어를 직접 하는 전통적인 장치 드라이버는 ‘커널의 일부’로 간주됩니다.\n❌ 하지만 모든 드라이버가 커널 코드 트리에 포함되거나, 커널 공간에서만 동작하는 것은 아닙니다.","1-전통적인-장치-드라이버--커널의-일부-예-네트워크-카드-usb-디스크-tty-드라이버-등#1. 전통적인 장치 드라이버 → 커널의 일부 (예: 네트워크 카드, USB, 디스크, TTY 드라이버 등)":"이들은 다음 조건을 충족하므로 커널의 일부로 간주됩니다:\n커널 공간(kernel space)에서 실행됨 하드웨어 레지스터, 인터럽트, DMA 등에 접근 시스템 콜이나 VFS(가상 파일 시스템)와 통합됨 커널의 메모리 관리, 스케줄러와 상호작용","2-로드-가능한-모듈도-커널의-일부인가--네-삽입된-순간부터는#2. 로드 가능한 모듈도 “커널의 일부\u0026#34;인가? =\u0026gt; \u003cstrong\u003e네, 삽입된 순간부터는 ‘커널의 일부’입니다.\u003c/strong\u003e":"예를 들어:\n$ sudo modprobe usbserial → 이 모듈은 .ko 파일로 디스크에 있지만, 로드되면 커널 메모리에 적재되어 커널과 같은 권한으로 실행됩니다.","3-사용자-공간에서-동작하는-드라이버는#3. 사용자 공간에서 동작하는 드라이버는?":"이 경우는 정의상 논란이 있지만, 일반적으로는 “드라이버\"라고는 해도 커널의 일부는 아님.","4-그럼-드라이버라는-말의-의미는#4. 그럼 \u0026ldquo;드라이버\u0026quot;라는 말의 의미는?":"여기서 혼동이 생길 수 있어요. “드라이버\"라는 단어는 맥락에 따라 다르게 쓰입니다:\n맥락 의미 커널의 일부? 전통적 의미 (리눅스 커널 개발자 관점) 커널 공간에서 하드웨어 제어 ✅ 예 일반 사용자 관점 “장치를 쓰게 해주는 소프트웨어” ❌ 아닐 수 있음 임베디드/고성능 컴퓨팅 사용자 공간에서 동작하는 고속 드라이버 ⚠️ 부분적으로만","5-ttypty-드라이버는#5. TTY/PTY 드라이버는?":"커널 내부 코드 (drivers/tty/*) pty.c, n_tty.c(line discipline) 등은 모두 커널 소스에 있음 /dev/tty, /dev/pts/* 장치 파일은 커널이 관리 확실히 커널의 일부입니다.","결론-모든-드라이버는-커널의-일부인가#결론: \u0026ldquo;모든 드라이버는 커널의 일부인가?\u0026rdquo;":"질문 답변 모든 드라이버가 커널 소스 트리에 포함되는가? ❌ 아니요. FUSE, 외부 모듈 등은 별도 모든 드라이버가 커널 공간에서 실행되는가? ❌ 아니요. FUSE, UIO 등은 userspace 전통적인 장치 드라이버는 커널의 일부인가? ✅ 예 — 정의상 커널 공간에서 동작해야 함 커널의 일부로 간주되는 기준은? ✔️ 커널과 같은 공간에서 실행되고, 커널 API 사용, 시스템 리소스 제어","예-1-fusefilesystem-in-userspace#예 1: \u003cstrong\u003eFUSE\u003c/strong\u003e(Filesystem in Userspace)":"파일 시스템 드라이버처럼 동작하지만, 사용자 공간에서 실행 커널의 fuse.ko 모듈이 중간에서 시스템 콜과 연결 $ sshfs user@remote:/ ~/remote_folder → 이건 사용자 공간에서 동작하는 FUSE 기반 드라이버\n➡️ 하지만 진짜 하드웨어 제어는 커널이 함. FUSE는 “인터페이스 제공 + 중계” 역할.","예-2-uio--vfio#예 2: \u003cstrong\u003eUIO / VFIO\u003c/strong\u003e":"특정 PCI 장치를 사용자 공간에서 제어 (예: DPDK, SR-IOV) 커널이 메모리 매핑만 해주고, 나머지는 앱이 처리 ➡️ 이 경우도 커널의 도움 없이는 불가능. 완전히 독립된 건 아님.","예시#예시:":"// 커널 소스 트리에서 볼 수 있는 드라이버 코드 예 drivers/usb/core/hub.c drivers/tty/pty.c drivers/net/ethernet/intel/e1000/e1000_main.c → 이 코드들은 리눅스 커널 소스 트리(https://git.kernel.org)에 포함되어 있고,\n컴파일 시 커널의 일부가 되거나, 로드 가능한 모듈로 분리됩니다."},"title":"드라이버는 커널인가"},"/02.inbox/%EB%94%94%EB%B2%84%EA%B1%B0-cli-%EB%AA%85%EB%A0%B9%EC%96%B4-%EB%AA%A8%EC%9D%8C/":{"data":{"":"","-gdb--lldb-명령어-비교-참고#🔹 \u003cstrong\u003eGDB ↔ LLDB 명령어 비교 (참고)\u003c/strong\u003e":"GDB LLDB run run break main b main step step next next print x p x info breakpoints br list bt bt","-lldb--gdb-명령어-비교-참고#🔹 \u003cstrong\u003eLLDB ↔ GDB 명령어 비교 (참고)\u003c/strong\u003e":"LLDB GDB b main b main br list info breakpoints v 또는 frame variable info locals expr x = 5 set variable x = 5 process launch run memory read x/... settings set target.run-args ... set args ...","-기본-실행-및-종료#🔹 \u003cstrong\u003e기본 실행 및 종료\u003c/strong\u003e":"명령어 설명 gdb 실행 파일로 GDB 시작 run 또는 r 프로그램 실행 (인자: run arg1 arg2) quit 또는 q GDB 종료","-기본-실행-및-종료-1#🔹 \u003cstrong\u003e기본 실행 및 종료\u003c/strong\u003e":"명령어 설명 lldb 실행 파일로 LLDB 시작 run 또는 r 프로그램 실행 process launch 프로그램 실행 (옵션 사용 가능) quit 또는 q LLDB 종료","-도움말-및-설정#🔹 \u003cstrong\u003e도움말 및 설정\u003c/strong\u003e":"명령어 설명 help 전체 도움말 help 특정 명령어에 대한 도움말 set args arg1 arg2 실행 인자 설정 run \u003c input.txt 표준 입력 리다이렉션 (쉘 수준에서 처리) set environment VAR=value 환경 변수 설정","-도움말-및-설정-1#🔹 \u003cstrong\u003e도움말 및 설정\u003c/strong\u003e":"명령어 설명 help 전체 도움말 help 특정 명령어에 대한 도움말 settings set target.run-args arg1 arg2 실행 인자 설정 settings set target.input-path input.txt 표준 입력 리다이렉션","-변수-및-메모리-보기#🔹 \u003cstrong\u003e변수 및 메모리 보기\u003c/strong\u003e":"명령어 설명 print 또는 p 변수 값 출력 (식 평가 가능) display 매 스텝마다 자동으로 변수 출력 undisplay 1 display 목록에서 제거 x/16xb 0x12345678 메모리 덤프 (x/[count][format][size] address) set variable x = 10 변수 값 변경","-변수-및-메모리-보기-1#🔹 \u003cstrong\u003e변수 및 메모리 보기\u003c/strong\u003e":"명령어 설명 frame variable 또는 v 현재 프레임의 지역 변수 출력 print 또는 p 변수 값 출력 (식 평가 가능) expr 표현식 평가 및 실행 (변수 수정도 가능) memory read --size 1 --count 16 0x12345678 메모리 덤프","-스택-및-프레임#🔹 \u003cstrong\u003e스택 및 프레임\u003c/strong\u003e":"명령어 설명 backtrace 또는 bt 콜 스택 출력 frame 2 또는 f 2 특정 프레임으로 이동 up / down 스택 프레임 위/아래로 이동","-스택-및-프레임-1#🔹 \u003cstrong\u003e스택 및 프레임\u003c/strong\u003e":"명령어 설명 bt 또는 thread backtrace 콜 스택 출력 frame select 2 특정 프레임으로 이동 up / down 스택 프레임 위/아래로 이동","-스텝-실행-stepping#🔹 \u003cstrong\u003e스텝 실행 (Stepping)\u003c/strong\u003e":"명령어 설명 step 또는 s 한 줄 실행 (함수 내부로 들어감) next 또는 n 한 줄 실행 (함수 내부로 안 들어감) finish 현재 함수 끝까지 실행 후 반환 continue 또는 c 다음 중단점까지 실행","-스텝-실행-stepping-1#🔹 \u003cstrong\u003e스텝 실행 (Stepping)\u003c/strong\u003e":"명령어 설명 step 또는 s 한 줄 실행 (함수 내부로 들어감) next 또는 n 한 줄 실행 (함수 내부로 안 들어감) finish 현재 함수 끝까지 실행 후 반환 continue 또는 c 다음 중단점까지 실행","-중단점-breakpoint#🔹 \u003cstrong\u003e중단점 (Breakpoint)\u003c/strong\u003e":"명령어 설명 break main.cpp:10 또는 b main.cpp:10 파일의 특정 라인에 중단점 설정 break main 또는 b main 함수 이름에 중단점 설정 info breakpoints 또는 i b 현재 중단점 목록 보기 delete 1 ID가 1인 중단점 삭제 disable 1 중단점 비활성화 enable 1 중단점 활성화 clear main.cpp:10 특정 위치의 중단점 제거","-중단점-breakpoint-1#🔹 \u003cstrong\u003e중단점 (Breakpoint)\u003c/strong\u003e":"명령어 설명 breakpoint set --file main.cpp --line 10 파일의 특정 라인에 중단점 설정 b main.cpp:10 위와 동일 (간단한 형태) breakpoint set --name main 함수 이름에 중단점 설정 b main 위와 동일 breakpoint list 또는 br list 현재 중단점 목록 보기 breakpoint delete 1 ID가 1인 중단점 삭제 breakpoint disable 1 중단점 비활성화 breakpoint enable 1 중단점 활성화","-팁#💡 팁":"GDB는 .gdbinit 파일을 통해 시작 시 자동으로 명령어를 실행할 수 있습니다. 최신 GDB(8.0+)는 Python 스크립팅을 지원하여 고급 디버깅이 가능합니다. ARM64 환경에서도 잘 작동하지만, 크로스 디버깅 시 gdb-multiarch나 대상 아키텍처 전용 GDB를 사용해야 할 수 있습니다.","-프로세스-및-스레드#🔹 \u003cstrong\u003e프로세스 및 스레드\u003c/strong\u003e":"명령어 설명 info threads 현재 스레드 목록 thread 2 특정 스레드로 전환 kill 디버그 중인 프로세스 강제 종료","-프로세스-및-스레드-1#🔹 \u003cstrong\u003e프로세스 및 스레드\u003c/strong\u003e":"명령어 설명 thread list 현재 스레드 목록 process status 현재 프로세스 상태 확인 process kill 디버그 중인 프로세스 강제 종료","gdb#GDB":"","lldb#LLDB":""},"title":"디버거 cli 명령어 모음"},"/02.inbox/%EB%94%B0%EB%9D%BCit/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EA%B3%A0%EA%B8%89/":{"data":{"":"계층별 장비","네트워크-계층#네트워크 계층":"라우터 : 라우팅 테이브를 참고하여 목적지와 연결되는 포트로 paket 을 전송 =\u003e 라우팅 3계층 장비는 브로트캐스트를 모두 차단","데이터-링크-2계층#데이터 링크 2계층":"브릿지 : 맥주로를 기반으로 전송 포트를 결정 스위치 : 브릿지에 collision domain 기능 추가","물리계층#물리계층":"리피터 : 전기적 신호가 약할때 증폭 기능 허브 : 데이터를 모든 장비에 전송 일종의 브로드캐스트","케이블#케이블":""},"title":"네트워크 고급"},"/02.inbox/%EB%94%B0%EB%9D%BCit/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-2%EA%B3%84%EC%B8%B5/":{"data":{"":"ㅆ근거리(동일 네트워크 대역) 간 통신 7.png)\nethernet type 을 상위 프로토콜 type 로 이해하자\nipconfig /all 명령으로 자신의 mac 주소를 확인","mac-주소#mac 주소":"앞 3자리 OUI : IEEE 에서 부여하는 일종의 제조회사 식별 ID 뒤 3자리 고유번호 : 제조사에서 부여한 고유번호 destination Address , source address, Ethernet type 만 확인 destination address 목적지 MAC 주소\nEthernet Type : 상위 프로토콜 타입 2바이트: IPv4(0x0800), ARP(Ox0806)"},"title":"네트워크 2계층"},"/02.inbox/%EB%94%B0%EB%9D%BCit/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-3%EA%B3%84%EC%B8%B5/":{"data":{"":"먼거리(인터넷 통신) 간 통신\n용어 설명 IPv4: 현제 PC 에 할당된 ip 주소 서브넷 마스크 : ip 주소에 대한 네트워크 대역을 규정하는 것 게이트 웨이 : 외부와 통신할 때 사용하는 네트워크 출입구","arp-protocol#ARP Protocol":"동일 네트워크 대역 같은 네트워크 대역에서 통신을 하기 위해 MAC 주소를 ip 주소를 이용해서 알아오는 프로토콜\nhardware type : 2계층 프로토콜 type( 대부분 이더넷 0x0001) protocol type : 3계층 프로토콜 type( 대부분 ip 0x0800 ) hardware address Length : MAC 주소의 길이 06 Protocol address length : IP 주소의 길이 04 opcode : 질문 0x0001 또는 대답 0x0002 source hardware address : 출발지 MAC 주소 source protocol address : 출발지 ip 주소 destination hardware address : 도착지 MAC 주소 (알고 싶은 mac 주소) 질문시에는 모르니까 000000 destination protocol address : 도착지 ip 주소 mac 주소를 모르므로 00000… 으로 비워둔다\n동일 네트워크 대역에서 통신을 한다고 하더라도 데이터를 보내기 위해서는 7계층 부터 캡술화를 통해 데이터를 보내기 때문에 ip 주소와 MAC 주소 모두 필요하다 이때 IP 주소는 알고 MAC 주소를 도르더라도 ARP 를 통해 통신이 가능하다\narp 는 3계층이지만 동일 네트워크 대역에서만 사용할 수 있다\n통신 이후 arp 캐시 테이블로 관리한다","classful-ip-1세대#classful IP 1세대":"네트워크 클래스별로 대역을 구분","classfulless-ip-2세대#classfulless IP 2세대":"서브넷 마스크 도입으로 임의로 대역을 구분 가능","ipv4--icmp-protocol#IPv4 \u0026amp; ICMP Protocol":"시대별 구분 프로토콜 구조 라우팅 테이블 타 네트워크 통신과정 조각화","라우팅-테이블#라우팅 테이블":"netstat -r 명령어를 통해 확인","목차#목차":"ARP 프로토콜 : 동일 네트워크 대역 MAC 주소를 알기 위해 사용하는 프로토콜 IPv4 프로토콜 : ICMP 프로토콜 : 연결 확인용 프로토콜","시대별-구분#시대별 구분":"classful classfulless 공인 사설","조각화#조각화":"ip 자체 프로토콜 최소 20 바이트를 고려해서 분리해야한다","프로토콜-구조#프로토콜 구조":"Version 버전 0x4 고정 IHL(Header Length) (헤더 길이/4) : 0x5, 0x6 … type of Service (TOS) : 0 으로 비어있음 서비스 형식 과거에 사용 Total Length : Packet 전체 크기 : 헤더와 페이로드 포함 Identification, IP Flags, Fragment Offset : 전송시 분리되서 보내지는데 이때 구별을 위한 정보 identification : 패킷 id, 조각화시 조각들은 동일 id IP Flags(x 사용하지 않음, D Dont Fragmentation:쪼개지 마라, More Fragmentation:조각화시 마지막 패킷만 0 ) fragment Offset : 초기 위치에서 떨어진 만큼의 위치 8로 나눔 Time To Live : 패킷의 생존 시간 ( 순환 오류 발생 대비 노드 최대 방문 횟수 ) unix 는 64 설정, window 는 128 기본 설정 이를 통해 운영체제 예측 가능 Protocol : ICMP(3계층 0x01=1), TCP(4계층 0x06=6), UDP(4계층 0x11=17 ) Header Checksum : 헤더를 통해 생성 hash 알고리즘 Source address : 출발지 ip Destination address : 목적지 ip IP Option : 추가적인 정보란( 0~12 바이트 정도) 정확하게 전달될 것을 보장하지 않는다\ntype : 카테고리 Code : 소분류 Checksum : 헤더 오류 검출용 추가 Type Code Description 0 0 응답 echo request 8 0 요청 echo respond 3 0~15 목적지 도달 불가 Destination Unrechable 11 0~1 도착이후 반환 불가(방화벽, 응답x) Time Exceeded 5 0 ~ 3 원격지 라우팅 테이블 수정 Redirect Message ICMP 메세지 타입 검색","현제-ip-3세대#현제 IP 3세대":"NAT\n터널링"},"title":"네트워크 3계층"},"/02.inbox/%EB%94%B0%EB%9D%BCit/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-4%EA%B3%84%EC%B8%B5/":{"data":{"":"프로그램(프로세스) 간 통신\n4계층 프로토콜 포트번호 프로그램 연결 정보","4계층-프로토콜#4계층 프로토콜":"전송계층 송신자 프로세스 수신자 프로세스 통신\nTCP UDP 포트번호(4계층 주소)","tcp-통신-과정-3way-hand-shake#TCP 통신 과정 3way hand shake":"+1 은 데이터가 포함된(페이로드) 때는 데이터의 크기를 더해준다\n점선은 클라이언트 요청 실선은 서버 응답","udp#UDP":"source Port : 출발 프로세스 포트번호(2바이트 2^16) Destination Port : 도착 프로세스 포트번호 Length : 길이 Checksum DNS 서버 전송이 실패해도 다시보내면 그만 tftp 서버 : 파일 공유 RIP 프로토콜 : 라우팅 정보 공유 ###6174939.png)\nsource Port : 출발 프로세스 포트번호(2바이트 2^16) Destination Port : 도착 프로세스 포트번호 Sequence Number, Acknowledgment Number : 연결을 보장하는 용도로 사용 보내는 입장에서의 S : 상대방의 어떠한 대답의 질문인지 기록 보내는 입장에서의 A : 상대방의 질문에 데이터를 더해 전송 받는 입장의 S: 어떠한 대답에 대한 질문인가 받는 입장의 A : 내가 보낸 질문이 정확하게 도달했는가 내가 보냈던 질문의 S에 데이터의 크기를 더해 확인한다 3way hand shake 시에는 0으로 초기화 보낼때는 +1 을 답변으로 Offset : 헤더 길이 전체크기/4 Reserved : 예약 사용하지 않음 TCP Flags : 통신 상황 파악용 C, E 몰라도 된다 U : 긴급한 자료인가? A : 승인 bit 대답용 P : tcp 버퍼 크기 상관없이 보낸다? R : 연결된 상태에서 문제 발생 초기화 필요 reset S : sync 동기화 연결 시작시 1 F : 종료 Window : 자신의 TCP 공간 버퍼(상대방서 보내도 되는지 판단 기준) Checksum Urgent Pointer : 긴급 데이터 위치데이터 TCP Options","포트-번호#포트 번호":"하나의 포트는 하나의 프로세스만 사용 가능하다"},"title":"네트워크 4계층"},"/02.inbox/%EB%94%B0%EB%9D%BCit/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-7%EA%B3%84%EC%B8%B5/":{"data":{"":"5계층 부터 7계층 까지 한번에 관리 {세션 표현 응용}\nhttp 1.0 에서 1.1 변경 http 요청 프로토콜 http 응답 프로토콜 http 헤더 포멧 http 버전 RFC2068(1997) RFC2616(1999) RFC7230~7235(2014)","headers#Headers":"","http-10-에서-11-변경#http 1.0 에서 1.1 변경":"매우 비요율적 모든 요청 응답 하나하나 3wh를 해야한다","http-요청--응답-프로토콜#http 요청 \u0026amp; 응답 프로토콜":"","request-line#request Line":"ex) GET / HTTP/1.1","status-line#status line":"ex) HTTP/1.1 200 OK","uri#URI":"","요청-타입#요청 타입":"최근 백엔드(was)와 프론트(client)의 데이터 흐름은 json 형식으로 많이 사용한다 이때 요청 방식의 단일화 규칙을 세우는 것을 REST API 라고 한다\nget : 정보를 url 에 포함해서 보낸다 post : 정보를 body에 포함해서 보낸다","요청-헤더#요청 헤더":"","응답-헤더#응답 헤더":"","일반-헤더#일반 헤더":"","항목-헤더#항목 헤더":"….."},"title":"네트워크 7계층"},"/02.inbox/%EB%94%B0%EB%9D%BCit/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC/":{"data":{"":"","계층별-프로토콜#계층별 프로토콜":"","연결-형테애-따른-분류#연결 형테애 따른 분류":"Star 중앙장비에 모든 노드가 연결 Mesh 여러노드의 그물 형태 Tree 계층 구조의 형태 링형, 버스형, 혼합형","크기에-따른-분류#크기에 따른 분류":"LAN ( Local Area Network ) WAN ( Wide Area Network ) MAN ( Metropolitan Area Network ) VLAN CAN PAN","통신방식에-따른-분류#통신방식에 따른 분류":"유니 캐스트 ( 특정 대상과 1:1 통신 ) 멀티 캐스트 ( 특정 다수와 1:N 통신 멀티 캐스트 {특정 인원}) 브로트 캐스트 ( 네트워크에 있는 모든 대상과 통신 )","패킷#패킷":"이더넷 프로토콜만 풋터 사용\n테이터 -\u003e 캡슐화 인캡슐레이션 incapsulation 캡슐 -\u003e 데이터 디캡슐레이션 decapsulati%20image%2020240506030502.png) frame 의 최소 크기 60byte 1계층 에서 붙는다 최대 1514byte Transport TCP 에서 PDU : segment Transport UDP 에서 PDU : user datagram Network IP 에서 PDU : datagram\n01. 네트워크란 무엇인가https://docs.google.com/presentation/d/1cBVIS457shcUV3cfSrM9c1w3Lws3ZVE9/edit?usp=sharing\u0026ouid=109006469823185730332\u0026rtpof=true\u0026sd=true 02. 네트워크의 기준! 네트워크 모델 https://docs.google.com/presentation/d/1ui8oW-jTp3z5dU7XP1a-eMnJu9GcAs49/edit?usp=sharing\u0026ouid=109006469823185730332\u0026rtpof=true\u0026sd=true 03. 가까이 있는 컴퓨터끼리는 이렇게 데이터를 주고받는다 https://docs.google.com/presentation/d/1HYg9YC3_luzxMHzVn-sGd6gzjgExGKV6/edit?usp=sharing\u0026ouid=109006469823185730332\u0026rtpof=true\u0026sd=true 04. 실제로 컴퓨터끼리는 IP주소를 사용해 데이터를 주고받는다\n05. 통신하기 전 반드시 필요한 ARP 프로토콜 https://docs.google.com/presentation/d/1GParqmJVI3xwzFDk-FrOqGzFsAFbqUC5/edit?usp=sharing\u0026ouid=109006469823185730332\u0026rtpof=true\u0026sd=true 06. 멀리있는 컴퓨터기리는 이렇게 데이터를 주고받는다https://docs.google.com/presentation/d/1ezrr3wC9UaTGqtjRPfetCrstnd6qZ8G0/edit?usp=sharing\u0026ouid=109006469823185730332\u0026rtpof=true\u0026sd=true 07. 컴퓨터의 프로그램끼리는 이렇게 데이터를 주고 받는다 https://docs.google.com/presentation/d/1z-WGHNF81x40zbNrJRv29NMFCUVzKeyh/edit?usp=sharing\u0026ouid=109006469823185730332\u0026rtpof=true\u0026sd=true 08. 비연결지향형 UDP 프로토콜 https://docs.google.com/presentation/d/1vOOj3I0zHIuqLmSKwCicuSLuveZtuz9a/edit?usp=sharing\u0026ouid=109006469823185730332\u0026rtpof=true\u0026sd=true 09. 연결지향형 TCP 프로토콜 https://docs.google.com/presentation/d/15SyhelhPtlwbz6wqeodjHhwVfU2bop50/edit?usp=sharing\u0026ouid=109006469823185730332\u0026rtpof=true\u0026sd=true 10. NAT와 포트포워딩\nhttps://docs.google.com/presentation/d/1N7gScAhktYl3i_cSRi6-DHRTIwfPvq0O/edit?usp=sharing\u0026ouid=109006469823185730332\u0026rtpof=true\u0026sd=true 11. WWW(웹)를 이용할 때는 이렇게 데이터를 주고받는다 https://docs.google.com/presentation/d/1W2AIBsANAttvrbcrh9wLMrPYbaB8Hkht/edit?usp=sharing\u0026ouid=109006469823185730332\u0026rtpof=true\u0026sd=true\ntracert"},"title":"네트워크"},"/02.inbox/%EB%A6%AC%EC%8A%A4%ED%8A%B8-%EC%BB%B4%ED%94%84%EB%A6%AC%ED%97%A8%EC%85%98list-comprehension/":{"data":{"":"%20image%2020231223111957.png)\n컴퓨터 계산 기준 output 식 발견 뒤의 for , if 좌측에서 우측으로 순서대로 순회후 out put을 계산","for문#for문":"for 문이 무조건 한개는 있어야 한다\nlst = [1,2,3,4,5,6,7,8,9,10] a = [x+1 for x in lst] print(a) [2, 3, 4, 5, 6, 7, 8, 9, 10, 11] \u003e\u003e\u003e [ (x, y) for x in ['쌈밥', '치킨', '피자'] for y in ['사과', '아이스크림', '커피']] [('쌈밥', '사과'), ('쌈밥', '아이스크림'), ('쌈밥', '커피'), ('치킨', '사과'), ('치킨', '아이스크림'), ('치킨', '커피'), ('피자', '사과'), ('피자', '아이스크림'), ('피자', '커피')] 좌측부터 계산","if-else#if else":"lst = [1,2,3,4,5,6,7,8,9,10] e = [x if x \u003e 4 else 'less than 4' for x in lst] print(e) ['less than 4', 'less than 4', 'less than 4', 'less than 4', 5, 6, 7, 8, 9, 10] Note\nif else 문은 왜 앞에다가 사용하는가?? if else 는 여기서는 삼항 연산자로 사용된다 처음에 예시로 든 (x+1) 과 (x if x \u003e 4 else ’less than 4’) 이렇게 하나의 output 이다 문으로 보지 않도록 하자","if-문#if 문":"lst = [1,2,3,4,5,6,7,8,9,10] c = [x for x in lst if x \u003e 4] print(c) [5, 6, 7, 8, 9, 10]","nested#nested":"matrix = [ [1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], ] [[row[i] for row in matrix] for i in range(4)] [1, 5, 9](1,%205,%209)","중첩-if-문#중첩 if 문":"d = [x for x in lst if x \u003e 4 if x%2 == 0] [6, 8, 10]"},"title":"리스트 컴프리헨션(List Comprehension)"},"/02.inbox/%EB%A9%94%EB%AA%A8%EB%A6%AC-%EC%B5%9C%EB%8C%80-%ED%81%AC%EA%B8%B0/":{"data":{"":"","결론#결론":"결론적으로 메모리 MAX 계산은 메모리 접근은 1Byte 단위로 한다는 가정하에 계산한 것이다","문제-발생#문제 발생":"나의 32 비트 cpu 의 경우 logisim 으로 구현 했는데 logisim 소프트웨어 자체의 한계로 인해 address bit width 의 크기는 24 비트로 제한 data bit width 는 32 비트로 제한되었다 나의 경우는 data bit width 의 크기를 word 로 맞추어 넣고 시작했기 때문에 정확하게 메모리의 크기는 32 * 2^(24) = 64MiB 로 나오게 된다 만약 logsim 이 32 비트 address bit width 크기가 32 제한 이었다면 32 * 2^(32) = 64GiB 가 나오게 되고 내가 이미 알던 32비트 컴퓨터의 메모리 최대 4GiB 의 크기와 다르게 된다\n즉 이때 부터 궁금증이 시작되었고 여러가지를 찾아보니 메모리 주소당 데이터 용량이 1바이트인 이유 주소지정단위와 주소비트수의 관계/워드와 명령어형식/pc의 증가폭 2개를 보고 많이 배워 다시 정리 해본다","문제-발생-이전#문제 발생 이전":"메모리의 최대 크기는 RAM 에 저장할 수 있는 bit 최대 개수를 의미한다 word 는 bus 의 크기를 이야기 한다 하지만 직접 CPU 를 만들다 보니(logisim) (그래서 컴퓨터는 어떻게 동작하나요 1) 지금까지 나는 byte 단위로 메모리에 접근한 것이 아닌 word 단위로 접근 했었고 이것이 8비트 cpu 에서는 word 와 byte 가 운 좋게 8bit 로 일치되어 메모리 최대 크기를 계산 할 때 주소폭 크기 (data bit width = word) * 2^(address bit width) 즉 8 * 2^8 즉 2048b ~= 256B 라고 계산 했었다 답은 맞지만 16비트 32 비트로 cpu 를 개선해나가는 과정에서 문제가 발생했다","이해-과정#이해 과정":"위에서 말하는 것중 가장 정리되어 있는 글을 퍼온 것이다\n1 Word 는 CPU 가 한 클럭에 받아들일 수 있는 Data 의 너비 (Data bus width) 입니다. 보통 8 bit, 16 bit, 32 bit, 64 bit 컴퓨터라고 하면, Data Bus Width 를 의미하는 것입니다. 하지만, 정확하게는 외부의 데이터를 내부에 저장해두는 레지스터의 크기입니다. 외부에 핀이 4 pin 밖에 없지만, 내부 레지스터가 4 bit씩 2개 연결되어 2 클럭에 저장이 된다면, 실제 Word 크기는 8 bit 가 되는 것입니다. 2. Data 는 피연산 대상인 수(Number)만을 의미하지는 않고, OP Code(Operator Code) Operand, ... 조합의 Instruction 일 수도 있으며, 여러개의 Operand 가 다음 Word 로 들어오는 경우도 있습니다. 즉, Inst. Operand 1 + Operand 2 + Operand 3 + ... 식으로 연결되어서 각 클럭마다 입력받을 수 있고 SIMD(Single Instruction Multi Data, 다중 피연산자처리 단일 명령어) 종류의 Instruction 에서 나타나는 형태입니다. 이 때, 이러한 종류의 명령어 길이에 따라 Program Counter 의 값이 2 Word 이상 늘어나게 됩니다. 3. Word 는 1. 에서 말했듯이 8, 16, 32 bit 너비일 수 있습니다. 바이트로 환산하면 1,2,4 bytes가 됩니다. 메모리 주소는 1 byte 단위로 지정(Addressing)하기 때문에, 32 bit 컴퓨터에서는 한 클럭마다 4의 배수로 Program Counter 값이 바뀔 것입니다. 4. PC(Program Counter) 레지스터는 실행할 명령어가 담겨있는 메모리주소를 저장하는 공간이기 때문에 Address Bus Width 와 같거나 더 큽니다. 5. Address Bus Width 는 꼭 Data Bus Width 와 일치하지는 않습니다. 32 bit CPU 이지만, 24 bit 메모리 주소 버스를 갖는 i386 CPU 처럼, 대부분은 비대칭적인 경우가 많습니다. 현재 64 bit CPU 인 x86_64 는 물리적 메모리 주소 버스 폭이 48 bit 입니다. 그러나 PC 레지스터의 크기는 64 bit 입니다. A. 주소공간(Address Space) 이라는 개념에 대해 설명듣지 못하셨을 겁니다. 주 메모리의 한계용량을 의미하고, i686(IA32, x86) 구조에서는 32 bit, 즉 2^32 bytes 의 영역인 4 GB 가 주 메모리 한계공간입니다. i686은 Data Bus Width 가 32 bit, 즉 4 Bytes 이기 때문에, 32 bit 의 메모리 핀 중, 30 핀만 사용한다고 하더라도 충분히 4 GB 주소공간을 지정할 수 있었을 겁니다. 즉, 주소 지정 단위(Address Unit)가 어떻게 지정되느냐에 따라, Address Pin 의 갯수, 혹은 Address Bus Width 가 달라지는 셈입니다. 64 bit 컴퓨터인 x86_64 구조에서는 주소지정단위가 64bit, 즉 8 bytes 이므로, 48 bit 로 나타낼 수 있는 2^48 = 64 TBytes 의 공간을 8 Bytes 씩 지정한다고 했을 때, 45 bit 의 Address Bus Width 를 갖게 되는 셈입니다. 하지만, 최신 코어에서는 64 bit 컴퓨터라서 꼭 8 bytes 씩 단위를 쓰지는 않고, 16 bit (2 bytes), 32 bit (4 bytes) 단위로도 접근해서 쓰기 때문에, 동작하는 환경에 따라 주소공간이 각각 달라진다는 점을 알고 계시면 좋겠습니다. 가장 잘 정리되어 있는 글이지만 내가 만든 cpu 의 경우 byte 단위로 메모리를 읽는 것이 아닌 data bit width 로 32 비트로 접근 하였고 총 4Byte 로 접근 한 것이다 그래서 PC 명령어를 클락 주기 마다 4 증가 한 것이 아닌 1만 증가 했던 것이다\nlogisim 제한이 없는 가정에서 내가 만든 CPU 의 메모리 MAX 예상치와 학교에서 배운 메모리 MAX 예상치가 달랐던 것이다","추가#추가":"최신 컴퓨터의 경우 (아니 최신도 아니지만… ) 메모리 클럭이 따로 존재한다 cpu 클럭에 메모리 클럭이 따라가지 못한다 그러면 캐쉬메모리는 동일한 클럭을 사용하는 가? 아니다 그러면 어떻게 그 사이를 중계하는 알고리즘을 어떻게 사용하는 걸까","학교에서#학교에서":"학교에서는 32 비트의 cpu가 가질 수 있는 메모리의 최대 크기가 4GiB 라고 했고 이유는 2^32 Byte 라고 했다 왜 Byte 인지는 이번에 알게 되었다"},"title":"메모리 최대 크기"},"/02.inbox/%EB%AC%B8%EC%84%9C-%EA%B0%9D%EC%B2%B4-%EB%AA%A8%EB%8D%B8-dom/":{"data":{"":"The HTML DOM document object is the owner of all other objects in your web page.\nThe document object represents your web page.\nIf you want to access any element in an HTML page, you always start with accessing the document object.\nBelow are some examples of how you can use the document object to access and manipulate HTML.\nMethod Description document.getElementById(id) Find an element by element id document.getElementsByTagName(name) Find elements by tag name document.getElementsByClassName(name) Find elements by class name Property Description element.innerHTML = new html content Change the inner HTML of an element element.attribute = new value Change the attribute value of an HTML element element.style.property = new style Change the style of an HTML element Method Description element.setAttribute_(attribute, value)_ Change the attribute value of an HTML element Method Description document.createElement(element) Create an HTML element document.removeChild(element) Remove an HTML element document.appendChild(element) Add an HTML element document.replaceChild(new, old) Replace an HTML element document.write(text) Write into the HTML output stream Method Description document.getElementById(id).onclick = function(){code} Adding event handler code to an onclick event The first HTML DOM Level 1 (1998), defined 11 HTML objects, object collections, and properties. These are still valid in HTML5.\nLater, in HTML DOM Level 3, more objects, collections, and properties were added.\nProperty Description DOM document.anchors Returns all \u003ca\u003e elements that have a name attribute 1 document.applets Deprecated 1 document.baseURI Returns the absolute base URI of the document 3 document.body Returns the \u003cbody\u003e element 1 document.cookie Returns the document’s cookie 1 document.doctype Returns the document’s doctype 3 document.documentElement Returns the \u003chtml\u003e element 3 document.documentMode Returns the mode used by the browser 3 document.documentURI Returns the URI of the document 3 document.domain Returns the domain name of the document server 1 document.domConfig Obsolete. 3 document.embeds Returns all \u003cembed\u003e elements 3 document.forms Returns all \u003cform\u003e elements 1 document.head Returns the \u003chead\u003e element 3 document.images Returns all \u003cimg\u003e elements 1 document.implementation Returns the DOM implementation 3 document.inputEncoding Returns the document’s encoding (character set) 3 document.lastModified Returns the date and time the document was updated 3 document.links “Returns all \u003carea\u003e and \u003ca\u003e elements that have a href attribute” 1 document.readyState Returns the (loading) status of the document 3 document.referrer Returns the URI of the referrer (the linking document) 1 document.scripts Returns all \u003cscript\u003e elements 3 document.strictErrorChecking Returns if error checking is enforced 3 document.title Returns the \u003ctitle\u003e element 1 document.URL Returns the complete URL of the document 1"},"title":"문서 객체 모델 (DOM)"},"/02.inbox/%EB%B0%B1%EC%97%94%EB%93%9C-%EA%B5%AC%EC%A1%B0-%EB%B3%80%ED%99%94-%EC%97%AD%EC%82%AC/":{"data":{"":"","stage-1-모델-1---모든-것이-섞여있는-코드#Stage 1: 모델 1 - 모든 것이 섞여있는 코드":"🎯 목표: 왜 모델 1 아키텍처가 유지보수에 재앙인지 코드로 직접 경험합니다. 하나의 클래스 안에서 요청 분석, 데이터 처리, 화면 생성이 모두 일어나는 상황의 문제점을 느껴봅니다.\n📝 문제:\nPostManager라는 클래스를 만드세요. 이 클래스는 main 메소드를 가지고 있으며, 실행하면 게시판 목록을 HTML 문자열 형태로 콘솔에 출력해야 합니다.\n요구사항:\nPostManager 클래스 안에 게시물 데이터를 List","stage-2-모델-2-mvc---역할의-분리#Stage 2: 모델 2 (MVC) - 역할의 분리":"🎯 목표: 모델 1의 문제를 해결하기 위해 ‘관심사의 분리’를 적용합니다. Controller, Service, View의 역할을 하는 클래스들을 만들어 코드를 분리합니다.\n📝 문제:\nStage 1의 PostManager를 Controller, Service, View 역할로 나누어 리팩토링하세요.\n요구사항:\nPostController: 요청을 받는 진입점. PostService를 호출하여 데이터를 받고, 받은 데이터를 PostView에 넘겨 최종 결과를 받아옵니다.\nPostController 내부에 private PostService postService = new PostServiceImpl(); 와 같이 서비스 객체를 직접 생성해야 합니다. PostService: 비즈니스 로직과 데이터 처리를 담당. 게시물 목록 데이터를 List","stage-3-dto-도입---명확한-데이터-계약#Stage 3: DTO 도입 - 명확한 데이터 계약":"🎯 목표: 모델 2 구조에서 계층 간 데이터를 Map이 아닌 DTO(Data Transfer Object)로 주고받도록 개선합니다. ‘어레이 문제’를 해결하고 타입 안정성을 확보하는 과정을 이해합니다.\n📝 문제:\nStage 2의 코드에서 List","stage-4-의존성-주입-di---궁극의-유연성-확보#Stage 4: 의존성 주입 (DI) - 궁극의 유연성 확보":"🎯 목표: 인터페이스를 도입하고 외부에서 의존성을 주입하여 각 컴포넌트 간의 결합을 끊어냅니다. 이를 통해 기능의 교체가 유연해지고 테스트가 쉬워지는 것을 확인합니다.\n📝 문제:\nStage 3의 강한 결합 문제를 해결하기 위해 의존성 주입(DI) 원리를 적용하세요.\n요구사항:\nPostService 인터페이스를 만드세요. (List getPosts() 메소드 선언)\n기존 PostService 클래스의 이름을 **PostServiceImpl**로 바꾸고 PostService 인터페이스를 구현(implements)하도록 하세요.\n**PostController**가 더 이상 PostServiceImpl을 직접 생성하지 않도록 수정합니다. 대신 PostService 인터페이스 타입의 멤버 변수를 선언하고, 생성자를 통해 외부에서 PostService 구현체를 주입받도록 변경하세요.\npublic class PostController { private final PostService postService; // 생성자를 통해 의존성 주입 public PostController(PostService postService) { this.postService = postService; } // ... } Main (또는 Application) 클래스를 만들어 DI 컨테이너의 역할을 하도록 합니다. 이 클래스가 PostServiceImpl 객체를 생성하고, 이 객체를 PostController의 생성자에 인자로 넘겨주어 전체 시스템을 조립하고 실행합니다.\n(심화) TestPostServiceImpl이라는 PostService의 또 다른 구현체를 만드세요. 이 클래스는 테스트용 고정 데이터(“테스트 제목 1”, “테스트 제목 2” 등)를 반환하도록 합니다. Main 클래스에서 PostServiceImpl 대신 TestPostServiceImpl을 주입했을 때, Controller 코드를 전혀 바꾸지 않고도 프로그램의 동작이 바뀌는 것을 확인하세요.\n🔑 핵심 질문:\n‘사육사(Controller)‘는 ‘동물(Service 인터페이스)‘에게 일을 시킬 뿐, 실제 일하는 동물이 ‘오리(ServiceImpl)‘인지 ‘강아지(TestServiceImpl)‘인지 더 이상 신경 쓰지 않게 되었습니다. 이로 인해 얻는 가장 큰 이점은 무엇일까요?\n이제 PostService 로직만 따로 테스트하는 것이 얼마나 쉬워졌나요? 이것이 바로 **단위 테스트(Unit Test)**의 시작입니다.","결론-정적인-코드에서-동적인-아키텍처로#결론: 정적인 코드에서 동적인 아키텍처로":"모델 1에서 모델 2로의 발전, 그리고 DI의 도입은 단순히 코드를 정리하는 수준을 넘어 개발의 패러다임을 바꾼 혁신입니다.\n모델 1: 모든 것이 얽힌 정적인 구조. 변경에 취약하고 재사용이 불가능하며 테스트가 어렵다. 모델 2 (MVC): 역할과 책임을 분리하여 느슨한 결합을 추구. 유지보수성과 재사용성의 기틀을 마련. 모델 2 + DI: 인터페이스를 통한 의존성 주입으로 결합을 끊어내고 동적인 구조를 완성. 각 기능의 완벽한 독립성과 테스트 용이성을 확보하여 유연하고 확장 가능한 시스템을 구축. “백엔드 개발자는 기본적인 문법의 영적이고 확장적인 기능을 파악하여 정적인 기능을 동쪽으로 유도할 줄 아는 능력이 필요합니다\"는 이 모든 과정을 함축합니다. 훌륭한 백엔드 개발자는 단순히 문법에 맞춰 코드를 작성하는 사람이 아닙니다. 변화를 예측하고, 각 기능이 독립적으로 존재하며 서로 유연하게 협력할 수 있는 ‘구조’를 설계할 줄 아는 사람입니다. 딱딱하게 굳어있는 정적인 코드를, 언제든 다른 부품으로 교체할 수 있는 유연하고 살아있는 동적인 시스템으로 만드는 능력, 이것이 바로 모델 2와 DI가 우리에게 가르쳐주는 핵심 교훈이자 현대 백엔드 개발자가 갖춰야 할 가장 중요한 역량입니다.\n문제\n순수 Java 코드(Plain Old Java Object, POJO)로 시작하여 프레임워크 없이 각 개념을 구현해보는 실습입니다.","모델-1에서-모델-2로의-진화-웹-개발-아키텍처-심층-분석#모델 1에서 모델 2로의 진화: 웹 개발 아키텍처 심층 분석":"현대 백엔드 개발의 핵심 철학","서론-왜-아키텍처는-중요한가#서론: 왜 아키텍처는 중요한가?":"소프트웨어 개발은 단순히 ‘동작하는 코드’를 만드는 행위에서 그치지 않습니다. 시간이 지나면서 요구사항은 끊임없이 변화하고, 새로운 기술이 등장하며, 비즈니스는 확장됩니다. 이러한 변화의 파도 속에서 흔들리지 않는 견고하고 유연한 시스템을 구축하는 것, 이것이 바로 ‘아키텍처’의 역할입니다. 제공된 텍스트는 웹 애플리케이션 개발 아키텍처의 중요한 변곡점인 모델 1과 모델 2의 차이를 통해, 좋은 아키텍처가 무엇이며 어떻게 발전해 왔는지를 심도 있게 이야기하고 있습니다. 이는 단순히 기술의 변화가 아닌, ‘문제 해결 방식’에 대한 패러다임의 전환을 의미합니다.","제1장-혼돈의-시대-모델-1-아키텍처#제1장: 혼돈의 시대, 모델 1 아키텍처":"모델 1 아키텍처는 초창기 웹 개발의 직관적인 접근 방식이었습니다. 웹 페이지(JSP, ASP, PHP 등) 하나가 하나의 요청을 처음부터 끝까지 모두 책임지는 구조입니다.\n1. 핵심 구조: All-in-One 페이지\n사용자가 list.jsp라는 페이지를 요청했다고 가정해 봅시다. 모델 1 구조에서 이 list.jsp 파일 안에는 다음과 같은 코드들이 뒤섞여 있습니다.\n① 요청 분석 코드 (Controller의 역할): 사용자가 검색어를 입력했는지, 특정 페이지 번호를 요청했는지 등의 파라미터를 분석하는 자바 코드. ② 비즈니스 로직 및 데이터 처리 코드 (Service \u0026 Repository의 역할): 데이터베이스에 연결하여 게시글 목록을 조회하는 SQL 쿼리와 JDBC 코드. ③ 화면 출력 코드 (View의 역할): 조회된 데이터를 , 등의 HTML 태그를 사용하여 웹 페이지 형태로 그려내는 코드. \u003c%-- list.jsp (모델 1 예시) --%\u003e \u003c%@ page import=\"java.sql.*, java.util.*\" %\u003e 게시판 목록 게시판 목록 \u003c% // ① 요청 분석 + ② 데이터 처리 (Controller + Service + Repository) Connection conn = null; PreparedStatement pstmt = null; ResultSet rs = null; List","제2장-역할의-분리-모델-2-아키텍처의-등장-mvc-패턴#제2장: 역할의 분리, 모델 2 아키텍처의 등장 (MVC 패턴)":"이러한 모델 1의 혼돈을 해결하기 위해 등장한 것이 바로 모델 2 아키텍처, 즉 우리에게 친숙한 MVC(Model-View-Controller) 패턴입니다. 모델 2의 핵심 철학은 ‘관심사의 분리(Separation of Concerns)‘입니다. 각자 잘하는 일에만 집중하자는 것입니다.\nController: 사용자의 요청을 가장 먼저 받는 ‘교통 경찰’입니다. 요청(URL, 파라미터 등)을 분석하여 어떤 작업이 필요한지 판단하고, 그 작업을 실제 일꾼인 ‘Service’에게 위임합니다. 작업이 끝나면 결과를 받아 어떤 ‘View’에게 전달하여 화면을 그리게 할지 결정합니다. Model: 실질적인 데이터와 비즈니스 로직을 담당하는 영역입니다. “게시글을 저장한다”, “사용자 레벨을 업그레이드한다\"와 같은 핵심 로직이 여기에 포함됩니다. 현대 개발에서는 이를 다시 Service와 Repository로 세분화합니다. View: Controller로부터 전달받은 데이터를 화면에 ‘그리는’ 일만 합니다. JSP, Thymeleaf 등이 여기에 해당하며, 내부에는 비즈니스 로직이 전혀 없고 오직 표현 로직만 존재합니다. 1. 모델 2의 정제: Controller-Service-Repository 구조\n텍스트에서 설명하듯, 현대적인 모델 2 구현은 Model 영역을 더욱 구체적으로 분화하여 책임과 역할을 명확히 합니다.\nController: 오직 웹 요청과 응답에만 집중합니다. HTTP 헤더를 분석하고, 요청 본문을 객체로 변환하며, 인증/인가를 확인하고, 적절한 Service 메소드를 호출한 뒤, 그 결과를 JSON, HTML 등 요청된 형식으로 변환하여 응답합니다. 예시: /posts (GET 요청) -\u003e PostController.getPostList() 호출 Service: ‘비즈니스 로직’의 중심입니다. 트랜잭션 관리, 여러 데이터 소스 조합 등 애플리케이션의 핵심 정책과 규칙을 구현합니다. 이 계층은 웹(HTTP)이나 데이터베이스(SQL) 기술에 의존하지 않는 순수한 자바 코드로 작성되는 것을 지향합니다. 예시: PostService.getPostList() -\u003e 게시글 목록 조회 로직 수행. 필요하다면 UserService를 호출하여 작성자 정보를 함께 가져올 수도 있음. 재사용성의 핵심: 텍스트의 “웹에서 작동했던 게시판의 기능을 단말 어플로 확장해야 할 때 서비스의 고유 기능을 유지한 상태에서 컨트롤러의 기능만 수정\"할 수 있다는 설명이 바로 이 지점입니다. 모바일 앱을 위한 JSON 응답이 필요하면, 기존 PostService는 그대로 두고 ApiPostController를 새로 만들어 동일한 서비스를 호출하기만 하면 됩니다. 핵심 로직의 재사용성이 극대화됩니다. Repository(DAO): 데이터 영속성(Persistence)만을 전담합니다. 즉, 데이터베이스에 데이터를 저장(Save), 조회(Find), 수정(Update), 삭제(Delete)하는 역할만 수행합니다. 예시: PostRepository.findAll() -\u003e SELECT * FROM post 쿼리 실행 유지보수의 효율성: 텍스트의 “테이블 구조 변경 시 리파지토리 수정만으로 적용이 가능\"하다는 설명이 여기에 해당합니다. 데이터베이스가 MySQL에서 PostgreSQL로 바뀌거나, ORM 기술(JPA 등)을 도입할 때, 오직 Repository 계층의 코드만 수정하면 Service나 Controller는 아무런 영향을 받지 않습니다. 2. 소통의 규약: DTO (Data Transfer Object)\n모델 1의 ‘어레이 문제’를 해결하는 모델 2의 해법이 바로 DTO입니다. 텍스트에서는 ‘데이터 전달 객체’라고 표현했습니다.\nDTO란? 계층 간 데이터 교환을 위해 사용하는, 데이터 필드(멤버 변수)와 그에 대한 Getter/Setter 메소드만으로 이루어진 순수한 데이터 운반용 객체입니다. 장점: 명확한 계약: DTO는 그 자체로 계층 간에 “우리는 이런 구조의 데이터를 주고받을 것이다\"라는 명확한 약속(Contract)이 됩니다. 타입 안정성(Type Safety): map.get(\"title\") 대신 postDto.getTitle()을 사용합니다. getTitle() 메소드는 항상 문자열(String)을 반환함이 보장되며, 만약 getTitel()과 같이 오타를 내면 컴파일 시점에 즉시 오류를 발견할 수 있습니다. 개발 편의성: IDE의 자동완성 기능 등을 통해 어떤 데이터가 있는지 쉽게 파악할 수 있어 생산성이 향상됩니다.","제3장-궁극의-유연성-의존성-주입-dependency-injection#제3장: 궁극의 유연성, 의존성 주입 (Dependency Injection)":"모델 2 구조로 역할을 분리하고 DTO로 소통 규약을 정했지만, 마지막 문제가 남아있습니다. “실제 구현에서 각각의 기능을 연동하기 위한 코드가 생성되어 기능의 독립성이 사라지는 문제\"입니다.\nPostController가 PostService를 사용하려면 어떻게 해야 할까요? 가장 단순한 방법은 다음과 같습니다.\npublic class PostController { private PostService postService = new PostServiceImpl(); // ★ 문제 지점! // ... } PostController가 PostServiceImpl이라는 ‘구체적인 구현 클래스’를 직접 생성하고 있습니다. 이를 **‘강한 결합(Tight Coupling)’**이라고 합니다. 이 코드의 문제는, 만약 PostService의 구현체를 테스트용 TestPostServiceImpl로 바꾸고 싶을 때 PostController의 코드를 직접 수정해야 한다는 것입니다. 각 기능의 독립적인 개발과 테스트가 다시 어려워집니다.\n1. 의존성 주입(DI)과 제어의 역전(IoC)\n이 문제를 해결하는 기술이 바로 **의존성 주입(DI)**입니다. DI의 근간에는 **제어의 역전(Inversion of Control, IoC)**이라는 원리가 있습니다.\n기존 방식: PostController가 자신이 사용할 PostService 객체를 **직접 생성(제어)**한다. IoC/DI 방식: PostController는 PostService 객체를 생성하지 않는다. 단지 “나는 PostService 타입의 객체가 필요해!“라고 선언만 해둔다. 그러면 **외부의 누군가(DI 컨테이너, 예: 스프링 프레임워크)**가 PostController에게 필요한 PostService 객체를 만들어서 **주입(연결)**해준다. 객체를 생성하고 연결하는 ‘제어’의 흐름이 개발자 코드에서 프레임워크로 역전된 것입니다. 2. “동물이 오리로 변하고 강아지로 변한다\"는 비유의 해석\n텍스트의 이 비유는 DI의 핵심을 완벽하게 설명합니다.\n동물 (Animal): 이것이 바로 **인터페이스(Interface)**입니다. 소리를 내다(makeSound())라는 ‘기능(메소드)‘을 약속(정의)합니다. 오리(Duck), 강아지(Dog): 이것이 **구현체(Implementation)**입니다. 동물 인터페이스를 구현하여, 소리를 내다() 메소드를 꽤액꽤액 또는 멍멍으로 구체화합니다. 사육사(Zookeeper): 동물을 필요로 하는 클라이언트 코드(예: Controller, Service)입니다. // 인터페이스 (약속) public interface Animal { String makeSound(); } // 구현체 1 public class Duck implements Animal { @Override public String makeSound() { return \"꽤액꽤액\"; } } // 구현체 2 public class Dog implements Animal { @Override public String makeSound() { return \"멍멍\"; } } // 클라이언트 (스프링에서의 예시) @RestController public class ZookeeperController { private final Animal animal; // '구현체'가 아닌 '인터페이스'에 의존! // 생성자를 통해 외부에서 Animal 객체를 주입받음 (DI) @Autowired public ZookeeperController(Animal animal) { this.animal = animal; } @GetMapping(\"/sound\") public String hearSound() { // 주입된 객체가 Dog라면 \"멍멍\", Duck이라면 \"꽤액꽤액\"이 반환됨 return animal.makeSound(); } } ZookeeperController는 Dog인지 Duck인지 전혀 모릅니다. 단지 Animal 인터페이스에 정의된 makeSound()를 호출할 뿐입니다. 어떤 동물이 주입될지는 스프링 프레임워크가 설정(Configuration)에 따라 **런타임(실행 시점)**에 결정하여 ‘동적으로’ 연결해줍니다. 이것이 바로 텍스트에서 말한 “인터페이스로 연동하여 기능이 실행되는 런타임에서 인터페이스의 구현체를 주입하는 방식\"이며, “동적 생성\"의 진정한 의미입니다.\n이러한 DI를 통해, 우리는 테스트 시에는 실제 DB에 접근하는 RealPostRepository 대신, 메모리에서 가짜 데이터를 반환하는 MockPostRepository를 PostService에 주입하여 DB 없이도 Service 로직을 완벽하게 테스트할 수 있게 됩니다. 각 계층이 완벽하게 분리되어 독립적인 개발과 테스트가 가능해지는 것입니다."},"title":"백엔드 구조 변화 역사"},"/02.inbox/%EB%B2%A8%EB%A7%8C-%ED%8F%AC%EB%93%9C-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%EC%83%81%EC%84%B8%EA%B3%BC%EC%A0%95/":{"data":{"":"이 표는 시작 노드 u에서 다른 모든 노드(v, w, x, y, z)까지의 최단 거리를 벨만-포드 알고리즘을 사용하여 찾는 과정을 보여줍니다. 벨만-포드 알고리즘은 거쳐가는 간선(hop)의 개수를 1개부터 점차 늘려가며 최단 거리를 갱신하는 방식입니다.","--2단계-최대-2개-간선-사용-상세-비교-과정### 🔎 2단계 (최대 2개 간선 사용) 상세 비교 과정":"2단계는 1단계의 결과에, 간선을 하나 더 추가했을 때 더 짧은 경로가 생기는지 모든 가능성을 확인하는 과정입니다.\n시작 정보 (1단계 결과):\nD(v) = 2 (경유지 v) D(w) = 5 (경유지 w) D(x) = 1 (경유지 x) D(y) = ∞ D(z) = ∞ 이제 각 목적지(v, w, x, y, z)에 대해, u의 직접 이웃(v, w, x)을 거쳐 가는 경로와 기존 경로를 비교합니다.","-1단계-최대-1개의-간선-사용-up-to-1-hop#🔎 \u003cstrong\u003e1단계: 최대 1개의 간선 사용 (up to 1 hop)\u003c/strong\u003e":"이 단계에서는 시작 노드 u와 직접 연결된 이웃 노드까지만의 거리를 계산합니다.\nv까지의 비용: 2, 경유지: (v) 논리: u에서 v까지 직접 연결된 간선의 비용이 2입니다. w까지의 비용: 5, 경유지: (w) 논리: u에서 w까지 직접 연결된 간선의 비용이 5입니다. x까지의 비용: 1, 경유지: (x) 논리: u에서 x까지 직접 연결된 간선의 비용이 1입니다. y, z까지의 비용: ∞ 논리: u에서 y와 z로는 직접 연결된 간선이 없으므로, 초기 비용은 무한대(∞)입니다.","-2단계-최대-2개의-간선-사용-up-to-2-hops#🔎 \u003cstrong\u003e2단계: 최대 2개의 간선 사용 (up to 2 hops)\u003c/strong\u003e":"이제 최대 2개의 간선을 사용하여 갈 수 있는 경로를 계산합니다. 즉, 1단계에서 계산된 이웃 노드(v, w, x)를 거쳐 다른 노드로 가는 경로를 고려합니다.\nv까지의 비용: 2, 경유지: (v) 논리: u에서 v로 가는 직접 경로(비용 2)보다 더 짧은 경로가 발견되지 않았습니다. w까지의 비용: 4, 경유지: (x) 논리: 기존의 u→w 직접 경로(비용 5)보다 u→x→w 경로가 더 짧다는 것을 의미합니다. 계산: u→x 비용(1) + x→w 비용(3) = 4 입니다. (따라서 x와 w는 비용 3으로 연결되어 있음을 알 수 있습니다.) 비용이 5에서 4로 갱신되고, 경유지도 w에서 x로 변경되었습니다. x까지의 비용: 1, 경유지: (x) 논리: u에서 x로 가는 직접 경로(비용 1)가 여전히 최단 거리입니다. y까지의 비용: 2, 경유지: (x) 논리: u에서 y로 가는 새로운 경로가 발견되었습니다. u→x→y 경로입니다. 계산: u→x 비용(1) + x→y 비용(1) = 2 입니다. (x와 y는 비용 1로 연결되어 있음을 알 수 있습니다.) z까지의 비용: 10, 경유지: (w) 논리: u에서 z로 가는 새로운 경로가 발견되었습니다. u→w→z 경로입니다. 계산: u→w 비용(5) + w→z 비용(5) = 10 입니다. (w와 z는 비용 5로 연결되어 있음을 알 수 있습니다.)","-3단계-최대-3개의-간선-사용-up-to-3-hops#🔎 \u003cstrong\u003e3단계: 최대 3개의 간선 사용 (up to 3 hops)\u003c/strong\u003e":"최대 3개의 간선을 사용하여 가는 경로를 계산합니다. 2단계에서 갱신된 거리 정보를 활용합니다.\nw까지의 비용: 3, 경유지: (x) 논리: 기존 u→x→w 경로(비용 4)보다 더 짧은 경로가 발견되었습니다. u→x→y→w 경로일 가능성이 높습니다. 계산: u→x→y 비용(2) + y→w 비용(1) = 3 입니다. (y와 w는 비용 1로 연결되어 있음을 알 수 있습니다.) 비용이 4에서 3으로 갱신되었습니다. z까지의 비용: 4, 경유지: (x) 논리: 기존 u→w→z 경로(비용 10)보다 훨씬 짧은 경로가 발견되었습니다. u→x→y→z 경로일 가능성이 있습니다. 계산: u→x→y 비용(2) + y→z 비용(2) = 4 입니다. (y와 z는 비용 2로 연결되어 있음을 알 수 있습니다.) 비용이 10에서 4로 크게 줄고, 경유지도 w에서 x로 변경되었습니다. v, x, y는 변경 없음: 더 짧은 경로가 발견되지 않았습니다.","-4단계-및-5단계-최대-4-5개-간선-사용#🔎 \u003cstrong\u003e4단계 및 5단계: 최대 4, 5개 간선 사용\u003c/strong\u003e":"논리: 3단계에서 계산된 비용과 비교했을 때 어떤 노드로의 비용도 더 이상 줄어들지 않았습니다. 이는 3개의 간선을 사용하는 경로에서 이미 모든 노드까지의 최단 거리가 구해졌음을 의미합니다. 벨만-포드 알고리즘은 이렇게 더 이상 거리 갱신이 일어나지 않으면 최단 경로 탐색을 완료합니다. 보통 (전체 노드 개수 - 1) 만큼 반복하면 최단 거리를 보장하지만, 그전에 갱신이 멈추면 조기 종료할 수 있습니다.","-경유지next-hop-표기의-장점### 경유지(Next Hop) 표기의 장점":"최단 거리 알고리즘에서 비용(Cost)만 계산하지 않고 다음 경유지(표에서는 ’to neighbor of u’)를 함께 기록하는 이유는 실제 경로를 복원하기 위해서입니다.\n비용 vs. 경로: 단순히 ‘u에서 z까지 최단 거리는 4’라는 사실만 아는 것과, ‘u → x → y → z‘라는 경로를 아는 것은 큰 차이가 있습니다. 내비게이션 앱이 “목적지까지 요금은 5,000원입니다\"라고만 알려주고 경로를 알려주지 않는다면 무용지물인 것과 같습니다. 경로 재구성 (Path Reconstruction): 최종적으로 계산된 경유지 정보를 따라가면 전체 경로를 알아낼 수 있습니다. 예시: z로 가는 최종 경유지는 **(x)**입니다. 이는 최단 경로가 u → x ...로 시작함을 의미합니다. (실제 알고리즘에서는 모든 노드에 대해 직전 노드(predecessor)를 저장하므로) x는 y를 통해 왔고, y는 u에서 온 x를 통해 왔다는 것을 역추적하여 u → x → y → z 전체 경로를 완성할 수 있습니다. 결론적으로 경유지 정보는 알고리즘이 찾은 **최단 거리의 ‘증거’이자 ‘실행 계획’**이 됩니다.","-기본-개념-벨만-포드-알고리즘### 기본 개념: 벨만-포드 알고리즘":"벨만-포드 알고리즘의 핵심 아이디어는 다음과 같습니다.\nk개의 간선까지만 사용했을 때의 최단 거리를 계산합니다. 이전 단계(k-1개 간선 사용)의 최단 거리 정보를 이용해 현재 단계(k개 간선 사용)의 최단 거리를 갱신합니다. 공식: D[u] \u003e D[v] + cost(v, u) 이면 D[u] = D[v] + cost(v, u)로 갱신합니다. (v를 거쳐 u로 가는 거리가 더 짧다면 갱신) 주어진 표에서 “up to k hops\"는 최대 k개의 간선을 사용했을 때 u로부터 각 노드까지의 최단 거리를 의미합니다.","-단계별-논리-설명### 단계별 논리 설명":"각 단계에서 비용(Cost)과 다음 경유지(to neighbor of u)가 어떻게 결정되는지 살펴보겠습니다. 이 과정을 이해하려면 각 노드 간의 직접적인 연결 비용을 알아야 하지만, 표의 변화를 통해 역으로 추적해 보겠습니다.","-최종-결과-요약### 최종 결과 요약":"표의 마지막 줄(up to 4 또는 5 hops)이 시작 노드 u에서 각 노드까지의 최종 최단 거리입니다.\nu → v: 비용 2 (경로: u→v) u → w: 비용 3 (경로: u→x→y→w) u → x: 비용 1 (경로: u→x) u → y: 비용 2 (경로: u→x→y) u → z: 비용 4 (경로: u→x→y→z)","1-목적지-v#\u003cstrong\u003e1. 목적지: v\u003c/strong\u003e":"기존 최단 거리: u → v (비용 2) 새로운 경로 탐색: u → w → v: 비용 D(w) + cost(w,v) = 5 + ? u → x → v: 비용 D(x) + cost(x,v) = 1 + ? 결론: u → v 직접 경로(비용 2)보다 더 짧은 2-hop 경로가 발견되지 않았습니다. 변경 없음.","2-목적지-w#\u003cstrong\u003e2. 목적지: w\u003c/strong\u003e":"기존 최단 거리: u → w (비용 5) 새로운 경로 탐색: u → v → w: 비용 D(v) + cost(v,w) = 2 + ? u → x → w: 비용 D(x) + cost(x,w) = 1 + 3 = 4 비교: 새로운 경로 u → x → w의 비용(4)이 기존 경로 비용(5)보다 더 저렴합니다. 결론: w까지의 최단 거리를 4로 갱신하고, 경유지를 (w)에서 **(x)**로 변경합니다.","3-목적지-x#\u003cstrong\u003e3. 목적지: x\u003c/strong\u003e":"기존 최단 거리: u → x (비용 1) 새로운 경로 탐색: u → v → x: 비용 D(v) + cost(v,x) = 2 + ? u → w → x: 비용 D(w) + cost(w,x) = 5 + ? 결론: u → x 직접 경로(비용 1)는 이미 매우 저렴하여, 다른 노드를 거쳐 가는 경로가 더 짧아질 가능성이 거의 없습니다. 변경 없음.","4-목적지-y#\u003cstrong\u003e4. 목적지: y\u003c/strong\u003e":"기존 최단 거리: ∞ (경로 없음) 새로운 경로 탐색: u → v → y: 비용 D(v) + cost(v,y) = 2 + ? u → w → y: 비용 D(w) + cost(w,y) = 5 + ? u → x → y: 비용 D(x) + cost(x,y) = 1 + 1 = 2 비교: 새로운 경로 u → x → y의 비용(2)이 기존 비용(∞)보다 더 저렴합니다. 결론: y까지의 최단 거리를 2로 갱신하고, 경유지를 **(x)**로 설정합니다.","5-목적지-z#\u003cstrong\u003e5. 목적지: z\u003c/strong\u003e":"기존 최단 거리: ∞ (경로 없음) 새로운 경로 탐색: u → v → z: 비용 D(v) + cost(v,z) = 2 + ? u → w → z: 비용 D(w) + cost(w,z) = 5 + 5 = 10 u → x → z: 비용 D(x) + cost(x,z) = 1 + ? 비교: 새로운 경로 u → w → z의 비용(10)이 기존 비용(∞)보다 더 저렴합니다. (u→x를 통한 경로는 아직 z로 이어지지 않음) 결론: z까지의 최단 거리를 10으로 갱신하고, 경유지를 **(w)**로 설정합니다. 이러한 모든 비교 과정을 거쳐 표의 “up to 2 hops” 행이 완성되는 것입니다. 이와 같은 ‘완화(relaxation)’ 과정을 모든 간선에 대해 반복하며 최적의 해를 찾아 나가는 것이 벨만-포드 알고리즘의 핵심입니다."},"title":"벨만 포드 알고리즘 상세과정"},"/02.inbox/%EB%B8%8C%EB%9D%BC%EC%9A%B0%EC%A0%80-%EA%B8%B0%EB%B0%98-%EC%88%98%EA%B0%95%EC%8B%A0%EC%B2%AD-%EC%95%8C%EB%A6%BC-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%84%A4%EA%B3%84%EC%84%9C/":{"data":{"":"","1-프로젝트-개요#1. 프로젝트 개요":"명지대학교 수강신청 시스템의 ‘미리담기 내역’ 페이지(https://class.mju.ac.kr/main/bag)에서 ‘인원초과’ 상태인 강의에 빈자리가 발생했을 때, 사용자에게 데스크탑 알림을 보내주는 크롬 확장 프로그램을 개발한다. 이 프로그램은 사용자가 수동으로 새로고침하며 자리를 확인하는 불편함을 해소하는 것을 목표로 한다.","2-목표#2. 목표":"특정 페이지에서만 동작: https://class.mju.ac.kr/main/bag URL에서만 확장 프로그램의 기능이 활성화된다. UI 요소 삽입: ‘인원초과’가 표시된 강의 항목에 ‘알림 대기’ 버튼을 동적으로 추가한다. 백그라운드 모니터링: 사용자가 ‘알림 대기’ 버튼을 클릭하면, 해당 강의를 백그라운드에서 주기적으로 확인한다. 실시간 알림: 모니터링 중인 강의에 빈자리([인원초과] 문자열 제거)가 확인되면 즉시 사용자에게 크롬 데스크탑 알림을 보낸다. 메모리 기반 데이터 관리: 알림 대기 중인 강의 목록, CSRF 토큰 등 모든 상태 정보는 chrome.storage를 사용하지 않고, 확장 프로그램의 실행 시간 동안 메모리(JavaScript 변수)에만 저장한다. 비-간섭적 작동: 백그라운드 확인 작업은 현재 사용자가 보고 있는 페이지를 새로고침하거나 UI를 변경하지 않는다.","3-아키텍처-및-구성-요소#3. 아키텍처 및 구성 요소":"확장 프로그램은 다음과 같은 세 가지 주요 파일로 구성된다.\nmanifest.json (확장 프로그램 설정 파일)\n확장 프로그램의 이름, 버전, 설명 등 기본 정보 정의 필요한 권한 요청 (notifications, alarms, scripting) Content Script가 실행될 URL 지정 (https://class.mju.ac.kr/main/bag) Background Script(Service Worker) 등록 content_script.js (콘텐츠 스크립트)\n역할: 웹 페이지 DOM(Document Object Model)에 직접 접근하여 UI를 조작하고, 백그라운드 스크립트와 통신하는 중개자. 주요 기능: 페이지 로드 시, 현재 URL이 https://class.mju.ac.kr/main/bag인지 확인. div.coursedata 요소를 모두 순회하며, 내부에 [ 인원초과 ] 텍스트가 포함된 span.fullclass가 있는지 확인. 조건에 맞는 강의의 div.btnarea 내부에 ‘알림 대기’ 버튼을 생성하고 삽입. ‘알림 대기’ 버튼에 클릭 이벤트 리스너를 추가. 버튼 클릭 시, 해당 강의의 고유 식별자(예: data-coursecls 값)와 페이지의 CSRF 토큰(meta[name=\"_csrf\"] 태그의 content 값)을 추출. 추출된 (강의 ID, CSRF 토큰) 정보를 Background Script로 메시지 전송. (선택) 알림이 시작되면 버튼의 텍스트를 ‘알림 대기중…‘으로 변경하고 비활성화하여 중복 요청 방지. background.js (백그라운드 스크립트 - Service Worker)\n역할: 확장 프로그램의 핵심 두뇌. 보이지 않는 곳에서 주기적인 작업을 수행하고 상태를 관리. 주요 기능: 상태 관리 (메모리): monitoredCourses: 알림 대기 중인 강의 ID를 저장하는 Set 또는 Map 객체. (예: new Set(['0710', '0084'])) csrfToken: Content Script로부터 최초로 전달받은 CSRF 토큰을 저장하는 변수. 메시지 수신: Content Script로부터 메시지(chrome.runtime.onMessage)를 수신 대기. 메시지 수신 시, 전달받은 강의 ID를 monitoredCourses에 추가하고, csrfToken을 업데이트. 알림 대기 목록에 강의가 추가되면 주기적인 확인 작업을 시작/유지. 주기적 작업 (chrome.alarms API 사용): 일정 시간(예: 5초) 간격으로 알람을 설정. setInterval보다 Service Worker 환경에 더 적합. 알람이 울리면 등록된 모든 monitoredCourses에 대해 확인 작업 수행. 데이터 확인 (Fetch): 저장된 csrfToken을 사용하여 https://class.mju.ac.kr/main/bag에 POST 요청을 보냄 (요청 형식은 제공된 명세와 동일하게 구성). 응답으로 받은 HTML 텍스트를 파싱. 상태 비교 및 알림: 파싱된 HTML 내에서, monitoredCourses에 포함된 각 강의 ID에 해당하는 div.coursedata를 찾음. 해당 강의의 span.fullclass 요소에서 [ 인원초과 ] 문자열이 사라졌는지 확인. 빈자리가 확인되면 chrome.notifications.create API를 사용하여 사용자에게 데스크탑 알림을 표시. (예: “‘알고리즘’ 강의에 빈자리가 생겼습니다!”). 알림을 보낸 강의 ID는 monitoredCourses 목록에서 제거하여 더 이상 확인하지 않도록 함.","4-데이터-관리-전략#4. 데이터 관리 전략":"저장소: 모든 데이터는 background.js 내의 JavaScript 변수(전역 스코프)에 저장된다. 데이터 생명주기: 알림 대기 강의 목록 (monitoredCourses): 사용자가 ‘알림 대기’ 버튼을 누를 때 추가되고, 빈자리 알림이 발생하거나 브라우저가 종료되면 초기화된다. CSRF 토큰 (csrfToken): 사용자가 첫 ‘알림 대기’ 버튼을 누를 때 content_script.js가 페이지에서 추출하여 background.js로 전달하며, 이후 모든 백그라운드 fetch 요청에 사용된다. 브라우저 종료 시 사라진다. 장점: 구현이 간단하고 빠르다. 단점: 브라우저를 닫거나 크롬을 재시작하면 모든 알림 대기 상태가 초기화된다. 이는 요구사항에 부합하는 설계이다.","5-동작-시나리오-user-flow#5. 동작 시나리오 (User Flow)":"사용자가 명지대학교 수강신청 사이트에 로그인 후, https://class.mju.ac.kr/main/bag 페이지로 이동한다. content_script.js가 실행되어 [ 인원초과 ]가 붙은 ‘알고리즘’ 강의 옆에 ‘알림 대기’ 버튼을 생성한다. 사용자가 ‘알고리즘’ 강의의 ‘알림 대기’ 버튼을 클릭한다. content_script.js는 ‘알고리즘’의 강의 ID(‘0710’)와 현재 페이지의 CSRF 토큰 값을 가져와 background.js로 전송한다. 버튼은 ‘알림 대기중…‘으로 변경된다. background.js는 메시지를 수신하고, 내부 변수 monitoredCourses에 ‘0710’을 추가하고, csrfToken 변수에 토큰 값을 저장한다. background.js는 chrome.alarms를 이용해 5초 간격의 확인 작업을 시작한다. 5초 후, background.js는 저장된 csrfToken을 이용해 /main/bag 페이지의 최신 정보를 fetch로 가져온다. 가져온 HTML을 분석하여 ‘0710’ 강의에 여전히 [ 인원초과 ]가 있는지 확인한다. 아직 자리가 없다. (시간 경과 후) 다음 확인 주기에서 fetch한 HTML에서 ‘0710’ 강의에 [ 인원초과 ] 문구가 사라진 것을 감지한다. background.js는 chrome.notifications.create를 호출하여 “‘0710 알고리즘’ 강의에 빈자리가 생겼습니다!” 라는 알림을 띄운다. background.js는 monitoredCourses 목록에서 ‘0710’을 제거하고, 해당 강의에 대한 모니터링을 중단한다. content_script.js 가 생성한 알림 버튼도 같이 제거한다","6-기술적-고려사항#6. 기술적 고려사항":"CSRF 토큰 및 세션: 사용자의 세션이 만료되거나 로그아웃되면 백그라운드 fetch 요청이 실패할 수 있다. 이 경우, 알람을 중지하고 사용자에게 재로그인 및 페이지 새로고침이 필요함을 알리는 것을 고려할 수 있다 (고급 기능). 요청 주기: 서버에 과도한 부하를 주지 않기 위해 fetch 요청 간격을 너무 짧지 않게 설정해야 한다 (예: 3~10초). 웹사이트 구조 변경: 명지대학교 수강신청 사이트의 HTML 구조(클래스 이름, ID 등)가 변경되면 확장 프로그램이 오작동할 수 있다. 이는 유지보수 시 대응해야 할 부분이다. 오류 처리: fetch 실패, 네트워크 오류 등에 대한 예외 처리를 구현하여 안정성을 높여야 한다.","6-요청된-url-에서-강의-데이터-구조#6. 요청된 url 에서 강의 데이터 구조":"\u003cdiv id=\"bagresult\" class=\"courselist\" data-req=\"Y\" data-bag=\"N\" data-reqdel=\"N\" data-bagdel=\"Y\" role=\"list\"\u003e \u003cdiv class=\"coursedata filter\" role=\"listitem\" id=\"coursedataid-0419\" data-addtime=\"808151054\" data-coursecls=\"0419\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan class=\"fullclass\" id=\"fullsign-0419\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e0419 빅데이터인포그래픽(KCU)\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 전학년 / 균컴114 / 학점 : 3 / 담당교수 : 이규연 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e시간 미지정\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-remark\"\u003e 비고 : \u003cb\u003e온라인(원격수업)\u003c/b\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-0419\"\u003e457\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-0419\"\u003e108\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-0419\"\u003e108\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied0419\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-0419\" class=\"classbtn reqbtn sorthide\" aria-label=\"0419 빅데이터인포그래픽(KCU) 수강신청하기\" data-coursecls=\"0419\" data-curinum=\"KMQ01114\" style=\"display: block;\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"0419\" data-curinum=\"KMQ01114\" aria-label=\"0419 빅데이터인포그래픽(KCU) 미리담기 삭제하기\" style=\"display: block;\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\" style=\"display: none;\"\u003e≡\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"coursedata filter\" role=\"listitem\" id=\"coursedataid-5469\" data-addtime=\"808164217\" data-coursecls=\"5469\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan class=\"fullclass\" id=\"fullsign-5469\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e5469 인체안의전쟁(KCU)\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 전학년 / 균여133 / 학점 : 3 / 담당교수 : 미배정 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e시간 미지정\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-remark\"\u003e 비고 : \u003cb\u003e온라인(원격수업),KCU\u003c/b\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-5469\"\u003e433\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-5469\"\u003e176\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-5469\"\u003e176\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied5469\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-5469\" class=\"classbtn reqbtn sorthide\" aria-label=\"5469 인체안의전쟁(KCU) 수강신청하기\" data-coursecls=\"5469\" data-curinum=\"KMO02133\" style=\"display: block;\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"5469\" data-curinum=\"KMO02133\" aria-label=\"5469 인체안의전쟁(KCU) 미리담기 삭제하기\" style=\"display: block;\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\" style=\"display: none;\"\u003e≡\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"coursedata filter\" role=\"listitem\" id=\"coursedataid-0233\" data-addtime=\"814100108\" data-coursecls=\"0233\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan class=\"fullclass\" id=\"fullsign-0233\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e0233 문화속디자인여행(KCU)\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 전학년 / 기문217 / 학점 : 3 / 담당교수 : 이규연 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e시간 미지정\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-remark\"\u003e 비고 : \u003cb\u003e온라인(원격수업)\u003c/b\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-0233\"\u003e598\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-0233\"\u003e108\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-0233\"\u003e108\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied0233\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-0233\" class=\"classbtn reqbtn sorthide\" aria-label=\"0233 문화속디자인여행(KCU) 수강신청하기\" data-coursecls=\"0233\" data-curinum=\"KMC02217\" style=\"display: block;\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"0233\" data-curinum=\"KMC02217\" aria-label=\"0233 문화속디자인여행(KCU) 미리담기 삭제하기\" style=\"display: block;\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\" style=\"display: none;\"\u003e≡\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"coursedata filter\" role=\"listitem\" id=\"coursedataid-5431\" data-addtime=\"814100118\" data-coursecls=\"5431\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan class=\"fullclass\" id=\"fullsign-5431\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e5431 영화제작에대해알고싶은모든것(KCU)\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 전학년 / 균문122 / 학점 : 3 / 담당교수 : 미배정 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e시간 미지정\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-remark\"\u003e 비고 : \u003cb\u003e온라인(원격수업),KCU\u003c/b\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-5431\"\u003e516\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-5431\"\u003e176\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-5431\"\u003e176\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied5431\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-5431\" class=\"classbtn reqbtn sorthide\" aria-label=\"5431 영화제작에대해알고싶은모든것(KCU) 수강신청하기\" data-coursecls=\"5431\" data-curinum=\"KML02122\" style=\"display: block;\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"5431\" data-curinum=\"KML02122\" aria-label=\"5431 영화제작에대해알고싶은모든것(KCU) 미리담기 삭제하기\" style=\"display: block;\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\" style=\"display: none;\"\u003e≡\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"coursedata filter\" role=\"listitem\" id=\"coursedataid-0084\" data-addtime=\"814104427\" data-coursecls=\"0084\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan class=\"fullclass\" id=\"fullsign-0084\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e0084 영어회화2\u003c/span\u003e \u003cspan\u003e (\u003cspan\u003eL3\u003c/span\u003e) \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 전학년 / 교필109 / 학점 : 1 / 담당교수 : 데본 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e \u003cspan\u003e월12:00~12:50(Y9230), 수12:00~12:50(Y9230)\u003c/span\u003e \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-0084\"\u003e48\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-0084\"\u003e11\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-0084\"\u003e11\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied0084\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-0084\" class=\"classbtn reqbtn sorthide\" aria-label=\"0084 영어회화2 수강신청하기\" data-coursecls=\"0084\" data-curinum=\"KMA02109\" style=\"display: block;\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"0084\" data-curinum=\"KMA02109\" aria-label=\"0084 영어회화2 미리담기 삭제하기\" style=\"display: block;\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\" style=\"display: none;\"\u003e≡\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"coursedata filter\" role=\"listitem\" id=\"coursedataid-0710\" data-addtime=\"814104302\" data-coursecls=\"0710\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan class=\"fullclass\" id=\"fullsign-0710\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e0710 알고리즘\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 3학년 / 컴공316 / 학점 : 3 / 담당교수 : 조민경 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e \u003cspan\u003e월09:00~10:50(Y5437), 목09:00~09:50(Y5437)\u003c/span\u003e \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-0710\"\u003e53\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-0710\"\u003e30\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-0710\"\u003e30\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-past\" data-grade=\"D+\"\u003e ※ 과거 이수성적 : 2023-2학기 : 알고리즘 D+ \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied0710\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-0710\" class=\"classbtn reqbtn sorthide\" aria-label=\"0710 알고리즘 수강신청하기\" data-coursecls=\"0710\" data-curinum=\"JEJ02316\" style=\"display: block;\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"0710\" data-curinum=\"JEJ02316\" aria-label=\"0710 알고리즘 미리담기 삭제하기\" style=\"display: block;\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\" style=\"display: none;\"\u003e≡\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"coursedata filter\" role=\"listitem\" id=\"coursedataid-0762\" data-addtime=\"814100722\" data-coursecls=\"0762\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan style=\"display:none\" class=\"fullclass\" id=\"fullsign-0762\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e0762 산업경영공학개론\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 1학년 / 산업213 / 학점 : 3 / 담당교수 : 한민탁 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e시간 미지정\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-remark\"\u003e 비고 : \u003cb\u003e아너칼리지및타전공수강,전공자수강X,전공이해기초교과,MJU자율수강제강좌,온라인강의\u003c/b\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-0762\"\u003e6\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-0762\"\u003e7\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-0762\"\u003e50\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied0762\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-0762\" class=\"classbtn reqbtn sorthide\" aria-label=\"0762 산업경영공학개론 수강신청하기\" data-coursecls=\"0762\" data-curinum=\"JEO01213\" style=\"display: block;\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"0762\" data-curinum=\"JEO01213\" aria-label=\"0762 산업경영공학개론 미리담기 삭제하기\" style=\"display: block;\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\" style=\"display: none;\"\u003e≡\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"coursedata filter\" role=\"listitem\" id=\"coursedataid-0238\" data-addtime=\"814102933\" data-coursecls=\"0238\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan class=\"fullclass\" id=\"fullsign-0238\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e0238 MJ사회봉사\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 전학년 / 기사167 / 학점 : 3 / 담당교수 : 유우연 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e \u003cspan\u003e월17:00~19:50(Y501)\u003c/span\u003e \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-remark\"\u003e 비고 : \u003cb\u003eN/P과목\u003c/b\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-0238\"\u003e56\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-0238\"\u003e17\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-0238\"\u003e17\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied0238\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-0238\" class=\"classbtn reqbtn sorthide\" aria-label=\"0238 MJ사회봉사 수강신청하기\" data-coursecls=\"0238\" data-curinum=\"KMD02167\" style=\"display: block;\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"0238\" data-curinum=\"KMD02167\" aria-label=\"0238 MJ사회봉사 미리담기 삭제하기\" style=\"display: block;\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\" style=\"display: none;\"\u003e≡\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003c/div\u003e\u003cdiv id=\"bagresult\" class=\"courselist\" data-req=\"Y\" data-bag=\"N\" data-reqdel=\"N\" data-bagdel=\"Y\" role=\"list\"\u003e \u003cdiv class=\"coursedata filter\" role=\"listitem\" id=\"coursedataid-0419\" data-addtime=\"808151054\" data-coursecls=\"0419\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan class=\"fullclass\" id=\"fullsign-0419\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e0419 빅데이터인포그래픽(KCU)\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 전학년 / 균컴114 / 학점 : 3 / 담당교수 : 이규연 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e시간 미지정\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-remark\"\u003e 비고 : \u003cb\u003e온라인(원격수업)\u003c/b\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-0419\"\u003e457\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-0419\"\u003e108\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-0419\"\u003e108\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied0419\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-0419\" class=\"classbtn reqbtn sorthide\" aria-label=\"0419 빅데이터인포그래픽(KCU) 수강신청하기\" data-coursecls=\"0419\" data-curinum=\"KMQ01114\" style=\"display: block;\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"0419\" data-curinum=\"KMQ01114\" aria-label=\"0419 빅데이터인포그래픽(KCU) 미리담기 삭제하기\" style=\"display: block;\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\" style=\"display: none;\"\u003e≡\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"coursedata filter\" role=\"listitem\" id=\"coursedataid-5469\" data-addtime=\"808164217\" data-coursecls=\"5469\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan class=\"fullclass\" id=\"fullsign-5469\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e5469 인체안의전쟁(KCU)\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 전학년 / 균여133 / 학점 : 3 / 담당교수 : 미배정 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e시간 미지정\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-remark\"\u003e 비고 : \u003cb\u003e온라인(원격수업),KCU\u003c/b\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-5469\"\u003e433\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-5469\"\u003e176\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-5469\"\u003e176\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied5469\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-5469\" class=\"classbtn reqbtn sorthide\" aria-label=\"5469 인체안의전쟁(KCU) 수강신청하기\" data-coursecls=\"5469\" data-curinum=\"KMO02133\" style=\"display: block;\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"5469\" data-curinum=\"KMO02133\" aria-label=\"5469 인체안의전쟁(KCU) 미리담기 삭제하기\" style=\"display: block;\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\" style=\"display: none;\"\u003e≡\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"coursedata filter\" role=\"listitem\" id=\"coursedataid-0233\" data-addtime=\"814100108\" data-coursecls=\"0233\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan class=\"fullclass\" id=\"fullsign-0233\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e0233 문화속디자인여행(KCU)\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 전학년 / 기문217 / 학점 : 3 / 담당교수 : 이규연 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e시간 미지정\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-remark\"\u003e 비고 : \u003cb\u003e온라인(원격수업)\u003c/b\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-0233\"\u003e598\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-0233\"\u003e108\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-0233\"\u003e108\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied0233\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-0233\" class=\"classbtn reqbtn sorthide\" aria-label=\"0233 문화속디자인여행(KCU) 수강신청하기\" data-coursecls=\"0233\" data-curinum=\"KMC02217\" style=\"display: block;\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"0233\" data-curinum=\"KMC02217\" aria-label=\"0233 문화속디자인여행(KCU) 미리담기 삭제하기\" style=\"display: block;\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\" style=\"display: none;\"\u003e≡\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"coursedata filter\" role=\"listitem\" id=\"coursedataid-5431\" data-addtime=\"814100118\" data-coursecls=\"5431\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan class=\"fullclass\" id=\"fullsign-5431\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e5431 영화제작에대해알고싶은모든것(KCU)\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 전학년 / 균문122 / 학점 : 3 / 담당교수 : 미배정 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e시간 미지정\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-remark\"\u003e 비고 : \u003cb\u003e온라인(원격수업),KCU\u003c/b\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-5431\"\u003e516\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-5431\"\u003e176\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-5431\"\u003e176\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied5431\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-5431\" class=\"classbtn reqbtn sorthide\" aria-label=\"5431 영화제작에대해알고싶은모든것(KCU) 수강신청하기\" data-coursecls=\"5431\" data-curinum=\"KML02122\" style=\"display: block;\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"5431\" data-curinum=\"KML02122\" aria-label=\"5431 영화제작에대해알고싶은모든것(KCU) 미리담기 삭제하기\" style=\"display: block;\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\" style=\"display: none;\"\u003e≡\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"coursedata filter\" role=\"listitem\" id=\"coursedataid-0084\" data-addtime=\"814104427\" data-coursecls=\"0084\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan class=\"fullclass\" id=\"fullsign-0084\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e0084 영어회화2\u003c/span\u003e \u003cspan\u003e (\u003cspan\u003eL3\u003c/span\u003e) \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 전학년 / 교필109 / 학점 : 1 / 담당교수 : 데본 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e \u003cspan\u003e월12:00~12:50(Y9230), 수12:00~12:50(Y9230)\u003c/span\u003e \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-0084\"\u003e48\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-0084\"\u003e11\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-0084\"\u003e11\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied0084\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-0084\" class=\"classbtn reqbtn sorthide\" aria-label=\"0084 영어회화2 수강신청하기\" data-coursecls=\"0084\" data-curinum=\"KMA02109\" style=\"display: block;\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"0084\" data-curinum=\"KMA02109\" aria-label=\"0084 영어회화2 미리담기 삭제하기\" style=\"display: block;\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\" style=\"display: none;\"\u003e≡\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"coursedata filter\" role=\"listitem\" id=\"coursedataid-0710\" data-addtime=\"814104302\" data-coursecls=\"0710\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan class=\"fullclass\" id=\"fullsign-0710\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e0710 알고리즘\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 3학년 / 컴공316 / 학점 : 3 / 담당교수 : 조민경 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e \u003cspan\u003e월09:00~10:50(Y5437), 목09:00~09:50(Y5437)\u003c/span\u003e \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-0710\"\u003e53\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-0710\"\u003e30\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-0710\"\u003e30\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-past\" data-grade=\"D+\"\u003e ※ 과거 이수성적 : 2023-2학기 : 알고리즘 D+ \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied0710\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-0710\" class=\"classbtn reqbtn sorthide\" aria-label=\"0710 알고리즘 수강신청하기\" data-coursecls=\"0710\" data-curinum=\"JEJ02316\" style=\"display: block;\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"0710\" data-curinum=\"JEJ02316\" aria-label=\"0710 알고리즘 미리담기 삭제하기\" style=\"display: block;\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\" style=\"display: none;\"\u003e≡\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"coursedata filter\" role=\"listitem\" id=\"coursedataid-0762\" data-addtime=\"814100722\" data-coursecls=\"0762\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan style=\"display:none\" class=\"fullclass\" id=\"fullsign-0762\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e0762 산업경영공학개론\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 1학년 / 산업213 / 학점 : 3 / 담당교수 : 한민탁 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e시간 미지정\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-remark\"\u003e 비고 : \u003cb\u003e아너칼리지및타전공수강,전공자수강X,전공이해기초교과,MJU자율수강제강좌,온라인강의\u003c/b\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-0762\"\u003e6\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-0762\"\u003e7\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-0762\"\u003e50\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied0762\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-0762\" class=\"classbtn reqbtn sorthide\" aria-label=\"0762 산업경영공학개론 수강신청하기\" data-coursecls=\"0762\" data-curinum=\"JEO01213\" style=\"display: block;\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"0762\" data-curinum=\"JEO01213\" aria-label=\"0762 산업경영공학개론 미리담기 삭제하기\" style=\"display: block;\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\" style=\"display: none;\"\u003e≡\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"coursedata filter\" role=\"listitem\" id=\"coursedataid-0238\" data-addtime=\"814102933\" data-coursecls=\"0238\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan class=\"fullclass\" id=\"fullsign-0238\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e0238 MJ사회봉사\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 전학년 / 기사167 / 학점 : 3 / 담당교수 : 유우연 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e \u003cspan\u003e월17:00~19:50(Y501)\u003c/span\u003e \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-remark\"\u003e 비고 : \u003cb\u003eN/P과목\u003c/b\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-0238\"\u003e56\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-0238\"\u003e17\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-0238\"\u003e17\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied0238\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-0238\" class=\"classbtn reqbtn sorthide\" aria-label=\"0238 MJ사회봉사 수강신청하기\" data-coursecls=\"0238\" data-curinum=\"KMD02167\" style=\"display: block;\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"0238\" data-curinum=\"KMD02167\" aria-label=\"0238 MJ사회봉사 미리담기 삭제하기\" style=\"display: block;\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\" style=\"display: none;\"\u003e≡\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003c/div\u003e","명지대학교-수강신청-빈자리-알림-크롬-확장프로그램-프로젝트-설계서#명지대학교 수강신청 빈자리 알림 크롬 확장프로그램 프로젝트 설계서":""},"title":"브라우저 기반 수강신청 알림 시스템 설계서"},"/02.inbox/%EB%B8%8C%EB%9D%BC%EC%9A%B0%EC%A0%80-%EA%B8%B0%EB%B0%98-%EC%88%98%EA%B0%95%EC%8B%A0%EC%B2%AD-%EC%95%8C%EB%A6%BC/":{"data":{"":"이 사이트를 기준으로 알림 확장 프로그램을 만들꺼야\n만약 현재 사이트 url 이 https://class.mju.ac.kr/main/bag 일때만 작동 사이트에서 [인원초과] 가 들어가 있는 강의에는 수강신청, 미리담기 삭제 옆에 알림 대기 버튼을 삽입 정해진 시간마다 백그라운드로 뒤에서 작동 fetch(\"https://class.mju.ac.kr/main/bag\", {\n“headers”: {\n“accept”: “text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,/;q=0.8,application/signed-exchange;v=b3;q=0.7”,\n“accept-language”: “ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7”,\n“cache-control”: “no-cache”,\n“content-type”: “application/x-www-form-urlencoded”,\n“pragma”: “no-cache”,\n“sec-ch-ua”: ““Not;A=Brand”;v=“99”, “Google Chrome”;v=“139”, “Chromium”;v=“139\"”,\n“sec-ch-ua-mobile”: “?0”,\n“sec-ch-ua-platform”: ““Windows””,\n“sec-fetch-dest”: “document”,\n“sec-fetch-mode”: “navigate”,\n“sec-fetch-site”: “same-origin”,\n“sec-fetch-user”: “?1”,\n“upgrade-insecure-requests”: “1”\n},\n“referrer”: “https://class.mju.ac.kr/main/class”,\n“body”: “_csrf=8e4b9cbe-fc28-4a14-82f1-3e34e72aba4b”,\n“method”: “POST”,\n“mode”: “cors”,\n“credentials”: “include”\n}); 요청해서 백단에서 해당 강의가 [인원초과] 문자가 사라지면 사용자에게 알림을 알리는 방식 백그라운드에서 일정 시간마다 요청할때는 초기에 요청했던 초반 html 에서 csrf 토큰을 가져와햐야해 백그라운드에서 일정시간마다 요청한다고 화면을 갱신하지는 마 해당 백그라운드의 의미는 [인원초과] 가 아닌지만 확인하면되 인원초과가 사라지면 기존에 사이트에서 해당강의가 [인원초과]라고 판단했던 것은 강제 refresh 아래는 초기 https://class.mju.ac.kr/main/bag 사이트의 요청 결과야\n\u003c!DOCTYPE html\u003e \u003chtml lang=\"ko\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1, user-scalable=no\"\u003e \u003cmeta id=\"_csrf\" name=\"_csrf\" content=\"60ce7efa-b9bf-49ee-b384-149961502d34\"/\u003e \u003cmeta id=\"_csrf_header\" name=\"_csrf_header\" content=\"X-CSRF-TOKEN\"/\u003e \u003c!-- mobile 주소표시줄 색깔 (다크테마는 적용되지 않음) --\u003e \u003cmeta name=\"theme-color\" content=\"#003f9b\"\u003e \u003cmeta name=\"apple-mobile-web-app-status-bar-style\" content=\"#003f9b\"\u003e \u003cmeta name=\"robots\" content=\"noindex,nofollow\"/\u003e \u003ctitle\u003e명지대학교 수강신청시스템\u003c/title\u003e \u003clink rel=\"stylesheet\" href=\"/css/style.css\"/\u003e \u003cscript src=\"/js/jquery-3.6.3.min.js\"\u003e\u003c/script\u003e \u003cscript\u003e $(document).ready(function(){ $(\".reqbtn\").click(function(){ const curiNum = $(this).data(\"curinum\"); const courseCls = $(this).data(\"coursecls\"); saveLecture(true, $(this)); }); $(\".delbtn\").click(function(){ const curiNum = $(this).data(\"curinum\"); const courseCls = $(this).data(\"coursecls\"); removeBeforeConfirm(false, $(this)); }); isBagSorting(false); //미리담기 내역이 1개 이하로 있을 경우 버튼이 있는 div영역을 감춘다. if($(\"div.coursedata\").length \u003c= 1){ $(\"div.sortbtn\").hide(); } }); \u003c/script\u003e \u003c/head\u003e \u003cbody\u003e \u003c!-- header --\u003e \u003cheader\u003e \u003cscript\u003e /* 개발자도구 방지 로직 */ /* !function() { function detectDevTool(allow) { if(isNaN(+allow)) allow = 100; var start = +new Date(); debugger; var end = +new Date(); if(isNaN(start) || isNaN(end) || end - start \u003e allow) { alert(MSG_ALERT_DEVTOOL); location.href = \"/logout\"; } } if(window.attachEvent) { if (document.readyState === \"complete\" || document.readyState === \"interactive\") { detectDevTool(); window.attachEvent('onresize', detectDevTool); window.attachEvent('onmousemove', detectDevTool); window.attachEvent('onfocus', detectDevTool); window.attachEvent('onblur', detectDevTool); } else { setTimeout(argument.callee, 0); } } else { window.addEventListener('load', detectDevTool); window.addEventListener('resize', detectDevTool); window.addEventListener('mousemove', detectDevTool); window.addEventListener('focus', detectDevTool); window.addEventListener('blur', detectDevTool); } }(); */ \u003c/script\u003e \u003cscript src=\"/js/jquery-3.6.3.min.js\"\u003e\u003c/script\u003e \u003cscript src=\"/js/netfunnel.js\"\u003e\u003c/script\u003e \u003cscript src=\"/js/languagecookie.js\"\u003e\u003c/script\u003e \u003cscript src=\"/js/customjs.js\"\u003e\u003c/script\u003e \u003cscript src=\"/js/Sortable.min.js\"\u003e\u003c/script\u003e \u003cscript src=\"/js/jquery-sortable.js\"\u003e\u003c/script\u003e \u003cscript src=\"/js/mbuster_meta.js\"\u003e\u003c/script\u003e \u003cscript src=\"/js/mbuster_api.js\"\u003e\u003c/script\u003e \u003cscript src=\"/js/msg_ko.js\"\u003e\u003c/script\u003e \u003cscript\u003e const CSRFHEADER = document.querySelector('meta[name=\"_csrf_header\"]').content; const CSRFTOKEN = document.querySelector('meta[name=\"_csrf\"]').content; const isSeason = JSON.parse('false'.toLowerCase()); const userIpAddress = '222.233.240.27'; const MAXSESSIONTIME = 1800; var timeoutSec = MAXSESSIONTIME; $(document).ready(function(){ //mbuster /* MBUSTER_API({ clientIp: userIpAddress, user_login_id: \"60222100\" }); */ let currentPagecode = \"bag\"; $(`nav.nav-gnb li[data-pagecode='${currentPagecode}']`).removeClass(\"gnb-link\").removeAttr(\"aria-label\"); $(`nav.nav-gnb li.gnb-link`).click(function(){ let pagecode = $(this).data(\"pagecode\"); moveClassPage(pagecode); }); setLanguageCookie(); for(const element of document.getElementsByClassName(\"entersearch\")) { element.addEventListener(\"keypress\", function(event){ if(event.key === 'Enter'){ validateInput(false); searchCourse(); } }); } setInterval(updateTimer, 1000); }); $(document).mouseup(function(e){ //알람 구역(알림버튼 + 알림 내용 팝업) 외의 부분을 클릭했을 때 if($(e.target).parents(\"div#optbtn\").length == 0){ $(\"#dropdownCheck\").prop(\"checked\", false); } }); \u003c/script\u003e \u003cform method=\"post\" name=\"mainfrm\" action=\"/\"\u003e\u003cinput type=\"hidden\" name=\"_csrf\" value=\"60ce7efa-b9bf-49ee-b384-149961502d34\"/\u003e \u003c/form\u003e \u003cform method=\"post\" name=\"reqfrm\" action=\"/\" target=\"_self\"\u003e\u003cinput type=\"hidden\" name=\"_csrf\" value=\"60ce7efa-b9bf-49ee-b384-149961502d34\"/\u003e \u003cinput type=\"hidden\" name=\"curiNum\"/\u003e \u003cinput type=\"hidden\" name=\"courseCls\"/\u003e \u003cinput type=\"hidden\" name=\"pageFrom\"/\u003e \u003c/form\u003e \u003c!-- \u003ca id=\"page-top\"\u003e\u003c/a\u003e --\u003e \u003cdiv id=\"sessiontimelayer\" role=\"none\"\u003e \u003cdiv\u003e \u003cspan id=\"remaintimetext\"\u003e로그인 남은 시간\u003c/span\u003e \u003cspan id=\"remaintime\"\u003e\u003c/span\u003e \u003c/div\u003e \u003cdiv\u003e \u003cbutton onclick=\"javascript:resetTimer(false);\" tabindex=\"-1\"\u003e연장\u003c/button\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv id=\"optbtnlayer\"\u003e \u003cdiv id=\"logoarea\" role=\"none\"\u003e \u003cimg src=\"/images/classlogo.png\" width=\"180\" alt=\"명지대학교 수강신청시스템\"/\u003e \u003c/div\u003e \u003cdiv id=\"optbtn\" role=\"menu\"\u003e \u003cinput id=\"dropdownCheck\" type=\"checkbox\"/\u003e \u003clabel for=\"dropdownCheck\"\u003e \u003cspan id=\"username\"\u003e신년기\u003c/span\u003e \u003cimg id=\"maruicon\" alt=\"opt\" src=\"/images/icon/icon_maru.png\"/\u003e \u003cspan class=\"caret\"\u003e\u003c/span\u003e \u003c/label\u003e \u003cul id=\"profile\"\u003e \u003cli class=\"stdinfo\"\u003e \u003cspan\u003e60222100\u003c/span\u003e \u003cspan id=\"stdname\"\u003e신년기\u003c/span\u003e \u003c/li\u003e \u003cli class=\"stdinfo\"\u003e \u003cspan\u003e현재학년\u003c/span\u003e : \u003cspan\u003e4\u003c/span\u003e \u003c/li\u003e \u003cli class=\"stdinfo\"\u003e \u003cspan\u003e수강신청학년\u003c/span\u003e : \u003cspan\u003e4\u003c/span\u003e \u003c/li\u003e \u003cli class=\"divider\"\u003e\u003c/li\u003e \u003cli role=\"menuitem\"\u003e \u003ca href=\"/main?lang=en\" class=\"profile_language\"\u003e Change Language : English \u003c/a\u003e \u003c/li\u003e \u003cli role=\"menuitem\"\u003e \u003ca href=\"/download/manual_ko.pdf\" class=\"profile_manual\" target=\"_blank\" download\u003e 수강신청 사용설명서 \u003c/a\u003e \u003c/li\u003e \u003cli role=\"menuitem\"\u003e \u003ca href=\"/logout\" class=\"profile_logout\"\u003e 로그아웃 \u003c/a\u003e \u003c/li\u003e \u003c/ul\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv id=\"statuslayer\"\u003e \u003cdiv id=\"statusshow\" class=\"mobileblock\" onclick=\"javascript:showCdtStatus(true);\"\u003e 수강신청 대상단계 및 신청학점 보이기 \u003c/div\u003e \u003ctable id=\"cdtstatus\" class=\"defaultTable pcblock\" onclick=\"javascript:showCdtStatus(false);\" aria-describedby=\"수강신청에서 보여지는 단계는 신청이 가능한 교과목을 의미하며 MSI와는 다릅니다.\"\u003e \u003cthead\u003e \u003ctr\u003e \u003cth class=\"tooltip topoutline\" colspan=\"3\"\u003e 수강신청 대상단계 \u003cspan class=\"qmark\"\u003e(?)\u003c/span\u003e \u003cspan class=\"tooltiptext\" role=\"tooltip\"\u003e 수강신청에서 보여지는 단계는 신청이 가능한 교과목을 의미하며 MSI와는 다릅니다. \u003c/span\u003e \u003c/th\u003e \u003c/tr\u003e \u003ctr\u003e \u003cth class=\"topdetail\"\u003e 영어 \u003c/th\u003e \u003cth class=\"topdetail\"\u003e 영어회화 \u003c/th\u003e \u003cth class=\"topdetail\"\u003e 미적분학 \u003c/th\u003e \u003c/tr\u003e \u003c/thead\u003e \u003ctbody\u003e \u003ctr\u003e \u003ctd\u003e영어3 (R4)\u003c/td\u003e \u003ctd\u003e영어회화2 (L3)\u003c/td\u003e \u003ctd\u003e미적분학2 (A3)\u003c/td\u003e \u003c/tr\u003e \u003c/tbody\u003e \u003cthead\u003e \u003ctr\u003e \u003cth class=\"topdetail\"\u003e 수강가능학점 \u003c/th\u003e \u003cth class=\"topdetail\"\u003e 총 수강신청 강좌 수 \u003c/th\u003e \u003cth class=\"topdetail\"\u003e 총 수강신청 학점 수 \u003c/th\u003e \u003c/tr\u003e \u003c/thead\u003e \u003ctbody\u003e \u003ctr\u003e \u003ctd\u003e18\u003c/td\u003e \u003ctd id=\"stat-sugcnt\"\u003e6\u003c/td\u003e \u003ctd id=\"stat-sugcdt\"\u003e15\u003c/td\u003e \u003c/tr\u003e \u003c/tbody\u003e \u003c/table\u003e \u003c/div\u003e \u003cnav id=\"class-gnb\" class=\"nav-gnb\"\u003e \u003cul\u003e \u003cli data-pagecode=\"bag\" class=\"gnb-link\" aria-label=\"미리담기내역\"\u003e 미리담기내역 \u003c/li\u003e \u003cli data-pagecode=\"class\" class=\"gnb-link\" aria-label=\"수강신청내역\"\u003e 수강신청내역 \u003c/li\u003e \u003cli data-pagecode=\"search\" class=\"gnb-link\" aria-label=\"교과목 검색\"\u003e 교과목 검색 \u003c/li\u003e \u003c/ul\u003e \u003c/nav\u003e \u003c/header\u003e \u003csection id=\"container\"\u003e \u003cdiv id=\"searchlayer\"\u003e \u003cdiv id=\"class-mine\"\u003e \u003cdiv id=\"curiblock\" class=\"categorybox\"\u003e \u003cdiv class=\"categorytop\"\u003e \u003cdiv class=\"smallinfo sortshow\"\u003e ※ 미리담기한 교과목을 끌어서 순서를 변경할 수 있습니다. \u003c/div\u003e \u003cdiv class=\"sortbtn\"\u003e \u003cbutton class=\"orderby sorthide\" id=\"sortable\" onclick=\"javascript:doSortable();\"\u003e미리담기 정렬 변경\u003c/button\u003e \u003cbutton class=\"orderby sortshow\" id=\"sortconfirm\" onclick=\"javascript:saveSort();\"\u003e정렬 저장\u003c/button\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv id=\"bagresult\" class=\"courselist\" data-req=\"Y\" data-bag=\"N\" data-reqdel=\"N\" data-bagdel=\"Y\" role=\"list\"\u003e \u003cdiv class=\"coursedata\" role=\"listitem\" id=\"coursedataid-0419\" data-addtime=\"808151054\" data-coursecls=\"0419\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan class=\"fullclass\" id=\"fullsign-0419\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e0419 빅데이터인포그래픽(KCU)\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 전학년 / 균컴114 / 학점 : 3 / 담당교수 : 이규연 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e시간 미지정\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-remark\"\u003e 비고 : \u003cb\u003e온라인(원격수업)\u003c/b\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-0419\"\u003e457\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-0419\"\u003e108\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-0419\"\u003e108\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied0419\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-0419\" class=\"classbtn reqbtn sorthide\" aria-label=\"0419 빅데이터인포그래픽(KCU) 수강신청하기\" data-coursecls=\"0419\" data-curinum=\"KMQ01114\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"0419\" data-curinum=\"KMQ01114\" aria-label=\"0419 빅데이터인포그래픽(KCU) 미리담기 삭제하기\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\"\u003e\u0026equiv;\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"coursedata\" role=\"listitem\" id=\"coursedataid-5469\" data-addtime=\"808164217\" data-coursecls=\"5469\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan class=\"fullclass\" id=\"fullsign-5469\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e5469 인체안의전쟁(KCU)\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 전학년 / 균여133 / 학점 : 3 / 담당교수 : 미배정 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e시간 미지정\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-remark\"\u003e 비고 : \u003cb\u003e온라인(원격수업),KCU\u003c/b\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-5469\"\u003e433\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-5469\"\u003e176\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-5469\"\u003e176\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied5469\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-5469\" class=\"classbtn reqbtn sorthide\" aria-label=\"5469 인체안의전쟁(KCU) 수강신청하기\" data-coursecls=\"5469\" data-curinum=\"KMO02133\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"5469\" data-curinum=\"KMO02133\" aria-label=\"5469 인체안의전쟁(KCU) 미리담기 삭제하기\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\"\u003e\u0026equiv;\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"coursedata\" role=\"listitem\" id=\"coursedataid-0233\" data-addtime=\"814100108\" data-coursecls=\"0233\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan class=\"fullclass\" id=\"fullsign-0233\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e0233 문화속디자인여행(KCU)\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 전학년 / 기문217 / 학점 : 3 / 담당교수 : 이규연 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e시간 미지정\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-remark\"\u003e 비고 : \u003cb\u003e온라인(원격수업)\u003c/b\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-0233\"\u003e598\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-0233\"\u003e108\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-0233\"\u003e108\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied0233\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-0233\" class=\"classbtn reqbtn sorthide\" aria-label=\"0233 문화속디자인여행(KCU) 수강신청하기\" data-coursecls=\"0233\" data-curinum=\"KMC02217\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"0233\" data-curinum=\"KMC02217\" aria-label=\"0233 문화속디자인여행(KCU) 미리담기 삭제하기\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\"\u003e\u0026equiv;\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"coursedata\" role=\"listitem\" id=\"coursedataid-5431\" data-addtime=\"814100118\" data-coursecls=\"5431\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan class=\"fullclass\" id=\"fullsign-5431\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e5431 영화제작에대해알고싶은모든것(KCU)\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 전학년 / 균문122 / 학점 : 3 / 담당교수 : 미배정 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e시간 미지정\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-remark\"\u003e 비고 : \u003cb\u003e온라인(원격수업),KCU\u003c/b\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-5431\"\u003e516\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-5431\"\u003e176\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-5431\"\u003e176\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied5431\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-5431\" class=\"classbtn reqbtn sorthide\" aria-label=\"5431 영화제작에대해알고싶은모든것(KCU) 수강신청하기\" data-coursecls=\"5431\" data-curinum=\"KML02122\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"5431\" data-curinum=\"KML02122\" aria-label=\"5431 영화제작에대해알고싶은모든것(KCU) 미리담기 삭제하기\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\"\u003e\u0026equiv;\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"coursedata\" role=\"listitem\" id=\"coursedataid-0084\" data-addtime=\"814104427\" data-coursecls=\"0084\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan class=\"fullclass\" id=\"fullsign-0084\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e0084 영어회화2\u003c/span\u003e \u003cspan\u003e (\u003cspan\u003eL3\u003c/span\u003e) \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 전학년 / 교필109 / 학점 : 1 / 담당교수 : 데본 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e \u003cspan\u003e월12:00~12:50(Y9230), 수12:00~12:50(Y9230)\u003c/span\u003e \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-0084\"\u003e48\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-0084\"\u003e11\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-0084\"\u003e11\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied0084\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-0084\" class=\"classbtn reqbtn sorthide\" aria-label=\"0084 영어회화2 수강신청하기\" data-coursecls=\"0084\" data-curinum=\"KMA02109\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"0084\" data-curinum=\"KMA02109\" aria-label=\"0084 영어회화2 미리담기 삭제하기\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\"\u003e\u0026equiv;\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"coursedata\" role=\"listitem\" id=\"coursedataid-0710\" data-addtime=\"814104302\" data-coursecls=\"0710\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan class=\"fullclass\" id=\"fullsign-0710\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e0710 알고리즘\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 3학년 / 컴공316 / 학점 : 3 / 담당교수 : 조민경 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e \u003cspan\u003e월09:00~10:50(Y5437), 목09:00~09:50(Y5437)\u003c/span\u003e \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-0710\"\u003e53\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-0710\"\u003e30\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-0710\"\u003e30\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-past\" data-grade=\"D+\"\u003e ※ 과거 이수성적 : 2023-2학기 : 알고리즘 D+ \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied0710\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-0710\" class=\"classbtn reqbtn sorthide\" aria-label=\"0710 알고리즘 수강신청하기\" data-coursecls=\"0710\" data-curinum=\"JEJ02316\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"0710\" data-curinum=\"JEJ02316\" aria-label=\"0710 알고리즘 미리담기 삭제하기\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\"\u003e\u0026equiv;\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"coursedata\" role=\"listitem\" id=\"coursedataid-0762\" data-addtime=\"814100722\" data-coursecls=\"0762\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan style=\"display:none\" class=\"fullclass\" id=\"fullsign-0762\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e0762 산업경영공학개론\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 1학년 / 산업213 / 학점 : 3 / 담당교수 : 한민탁 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e시간 미지정\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-remark\"\u003e 비고 : \u003cb\u003e아너칼리지및타전공수강,전공자수강X,전공이해기초교과,MJU자율수강제강좌,온라인강의\u003c/b\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-0762\"\u003e6\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-0762\"\u003e7\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-0762\"\u003e50\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied0762\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-0762\" class=\"classbtn reqbtn sorthide\" aria-label=\"0762 산업경영공학개론 수강신청하기\" data-coursecls=\"0762\" data-curinum=\"JEO01213\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"0762\" data-curinum=\"JEO01213\" aria-label=\"0762 산업경영공학개론 미리담기 삭제하기\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\"\u003e\u0026equiv;\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"coursedata\" role=\"listitem\" id=\"coursedataid-0238\" data-addtime=\"814102933\" data-coursecls=\"0238\"\u003e \u003cdiv class=\"infoarea\"\u003e \u003cdiv class=\"course-title\" style=\"font-weight: bold;\"\u003e \u003cspan class=\"fullclass\" id=\"fullsign-0238\"\u003e [ 인원초과 ] \u003c/span\u003e \u003cspan\u003e0238 MJ사회봉사\u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-basicinfo\"\u003e \u003cspan\u003e 전학년 / 기사167 / 학점 : 3 / 담당교수 : 유우연 \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-schedule\"\u003e \u003cspan\u003e \u003cspan\u003e월17:00~19:50(Y501)\u003c/span\u003e \u003c/span\u003e \u003c/div\u003e \u003cdiv class=\"course-remark\"\u003e 비고 : \u003cb\u003eN/P과목\u003c/b\u003e \u003c/div\u003e \u003cdiv class=\"course-count\"\u003e 담은인원 : \u003cspan id=\"bagcnt-0238\"\u003e56\u003c/span\u003e / 수강인원 : \u003cspan id=\"listencnt-0238\"\u003e17\u003c/span\u003e / 제한인원 : \u003cspan id=\"takecnt-0238\"\u003e17\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv class=\"btnarea\"\u003e \u003cspan class=\"applied\" style=\"display:none\" id=\"applied0238\"\u003e 신청완료 \u003c/span\u003e \u003cbutton id=\"req-0238\" class=\"classbtn reqbtn sorthide\" aria-label=\"0238 MJ사회봉사 수강신청하기\" data-coursecls=\"0238\" data-curinum=\"KMD02167\"\u003e 수강신청 \u003c/button\u003e \u003cbutton class=\"classbtn delbtn sorthide\" data-coursecls=\"0238\" data-curinum=\"KMD02167\" aria-label=\"0238 MJ사회봉사 미리담기 삭제하기\"\u003e 미리담기 삭제 \u003c/button\u003e \u003cspan class=\"sortshow\"\u003e\u0026equiv;\u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003c/div\u003e \u003c/div\u003e \u003c/div\u003e \u003c/div\u003e \u003c/section\u003e \u003c/body\u003e \u003c/html\u003e"},"title":"브라우저 기반 수강신청 알림"},"/02.inbox/%EB%B9%8C%EB%93%9C%EC%BB%B4%ED%8C%8C%EC%9D%BC-%EA%B3%BC%EC%A0%95/":{"data":{"":"","과정별-순서#과정별 순서":"","링커의-역할#\u003cstrong\u003e링커의 역할\u003c/strong\u003e":"링커의 역할은 크게 심볼 해석과 재배치로 나눌 수 있다.","링킹#링킹":"링킹(Linking) 과정은 링커(Linker)를 통해 오브젝트 파일(*.o)들을 묶어 실행 파일로 만드는 과정이다.\n이 과정에서 오브젝트 파일들과 프로그램에서 사용하는 라이브러리 파일들을 링크하여 하나의 실행 파일을 만든다.\n이때 라이브러리를 링크하는 방법에 따라 **정적 링킹(Static Linking)**과 **동적 링킹(Dynamic Linking)**으로 나눌 수 있다. 링킹 방식의 차이는 앞서 설명했던 라이브러리 포스트를 참고하자.\n서론 개발하다 보면 라이브러리를 사용할 일이 많다. 라이브러리를 사용해보면 정확한 개념은 몰라도 프로그램을 개발할 때 필요한 기능을 가져다 쓰는 도구라는 것은 어렴풋이 이해할 수 있다","심볼-해석symbol-resolution#\u003cstrong\u003e심볼 해석(Symbol Resolution)\u003c/strong\u003e":"심볼 해석은 각 오브젝트 파일에 있는 심볼 참조를 어떤 심볼 정의에 연관시킬지 결정하는 과정이다. 여러 개의 오브젝트 파일에 같은 이름의 함수 또는 변수가 정의되어 있을 때 어떤 파일의 어떤 함수를 사용할지 결정한다.","어셈블리#어셈블리":"gcc -c program.s -o program.o","요약#요약":"%20image%2020240104121023.png)","재배치relocation#\u003cstrong\u003e재배치(Relocation)\u003c/strong\u003e":"재배치는 오브젝트 파일에 있는 데이터의 주소나 코드의 메모리 참조 주소를 알맞게 배치하는 과정이다.\n링커가 컴파일러가 생성한 오브젝트 파일을 모아서 하나의 실행 파일을 만들 때, 각 오브젝트 파일에 있는 데이터의 주소나 코드의 메모리 참조 주소가 링커에 의해 합쳐진 실행 파일에서의 주소와 다르게 때문에 그것을 알맞게 수정해줘야 한다.\n**이를 위해 오브젝트 파일 안에 재배치 정보 섹션(**Relocation Information Section)이 존재한다. 링킹 과정에서 같은 세션끼리 합쳐진 후 재배치가 일어난다.\n위 그림을 통해 알 수 있듯이 오브젝트 파일 형식은 링킹 과정에서 링커가 여러 개의 오브젝트 파일들을 하나의 실행 파일로 묶을 때 필요한 정보를 효율적으로 파악할 수 있는 구조이다.\n링킹을 하기 전 오브젝트 파일을 **재배치 가능한 오브젝트 파일(Relocatable Object File)**이라 부르고 링킹을 통해 만들어지는 오브젝트 파일을 **실행 가능한 오브젝트 파일(Executable Object File)**이라 부른다.\nc++ -\u003e c 변환 번역기 컴파일러(?)를 cfront 라 한다 GNU g++ gcc 과 같은 컴파일러를 프리웨어라 한다 어떤라이ㅡㅂ러리들은 그것을 사용하려면 컴파일 명령행에 명시적으로 요구된 명령을 입력해야한다 ( CC test.c -lm) (-lm 수학라이브러리 링크 명령)\n(g++ test.cpp. -lg++)\n윈도우 커맨드라인 컴파일러는 Cygwin 과 MinGW 이다","전처리기#전처리기":"gcc -E program.c -o program.i 옵션 : -E Preprocess only; do not compile, assemble or link.\n헤더 파일 삽입 : #include 지시문을 만나면 해당하는 헤더 파일을 찾아 헤더 파일에 있는 모든 내용을 복사해서 소스 코드에 삽입한다. 즉, 헤더 파일은 컴파일에 사용되지 않고 소스 코드 파일 내에 전부 복사된다. 헤더 파일에 선언된 함수 원형은 후에 링킹 과정을 통해 실제로 함수가 정의되어 있는 오브젝트 파일(컴파일된 소스 코드 파일)과 결합한다.\n매크로 치환 및 적용 : #define 지시문에 정의된 매크로를 저장하고 같은 문자열을 만나면 #define 된 내용으로 치환한다. 간단하게 말해 매크로 이름을 찾아서 정의한 값으로 전부 바꿔준다.\n컴파일러 기능 지정 : #pragma once 한번만 컴파일 #pragma warning(disable:4996) scanf 경고 끄기","컴파일#컴파일":"gcc -S hello.c gcc -S hello.i `-S Compile only; do not assemble or link.``"},"title":"빌드(컴파일) 과정"},"/02.inbox/%EC%84%9C%EB%B2%84-db-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/":{"data":{"":"미리 data 를 담아놓은 db 입니다 환경구성이 잘 안되시는 분은 여기서 이것을 사용하시면 됩니다 학기 끝날 때 까지 서버를 열어 두겠습니다 %20image%2020241113211582.png) 비밀번호는 1111 단 data 뷰어 용으로만 사용해 주세요(create문 truncate 등등 data 를 손보는 작업은 하지 말아 주세요)"},"title":"서버 db 사용하기"},"/02.inbox/%EC%84%A0%ED%98%95%EB%8C%80%EC%88%98%ED%95%99-worksheet11-6%EB%B2%88/":{"data":{"":"$R_2 의\\ 기저는 { u_1 = (1,-3), u_2 = (2,2)}$ $이를\\ 통해\\ 직교기저 {v_1, v_2} 를\\ 구하여라\\ \u0026\\ 정규직교기저 {q_1, q_2} 를 구하라$\n$문제\\ 1\\ 그램\\ 슈미트\\ 직교화\\ 과정을\\ 통해\\ 직교기저가\\ 아닌\\ 기저에서\\ 직교기저를\\ 구한다$ $u_1 = v_1 = (1,-3)$ $u_2 = (2,2)$ $v_2 = u_2 - \\frac{u_2 \\cdot v_1}{|v_1|^2} v_1$ $v_2 = (2,2) + \\frac{4}{10}(1,-3)$ $v_2 = (\\frac{12}{5}, \\frac{4}{5})$ $즉\\ 직교기저\\ {v_1,v_2} = {(1,-3),(\\frac{12}{5},\\frac{4}{5})}$\n$문제\\ 2\\ 직교\\ 기저에\\ 정규화를\\ 진행한다$ $각각의\\ 원소의\\ 크기가\\ 1이어야\\ 한다$ $(q_1,q_2) = {(k_1,-3k_1),(\\frac{12}{5}k_2,\\frac{4}{5}k_2)}$ $|q_1| = \\sqrt{{k_1}^2 + 9k_1^2} = 1$ $|q_2| = \\sqrt{\\frac{144}{25}{{k_2}^2 + \\frac{16}{25}k_2^2}} = 1$ $k_1 = \\frac{1}{\\sqrt{10}}$ $k_2 = \\frac{5}{4\\sqrt{10}}$ $즉\\ 정규직교기저\\ {q_1,q_2}= {(\\frac{1}{\\sqrt{10}},\\frac{-3}{\\sqrt{10}}),(\\frac{3}{\\sqrt{10}},\\frac{1}{\\sqrt{10}})}\\ 이다$","풀이2#풀이2":"실수 벡터 2개를 기저로 하는 벡터 공간은 이차원 벡터 공간이며 {(1,0), (0,1)}이 좌표평면이라고 불리우는 2차원 벡터공간 표준 기저이다 표준 직교기저 조건은 정규 직교기저를 포함하고 정규 정규직교는 직교기저 조건을 포함하므로 직교기저 = {(1,0), (0,1)} 정규직교기저 = {(1,0), (0,1)}"},"title":"선형대수학 worksheet11 6번"},"/02.inbox/%EC%88%9C%EC%88%98-ui-%EB%94%94%EC%9E%90%EC%9D%B8-%EC%9A%A9%EC%96%B4/":{"data":{"":"","-디자이너를-위한-팁#💡 디자이너를 위한 팁":"“Less is More” — 불필요한 장식은 과감히 제거하세요. 일관성 \u003e 창의성 — 사용자는 예측 가능한 디자인을 좋아합니다. 컬러는 감정을, 타이포는 신뢰를, 여백은 고급스러움을 전달합니다. 이 리스트는 포트폴리오 준비, 디자인 리뷰, 협업 커뮤니케이션 등에 유용하게 쓰실 수 있어요.\n더 깊이 알고 싶은 용어나 예시가 있으면 언제든지 물어보세요! 😊✨","-순수-디자인-관련-용어-30가지-visualui-design-중심#🖌️ 순수 디자인 관련 용어 30가지 (Visual/UI Design 중심)":"","1-스케어모피즘-skeuomorphism#1. \u003cstrong\u003e스케어모피즘 (Skeuomorphism)\u003c/strong\u003e":"실제 물체의 질감, 그림자, 입체감을 디지털에 그대로 구현한 디자인 스타일.","10-비주얼-계층-visual-hierarchy#10. \u003cstrong\u003e비주얼 계층 (Visual Hierarchy)\u003c/strong\u003e":"색상, 크기, 위치, 굵기 등을 통해 어떤 요소가 더 중요한지 시각적으로 표현.","11-화이트-스페이스-white-space--negative-space#11. \u003cstrong\u003e화이트 스페이스 (White Space / Negative Space)\u003c/strong\u003e":"콘텐츠 사이의 “빈 공간”. 숨 쉴 공간을 주어 가독성과 고급스러움을 높임.","12-그리드-시스템-grid-system#12. \u003cstrong\u003e그리드 시스템 (Grid System)\u003c/strong\u003e":"요소들을 정렬하고 일관성 있게 배치하기 위한 수직/수평 레이아웃 구조.","13-정렬-alignment#13. \u003cstrong\u003e정렬 (Alignment)\u003c/strong\u003e":"요소들이 축을 기준으로 정돈되어 배치된 상태. 시각적 안정감을 줌.","14-근접성-proximity#14. \u003cstrong\u003e근접성 (Proximity)\u003c/strong\u003e":"관련된 요소끼리 가깝게 배치해 그룹으로 인식되도록 유도하는 원칙.","15-대비-contrast#15. \u003cstrong\u003e대비 (Contrast)\u003c/strong\u003e":"색상, 크기, 형태 등의 차이를 통해 특정 요소를 강조하거나 구분하는 기법.","16-반복-repetition#16. \u003cstrong\u003e반복 (Repetition)\u003c/strong\u003e":"디자인 내에서 같은 색상, 폰트, 아이콘 스타일 등을 반복해 일관성과 통일감을 줌.","17-균형-balance#17. \u003cstrong\u003e균형 (Balance)\u003c/strong\u003e":"시각적 무게가 좌우 또는 상하로 고르게 분포된 상태. 대칭 또는 비대칭 균형이 있음.","18-아이콘-icon#18. \u003cstrong\u003e아이콘 (Icon)\u003c/strong\u003e":"기능이나 의미를 직관적으로 전달하기 위한 상징적 그래픽 요소.","19-라인아이콘-vs-솔리드아이콘-line-icon-vs-solid-icon#19. \u003cstrong\u003e라인아이콘 vs 솔리드아이콘 (Line Icon vs Solid Icon)\u003c/strong\u003e":"테두리로만 구성된 아이콘 vs 면으로 채워진 아이콘. 스타일에 따라 선택.","2-플랫-디자인-flat-design#2. \u003cstrong\u003e플랫 디자인 (Flat Design)\u003c/strong\u003e":"그림자, 텍스처, 그라데이션을 배제하고 단순한 색상과 형태로 구성된 디자인.","20-일러스트레이션-illustration#20. \u003cstrong\u003e일러스트레이션 (Illustration)\u003c/strong\u003e":"캐릭터, 장면, 추상적 그래픽 등을 통해 감성이나 브랜드를 표현하는 삽화.","21-패턴-pattern#21. \u003cstrong\u003e패턴 (Pattern)\u003c/strong\u003e":"반복되는 그래픽 요소 (예: 배경용 기하학적 패턴, 텍스처).","22-텍스처-texture#22. \u003cstrong\u003e텍스처 (Texture)\u003c/strong\u003e":"표면의 질감을 표현 (예: 나무결, 천, 금속). 스케어모피즘에서 자주 사용됨.","23-그라데이션-gradient#23. \u003cstrong\u003e그라데이션 (Gradient)\u003c/strong\u003e":"색상이 부드럽게 전환되는 효과. 배경이나 버튼에 감성과 깊이를 더함.","24-섀도우-drop-shadow#24. \u003cstrong\u003e섀도우 (Drop Shadow)\u003c/strong\u003e":"요소에 입체감을 주기 위해 추가하는 그림자. 레이어링 느낌을 줌.","25-브랜딩-디자인-branding-design#25. \u003cstrong\u003e브랜딩 디자인 (Branding Design)\u003c/strong\u003e":"로고, 컬러, 폰트, 아이콘 등을 통해 브랜드의 시각적 정체성을 구축.","26-스타일-가이드-style-guide#26. \u003cstrong\u003e스타일 가이드 (Style Guide)\u003c/strong\u003e":"디자인 요소(색상, 폰트, 버튼, 아이콘 등)의 사용 규칙을 문서화한 것.","27-디자인-토큰-design-token#27. \u003cstrong\u003e디자인 토큰 (Design Token)\u003c/strong\u003e":"색상, 여백, 라운딩, 그림자 등 디자인 속성값을 코드와 공유할 수 있게 추상화한 변수.","28-컴포넌트-component#28. \u003cstrong\u003e컴포넌트 (Component)\u003c/strong\u003e":"재사용 가능한 UI 요소 (버튼, 카드, 헤더 등). 디자인 시스템의 기본 단위.","29-비주얼-아이덴티티-visual-identity#29. \u003cstrong\u003e비주얼 아이덴티티 (Visual Identity)\u003c/strong\u003e":"브랜드를 시각적으로 표현하는 모든 요소 — 로고, 컬러, 이미지 스타일, 타이포그래피 등.","3-세미-플랫-디자인-semi-flat-design#3. \u003cstrong\u003e세미 플랫 디자인 (Semi-Flat Design)\u003c/strong\u003e":"플랫 디자인에 약간의 그림자나 입체감을 더해 깊이감을 준 디자인.","30-모션-디자인-motion-design#30. \u003cstrong\u003e모션 디자인 (Motion Design)\u003c/strong\u003e":"트랜지션, 로딩 애니메이션, 마이크로 인터랙션 등 시각적 움직임을 디자인하는 것.\n(※ 엄밀히는 인터랙션과 연결되지만, 순수 “시각적 애니메이션 디자인”으로 한정해 포함)","4-머티리얼-디자인-material-design#4. \u003cstrong\u003e머티리얼 디자인 (Material Design)\u003c/strong\u003e":"구글의 디자인 언어. “종이처럼 쌓인 레이어” 컨셉으로 그림자와 모션을 활용.","5-네오모피즘-neumorphism#5. \u003cstrong\u003e네오모피즘 (Neumorphism)\u003c/strong\u003e":"소프트한 입체감과 음영을 사용해 “눌린 버튼” 또는 “튀어나온 요소”처럼 보이게 하는 디자인 트렌드.","6-글라스모피즘-glassmorphism#6. \u003cstrong\u003e글라스모피즘 (Glassmorphism)\u003c/strong\u003e":"유리처럼 반투명하고 흐릿한 배경(blur) + 경계선 + 레이어 효과를 사용하는 디자인 스타일 (예: macOS Big Sur, Windows 11).","7-컬러-팔레트-color-palette#7. \u003cstrong\u003e컬러 팔레트 (Color Palette)\u003c/strong\u003e":"디자인에서 사용할 주조색, 보조색, 강조색 등을 체계적으로 정리한 색상 집합.","8-타이포그래피-typography#8. \u003cstrong\u003e타이포그래피 (Typography)\u003c/strong\u003e":"글자의 스타일, 크기, 간격, 정렬 등을 조화롭게 배치하여 가독성과 미학을 높이는 기술.","9-폰트-페어링-font-pairing#9. \u003cstrong\u003e폰트 페어링 (Font Pairing)\u003c/strong\u003e":"서로 다른 두 가지 이상의 폰트를 조합해 시각적 계층과 조화를 만드는 기법."},"title":"순수 UI 디자인 용어"},"/02.inbox/%EC%8B%A4%EC%88%98-%ED%91%9C%ED%98%84%EB%B0%A9%EB%B2%95-%EA%B3%A0%EC%A0%95%EC%86%8C%EC%88%98%EC%A0%90%EA%B3%BC-%EB%B6%80%EB%8F%99%EC%86%8C%EC%88%98%EC%A0%90/":{"data":{"":"","결론-단정밀도-기준#결론 (단정밀도 기준)":"만약 $E = 255$ 이고 $M\\neq0$ 이면 $N =\\text{NaN}$ (Not a Number). 만약 $E = 255$ 이고 $M = 0$ 이면 $N=(-1)^S \\times \\infty$ 만약 $0","결론-반정밀도-기준#결론 (반정밀도 기준)":"$E = 31$ 이고 $M \\neq 0$ 이면 $N = \\text{NaN}$ $E = 31$ 이고 $M = 0$ 이면 $N = (-1)^S \\times \\infty$ $0 \u003c E \u003c 31$ 이면 $N = (-1)^S \\times 2^{E - 15} \\times (1.M)$ $E = 0$ 이고 $M \\neq 0$ 이면 $N = (-1)^S \\times 2^{-14} \\times (0.M)$ $E = 0$ 이고 $M = 0$ - $N = (-1)^S \\times 0$.","결론-배정밀도-기준#결론 (배정밀도 기준)":"$E = 2047$ 이고 $M \\neq 0$ 이면 $N = \\text{NaN}$ $E = 2047$ 이고 $M = 0$ 이면 $N = (-1)^S \\times \\infty$ $0 \u003c E \u003c 2047$ 이면 $N = (-1)^S \\times 2^{E - 1023} \\times (1.M)$ $E = 0$ 이고 $M \\neq 0$ 이면 $N = (-1)^S \\times 2^{-1022} \\times (0.M)$ $E = 0$ 이고 $M = 0$ 이면 $N = (-1)^S \\times 0$","부동-소수점-방식#부동 소수점 방식":"$N = (-1)^S * 2^{E-127} * 1.M$ 부호 1 비트 S 지수 8비트 : 범위(range)를 나타낸다 E 가수 23 비트 : 정밀도(precision)를 나타낸다 M 바이어스 127 : 정규화된 표현 : 가수 23 M 에서 1.M 형태의 정규화된 표현을 사용한다 이를 통해 더 큰 범위를 표현할 수 있도록 한다\n정규화된 표현을 모든 지수부 모든 가수부에서 그대로 사용한다면 부동소수점방식에서 0을 표시할 수 없다\n지수부를 2의 보수로 하지 않고 바이어스를 사용해서 음수를 표현한 이유 : 지수부가 0 이면 0.M 비정규표현을 사용할 때 지수부와 가수부가 모두 0일때 0이 계산된다 0임을 확인하는 하드웨어 복잡성 증대를 막기 위해 이렇게 사용한다","소수의-10진수-2진수-계산-방법#소수의 10진수 2진수 계산 방법":"예시 1: 10진수 1.625 → 2진수 1.101\n정수 부분(1):\n1 ÷ 2 = 0 … 나머지 1 따라서 정수 부분은 1입니다. 소수 부분(0.625):\n0.625 × 2 = 1.25 → 정수 부분 1, 소수 부분 0.25 0.25 × 2 = 0.5 → 정수 부분 0, 소수 부분 0.5 0.5 × 2 = 1.0 → 정수 부분 1, 소수 부분 0 (계산 종료) 따라서 소수 부분은 101입니다. 결과:\n정수 부분(1) + 소수 부분(.101) = 1.101 예시 2: 10진수 3.375 → 2진수 11.011\n정수 부분(3): 3 ÷ 2 = 1 … 나머지 1 1 ÷ 2 = 0 … 나머지 1 따라서 정수 부분은 11입니다. 소수 부분(0.375): 0.375 × 2 = 0.75 → 정수 부분 0, 소수 부분 0.75 0.75 × 2 = 1.5 → 정수 부분 1, 소수 부분 0.5 0.5 × 2 = 1.0 → 정수 부분 1, 소수 부분 0 (계산 종료) 따라서 소수 부분은 011입니다. 결과: 정수 부분(11) + 소수 부분(.011) = 11.011 예시 3: 10진수 0.875 → 2진수 0.111\n정수 부분(0): 정수 부분이 없으므로 0입니다. 소수 부분(0.875): 0.875 × 2 = 1.75 → 정수 부분 1, 소수 부분 0.75 0.75 × 2 = 1.5 → 정수 부분 1, 소수 부분 0.5 0.5 × 2 = 1.0 → 정수 부분 1, 소수 부분 0 (계산 종료) 따라서 소수 부분은 111입니다. 결과: 정수 부분(0) + 소수 부분(.111) = 0.111 예시 4: 10진수 5.6 → 2진수 101.100110… (반복 소수)\n정수 부분(5): 5 ÷ 2 = 2 … 나머지 1 2 ÷ 2 = 1 … 나머지 0 1 ÷ 2 = 0 … 나머지 1 따라서 정수 부분은 101입니다. 소수 부분(0.6): 0.6 × 2 = 1.2 → 정수 부분 1, 소수 부분 0.2 0.2 × 2 = 0.4 → 정수 부분 0, 소수 부분 0.4 0.4 × 2 = 0.8 → 정수 부분 0, 소수 부분 0.8 0.8 × 2 = 1.6 → 정수 부분 1, 소수 부분 0.6 (반복 시작) 따라서 소수 부분은 100110… (0.6이 반복되므로 순환 소수). 결과: 정수 부분(101) + 소수 부분(.100110…) = 101.100110… 고정 소수점 방식 vs 부동 소수점 방식 두개의 논의 또한 실제 어떻게 컴퓨터에0,75 = 0.11(2진수) =\u003e 사람이 표현하는 방식 12.125 = 1100.001(2진수) =\u003e 사람이 표현하는 방식 실제 컴퓨터에 저장할 떄는 . 소수점을 넣을 수 없으므로 고정적으로 소수점 (.) 을 지정해서 저장하는 방식이 사용된다 예컨테 위의 0.75 를 8bit 자료형에서 앞자리 4은 정수 뒷자리 4 는 소수점 아래라고 정하면 실제 컴퓨터에 32 bit 가 저장될 때는 (00001100) 이렇게 저장된다 부호비트가 맨 앞의 bit 를 할당 3자리 정수 4자리 소수점 아래 소수 라고 전제하여도 동일한 bit 로 저장됨\n즉 고정적으로 소수점을 정한다고 해서 고정 소수점 방식이라고 한다\n하지만 위의 방식은 0.1 같은 수는 어림잡아 표현할 수 밖에 없다 0.3 =\u003e 0.01001100110011……(0011)\n즉 위의 방식은 2가지 문제를 가지고 있다\n정확한 수를 표현하지 못함 소수점 아래에 bit를 많이 배정하면 작은수 밖에 표현하지 못하고 정수부에 bit 를 많이 배정하면 작은 수밖에 표현하지 못한다 여기서 우리는 2번 째 문제를 해결해 보자"},"title":"실수 표현방법 고정소수점과 부동소수점"},"/02.inbox/%EC%8B%B1%EA%B8%80%ED%86%A4-%EB%82%B4%EB%B6%80-%EC%9D%98%EC%A1%B4%EA%B4%80%EA%B3%84%EB%A1%9C-%ED%94%84%EB%A1%9C%ED%86%A0%ED%83%80%EC%9E%85-%EC%8A%A4%EC%BD%94%ED%94%84%EC%9D%98-bean-%EC%9D%84-%EA%B0%80%EC%A7%88%EB%95%8C/":{"data":{"":"@Scope(\"singleton\") static class ClientBean { @Autowired private ObjectProvider\u003cPrototypeBean\u003e prototypeBeanProvider; // 객체를 필요한 시점에 찾아서 주입받는 경우에 사용 // private final PrototypeBean prototypeBean; // @Autowired // public ClientBean(PrototypeBean prototypeBean){ // 생성시점에 주입 // this.prototypeBean = prototypeBean; // } public int logic(){ PrototypeBean prototypeBean = prototypeBeanProvider.getObject(); //ApplicationContext ac = //new AnnotationConfigApplicationContext(); //ac.getBean(PrototypeBean.class); } } } @Scope(\"prototype\") static class PrototypeBean { private int count = 0; public int addCount(){ return ++count; } public int getCount(){ return count; } } Prototype 타입의 객체는 지속적으로 객체를 새로 생성하고자 하는 목적으로 만들었으나 @Autowired 속성, ClientBean 의 singleton scope 속성으로 인해 bean 의존관계 단계에서 미리 생성되어 버림 그리고 다시 생성되지 않음\nObjectFatory 부모 ObjectProvider 자식 객체를 생성하는 시기를 조절 가능 DL dependency Lookup 스프링 의존적'\n@Test void SingletonClientUsePrototype(){ AnnotationConfigApplicationContext ac = new AnnotationConfigApplicationContext(ClientBean.class, PrototypeBean.class); ClientBean clientBean1 = ac.getBean(ClientBean.class); int count1 = clientBean1.logic(); ClientBean clientBean2 = ac.getBean(ClientBean.class); int count2 = clientBean2.logic(); assertThat(count2).isEqualTo(1); } @Scope(\"singleton\") static class ClientBean { // private final PrototypeBean prototypeBean; // @Autowired // 컨테이너를 새로 만들어서 prototypeBean을 주입받는 경우 // private ApplicationContext ac; // @Autowired // public ClientBean(PrototypeBean prototypeBean){ // 생성시점에 주입 // this.prototypeBean = prototypeBean; // } @Autowired private Provider\u003cPrototypeBean\u003e prototypeBeanProvider; // 객체를 필요한 시점에 찾아서 주입받는 경우에 사용 public int logic(){ PrototypeBean prototypeBean = prototypeBeanProvider.get(); prototypeBean.addCount(); return prototypeBean.getCount(); } @PostConstruct public void init(){ System.out.println(\"SingletonTest.SingletonBean.init() + \" + this); } @PreDestroy public void destroy(){ System.out.println(\"SingletonTest.SingletonBean.destroy() + \" + this); } } @Scope(\"prototype\") static class PrototypeBean { private int count = 0; public int addCount(){ return ++count; } public int getCount(){ return count; } @PostConstruct public void init(){ System.out.println(\"SingletonTest.PrototypeBean.init() + \" + this); } @PreDestroy public void destroy(){ System.out.println(\"SingletonTest.PrototypeBean.destory() + \" + this); } }"},"title":"싱글톤 내부 의존관계로 프로토타입 스코프의 bean 을 가질때"},"/02.inbox/%EC%8B%B1%EA%B8%80%ED%86%A4-%ED%8C%A8%ED%84%B4%EC%9D%98-%EB%AC%B8%EC%A0%9C/":{"data":{"":"클래스의 생성자를 통해 만들어지는 인스턴스의 개수를 1개로 고정시키는 디자인 패턴이다 하지만 이는 몇가지 문제를 만들어낸다\n의존성 문제 OCP 원칙 위반 테스트 어려움 내부 속성 변경 어려움 자식 클래스 생성 어려움","ocp-원칙-위반#OCP 원칙 위반":"만약 다른 싱글톤 클래스로 교체하려면 클라이언트 코드를 직접 수정해야 합니다. 이는 개방-폐쇄 원칙(Open/Closed Principle, OCP)을 위반하는 것이며, 시스템 확장이 어려워집니다.\npublic class Client { private Singleton singleton = SingletonImpl.getInstance(); // 다른 싱글톤 클래스로 교체하려면 클라이언트 코드 수정 필요 }","내부-속성-변경-어려움#내부 속성 변경 어려움":"일반적으로 싱글톤은 내부 상태를 변경하거나 초기화하는 메서드를 제공하지 않습니다. 따라서 내부 속성을 동적으로 변경하기 어려울 수 있습니다.\npublic class SingletonImpl { private int value; private SingletonImpl() { this.value = 0; } // 내부 속성 변경 메서드가 없음 }","의존성-문제#의존성 문제":"클라이언트는 Singleton 클래스에 직접 의존하게 되므로, 의존성 역전 원칙(Dependency Inversion Principle, DIP)을 위반합니다. 즉, 클라이언트는 구체 클래스에 종속되어 유연성이 감소합니다.\npublic class Client { private Singleton singleton = SingletonImpl.getInstance(); // 클라이언트가 SingletonImpl 클래스에 직접 의존 }","자식-클래스-생성-어려움#자식 클래스 생성 어려움":"싱글톤 클래스의 생성자가 private이므로 자식 클래스에서 이를 상속하고 확장하기 어려워집니다.\npublic class ChildSingleton extends SingletonImpl { // 오류: 부모 클래스의 생성자에 접근할 수 없음 } 유연성 감소: 위의 문제들로 인해 싱글톤 패턴은 유연성이 감소하게 되며, 코드 유지보수 및 확장이 어려워집니다. 이로 인해 안티패턴으로 불리기도 합니다.","코드-양-증가#코드 양 증가":"싱글톤 패턴을 구현하려면 클래스 내에 싱글톤 인스턴스를 생성하고 관리하는 코드가 추가됩니다. 이로 인해 코드가 더 복잡해지고, 가독성이 떨어질 수 있습니다.\npublic class SingletonImpl implements Singleton{ private static SingletonImpl instance; private SingletonImpl() { // private 생성자 } public static SingletonImpl getInstance() { if (instance == null) { instance = new SingletonImpl(); } return instance; } }","테스트-어려움#테스트 어려움":"싱글톤은 전역 상태를 가지고 있어 테스트하기 어려울 수 있습니다. 특히 싱글톤 인스턴스가 다른 객체에 의존하는 경우, 모의 객체(Mock Object) 등을 사용하기 어려워집니다. 싱글톤 인스턴스가 다른 객체에 의존하는 경우, 이 의존성을 모의 객체로 대체하는 것이 어렵습니다. 싱글톤 인스턴스는 생성 시점에 의존성을 갖게 되므로, 테스트 시점에 이를 모의 객체로 대체하는 것이 불가능합니다. 이로 인해 의존성에 대한 제어가 어려워져, 테스트가 복잡해질 수 있습니다.\npublic class SingletonImpl { private Dependency dependency; private SingletonImpl() { this.dependency = new Dependency(); // 의존성 주입이 어려움 } // ... }"},"title":"싱글톤 패턴의 문제"},"/02.inbox/%EC%9A%B0%EB%B6%84%ED%88%AC-%EB%A6%AC%EB%88%85%EC%8A%A4-%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%84%B1/":{"data":{"":"","c샵#c샵":"닷넷","go#go":"","java#java":"apt 로 설치 (open-jdk) update-java-alternatives java 버전 변경\nshinnk@n100-server:/usr/lib/jvm$ java --version openjdk 21.0.4 2024-07-16 OpenJDK Runtime Environment (build 21.0.4+7-Ubuntu-1ubuntu222.04) OpenJDK 64-Bit Server VM (build 21.0.4+7-Ubuntu-1ubuntu222.04, mixed mode, sharing) shinnk@n100-server:/usr/lib/jvm$ update-java-alternatives -l java-1.17.0-openjdk-amd64 1711 /usr/lib/jvm/java-1.17.0-openjdk-amd64 java-1.21.0-openjdk-amd64 2111 /usr/lib/jvm/java-1.21.0-openjdk-amd64 shinnk@n100-server:/usr/lib/jvm$ java --version openjdk 21.0.4 2024-07-16 OpenJDK Runtime Environment (build 21.0.4+7-Ubuntu-1ubuntu222.04) OpenJDK 64-Bit Server VM (build 21.0.4+7-Ubuntu-1ubuntu222.04, mixed mode, sharing) shinnk@n100-server:/usr/lib/jvm$ sudo update-java-alternatives -s java-1.17.0-openjdk-amd64 shinnk@n100-server:/usr/lib/jvm$ java --version openjdk 17.0.12 2024-07-16 OpenJDK Runtime Environment (build 17.0.12+7-Ubuntu-1ubuntu222.04) OpenJDK 64-Bit Server VM (build 17.0.12+7-Ubuntu-1ubuntu222.04, mixed mode, sharing)","javascript#javascript":"node 를 말함 fnm 을 사용하며 fnm 의 경우 ~/.local 에 존재,폴더를 지우면 완전히 사라진다","python#python":"ppa 를 통해 python 의 각 버전을 설치 기본적으로 full 버전을 설치, 제안인 dev 버전도 설치\n$ apt depends python3.12-full python3.12-full Depends: python3.12 (= 3.12.8-1+jammy1) Depends: libpython3.12-testsuite Depends: python3.12-venv (= 3.12.8-1+jammy1) Depends: idle-python3.12 Depends: python3.12-gdbm Depends: python3.12-lib2to3 Depends: python3.12-tk Depends: ca-certificates Recommends: python3.12-examples Suggests: python3.12-dev 파이썬 인터브리터를 변경하는방법 /bin 폴더를 ln 을 조작함\nlrwxrwxrwx 1 root root 10 Nov 14 19:51 python -\u003e python3.12* lrwxrwxrwx 1 root root 10 Sep 11 21:06 python3 -\u003e python3.10* -rwxr-xr-x 1 root root 5941832 Nov 7 05:22 python3.10* -rwxr-xr-x 1 root root 7894408 Oct 1 17:52 python3.12* lrwxrwxrwx 1 root root 34 Oct 1 17:52 python3.12-config -\u003e x86_64-linux-gnu-python3.12-config* python3 의 경우 우분투가 사용하는 버전 python 의 경우 내가 사용하는 버전 패키지 관리자 get-pip.py 를 통해 설치 get-pip.py 의 경우 ~/.local 에 설치되며 변경시 get-pip 를 다시 실행해서 설치한다","rust#rust":"","각-언어별-환경구성#각 언어별 환경구성":"","도커#도커":"공식 문서에 apt 를 통해 설치 또는 snap 패키지"},"title":"우분투 리눅스 환경 구성"},"/02.inbox/%EC%9C%88%EB%8F%84%EC%9A%B0-%ED%8C%8C%EC%9D%BC%EC%9D%B4%EB%A6%84%EC%9C%BC%EB%A1%9C-%EC%82%AC%EC%9A%A9%ED%95%A0-%EC%88%98-%EC%97%86%EB%8A%94-%EB%AC%B8%EC%9E%90/":{"data":{"":"문자 이유 \\ 디렉터리의 구분자로 쓰인다.\n예: C:\\\\Users\\\\user\\\\Downloads\\\\namuwiki.url / 디렉터리의 구분자로 쓰인다. : C:, D:와 같은 드라이브 기호로 쓰인다. * 와일드 카드로 쓰인다.\n?는 한 글자의 의미로 쓰이기도 하며, UNC(Universal Naming Convention)에도 사용된다. ? 와일드 카드로 쓰인다. \" 경로의 시작과 끝을 나타낸다.\n예: \"C:\\\\Users\\\\user\\\\Downloads\\\\namuwiki.url\" \u003c 리다이렉트, 파이프 등 특수 문법에 쓰인다. \u003e 리다이렉트, 파이프 등 특수 문법에 쓰인다. | 리다이렉트, 파이프 등 특수 문법에 쓰인다. ? =\u003e ❓"},"title":"윈도우 파일이름으로 사용할 수 없는 문자"},"/02.inbox/%EC%9D%B4%EA%B2%83%EC%9D%B4-%EC%BD%94%EB%94%A9%ED%85%8C%EC%8A%A4%ED%8A%B8%EB%8B%A4-with-python/%EA%B5%AC%ED%98%84implementation/":{"data":{"":"머릿속에 있는 알고리즘을 소스코드로 바꾸는 과정\n알고리즘은 간단한데 코드가 지나칠 만큼 길어지는 문제 실수 연산을 다루고 특정 소수점 자리까지 출력해야 하는 문제 문자열을 특정한 기준에 따라서 끊어 처리해야 하는 문제 적절한 라이브러리를 찾아서 사용해야 하는 문제 ( 모든 순열 모든 조합을 찾는 문제 python itertools 모듈을 사용해야 쉬워진다 ) 시뮬레이션 유형 구현 유형 완전탐색 미로 탐색 (문제 번호: 2178) - BFS 알고리즘을 사용하여 최단 경로를 찾는 문제입니다.\nURL: https://www.acmicpc.net/problem/2178\n토마토 (문제 번호: 7576) - BFS 알고리즘을 사용하여 최소 일수를 구하는 문제입니다.\nURL: https://www.acmicpc.net/problem/7576\n단지번호붙이기 (문제 번호: 2667) - DFS 또는 BFS 알고리즘을 사용하여 단지를 구분하고 개수를 세는 문제입니다.\nURL: https://www.acmicpc.net/problem/2667\n유기농 배추 (문제 번호: 1012) - DFS 또는 BFS 알고리즘을 사용하여 배추흰지렁이가 필요한 최소 개수를 구하는 문제입니다.\nURL: https://www.acmicpc.net/problem/1012\n섬의 개수 (문제 번호: 4963) - DFS 또는 BFS 알고리즘을 사용하여 섬의 개수를 구하는 문제입니다.\nURL: https://www.acmicpc.net/problem/4963\n행렬 (문제 번호: 1080) - 그리디 알고리즘을 사용하여 최소 횟수로 변환하는 문제입니다.\nURL: https://www.acmicpc.net/problem/1080\n2차원 배열 문제들\nh , K = map(str,input().split()) h = int(h) count = 0 for j in range(60): for k in range(60): if K in str(i) + str(j) + str(k): count += 1 print(count) input_data = input() row = int(input_data[1]) column = ord(input_data[0]) - ord('a') + 1 steps = [ # dx dy 로 리스트 2개로 만드는게 낮다 c/java 대응 (-2,-1), (-2,1), (-1,2), (1,2), (2,1), (2,-1), (1,-2), (-1,-1), ] count = 0 for step in steps: next_row = row + step[0] next_column = column + step[1] if next_row \u003e 0 and next_row \u003c 9 and next_column \u003e 0 and next_column \u003c 9: count += 1 print(count) Note\n0 인 경우를 생각하자"},"title":"구현(Implementation)"},"/02.inbox/%EC%9D%B4%EA%B2%83%EC%9D%B4-%EC%BD%94%EB%94%A9%ED%85%8C%EC%8A%A4%ED%8A%B8%EB%8B%A4-with-python/%EA%B7%B8%EB%9E%98%ED%94%84graph/":{"data":{"":"","-그래프의-종류와-개념#📖 그래프의 종류와 개념":"그래프는 여러 개의 점(노드 또는 정점)들이 선으로 연결된 구조를 나타내는 수학적인 개념입니다. 그래프는 다양한 현실 세계의 문제를 모델링하고 분석하는 데 사용됩니다.","1-인접-리스트adjacency-list#1. 인접 리스트(Adjacency List)":"인접 리스트(Adjacency List)로 그래프를 표현하는 것이 가장 일반적인 방법 이다.\n모든 정점(혹은 노드)을 인접 리스트에 저장한다. 즉, 각각의 정점에 인접한 정점들을 리스트로 표시한 것이다. 배열(혹은 해시테이블)과 배열의 각 인덱스마다 존재하는 또 다른 리스트(배열, 동적 가변 크기 배열(ArrayList), 연결리스트(LinkedList) 등)를 이용해서 인접 리스트를 표현\n0: 1 1: 2 2: 0, 3 3: 2 4: 6 5: 4 6: 5 정점의 번호만 알면 이 번호를 배열의 인덱스로 하여 각 정점의 리스트에 쉽게 접근할 수 있다.\n무방향 그래프(Undirected Graph)에서 (a, b) 간선은 두 번 저장된다. 한 번은 a 정점에 인접한 간선을 저장하고 다른 한 번은 b에 인접한 간선을 저장한다. 정점의 수: N, 간선의 수: E인 무방향 그래프의 경우 N개의 리스트, N개의 배열, 2E개의 노드가 필요 트리에선 특정 노드 하나(루트 노드)에서 다른 모든 노드로 접근이 가능 -\u003e Tree 클래스 불필요 그래프에선 특정 노드에서 다른 모든 노드로 접근이 가능하지는 않음 -\u003e Graph 클래스 필요\nclass Graph { public Node[] nodes; } // 트리의 노드 클래스와 동일 class Node { public String name; public Node[] children; }","2-인접-행렬adjacency-matrix#2. 인접 행렬(Adjacency Matrix)":"인접 행렬은 NxN 불린 행렬(Boolean Matrix)로써 matrix[i][j]가 true라면 i -\u003e j로의 간선이 있다는 뜻이다.\n0과 1을 이용한 정수 행렬(Integer Matrix)을 사용할 수도 있다.\nif(간선 (i, j)가 그래프에 존재) matrix[i][j] = 1; else matrix[i][j] = 0; 정점(노드)의 개수가 N인 그래프를 인접 행렬로 표현\n간선의 수와 무관하게 항상 n^2개의 메모리 공간이 필요하다. 무방향 그래프를 인접 행렬로 표현한다면 이 행렬은 대칭 행렬(Symmetric Matrix)이 된다.\n물론 방향 그래프는 대칭 행렬이 안 될 수도 있다. 인접 리스트를 사용한 그래프 알고리즘들(Ex. 너비 우선 탐색) 또한 인접 행렬에서도 사용이 가능하다.\n하지만 인접 행렬은 조금 효율성이 떨어진다. 인접 리스트는 어떤 노드에 인접한 노드들을 쉽게 찾을 수 있지만 인접 행렬에서는 인접한 노드를 찾기 위해서는 모든 노드를 전부 순회해야 한다. ==인접 리스트와 인접 행렬 중 선택 방법==\n인접 리스트 그래프 내에 적은 숫자의 간선만을 가지는 희소 그래프(Sparse Graph) 의 경우 장점 어떤 노드에 인접한 노드들 을 쉽게 찾을 수 있다. 그래프에 존재하는 모든 간선의 수 는 O(N+E) 안에 알 수 있다.: 인접 리스트 전체를 조사한다. 단점 간선의 존재 여부와 정점의 차수: 정점 i의 리스트에 있는 노드의 수 즉, 정점 차수만큼의 시간이 필요 인접 행렬 그래프에 간선이 많이 존재하는 밀집 그래프(Dense Graph) 의 경우 장점 두 정점을 연결하는 간선의 존재 여부 (M[i][j])를 O(1) 안에 즉시 알 수 있다. 정점의 차수 는 O(N) 안에 알 수 있다.: 인접 배열의 i번 째 행 또는 열을 모두 더한다. 단점 어떤 노드에 인접한 노드들을 찾기 위해서는 모든 노드를 전부 순회해야 한다. 그래프에 존재하는 모든 간선의 수는 O(N^2) 안에 알 수 있다.: 인접 행렬 전체를 조사한다. 밀집 그래프(dense graph)는 간선의 수가 최대 간선의 수에 가까운 그래프이다. 그와 반대로, 간선이 얼마 없는 그래프는 희소 그래프(sparse graph)라고 한다.","그래프graph의-구현-2가지#그래프(Graph)의 구현 2가지":"","그래프graph의-탐색#그래프(Graph)의 탐색":"일반적인 방법 두 가지:\n깊이 우선 탐색(Depth-First Search) 과 너비 우선 탐색(Breadth-First Search)\n루트 노드(혹은 다른 임의의 노드)에서 시작해서 다음 분기(branch)로 넘어가기 전에 해당 분기를 완벽하게 탐색하는 방법\n즉, 넓게(wide) 탐색하기 전에 깊게(deep) 탐색하는 것이다. 사용하는 경우: 모든 노드를 방문 하고자 하는 경우에 이 방법을 선택한다. 깊이 우선 탐색이 너비 우선 탐색보다 좀 더 간단하다. 루트 노드(혹은 다른 임의의 노드)에서 시작해서 인접한 노드를 먼저 탐색하는 방법\n즉, 깊게(deep) 탐색하기 전에 넓게(wide) 탐색하는 것이다. 사용하는 경우: 두 노드 사이의 최단 경로 혹은 임의의 경로를 찾고 싶을 때 이 방법을 선택한다. Ex) 지구상에 존재하는 모든 친구 관계를 그래프로 표현한 후 Ash와 Vanessa 사이에 존재하는 경로를 찾는 경우 깊이 우선 탐색의 경우 - 모든 친구 관계를 다 살펴봐야 할지도 모른다. 너비 우선 탐색의 경우 - Ash와 가까운 관계부터 탐색","그래프의-용어#그래프의 용어":"노드(Node) 또는 정점(Vertex) N or V 그래프에서 하나의 점을 나타냅니다. 노드는 데이터를 저장하는데 사용될 수 있습니다.\n간선(Edge) E 그래프에서 노드와 노드를 연결하는 선을 나타냅니다. 간선은 노드 쌍 사이의 관계를 나타냅니다.\n인접(Adjacent) 두 개의 노드가 간선으로 직접 연결되어 있는 상태를 말합니다. 인접한 노드는 서로 이웃이라고도 합니다.\n차수(Degree) 노드에 연결된 간선의 수를 나타냅니다. 무방향 그래프에서는 노드의 차수는 해당 노드와 인접한 노드의 수입니다.\n경로(Path) 그래프에서 노드들을 연결하는 간선의 순서를 나타내는 순서쌍입니다. 경로의 길이는 경로에 속한 간선의 수입니다.\n사이클(Cycle) 그래프에서 동일한 노드로 되돌아오는 경로를 말합니다. 즉, 경로의 시작 노드와 끝 노드가 동일한 경우를 말합니다.\n가중치(Weight) 가중치 그래프에서 간선에 할당된 값 또는 비용을 나타냅니다. 가중치는 간선의 특성을 나타내는데 사용됩니다.","그래프의-종류#그래프의 종류":"무방향 그래프 \u0026 방향 그래프 간선의 방향의 유무에 따라 구분되는 그래프\n가중치 그래프 그래프에 가중치 또는 비용이 할당된 그래프(네트워크 이론이나 신경망 이론에 활용되는 개념) 연결 그래프 \u0026 비연결 그래프 모든 노드에 대해 경로가 존재하면 연결 그래프, 특정 노드에 대한 경로가 하나라도 존재하지 않을 경우 비연결 그래프\n사이클 그래프 \u0026 비순환 그래프\n완전 그래프 그래프의 모든 노드가 연결되어 있는 그래프","그래프의-한-종류인-트리에-대해#그래프의 한 종류인 트리에 대해🧐":"트리(Tree)는 그래프(Graph)의 한 종류로, 계층적인 구조를 나타내는 비순환적인 연결 그래프입니다. 트리는 하나의 루트(Root) 노드에서 시작하여 다양한 자식(Child) 노드들로 확장되는 구조를 가지며, 각 노드는 하나의 부모(Parent) 노드와 연결되어 있습니다.","알고리즘에서-그래프#알고리즘에서 그래프":"알고리즘 코딩테스트에서는 다양한 그래프 알고리즘과 그래프 기반의 문제들이 출제될 수 있습니다. 주요한 그래프 알고리즘과 문제 유형은 다음과 같습니다:\n깊이 우선 탐색 (Depth-First Search, DFS) 그래프의 모든 노드를 탐색하고, 각 노드를 방문한 순서를 기록하는 알고리즘입니다. 주로 그래프 탐색, 사이클 판별, 연결 요소 확인 등에 사용됩니다.\n문제 풀어보기 너비 우선 탐색 (Breadth-First Search, BFS) 루트 노드(혹은 다른 임의의 노드)에서 시작해서 다음 분기(branch)로 넘어가기 전에 해당 분기를 완벽하게 탐색하는 방법 문제 풀어보기 다익스트라 알고리즘 (Dijkstra's Algorithm) 가중치 그래프에서 시작 노드로부터 모든 다른 노드까지의 최단 경로를 찾는 알고리즘입니다.\n문제 풀어보기 벨만-포드 알고리즘 (Bellman-Ford Algorithm) 가중치 그래프에서 시작 노드로부터 모든 다른 노드까지의 최단 경로를 찾는 알고리즘입니다. 음수 가중치를 가진 간선이 있는 경우에도 동작합니다.\n문제 풀어보기 크루스칼 알고리즘 (Kruskal's Algorithm) 가중치 그래프에서 최소 신장 트리를 찾는 알고리즘입니다. 모든 간선을 가중치 순으로 정렬한 뒤, 사이클을 형성하지 않는 간선을 추가하여 트리를 형성합니다.\n문제 풀어보기 프림 알고리즘 (Prim's Algorithm) 가중치 그래프에서 최소 신장 트리를 찾는 알고리즘입니다. 시작 노드에서부터 출발하여, 현재 트리와 연결되지 않은 노드 중 최소 가중치의 간선을 선택하여 트리를 확장합니다.\n문제 풀어보기 위상 정렬 (Topological Sorting) 방향 그래프에서 노드들을 선형적으로 정렬하는 알고리즘입니다. 선행 관계가 있는 작업의 우선 순위를 결정하는 데 사용됩니다.\n문제 풀어보기 최소 공통 조상 (Lowest Common Ancestor, LCA) 트리에서 두 노드의 가장 가까운 공통 조상을 찾는 알고리즘입니다. 주로 트리 구조를 활용한 문제에서 사용됩니다.\n문제 풀어보기 이 외에도 그래프 기반의 다양한 문제 유형이 있을 수 있으며, 각 문제에 맞는 적절한 알고리즘을 선택하여 문제를 해결하는 것이 중요합니다.","트리에-종류#트리에 종류":"이진 트리 (Binary Tree) 각 노드가 최대 두 개의 자식을 가질 수 있는 트리입니다. 이진 트리는 왼쪽 자식과 오른쪽 자식으로 구성되며, 자식의 배치에는 순서가 있습니다. 이진 트리는 데이터 검색, 정렬, 압축 등 다양한 애플리케이션에서 사용됩니다. 이진 탐색 트리 (Binary Search Tree) 이진 트리의 한 종류로, 이진 탐색의 원리를 기반으로 합니다. 모든 노드는 왼쪽 서브트리의 값보다 작고, 오른쪽 서브트리의 값보다 큰 키 값을 가집니다. 이진 탐색 트리는 데이터 검색, 정렬, 범위 검색 등에 효율적으로 사용됩니다. AVL 트리 균형 이진 탐색 트리로서, 모든 노드의 왼쪽 서브트리와 오른쪽 서브트리의 높이 차이가 최대 1인 트리입니다. AVL 트리는 삽입, 삭제 시에 자동으로 균형을 유지하여 탐색 성능을 보장합니다. 레드-블랙 트리 (Red-Black Tree) 균형 이진 탐색 트리로서, 각 노드는 레드(Red) 또는 블랙(Black) 색깔을 가지며, 특정한 규칙을 따릅니다. 레드-블랙 트리는 AVL 트리보다 균형을 유지하는 데에 조금 덜 엄격한 규칙을 가지며, 데이터의 삽입과 삭제가 더 효율적입니다. B-트리 (B-Tree) 다양한 자료 구조에서 사용되는 균형 탐색 트리입니다. B-트리는 노드마다 여러 개의 키 값을 가지며, 많은 수의 자식을 가질 수 있습니다. B-트리는 대용량 데이터베이스의 인덱스 구조나 파일 시스템에서 사용되는 것과 같은 곳에서 사용됩니다. 힙 (Heap) 이진 트리의 한 종류로, 최대 힙과 최소 힙으로 나눌 수 있습니다. 최대 힙은 부모 노드의 값이 자식 노드의 값보다 큰 힙이며, 최소 힙은 그 반대입니다. 힙은 우선순위 큐와 같은 자료 구조에서 사용되어 최댓값 또는 최솟값에 빠르게 접근할 수 있습니다.","트리의-특징-#트리의 특징 🔎":"계층 구조: 트리는 하나의 루트 노드에서 시작하여 계층적인 구조를 형성합니다. 각 노드는 부모-자식 관계를 가지며, 자식 노드들은 동일한 계층에 속합니다.\n방향성: 트리는 방향 그래프의 한 형태로, 간선은 단방향으로 표시됩니다. 각 노드는 자식 노드들을 가리키는 방향으로 연결됩니다.\n비순환성: 트리는 순환 구조를 가지지 않습니다. 즉, 어떤 노드에서 시작해도 동일한 노드로 되돌아갈 수 있는 순환 경로가 존재하지 않습니다.\n유일한 경로: 루트 노드에서 어떤 노드까지의 경로는 유일합니다. 트리 내에서는 어떤 노드도 다른 경로를 통해 도달할 수 없습니다"},"title":"그래프(graph)"},"/02.inbox/%EC%9D%B4%EA%B2%83%EC%9D%B4-%EC%BD%94%EB%94%A9%ED%85%8C%EC%8A%A4%ED%8A%B8%EB%8B%A4-with-python/%EC%8A%A4%ED%83%9D%EA%B3%BC-%ED%81%90-%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0/":{"data":{"":"스택\n선입 후출 박스 쌓기 pop 함수 “후출” 구현\n큐\n선입 선출","c-의-스택#c++ 의 스택":"","c-의-큐#c++ 의 큐":"","java의-스택#java의 스택":"","java의-큐#java의 큐":"스택 라이브러리 대신에 재귀함수를 이용하는 경우","python-의-스택#python 의 스택":"","python-의-큐#python 의 큐":""},"title":"스택과 큐 자료구조"},"/02.inbox/%EC%9D%B4%EA%B2%83%EC%9D%B4-%EC%BD%94%EB%94%A9%ED%85%8C%EC%8A%A4%ED%8A%B8%EB%8B%A4-with-python/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%EC%84%B1%EB%8A%A5-%ED%8F%89%EA%B0%80/":{"data":{"":"시간 복잡도 공간 복잡도","수행시간-요구-사항#수행시간 요구 사항":"N \u003c 500 시간 복잡도 O(N^3) N \u003c 2000 시간 복잡도 O(N^2) N \u003c 100,000 시간 복잡도 O(NlogN) N \u003c 10,000,000 시간 복잡도 O(N) 예측 다음과 같은 이론을 따르는 것이 좋다"},"title":"알고리즘 성능 평가"},"/02.inbox/%EC%9D%B4%EA%B2%83%EC%9D%B4-%EC%BD%94%EB%94%A9%ED%85%8C%EC%8A%A4%ED%8A%B8%EB%8B%A4-with-python/%ED%83%90%EC%9A%95%EB%B2%95greedy/":{"data":{"":"현재 상황에서 지금 당장 가장 좋은 것만 고르는 방법\n지금 당장 가장 좋은 것을 고르는 방식이 답이 되는 것을 보장하는가? =\u003e 정당성\n그리디의 경우 정당성 분석이 가장 중요 단순히 매 상황에서 가장 큰 값만 고르는 경우(그리디)의 경우 5 -\u003e 10 -\u003e 4 를 고르게 되어 틀리게 된다\n[!] 탐욕법으로 얻은 해가 최적의 해가 되는 상황에서 이를 추론 할 수 있어야 풀리는 문제 출제\n가장 큰 회폐 단위부터 최대한 돈을 거슬러 준다 ==\u003e 그리디 정당성 분석: 거스름돈 동전 중에서 모든 조합의 큰 단위가 작은 단위의 배수 이므로 작은 단위의 동전들을 조합해 다른 해가 나올 수 없다 예시: 거스름돈 800원 일때 화폐 단위가 500원 400원 100원 이라면 500 x 1 + 100 x 3 (틀림) 400 x 2 (맞음) n = 1260 count = 0 array = [500,100,50,10] for coin in array: count += m // coin n %= coin print(count) using namespace std; int n = 1260; int cnt = 0; int coinTypes[4] = {500, 100, 50, 10}; int main() { for (int i = 0; i \u003c 4; i++) { int coin = coinTypes[i]; cnt += n / coin; n %= coin; } cout \u003c\u003c cnt \u003c\u003c '\\n'; }","문제1#문제1":"Note\n가능하면 최대한 많이 나눈다 정당성 분석: N 이 아무리 큰 수여도 k 로 계속 나눈다면 기하급수적으로 빠르게 줄일 수 있다 (k\u003e=2 일때 기준)\ndef greedy(n,k): count = 0 while n != 0: if (n % k) == 0: n = n // k count += 1 else: n -= 1 count += 1 return count n,k = map(int,input().split()) print(greedy(n,k))","문제2#문제2":"Note\n0을 곱하는 경우 숫자가 작아짐 / 0을 더하는 경우 숫자가 동일함 1을 곱하는 경우 숫자가 동일함 / 1을 더하는 경우 숫자가 커짐\ndef greedy(s): first = 0 second = 0 for i in range(len(s)): second = s[i] if first == 0 or second == 0 or first == 1 or second == 1: first += second else: first *=second return first s = [int(i) for i in input()] print(greedy(s)) Note\n정당성 분석: ??\nn = int(input()) data = list(map(int, input().split())) data.sort() count = 0 # 현제 그룹에 포함된 모험가의 수 result = 0 # 총 그룹의 수 for i in data: # 공포도를 기준으로 낮은 것을 한개씩 확인하면서 순회 count += 1 # 해당 모험가 포함 # 현재 그룹에 포함된 모험가의 수가 현재 공포도 이상이렴 그룹 결정 if count \u003e= i: result += 1 # 총 그룹수 증가 count = 0 # 모험가 수 초기화 print(result)","실전#실전":""},"title":"탐욕법(greedy)"},"/02.inbox/%EC%9D%B4%EA%B2%83%EC%9D%B4-%EC%BD%94%EB%94%A9%ED%85%8C%EC%8A%A4%ED%8A%B8%EB%8B%A4-with-python/%ED%88%AC-%ED%8F%AC%EC%9D%B8%ED%84%B0-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/":{"data":{"":"리스트에 순차적으로 접근해야 할 때 두개의 점의 위치를 기록하면서 처리하는 알고리즘\n완전 탐색에서 인덱스인 end 가 1 증가하면 부분합이 증가 인덱스인 start 가 1 증가하면 부분합이 감소 이조건을 이용해서 $O(n)$ 으로 만들어야 한다\nint countSubarraysWithSum(const std::vector\u003cint\u003e\u0026 vec, int M) { int ret = 0; // 부분합이 M인 부분 배열의 개수 int start = 0; // start 포인터 초기화 int end = 0; // end 포인터 int interval_sum = 0; // 현재 부분합 while (start \u003c vec.size()) { // end 포인터를 가능한 만큼 이동 while (end \u003c n \u0026\u0026 interval_sum \u003c M) { interval_sum += vec[end]; // 부분합 계산 end++; // 인덱스 이동 } // 부분합이 M일 때 카운트 증가 if (interval_sum == M) { ret++; } // interval_sum 이 target 보다 클 때는 start 를 이동 // start 포인터를 증가시키고, interval_sum에서 vec[start]를 빼기 interval_sum -= vec[start]; start++; } return ret; } class Solution { public: bool isSubsequence(string \u0026s, string \u0026t) { int sp = 0; int tp = 0; // 투포인터여도 다른 배열을 지칭하는 인덱스이므로 1개의 반복문으로 해결 가능하다 // 포인터가 size 보다 작아야 하는 조건이 필요하다 while(sp \u003c s.size() \u0026\u0026 tp \u003c t.size()){ if(s[sp] == t[tp]){ sp++; } tp++; } return sp == s.size(); } };"},"title":"투 포인터 알고리즘"},"/02.inbox/%EC%9D%B4%EA%B2%83%EC%9D%B4-%EC%BD%94%EB%94%A9%ED%85%8C%EC%8A%A4%ED%8A%B8%EB%8B%A4-with-python/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EB%AC%B8%EB%B2%95/":{"data":{"":"파이썬 자료형\n정수형 실수형 복소수형 문자열 리스트 튜플 사전 등등\npython 타입 확인\na.\\__class\\__ type(a) isinstance(a) # 상속관계도 알려줌","dictionary#dictionary":"a = { key = 'value' } a[key] == value","f-string-36-부터#f-string 3.6 부터":"f\"정답은 {answer}입니다\"","람다-표현식#람다 표현식":"함수를 한줄에 작성 가능\narray = [('홍길동', 50), ('이순신', 32), ('아무개', 74)] def my_key(x): return x[1] print(sroted(array, key=my_key)) print(sorted(array, key=lamda x: x[1])) from functools import reduce print(list(map(lambda x:x**2,range(5)))) print(lambda x, y: x+y,range(5)) 출력: [0,1,4,9,16] []","리스트-#리스트 []":"append(value) sort() reverse() insert(index,value) count(value) remove(value)","입출력#입출력":"map() 리스트의 모든 원소에 각각 특정한 함수를 적용할 때 사용합니다\nlist(map(int, input().split())) map( 함수 . 리스트 ) 바르게 입력받기 sys.stdin.readline() 줄바꿈 기호 입력되므로 rstrip() 메서드도 사용한다\ndata = sys.stin.readline().rstrip()","조건부-표현식#조건부 표현식":"result = \"Success\" if score \u003e= 80 else \"Fail\"","집합#집합":"","튜플-#튜플 ()":"변경 불가 문자열","표준-라이브러리#표준 라이브러리":"내장함수 itertools : 반복되는 형태의 데이터를 처리하기 위한 기능 =\u003e 순열 조함 라이브러리 heapq : 힙 자료구조를 제공 =\u003e 우선순위 큐 기능 bisect: 이진 탐색 기능 제공 collections 텍 카운터 등 유용한 자료구조 포함 math : 필수적인 수학적 기능을 제공한다 =\u003e 팩토리얼 제곱근 최대공약수 삼각함수 관련함수 부터 파이 와 같은 상수를 포함한다 sum([1,2,3,4,5]) # 15 min(7,3,4,9) # 3 max eval(\"(3+5)*7\") # 56 sorted(,) # 기본이 오름차순 from itertools import permutations data = {'a','b','c'} result = list(permutations(data, 3)) print(result) from itertools import combination ... from collections import Counter def lcm(a,b): # 최대 공배수 return a*b // math.gcd(a,b)"},"title":"파이썬 문법"},"/02.inbox/%EC%9D%B4%EA%B2%83%EC%9D%B4-%EC%BD%94%EB%94%A9%ED%85%8C%EC%8A%A4%ED%8A%B8%EB%8B%A4-with-python/bfs-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/":{"data":{"":"#include \u003ciostream\u003e #include \u003cvector\u003e #include \u003cqueue\u003e #include \u003carray\u003e // for std::array using namespace std; void bfs(int start) { queue\u003cint\u003e q; q.push(start); // 초기 시작 노드 큐에 삽입 visited[start] = true; // 방문 처리 // que 처리 알고리즘 while (!q.empty()) { // 해당 노드 처리 int x = q.front(); q.pop(); cout \u003c\u003c x \u003c\u003c ' '; // 해당 노드와 연결된 방문하지 않은 노드 처리 for (int y : graph[x]) { if (!visited[y]) { q.push(y); visited[y] = true; } } } } int main(void) { // visited 배열을 std::array로 변경 (선택적) array\u003cbool, 9\u003e visited{}; // 기본적으로 false로 초기화 // 그래프 연결 정보를 중괄호 초기화 리스트로 표현 vector\u003cint\u003e graph[] = { {}, // 0번 인덱스는 사용하지 않음 (1번부터 시작) {2, 3, 8}, // 1번 노드에 연결된 노드들 {1, 7}, // 2번 노드에 연결된 노드들 {1, 4, 5}, // 3번 노드에 연결된 노드들 {3, 5}, // 4번 노드에 연결된 노드들 {3, 4}, // 5번 노드에 연결된 노드들 {7}, // 6번 노드에 연결된 노드들 {2, 6, 8}, // 7번 노드에 연결된 노드들 {1, 7} // 8번 노드에 연결된 노드들 }; bfs(1); // 1번 노드부터 탐색 시작 return 0; }"},"title":"BFS 알고리즘"},"/02.inbox/%EC%9D%B4%EA%B2%83%EC%9D%B4-%EC%BD%94%EB%94%A9%ED%85%8C%EC%8A%A4%ED%8A%B8%EB%8B%A4-with-python/dfs-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/":{"data":{"":"1.gif)\nstack vs recursion 풀이 2개로 나뉘며 stack 의 경우 dfs 시 탐색해야할 나머지 노드를 stack 에 저장해두고 빼서 탐색하는 방식의 알고리즘 recursion 의 경우 하위 트리가 없을 때 또는 자신이 null 일때 탈출조건을 준다면 recursion 풀이가 가능하다","binary-tree-dfs#binary tree DFS":"stack 기반 풀이 1. recursion 기반 풀이 1.","grath-dfs#grath DFS":"기본적으로 작은 숫자부터 탐색하는 것을 기본으로 한다\nrecursion 풀이\nusing namespace std; bool visited[9]; vector\u003cint\u003e graph[9]; // DFS 함수 정의 void dfs(int x) { // 현재 노드 방문 처리 visited[x] = true; cout \u003c\u003c x \u003c\u003c ' '; // 현재 노드와 연결된 다른 노드를 재귀적으로 방문 for (int i = 0; i \u003c graph[x].size(); i++) { int y = graph[x][i]; if (!visited[y]) dfs(y); } } int main() { // 각 노드의 인접 노드 정보를 초기화 리스트로 간단하게 할당 graph[1] = {2, 3, 8}; graph[2] = {1, 7}; graph[3] = {1, 4, 5}; graph[4] = {3, 5}; graph[5] = {3, 4}; graph[6] = {7}; graph[7] = {2, 6, 8}; graph[8] = {1, 7}; dfs(1); return 0; } stack 풀이\n#include #include #include using namespace std; bool visited[9]; vector\u003cint\u003e graph[9]; void dfs_iterative(int start) { stack\u003cint\u003e s; s.push(start); while (!s.empty()) { int x = s.top(); s.pop(); if (!visited[x]) { visited[x] = true; cout \u003c\u003c x \u003c\u003c ' '; // 재귀 DFS와 동일한 방문 순서를 위해 인접 노드를 역순으로 스택에 넣습니다. for (auto it = graph[x].rbegin(); it != graph[x].rend(); ++it) { int y = *it; if (!visited[y]) s.push(y); } } } } int main() { // 각 노드의 인접 노드 정보를 초기화 리스트로 간단하게 할당 graph[1] = {2, 3, 8}; graph[2] = {1, 7}; graph[3] = {1, 4, 5}; graph[4] = {3, 5}; graph[5] = {3, 4}; graph[6] = {7}; graph[7] = {2, 6, 8}; graph[8] = {1, 7}; dfs_iterative(1); return 0; }"},"title":"DFS 알고리즘"},"/02.inbox/%EC%9D%B8%EC%82%AC%EC%9D%B4%ED%8A%B8-%EC%A0%9C%EC%95%88-%EC%A3%BC%EC%9E%A5%EC%9D%98-%EC%B0%A8%EC%9D%B4%EC%A0%90/":{"data":{"":"","왜-주장이-중요한가#왜 ‘주장’이 중요한가?":"인사이트와 제안만으로는 실제 변화나 실행이 일어나지 않음\n주장은 행동과 결과에 대한 책임을 동반, 실제로 무언가를 ‘움직이게’ 만듦\n조직 내에서 영향력을 가지려면, 단순히 정보 전달이 아니라 본인만의 관점과 실행 의지가 필요","인사이트-제안-주장의-차이점#인사이트, 제안, 주장의 차이점":"인사이트(Insight): 관찰·분석을 통해 얻은 흥미로운 사실이나 트렌드 공유\n예) “최근에 이런 현상이 있더라.” 제안(Suggestion): 문제 해결을 위한 여러 옵션을 제시\n예) “이렇게 해보는 건 어떨까요?” 주장(Assertion): 구체적이고 명확한 방향성과 행동을 제시하며, 그에 대한 책임을 본인이 짐\n예) “이렇게 해야 합니다. 제가 책임지고 추진하겠습니다.”","주장의-3가지-핵심-요소#주장의 3가지 핵심 요소":"실행 중심(Execution-oriented):\n“그래서 우리는 무엇을 해야 하는가?”에 답함 단순 분석이 아니라, 구체적 실행 계획과 연결됨 확신이 담긴 관점(Conviction):\n본인이 믿고, 설득할 수 있는 의견이어야 함\n남의 생각이 아닌, 본인만의 해석과 신념이 중요 책임감(Ownership):\n“내가 앞장서겠다”는 태도\n결과에 대해 책임질 각오가 필요"},"title":"인사이트, 제안, 주장의 차이점"},"/02.inbox/%EC%9D%BC%EB%B0%98-%ED%95%A8%EC%88%98-%ED%98%B8%EC%B6%9C-user-level-function-call-vs-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%BD%9C-system-call-%ED%98%B8%EC%B6%9C-%EB%B0%A9%EC%8B%9D%EC%9D%98-%EC%B0%A8%EC%9D%B4/":{"data":{"":"시스템 콜(system call)은 사용자 프로그램이 커널의 기능을 간접적으로 호출하는 메커니즘이며, **매핑 테이블(시스템 콜 테이블)**을 통해 실제 커널 함수로 연결됩니다. 일반 함수 호출과 시스템 콜의 동작 방식을 인텔 어셈블리 문법과 함께 비교 설명합니다.","1-일반-함수-호출-user-level-function-call#\u003cstrong\u003e1. 일반 함수 호출 (User-level Function Call)\u003c/strong\u003e":"","2-시스템-콜-system-call#\u003cstrong\u003e2. 시스템 콜 (System Call)\u003c/strong\u003e":"","3-시스템-콜-vs-일반-함수-호출의-핵심-차이#\u003cstrong\u003e3. 시스템 콜 vs 일반 함수 호출의 핵심 차이\u003c/strong\u003e":"구분 일반 함수 호출 시스템 콜 실행 모드 사용자 모드 (User Mode) 커널 모드 (Kernel Mode) 호출 방식 직접 호출 (call 명령어) 간접 호출 (인터럽트/시스템 콜 명령어) 파라미터 전달 레지스터/스택 레지스터 (커널에서 정의한 규칙) 오버헤드 낮음 (메모리 접근만 발생) 높음 (모드 전환, 컨텍스트 스위칭) 보안 제한 없음 커널이 검증 후 실행","동작-방식#\u003cstrong\u003e동작 방식\u003c/strong\u003e":"직접 호출: 호출자(caller)가 함수의 메모리 주소를 직접 참조합니다. 파라미터 전달: 레지스터 또는 스택을 사용합니다. 제어권 이동: 사용자 공간 내에서만 실행되며, 커널 모드 전환 없이 동작합니다.","동작-방식-1#\u003cstrong\u003e동작 방식\u003c/strong\u003e":"간접 호출: 시스템 콜 번호를 **매핑 테이블(sys_call_table)**에 전달해 커널 함수를 찾아 실행합니다. 모드 전환: 사용자 모드 → 커널 모드 전환 (特权级别 변경). 파라미터 전달: 레지스터에 시스템 콜 번호와 인자 저장 (예: eax, ebx, ecx 등).","시스템-콜-처리-과정#\u003cstrong\u003e시스템 콜 처리 과정\u003c/strong\u003e":"인터럽트 발생: int 0x80 또는 syscall 명령어로 커널 모드 진입. 시스템 콜 번호 확인: eax 레지스터에서 시스템 콜 번호를 읽습니다. 매핑 테이블 조회: 커널은 sys_call_table에서 해당 번호의 함수 포인터를 찾습니다. // 커널 내부 sys_call_table 예시 (x86) asmlinkage long sys_write(unsigned int fd, const char __user *buf, size_t count); 함수 실행: 매핑된 커널 함수(예: sys_write)를 실행합니다. 결과 반환: 사용자 모드로 복귀 후 결과를 레지스터(eax)에 저장합니다.","시스템-콜-테이블의-구조-linux-x86-예시#\u003cstrong\u003e시스템 콜 테이블의 구조 (Linux x86 예시)\u003c/strong\u003e":"// arch/x86/kernel/syscall_32.c (커널 소스) extern asmlinkage long sys_write(unsigned int, const char __user *, size_t); extern asmlinkage long sys_read(unsigned int, char __user *, size_t); static const sys_call_ptr_t sys_call_table[__NR_syscall_max + 1] = { [0 ... __NR_syscall_max] = \u0026sys_ni_syscall, // 기본값: 지원되지 않는 시스템 콜 [__NR_write] = sys_write, [__NR_read] = sys_read, // ... (다른 시스템 콜 매핑) }; 간접 참조: sys_call_table[__NR_write] → sys_write 함수 포인터.","시스템-콜-테이블의-역할#\u003cstrong\u003e시스템 콜 테이블의 역할\u003c/strong\u003e":"커널은 sys_call_table이라는 배열을 유지하며, 각 인덱스는 시스템 콜 번호에 해당합니다. 예: Linux x86에서 sys_write의 시스템 콜 번호는 4입니다. // Linux 커널 소스 (unistd_32.h) #define __NR_write 4","예시#\u003cstrong\u003e예시: \u003ccode\u003esys_write\u003c/code\u003e 시스템 콜 호출\u003c/strong\u003e":"section .data msg db \"Hello, World!\", 0xA ; 출력 메시지 (0xA = 개행) len equ $ - msg ; 메시지 길이 section .text global _start _start: ; 시스템 콜 파라미터 설정 (레지스터 사용) mov eax, 4 ; sys_write 시스템 콜 번호 (NR_write = 4) mov ebx, 1 ; 파일 디스크립터 (stdout = 1) mov ecx, msg ; 메시지 주소 mov edx, len ; 메시지 길이 int 0x80 ; 커널 모드 전환 (소프트웨어 인터럽트) ; 프로그램 종료 mov eax, 1 ; sys_exit 시스템 콜 번호 xor ebx, ebx ; 반환 값 0 int 0x80","예시-간단한-덧셈-함수-호출#\u003cstrong\u003e예시: 간단한 덧셈 함수 호출\u003c/strong\u003e":"section .data num1 dd 10 num2 dd 20 section .text global _start _start: ; 파라미터 전달 (레지스터 사용) mov eax, [num1] ; EAX = 10 mov ebx, [num2] ; EBX = 20 call add_numbers ; 함수 호출 ; 종료 (시스템 콜 예시로 대체 가능) mov eax, 1 ; sys_exit 시스템 콜 번호 int 0x80 ; 커널 호출 add_numbers: add eax, ebx ; EAX = EAX + EBX ret ; 결과 반환 특징: call 명령어로 직접 함수 주소로 점프 → 커널 개입 없이 사용자 공간에서 실행.","요약#\u003cstrong\u003e요약\u003c/strong\u003e":"일반 함수 호출: 사용자 공간 내에서 직접 실행되며, 빠르지만 권한이 제한적입니다. 시스템 콜: 커널의 매핑 테이블을 통해 간접적으로 실행되며, 모드 전환과 검증 과정을 거쳐 안전하게 하드웨어/커널 자원을 제어합니다. 예시: int 0x80은 커널의 인터럽트 핸들러를 호출해 시스템 콜 테이블을 조회하고, 실제 함수(예: sys_write)를 실행합니다."},"title":"일반 함수 호출 (User level Function Call) vs 시스템 콜 (System Call) 호출 방식의 차이"},"/02.inbox/%EC%A3%BC%EC%84%9D-%EC%9C%A0%ED%98%95-docstring/":{"data":{"":"","docstring-유형-라벨-분류#docstring 유형 라벨 (분류)":"한국어 영어 라벨 설명 설명 Description 함수/클래스의 기본 동작 설명 사용법 Usage 호출 방법, 예제 포함 예제 Example 실제 사용 예시 (\u003e\u003e\u003e) 포함 가능 매개변수 Parameters 입력 인자 설명 반환값 Returns 반환 값에 대한 설명 예외 Raises 발생 가능한 예외 설명 참고 See Also 관련된 함수/클래스 참조 문법 Syntax 문법 구조나 규칙 설명 성능 Performance 시간/공간 복잡도, 효율성 관련 주의사항 Note 경고 또는 주의해야 할 사항 변경이력 Change Log 변경 내역 (버전별 관리 시) 의존성 Dependencies 외부 모듈이나 라이브러리 요구사항"},"title":"주석 유형 docstring"},"/02.inbox/%EC%A3%BC%EC%86%8C-%EB%B0%94%EC%9D%B8%EB%94%A9-%EC%8B%A4%EC%8A%B5%EC%86%8C%EC%8A%A4%EC%BD%94%EB%93%9C-%EB%B6%80%ED%84%B0-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EA%B9%8C%EC%A7%80/":{"data":{"":"","1-실행-파일-생성#1. 실행 파일 생성":"오브젝트 파일을 링킹하여 실행 파일을 생성합니다. 이 과정에서 printf 같은 외부 함수의 주소도 연결됩니다.\ngcc addr_test.o -o addr_test","1-오브젝트-파일-생성#1. 오브젝트 파일 생성":"gcc의 -c 옵션은 링킹을 수행하지 않고 컴파일만 진행하여 오브젝트 파일을 생성합니다.\nBash\ngcc -c addr_test.c -o addr_test.o","1-주소-바인딩의-개념과-목적#1. 주소 바인딩의 개념과 목적":"**주소 바인딩(Address Binding)**이란 프로그램의 소스 코드에 사용된 변수나 함수 같은 심볼릭 주소(Symbolic Address)가 실제 물리 메모리(Physical Memory)의 주소로 변환되는 전체 과정을 의미합니다. 이 과정은 컴퓨터가 프로그램을 실행하기 위한 핵심적인 메커니즘입니다.","1-페이지-폴트page-fault-관찰-perf#1. 페이지 폴트(Page Fault) 관찰 (\u003ccode\u003eperf\u003c/code\u003e)":"가상 주소가 처음 접근될 때, 해당 데이터가 물리 메모리에 없다면 페이지 폴트가 발생합니다. 이때 OS는 디스크에서 데이터를 물리 메모리로 가져오고 페이지 테이블을 업데이트합니다. 이것이 바로 실행 시간 바인딩의 핵심 순간입니다.\n# -e page-faults 옵션으로 페이지 폴트 이벤트 카운팅 perf stat -e page-faults ./addr_test 출력 예시:\nAddress of initialized_global_var: 0x55d8b2f9a030 Address of main function: 0x55d8b2f98173 Performance counter stats for './addr_test': 105 page-faults 0.001099684 seconds time elapsed 105개의 페이지 폴트가 발생했음을 보여줍니다. 이는 프로그램 실행에 필요한 코드/데이터 페이지가 실행 시점에 동적으로 물리 메모리에 바인딩되었음을 의미합니다.","1-프로세스-실행-및-pid-확인#1. 프로세스 실행 및 PID 확인":"프로세스를 백그라운드로 실행하고 해당 PID(Process ID)를 변수에 저장합니다.\n./addr_test \u0026 PID=$!","2-가상-주소--물리-주소-매핑-확인-pagemap-고급#2. 가상 주소 → 물리 주소 매핑 확인 (\u003ccode\u003epagemap\u003c/code\u003e, 고급)":"/proc//pagemap 파일은 각 가상 페이지에 대한 물리 페이지 프레임 번호(PFN) 정보를 담고 있습니다. 이를 통해 최종적인 가상-물리 주소 매핑을 직접 확인할 수 있지만, 루트 권한이 필요하며 파싱이 복잡합니다. 이는 주소 변환의 가장 낮은 수준을 보여주는 증거입니다.\n관심 있는 사용자는 kernel.org의 pagemap 문서를 참조하여 직접 스크립트를 작성해볼 수 있습니다.","2-실습-환경-구성#2. 실습 환경 구성":"실습을 위해 간단한 C 코드를 작성합니다. 이 코드는 전역 변수, 함수 등을 포함하여 각 단계별 변화를 관찰하기에 용이합니다.","2-실행-파일의-심볼-주소-확인-readelf#2. 실행 파일의 심볼 주소 확인 (\u003ccode\u003ereadelf\u003c/code\u003e)":"readelf -s는 ELF(Executable and Linkable Format) 형식 파일의 심볼 테이블을 더 상세히 보여줍니다.\nreadelf -s ./addr_test | grep 'main\\|function\\|initialized' 출력 예시 및 분석:\n38: 0000000000004030 4 OBJECT GLOBAL DEFAULT 15 initialized_global_var 63: 0000000000001159 26 FUNC GLOBAL DEFAULT 14 function 69: 0000000000001173 69 FUNC GLOBAL DEFAULT 14 main 이제 주소(0x4030, 0x1159 등)는 0이 아닌, 가상 메모리 주소로 확정되었습니다. 이 주소는 프로세스가 시작될 때 할당될 논리적인 주소이며, 모든 심볼이 고유한 가상 주소를 갖게 됩니다.","2-심볼-테이블-분석-nm#2. 심볼 테이블 분석 (\u003ccode\u003enm\u003c/code\u003e)":"nm 도구는 오브젝트 파일의 심볼 테이블을 보여줍니다. 이를 통해 각 심볼이 어떤 섹션에, 어떤 상대 주소로 할당되었는지 확인할 수 있습니다.\nnm addr_test.o 출력 예시 및 분석:\n000000000000001e T function 0000000000000000 D initialized_global_var 0000000000000035 T main U printf 0000000000000004 C uninitialized_global_var ... 주소: 0x00...으로 시작하는 이 값들은 최종 메모리 주소가 아닌, 파일 내의 **상대 주소(오프셋)**입니다. 심볼 타입: T: .text 섹션(코드)에 위치한 심볼. main, function 함수가 해당됩니다. D: .data 섹션(초기화된 데이터)에 위치한 심볼. initialized_global_var가 해당됩니다. C: Common 심볼. 초기화되지 않은 전역 변수(uninitialized_global_var)로, 크기만 명시되고 최종 위치는 링커가 결정합니다. U: Undefined. 이 파일 내에 정의되지 않은 심볼로, printf처럼 외부 라이브러리에서 가져와야 함을 의미합니다.","2-프로세스-메모리-맵-확인-pmap#2. 프로세스 메모리 맵 확인 (\u003ccode\u003epmap\u003c/code\u003e)":"pmap은 특정 프로세스의 메모리 맵을 보여주는 강력한 도구입니다.\npmap $PID 출력 예시 및 분석:\n000055a3d0ab4000 4K r-xp /path/to/addr_test \u003c-- Code (.text) 000055a3d0acb000 4K r--p /path/to/addr_test \u003c-- Read-only data 000055a3d0acc000 4K rw-p /path/to/addr_test \u003c-- Read-write data (.data, .bss) ... 00007ffc8d9e8000 132K rw-p [stack] \u003c-- Stack ... 첫 번째 열: 각 메모리 영역의 시작 가상 주소입니다. ASLR (Address Space Layout Randomization) 때문에 프로그램을 실행할 때마다 이 시작 주소는 변경될 수 있습니다. readelf에서 본 오프셋은 유지된 채, 전체적인基底 주소(Base Address)가 바뀌는 것입니다.","3-1단계-컴파일-시간-바인딩-compile-time-binding#3. 1단계: 컴파일 시간 바인딩 (Compile-Time Binding)":"목표: 소스 코드의 심볼릭 주소(변수명, 함수명)가 컴파일러에 의해 재배치 가능한(Relocatable) 주소로 변환되는 과정을 확인합니다. 이 주소는 각 오브젝트 파일(.o) 내에서의 상대적인 오프셋(offset)입니다.","3-proc-파일-시스템으로-확인#3. \u003ccode\u003e/proc\u003c/code\u003e 파일 시스템으로 확인":"/proc//maps 파일은 pmap보다 더 상세한 정보를 제공합니다.\ncat /proc/$PID/maps 출력 형식은 pmap과 유사하지만, 파일 오프셋, 디바이스/inode 정보 등 더 많은 세부 정보를 포함합니다. 이 파일을 통해 코드, 데이터, 스택, 힙 및 동적 라이브러리가 가상 주소 공간에 어떻게 배치되었는지 명확히 볼 수 있습니다.","3-섹션별-상세-분석-objdump#3. 섹션별 상세 분석 (\u003ccode\u003eobjdump\u003c/code\u003e)":"objdump -d는 코드 섹션(.text)을 디스어셈블하여 명령어 수준에서 상대 주소를 보여줍니다.\nobjdump -d addr_test.o 출력된 어셈블리 코드에서 call이나 mov 명령어의 대상 주소가 0 또는 상대적인 값으로 표시된 것을 볼 수 있습니다. 이는 링커가 채워주어야 할 부분입니다.","4-2단계-링크-시간-바인딩-link-time-binding#4. 2단계: 링크 시간 바인딩 (Link-Time Binding)":"목표: 링커가 여러 오브젝트 파일과 라이브러리를 결합하여 단일 실행 파일을 만드는 과정을 확인합니다. 이 과정에서 재배치 가능 주소는 프로그램의 가상 주소 공간(Virtual Address Space) 내의 **절대 주소(Absolute Address)**로 확정됩니다.","5-3단계-적재-시간-바인딩-load-time-binding#5. 3단계: 적재 시간 바인딩 (Load-Time Binding)":"목표: 운영체제(OS)의 로더(Loader)가 실행 파일을 메모리에 올릴 때, 프로그램의 각 세그먼트(코드, 데이터 등)가 프로세스의 가상 주소 공간에 어떻게 매핑되는지 확인합니다.","6-4단계-실행-시간-바인딩-execution-time-binding#6. 4단계: 실행 시간 바인딩 (Execution-Time Binding)":"목표: 프로그램이 실제로 실행되는 동안 MMU(Memory Management Unit) 하드웨어가 가상 주소를 물리 주소로 동적으로 변환하는 개념을 간접적으로 확인합니다. 현대 OS는 대부분 이 방식을 사용합니다.","7-전체-과정-요약#7. 전체 과정 요약":"바인딩 단계 목적 핵심 도구 주소의 상태 컴파일 시간 심볼릭 주소를 상대 주소로 변환 gcc -c, nm, objdump 재배치 가능 주소 (Relocatable Address) 링크 시간 여러 오브젝트를 묶어 가상 주소 결정 gcc, readelf -s 절대 가상 주소 (Absolute Virtual Address) 적재 시간 실행 파일을 프로세스 가상 공간에 매핑 pmap, /proc/PID/maps 가상 메모리 주소 (Mapped Virtual Address) 실행 시간 MMU가 가상 주소를 물리 주소로 변환 MMU (HW), perf, /proc/PID/pagemap 물리 주소 (Physical Address)","목적#목적":"재배치(Relocation): 프로그램을 메모리의 어느 위치에든 적재하여 실행할 수 있도록 합니다. 만약 주소가 고정되어 있다면 여러 프로그램을 동시에 실행하기 어렵습니다. 메모리 보호(Memory Protection): 각 프로세스가 자신에게 할당된 메모리 영역만 접근하도록 격리하여 시스템의 안정성을 높입니다. 메모리 효율성 증대: 가상 메모리(Virtual Memory), 공유 라이브러리(Shared Library) 등의 기법을 통해 한정된 물리 메모리를 여러 프로세스가 효율적으로 나누어 사용할 수 있게 합니다. 본 문서는 리눅스 CLI 환경에서 제공하는 다양한 도구를 활용하여, 컴파일 → 링크 → 적재 → 실행 각 단계에서 주소 바인딩이 어떻게 이루어지는지 구체적인 명령과 출력을 통해 심층적으로 추적하고 분석하는 것을 목표로 합니다.","예제-코드-addr_testc#예제 코드 (\u003ccode\u003eaddr_test.c\u003c/code\u003e)":"#include int initialized_global_var = 10; int uninitialized_global_var; const int const_global_var = 20; void function(void) { printf(\"Function address\\n\"); } int main(void) { static int static_local_var = 30; int local_var = 40; function(); printf(\"Address of initialized_global_var: %p\\n\", \u0026initialized_global_var); printf(\"Address of main function: %p\\n\", main); return 0; }","주소-바인딩address-binding-과정-심층-분석#주소 바인딩(Address Binding) 과정 심층 분석":""},"title":"주소 바인딩 실습(소스코드 부터 프로세스까지)"},"/02.inbox/%EC%B2%AD%EB%85%84%EC%B0%BD%EC%97%85-2025-%EC%B0%BD%EC%97%85-%EA%B8%B0%EC%A4%80/":{"data":{"":"2025년 창업 시 적용 기준 정리 표 항목 2024년 이전 창업 2025년 창업 설명 고용증대 추가감면율 최대 50% 최대 100% 상시근로자 증가율에 100% 적용 (기존 50% → 100% 상향) 감면한도 무제한 연간 5억 원 한도 세액감면 금액이 연간 5억 원으로 제한됨 (일반 중소기업 규모에서는 실제 영향 적음) 업종 우대감면 특정 업종 적용 기존 정책 종료 (세부 내용 미기재) ※ 기존 업종 우대감면 정책 종료, 새로운 정책 적용되나 구체적 내용은 제공된 자료에 없음 수도권 감면율 기존 적용 기존 적용 수도권 감면율 축소는 2026년 1월 1일 이후 창업부터 적용되며, 2025년 창업에는 영향 없음","-2025년-창업-시-적용-기준-요약표#📊 2025년 창업 시 적용 기준 요약표":"구분 적용 내용 비고 ✅ 적용 대상자 - 창업 당시 만 15세 이상 ~ 34세 이하 청년\n- 병역 이행자: 복무기간(최대 6년) 차감 후 연령 계산\n- 법인: 청년이 최대주주 또는 최대출자자여야 함 개인사업자/법인 모두 가능 ✅ 감면 기간 창업 후 첫 소득 발생 연도로부터 5년간 일반 창업중소기업과 동일 ✅ 적용 업종 조세특례제한법상 지정 업종만 가능\n▶ 음식점, 미용실, 피트니스센터, 디자인업, 출판사, 통신판매업, 제조업, 사회복지업 등 포함 ⚠️ 2025년 창업부터 ‘업종 우대감면’ 종료\n→ 기존 일부 업종에 추가로 주던 우대 혜택 없어짐 ✅ 감면율 (지역별) - 비수도권: 100% 감면\n- 수도권 과밀억제권역: 50% 감면\n- 수도권 내 과밀억제권역外 (인천경제자유구역, 김포, 파주 등): 100% 감면 (2025년까지는 기존 혜택 유지) ⚠️ 수도권 감면율 축소는 2026년 1월 1일 이후 창업부터 적용\n→ 2025년 창업자는 기존 혜택 그대로 받음 ✅ 고용증대 추가감면 기존보다 상향 적용\n- 고용인원 증가시 추가 감면율 ↑\n- 구체적 비율은 세법 시행령 참조 2025년 창업자 대상으로 고용증대 감면 혜택 확대 ✅ 감면 한도 연간 최대 5억 원으로 제한 2025년 창업부터 신설된 한도\n→ 감면액이 5억 원을 초과하면 그 이상은 감면 불가 ✅ 신고 요건 - 복식부기 의무자: 반드시 복식부기로 신고해야 감면 가능\n- 간편장부 대상자: 추계신고도 가능 무신고, 기한 후 신고, 간편장부(복식부기 의무자) 신고 시 감면 불가 ❌ 신규 창업 불인정 사례 ① 기존 사업 승계(합병/양수 등)\n② 개인→법인 전환\n③ 폐업 후 동일 업종 재개업\n④ 사업 확장 또는 업종 추가 신규 창업으로 인정되지 않으면 감면 불가","-주요-설명#📌 주요 설명":"고용증대 추가감면율\n2025년 이후 창업 기업은 고용 증가율에 따라 최대 100% 추가 감면 적용 예) 기존 50% → 100%로 상향되며, 고용 증가율 100% 시 추가 100% 감면 가능 감면한도\n2025년부터 연간 5억 원 한도 도입 기존에는 한도 없었으나, 최대 감면액이 5억 원으로 제한됨 소규모 자영업자 대부분은 이 한도에 도달하지 않아 실질적 영향 적음 업종 우대감면\n제공된 자료에 구체적 설명 없음 다만 기존 업종(음식점, 미용실, 제조업 등)은 여전히 감면 대상으로 적용됨 “종료\"라는 표현은 기존 정책 체계의 종료를 의미할 수 있으나, 세부 내용은 확인 불가 수도권 감면율\n2026년 창업부터 적용되는 사항으로, 2025년 창업에는 영향 없음 수도권을 △과밀억제권역 △과밀억제권역이 아닌 수도권 △비수도권으로 세분화해 적용 2025년 창업자는 기존 수도권 규정 적용 (비수도권 100% 감면, 수도권 50% 감면 등) 💡 참고: 2025년 창업자도 여전히 음식점, 미용실, 피트니스센터, 디자인업, 출판사, 통신판매업, 제조업 등 기존 업종에서 창업 시 세액감면 적용 가능합니다. 다만 감면율 계산 방식과 한도가 변경되었음을 유의하세요.\n아래는 2025년에 창업한 경우 적용받는 ‘청년창업중소기업 세액감면’ 기준을, 본문에서 언급된 4가지 핵심 변경 사항(△업종 우대감면 종료, △고용증대 추가감면 상향, △감면한도 연 5억 원 제한, △수도권 감면율 축소는 2026년 적용)을 정확히 반영하여 정리한 표입니다.\nInfo\n성남시의 경우 과밀억제권역","-핵심-포인트-요약#🔍 핵심 포인트 요약":"업종 우대감면 종료\n→ 2025년 창업부터는 특정 업종(예: 문화콘텐츠, 지식서비스 등)에 추가로 주던 우대 감면이 완전히 사라짐. 모든 지정 업종은 동일한 기본 감면율 적용.\n고용증대 감면 상향\n→ 청년창업기업이 고용을 늘릴 경우, 기존보다 더 큰 추가 감면 혜택 제공 (구체적 %는 국세청 고시 참조).\n감면 한도 연 5억 원\n→ 1년간 감면받을 수 있는 세액 총액이 최대 5억 원으로 제한됨. 이는 청년창업자에게도 동일하게 적용.\n수도권 감면율 축소는 2026년부터\n→ 2025년 창업자는 기존 감면율 그대로 적용\n- 비수도권: 100%\n- 수도권 과밀억제권역外: 100% (인천경제자유구역, 김포, 파주 등 포함)\n- 수도권 과밀억제권역: 50%\n✅ 결론: 2025년 창업자는 ‘업종 우대감면 종료’, ‘고용증대 감면 확대’, ‘연 5억 한도’는 적용받지만, ‘수도권 감면율 축소’는 적용되지 않음.\n→ 수도권 외곽(김포, 파주 등)에서 창업할 계획이라면, 2025년 안에 창업하는 것이 혜택 면에서 유리함.\nInfo\n복식부기 의무자란\nhttps://mybiz.pay.naver.com/contentsGuide/271\nInfo\n개인사업자와 취업과의 관계\nhttps://m.kin.naver.com/qna/dirs/40309/docs/482005709?answerNo=1\nhttps://www.jobkorea.co.kr/User/Qstn/AnswerWrite?qstnNo=47800\nhttps://www.a-ha.io/questions/4ef9d03e9e90b44998c5cdb07a45bfd4","2025년-창업-시-적용-기준-정리-표#2025년 창업 시 적용 기준 정리 표":""},"title":"청년창업 2025 창업 기준"},"/02.inbox/%EC%BB%B4%ED%93%A8%ED%84%B0-%EA%B5%AC%EC%A1%B0-chapter1/":{"data":{"":"","a-tour-of-computer-systems#A Tour of Computer Systems":"1.1 Information Is Bits + Context 39 정보는 비트 + 문맥이다 동일한 비트열이 문맥에 따라 string integer floating-point instruction 으로 해석될수 있다 1.2 Programs Are Translated by Other Programs into Different Forms 40 1.3 It Pays to Understand How Compilation Systems Work 42 1.4 Processors Read and Interpret Instructions Stored in Memory 43 1.5 Caches Matter 47 1.6 Storage Devices Form a Hierarchy 50 1.7 The Operating System Manages the Hardware 50 1.8 Systems Communicate with Other Systems Using Networks 55 1.9 Important Themes 58 1.10 Summary 63 Bibliographic Notes 64 Solutions to Practice Problems 64 direct memory access (DMA, discussed in Chap- ter 6) cache memories chapter6 공유 라이브러리 주소 공간 chapter 7 kernel vietual memory 가 뭐지?? chapter 9 unix i o chapter 10 Thread-Level Concurrency vs instruction level parallelism 의 차이 12장 에서 하이퍼스레딩? 5장에서 instruction ?? 파이프라닝 chapter4\n62page\nThread level concurrency instruction level parallelism single instruction multiple data parallelism ?? relocatable object program 과 excutable object program 의 차이 hello.o 파일에서 내부의 printf 함수의 구현은 printf.o라는 별도의 사전 컴파일된 개체 파일에 있으며, 이 파일은 어떻게든 우리의 hello.o 프로그램과 병합되어야 합니다. 이 병합을 링커(ld)가 처리합니다. 재배치 가능한 오브젝트 프로그램은 컴파일러나 어셈블러가 소스 코드를 컴파일하여 생성한 중간 단계의 파일 .o 파일이며 링크 단계 통과후 실행파일이 됩니다\nbuses 는 word 라는 단위로 잘려져 전송된다 여기서 워드의 크기는 시스템에 따라 달라진다 32 비트에서는 4바이트 64 비트는 8바이트 이다 즉 워드라는 것은 시스템에서 사용하는 기본적인 전송 단위로서 고정적인 단위가 아닌 추상 단위이다\nio 장치는 io 버스에 컨트롤러 또는 아탑터 로 연결된다 둘의 차이는 #ModificationRequired\nmain memory 는 바이트 1개가 하나의 주소에 매핑된다 주소는 0부터\n프로세서는 instruction set 을 구현한 것은 맞지만 실제로는 실행속도를 빠르게 하는 여러가지 기술을 지원한다 즉 동일한 instruction set을 해석하는 프로세스의 구현은 많이 다를 수 있다\nL1 L2 cache 는 sram 이고 main memory 는 dram 이다\n%20image%2020240619110245.png)\n프로세스의 메모리 자원 (코드 데이터 힙 스텍 레지스터 ) 쓰레드 메모리 자원( 스텍 레지스터 ) 나머지는 공유한다\n1 클록에 1개 이상의 명령을 수행하는 프로세서를 puperscalar 라고 한다\nword 는 포인터의 크기를 나타내는 자료형이다 크기는 컴퓨터 비트 마다 다르다"},"title":"컴퓨터 구조 chapter1"},"/02.inbox/%ED%84%B0%EB%AF%B8%EB%84%90-%EB%8F%99%EC%9E%91-%EC%9B%90%EB%A6%AC-%EB%A7%A4%EC%9A%B0-%EC%83%81%EC%84%B8%ED%95%98%EA%B2%8C/":{"data":{"":"","1-커널의-tty-서브시스템-tty-subsystem--tty-core#1. 커널의 \u003cstrong\u003eTTY 서브시스템 (TTY Subsystem / TTY Core)\u003c/strong\u003e":"이것이 흔히 사람들이 “커널의 TTY 드라이버\"라고 넓은 의미로 말할 때 가리키는 대상입니다. TTY 서브시스템은 특정 하드웨어나 PTY에 종속되지 않는, 터미널의 핵심 동작 로직을 담고 있는 커널의 공통 모듈입니다.\n역할: 터미널의 “두뇌” 또는 “공통 로직\"입니다. 주요 기능 (Line Discipline): 입력 편집 (Line Buffering): cooked 모드에서 줄 단위로 입력을 모으고, Backspace 등을 처리합니다. 문자 에코 (Echo): 입력된 문자를 되돌려 보내 화면에 보이게 합니다. 신호 생성 (Signal Generation): Ctrl+C 같은 제어 문자를 SIGINT 같은 실제 신호로 변환합니다. 흐름 제어 (Flow Control): 데이터가 너무 빨리 오고 갈 때 이를 조절합니다. (주로 시리얼 통신에서 중요) 문자 변환: Enter 키를 \\n(LF) 또는 \\r\\n(CRLF)으로 변환하는 등의 규칙을 적용합니다. 특징: 이 서브시스템은 추상화되어 있습니다. 데이터가 실제 물리적인 시리얼 포트에서 오는지, 가상 터미널인 PTY에서 오는지는 신경 쓰지 않습니다. 그저 자신에게 데이터를 넣어주고, 자신이 처리한 데이터를 가져갈 하위 드라이버가 있기만 하면 됩니다.","2-커널의-pty-드라이버-pty-driver#2. 커널의 \u003cstrong\u003ePTY 드라이버 (PTY Driver)\u003c/strong\u003e":"PTY 드라이버는 TTY 서브시스템에 연결되는 여러 종류의 하위 드라이버 중 하나입니다. 실제 하드웨어를 제어하는 대신, 소프트웨어적으로 터미널 장치를 흉내 내는 역할을 전문적으로 수행합니다.\n역할: TTY 서브시스템을 위한 **“가상 하드웨어 드라이버”**입니다. 주요 기능: 마스터-슬레이브 쌍 생성: ioctl 등을 통해 터미널 에뮬레이터가 사용할 마스터(Master) FD와 셸이 사용할 슬레이브(Slave) FD라는 한 쌍의 통신 채널을 만듭니다. 데이터 중계: 마스터 측에서 온 데이터(터미널 에뮬레이터의 입력)를 TTY 서브시스템으로 밀어 넣습니다. TTY 서브시스템이 처리를 마친 데이터(셸에게 갈 데이터)를 슬레이브 측에서 읽을 수 있게 해줍니다. 슬레이브 측에서 온 데이터(셸의 출력)를 마스터 측으로 그대로 전달합니다. 특징: PTY 드라이버 자체는 Echo나 Line Buffering 같은 복잡한 로직을 가지고 있지 않습니다. 이 모든 작업은 TTY 서브시스템에 위임합니다. PTY 드라이버의 핵심 임무는 오직 가상의 데이터 통로를 만들고 유지하는 것입니다.","case-1-사용자가#\u003cstrong\u003eCase 1: 사용자가 \u003ccode\u003els\u003c/code\u003e를 입력하고 Enter를 누를 때 (가장 기본적인 흐름)\u003c/strong\u003e":"사용자: 키보드를 사용하여 l, s, 그리고 Enter 키를 순서대로 누릅니다.\n터미널 에뮬레이터 (예: gnome-terminal): 운영체제로부터 키보드 입력 이벤트를 전달받습니다. 이 프로그램은 각 키 입력이 어떤 바이트 데이터에 해당하는지 알고 있습니다.\nl 키 → 바이트 0x6C s 키 → 바이트 0x73 Enter 키 → 개행(Line Feed) 문자를 의미하는 바이트 0x0A 이 바이트들을 순서대로, 자신이 프로세스를 시작할 때 열었던 PTY 마스터 파일 디스크립터(FD)에 씁니다(write 시스템 콜 사용). 커널 (PTY/TTY 드라이버) - 입력 수신 및 처리: 커널은 누군가 PTY 마스터 FD에 데이터를 썼다는 것을 인지하고, 해당 데이터를 자신의 버퍼로 읽어들입니다. 현재 터미널은 기본 모드인 cooked (또는 canonical) 모드로 동작하고 있으므로, 커널 드라이버는 다음과 같은 규칙을 적용합니다.\nEcho 기능: 첫 번째 바이트 0x6C(l)를 읽자마자, 사용자가 자신이 무엇을 입력하고 있는지 볼 수 있도록 이 바이트를 즉시 PTY 마스터 FD 쪽으로 다시 써줍니다. 터미널 에뮬레이터 (Echo 표시): 자신의 마스터 FD에서 읽을 데이터(0x6C)가 생긴 것을 감지하고, 이를 읽어 화면의 커서 위치에 l이라는 문자를 렌더링합니다. 커널 드라이버 (Echo 반복): 두 번째 바이트 0x73(s)에 대해서도 동일한 Echo 과정을 수행합니다. 터미널 에뮬레이터는 화면에 s를 이어서 표시합니다. 이제 화면에는 ls가 보입니다. Line Buffering 기능: 커널 드라이버는 l과 s를 Echo 처리함과 동시에, 자신의 **내부 라인 버퍼(line buffer)**에 이 문자들을 차곡차곡 쌓아둡니다. 이 버퍼는 셸과 같은 최종 애플리케이션에 아직 전달되지 않은, 편집 중인 한 줄의 데이터를 임시로 보관하는 장소입니다. Line Completion 기능: 마지막으로 0x0A(Enter) 바이트를 읽습니다. 커널 드라이버는 이 문자를 “한 줄 입력의 끝\"으로 해석합니다. 이제 라인 버퍼에 저장되어 있던 ls와 방금 들어온 \\n을 합쳐, ls\\n이라는 완전한 한 줄의 데이터를 확정합니다. 커널 (PTY 드라이버) - 데이터 전달: 완성된 ls\\n 데이터를 이제 PTY 슬레이브 파일 디스크립터(FD)에서 읽을 수 있도록 준비시킵니다. (정확히는, 슬레이브 FD를 read() 하고 있던 프로세스를 깨워서 데이터를 전달할 준비를 합니다.)\n셸 (bash): 셸 프로세스는 시작된 이후로 계속해서 자신의 표준 입력(stdin), 즉 PTY 슬레이브 FD에 새로운 입력이 들어오기를 기다리며 대기(block)하고 있었습니다. 커널이 데이터를 준비시켰으므로, 셸은 read() 시스템 콜을 통해 드디어 ls\\n 데이터를 읽어들입니다.\n셸 (명령어 해석 및 실행): 셸은 읽어들인 ls\\n 문자열을 해석합니다. 공백과 개행 문자를 기준으로 첫 번째 단어인 ls를 실행할 명령어로 인식합니다. 셸은 fork()와 execve() 시스템 콜을 사용하여 ls라는 새로운 프로세스를 생성하고 실행합니다. 이때, 자식 프로세스인 ls는 부모인 셸의 표준 입출력을 상속받으므로, ls의 표준 출력(stdout) 역시 PTY 슬레이브 FD를 가리키게 됩니다.\nls 프로세스: ls 프로그램은 현재 디렉토리의 파일 및 폴더 목록을 조회하여 텍스트 데이터(예: file1.txt\\nfolder1\\nfile2.txt\\n)를 생성합니다. 이 결과 텍스트를 자신의 표준 출력(stdout)인 PTY 슬레이브 FD에 씁니다.\n커널 (PTY 드라이버) - 출력 중계: 슬레이브 측에 데이터가 쓰인 것을 감지하고, 이 데이터를 그대로 **PTY 마스터 FD 쪽으로 전달(중계)**합니다.\n터미널 에뮬레이터 - 결과 렌더링: 터미널 에뮬레이터는 항상 자신의 PTY 마스터 FD에 읽을 데이터가 있는지 주시하고 있습니다. ls의 결과 텍스트가 도착하면, 이를 읽어서 화면에 렌더링합니다. 만약 텍스트에 색상 등을 위한 이스케이프 시퀀스가 포함되어 있다면, 이를 해석하여 색깔 있는 텍스트로 표시합니다.\n💡 이 시나리오의 핵심: 사용자의 키 입력이 터미널 에뮬레이터 → 커널 드라이버(마스터 측) → 커널 드라이버의 처리(Echo, Buffering) → 커널 드라이버(슬레이브 측) → 셸 순서로 전달되고, 명령어의 결과는 역순으로 사용자에게 돌아오는 가장 기본적인 파이프라인 구조를 보여줌.","case-2-사용자가#\u003cstrong\u003eCase 2: 사용자가 \u003ccode\u003eCtrl+C\u003c/code\u003e를 누를 때 (신호 처리)\u003c/strong\u003e":"상황: 사용자가 셸에서 sleep 100 같은 오래 걸리는 명령을 실행시킨 상태입니다. 이 sleep 프로세스는 현재 터미널 세션의 전면(foreground) 프로세스입니다.\n사용자: 명령을 중단시키기 위해 Ctrl 키와 C 키를 동시에 누릅니다.\n터미널 에뮬레이터: 이 키 조합이 일반적인 문자 입력이 아니라 특별한 제어 명령임을 인지합니다. 유닉스 터미널 규약에 따라 Ctrl+C는 INTR (interrupt) 제어 문자에 해당하며, 이는 ASCII 코드 3 (0x03, End of Text)에 매핑됩니다. 터미널 에뮬레이터는 이 0x03 바이트 하나를 PTY 마스터 FD에 씁니다.\n커널 (PTY/TTY 드라이버) - 제어 문자 해석: 커널 드라이버는 마스터 측에서 0x03 바이트를 읽습니다. 터미널이 cooked 모드이고, ISIG (Interpret Signals) 플래그가 켜져 있는 상태이므로, 커널은 이 바이트를 일반 데이터로 취급하지 않습니다. 대신, 터미널 설정(termios)을 참조하여 0x03이 VINTR 문자와 일치함을 확인하고, 이를 “SIGINT 신호를 생성하라\"는 이벤트로 변환합니다.\n커널 (프로세스 관리 모듈): PTY/TTY 드라이버로부터 신호 생성 요청을 받습니다. 커널은 이 PTY 세션과 연결된 **“전면 프로세스 그룹(foreground process group)”**을 찾습니다. 이 그룹에는 현재 명령을 실행하고 있는 sleep 100 프로세스가 포함되어 있습니다.\n커널 (신호 전달): 커널은 해당 전면 프로세스 그룹에 속한 모든 프로세스에게 SIGINT 신호를 전달합니다.\nsleep 프로세스: SIGINT 신호를 수신합니다. sleep 프로그램은 이 신호에 대한 별도의 처리기(handler)를 등록해두지 않았으므로, 신호에 대한 **기본 동작(default action)**을 수행합니다. SIGINT의 기본 동작은 “프로세스 종료” 입니다.\n프로세스 종료: sleep 100 프로세스는 즉시 종료됩니다.\n셸: 자식 프로세스(sleep)가 종료되었음을 감지하고, 다음 명령을 입력받기 위해 새로운 프롬프트를 화면에 출력합니다. (이 과정은 Case 1의 7~9번과 유사하게 진행됩니다.)\n💡 이 시나리오의 핵심: 터미널 에뮬레이터는 단지 특정 바이트(0x03)를 보낼 뿐, 실제 그 바이트를 해석하여 운영체제 수준의 이벤트(신호)로 변환하고, 올바른 대상(전면 프로세스 그룹)에게 전달하는 복잡한 작업의 주체는 전적으로 커널임.","case-3-사용자가-입력-중#\u003cstrong\u003eCase 3: 사용자가 입력 중 \u003ccode\u003eBackspace\u003c/code\u003e로 수정할 때 (입력 편집)\u003c/strong\u003e":"사용자: ls를 입력하려다가 실수로 lp를 입력하는 상황을 가정합니다. 키보드로 l, s, Backspace, p, Enter 순으로 누릅니다.\n터미널 에뮬레이터: 각 키 입력에 해당하는 바이트들을 순서대로 PTY 마스터 FD에 씁니다.\nl → 0x6C s → 0x73 Backspace → 0x08 (Backspace 제어 문자) p → 0x70 Enter → 0x0A 커널 (PTY/TTY 드라이버) - 단계별 처리: cooked 모드의 커널 드라이버가 이 바이트 스트림을 순차적으로 처리합니다.\nl, s 수신: Case 1과 동일하게, l과 s를 Echo하여 마스터 FD로 되돌려 보내고, 내부 라인 버퍼에는 ls를 저장합니다. 터미널 화면에는 ls가 보입니다. Backspace(0x08) 수신: 커널 드라이버는 터미널 설정(termios)을 참조하여 0x08이 VERASE (지우기) 문자와 일치함을 확인합니다. 이를 “라인 버퍼에서 한 글자 지우기” 명령으로 해석합니다. 버퍼 수정: 내부 라인 버퍼의 맨 끝에 있던 s를 삭제합니다. 이제 라인 버퍼의 내용은 l이 됩니다. 화면 수정 지시: 사용자가 시각적으로도 글자가 지워졌음을 인지할 수 있도록, 화면을 수정하라는 지시를 터미널 에뮬레이터에게 보내야 합니다. 가장 일반적인 방법은 “커서를 한 칸 뒤로, 그 자리에 공백을 출력, 다시 커서를 한 칸 뒤로” 라는 동작을 유발하는 제어 시퀀스를 보내는 것입니다. 이 시퀀스는 보통 \\b \\b (바이트 0x08, 0x20, 0x08) 입니다. 커널 드라이버는 이 세 바이트를 PTY 마스터 FD 쪽으로 써줍니다. 터미널 에뮬레이터 (화면 수정): 마스터 FD에서 \\b \\b 시퀀스를 읽고, 이를 명령으로 해석하여 화면의 커서를 한 칸 뒤로 옮겼다가, 공백을 찍어 s를 덮어쓰고, 다시 커서를 그 자리로 돌려놓습니다. 이제 화면에는 l만 보이고 커서는 그 뒤에서 깜빡입니다. p 수신: 커널 드라이버는 p(0x70)를 수신합니다. Echo 기능에 의해 이 바이트를 마스터 FD로 되돌려 보내고, 수정된 라인 버퍼(l) 뒤에 p를 추가합니다. 라인 버퍼는 이제 lp가 됩니다. 터미널 화면에는 lp가 표시됩니다. Enter 수신: Enter(0x0A)를 수신하고, 한 줄 입력이 끝났다고 판단합니다. 최종적으로 확정된 라인 버퍼의 내용 lp와 \\n을 합쳐 lp\\n을 만듭니다. 커널 (PTY 드라이버) -\u003e 셸: 사용자의 모든 오타와 수정 과정은 커널 드라이버 수준에서 모두 처리되었습니다. 셸에게는 오직 최종 결과물인 lp\\n 만 PTY 슬레이브 FD를 통해 전달됩니다.\n셸: lp\\n을 읽고 lp라는 명령을 실행하려 하지만, 그런 명령이 없으므로 “command not found” 같은 오류 메시지를 표준 에러(stderr)로 출력합니다. 이 오류 메시지는 Case 1의 7~9번과 같은 경로를 통해 터미널 화면에 표시됩니다.\n💡 이 시나리오의 핵심: 우리가 당연하게 여기는 한 줄 내의 간단한 입력 편집(글자 추가, 삭제)조차 애플리케이션(셸)이 아니라 커널의 TTY 드라이버가 담당하는 중요한 기능임. 셸은 이런 편집 과정을 전혀 알지 못하고, 깨끗하게 정제된 최종 입력 라인만 전달받음.","case-4#\u003cstrong\u003eCase 4: \u003ccode\u003eread -s\u003c/code\u003e로 비밀번호를 입력할 때 (터미널 모드 변경)\u003c/strong\u003e":"셸: 사용자가 셸 프롬프트에서 read -s password와 같은 명령이 포함된 스크립트를 실행합니다. 셸은 이 명령을 해석하여 read 내장 명령어나 관련 유틸리티를 실행합니다.\nread 명령어 (ioctl 호출): read 명령어는 -s (silent) 옵션을 인지합니다. 비밀번호 입력을 화면에 표시하지 않기 위해, 자신의 표준 입력(stdin)인 **PTY 슬레이브 파일 디스크립터(FD)**에 대해 ioctl() 시스템 콜을 호출합니다. 이 시스템 콜은 커널에게 “이 터미널의 설정을 변경해달라\"고 요청하는 것입니다. 구체적으로는 현재 터미널 속성을 가져와서 ECHO 플래그를 비활성화한 후, 변경된 속성을 다시 설정합니다.\n커널 (PTY/TTY 드라이버): ioctl() 호출을 수신하고, 해당 PTY 슬레이브에 대한 내부 설정에서 ECHO 기능을 끕니다. 이제부터 이 PTY 슬레이브로 들어오는 데이터는 자동으로 PTY 마스터 쪽으로 반사되지 않습니다.\n사용자: 화면에 프롬프트가 뜬 상태에서 비밀번호 pass를 입력합니다.\n터미널 에뮬레이터: 키보드 입력을 받아 p, a, s, s에 해당하는 바이트들을 순서대로 자신이 열고 있는 PTY 마스터 FD에 씁니다(write).\n커널 (PTY 드라이버): 마스터 측에 쓰인 p, a, s, s 바이트를 읽습니다. 하지만 현재 이 터미널 세션은 ECHO가 꺼져 있으므로, 이 바이트들을 다시 마스터 FD 쪽으로 써주지 않습니다.\n터미널 에뮬레이터: PTY 마스터 FD로부터 되돌아오는 데이터가 없으므로, 화면에 아무것도 그리지 않습니다. 사용자 눈에는 입력이 안 되는 것처럼 보입니다.\n커널 (PTY 드라이버): ECHO는 꺼졌지만, 여전히 cooked mode의 다른 기능(Line Buffering)은 활성화되어 있습니다. 따라서 수신한 pass를 내부 라인 버퍼에 저장합니다.\n사용자: 입력이 끝났음을 알리기 위해 Enter 키를 누릅니다.\n터미널 에뮬레이터: Enter 키에 해당하는 0x0A 바이트를 PTY 마스터 FD에 씁니다.\n커널 (PTY 드라이버): 0x0A 바이트를 수신하고, 한 줄 입력이 끝났다고 판단합니다. 버퍼에 저장해 둔 pass와 합쳐 pass\\n이라는 완전한 데이터를 만듭니다.\n커널 (PTY 드라이버): 완성된 pass\\n 데이터를 PTY 슬레이브 FD에서 읽을 수 있도록 준비시킵니다.\nread 명령어: 자신의 표준 입력(stdin)인 PTY 슬레이브 FD에서 읽기(read)를 시도하고, pass\\n 데이터를 가져옵니다. 이 데이터를 password 셸 변수에 저장합니다.\nread 명령어 (ioctl 복구): 비밀번호 입력 후, ECHO 플래그를 원래 상태로 되돌립니다.\n셸 프롬프트 복귀: 사용자 입력이 다시 화면에 표시되는 평상시 상태로 돌아옵니다.\n💡 이 시나리오의 핵심: 애플리케이션(read)이 ioctl()을 통해 커널 드라이버의 동작 모드를 일시적으로 변경하여 터미널의 기본 기능(Echo)을 제어함.","case-5#\u003cstrong\u003eCase 5: \u003ccode\u003evim\u003c/code\u003e 같은 전체 화면 프로그램을 실행할 때 (Raw 모드와 화면 렌더링)\u003c/strong\u003e":"셸: 사용자가 vim file.txt를 입력하고 Enter를 누르면, 셸은 vim 프로세스를 생성하고 실행합니다. 이때 vim의 표준 입출력/에러는 PTY 슬레이브 FD로 연결됩니다.\nvim (터미널 모드 변경): vim은 시작과 동시에, 전체 화면을 직접 제어하기 위해 ioctl() 시스템 콜을 호출합니다. 이 호출을 통해 커널 PTY/TTY 드라이버에게 터미널 모드를 cooked에서 raw 모드로 변경하도록 요청합니다.\nRaw 모드: ECHO, Line Buffering, 특수 문자(Ctrl+C 등)의 신호 변환, 입력 편집 등 커널이 제공하는 대부분의 편의 기능을 모두 끕니다. 이제 키 입력은 발생 즉시, 아무런 가공 없이 vim 프로세스에 전달됩니다. vim (화면 초기화): vim은 전체 화면을 새로 그려야 합니다. 이를 위해 터미널을 제어하는 이스케이프 시퀀스들을 생성하여 자신의 표준 출력(stdout)인 PTY 슬레이브 FD에 씁니다.\n예시 시퀀스: \\033[?1049h (대체 화면 버퍼 사용), \\033[2J (화면 전체 지우기), \\033[H (커서 홈 위치로 이동) 등. 커널 (PTY 드라이버): 슬레이브 측에 쓰인 이스케이프 시퀀스들을 읽습니다. raw 모드이므로 특별한 해석 없이 그대로 PTY 마스터 FD 쪽으로 전달합니다.\n터미널 에뮬레이터: PTY 마스터 FD에서 이스케이프 시퀀스들을 읽습니다. 이 바이트들을 화면에 문자로 출력하는 대신, 명령으로 해석하여 실행합니다. (화면을 지우고, 대체 버퍼를 활성화하는 등)\nvim (내용 렌더링): vim은 파일 내용, 상태 표시줄, 줄 번호 등을 포함한 텍스트를 계산하여 마찬가지로 PTY 슬레이브 FD에 씁니다. 이 데이터 역시 커널 드라이버를 거쳐 터미널 에뮬레이터로 전달되고 화면에 그려집니다.\n사용자: j 키를 눌러 커서를 아래로 이동시킵니다.\n터미널 에뮬레이터: j 키 입력을 받아 바이트(0x6A)를 PTY 마스터 FD에 씁니다.\n커널 (PTY 드라이버): raw 모드이므로 0x6A 바이트를 읽자마자 아무런 버퍼링이나 해석 없이 즉시 PTY 슬레이브 FD에서 읽을 수 있도록 준비시킵니다.\nvim: 슬레이브 FD에서 0x6A 바이트를 즉시 읽고, 이를 “커서를 한 줄 아래로 이동” 명령으로 내부적으로 해석합니다.\nvim (화면 업데이트): vim은 화면의 변화를 최소화하는 방식으로 필요한 업데이트를 계산합니다. 이 경우, 단지 커서 위치만 바꾸면 되므로, 커서 이동 이스케이프 시퀀스(예: \\033[11;5H - “11행 5열로 이동”)를 생성하여 PTY 슬레이브 FD에 씁니다.\n커널 (PTY 드라이버): 이 시퀀스를 그대로 PTY 마스터 FD 쪽으로 전달합니다.\n터미널 에뮬레이터: 마스터 FD에서 커서 이동 시퀀스를 읽고, 명령으로 해석하여 화면에 보이는 커서를 실제로 이동시킵니다.\n💡 이 시나리오의 핵심: raw 모드에서 커널 드라이버는 단순 중계자 역할로 바뀌고, 애플리케이션(vim)과 터미널 에뮬레이터가 이스케이프 시퀀스를 통해 화면의 모든 요소를 직접 제어함.","case-6-위쪽-화살표-키로-히스토리-검색할-때-애플리케이션의-시퀀스-해석#\u003cstrong\u003eCase 6: 위쪽 화살표 키로 히스토리 검색할 때 (애플리케이션의 시퀀스 해석)\u003c/strong\u003e":"사용자: 셸 프롬프트가 떠 있는 상태에서 위쪽 화살표(↑) 키를 누릅니다.\n터미널 에뮬레이터: 위쪽 화살표 키가 단일 ASCII 문자가 아니라는 것을 인지합니다. 터미널 종류(예: xterm)에 따라 미리 약속된 이스케이프 시퀀스로 변환합니다. 가장 일반적인 시퀀스는 \\033[A 입니다. 이 세 바이트(0x1B, 0x5B, 0x41)를 PTY 마스터 FD에 씁니다.\n커널 (PTY/TTY 드라이버): 마스터 측에서 이 세 바이트를 차례로 읽습니다. cooked 모드이지만, \\033[A는 커널이 특별히 신호로 바꾸거나 편집 명령으로 해석하는 시퀀스가 아닙니다. 따라서 이 바이트들을 일반적인 데이터로 취급하여 내부 라인 버퍼에 추가합니다.\n참고: Enter가 눌리지 않았으므로 아직 셸에게 전달되지는 않습니다. 커널 (PTY 드라이버): (이 부분은 셸의 설정에 따라 다릅니다. 대부분의 현대 셸은 아래와 같이 동작합니다.) bash나 zsh 같은 셸은 readline 라이브러리를 사용하며, 이 라이브러리는 효율적인 상호작용을 위해 시작 시 ioctl로 터미널을 canonical(cooked) 모드가 아닌, 약간 변형된 모드로 설정할 수 있습니다. 이 경우, \\033[A 같은 시퀀스가 입력되면 라인 버퍼링을 거치지 않고 즉시 셸에게 전달될 수 있습니다. 여기서는 더 일반적인 canonical 모드를 가정하고, 셸이 어떻게든 이 데이터를 읽는다고 가정하고 진행하겠습니다. (실제로는 read 시스템 콜이 바이트 단위로 읽을 수 있습니다.)\n셸: PTY 슬레이브 FD를 통해 \\033[A 라는 바이트 시퀀스를 읽습니다.\n셸 (readline 라이브러리): 셸(또는 셸이 사용하는 readline 라이브러리)은 이 바이트 시퀀스를 해석합니다. \\033으로 시작하는 것을 보고 이스케이프 시퀀스임을 인지하고, 뒤따르는 [A를 “이전 히스토리” 명령으로 매핑된 테이블에서 찾습니다.\n셸 (명령 실행): “이전 히스토리” 명령을 실행합니다. 히스토리 파일(~/.bash_history 등)을 참조하여 가장 최근의 명령어(예: vim file.txt)를 가져옵니다.\n셸 (화면 업데이트): 셸은 사용자에게 현재 입력 줄이 이전 명령어로 대체되었음을 보여줘야 합니다. 이를 위해 터미널 제어 시퀀스를 조합하여 PTY 슬레이브 FD에 씁니다.\n\\r (Carriage Return): 커서를 줄의 맨 앞으로 이동. \\033[K (Erase in Line): 커서 위치부터 줄 끝까지 내용 지우기. vim file.txt: 가져온 히스토리 텍스트. 커널 (PTY 드라이버): 슬레이브에 쓰인 이 시퀀스들과 텍스트를 읽어 PTY 마스터 FD 쪽으로 전달합니다.\n터미널 에뮬레이터: 마스터 FD에서 이 데이터 스트림을 읽습니다. \\r과 \\033[K는 명령으로 해석하여 실행하고(커서를 옮기고 줄을 지움), vim file.txt는 텍스트로 인식하여 화면에 그립니다.\n💡 이 시나리오의 핵심: 화살표 키와 같은 특수 키 입력은 터미널 에뮬레이터가 이스케이프 시퀀스로 변환하고, 이 시퀀스의 의미를 해석하여 특정 동작(히스토리 검색)을 수행하는 것은 **커널이 아닌 애플리케이션(셸)**의 책임임.","case-별-구성요소들의-처리-과정#Case 별 구성요소들의 처리 과정":"","둘의-관계와-협력-방식#둘의 관계와 협력 방식":"구분 커널의 TTY 서브시스템 (Line Discipline) 커널의 PTY 드라이버 역할 터미널의 핵심 동작 규칙(두뇌) 가상의 터미널 장치(입출력 통로) 핵심 기능 Echo, Line Buffering, Signal 생성 마스터-슬레이브 쌍 생성 및 데이터 중계 추상화 수준 높음 (하드웨어 독립적) 낮음 (TTY 서브시스템에 데이터를 공급) 관계 상위 모듈. PTY 드라이버의 서비스를 받음 하위 모듈. TTY 서브시스템의 서비스를 이용함 사용자가 ls를 입력하는 과정을 이 둘의 관계로 다시 보면 다음과 같습니다.\n터미널 에뮬레이터가 l, s 바이트를 PTY 마스터 FD에 씁니다. PTY 드라이버가 이 데이터를 감지합니다. PTY 드라이버는 이 데이터를 “가상 장치에서 입력이 들어왔다\"고 알리며 TTY 서브시스템으로 전달합니다. TTY 서브시스템은 cooked 모드 규칙에 따라 다음을 수행합니다. l, s를 Echo하기 위해 다시 PTY 드라이버에게 “이 데이터를 마스터 쪽으로 보내라\"고 지시합니다. 내부 라인 버퍼에 ls를 저장합니다. (Enter 입력 후) TTY 서브시스템은 완성된 ls\\n을 PTY 드라이버에게 “이 데이터를 슬레이브 쪽에서 읽을 수 있게 하라\"고 전달합니다. 셸이 PTY 슬레이브 FD에서 ls\\n을 읽어갑니다. 셸에서 이벤트가 출발하지 않는 경우가 있을 수 있다 ex)시그널 ↩︎","역할-분담-터미널-에뮬레이터-vs-커널-pty-드라이버드라이버는-커널인가#역할 분담: 터미널 에뮬레이터 vs. 커널 (PTY 드라이버)드라이버는 커널인가":"터미널의 동작원리를 정확하게 이해하기 위해 터미널의 구성요소를 먼저 알아보고 case 별로 어떤 방식으로 이벤트가 전달되는가를 확인해보자\n터미널의 구성 요소와 역할 터미널 환경은 크게 **3개의 행위자(Actor)**와 이들을 연결하는 **1개의 통신 채널(Channel)**로 구성됩니다. 각 요소가 어떤 일을 하는지 명확히 구분하는 것이 중요합니다.\n터미널 에뮬레이터 (Terminal Emulator, 예: gnome-terminal, iTerm2) 역할: 사용자를 위한 그래픽 인터페이스(GUI 창)를 제공하고, 그래픽 시스템과 바이트 스트림 간의 번역을 담당합니다.\n입력 처리:\n누구에게 받아서: 사용자로부터 키보드 입력, 마우스 클릭 등 그래픽 시스템 이벤트를 받습니다. 무엇을 하는가: 이벤트를 해석하여 약속된 바이트(byte) 데이터로 변환합니다. A 키 → 0x41 바이트 위쪽 화살표 키 → \\033[A (이스케이프 시퀀스) 어디에 전달: 변환된 바이트 데이터를 PTY 통신 채널의 마스터(Master) 측 파일 디스크립터에 씁니다(write). 출력 처리:\n어디에서 받아서: PTY 통신 채널의 마스터(Master) 측 파일 디스크립터에서 바이트 데이터를 읽습니다(read). 무엇을 하는가: 읽어들인 바이트 스트림을 해석하여 화면에 글자나 그래픽 요소로 렌더링합니다. 이것이 에뮬레이터의 핵심 기능입니다. hello 같은 일반 텍스트는 그대로 화면에 그립니다. \\033[1m (굵게), \\033[31m (빨간색) 같은 이스케이프 시퀀스는 명령으로 해석하여 글자의 스타일을 바꿔서 그립니다. 누구에게 전달: 렌더링 결과를 사용자 눈에 보이는 화면(GUI 창)에 표시합니다. 통신 채널: PTY (Pseudo-Terminal) 역할: 터미널 에뮬레이터와 셸(애플리케이션) 사이의 양방향 통신 파이프 역할을 합니다. 커널에 의해 생성되고 관리되는 **가상 장치(Virtual Device)**입니다. 구조: 두 개의 끝점으로 구성됩니다. PTY 마스터(Master) 파일 디스크립터: 터미널 에뮬레이터가 사용하는 통신 끝점입니다. PTY 슬레이브(Slave) 파일 디스크립터: 셸(애플리케이션)이 사용하는 통신 끝점입니다. /dev/pts/N 형태의 장치 파일에 해당합니다. 특징: PTY 자체는 단순한 데이터 통로이지만, 이 통로를 지나는 데이터는 커널의 TTY 드라이버에 의해 감시되고 처리됩니다. 행위자 2: 커널 (Kernel)의 TTY/PTY 드라이버 역할: PTY 통신 채널의 중간에서 데이터를 중계하며, 전통적인 터미널의 동작 규칙(Line Discipline)을 적용하는 실제 두뇌입니다. 기능 (주로 cooked 모드일 때): 어디에서 받아서: PTY 마스터 FD에 쓰인 데이터를 읽고, PTY 슬레이브 FD에 쓰인 데이터를 읽습니다. 무엇을 하는가 (마스터 → 슬레이브 방향): 문자 에코 (Echo): PTY 마스터로부터 받은 입력 바이트를 다시 PTY 마스터 쪽으로 되돌려 써서, 터미널 에뮬레이터가 사용자가 입력한 내용을 화면에 표시하게 합니다. 입력 편집 (Line Buffering): Enter가 입력될 때까지 데이터를 내부 버퍼에 모으고, Backspace 같은 편집 문자를 해석하여 버퍼를 수정합니다. 신호(Signal) 생성: Ctrl+C에 해당하는 바이트(0x03)를 감지하면, 이를 데이터로 전달하는 대신 커널의 프로세스 관리자에게 SIGINT 신호를 생성하도록 요청합니다. 이 신호는 PTY 슬레이브에 연결된 전면 프로세스 그룹에 전달됩니다. 무엇을 하는가 (슬레이브 → 마스터 방향): 단순 중계: 일반적으로 셸(애플리케이션)이 PTY 슬레이브에 쓴 출력 데이터는 특별한 처리 없이 그대로 PTY 마스터 쪽으로 전달합니다. 어디에 전달: 처리된 데이터를 반대편 파일 디스크립터에서 읽을 수 있도록 준비시킵니다. 제어: 셸이나 애플리케이션은 ioctl() 시스템 콜을 통해 이 드라이버의 동작 방식(raw 모드, ECHO 끄기 등)을 변경할 수 있습니다. 행위자 3: 셸 / 터미널 애플리케이션 (Shell / e.g., bash, vim) 역할: 사용자의 명령을 실행하고 그 결과를 제공하는 프로그램입니다. 기능: 어디에서 받아서: 자신의 표준 입력(stdin), 즉 PTY 슬레이브 파일 디스크립터로부터 데이터를 읽습니다. 무엇을 하는가: 커널 드라이버에 의해 가공된(또는 raw 모드에서는 가공되지 않은) 데이터를 읽어 명령어로 해석하고 실행합니다. ls\\n: ls 명령을 실행. \\033[A (화살표 키): 히스토리 검색 기능 실행. 어디에 전달: 실행 결과(텍스트)나 화면 제어를 위한 이스케이프 시퀀스를 자신의 표준 출력(stdout) 또는 표준 에러(stderr), 즉 PTY 슬레이브 파일 디스크립터에 씁니다. 역할 분담: 터미널 에뮬레이터 vs. 커널 (PTY 드라이버)드라이버는 커널인가 기능 담당자 설명 Ctrl+C 입력 시 SIGINT 신호 전달 커널 (PTY 드라이버) 에뮬레이터는 제어문자(0x03)만 보내면, 커널이 이를 해석해 전면 프로세스 그룹(foreground process group)에 신호를 보냅니다. read -s (입력 숨기기) 커널 (PTY 드라이버) 셸이 ioctl(TCSETSW)로 echo 모드를 끄면, 커널(PTY 드라이버)이 입력 문자를 되돌려 보내지 않습니다. stty raw (Raw 모드 설정) 커널 (PTY 드라이버) Raw 모드 설정 시, 커널은 줄 단위 편집, 신호 처리 등을 비활성화하고 바이트를 그대로 통과시킵니다. 이스케이프 시퀀스 해석 터미널 에뮬레이터 \\033[1m(굵게), \\033[31m(빨강) 같은 시퀀스는 커널이 이해하지 못하며, 에뮬레이터가 직접 해석하여 화면에 렌더링해야 합니다. 커서 이동, 화면 지우기 터미널 에뮬레이터 clear, tput cup, vim 등이 사용하는 화면 제어 이스케이프 시퀀스를 에뮬레이터가 이해하고 커서 위치를 바꾸거나 화면을 다시 그려야 합니다. UTF-8 등 다중 바이트 문자 처리 터미널 에뮬레이터 ä, 한, 😊 같은 문자가 깨지지 않고 올바른 폭으로 렌더링되도록 처리하는 것은 에뮬레이터의 몫입니다. 줄 바꿈, 줄 감김 (Line Wrap) 터미널 에뮬레이터 한 줄의 끝(예: 80자)을 넘어서는 문자가 입력될 때 다음 줄로 넘길지, 개행 문자를 어떻게 처리할지 등을 에뮬레이터가 결정하고 구현해야 합니다. 🔺 핵심 요약: 커널(PTY 드라이버)은 입출력 중계와 신호/모드 처리를 담당하고, 터미널 에뮬레이터는 화면에 보이는 모든 시각적 표현(렌더링)을 책임집니다.","추가--tty-pty#추가 =\u0026gt; TTY? PTY?":"","터미널-에뮬레이터-terminal-emulator-예#\u003cstrong\u003e터미널 에뮬레이터 (Terminal Emulator, 예: \u003ccode\u003egnome-terminal\u003c/code\u003e, \u003ccode\u003eiTerm2\u003c/code\u003e)\u003c/strong\u003e":"","터미널의-구성-요소와-역할#\u003cstrong\u003e터미널의 구성 요소와 역할\u003c/strong\u003e":"","통신-채널-pty-pseudo-terminal#\u003cstrong\u003e통신 채널: PTY (Pseudo-Terminal)\u003c/strong\u003e":"","핵심-데이터-흐름-두-개의-파이프라인#\u003cstrong\u003e핵심 데이터 흐름: 두 개의 파이프라인\u003c/strong\u003e":"사용자 입력 파이프라인 (Input Flow: 키보드 입력이 셸에 도달하기까지)\n에뮬레이터 (키 입력→바이트 변환) → PTY Master → 커널 (PTY 드라이버 → TTY 서브시스템) (Echo, 버퍼링, 신호 처리) → PTY Slave → 셸/앱 (데이터 읽기)\n프로그램 출력 파이프라인 (Output Flow: 프로그램 결과가 화면에 보이기까지)1\n셸/앱 (결과 출력) → PTY Slave → 커널 (PTY 드라이버) (단순 중계) → PTY Master → 에뮬레이터 (바이트→화면 렌더링)","행위자-2-커널-kernel의-ttypty-드라이버#\u003cstrong\u003e행위자 2: 커널 (Kernel)의 TTY/PTY 드라이버\u003c/strong\u003e":"","행위자-3-셸--터미널-애플리케이션-shell--eg#\u003cstrong\u003e행위자 3: 셸 / 터미널 애플리케이션 (Shell / e.g., \u003ccode\u003ebash\u003c/code\u003e, \u003ccode\u003evim\u003c/code\u003e)\u003c/strong\u003e":""},"title":"터미널 동작 원리 매우 상세하게"},"/02.inbox/%ED%84%B0%EB%AF%B8%EB%84%90-%EB%8F%99%EC%9E%91-%EC%9B%90%EB%A6%AC-%EB%A7%A4%EC%9A%B0-%EC%83%81%EC%84%B8%ED%95%98%EA%B2%8C2-%EB%94%94%EB%B2%84%EA%B9%85/":{"data":{"":"각 케이스별로 터미널의 동작을 디버깅하고 특히 PTY 마스터-슬레이브 간의 통신을 실시간으로 확인하는 방법","1단계-환경-준비#1단계: 환경 준비":"두 개의 터미널 창을 엽니다.\n터미널 1 (실행용): 우리가 ls, Ctrl+C 등을 입력할 터미널입니다. 터미널 2 (관찰용): strace를 실행하여 터미널 1의 셸을 감시할 터미널입니다.","2단계-추적-대상-찾기#2단계: 추적 대상 찾기":"터미널 1에서 다음을 입력하여 현재 셸의 프로세스 ID(PID)와 PTY 슬레이브 장치 파일을 확인합니다.\n# 현재 셸의 PID 확인 echo $$ # 출력 예시: 24567 # 현재 터미널의 PTY 슬레이브 장치 파일 확인 tty # 출력 예시: /dev/pts/3 이제 우리는 PID 24567를 가진 bash 프로세스가 /dev/pts/3을 통해 통신한다는 것을 알았습니다.","3단계-strace-실행#3단계: \u003ccode\u003estrace\u003c/code\u003e 실행":"**터미널 2 (관찰용)**에서 다음 명령을 실행하여 터미널 1의 셸에 strace를 붙입니다. sudo가 필요할 수 있습니다.\n# -p [PID]: 특정 프로세스에 연결 # -e trace=read,write,ioctl: read, write, ioctl 시스템 콜만 추적 # -s 100: 문자열 데이터는 최대 100자까지 표시 # -xx: 문자열이 아닌 데이터는 Hex(16진수)로 표시 sudo strace -p 24567 -e trace=read,write,ioctl -s 100 -xx 이제 strace가 터미널 1의 셸을 감시하기 시작합니다. strace는 read(0, ...)와 같이 셸이 입력을 기다리며 멈춰있을 겁니다. (여기서 FD 0은 셸의 표준 입력, 즉 /dev/pts/3 입니다.)","4단계-케이스별-관찰-터미널-1에서-입력#4단계: 케이스별 관찰 (터미널 1에서 입력)":"이제 터미널 1에서 여러 가지 입력을 해보고 터미널 2에 나타나는 strace 출력을 관찰합시다.\n▶️ Case 1: ls를 입력하고 Enter\n터미널 1: l, s, Enter를 차례로 입력합니다.\n터미널 2 (strace 출력):\n# 커널의 라인 버퍼링 때문에 'ls'와 '\\n'이 한번에 전달됨 read(0, \"ls\\n\", 100) = 3 # ... fork, execve(\"ls\") 등 ... # ls의 결과가 PTY 슬레이브를 통해 터미널 에뮬레이터로 출력됨 write(1, \"Desktop Downloads Music\\n\", 28) = 28 # 셸 프롬프트가 다시 출력됨 write(2, \"$ \", 2) = 2 핵심 관찰: l이나 s를 입력할 때는 read가 호출되지 않습니다. 커널(TTY 드라이버)이 Enter가 올 때까지 버퍼링하다가 ls\\n을 한 번에 셸에게 전달합니다. 이것이 cooked 모드의 증거입니다. ▶️ Case 2: 입력 중 Backspace 사용\n터미널 1: l, p, Backspace, s, Enter를 입력합니다.\n터미널 2 (strace 출력):\nread(0, \"ls\\n\", 100) = 3 핵심 관찰: strace 결과는 Case 1과 완전히 동일합니다. 셸은 p를 입력했는지, Backspace로 지웠는지 전혀 모릅니다. 커널의 TTY 드라이버가 입력 편집을 모두 처리하고 최종 결과인 ls\\n만 셸에게 전달했기 때문입니다. ▶️ Case 3: Ctrl+C 누르기\n터미널 1: sleep 100을 실행한 뒤, 바로 Ctrl+C를 누릅니다.\n터미널 2 (strace 출력):\n# sleep 100 실행 부분 생략 ... # Ctrl+C를 누르면, 셸은 0x03 바이트를 read 하는 것이 아니라, # SIGINT 시그널을 받는다! --- SIGINT {si_signo=SIGINT, si_code=SI_KERNEL} --- # 시그널을 받은 후, 셸은 다시 프롬프트를 찍는다. write(2, \"\\n\", 1) = 1 write(2, \"$ \", 2) = 2 read(0, 핵심 관찰: read 시스템 콜로 0x03 바이트가 들어오는 것이 아니라, --- SIGINT --- 라는 메시지가 뜹니다. 이는 커널이 Ctrl+C에 해당하는 바이트를 해석하여 셸 프로세스에 SIGINT 시그널을 보냈음을 명확히 보여줍니다. ▶️ Case 5: vim 실행 (Raw 모드)\n터미널 1: vim을 실행합니다.\n터미널 2 (strace 출력):\n# vim이 시작하자마자 터미널 설정을 바꾸기 위해 ioctl을 호출한다. # TCSETSW는 \"지금 바로 설정을 바꿔라\"는 의미. # c_lflag에서 ICANON(Canonical 모드), ECHO(에코) 등이 꺼진 것을 볼 수 있음. ioctl(0, TCSETSW, {c_iflag=ICRNL|IXON, c_oflag=OPOST|ONLCR, c_cflag=B38400|CS8|CREAD, c_lflag=ISIG|IEXTEN, ...}) # 화면을 그리기 위해 수많은 이스케이프 시퀀스를 write 한다. write(1, \"\\33[?2004h\\33[?1049h\\33[22;0;0t\\33[1;24r\\33[m\\33[H\\33[2J...\", 200) = 200 터미널 1 (vim 내부): j 키를 한 번 눌러 커서를 아래로 이동합니다.\n터미널 2 (strace 출력):\n# Raw 모드이므로 'j' 키를 누르자마자 read가 즉시 반환됨. read(0, \"j\", 16) = 1 # vim은 'j' 입력에 대한 반응으로, 커서를 이동시키는 이스케이프 시퀀스를 출력. write(1, \"\\33[11;5H\", 6) = 6 핵심 관찰: ioctl 호출로 터미널이 raw 모드로 변경되는 것을 확인했습니다. j 키 하나를 누르자마자 read가 바로 반환됩니다. 라인 버퍼링이 꺼졌다는 증거입니다. vim은 커서 이동 같은 간단한 동작조차 이스케이프 시퀀스를 write하여 직접 처리합니다.","끝판왕-socat으로-실시간-양방향-트래픽-감시하기#끝판왕: \u003ccode\u003esocat\u003c/code\u003e으로 실시간 양방향 트래픽 감시하기":"이 방법은 가장 복잡하지만 마스터와 슬레이브 사이를 오가는 모든 데이터를 실시간으로 보여줍니다.\n**터미널 2 (관찰용)**에서 socat으로 가짜 PTY를 생성하고 중간에서 데이터를 감시합니다.\n# 두 개의 PTY 쌍을 만들고, 그 사이를 오가는 모든 데이터를 hex(-x)로 출력 # 터미널 1은 /tmp/my-pty1에, 터미널 2의 셸은 /tmp/my-pty2에 연결될 것임 socat -d -d -x PTY,link=/tmp/my-pty1,raw,echo=0 PTY,link=/tmp/my-pty2,raw,echo=0 이제 **새 터미널(터미널 3)**을 열고, 셸을 PTY 슬레이브 쪽에 연결합니다.\n# stty raw -echo: 이 터미널 자체의 cooked 모드를 꺼서 socat에 방해되지 않게 함 # exec bash \u003c /tmp/my-pty2 \u003e /tmp/my-pty2 2\u003e\u00261: bash의 입출력을 PTY 슬레이브로 리다이렉션 stty raw -echo; exec bash \u003c /tmp/my-pty2 \u003e /tmp/my-pty2 2\u003e\u00261 터미널 1에서는 터미널 에뮬레이터 역할을 할 프로그램을 PTY 마스터 쪽에 연결합니다. socat을 또 사용하면 편리합니다.\nsocat - \"file:/tmp/my-pty1,raw,echo=0\" 이제 터미널 1에서 키보드를 입력하면, 그 데이터가 터미널 2의 socat 감시 화면에 보이고, 처리된 결과가 터미널 3의 bash로 전달됩니다. bash의 출력 역시 터미널 2를 거쳐 터미널 1에 보이게 됩니다. 이로써 완벽한 Man-in-the-middle 감시 환경이 구축되었습니다.\n이 방법을 통해 제공해주신 문서의 모든 데이터 흐름도를 눈으로 직접 확인할 수 있습니다.","디버깅을-위한-핵심-도구-toolbox#디버깅을 위한 핵심 도구 (Toolbox)":"우리가 사용할 주요 도구는 다음과 같습니다. 각 도구의 역할을 이해하면 어떤 상황에 무엇을 써야 할지 명확해집니다.\n도구 핵심 기능 무엇을 볼 수 있는가? strace 시스템 콜 추적 프로세스(셸, vim)가 커널과 어떤 상호작용을 하는지 (read, write, ioctl 호출 및 주고받는 데이터)를 정확히 보여줍니다. 슬레이브 측 통신 확인에 최적화되어 있습니다. script 터미널 세션 기록 터미널 에뮬레이터와 PTY 마스터 사이의 **모든 바이트 스트림(입력/출력)**을 날것 그대로 파일에 기록합니다. 마스터 측 통신 확인에 완벽합니다. socat 만능 데이터 중계기 두 개의 통신 채널을 엮고 그 사이를 흐르는 데이터를 엿볼 수 있습니다. PTY를 직접 생성하여 마스터-슬레이브 양단의 모든 트래픽을 실시간 Hex 덤프로 확인하는 궁극의 방법입니다. lsof 열린 파일 목록 확인 특정 프로세스가 어떤 파일 디스크립터(PTY 슬레이브 포함)를 열고 있는지 확인하는 데 사용합니다.","실전-디버깅-시나리오-strace로-셸slave-관찰하기#실전! 디버깅 시나리오: \u003ccode\u003estrace\u003c/code\u003e로 셸(Slave) 관찰하기":"이 방법은 셸(bash)이 PTY 슬레이브와 어떻게 상호작용하는지를 가장 직접적으로 보여줍니다.","심화-과정-script로-마스터-측-통신-훔쳐보기#심화 과정: \u003ccode\u003escript\u003c/code\u003e로 마스터 측 통신 훔쳐보기":"strace는 셸(슬레이브) 관점의 훌륭한 도구지만, 커널이 편집해주는 Backspace나 에뮬레이터가 보내는 화살표 키의 실제 바이트는 볼 수 없습니다. 이때 script를 사용합니다.\n터미널 1에서 다음을 실행합니다.\n# -t 옵션은 시간 정보를 timing.log에 기록 # session.log 파일에 모든 바이트 스트림을 기록 script -t timing.log session.log 이제 script가 새로운 셸을 실행시키고, 이 세션에서 일어나는 모든 입출력을 기록하기 시작합니다. 여기서 다음을 순서대로 입력해보세요.\nl, p, Backspace, s, Enter 위쪽 화살표(↑) 키 Ctrl+C exit 를 입력하여 script 종료 이제 session.log 파일을 hexdump로 열어보면 날것 그대로의 데이터가 보입니다.\nhexdump -C session.log 아마 다음과 유사한 내용을 볼 수 있을 겁니다.\n# ... 프롬프트 ... # 'l', 'p', 'Backspace', 's', '\\r' (Enter) 6c 70 08 73 0d # 'Backspace'에 대한 커널의 화면 수정 응답: \\b \\b 08 20 08 # ... ls 결과 ... # 위쪽 화살표 키 입력 1b 5b 41 # 셸이 히스토리를 찾아 화면에 그려주는 응답 0d 1b 5b 4b 6c 73 ... # Ctrl+C 입력 03 # ... exit 입력 ... 핵심 관찰: 사용자가 누른 Backspace(0x08)와 화살표 키(1b 5b 41)가 PTY 마스터에 기록된 것을 볼 수 있습니다. strace로는 볼 수 없었던 정보입니다. scriptreplay timing.log session.log 명령으로 당시 상황을 영상처럼 다시 재생해볼 수도 있습니다."},"title":"터미널 동작 원리 매우 상세하게2 (디버깅)"},"/02.inbox/%ED%95%A8%EC%88%98%ED%8F%AC%EC%9D%B8%ED%84%B0/":{"data":{"":"int foo(){ // foo 코드는 메모리 주소 0x002717f0에서 시작한다. return 5; } int main(){ printf(\"%d\\n\",foo()); // 주소 0x002717f0로 점프한다. 5 출력 printf(\"%p\\n\",foo); // 주소를 출력 return 0; } 코드에서 보듯 함수의 이름은 함수의 주소를 가르킨다 int a[7] 에서 a 가 주소를 가리키듯\nint add(int a, int b){return a + b;} //덧셈함수 int sub(int a, int b){return a - b;} //뺄셈함수 int mul(int a, int b){return a * b;} //곱셈함수 int div(int a, int b){return a / b;} //나눗셈함수 int main() { int (*fp[4])(int, int); //함수 포인터 배열 선언 fp[0] = add; // 배열[1]에 덧셈 함수의 메모리 주소 저장 fp[1] = sub; // 배열[2]에 뺄셈 함수의 메모리 주소 저장 fp[2] = mul; // 배열[3]에 곱셈 함수의 메모리 주소 저장 fp[3] = div; // 배열[4]에 나눗셈 함수의 메모리 주소 저장 for (int i = 0; i \u003c 4; i++) { printf(\"배열[%d](20,%2010)); } return 0; } typedef int (*PtrFunc)(int, int) PtrFunc fp = NULL; fp = add;"},"title":"함수포인터"},"/02.inbox/2%EC%9D%98-%EB%B3%B4%EC%88%98%EB%A5%BC-%EC%9D%8C%EC%88%98-%ED%91%9C%ED%98%84%EB%B2%95%EC%9C%BC%EB%A1%9C-%EC%A0%95%ED%95%9C-%EC%9D%B4%EC%9C%A0/":{"data":{"":"첫자리 a0 부터 a3 이라고 가정 맨 앞자리를 음수를 나타내는 비트라고 정하는 방법과 2의 보수를 음수를 나타내는 비트라고 정하는 방법 2가지를 비교\n이진수 초기 구현 2의 보수로 구현한 음수 더하기 식 0000 0 0 0*a3 + 0*a2 + 0*a1 + 0*a0 0001 1 1 1*a3 + 0*a2 + 0*a1 + 1*a0 0010 2 2 0*a3 + 0*a2 + 1*a1 + 0*a0 0011 3 3 0*a3 + 0*a2 + 1*a1 + 1*a0 0100 4 4 0*a3 + 1*a2 + 0*a1 + 0*a0 0101 5 5 0*a3 + 1*a2 + 0*a1 + 1*a0 0110 6 6 0*a3 + 1*a2 + 1*a1 + 0*a0 0111 7 7 0*a3 + 1*a2 + 1*a1 + 1*a0 1000 -0 -8 -1*a3 + 0*a2 + 0*a1 + 0*a0 1001 -1 -7 -1*a3 + 0*a2 + 0*a1 + 1*a0 1010 -2 -6 -1*a3 + 0*a2 + 1*a1 + 0*a0 1011 -3 -5 -1*a3 + 0*a2 + 1*a1 + 1*a0 1100 -4 -4 -1*a3 + 1*a2 + 0*a1 + 0*a0 1101 -5 -3 -1*a3 + 1*a2 + 0*a1 + 1*a0 1110 -6 -2 -1*a3 + 1*a2 + 1*a1 + 0*a0 1111 -7 -1 -1*a3 + 1*a2 + 1*a1 + 1*a0 이진수 덧셈 방식에 따를 때 (회로의 구현방식중 ) 2의 보수가 가장 적절한 음수 표현 방법이다\n2는 0으로 부터 아래로 2칸 -4는 0으로 부터 위로 4칸\n음수를 2의 보수로 표현 가능하다면 덧셈 회로 만으로도 뺄셈 방식이 구현 가능하다\nunsigned 와 signed 는 오버 플로우 발생 비트가 다르다 (1000 에서 발생 vs 1111 에서 발생)\n결국 이러한 방식의 남은 마지막 문제는 0111 = 7 에서 양수가 더해질 때 즉 7보다 큰 수 -8 보다 작은수를 표현하려고 할 때 오버플로가 일어나 의도하지 않은 숫자가 나오게 된다\n위에는 일반적인 자료형의 음수 표현 비트 사용이다 하지만 unsigned 자료형의 경우 위의 것을 고민할 필요가 없다"},"title":"2의 보수를 음수 표현법으로 정한 이유"},"/02.inbox/abi/":{"data":{"":"gcc-arm-[플렛폼]-[ABI 타입] gcc-arm-linux-gnueabi/jammy 4:11.2.0-1ubuntu1 amd64 GNU C compiler for the armel architecture gcc-arm-linux-gnueabihf/jammy 4:11.2.0-1ubuntu1 amd64 GNU C compiler for the armhf architecture gcc-arm-none-eabi/jammy 15:10.3-2021.07-4 amd64 GCC cross compiler for ARM Cortex-R/M processors gcc-arm-none-eabi-source/jammy 15:10.3-2021.07-4 all GCC cross compiler for ARM Cortex-R/M processors (source) arm-none-eabi-gcc\nABI는 “Application Binary Interface\"의 약자로, 소프트웨어와 하드웨어 간의 상호작용을 정의하는 규약입니다. ABI는 다음과 같은 요소를 포함합니다:\n데이터 타입: 데이터의 크기, 정렬 방식, 표현 방식 등을 정의합니다. 함수 호출 규약: 함수에 인자를 전달하는 방법, 반환 값 처리, 스택 관리 등을 규정합니다. 레지스터 사용: CPU 레지스터의 사용 방식과 어떤 레지스터가 어떤 용도로 사용되는지를 정의합니다. 바이너리 형식: 실행 파일과 라이브러리의 구조와 형식에 대해 설명합니다."},"title":"abi"},"/02.inbox/android-sdk-tool-list/":{"data":{"":"","-기타-파일-및-디렉토리#📂 기타 파일 및 디렉토리":"","-보조-및-전문-도구#🛠️ 보조 및 전문 도구":"","-시스템-및-파일-시스템-관련-도구-일반-개발자는-거의-사용하지-않음#🔩 시스템 및 파일 시스템 관련 도구 (일반 개발자는 거의 사용하지 않음)":"이 도구들은 안드로이드 OS 자체를 빌드하거나, 시스템 이미지를 생성하는 등 매우 낮은 수준의 작업을 할 때 사용됩니다. 일반적인 앱 개발자는 직접 사용할 일이 거의 없습니다.","-핵심-도구-가장-중요하고-자주-사용#⭐ 핵심 도구 (가장 중요하고 자주 사용)":"","1-adb-android-debug-bridge#1. \u003ccode\u003eadb\u003c/code\u003e (Android Debug Bridge)":"가장 중요하고 다재다능한 도구입니다. 실행 중인 안드로이드 기기(에뮬레이터 포함)와 통신하기 위한 클라이언트-서버 프로그램입니다. PC에서 실행하는 adb는 클라이언트, 기기에서 실행되는 adbd는 데몬(서버) 역할을 합니다. USB 케이블이나 Wi-Fi를 통해 연결됩니다.\n주요 기능 및 사용 사례:\n기기 연결 확인: adb devices: 현재 PC에 연결된 기기 목록을 확인합니다. 기기가 정상적으로 인식되었는지 확인할 때 가장 먼저 사용하는 명령어입니다. 앱 설치 및 삭제: adb install [앱이름].apk: PC에 있는 APK 파일을 기기에 설치합니다. adb uninstall [패키지이름]: 기기에 설치된 앱을 삭제합니다. 파일 전송: adb push [PC 경로] [기기 경로]: PC의 파일을 기기로 복사합니다. adb pull [기기 경로] [PC 경로]: 기기의 파일을 PC로 복사합니다. 쉘(Shell) 접근: adb shell: 기기의 리눅스 쉘에 원격으로 접속합니다. 이를 통해 기기 내부의 파일 시스템을 탐색하거나, 각종 시스템 명령어를 실행할 수 있습니다. (예: adb shell ls /sdcard/) 로그 확인 (디버깅): adb logcat: 기기에서 실시간으로 발생하는 시스템 로그를 출력합니다. 앱 개발 시 에러나 동작을 추적하는 데 필수적입니다. 기기 제어: adb reboot: 기기를 재부팅합니다. adb reboot recovery: 리커버리 모드로 재부팅합니다. adb reboot bootloader: 부트로더(패스트붓) 모드로 재부팅합니다. 기타 고급 기능: 포트 포워딩: adb forward tcp:[PC 포트] tcp:[기기 포트] - PC의 특정 포트로 들어오는 요청을 기기의 포트로 전달합니다. 디버깅 시 유용합니다. 스크린샷/녹화: adb shell screencap (스크린샷), adb shell screenrecord (화면 녹화).","1-개요-build-tools-디렉토리의-역할#1. 개요: \u003ccode\u003ebuild-tools\u003c/code\u003e 디렉토리의 역할":"build-tools는 Android SDK(소프트웨어 개발 키트)의 일부로, 개발자가 작성한 소스 코드(Java/Kotlin), 리소스 파일(XML 레이아웃, 이미지 등), 그리고 라이브러리들을 실제 Android 기기에서 실행될 수 있는 패키지 파일(.apk 또는 .aab)로 변환하는 데 필요한 모든 명령줄 도구들을 포함하고 있습니다.\nGradle과 같은 현대적인 빌드 시스템이 이 도구들을 자동으로 호출하여 빌드 프로세스를 진행하지만, 각 도구의 역할을 이해하는 것은 고급 빌드 최적화나 문제 해결에 매우 중요합니다.","10-packagexml--sourceproperties#10. \u003ccode\u003epackage.xml\u003c/code\u003e / \u003ccode\u003esource.properties\u003c/code\u003e":"안드로이드 SDK 매니저가 이 패키지를 관리하기 위해 사용하는 메타데이터 파일입니다. 패키지의 버전, 설명, 의존성 등의 정보가 기록되어 있습니다. SDK 매니저가 업데이트를 확인하거나 패키지를 설치/삭제할 때 이 파일들을 참조합니다.","2-fastboot-fastboot-protocol-tool#2. \u003ccode\u003efastboot\u003c/code\u003e (Fastboot Protocol Tool)":"부트로더(Bootloader) 상태의 기기와 통신하는 도구입니다. 운영체제(OS)가 부팅되기 전의 단계에서 기기의 파티션을 수정하거나 펌웨어(ROM)를 설치(플래싱)할 때 사용됩니다. adb가 OS가 켜진 상태에서 통신하는 것과 달리, fastboot는 더 낮은 수준(low-level)에서 기기를 제어합니다.\n주요 기능 및 사용 사례:\n부트로더 언락/락: fastboot flashing unlock 또는 fastboot oem unlock: 기기의 부트로더를 언락하여 커스텀 펌웨어를 설치할 수 있는 상태로 만듭니다. (※ 기기 데이터가 초기화됩니다!) fastboot flashing lock: 부트로더를 다시 잠급니다. 펌웨어 이미지 플래싱: fastboot flash [파티션 이름] [이미지 파일]: 특정 파티션에 이미지 파일을 덮어씌웁니다. 예를 들어, 시스템 파티션에 새로운 OS 이미지를 설치할 때 사용합니다. 예시: fastboot flash system system.img, fastboot flash boot boot.img 기기 정보 확인: fastboot getvar all: 기기의 시리얼 번호, 부트로더 버전 등 다양한 하드웨어 정보를 확인합니다. 재부팅: fastboot reboot: 기기를 일반 모드로 재부팅합니다. fastboot reboot bootloader: 현재의 부트로더 모드로 다시 재부팅합니다.","2-버전별-디렉토리-구조-3500-3600-3610-rc1#2. 버전별 디렉토리 구조 (\u003ccode\u003e35.0.0\u003c/code\u003e, \u003ccode\u003e36.0.0\u003c/code\u003e, \u003ccode\u003e36.1.0-rc1\u003c/code\u003e)":"build-tools는 하위 호환성을 유지하고 프로젝트별로 특정 버전의 도구를 사용할 수 있도록 버전별로 폴더가 나뉘어 있습니다.\n35.0.0, 36.0.0: 안정화된 릴리스 버전입니다. 36.1.0-rc1: rc1은 “Release Candidate 1\"을 의미하며, 정식 출시 전의 테스트 버전입니다. 프로젝트의 build.gradle 파일에 있는 buildToolsVersion \"35.0.0\"과 같은 설정은 빌드 시 사용할 이 디렉토리 버전을 지정하는 역할을 합니다. 각 버전 폴더 안의 내용은 대부분 비슷하며, 버전이 올라갈수록 버그 수정, 성능 향상, 새로운 Android 플랫폼 기능 지원 등이 추가됩니다.","3-sqlite3#3. \u003ccode\u003esqlite3\u003c/code\u003e":"안드로이드 앱이 데이터를 저장하는 데 널리 사용하는 SQLite 데이터베이스를 관리하기 위한 커맨드 라인 도구입니다. adb shell을 통해 기기에 접속한 후, 이 도구를 사용하여 앱의 데이터베이스 파일(.db)을 직접 열고 SQL 쿼리를 실행할 수 있습니다.\n사용 사례: 앱 개발 중 데이터가 올바르게 저장되고 있는지 확인하거나, 데이터베이스 스키마를 검사하고, 데이터를 직접 수정할 때 유용합니다. 예시: adb shell로 접속 후, sqlite3 /data/data/[앱 패키지]/databases/mydatabase.db 명령어로 DB에 접근하여 .tables로 테이블 목록을 보거나 SELECT * FROM my_table; 같은 쿼리를 실행할 수 있습니다.","3-주요-도구-상세-설명-버전-폴더-최상위#3. 주요 도구 상세 설명 (버전 폴더 최상위)":"각 버전 폴더 안에 있는 핵심 도구들의 역할은 다음과 같습니다.\naapt / aapt2 (Android Asset Packaging Tool)\n역할: Android 앱 빌드 과정에서 가장 중요한 도구 중 하나입니다. 리소스 파일(res 디렉토리의 XML, 이미지 등)을 분석하고 바이너리 형식으로 컴파일합니다. AndroidManifest.xml 파일을 처리합니다. 리소스 ID를 담고 있는 R.java (또는 R.kt) 파일을 생성하여 코드에서 리소스를 참조할 수 있게 합니다. aapt2는 aapt의 개선된 버전으로, 증분 리소스 처리(incremental resource processing)를 지원하여 빌드 속도를 크게 향상시켰습니다. 현재는 aapt2가 기본으로 사용됩니다. apksigner (APK Signer)\n역할: 생성된 APK 파일에 디지털 서명을 합니다. Android 시스템은 앱을 설치하거나 업데이트할 때 이 서명을 확인하여 앱의 무결성(변조되지 않았음)과 개발자 신원을 보장합니다. 서명되지 않은 앱은 기기에 설치할 수 없습니다. zipalign\n역할: APK 패키지 파일을 최적화하는 도구입니다. APK 내부의 압축되지 않은 데이터(예: 이미지 리소스)를 4바이트 경계에 맞게 정렬합니다. 이 작업을 통해 앱 실행 시 메모리 사용량이 줄어들고 리소스 접근 속도가 빨라집니다. 중요: zipalign은 반드시 apksigner로 서명하기 전에 실행해야 합니다. (Google Play에 업로드할 때는 서명 후에 실행해도 Google이 재정렬 및 재서명을 해줍니다.) d8 (DEXer)\n역할: Java 또는 Kotlin 컴파일러가 생성한 .class 파일(자바 바이트코드)을 Android 런타임(ART)이 실행할 수 있는 .dex 파일(Dalvik Executable) 형식으로 변환합니다. 이 과정에서 코드 최적화, 축소(shrinking), 그리고 Java 8+의 새로운 언어 기능을 이전 Android 버전에서도 사용할 수 있도록 디슈가링(desugaring)하는 작업도 수행합니다. d8은 이전의 dx 도구를 대체한 더 빠르고 효율적인 도구입니다. aidl (Android Interface Definition Language)\n역할: 앱의 여러 프로세스 간 통신(IPC)을 위한 인터페이스를 생성하는 데 사용됩니다. 개발자가 .aidl 파일에 인터페이스를 정의하면, 이 도구가 해당 인터페이스를 구현하는 Java 코드를 자동으로 생성해 줍니다. 서비스(Service)와 다른 앱 컴포넌트 간의 통신에 주로 사용됩니다. dexdump\n역할: .dex 파일의 내용을 사람이 읽을 수 있는 형태로 덤프(출력)하는 디버깅 도구입니다. 앱의 바이트코드를 직접 분석하거나 최적화 문제를 확인할 때 유용합니다. *-ld 파일들 (Linkers)\naarch64-linux-android-ld, arm-linux-androideabi-ld, i686-linux-android-ld, x86_64-linux-android-ld 등 역할: NDK(Native Development Kit)를 사용하여 C/C++ 코드를 빌드할 때 사용되는 링커입니다. 컴파일된 네이티브 목적 파일(.o)들을 모아서 공유 라이브러리(.so)나 실행 파일을 만듭니다. 각 파일은 특정 CPU 아키텍처(arm64, armv7, x86 등)에 해당합니다. lld / lld-bin\n역할: LLVM 프로젝트에서 개발한 새로운 고성능 링커입니다. 기존의 ld 링커보다 빠르며, NDK 빌드에서 사용됩니다.","4-hprof-conv-hprof-converter#4. \u003ccode\u003ehprof-conv\u003c/code\u003e (HPROF Converter)":"안드로이드 앱의 메모리 힙 덤프(Heap Dump) 파일을 변환하는 도구입니다. 안드로이드 스튜디오의 프로파일러에서 생성된 .hprof 파일은 안드로이드 고유의 형식을 사용합니다. 이 파일을 jhat과 같은 표준 Java 힙 분석 도구에서 사용 가능한 형식으로 변환할 때 사용됩니다.\n사용 사례: 메모리 누수(Memory Leak) 분석과 같은 고급 메모리 프로파일링 작업을 할 때 필요할 수 있습니다.","4-renderscript-디렉토리-상세-설명#4. \u003ccode\u003erenderscript\u003c/code\u003e 디렉토리 상세 설명":"RenderScript는 고성능 컴퓨팅, 특히 이미지 처리나 계산 집약적인 작업을 위해 만들어진 프레임워크입니다. 중요: RenderScript는 API 레벨 31부터 공식적으로 Deprecated(사용 중단)되었습니다. 하지만 하위 호환성을 위해 도구들은 여전히 포함되어 있습니다.\nllvm-rs-cc: RenderScript 소스 코드(.rs 파일)를 LLVM 비트코드로 컴파일하는 컴파일러입니다. clang-include: RenderScript 컴파일 시 필요한 Clang/LLVM 관련 C/C++ 헤더 파일들입니다. *intrin.h 파일들은 CPU 고유의 명령어(intrinsics)를 사용해 코드를 최적화하기 위한 헤더입니다. include: rs_*.rsh 파일들이 있으며, RenderScript 코드 내에서 사용할 수 있는 표준 API(수학, 시간, 변환 등)를 정의한 헤더 파일입니다. lib: RenderScript 지원 라이브러리들이 모여 있습니다. bc: 각 CPU 아키텍처별로 사전 컴파일된 RenderScript 핵심 라이브러리 비트코드(libclcore.bc)가 있습니다. packaged: RenderScript를 사용하는 앱에 포함되는 네이티브 라이브러리(.so)입니다. libRSSupport.so는 RenderScript API를 이전 Android 버전에서도 사용할 수 있도록 하는 호환성 라이브러리입니다. androidx-rs.jar, renderscript-v8.jar: RenderScript를 Java/Kotlin 코드에서 호출하기 위한 자바 라이브러리입니다.","5-etc1tool#5. \u003ccode\u003eetc1tool\u003c/code\u003e":"ETC1 형식의 텍스처 압축 및 해제를 위한 도구입니다. ETC1은 안드로이드가 지원하는 텍스처 압축 형식으로, GPU 메모리를 효율적으로 사용하는 데 도움을 줍니다.\n사용 사례: 게임 개발이나 그래픽 집약적인 앱을 만들 때, PNG와 같은 일반 이미지 파일을 ETC1 형식(.pkm)으로 압축하거나, 압축된 파일을 다시 디코딩하여 확인하는 용도로 사용됩니다.","5-lib-및-lib64-디렉토리#5. \u003ccode\u003elib\u003c/code\u003e 및 \u003ccode\u003elib64\u003c/code\u003e 디렉토리":"이 디렉토리들은 build-tools에 포함된 명령줄 도구들이 내부적으로 사용하는 라이브러리를 담고 있습니다.\nlib: Java 라이브러리(.jar)가 위치합니다. d8.jar: d8 도구의 핵심 로직이 담긴 자바 라이브러리입니다. apksigner.jar: apksigner 도구의 핵심 로직입니다. lib64: 네이티브 공유 라이브러리(.dylib for macOS, .so for Linux, .dll for Windows)가 위치합니다. libc++.dylib: C++ 표준 라이브러리. libLLVM_android.dylib: RenderScript 컴파일러와 같은 도구들이 사용하는 LLVM/Clang 라이브러리입니다.","6-make_f2fs--make_f2fs_casefold#6. \u003ccode\u003emake_f2fs\u003c/code\u003e / \u003ccode\u003emake_f2fs_casefold\u003c/code\u003e":"F2FS(Flash-Friendly File System) 파일 시스템을 생성하는 도구입니다. F2FS는 플래시 메모리(SSD, eMMC 등)에 최적화된 파일 시스템으로, 최신 안드로이드 기기에서 널리 사용됩니다.\nmake_f2fs_casefold: 파일 이름의 대소문자를 구분하지 않는(case-insensitive) F2FS 파일 시스템을 생성합니다.","6-기타-파일#6. 기타 파일":"NOTICE.txt: 이 도구들에 사용된 오픈소스 라이브러리의 라이선스 및 저작권 정보가 담겨 있습니다. package.xml, source.properties, runtime.properties: Android SDK Manager가 이 패키지를 인식하고 관리하기 위한 메타데이터 파일입니다. 패키지의 버전, 설명, 종속성 등의 정보가 포함됩니다.","7-mke2fs--mke2fsconf#7. \u003ccode\u003emke2fs\u003c/code\u003e / \u003ccode\u003emke2fs.conf\u003c/code\u003e":"ext2, ext3, ext4 파일 시스템을 생성하는 도구입니다. 과거 안드로이드 기기들은 ext4를 주로 사용했습니다.\nmke2fs.conf: mke2fs가 파일 시스템을 생성할 때 참조하는 설정 파일입니다.","8-lib64#8. \u003ccode\u003elib64\u003c/code\u003e":"64비트 시스템에서 위 도구들이 실행되는 데 필요한 공유 라이브러리(Shared Libraries) 파일들이 들어있는 디렉토리입니다. (예: .dylib on macOS, .so on Linux, .dll on Windows)","9-noticetxt#9. \u003ccode\u003eNOTICE.txt\u003c/code\u003e":"platform-tools에 포함된 오픈소스 소프트웨어들의 라이선스 및 저작권 관련 고지 사항이 담긴 텍스트 파일입니다.","sdk-locationbuild-toolssdk-version#\u003ccode\u003e{sdk location}/build-tools/{sdk version}\u003c/code\u003e":"네, 제공해주신 build-tools 디렉토리 구조를 매우 상세하게 설명해 드리겠습니다. 이 디렉토리는 Android 앱을 개발하고 빌드하는 데 있어 가장 핵심적인 역할을 하는 도구들을 모아놓은 곳입니다.","sdk-locationplatform-tools#\u003ccode\u003e{sdk location}/platform-tools\u003c/code\u003e":"","결론#결론":"build-tools 디렉토리는 Android 앱의 “생산 공장\"과 같습니다. 개발자가 제공한 설계도(소스 코드)와 재료(리소스)를 받아, aapt2로 부품을 가공하고, d8으로 엔진(로직)을 만들며, 이 모든 것을 zipalign으로 최적화된 상자(.apk)에 담아 apksigner로 품질 보증 도장(서명)을 찍는, 전체 빌드 과정의 핵심 엔진 역할을 수행하는 곳입니다.","요약#요약":"이름 종류 설명 adb 핵심 도구 실행 중인 안드로이드 기기와 통신 (앱 설치, 파일 전송, 디버깅 등) fastboot 핵심 도구 부트로더 상태의 기기와 통신 (펌웨어 플래싱, 부트로더 언락 등) sqlite3 전문 도구 안드로이드 기기 내의 SQLite 데이터베이스를 관리 hprof-conv 전문 도구 안드로이드 메모리 힙 덤프 파일을 표준 형식으로 변환 etc1tool 전문 도구 ETC1 텍스처 압축/해제 make_f2fs 등 시스템 도구 F2FS, ext4 등 안드로이드 파일 시스템 이미지를 생성 lib64, NOTICE.txt 등 지원 파일 라이브러리, 라이선스, SDK 매니저용 메타데이터 결론적으로, 일반적인 안드로이드 개발이나 기기 관리를 위해서는 adb와 fastboot 두 가지의 사용법만 확실히 알아두어도 대부분의 작업을 수행할 수 있습니다. 나머지 도구들은 특정 목적을 위한 보조적인 역할을 합니다."},"title":"android sdk tool list"},"/02.inbox/ascii-code/":{"data":{"":"제어 문자\n0 (Null) - 십진수 0에 해당하는 제어 문자입니다. 주로 문자열의 종료를 나타내는 데 사용됩니다. 1 (Start of Heading) - 통신 제어에서 사용되는 제어 문자로, 통신 헤더의 시작을 나타냅니다. 2 (Start of Text) - 통신 제어에서 사용되는 제어 문자로, 텍스트 데이터의 시작을 나타냅니다. 3 (End of Text) - 통신 제어에서 사용되는 제어 문자로, 텍스트 데이터의 종료를 나타냅니다. 4 (End of Transmission) - 통신 제어에서 사용되는 제어 문자로, 전송의 종료를 나타냅니다. 5 (Enquiry) - 통신 제어에서 사용되는 제어 문자로, 상대방에게 정보 요청을 나타냅니다. 6 (Acknowledge) - 통신 제어에서 사용되는 제어 문자로, 정보 수신을 확인하는 신호를 나타냅니다. 7 (Bell) - 터미널이나 출력 장치에서 경고음을 발생시키는 제어 문자입니다. 8 (Backspace) - 커서를 한 칸 뒤로 이동시키는 제어 문자입니다. 공백문자\n9 (Horizontal Tab) - 가로 탭 문자로, 텍스트에서 일정한 간격으로 열을 정렬하거나 수평 간격을 만들기 위해 사용됩니다. 일반적으로 탭 문자는 다음 탭 정지 위치로 커서를 이동시킵니다. 10 (Line Feed) - 줄 바꿈 문자로, 텍스트에서 다음 줄로 이동하여 새로운 줄을 시작합니다. 주로 줄 바꿈을 나타내는 역할을 합니다. 11 (Vertical Tab) - 세로 탭 문자로, 주로 출력 장치에서 사용되며, 수직 간격을 만들기 위해 사용될 수 있습니다. 일반적으로 세로 탭은 다음 세로 탭 정지 위치로 커서를 이동시킵니다. 12 (Form Feed) - 용지 공급 문자로, 출력 장치에서 새로운 페이지를 시작하거나 용지를 공급하는 데 사용됩니다. 일반적으로 용지 공급 문자는 출력 장치의 내부 버퍼를 비우고 커서를 첫 번째 위치로 이동시킵니다. 13 (Carriage Return) - 복귀 문자로, 텍스트에서 커서를 현재 줄의 처음으로 이동시킵니다. 주로 줄의 끝으로 커서를 이동한 후 다음 줄로 이동하기 전에 사용됩니다. 제어문자\n14 (Shift Out) - 출력 장치에 문자 세트 전환이 필요한 경우에 사용됩니다. 주로 7비트 ASCII 코드와 다른 문자 세트 간의 전환이나 확장 문자 세트의 사용을 나타내기 위해 사용됩니다. 15 (Shift In) - 출력 장치에서 이전 문자 세트로 전환하는 데 사용됩니다. Shift Out과 짝을 이루며, 문자 세트 전환이 필요한 경우에 사용됩니다. 16 (Data Link Escape) - 통신 제어에서 사용되며, 데이터 링크 계층에서 제어 문자가 전송되어야 함을 나타냅니다. 주로 프로토콜 간의 전환, 프레임 동기화 등에 사용됩니다. 17 (Device Control 1) - 주로 출력 장치 제어에 사용되는 제어 문자입니다. 특정 출력 장치의 기능을 활성화 또는 비활성화하기 위해 사용될 수 있습니다. 18 (Device Control 2) - 주로 출력 장치 제어에 사용되는 제어 문자입니다. 특정 출력 장치의 기능을 활성화 또는 비활성화하기 위해 사용될 수 있습니다. 19 (Device Control 3) - 주로 출력 장치 제어에 사용되는 제어 문자입니다. 특정 출력 장치의 기능을 활성화 또는 비활성화하기 위해 사용될 수 있습니다. 20 (Device Control 4) - 주로 출력 장치 제어에 사용되는 제어 문자입니다. 특정 출력 장치의 기능을 활성화 또는 비활성화하기 위해 사용될 수 있습니다. 21 (Negative Acknowledge) - 통신 제어에서 사용되며, 정보 수신이 실패하거나 확인이 불가능한 경우에 사용됩니다. 22 (Synchronous Idle) - 동기화된 통신에서 사용되며, 데이터 전송이 없는 상태를 나타냅니다. 23 (End of Transmission Block) - 통신 제어에서 사용되며, 전송 블록의 종료를 나타냅니다. 24 (Cancel) - 현재 진행 중인 작업을 취소하거나 중단하기 위해 사용됩니다. 25 (End of Medium) - 현재 데이터 저장 장치의 끝을 나타내는 제어 문자입니다. 26 (Substitute) - 통신 제어에서 사용되며, 데이터 전송 중에 오류가 발생한 경우 대체 문자로 사용될 수 있습니다. 27 (Escape) - 통신 및 컴퓨터 시스템에서 특정 동작이나 명령을 활성화하기 위해 사용됩니다. 주로 제어 시퀀스나 특수 명령을 나타내는 데 사용됩니다. 28 (File Separator) - 파일 분리자로, 데이터 레코드 내에서 파일 경계를 나타냅니다. 29 (Group Separator) - 그룹 분리자로, 데이터 레코드 내에서 그룹 경계를 나타냅니다. 30 (Record Separator) - 레코드 분리자로, 데이터 레코드를 분리하기 위해 사용됩니다. 31 (Unit Separator) - 유닛 분리자로, 데이터 레코드 내에서 유닛 경계를 나타냅니다. 127 (Delete) - delete 제어 문자로 해당 문자 이전의 문자를 삭제하는 역할을 합니다 vim에서 제어문자 입력 Unix and Linux 에서 사용: ctrl- v ctrl-m Windows에서 사용: ctrl- q ctrl-m\nCtrl- V다음 입력 문자가 문자 그대로 삽입되어야 함을 vi(shell)에 알리고 ctrl- m는 캐리지 리턴을 위한 키 입력입니다."},"title":"ascii code"},"/02.inbox/asm-parameter-passing-%EC%9D%B8%EC%9E%90-%EC%A0%84%EB%8B%AC-%EB%B0%A9%EC%8B%9D/":{"data":{"":"다음은 인텔 어셈블리 문법으로 각 파라미터 전달 방식을 구현한 예시","1-register를-통한-파라미터-전달#\u003cstrong\u003e1. Register를 통한 파라미터 전달\u003c/strong\u003e":"section .data ; (데이터 섹션은 필요 시 정의) section .text global _start _start: ; 두 정수를 레지스터로 전달 (EAX=5, EBX=10) mov eax, 5 mov ebx, 10 call add_registers ; 함수 호출 ; 결과 확인 (EAX에 저장됨) ; ... (종료 코드 생략) add_registers: add eax, ebx ; EAX = EAX + EBX ret ; 결과를 EAX에 반환 특징: 레지스터(eax, ebx)에 직접 값 저장 → 빠른 접근 가능. 주의: 레지스터 수가 제한적이므로 복잡한 함수에는 부적합.","2-memory를-통한-파라미터-전달-포인터-사용#\u003cstrong\u003e2. Memory를 통한 파라미터 전달 (포인터 사용)\u003c/strong\u003e":"section .data var1 dd 15 ; 32비트 정수 (15) var2 dd 25 ; 32비트 정수 (25) section .text global _start _start: ; 메모리 주소를 레지스터로 전달 mov esi, var1 ; ESI = var1의 주소 mov edi, var2 ; EDI = var2의 주소 call add_memory ; 함수 호출 ; ... (종료 코드 생략) add_memory: mov eax, [esi] ; EAX = [var1] (15) add eax, [edi] ; EAX += [var2] (25) ret ; 결과 반환 특징: 메모리 주소를 레지스터(esi, edi)로 전달 → 대용량 데이터 처리 가능. 주의: 메모리 접근 오버헤드 발생 (캐시 미스 시 성능 저하). 일반적으로 힙 영역에 적층","3-stack을-통한-파라미터-전달#\u003cstrong\u003e3. Stack을 통한 파라미터 전달\u003c/strong\u003e":"section .data ; (데이터 섹션은 필요 시 정의) section .text global _start _start: ; 스택에 파라미터 푸시 (역순으로 전달) push 30 ; 두 번째 인자 push 40 ; 첫 번째 인자 call add_stack ; 함수 호출 ; 스택 정리 (cdecl 규약: 호출자가 정리) add esp, 8 ; 2개의 DWORD(4바이트*2) 제거 ; ... (종료 코드 생략) add_stack: push ebp ; 베이스 포인터 보존 mov ebp, esp ; 스택 프레임 설정 ; [ebp+8] = 첫 번째 인자 (40) ; [ebp+12] = 두 번째 인자 (30) mov eax, [ebp+8] add eax, [ebp+12] pop ebp ; 베이스 포인터 복구 ret ; 결과 반환 특징: 스택을 통해 인자 전달 → 재귀 호출 등 복잡한 로직에 적합. 주의: 스택 오버플로우 위험 (너무 큰 데이터 전달 금지).","키-포인트#\u003cstrong\u003e키 포인트\u003c/strong\u003e":"Register: 빠르지만 제한적 → 최적화된 코드에 사용. Memory: 대용량 데이터 처리 가능 → 구조체/배열 전달 시 유리. Stack: 함수 호출 관리 용이 → 대부분의 고수준 언어 기본 방식. 인텔 문법에서 mov eax, [ebx]는 “ebx가 가리키는 메모리 값 로드\"이며, push, pop은 스택 조작 명령어입니다."},"title":"asm parameter passing 인자 전달 방식"},"/02.inbox/att-%EB%AC%B8%EB%B2%95-%EA%B3%BC-intel-assemble-%EB%AC%B8%EB%B2%95-%EC%B0%A8%EC%9D%B4/":{"data":{"":"x86 아키텍처에서 어셈블리 언어는 주로 Intel과 AT\u0026T 두 가지 구문 형식으로 나뉘어 사용된다 이 두 형식은 문법과 명령어의 표현 방식에서 차이가 있다","1-intel-구문#1. Intel 구문":"형식: 피연산자는 보통 목적지(대상) 먼저, 원천(소스) 다음으로 나열 예시: MOV EAX, EBX ; EBX의 값을 EAX로 이동 ADD EAX, 5 ; EAX에 5를 더함","2-att-구문#2. AT\u0026amp;T 구문":"형식: 소스가 먼저, 목적지가 뒤 레지스터와 즉시 값 앞에 ‘%‘와 ‘$‘를 붙입니다. 예시: mov %ebx, %eax ; EBX의 값을 EAX로 이동 add $5, %eax ; EAX에 5를 더함"},"title":"AT\u0026T 문법 과 Intel Assemble 문법 차이"},"/02.inbox/c-cpp-%EC%97%B0%EC%82%B0%EC%9E%90-%EC%9A%B0%EC%84%A0%EC%88%9C%EC%9C%84/":{"data":{"":""},"title":"c, cpp 연산자 우선순위"},"/02.inbox/cc++-vs-code/":{"data":{"":"컴파일 시에 다음과 같은 3가지 환경 설정이 필요하다(project 내부에서만 작동)\n==c_cpp_properties.json== (compiler path and IntelliSense settings) ==tasks.json== ==(build instructions) ==launch.json== ==(debugger settings)==","mac-기준#mac 기준":"task.json\n{ \"tasks\": [ { //c++ 컴파일러 \"type\": \"shell\", \"label\": \"clang++ 빌드 및 터미널 실행\", \"command\": \"/usr/bin/clang++\", \"args\": [ \"-std=c++17\", \"-fcolor-diagnostics\", \"-fansi-escape-codes\", \"-g\", \"${file}\", \"-o\", \"${fileDirname}/${fileBasenameNoExtension}\", // 파일 실행부 \"\u0026\u0026\", \"${fileDirname}/${fileBasenameNoExtension}\", ], \"options\": { \"cwd\": \"${fileDirname}\" }, \"problemMatcher\": [ \"$gcc\" ], \"group\": { \"kind\": \"build\", \"isDefault\": true }, \"detail\": \"직접 실행 task\" }, { //c 컴파일러 \"type\": \"shell\", \"label\": \"clang 빌드 및 터미널 실행\", \"command\": \"/usr/bin/clang\", \"args\": [ \"-std=c11\", \"-fcolor-diagnostics\", \"-fansi-escape-codes\", \"-g\", \"${file}\", \"-o\", \"${fileDirname}/${fileBasenameNoExtension}\", // 파일 실행부 \"\u0026\u0026\", \"${fileDirname}/${fileBasenameNoExtension}\", ], \"options\": { \"cwd\": \"${fileDirname}\" }, \"problemMatcher\": [ \"$gcc\" ], \"group\": { \"kind\": \"build\", \"isDefault\": true }, \"detail\": \"직접 실행 task\" }, { //디버깅시에 사용되는 cpp 빌드 설정 \"type\": \"cppbuild\", \"label\": \"C/C++: clang++ 활성 파일 빌드\", \"command\": \"/usr/bin/clang++\", \"args\": [ \"-std=c++17\", \"-fcolor-diagnostics\", \"-fansi-escape-codes\", \"-g\", \"${file}\", \"-o\", \"${fileDirname}/${fileBasenameNoExtension}\" ], \"options\": { \"cwd\": \"${fileDirname}\" }, \"problemMatcher\": [ \"$gcc\" ], \"group\": { \"kind\": \"build\", \"isDefault\": true }, \"detail\": \"디버거에서 생성된 작업입니다.\" }, { //디버깅시에 사용되는 c 빌드 설정 \"type\": \"cppbuild\", \"label\": \"C/C++: clang 활성 파일 빌드\", \"command\": \"/usr/bin/clang\", \"args\": [ \"-std=c11\", \"-fcolor-diagnostics\", \"-fansi-escape-codes\", \"-g\", \"${file}\", \"-o\", \"${fileDirname}/${fileBasenameNoExtension}\" ], \"options\": { \"cwd\": \"${fileDirname}\" }, \"problemMatcher\": [ \"$gcc\" ], \"group\": { \"kind\": \"build\", \"isDefault\": true }, \"detail\": \"디버거에서 생성된 작업입니다.\" }, { //실행용 \"label\": \"exec\", \"type\": \"shell\", \"command\": \"${fileDirname}/${fileBasenameNoExtension}\", \"group\": { \"kind\": \"build\", \"isDefault\": true } } ], \"version\": \"2.0.0\" } launch.json\n{ // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"c++ 디버그\", \"type\": \"lldb\", \"request\": \"launch\", \"program\": \"${fileDirname}/${fileBasenameNoExtension}\", \"args\": [], \"preLaunchTask\": \"C/C++: clang++ 활성 파일 빌드\", \"stdio\": [null, null, null], \"terminal\": \"integrated\" }, { \"name\": \"c 디버그\", \"type\": \"lldb\", \"request\": \"launch\", \"program\": \"${fileDirname}/${fileBasenameNoExtension}\", \"args\": [], \"preLaunchTask\": \"C/C++: clang 활성 파일 빌드\", \"stdio\": [null, null, null], \"terminal\": \"integrated\" }, { \"name\": \"g++ - Build and debug active file\", \"type\": \"cppdbg\", \"request\": \"launch\", \"program\": \"${fileDirname}/${fileBasenameNoExtension}\", \"args\": [], \"stopAtEntry\": true, \"cwd\": \"${workspaceFolder}\", \"environment\": [], \"externalConsole\": true, \"MIMode\": \"lldb\", \"preLaunchTask\": \"C/C++: g++ build active file\" } ] }"},"title":"c,c++ vs code"},"/02.inbox/cdn-%EB%A7%81%ED%81%AC-%EC%B0%BE%EA%B8%B0/":{"data":{"":"","-cdnjs#🔹 cdnjs":"","-jsdelivr#🔹 jsDelivr":"","-unpkg#🔹 UNPKG":"🔹 jsDelivr GitHub, npm 패키지를 CDN으로 제공 검색창에 라이브러리 이름 입력 → 버전 선택 → 자동 생성된 링크 복사 예: https://cdn.jsdelivr.net/npm/jquery@3.7.1/dist/jquery.min.js\n🔹 cdnjs 수천 개의 오픈소스 라이브러리 제공 검색 → 원하는 버전 클릭 → Copy 버튼으로 링크 복사 예: https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js\n🔹 UNPKG npm 패키지를 CDN으로 제공 https://unpkg.com/[패키지명]@[버전]/[파일경로] 예: https://unpkg.com/react@18/umd/react.production.min.js"},"title":"CDN 링크 찾기"},"/02.inbox/cloud-computing-%EA%B3%BC%EC%A0%9C2-%EB%B3%B4%EA%B3%A0%EC%84%9C/":{"data":{"":"1. 기존 WordCount 프로그램에 추가하거나 개선하고자 하는 각 기능 설명 문장 부호(!?,.’\"{}()) 및 소 중괄호 제거 대소문자 구분 여부를 확인하기 위해 –case-sensitive true|false 인수를 받음 2. 입력 데이터 설명 - 데이터 전체를 보고서에 포함하거나 별도 파일로 제출 bash_menual_file 를 사용하여 입력데이터로 사용하였음\n3. 각 기능에 대한 구현 결과물 - 소스 코드 전체를 보고서에 포함하거나 별도 파일로 제출 (jar 파일 X) WordCount.java 파일\n4. 각 기능에 대한 실행 결과물 - 실행 화면 전체를 보고서에 포함하거나 별도 파일로 제출]","1-기존-wordcount-프로그램에-추가하거나-개선하고자-하는-각-기능-설명#1. 기존 WordCount 프로그램에 추가하거나 개선하고자 하는 각 기능 설명":"","2-입력-데이터-설명---데이터-전체를-보고서에-포함하거나-별도-파일로-제출#2. 입력 데이터 설명 - 데이터 전체를 보고서에 포함하거나 별도 파일로 제출":"","3-각-기능에-대한-구현-결과물---소스-코드-전체를-보고서에-포함하거나-별도-파일로-제출-jar-파일-x#3. 각 기능에 대한 구현 결과물 - 소스 코드 전체를 보고서에 포함하거나 별도 파일로 제출 (jar 파일 X)":"","4-각-기능에-대한-실행-결과물---실행-화면-전체를-보고서에-포함하거나-별도-파일로-제출#4. 각 기능에 대한 실행 결과물 - 실행 화면 전체를 보고서에 포함하거나 별도 파일로 제출]":"","mapreduce-적용-방법론---input-keyvalue-pairs-input-parameters-map-함수-로직-reduce-함수-로직-output-keyvalue-pairs-등을-기술#MapReduce 적용 방법론 - Input Key/Value Pairs, Input Parameters, Map 함수 로직, Reduce 함수 로직, Output Key/Value Pairs 등을 기술":"Input Key/Value Pairs: Key: PATH (뉴스 기사저장 위치) Value: Text (뉴스 기사 내용) Input Parameters: 입력 경로: HDFS에 저장된 RSS 피드 데이터 경로 출력 경로: 분석 결과를 저장할 HDFS 경로 대소문자 구분 여부: –case-sensitive true|false Map 함수 로직: 기사를 입력받아 문장 부호를 제거하고, 대소문자를 처리한 후 단어를 토큰화 각 단어의 빈도를 카운트하여 (word, 1) 형식으로 출력 Reduce 함수 로직: 같은 단어에 대해 Map 단계에서 생성된 값을 합산하여 각 단어의 총 빈도를 계산합니다. 최종적으로 각 단어와 그 빈도를 출력합니다. Output Key/Value Pairs: Key: Text (단어) Value: IntWritable (단어 빈도수)","대소문자-구분-기능#대소문자 구분 기능":"대소문자 구분 안 하는 버전 대소문자 구분하지 않은 control 단어는 114개 산출됨\n대소문자 구분 버전 Control : 30 개 control : 84개 각각 분리됨","문장-부호--및-소-중괄호-제거-기능#문장 부호 !?,.\u0026rsquo;\u0026quot;{}() 및 소 중괄호 제거 기능":"제대로 동작확인함","응용-분야에-대한-설명-및-적합도why#응용 분야에 대한 설명 및 적합도(Why?)":"실시간으로 업데이트 되는 주식관련 기사를 분석하여 현재 시장에서 관심있는 키워드 분석을 통해 여론을 실시간으로 파악하는 것이 목표 RSS 피드를 통해 원하는 뉴스 출처를 구독하고 대규모 데이터 처리에 적합한 MapReduce 모델을 활용하여 대량의 기사 데이터를 효과적으로 분석 가능","입출력-데이터-정보---입력-데이터의-특징-및-수집-방법---출력-데이터-format-및-이를-통해-도출하고자-하는-정보#입출력 데이터 정보 - 입력 데이터의 특징 및 수집 방법 - 출력 데이터 Format 및 이를 통해 도출하고자 하는 정보":"입력 데이터: RSS 피드를 통해 수집된 주식관련 뉴스 기사. 각 기사는 제목, 본문, 날짜 등으로 구성됩니다. 수집 방법: Python의 feedparser 라이브러리 등을 사용하여 RSS 피드에서 데이터를 추출하고, 해당 데이터를 HDFS에 저장합니다. 출력데이터 : 실시간 뉴스 기다들의 키워드 별 빈도수를 계산한다"},"title":"Cloud Computing 과제2 보고서"},"/02.inbox/cpp-%EB%A9%94%EB%AA%A8%EB%A6%AC-%ED%95%A0%EB%8B%B9-%EC%B6%94%EC%B2%99/":{"data":{"":"operator new를 오버로딩하여 메모리 할당 시 로그를 출력\nvoid* operator new(std::size_t count) { std::cout \u003c\u003c count \u003c\u003c \" bytes 할당 \" \u003c\u003c std::endl; return malloc(count); } stdout 으로 할당된 양을 뽑는다"},"title":"cpp 메모리 할당 추척"},"/02.inbox/cpp-%EB%AC%B8%EC%9E%90%EC%97%B4-split/":{"data":{"":"vector\u003cstring\u003e split(const string\u0026 input, const string\u0026 delimiter) { vector\u003cstring\u003e ret; size_t pos = 0; string token; // input 문자열이 비어있거나 delimiter가 비어있으면 빈 벡터 반환 if (input.empty() || delimiter.empty()) { return ret; } string str = input; // 원본 문자열을 수정하지 않기 위해 복사 // 구분자가 문자열에 없을 때까지 반복 while ((pos = str.find(delimiter)) != string::npos) { token = str.substr(0, pos); // 구분자 이전의 문자열 추출 ret.push_back(token); // 벡터에 추가 str.erase(0, pos + delimiter.length()); // 구분자 이후의 문자열로 업데이트 } // 남은 문자열 추가 ret.push_back(str); // 마지막 토큰 추가 return ret; }"},"title":"cpp 문자열 split"},"/02.inbox/db-book-%EB%8B%B5%EC%A7%80-%ED%8C%8C%EC%9D%BC-%EB%8B%A4%EC%9A%B4%EB%B0%9B%EB%8A%94-javascript/":{"data":{"":"https://db-book.com/bib-dir/index.html 여기 위치에서 콘솔창은 연후 모든 pdf 파일을 다운받는다\n// 모든 PDF 링크와 이름을 선택 const rows = document.evaluate( '/html/body/center/table/tbody/tr', document, null, XPathResult.ORDERED_NODE_SNAPSHOT_TYPE, null ); // 링크 배열 생성 const pdfData = []; for (let i = 0; i \u003c rows.snapshotLength; i++) { const row = rows.snapshotItem(i); const nameElement = row.querySelector('td:nth-child(1)'); // 파일 이름 const linkElement = row.querySelector('td:nth-child(2) a'); // PDF 링크 // 요소가 존재하는지 확인 if (nameElement \u0026\u0026 linkElement) { const name = nameElement.textContent.trim(); // 파일 이름 const url = linkElement.href; // PDF 링크 pdfData.push({ url: url, name: name }); } else { console.warn(`Row ${i + 1} does not contain the expected elements.`); } } // PDF 다운로드 함수 const downloadFiles = async (pdfData) =\u003e { for (const { url, name } of pdfData) { const a = document.createElement('a'); a.href = url; a.download = name + '.pdf'; // 파일 이름 지정 document.body.appendChild(a); a.click(); document.body.removeChild(a); // 오류발생 가능성 때문에 다운로드 사이에 잠시 대기 오류발생 가능성 때문에 await new Promise(resolve =\u003e setTimeout(resolve, 100)); // 0.1초 대기 } }; // PDF 다운로드 수행 downloadFiles(pdfData);"},"title":"db book 답지 파일 다운받는 javascript"},"/02.inbox/di-%EC%9D%98%EC%A1%B4%EC%84%B1-%EC%A3%BC%EC%9E%85-%EC%9D%98-%ED%83%80-%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC-%EC%A0%91%EA%B7%BC-%EC%9C%A0%ED%8A%9C%EB%B8%8C-%EB%8C%93%EA%B8%80/":{"data":{"":"","elecricecooker#@elecricecooker":"","tjrals6665#@tjrals6665":"영상을보다가 좀 답답해서 글을 써봅니다. 호돌맨과 항로님이 그냥 코딩에대한 감각이 없는것같다는 생각이 듭니다. 두분이 좋아하는 방식은 데이터를 다루는 영역에서 유효한 방식인데 그게 두분 전문분야인 웹 백엔드죠. 그러다보니 조금 착각이 일어나시는 것 같습니다. 우선 백엔드의 환경에 대해서 알아야하는데 웹 백엔드는 환경을 통제하기 쉽고(내 서버에 배포) 일종의 요청의 처음과 끝이 존재하는 심플한 방식이고 데이터를 가공해서 스토리지에 저장하는것이 주 목적입니다. 이런 환경에서는 말씀하시는 클래스와 DI같은 레이어링을 위한 추상화 방식이 유효해집니다. 스토리지는 인터페이스는 같지만 실제 구현체가 여러종류일 수 있고 (다형성) 그런 구현체를 주입하기위한 DI는 유효할 수 있습니다, 두분이 좋아하시는 자바 스프링의 어노테이션은 나름 괜찮은 표현력을 제공하죠. 저도 어떤 환경에서 프로그래밍을 하던 데이터 레이어가 복잡해지면 그와 같은 방식을 선호합니다. 나쁘지않은 방식이죠 근데 웹 프론트 환경에서의 클래스와 DI는 복잡도를 더 높입니다. 두분이 선호하는 클래스와 DI방식의 프레임워크로는 앵귤러가 있는데요, 앵귤러는 어노테이션 DI 다 스프링처럼 제공합니다. 근데 앵귤러가 왜 시장에서 외면받았느냐를 분석해드리겠습니다. 실제로 웹 프론트엔드 환경에서 코딩을 해보시면 아시겠지만 js환경에서 앵귤러와같은 표현력을 제공하려면 추상화비용에서 오는 손실이 백엔드보다 더 큽니다. 랜더링이라는 개념이 있고 데이터와 상호작용을 해야해하고 이러한 구현들은 클라이언트 전체적인 아키텍쳐와 상호작용합니다. (백엔드와는 이런 부분들이 다르죠). 예를들어 클라이언트에선 뭔가 백그라운드에서 돌아가고 있을 수 도 있고, 거기에 필요한 데이터 영역이 UI와 상호작용할수도 있습니다. 이 뿐만 아니라 컴포넌트끼리의 상호작용까지 있습니다. 이런 환경에서 과도하게 추상화된 영역은 버그를 일으키고 의존성을 파악하기도 힘들어집니다. 디버깅도 어려워지죠. 작성하기 귀찮은 보일러플레이트는 덤이구요. 그래서 앵귤러는 웹 프론트엔드 환경에서 외면받았습니다. react에서도 mobx와 같은 도구들이 있는데요 컨셉은 좋습니다, 클래스로 탄탄하게 데이터를 다루는 표현력을 제공하겠다, 너무 좋죠. 근데 이게 생각보다 간단하지않습니다. 이런 도구들이 react와 붙으려면 역시 복잡한 의존관계를 관리해야하고 규모가 커질수록 이는 파악하기 어려워집니다. 앵귤러와 비슷한 딜레마가 있습니다, 그래서 메이저가 되진 못했죠. 결론적으로 자연스럽게 코딩하다보면, 호돌맨님과 향로님이 제시하시는 방식은 외면받을 수 밖에 없다는걸 깨달을 때가 되신것같은데 아직 깨닫지못했다는게 정말 신기할 따름입니다. 아키텍쳐만 정해주고 직접 코딩하시진 않아서 그런걸까요? 정말로 리액트에서 클래스랑 DI를 사용하는 방식이 생산성이높다는 생각이든다면 뭔가 어거지 보일러 플레이트를 만들면서 잘못 코딩하고 계신거같고 제 생각엔 그냥 효율성 안나오지만 보일러플레이트 정형화되게 착착 쌓고 이러다보니 아 코딩하기 편하군 이라는 착각에 빠져계신 것 같습니다. 실제 웹 프론트엔드에서 생산성높게 일하는 회사가 어떤 방식을 취하고 계신지 한번 살펴보기를 권합니다.\n간략히\n28\n답글\n답글 17개\n@worldhello-o4w 2주 전(수정됨))\n길게 적다보니 알아듣기 힘들것같은 분들을 위해 데이터와 스토리지를 다루는 백엔드 영역에서 클래스와 DI는 유효한 방법이고 그러한 레이어에서는 필자도 그것을 즐겨 씀 그러나 처음과 끝이 있는 심플한 백엔드와는 다르게 클라이언트는 끝이없는 사용자와의 무한한 상호작용이고, 구현은 클라이언트 전체 아키텍쳐와 상호작용함 이런 환경에서 지불해야하는 DI와 클래스 방식의 추상화비용은 직접 코딩하는사람들에게는 불편함을 불러일으킴, 불편함 대비 이득이 큰 것도 아님 고로 DI와 클래스 접근방식은 웹 프론트엔드 환경에서는 맞지않음. 물론 웹 프론트엔드에서도 데이터를 다루는 영역이 복잡해진다면 해당 레이어는 그러한 접근방법을 택함, 그러나 UI와는 격리함\n간략히\n7\n답글\n@user-vc5vo4ol2g 2주 전\n호돌맨은 내가 누군지 모르겠고, 향로님이 코딩에 대한 감각이 없어요?ㅋㅋㅋㅋ 얘 5년차 안됐네\n답글\n@worldhello-o4w 2주 전(수정됨))\n@user-vc5vo4ol2g “클래스나 DI 같은걸로 복잡도를 낮출 수 있는데 왜 웹 프론트엔드에서는 안하는지 모르겠다, 오히려 복잡도를 늘리는 방향으로 가고 있다” 라고 발언하셔서 코딩감각이 없구나(향로님이 말씀하신 방식은 오히려 복잡도를 늘리는 방식) 라고 판단했고 이유는 위에 적었습니다. 호돌맨님은 옆에 같이 방송하는 분이십니다. 최소 동영상은 보고 답글 달아주시면 좋을 것 같습니다. 마지막으로 인신공격을 하려면 적절한 근거를 부탁드립니다. 감사합니다.\n2\n답글\n@worldhello-o4w 2주 전(수정됨))\n@min-j4d-h3u 의견 감사합니다. 우선 OOP에 대해서 말씀드리면 댓글분의 말씀이 틀리진않습니다. OOP라는게 거기에서만 유효한 방법은 아니지요 다만 스프링과 백엔드에서 제시하는 OOP는 대부분 행동과 개체를 묘사하기 위한 OOP라기보다는 데이터와 스토리지를 다루는데 특화된 부분으로 진화되어 있습니다. 그래서 그런 부분을 프론트엔드에 강제로 적용하려는 방식은 오히려 개발자들의 불편을 불러일으킨다고 말씀드릴 수 있겠습니다. Unreal엔진같은 게임엔진에서 제시하는 OOP스타일도 한번 보신다면 흐름 자체가 상당히 많은 부분이 다르다는것을 알 수 있습니다. 물론 기초가 되는 개념 자체는 비슷할 수 있겠지만 게임쪽에서는 어떤 한 방법론만을 따르지않기때문에 여러가지 영감을 얻어보실 수 있을 겁니다. 향로님이 영상에서 말씀하신 것 처럼 “클래스나 DI 같은걸로 복잡도를 낮출 수 있는데 왜 웹 프론트엔드에서는 안하는지 모르겠다, 오히려 복잡도를 늘리는 방향으로 가고 있다” 라는 웹 프론트 생태계를 싸잡아 비난하는 태도도 좋은 접근은 아닌것같습니다, 심지어 구독자수도 꽤 되는 채널에서 말이죠. 이러면 이 채널을 보는 많은 신입 개발자들에게 혼란을 줍니다. 심지어 틀린말씀이라 조금 강하게 지적해보았습니다. 추가로 네임드 개발자분과 다른관점 이라고 하셨는데 사실 향로님과 호돌맨님은 그냥 평범한 백엔드 개발자시지 정말 최전선의 개발 생태계에 큰 영향을 끼치시는 분들은 아닙니다, 본인들도 그건 잘 알고 있을겁니다. 오히려 글로벌 빅 테크회사에서 웹 프론트엔드 생태계 프레임워크를 개발하는분들이 전 세계적인 네임드 개발자시기때문에 이 경우에는 향로님과 호돌맨님이 그분들과 다른의견을 내고 계산상황, 즉 도전자라고 보는것이 옳을 것 같습니다. 생산성 높게 일하는 회사들로는 한국에서는 당근, 토스, 그리고 해외에서는 대표적으로 react를 만든 메타가 있을것같습니다. 그 외 빅테크들도 react를 적절하게 활용하고 있으니 어떤 방식으로 다루는지 보면 좋겠지요. 이 회사들에서 외부에 공개해놓은 자료들을 참고해보신다면 어떤 얘기들을 하고있는지 확인해볼 수 있습니다. 마침 토스에서 공개해놓은 자료도 있으니 링크를 첨부해봅니다. https://frontend-fundamentals.com/code/examples/form-fields.html 대안의 경우는 특별히 대안이 있다기보단 일반적인 웹 프론트생태계의 흐름에 호돌맨님과 향로님이 반박을 하고 계신상황이기에, 일반적인 웹 프론트 생태계의 아키텍쳐나 코드구조 멘탈모델을 확인해보시면 좋을것같습니다.\n간략히\n3\n답글\n@elecricecooker 2주 전\n첫문장 들이박는거 보고 바로 쭉내렸습니다\n1\n답글\n@user-xk4jb8si8w 2주 전\n의존성 주입에 대해 좀 더 공부해보시는 게 좋을 거 같아요.. react에서 의존성 주입 라이브러리를 사용해서 프로젝트가 더 복잡해졌다고 하는데 애초에 의존성 주입 자체가 서로 간의 영향을 덜 받기위해 사용하는 기법이에요.. react에서 사용이 불편하단건 해당 라이브러리의 문제지 의존성 주입의 문제가 아닙니다.. 의존성 주입을 하기 위해 만드는 코드를 보일러 플레이트 코드라고 생각하시는 거 자체가 의존성 주입에 대한 이해도가 부족하다고 생각해요.. 혼자서 하는 단일 프로젝트는 속도를 위해 의존성 주입없이 하는게 편하긴 하지만 이 개념이 나온 이유에 대해 공부해보시는 걸 추천해요..\n답글\n@worldhello-o4w 2주 전(수정됨))\n@user-xk4jb8si8w 제 얘기는 영상을 찍으신 두 분이 제시하시는 DI방식에 대한 얘기였구요. 의존성 주입 이라는 개념자체를 배제하는것은 아닙니다. react에서도 props로 여러 요소들(함수 컴포넌트 등등)을 받는것도 의존성 주입이죠. 근데 DI framework같은 것들을 사용해서 뭔가 환경과 맞지않는 규격을 도입하려고하는게 좋지않은거구요, 그러므로 인해 멋들어지게 그런 개념을 도입해봤자 그 복잡성이라는것이 사라지지는 않는다는 뜻입니다. 그리고 코딩하기 불편하면 그냥 그 상황에서 안 좋은겁니다. react의 문제라기보단 react는 그런 방식의 코딩을 의도하지 않는거죠, 때문에 거기서 억지로 사용해야할 방법이 아니구요. (그럼 앵귤러는 잘 살아남았어야 합니다 DI를 편하게 지원하니깐) 개념은 훌륭한데 사용하기 불편해서 사용하지않는경우는 굉장히 많이 있습니다. 예를들어 effect-ts라는 라이브러리를 보시면 함수형 프로그래밍의 개념을 도입하여 부수 효과들을 어떻게 다룰지에 대한 굉장히 훌륭한 개념을 제시하고있습니다, rust에서 코딩하는것처럼 코딩할 수 있죠. 컨셉은 한번 보시길 추천드립니다. 근데 js에서 그런 개념을 네이티브하게 지원하지않고 해당 라이브러리에 대한 멘탈모델에 대한 학습비용, 그러한 개념을 js 환경에서 지원 안함으로써 커버해야하는 부분들, 이런 이유때문에 역시 메이저가 되진 못합니다. 대부분 이런것들은 어디선가 잘 작동하던 멘탈모델을 그대로 옮겨오고싶은것에서 기인하지만, 결국 사용이 불편한것들은 사용되지않습니다. 훌륭한 개념이라고 모든것을 도입해야하는것은 아닙니다. 전반적인 생태계에 대한 이해와 생태계가 주는 한계점을 파악하고, 적절한 코드와 인터페이스를 제시해야하죠. 경험과 공부를 더 해보는것을 추천드립니다, 특히 코딩은 좀 더 해보셔야할것같네요.\n자세히 보기\n1\n답글\n@user-xk4jb8si8w 2주 전\n@worldhello-o4w 저는 훌륭한 개념이라고 어디든 도입해야 한다고 말한적 없습니다. 의존성 주입자체의 개념이 특정 객체에 대한 연결성과 해당 class에 대한 변화가 있으면 그거에 영향을 받는 부분들을 고려해서 사용되는 겁니다. 이런거 고려해서 react라고 무조건 의존성 주입 사용하라거나 하지말라는게 아니라 프로젝트 규모나 인원에 따라서 사용할지 안할지 고려하는 거구요. 본인 아는 만큼 보이는거니까 이해하겠지만 남들이 다른 이야기할때는 그 부분에 대해서도 생각해보시길 바랍니다.\n답글\n@user-xk4jb8si8w 2주 전\n@worldhello-o4w 저는 공부하라고 말씀드린 것도 정말 의존성 주입에 대한 이해가 부족한 거 같아 말씀드리는 건데.. 이렇게 비꼬시는거 보면 더이상 이야기할 가치를 못 느낍니다.\n1\n답글\n@worldhello-o4w 2주 전(수정됨))\n@user-xk4jb8si8w 죄송한데 어떤말을 하고싶으신지 잘 모르겠습니다. 그래서 호돌맨님과 향로님의 접근방식이 맞다, 당신이 틀렸다 인지. 아니면 그저 의존성주입이라는 지식을 자랑하고 싶으셨던것인지 (솔직히 제가 당신보다는 많이 알것같긴합니다) 전자라면 이미 시장에서 여러가지 이유로 외면받는 구조라는것을 말씀드렸구요 후자면 대화를 더 해볼필요는 없을 것 같습니다. 대화할땐 의도를 명확하게 말씀해주시는걸 추천드립니다. 그리고 프로젝트 규모가 커진다고 스프링에서 사용하는 DI방식이 웹 프론트엔드에서 유효한건 아닙니다. 참고로 말씀드리면 저는 수백명의 엔지니어들이 작업하고있는 코드베이스에서 작업하고있습니다. 감사합니다.\n자세히 보기\n답글\n@아무것도몰라요-d3l 2주 전(수정됨))\n자바스크립트를 많이 안해봐서 생기는 오해라고 봅니다. 자바랑 자바스크립트는 겉으로 보면 for, if, class 같은 문법이 공통으로 있지만 본질은 다른 언어이죠. 자바스크립트는 웹을 위해 태어났고 HTML문서를 다루기 위해 만들어진 언어입니다. 그래서 플랫폼도 다르고 사용 용도도 다르고 언어의 철학도 많이 다릅니다. 자바스크립트는 본질적으로 타입이 없는 동적 언어이며 객체지향보다는 함수형 프로그래밍에 더 가깝습니다. ES6부터 클래스 문법을 지원하지만 신택스 슈거일 뿐이고 근본은 프로토타입 기반 함수 중심 패러다임입니다. 문제를 DI로 해결할수도 있지만 자바스크립트는 일급 함수를 기본으로 제공하기 때문에 대부분의 경우 함수형 패러다임을 활용하면 간단하고 직관적으로 문제 해결이 가능하죠. 안드로이드나 IOS처럼 코드가 컴파일된 후에 실행되는 구조가 아니기 때문에 언제든 쉽게 외부 툴로 인해 변경될 수 있는 환경이고, 이럴때는 오히려 동적 언어가 더 큰 장점이 되죠 솔직히 말하면 안드로이드에서 XML로 UI를 구성하고 자바로 컨테이너 만들어서 쿵짝쿵짝 하는 코드보다가 일반적인 웹프론트엔드 HTML,CSS,JS로 조합딘 코드를 보면 코드수도 적고 더 직관적이고 더 유지보수가능하고 더 효율적인것을 많이 간과하고 있는것 같아요 문제를 DI를 통해서도 풀 수 있지만 DI를 쓰지 않아서 복잡도가 높아졌다고 주장하는건 공감이 안갑니다. 같은 추상화 레벨이고 Android코드 보고 웹 JS코드보면 DI로 푼거나 함수형 프로그래밍으로 풀어낸거나 비슷비슷합니다. 오히려 DI쪽이 보일러플레이트도 많고 디버깅하기에 더 복잡합니다. 자바스크립트가 기본으로 제공하는 일급 함수, 함수형 패러다임만으로도 문제를 더 간결하게 해결할 수 있다는걸 경험이 부족해 받아들이지못하는것으로 보입니다.\n자세히 보기\n5\n답글\n@user-yl7oh4jb7k 2주 전\n저는 7년차 프론트 개발자 입니다, 허나 그간 BE 경험도 적지 않게 있습니다. 프론트와 백엔드의 궁국적인 차이는 결국 주체가 되는 부분이 무엇이냐에 갈리는것 이라고 생각합니다. 백엔드의 경우 리얼월드에 있는 기능과 관계 그리고 연관짓는거에 더 큰 관점을 둡니다. 프론트의 경우는 ui의 구조와 사용자 편의성 혹은 디자인에 큰 관심사를 지니며, 이런 관점에서 구조 및 추상화를 진행하게됩니다, 또한 사용자에게 보여지는 UI 는 떄때로 회사의 전략적인 이유로 변경을 하기도 합니다. 즉 각각의 개발자가 봐야하는 진리의 원천이 매번 변경된다는것을 의미하기도 하는데요. 이런 배경을 바탕으로 보았을때 OOP에서 사용하는 방식으로 못하지는 않습니다, 다만 진리의 원천이 매변 변경되는 상황에서 DI와 같은 방식이 어렵게 느껴집니다. 또한 많이 사용하게 되는 typescript 의 경우 데코레이터 및 OOP를 위한 타입을 보조해주는 기능이 적습니다. 개발에는 당연히 불가능하다는 거히 없다고 생각합니다만, 업계에서 자주 이야기되는 패러타임을 굳이 거스를 이유또한 없다고 생각합니다.\n간략히\n4\n답글\n@tjrals6665 2주 전(수정됨))\n음..지나가는 입장에서 일단 과한 표현들을 다 빼고 클래스와 (스프링 같은)DI를 사용하면 복잡도를 낮출수 있는가? 라고 하면 그렇지 않다고 생각합니다. 1. 클래스 실제로 클래스 기반 React가 hooks나오기 전에 주류였고요. hooks가 나오고 난 후 간결해지는 코드에 환영하며 다들 넘어갔지요. 저는 클래스로 대표되는 “상속\"모델이 복잡도를 낮출 수 있는가에 대해 회의적인 입장입니다. 특히 UI를 다루는데 있어서요. 간단하게 안드로이드에서 머터리얼 버튼을 생각해볼까요? 대략 다음 구조를 가지고 있습니다. 아름답죠? // Framework Button public class Button extends TextView { ... } // AppCompat implementation public class AppCompatButton extends Button implements TintableBackgroundView { ... } // Material Design variant public class MaterialButton extends AppCompatButton implements Checkable, Shapeable { ... } 하지만 실제 사용은 어떨까요? 스타일의 우선순위 문제가 생길 수 있죠. 라이프사이클쪽도 문제가 생길 수 있고요. https://github.com/material-components/material-components-android/issues/1013 게다가 Class 방식의 상속은 필요치 않은 메서드나 동작들도 상속하게 되는데요. 요구사항이 복잡해질수도록 Sideeffect가 끼어들 가능성이 매우 높습니다. 때문에 가능하면 합성을 하라고 하지요. (하지만 합성을 선호한다면, function 대신 class를 써야할 타당한 이유가 없습니다) 그 후에 나온 SwiftUI, JetpackCompose는 왜 Class모델을 안쓰려고 할까요? Class를 충분히 쓸수 있는 기반을 가진 플랫폼들인데도요? Native 기준으로 Class는 성능 문제도 일으킵니다. 포인터 동등성으로 인한 리렌더링 어려움은 물론이고, 컴파일러 최적화에서도 이득을 보기가 힘듭니다. 때문에 UIKit와 달리 SwiftUI에서는 Struct기반으로 넘어갔어요. https://wwdcnotes.com/documentation/wwdcnotes/wwdc15-414-building-better-apps-with-value-types-in-swift/ C++에서는 성능문제를 극복하기 위해 CRTP, EBO등 괴상한 최적화 방법을 사용해야 함은 물론 생성/소멸자의 예기치 못한 동작등 때문에 Rust도 Class 모델을 포기한거고요. https://blog.rust-lang.org/2015/05/11/traits.html 어찌되었건 다시 돌아오자면 UI에서 Class로 얻는 이득이 크지 않습니다. React 기준 hooks보다 성능이 살짝 좋다고는 하는데, 복잡도를 줄여주는가에는 의문이 듭니다. 2. DI DI는 이미 React Context로 되고 있습니다. https://ko.react.dev/learn/passing-data-deeply-with-context 때문에 Spring or Dagger 스타일의 DI가 필요하다는 뜻이겠지요? 프론트에서 Dagger와 같은 컴파일타임 DI는 Typescript 특성상 쉽지 않을 것 같아 제외하구요. Spring 스타일이라 하더라도 크게 복잡성을 개선시킬 수 있을지 모르겠네요. 그래도 Async Context는 기대하고 있어요. https://github.com/tc39/proposal-async-context 저는 Kotlin context parameters나 Racket Parameterize와 같이 언어 레벨에서 대부분 DI 문제는 해결해주는게 맞다는 입장이라서요. https://github.com/Kotlin/KEEP/blob/master/proposals/context-parameters.md https://docs.racket-lang.org/guide/parameterize.html 정말로 복잡도를 낮추고 간단하게 만들고 싶다면, 다음과 같은 라이브러리나 기술을 탐색/투자해보시기 바랍니다. - 서버상태: tanstack-query, Relay(GraphQL), Isograph - 라이프타임 매니저: Bunshi, Bunja - 폼이나 오버레이: react-hook-form, useFunnel/useOverlay 그렇게 되면 상당한 보일러 플레이트 코드가 줄 가능성이 높다고 봅니다.","user-vc5vo4ol2g#@user-vc5vo4ol2g":"","user-xk4jb8si8w#@user-xk4jb8si8w":"","user-xk4jb8si8w-1#@user-xk4jb8si8w":"","user-xk4jb8si8w-2#@user-xk4jb8si8w":"","user-yl7oh4jb7k#@user-yl7oh4jb7k":"","worldhello-o4w#@worldhello-o4w":"","worldhello-o4w-1#@worldhello-o4w":"","worldhello-o4w-2#@worldhello-o4w":"","worldhello-o4w-3#@worldhello-o4w":"","worldhello-o4w-4#@worldhello-o4w":"","아무것도몰라요-d3l#@아무것도몰라요-d3l":""},"title":"di (의존성 주입) 의 타 프레임워크 접근 유튜브 댓글"},"/02.inbox/disk/":{"data":{"":"mount 인수 없음 findmnt 추천2 fdisk -l (파티션 설정) lsblk * 추천1 df -a dmesg blkid\n순서\n디스크 -\u003e 파티션 -\u003e 파일시스템 지정 -\u003e 마운트\n디스크 -\u003e 파티션 : 파티션 정보를 저장하는 두 가지 다른 테이블 형식 mbr, gpt 방식을 먼저 정하자 fdisk parted gdisk cfdisk 파티션을 어떻게 사용할지 종류를 지정하자 linux, lvm, swap, EFI 등등 파티션 -\u003e 파일지스템 지정: 파티션을 사용하기 전 어떠한 파일 시스템을 사용할지 정하자 mkfs.[파일 시스템] [옵션] [디스크 파티션] mkfs -t(파일 시스템) [옵션] [디스크 파이션] 참조\nhard-disk, nvme 장치를 리눅스에서는 ==sd% # (% 장치 순서 abc, # 은 파티션)== cdrom dvd 장치를 리눅스에서는 sr# (#은 숫자)이라고 부른다 여기는 파티션이 존재하지 않는다\n디스크 파티셔닝 명령어 종류\nfdisk mkfs mount\nfdisk\n파일 시스템이란\n데이터를 더 빠르게 읽고 저장할 수 있는 단위 블록(클러스터)을 소프트웨어적으로 계산해준다. 분산 저장된 연관된 데이터들을 빠르게 찾게 해준다. 디스크 조각(섹터)모음과 같이 디스크 공간을 효율적으로 사용하게 해준다. 하나의 섹터 크기는 512kb 최근에는 4MB 로 바꾸는 추세 섹터를 묶은 단위를 클러스터(윈도우) 또는 블록(유닉스) 클러스터가 생기면서 낭비되는 현상을 slack space 이라고 한다 fdisk: fdisk /dev/sdX: 디스크 파티션 테이블을 관리하는 fdisk 도구를 실행합니다. n: 새로운 파티션 생성 d: 파티션 삭제 t: 파티션 유형 설정 w: 변경사항 저장 및 종료 parted: parted /dev/sdX: 디스크 파티션 테이블을 관리하는 parted 도구를 실행합니다. mklabel: 새로운 파티션 테이블 생성 mkpart: 새로운 파티션 생성 rm: 파티션 삭제 print: 파티션 정보 출력 quit: parted 종료 gdisk (GPT 디스크 전용): gdisk /dev/sdX: GPT 디스크 파티션 테이블을 관리하는 gdisk 도구를 실행합니다. n: 새로운 파티션 생성 d: 파티션 삭제 t: 파티션 유형 설정 p: 파티션 정보 출력 w: 변경사항 저장 및 종료 cfdisk (터미널 기반의 파티션 관리 도구): cfdisk /dev/sdX: cfdisk를 실행하여 디스크 파티션 관리를 시작합니다. 화살표 키와 Enter 키를 사용하여 메뉴를 탐색하고 파티션 작업을 수행합니다. parted, fdisk, gdisk, cfdisk 외에도 다른 도구 및 프로그램도 있을 수 있습니다. 예를 들어, macOS에서는 diskutil을 사용하여 파티션을 관리할 수 있습니다."},"title":"disk"},"/02.inbox/doxyzen-%ED%82%A4%EC%9B%8C%EB%93%9C/":{"data":{"":"키워드 용도 @brief 짧은 설명 @param 매개변수 설명 @return 반환값 설명 @pre 함수를 호출하기 전에 만족되어야 할 조건 (호출자 책임) @post 함수 실행 후 보장되는 상태 (구현자 책임) @throws 예외 명시 @note 부가 정보 @warning 경고 @see/@ref 관련 항목 참조 @deprecated 사용 중단 알림 @todo 향후 작업 @invariant 불변 조건 (클래스용) @author,@date 메타 정보","author-date-version#\u003ccode\u003e@author\u003c/code\u003e, \u003ccode\u003e@date\u003c/code\u003e, \u003ccode\u003e@version\u003c/code\u003e":"용도: 파일 또는 프로젝트 수준의 메타 정보를 제공합니다. 주로 파일 상단의 헤더 주석에 사용되며, 유지보수 및 버전 관리에 도움이 됩니다.\n예시:\n/** * @file heap_sort.cpp * @author 신년기 * @date 2025-10-19 * @version 1.2 * @brief 힙 정렬 알고리즘 구현 (Doxygen 문서화 완료) */ 이 스타일로 주석을 작성하면 코드의 가독성, 유지보수성, 협업 효율성이 크게 향상됩니다.","brief#\u003ccode\u003e@brief\u003c/code\u003e":"용도: 함수, 클래스, 변수 등의 간결한 요약 설명을 제공합니다. 자동 생성 문서에서 제목처럼 사용되며, 첫 문장으로 쓰는 것이 일반적입니다. 길이 제한은 없지만 한 문장이 이상적입니다.\n예시:\n/** * @brief 정수 배열을 힙 정렬로 오름차순 정렬합니다. */ void heapSort(std::vector\u003cint\u003e\u0026 arr);","deprecated#\u003ccode\u003e@deprecated\u003c/code\u003e":"용도: 더 이상 사용하지 말아야 할(구식) API임을 명시합니다. 대체 수단을 함께 제시하는 것이 좋습니다.\n예시:\n/** * @deprecated * @brief 구버전 정렬 함수 (비효율적) * @see heapSort 대신 사용하세요. */ void oldSort(int* arr, int n);","invariant#\u003ccode\u003e@invariant\u003c/code\u003e":"용도: 클래스 전체에서 항상 유지되어야 하는 불변 조건(invariant)을 명시합니다. 생성자, 모든 public 메서드 호출 전후에 이 조건이 항상 참이어야 합니다.\n예시:\n/** * @class MaxHeap * @brief 최대 힙 자료구조 * @invariant 모든 i에 대해: arr[i] \u003e= arr[2*i+1] 및 arr[i] \u003e= arr[2*i+2] * @invariant size() == arr.size() */ class MaxHeap { /* ... */ };","note#\u003ccode\u003e@note\u003c/code\u003e":"용도: 부가 정보, 알고리즘 특성, 시간/공간 복잡도, 사용 팁 등을 기술합니다. @warning보다 덜 강조적이며, 참고용 정보를 담을 때 적합합니다.\n예시:\n/** * @note 시간 복잡도: O(n log n), 공간 복잡도: O(1) * @note 불안정 정렬입니다 (같은 값의 순서가 바뀔 수 있음) */ void heapSort(std::vector\u003cint\u003e\u0026 arr);","param#\u003ccode\u003e@param\u003c/code\u003e":"용도: 함수의 매개변수에 대한 설명을 제공합니다. 매개변수의 이름, 의미, 제약 조건 등을 명시하며, 여러 매개변수가 있을 경우 각각에 대해 기술합니다.\n예시:\n/** * @param arr 정렬할 정수 배열 (참조로 전달됨) * @param ascending true면 오름차순, false면 내림차순 */ void sortArray(std::vector\u003cint\u003e\u0026 arr, bool ascending);","post#\u003ccode\u003e@post\u003c/code\u003e":"용도: 함수 실행이 완료된 후 보장되는 상태를 설명합니다. 이는 구현자의 책임이며, 출력, 부작용, 객체 상태 변화 등을 명확히 할 때 사용됩니다.\n예시:\n/** * @brief 힙에 새 요소를 삽입합니다. * @param value 삽입할 값 * @post 힙 속성이 유지되며, size()가 1 증가함 */ void push(int value);","pre#\u003ccode\u003e@pre\u003c/code\u003e":"용도: 함수를 호출하기 전에 반드시 만족되어야 하는 조건을 명시합니다. 이는 호출자의 책임이며, 조건을 위반할 경우 정의되지 않은 동작(undefined behavior)이 발생할 수 있습니다.\n예시:\n/** * @brief 배열의 중앙값을 반환합니다. * @param arr 비어 있지 않은 정렬된 배열 * @pre arr.size() \u003e 0 * @return 중앙값 */ int median(const std::vector\u003cint\u003e\u0026 arr);","return#\u003ccode\u003e@return\u003c/code\u003e":"용도: 함수의 반환값이 의미하는 바를 설명합니다. void 함수에는 사용하지 않으며, 반환 타입이 복잡하거나 의미가 명확하지 않을 때 특히 중요합니다.\n예시:\n/** * @brief 두 수의 최대공약수를 반환합니다. * @param a 양의 정수 * @param b 양의 정수 * @return a와 b의 최대공약수 (항상 ≥ 1) */ int gcd(int a, int b);","see--ref#\u003ccode\u003e@see\u003c/code\u003e / \u003ccode\u003e@ref\u003c/code\u003e":"용도: 관련된 함수, 클래스, 문서 등을 참조하도록 안내합니다.\n@see: 일반 텍스트로 참조 @ref: Doxygen이 자동으로 하이퍼링크를 생성 (HTML 문서에서 클릭 가능) 예시:\n/** * @brief 힙을 구성합니다. * @see heapSort * @ref pushDown 함수도 참조하세요. */ void buildHeap(std::vector\u003cint\u003e\u0026 arr);","throws-또는-exception#\u003ccode\u003e@throws\u003c/code\u003e (또는 \u003ccode\u003e@exception\u003c/code\u003e)":"용도: 함수가 던질 수 있는 예외의 종류와 그 조건을 명시합니다. 예외 안전성(exception safety)을 이해하고 안정적인 코드를 작성하는 데 중요합니다.\n예시:\n/** * @brief 인덱스로 요소에 접근합니다. * @param i 접근할 인덱스 * @throws std::out_of_range i가 [0, size()) 범위를 벗어날 경우 * @return 참조된 요소 */ int\u0026 at(size_t i);","todo#\u003ccode\u003e@todo\u003c/code\u003e":"용도: 향후 구현하거나 개선해야 할 사항을 기록합니다. 개발 중인 기능, 리팩토링 계획, 확장 포인트 등을 문서화할 때 유용합니다.\n예시:\n/** * @todo C++20 ranges 지원 추가 * @todo 병렬화 (std::execution::par) */ void advancedSort(std::vector\u003cint\u003e\u0026 arr);","warning#\u003ccode\u003e@warning\u003c/code\u003e":"용도: 심각한 부작용, 데이터 손실, 성능 문제 등 사용자가 꼭 알아야 할 경고를 강조합니다. 주의를 강하게 요구할 때 사용합니다.\n예시:\n/** * @warning 이 함수는 원본 배열을 파괴적으로 수정합니다. * 정렬 전 백업이 필요하면 복사본을 사용하세요. */ void destructiveSort(std::vector\u003cint\u003e\u0026 arr);"},"title":"Doxyzen 키워드"},"/02.inbox/form-%ED%83%9C%EA%B7%B8%EC%9D%98-http-%ED%8C%A8%ED%82%B7massage-%EC%A0%84%EC%86%A1/":{"data":{"":"클라이언트측 post 메서드 전송 예시\n\u003cform action=\"http://www.example.com/test\" method=\"POST\"\u003e \u003clabel for=\"userId\"\u003eUser ID:\u003c/label\u003e\u003cbr\u003e \u003cinput type=\"text\" id=\"userId\" name=\"userId\"\u003e\u003cbr\u003e \u003clabel for=\"password\"\u003ePassword:\u003c/label\u003e\u003cbr\u003e \u003cinput type=\"password\" id=\"password\" name=\"password\"\u003e\u003cbr\u003e \u003cinput type=\"submit\" value=\"Submit\"\u003e \u003c/form\u003e 서버측으로 전송되는 패킷 예시\nPOST /test HTTP/1.1 Host: www.example.com User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8 Accept-Language: en-US,en;q=0.5 Accept-Encoding: gzip, deflate, br Content-Type: application/x-www-form-urlencoded Content-Length: 43 Origin: http://www.example.com Connection: keep-alive Referer: http://www.example.com/test Cookie: PHPSESSID=5a1lvj45uk83a3k9opjkpo3jm2 \\n\\r userId=user\u0026password=password 클라이언트측 get 메서드 html\n\u003cform action=\"http://www.example.com/test\" method=\"GET\"\u003e \u003clabel for=\"userId\"\u003eUser ID:\u003c/label\u003e\u003cbr\u003e \u003cinput type=\"text\" id=\"userId\" name=\"userId\"\u003e\u003cbr\u003e \u003clabel for=\"password\"\u003ePassword:\u003c/label\u003e\u003cbr\u003e \u003cinput type=\"password\" id=\"password\" name=\"password\"\u003e\u003cbr\u003e \u003cinput type=\"submit\" value=\"Submit\"\u003e \u003c/form\u003e 서버측으로 전송되는 패킷 예시\nGET /test?userId=user\u0026password=password HTTP/1.1 Host: www.example.com"},"title":"form 태그의 http 패킷(massage) 전송"},"/02.inbox/gcc-defalut-%EB%B2%84%EC%A0%84-%ED%99%95%EC%9D%B8/":{"data":{"":"gcc -dM -E -x c - \u003c /dev/null | grep __STDC_VERSION__ g++ -dM -E -x c++ - \u003c /dev/null | grep __cplusplus C++98: 199711 C++11: 201103 C++14: 201402 C++17: 201703 C++20: 202002"},"title":"gcc defalut 버전 확인"},"/02.inbox/gcc-include-path-%ED%99%95%EC%9D%B8%ED%95%98%EA%B8%B0/":{"data":{"":"echo | gcc -xc -E -v - echo | gcc -xc++ -E -v -"},"title":"gcc include path 확인하기"},"/02.inbox/git-merge/":{"data":{"":"gitGraph commit id: \"H\" commit id: \"I\" branch topic commit id: \"B\" commit id: \"C\" checkout main commit id: \"J\" commit id: \"K\" 여기서 branch 를 merge 할 때\nmerge commit gitGraph commit id: \"D\" commit id: \"E\" branch topic commit id: \"B\" commit id: \"C\" checkout main commit id: \"F\" commit id: \"G\" merge topic 이러한 방식이 기본적인 e commit 를 base 로 한 merge 방식이다\ngit 은 main 의 commit 가 있을 경우 위의 방식을 선택한다 하지만 만약\ngitGraph commit id: \"H\" commit id: \"I\" branch topic commit id: \"B\" commit id: \"C\" checkout main 이렇게 있을 때(merge 시에 잡히는 base 가 최신 커밋일때)는 fast foword merge 가 기본적인 방법이다\n즉 여기서 git switch main 에서 git merge topic 실행시\ngitGraph commit id: \"H\" commit id: \"I\" commit id: \"B\" commit id: \"C\" 이렇게 commit 된다\ngitGraph TB: commit id: \"ZERO\" branch develop commit id:\"A\" checkout main commit id:\"ONE\" checkout develop commit id:\"B\" branch featureA commit id:\"FIX\" commit id: \"FIX-2\" checkout main commit id:\"TWO\" cherry-pick id:\"A\" commit id:\"THREE\" cherry-pick id:\"FIX\" checkout develop commit id:\"C\" merge featureA gitGraph commit id: \"H\" commit id: \"I\" branch topic commit id: \"B\" commit id: \"C\" checkout main commit id: \"J\" commit id: \"K\" merge topic id: \"M1\" type: NO_FF tag: \"main에서 merge\" gitGraph commit id: “H” commit id: “I” branch topic commit id: “B” commit id: “C” checkout main commit id: “J” commit id: “K” merge topic id: “M1” type: NO_FF tag: “main에서 merge”\n%%{init: { ‘gitGraph’: {‘showBranches’: true, ‘showCommitLabel’:true}} }%% gitGraph commit id: “H” commit id: “I” branch topic commit id: “B” commit id: “C” checkout main commit id: “J” commit id: “K” checkout topic merge main id: “M2” type: NO_FF tag: “topic에서 merge”"},"title":"git merge"},"/02.inbox/gitstatus-%ED%94%84%EB%A1%AC%ED%94%84%ED%8A%B8/":{"data":{"":"segment meaning master HEAD가 위치한 브렌치 이름 #v1 HEAD가 위치한 태그 이름 (브랜치 일 때는 사용 x) @5fc6fca4 HEAD가 위치한 커밋 hash (브랜치 or hash 일때 사용 x) ⇣1 로컬 브랜치가 원격 브랜치보다 1개의 커밋만큼 뒤쳐져 있음 ⇡2 로컬 브랜치가 원격 브랜치보다 2개의 커밋만큼 앞서 있음 ⇠3 로컬 브랜치가 푸시 원격 브랜치보다 3개의 커밋만큼 뒤쳐져 있음 ?? ⇢4 로컬 브랜치가 푸시 원격 브랜치보다 4개의 커밋만큼 앞서 있음 ?? *5 5개의 스태시가 있음 merge 병합이 진행 중임 (다른 작업일 수도 있음) ~6 6개의 병합 충돌이 있음 +7 7개의 stage 에 변경사항 발생 !8 8개의 stage 에 없는 변경사항 ?9 9개의 추적되지 않은 파일"},"title":"gitstatus 프롬프트"},"/02.inbox/h2-database-%EC%82%AC%EC%9A%A9%EB%B2%95/":{"data":{"":"다운로드 링크\nh2 homepage link\ntcp 포트 웹 접근 포트 file 접근 TCP 접근 TCP:9092 TCP:8082 jdbc:h2:~/test jdbc:h2:tcp://\u003c서버IP\u003e:9092/~/test","embedded-모드#Embedded 모드":"H2 DB를 시스템의 메인 메모리에서 (JVM 위에서) 구동시키는 방식으로 application이 종료된다면 저장, 수정된 Data가 손실(휘발) 된다. 즉 기본적으로는 영속적이지 않은 방식이다.\n→ 데이터에 대한 영속성을 제공하는 방법은 존재한다.\n메인 메모리에 DB를 띄워놓고 해당 DB를 사용하는 Application의 스레드로 데이터에 바로 접근함으로써 데이터 읽기, 쓰기에 대한 성능을 향상할 수 있으므로 유용하게 사용할 수 있으며, 데이터 캐싱 DB에 대해서도 H2를 고려할 수 있다고 한다.\n하지만 JVM에서 데이터 연산에 사용되는 쓰레드를 인터럽트 하지 않을 수 있기에, IO 수행 시에 I/O Handler가 닫힘으로써 데이터베이스의 손상을 일으킬 수 있다.","h2의-local-server-개념#H2의 Local, Server 개념":"","main#main":"h2/bin/h2.sh == java -cp h2-2.3.232.jar org.h2.tools.Server -tcp -web -tcp: TCP 서버 실행 -tcpAllowOthers: TCP 서버에 외부 IP에서 접속 가능하게 함 -web: 웹 콘솔 실행 -webAllowOthers: 웹 콘솔에 외부 IP에서 접속 가능하게 함 webGUI 기본 link path localhost:8082 cli java -cp h2-2.3.232.jar org.h2.tools.Shell","server-모드#Server 모드":"해당 이미지는 하나의 시스템에서 서버 모드를 사용하는 경우이다.\n**별도의 프로세스(JVM)를 통해 DB를 동작시켜 데이터베이스를 영속적으로 사용하는 방법이다. * *\nlocal 환경에서는 localhost의 9092포트를 통해 DB 콘솔에 접근할 수 있으며, 별도의 서버 위에서 동작시킬 경우에 여러 Application을 해당 데이터베이스에 동시적으로 연결할 수 있다.\n서버 모드도 내부적으로는 Embedded 모드와 동일한 실행방식을 가지지만, 모든 데이터의 처리 흐름이 TCP/IP를 통하여 전송되기 때문에 Embedded 모드보다 상대적으로 느릴 수밖에 없다.","추가-도구#추가 도구":"도구명 설명 사용 예시 RunScript SQL 스크립트 파일을 실행하여 데이터베이스 초기화 또는 변경 적용 bash java -cp h2-*.jar org.h2.tools.RunScript -url jdbc:h2:~/test -user sa -script init.sql Recover 크래시나 오류 후 데이터베이스 복구 bash java -cp h2-*.jar org.h2.tools.Recover -dir ~/h2db/ ChangeFileEncryption 데이터베이스 파일 암호화 방식 변경 bash java -cp h2-*.jar org.h2.tools.ChangeFileEncryption -dir ~/h2db/ -oldPassword oldpass -newPassword newpass RunScript\n.sql 파일에 저장된 SQL 명령들을 실행합니다. 주로 초기 데이터 삽입, 테이블 생성 등에 사용됩니다. Recover\n데이터베이스가 비정상 종료되었을 경우 로그를 분석해 데이터를 복구합니다. 디렉토리 내의 .h2.db 파일을 기준으로 복구 진행. ChangeFileEncryption\n인코딩된 H2 DB 파일의 암호를 변경하거나, 암호화 설정을 업데이트할 때 사용. 보안 강화 및 관리에 유용."},"title":"h2 database 사용법"},"/02.inbox/http%EB%8A%94-stateless-%ED%95%9C%EB%8D%B0-%ED%95%98%EC%9C%84-%EC%8A%A4%ED%83%9D%EC%9D%98-tcp-%EB%8A%94-stateful-%EC%9D%B4%EB%8B%A4-http1.1-%EA%B8%B0%EC%A4%80/":{"data":{"":"","1-tcp-연결-유지#\u003cstrong\u003e1. TCP 연결 유지\u003c/strong\u003e":"Persistent HTTP에서는 하나의 TCP 연결을 통해 여러 개의 HTTP 요청과 응답을 주고받을 수 있습니다. TCP 연결은 stateful이므로, 서버는 이미 설정된 TCP 연결을 통해 클라이언트로부터 들어오는 데이터를 인식하고 처리할 수 있습니다. 즉, 서버는 “이미 3-way handshake를 완료한 연결\"이라는 사실을 TCP 계층에서 관리하며, 이를 통해 추가적인 요청(GET 등)을 처리할 준비가 됩니다.","2-http-요청의-독립성#\u003cstrong\u003e2. HTTP 요청의 독립성\u003c/strong\u003e":"HTTP는 stateless이므로, 각 HTTP 요청은 독립적입니다. 클라이언트는 동일한 TCP 연결을 통해 새로운 HTTP 요청을 보내더라도, 이전 요청과 관련된 정보를 포함하지 않습니다. 서버는 매번 들어오는 HTTP 요청을 처음부터 해석하고 처리하며, 이전 요청에 의존하지 않습니다.","http의-stateless-특성과-persistent-http의-관계#\u003cstrong\u003eHTTP의 Stateless 특성과 Persistent HTTP의 관계\u003c/strong\u003e":"HTTP Stateless:\n각 HTTP 요청은 독립적이며, 서버는 이전 요청에 대한 정보를 유지하지 않습니다. 예를 들어, 첫 번째 GET 요청과 두 번째 GET 요청 사이에는 아무런 연관성이 없습니다. TCP Persistent:\nTCP 연결은 상태를 유지하므로, 동일한 연결을 통해 여러 개의 HTTP 요청을 보낼 수 있습니다. 즉, HTTP 요청은 무상태이지만, 이를 전달하는 TCP 연결은 상태를 유지합니다.","persistent-http에서-get-요청이-가능한-이유#\u003cstrong\u003ePersistent HTTP에서 GET 요청이 가능한 이유\u003c/strong\u003e":"","답변-요약#답변 요약":"Stateless 상태를 유지하지 않는 시스템의 특성의 의미 (HTTP) Stateful 은 상태를 유지하며 동작하는 시스템의 특성을 나타냅니다. (TCP) Persistent 는 연결을 재사용하여 네트워크 효율성을 높이는 방식을 의미합니다. 따라서 HTTP는 stateless 지만, (일반적으로 사용하는)전송 계층에서 TCP의 stateful 특성을 활용(HTTP 헤더의 Connection: keep-alive 속성) 하여 persistent connection을 구현할 수 있다","서버가-어떻게-tcp-연결을-인지하는가#\u003cstrong\u003e서버가 어떻게 TCP 연결을 인지하는가?\u003c/strong\u003e":"TCP는 연결 상태를 관리하는 프로토콜이므로, 서버는 다음과 같은 정보를 통해 연결을 인지합니다:\n소켓(Socket):\nTCP 연결은 클라이언트와 서버 간의 소켓으로 표현됩니다. 소켓은 IP 주소와 포트 번호 쌍으로 식별됩니다. 서버는 각 클라이언트의 소켓 정보를 기반으로 연결 상태를 관리합니다. 연결 식별자(Connection Identifier):\n서버는 각 TCP 연결을 고유한 식별자(예: 소켓 파일 디스크립터)로 관리합니다. 이 식별자를 통해 특정 클라이언트와의 연결을 추적합니다. 데이터 스트림(Stream):\nTCP는 데이터를 순차적으로 전송하는 스트림 기반 프로토콜입니다. 서버는 동일한 연결을 통해 들어오는 데이터를 순차적으로 처리합니다.","예시-persistent-http-동작-과정#\u003cstrong\u003e예시: Persistent HTTP 동작 과정\u003c/strong\u003e":"TCP 연결 설정 (3-way handshake):\n클라이언트와 서버 간 TCP 연결이 설정됩니다. 이 연결은 일정 시간 동안 유지됩니다. 첫 번째 HTTP GET 요청:\n클라이언트는 TCP 연결을 통해 첫 번째 HTTP GET 요청을 보냅니다. 서버는 이 요청을 처리하고 응답을 반환합니다. 두 번째 HTTP GET 요청:\n클라이언트는 동일한 TCP 연결을 통해 두 번째 HTTP GET 요청을 보냅니다. 서버는 이 요청을 처리하고 응답을 반환합니다. TCP 연결 종료:\n더 이상 요청이 없거나 타임아웃이 발생하면 TCP 연결이 종료됩니다.","요약#\u003cstrong\u003e요약\u003c/strong\u003e":"HTTP는 Stateless:\n각 HTTP 요청은 독립적이며, 서버는 이전 요청에 대한 정보를 유지하지 않습니다. TCP는 Stateful:\nTCP 연결은 상태를 유지하므로, 동일한 연결을 통해 여러 개의 HTTP 요청을 보낼 수 있습니다. Persistent HTTP 동작 원리:\nTCP 연결이 설정된 후, 이 연결을 통해 여러 개의 HTTP 요청(GET 등)을 순차적으로 보낼 수 있습니다. 서버는 TCP 연결 상태를 통해 클라이언트를 인지하며, 각 HTTP 요청은 독립적으로 처리됩니다. 따라서, HTTP의 Stateless 특성과 TCP의 Stateful 특성이 결합되어 Persistent HTTP가 가능하게 됩니다.","질문#질문":"Persistent HTTP 에서 기본적으로 http 는 stateless 해 하지만 어떻게 Persistent하게 get 요청을 보낼 수 있는 거야 즉 서버 측에서 이미 3way handshake 했다는 것을 어떻게 인지하는 거야??","핵심-개념-stateless-vs-stateful#**핵심 개념: Stateless vs Stateful":"HTTP는 Stateless(무상태)이다:\nHTTP 프로토콜 자체는 이전 요청에 대한 정보를 유지하지 않습니다. 매 요청은 독립적으로 처리됩니다. 즉, 서버는 클라이언트가 이전에 어떤 요청을 보냈는지 기억하지 않습니다. TCP는 Stateful(상태 유지)이다:\nTCP는 연결 지향(connection-oriented) 프로토콜로, 연결 상태를 유지합니다. 3-way handshake를 통해 연결이 설정된 후, 해당 연결은 특정 시간 동안 유지되며, 이 연결을 통해 여러 데이터 패킷을 주고받을 수 있습니다."},"title":"http는 stateless 한데 하위 스택의 tcp 는 stateful 이다 (HTTP1.1 기준)"},"/02.inbox/https%EC%99%80-%EB%B9%84%EB%8C%80%EC%B9%AD-%ED%82%A4-%EC%B4%88%EA%B8%B0-%EC%84%A4%EC%A0%95%EB%B6%80%ED%84%B0-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%86%A1%EA%B9%8C%EC%A7%80%EC%9D%98-%EB%AA%A8%EB%93%A0-%EA%B3%BC%EC%A0%95-simulation/":{"data":{"":"클라이언트가 서버로부터 HTTPS 프로토콜을 통해 index.html을 요청하는 상황에서 TCP 핸드셰이크가 완료된 후 진행되는 TLS 과정은 크게 세 단계로 나눌 수 있습니다:\n핸드셰이크 (Handshake Phase) 키 도출 (Key Derivation Phase) 데이터 전송 (Data Transfer Phase)","tls-과정-상세-설명#TLS 과정 상세 설명":"1. TLS 핸드셰이크 (Handshake Phase) TLS 핸드셰이크 단계는 클라이언트와 서버가 안전한 통신을 위해 필요한 매개변수와 키를 설정하는 과정입니다. 이 단계에서는 다음의 중요한 과정들이 진행됩니다:\n클라이언트 “Hello” 메시지 전송:\n클라이언트(Bob)는 서버(Alice)에게 지원하는 암호화 알고리즘 목록을 보냅니다. 이 목록에는 대칭키 알고리즘 (예: AES), 공개키 알고리즘 (예: RSA), HMAC 알고리즘 (예: MD5 또는 SHA-1) 등이 포함될 수 있습니다. 또한, **클라이언트 논스(Client Nonce)**를 함께 전송합니다. 논스는 프로토콜에서 한 번만 사용되는 고유한 숫자이며, 재생 공격(playback attack)을 방지하고 상대방이 ‘살아있는(live)’ 상태임을 확인하는 데 사용됩니다. 서버 “Hello” 및 인증서 응답:\n서버(Alice)는 클라이언트가 보낸 목록에서 선호하는 암호화 알고리즘들을 선택하여 클라이언트에게 다시 보냅니다. 서버는 자신의 **디지털 인증서(Certificate)**와 **서버 논스(Server Nonce)**를 함께 전송합니다. **인증서(Certificate)**는 서버의 **공개키(Public Key)**와 서버의 신원 정보를 포함하고 있으며, 인증 기관(Certification Authority, CA)에 의해 디지털 서명되어 있습니다. 클라이언트의 서버 인증 및 Pre-Master Secret 전송:\n클라이언트(Bob)는 수신한 서버의 인증서를 인증 기관(CA)의 공개키를 사용하여 검증합니다. 이 과정을 통해 클라이언트는 인증서에 포함된 서버의 공개키가 실제로 해당 서버(Alice)의 것임을 신뢰하게 됩니다. 이는 Trudy와 같은 침입자가 Bob에게 Alice로 가장하여 가짜 공개키를 전달하는 것을 방지합니다. 클라이언트는 **Pre-Master Secret (PMS)**이라는 무작위 값을 생성합니다. 이 PMS를 **서버의 공개키(Server’s Public Key)**로 암호화한 후, **암호화된 PMS (Encrypted PMS)**를 서버로 전송합니다. 서버의 PMS 복호화 및 Master Secret 계산:\n서버(Alice)는 클라이언트로부터 수신한 암호화된 PMS를 자신의 개인키(Private Key)를 사용하여 복호화하여 원래의 PMS를 얻습니다. 이제 클라이언트와 서버 모두 PMS, 클라이언트 논스, 서버 논스를 공유하게 됩니다. 이 세 가지 정보를 바탕으로 양측은 **동일한 키 도출 함수(Key Derivation Function)**를 사용하여 **마스터 시크릿(Master Secret, MS)**을 독립적으로 계산합니다. 핸드셰이크 메시지 무결성 확인:\n클라이언트는 지금까지 주고받은 모든 핸드셰이크 메시지들의 HMAC(Hash-based Message Authentication Code)을 계산하여 서버에 전송합니다. 서버도 동일하게 지금까지 주고받은 모든 핸드셰이크 메시지들의 HMAC을 계산하여 클라이언트에 전송합니다. 이 HMAC 값들은 핸드셰이크 과정에서 메시지가 조작되지 않았음을 상호 검증하는 데 사용됩니다. 예를 들어, Trudy가 클라이언트가 제안한 강력한 알고리즘을 목록에서 삭제하려 했다면, 이 HMAC 검증 단계에서 감지되어 연결이 종료될 수 있습니다. 이 단계에서 사용된 논스들은 “연결 재생 공격(connection replay attack)“을 방어하는 데 핵심적인 역할을 합니다. 2. 키 도출 (Key Derivation Phase) 핸드셰이크 단계에서 공유된 마스터 시크릿(MS)을 사용하여, 클라이언트와 서버는 실제로 데이터 암호화 및 무결성 검증에 사용될 4개의 세션 키를 도출합니다. 이는 보안 강화를 위한 것으로, 보통 동일한 키를 모든 암호화와 무결성 검증에 사용하지 않습니다.\n마스터 시크릿(MS)으로부터 세션 키 생성: EB: 클라이언트(Bob)가 서버(Alice)에게 데이터를 보낼 때 사용할 세션 암호화 키. MB: 클라이언트(Bob)가 서버(Alice)에게 데이터를 보낼 때 사용할 세션 HMAC 키. EA: 서버(Alice)가 클라이언트(Bob)에게 데이터를 보낼 때 사용할 세션 암호화 키. MA: 서버(Alice)가 클라이언트(Bob)에게 데이터를 보낼 때 사용할 세션 HMAC 키. Initialization Vector (IV) 생성 (필요시): 만약 선택된 대칭 암호화 방식이 CBC(Cipher Block Chaining) 모드를 사용하는 경우 (예: 3DES 또는 AES), 각 통신 방향(클라이언트-\u003e서버, 서버-\u003e클라이언트)에 대한 **Initialization Vector (IV)**도 마스터 시크릿(MS)으로부터 도출됩니다. IV는 동일한 평문 블록이 항상 다른 암호문 블록을 생성하도록 무작위성을 부여하는 데 사용됩니다. 이 단계가 완료되면, 클라이언트와 서버는 이제 향후 모든 메시지를 암호화하고 인증하는 데 필요한 모든 세션 키를 공유하게 됩니다.\n3. 데이터 전송 (Data Transfer Phase) 모든 세션 키가 설정된 후, 클라이언트와 서버는 안전한 TCP 연결을 통해 실제 애플리케이션 데이터 (예: index.html 파일의 내용)를 주고받기 시작합니다.\n데이터 스트림을 레코드(Record)로 분할: TLS는 긴 데이터 스트림을 **레코드(record)**라는 작은 단위로 분할합니다. index.html 파일의 내용도 여러 TLS 레코드로 나뉘어 전송됩니다. HMAC 추가 및 암호화: 각 레코드에 대해 발신자(클라이언트 또는 서버)는 해당 레코드 데이터, 해당 방향의 HMAC 세션 키 (클라이언트의 경우 MB, 서버의 경우 MA), 그리고 TLS 시퀀스 번호를 입력으로 사용하여 HMAC을 계산합니다. 이 HMAC은 메시지 무결성을 보장합니다. 계산된 HMAC은 레코드 데이터 뒤에 추가됩니다. 이 “레코드 + HMAC” 패키지 전체는 해당 방향의 암호화 세션 키 (클라이언트의 경우 EB, 서버의 경우 EA)를 사용하여 암호화됩니다. TCP로 전송: 암호화된 레코드 패키지는 하위 TCP 계층으로 전달되어 인터넷을 통해 전송됩니다. 수신자의 처리: 수신자(예: index.html을 받는 클라이언트)는 암호화된 레코드를 받으면 먼저 해당 세션 암호화 키로 복호화합니다. 복호화된 레코드와 TLS 시퀀스 번호를 사용하여 HMAC을 다시 계산하고, 수신된 HMAC과 비교하여 데이터 무결성을 확인합니다. HMAC이 일치하면 데이터가 변경되지 않았음을 확인합니다. TLS 시퀀스 번호의 사용은 Trudy가 TCP 세그먼트를 재정렬하거나 재생하는 등의 공격(“woman-in-the-middle” attack)을 막아줍니다. 무결성이 확인된 복호화된 데이터는 애플리케이션 계층으로 전달됩니다. 연결 종료 (Connection Closure): TLS 세션은 더 이상 필요하지 않을 때 종료됩니다. TLS는 단순히 하위 TCP 연결을 종료하는 대신, 레코드의 type 필드를 사용하여 TLS 세션 종료를 명시적으로 알립니다. 이는 Trudy가 TCP FIN 세그먼트를 주입하여 세션을 조기에 종료(truncation attack)시키고 수신자가 모든 데이터를 받지 못했다고 오인하게 만드는 것을 방지합니다.","tls-과정-요약-표#TLS 과정 요약 표":"단계 클라이언트 (요청자) 서버 (응답자) 주요 목적 및 포함 정보 1. 핸드셰이크 1. 지원 암호화 알고리즘 목록 및 클라이언트 논스 전송. 2. 암호화 알고리즘 선택, 서버 인증서, 서버 논스 전송. 안전한 통신을 위한 매개변수 및 키 설정. 3. 서버 인증서 검증 (CA를 통해 서버 공개키 신뢰). 4. Pre-Master Secret (PMS) 복호화. CA 역할: 서버 공개키가 진짜임을 검증. 5. PMS 생성 및 서버 공개키로 암호화 후 전송. 6. PMS와 논스로부터 Master Secret (MS) 계산. 논스: 재생 공격 방지 및 ‘살아있음’ 증명. 7. 핸드셰이크 메시지 HMAC 전송. 8. 핸드셰이크 메시지 HMAC 전송. HMAC: 핸드셰이크 메시지 무결성 검증. 2. 키 도출 MS로부터 4개의 세션 키 (EB, MB, EA, MA) 도출. MS로부터 4개의 세션 키 (EB, MB, EA, MA) 도출. 실제 데이터 암호화 및 무결성 검증에 사용될 대칭 세션 키 생성. (CBC 사용 시) IV 도출. (CBC 사용 시) IV 도출. 효율적이고 안전한 데이터 전송을 위한 준비. 3. 데이터 전송 index.html 데이터 스트림을 레코드로 분할. 수신한 레코드 복호화 및 HMAC 검증. index.html과 같은 애플리케이션 데이터의 기밀성 및 무결성 보장. 레코드에 HMAC 추가 (시퀀스 번호 포함). 무결성 확인된 데이터를 애플리케이션 계층에 전달. HMAC: 메시지 무결성 보장. 레코드+HMAC을 세션 암호화 키로 암호화 후 TCP로 전송. TLS 연결 종료 시 명시적 종료 레코드 사용. 시퀀스 번호: 재생 및 재정렬 공격 방지.","tls-과정-요약-표-tls-13-중심#TLS 과정 요약 표 (TLS 1.3 중심)":"단계 클라이언트 (시작) 서버 (응답) 주요 목적 및 tls.txt 로그 해석 1. 핸드셰이크 1. Client hello (TLS 1.3) 전송: 지원 암호화 목록, 클라이언트 논스, ALPN 제안. 2. Server hello (TLS 1.3) 전송: 암호화 알고리즘 선택, 서버 논스, Encrypted Extensions 전송. 안전한 통신 매개변수 협상 및 키 교환 준비. 로그: * ALPN, offering h2, * TLSv1.3 (OUT), TLS handshake, Client hello (1): * TLSv1.3 (IN), TLS handshake, Server hello (2):, * TLSv1.3 (IN), TLS handshake, Encrypted Extensions (8): 3. 서버 인증서 및 CERT verify 수신. CA 공개키로 서버 인증서 검증 (서버 인증). 4. Certificate 및 CERT verify 전송. 서버 신원 확인 및 핸드셰이크 메시지 무결성 보장. 로그: * TLSv1.3 (IN), TLS handshake, Certificate (11):, * TLSv1.3 (IN), TLS handshake, CERT verify (15): * SSL certificate verify ok. 5. Pre-Master Secret (PMS) 생성, 서버 공개키로 암호화 후 전송. 6. PMS 복호화. 논스, PMS 이용 Master Secret (MS) 독립적 계산. 마스터 시크릿 교환: 세션 키 생성을 위한 공유 비밀 값 확립. 로그: 이 단계는 로그에 직접 표시되지 않지만, SSL connection using TLSv1.3 결과에 내포됨. output.pdf에서 이 부분이 상세 설명됨. 7. 모든 핸드셰이크 메시지의 HMAC 전송. 8. 모든 핸드셰이크 메시지의 HMAC 전송. 핸드셰이크 무결성 검증: 메시지 조작 방지. 로그: * TLSv1.3 (IN), TLS handshake, Finished (20):, * TLSv1.2 (OUT), TLS header, Finished (20): (클라이언트 측에서 TLSv1.2로 표시된 Finished 메시지도 이 역할을 수행) 2. 키 도출 MS와 논스로부터 4개의 세션 키 (EB, MB, EA, MA) 및 IV(필요시) 도출. MS와 논스로부터 4개의 세션 키 (EB, MB, EA, MA) 및 IV(필요시) 도출. 실제 데이터 암호화 및 무결성 검증에 사용될 대칭 세션 키 생성. 로그: * SSL connection using TLSv1.3 / TLS_AES_256_GCM_SHA384 이 줄이 키 도출이 성공했음을 최종적으로 확인. 3. 데이터 전송 HTTP/2 요청 (예: GET / HTTP/2)을 레코드로 분할. HMAC 추가, 세션 키로 암호화 후 전송. 수신한 레코드 복호화 및 HMAC 검증. 무결성 확인된 데이터를 애플리케이션에 전달. index.html과 같은 애플리케이션 데이터의 기밀성 및 무결성 보장. 로그: * TLSv1.2 (OUT), TLS header, Supplemental data (23): (클라이언트 요청) * TLSv1.2 (IN), TLS header, Supplemental data (23): (서버 응답) \u003c HTTP/2 200 (애플리케이션 데이터 수신 확인) (선택) 세션 재개를 위한 Newsession Ticket 수신 [외부 정보]. (선택) Newsession Ticket 전송 [외부 정보]. 다음 연결의 효율성 증대. 로그: * TLSv1.3 (IN), TLS handshake, Newsession Ticket (4): 추가적인 통찰:\n보안 목표 달성: 이 TLS 과정을 통해 output.pdf에서 강조하는 다음의 보안 목표들이 달성됩니다: 기밀성 (Confidentiality): index.html 내용과 같은 애플리케이션 데이터는 세션 암호화 키 (EB, EA)로 암호화되어 전송되므로, Trudy(침입자)가 데이터를 스니핑하더라도 내용을 이해할 수 없습니다. 메시지 무결성 (Message integrity): 각 TLS 레코드에 HMAC이 포함되며, TLS 시퀀스 번호까지 HMAC 계산에 포함되므로, Trudy가 메시지 내용을 변경하거나, 순서를 재정렬하거나, 재생하더라도 수신 측에서 이를 감지할 수 있습니다. 종단점 인증 (End-point authentication): 클라이언트는 서버의 디지털 인증서를 CA의 공개키로 검증하여 서버의 신원을 확인하고, 서버는 클라이언트의 Pre-Master Secret을 복호화하여 클라이언트가 공유 비밀을 알고 있음을 (선택적으로) 확인합니다 (이 예시에서는 서버 인증만 명확함). TLS 1.3의 효율성: output.pdf는 Pre-Master Secret을 서버 공개키로 암호화하여 보내고, 이를 통해 Master Secret을 도출하는 과정을 설명합니다. TLS 1.3은 이 키 교환 과정을 더욱 최적화하여 대부분의 핸드셰이크가 단 한 번의 왕복으로 완료될 수 있도록 합니다 [외부 정보: 1-RTT 핸드셰이크]. 로그의 TLSv1.2 표기: 로그에 간간이 나타나는 TLSv1.2 표기는 실제 협상된 프로토콜 버전이 TLSv1.3임에도 불구하고 curl 내부 로직이나 TLS 레코드 계층의 특정 상태 또는 하위 호환성 메커니즘을 나타내는 것일 수 있습니다. 핵심은 최종적으로 TLSv1.3이 사용되었다는 점입니다.","tls-의-오해-바로잡기#TLS 의 오해 바로잡기":"Question\n헨드세이크 과정중에 키 도출을 하는 거야 아니면 handshake 이후에 키 도출을 하는 거야?\nTLS 핸드셰이크 과정에서 키 도출은 핸드셰이크 단계 내에서 이루어집니다.\n소스에 따르면, TLS 프로토콜은 핸드셰이크, 키 도출, 데이터 전송의 세 단계를 가집니다. 하지만 실제로 TLS 핸드셰이크 프로토콜을 더 자세히 살펴보면, 키 도출이 핸드셰이크 단계의 핵심 부분으로 통합되어 있음을 알 수 있습니다.\n실제 TLS 핸드셰이크 과정에서 키 도출은 다음과 같이 진행됩니다:\n클라이언트와 서버는 핸드셰이크 과정 중에 논스(nonces)를 서로 교환합니다. 논스는 재생 공격(replay attack)을 방지하고 통신 상대방의 “생존성(liveness)“을 확인하는 데 사용되는 고유한 숫자입니다. 클라이언트는 서버의 공개 키를 사용하여 사전 마스터 시크릿(Pre-Master Secret, PMS)을 생성하고 암호화하여 서버로 전송합니다. 클라이언트와 서버는 TLS 표준에 지정된 동일한 키 도출 함수를 사용하여 PMS와 논스로부터 마스터 시크릿(Master Secret, MS)을 독립적으로 계산합니다. 이 MS는 이후 세션 암호화 키(encryption keys)와 HMAC 키(HMAC keys)를 생성하는 데 사용됩니다. 만약 선택된 대칭 암호가 CBC(Cipher Block Chaining)를 사용한다면, 초기화 벡터(Initialization Vectors, IVs)도 MS에서 얻어집니다. 이 모든 과정, 즉 MS 계산 및 세션 키 생성은 TLS 핸드셰이크의 4단계에서 발생합니다. 이 단계가 완료되면 클라이언트와 서버 간의 모든 메시지는 생성된 키를 사용하여 암호화되고 인증(HMAC)됩니다. tls.txt 소스에서도 핸드셰이크 메시지 교환(Client hello, Server hello, Finished 등) 이후에 SSL 연결이 TLSv1.3 / TLS_AES_256_GCM_SHA384와 같은 특정 암호화 방식을 사용하여 설정되었음을 보여주며, 이는 핸드셰이크 과정에서 키가 성공적으로 도출되었음을 시사합니다.","tlstxt-로그-해석-tls-과정의-단계별-이해#\u003ccode\u003etls.txt\u003c/code\u003e 로그 해석: TLS 과정의 단계별 이해":"tls.txt 로그는 클라이언트(여기서는 curl 명령어를 실행한 당신의 시스템)와 서버(dns.google) 간의 TLS 통신을 보여줍니다. 이 로그는 output.pdf에 설명된 TLS 프로토콜의 원리와 실제 구현이 어떻게 연결되는지 이해하는 데 도움이 됩니다.\n시작 부분: TCP 연결 및 ALPN 협상\n* Trying 8.8.4.4:443...\n* Connected to dns.google (8.8.4.4) port 443 (#0)\n이 부분은 클라이언트가 서버의 IP 주소 8.8.4.4의 443 포트로 TCP 연결을 시도하고 성공했음을 보여줍니다. 이는 TCP 핸드셰이크가 완료되었다는 가정을 충족합니다. * ALPN, offering h2\n* ALPN, offering http/1.1\n**ALPN (Application-Layer Protocol Negotiation)**은 TLS 핸드셰이크 과정 중 클라이언트가 서버에게 자신이 지원하는 애플리케이션 계층 프로토콜 목록을 제안하는 것입니다 [외부 정보: ALPN은 TLS 확장 기능으로, HTTPS에서 HTTP/1.1과 HTTP/2 중 무엇을 사용할지 협상하는 데 사용됩니다]. 여기서 클라이언트는 HTTP/2 (h2)와 HTTP/1.1을 제안하고 있습니다. * CAfile: /etc/ssl/certs/ca-certificates.crt\n* CApath: /etc/ssl/certs\n이것은 클라이언트의 시스템이 **인증서 (Certificate)**를 검증하기 위해 사용할 인증 기관 (CA) 인증서의 경로를 나타냅니다. 클라이언트는 이 경로의 CA 인증서를 사용하여 서버가 전송한 인증서를 신뢰할 수 있는지 확인합니다. 1. TLS 핸드셰이크 (Handshake Phase)\nTLS 핸드셰이크는 클라이언트와 서버가 안전한 통신을 위한 모든 매개변수를 협상하고, 서로의 신원을 확인하며, 세션 키를 생성하는 데 필요한 **마스터 시크릿(Master Secret)**을 안전하게 교환하는 과정입니다.\n* TLSv1.0 (OUT), TLS header, Certificate Status (22):\n* TLSv1.3 (OUT), TLS handshake, Client hello (1):\n클라이언트 “Hello” 메시지 전송: 클라이언트는 TLS 1.3 버전으로 “Client Hello” 메시지를 전송하며 핸드셰이크를 시작합니다. 이 메시지에는 클라이언트가 지원하는 암호화 알고리즘 목록 (대칭키, 공개키, HMAC 알고리즘 등)과 함께 **클라이언트 논스 (Client Nonce)**가 포함됩니다. 논스는 재생 공격(playback attack)을 방지하고 상대방이 현재 “살아있는” 상태임을 확인하는 데 사용되는 “한 번만 사용되는 값\"입니다. 앞서 보이는 TLSv1.0이나 TLSv1.2 레코드는 curl의 내부 로깅이나 초기 협상 시도일 수 있으며, 실제로는 더 높은 버전이 사용됩니다. * TLSv1.2 (IN), TLS header, Certificate Status (22):\n* TLSv1.3 (IN), TLS handshake, Server hello (2):\n서버 “Hello” 및 인증서 응답: 서버는 클라이언트의 목록에서 암호화 알고리즘들을 선택하고, “Server Hello” 메시지를 보냅니다. 이 메시지에는 서버가 선택한 알고리즘과 함께 **서버 논스 (Server Nonce)**가 포함됩니다. * TLSv1.3 (IN), TLS handshake, Encrypted Extensions (8):\n암호화된 확장 (Encrypted Extensions): TLS 1.3의 특징 중 하나로, 이전 버전에서는 평문으로 전송되던 일부 핸드셰이크 확장(예: ALPN 협상 결과 등)이 이제 암호화되어 전송됩니다 [외부 정보: TLS 1.3의 주요 변경 사항 중 하나는 핸드셰이크 메시지의 더 많은 부분을 암호화하여 정보 노출을 줄이는 것입니다]. * TLSv1.3 (IN), TLS handshake, Certificate (11):\n서버 인증서 전송: 서버는 자신의 **디지털 인증서 (Certificate)**를 클라이언트에게 전송합니다. 이 인증서는 서버의 **공개키 (Public Key)**와 서버의 신원 정보를 포함하고 있으며, 신뢰할 수 있는 **인증 기관 (CA)**에 의해 디지털 서명되어 있습니다. * TLSv1.3 (IN), TLS handshake, CERT verify (15):\n인증서 검증 (Certificate Verify): 서버는 **자신의 개인키 (Private Key)**로 핸드셰이크 메시지들의 해시 값에 서명하여 클라이언트에게 보냅니다. 클라이언트는 서버의 공개키로 이 서명을 검증하여, 서버가 해당 공개키에 상응하는 개인키를 소유하고 있음을 확인하고, 핸드셰이크 메시지가 위변조되지 않았음을 검증합니다. * TLSv1.3 (IN), TLS handshake, Finished (20):\n* TLSv1.2 (OUT), TLS header, Finished (20):\n* TLSv1.3 (OUT), TLS change cipher, Change cipher spec (1):\n* TLSv1.3 (OUT), TLS handshake, Finished (20):\n핸드셰이크 완료 (Finished): 클라이언트와 서버는 지금까지 주고받은 모든 핸드셰이크 메시지들의 HMAC (Hash-based Message Authentication Code)을 계산하여 상호 전송합니다. 이 HMAC 값은 핸드셰이크 과정에서 메시지가 조작되지 않았음을 상호 검증하는 데 사용됩니다. Change Cipher Spec 메시지는 주로 하위 호환성을 위해 전송되며, 이제 암호화된 통신이 시작됨을 알리는 역할을 합니다 [외부 정보: TLS 1.3에서는 이 메시지가 TLS 1.2만큼 중요하지 않고 주로 하위 호환성을 위해 사용됩니다]. * SSL connection using TLSv1.3 / TLS_AES_256_GCM_SHA384\n이 줄은 TLS 핸드셰이크가 성공적으로 완료되었음을 명확히 보여줍니다. 협상된 프로토콜 버전은 TLSv1.3이며, 사용될 암호화 스위트는 TLS_AES_256_GCM_SHA384입니다. 이는 데이터 암호화에 **AES-256 (GCM 모드)**을 사용하고, 메시지 무결성 검증에 SHA384 기반의 HMAC를 사용하기로 결정되었음을 의미합니다. * ALPN, server accepted to use h2\n서버가 클라이언트가 제안한 HTTP/2 (h2) 프로토콜 사용을 수락했음을 확인합니다. 서버 인증서 상세 정보 및 검증 결과:\n* Server certificate: ... * subject: CN=dns.google * start date: ... * expire date: ... * issuer: C=US; O=Google Trust Services; CN=WE2 * SSL certificate verify ok. 이 부분은 클라이언트가 서버로부터 받은 인증서의 세부 정보를 보여줍니다. **인증서의 주체 (Subject)**가 dns.google이며, **발급자 (Issuer)**는 Google Trust Services라는 CA임을 명확히 보여줍니다. 또한, SSL certificate verify ok.는 클라이언트가 CA 공개키를 사용하여 서버 인증서의 유효성을 성공적으로 검증했으며, **서버의 신뢰성 (End-point authentication)**이 확인되었음을 의미합니다. 2. 키 도출 (Key Derivation Phase)\nTLS 1.3 핸드셰이크 과정에서 **Pre-Master Secret (PMS)**와 **논스(Nonces)**를 사용하여 **마스터 시크릿 (Master Secret, MS)**이 계산됩니다. 이 MS는 실제 데이터 암호화 및 무결성 검증에 사용될 세션 키들을 도출하는 데 사용됩니다. tls.txt 로그에는 이 과정이 명시적으로 나타나지 않지만, “SSL connection using TLSv1.3 / TLS_AES_256_GCM_SHA384\"라는 결과는 키 도출이 완료되었음을 암시합니다.\n세션 키 생성: 클라이언트와 서버는 MS와 논스를 바탕으로 **동일한 키 도출 함수 (Key Derivation Function)**를 사용하여 다음의 4가지 세션 키를 독립적으로 계산합니다: EB: 클라이언트가 서버로 데이터를 보낼 때 사용할 세션 암호화 키. MB: 클라이언트가 서버로 데이터를 보낼 때 사용할 세션 HMAC 키 (메시지 무결성 검증용). EA: 서버가 클라이언트로 데이터를 보낼 때 사용할 세션 암호화 키. MA: 서버가 클라이언트로 데이터를 보낼 때 사용할 세션 HMAC 키. Initialization Vector (IV) 생성: AES와 같은 블록 암호 방식이 CBC (Cipher Block Chaining) 모드를 사용하는 경우, 각 통신 방향에 대한 **Initialization Vector (IV)**도 MS로부터 도출됩니다. IV는 동일한 평문 블록이 항상 다른 암호문 블록을 생성하도록 무작위성을 부여하여 암호문의 패턴 노출을 방지합니다. (참고: AES-GCM은 IV/Nonce를 사용하지만, CBC와는 다른 방식으로 사용합니다. output.pdf는 주로 CBC를 예로 설명합니다.) 이 단계가 완료되면, 클라이언트와 서버는 이후 모든 메시지를 암호화하고 인증하는 데 필요한 모든 대칭 세션 키를 공유하게 됩니다.\n3. 데이터 전송 (Data Transfer Phase)\n모든 세션 키가 설정된 후, 클라이언트와 서버는 안전한 TLS 연결을 통해 실제 애플리케이션 데이터 (여기서는 HTTP/2 요청 및 응답)를 주고받기 시작합니다.\n* Using HTTP2, server supports multiplexing\n* Connection state changed (HTTP/2 confirmed)\n클라이언트와 서버가 이제 HTTP/2 프로토콜을 통해 통신할 것임을 확인합니다. * TLSv1.2 (OUT), TLS header, Supplemental data (23): (여러 번 반복)\n\u003e GET / HTTP/2\n\u003e Host: dns.google\n\u003e user-agent: curl/7.81.0\n\u003e accept: */*\n이 부분은 클라이언트가 서버로 실제 HTTP/2 요청을 전송하는 것을 보여줍니다. Supplemental data (23)는 TLS 레코드 형식에서 애플리케이션 데이터를 나타냅니다. TLS는 긴 데이터 스트림 (예: HTTP 요청)을 **레코드 (record)**라는 작은 단위로 분할합니다. 각 레코드에 대해 발신자 (여기서는 클라이언트)는 해당 레코드 데이터, 클라이언트의 HMAC 세션 키 (MB), 그리고 TLS 시퀀스 번호를 사용하여 HMAC을 계산하고 이를 레코드 뒤에 추가합니다. 그런 다음, 이 “레코드 + HMAC” 패키지 전체는 클라이언트의 **암호화 세션 키 (EB)**를 사용하여 암호화됩니다. 이 암호화된 패키지는 TCP 계층으로 전달되어 인터넷을 통해 전송됩니다. TLS 시퀀스 번호의 사용은 메시지 재정렬 또는 재생 공격 (woman-in-the-middle attack)을 막는 데 핵심적인 역할을 합니다. * TLSv1.2 (IN), TLS header, Supplemental data (23): (여러 번 반복)\n* TLSv1.3 (IN), TLS handshake, Newsession Ticket (4): (두 번)\n* old SSL session ID is stale, removing\n서버는 암호화된 애플리케이션 데이터 (Supplemental data (23))와 함께 **세션 재개 (Session Resumption)**를 위한 New Session Ticket을 전송하고 있습니다 [외부 정보: TLS 1.3의 주요 기능 중 하나로, 다음 연결을 더 빠르게 설정할 수 있도록 암호화된 세션 키 정보를 클라이언트에게 제공합니다]. \u003c HTTP/2 200\n\u003c content-security-policy: ... (이하 서버 응답 헤더)\n이 부분은 서버로부터 수신된 HTTP/2 응답 헤더를 보여줍니다. HTTP/2 200은 요청이 성공적으로 처리되었음을 나타냅니다. 클라이언트는 이 암호화된 레코드를 받으면 먼저 서버의 세션 암호화 키 (EA)로 복호화하고, 수신된 HMAC과 자체 계산한 HMAC을 비교하여 데이터 무결성을 확인합니다. 무결성이 확인된 복호화된 데이터는 애플리케이션 계층으로 전달됩니다. 이 과정에서 index.html 파일의 내용 (또는 여기서는 dns.google의 루트 페이지 내용)이 안전하게 클라이언트에게 전달됩니다.","실제-요청시-tls-과정#실제 요청시 TLS 과정":"shinnk@DESKTOP-KRSG68U:~/source_main/university/network_박현민_4$ curl -v \"https://dns.google\" * Trying 8.8.4.4:443... * Connected to dns.google (8.8.4.4) port 443 (#0) * ALPN, offering h2 * ALPN, offering http/1.1 * CAfile: /etc/ssl/certs/ca-certificates.crt * CApath: /etc/ssl/certs * TLSv1.0 (OUT), TLS header, Certificate Status (22): * TLSv1.3 (OUT), TLS handshake, Client hello (1): * TLSv1.2 (IN), TLS header, Certificate Status (22): * TLSv1.3 (IN), TLS handshake, Server hello (2): * TLSv1.2 (IN), TLS header, Finished (20): * TLSv1.2 (IN), TLS header, Supplemental data (23): * TLSv1.3 (IN), TLS handshake, Encrypted Extensions (8): * TLSv1.3 (IN), TLS handshake, Certificate (11): * TLSv1.3 (IN), TLS handshake, CERT verify (15): * TLSv1.3 (IN), TLS handshake, Finished (20): * TLSv1.2 (OUT), TLS header, Finished (20): * TLSv1.3 (OUT), TLS change cipher, Change cipher spec (1): * TLSv1.2 (OUT), TLS header, Supplemental data (23): * TLSv1.3 (OUT), TLS handshake, Finished (20): * SSL connection using TLSv1.3 / TLS_AES_256_GCM_SHA384 * ALPN, server accepted to use h2 * Server certificate: * subject: CN=dns.google * start date: Jun 2 08:37:32 2025 GMT * expire date: Aug 25 08:37:31 2025 GMT * subjectAltName: host \"dns.google\" matched cert's \"dns.google\" * issuer: C=US; O=Google Trust Services; CN=WE2 * SSL certificate verify ok. * Using HTTP2, server supports multiplexing * Connection state changed (HTTP/2 confirmed) * Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0 * TLSv1.2 (OUT), TLS header, Supplemental data (23): * TLSv1.2 (OUT), TLS header, Supplemental data (23): * TLSv1.2 (OUT), TLS header, Supplemental data (23): * Using Stream ID: 1 (easy handle 0x55896f9109f0) * TLSv1.2 (OUT), TLS header, Supplemental data (23): \u003e GET / HTTP/2 \u003e Host: dns.google \u003e user-agent: curl/7.81.0 \u003e accept: */* \u003e * TLSv1.2 (IN), TLS header, Supplemental data (23): * TLSv1.3 (IN), TLS handshake, Newsession Ticket (4): * TLSv1.3 (IN), TLS handshake, Newsession Ticket (4): * old SSL session ID is stale, removing * TLSv1.2 (IN), TLS header, Supplemental data (23): * TLSv1.2 (OUT), TLS header, Supplemental data (23): * TLSv1.2 (IN), TLS header, Supplemental data (23): * TLSv1.2 (IN), TLS header, Supplemental data (23): \u003c HTTP/2 200 \u003c content-security-policy: object-src 'none';base-uri 'self';script-src 'nonce-V0n3tKAxmea423-IDB1pAg' 'strict-dynamic' 'report-sample' 'unsafe-eval' 'unsafe-inline' https: http:;report-uri https://csp.withgoogle.com/csp/honest_dns/1_0;frame-ancestors 'none' \u003c strict-transport-security: max-age=31536000; includeSubDomains; preload \u003c x-content-type-options: nosniff \u003c content-security-policy-report-only: script-src 'none'; form-action 'none'; frame-src 'none'; report-uri https://csp.withgoogle.com/csp/scaffolding/ntdsgswbsc:55:0 \u003c cross-origin-opener-policy-report-only: same-origin; report-to=ntdsgswbsc:55:0 \u003c report-to: {\"group\":\"ntdsgswbsc:55:0\",\"max_age\":2592000,\"endpoints\":[{\"url\":\"https://csp.withgoogle.com/csp/report-to/scaffolding/ntdsgswbsc:55:0\"}],} \u003c server: scaffolding on HTTPServer2 \u003c x-xss-protection: 0 \u003c x-frame-options: SAMEORIGIN \u003c date: Wed, 25 Jun 2025 16:24:52 GMT \u003c expires: Wed, 25 Jun 2025 16:29:52 GMT \u003c cache-control: public, max-age=300 \u003c content-type: text/html; charset=UTF-8 \u003c age: 90 \u003c alt-svc: h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000 \u003c accept-ranges: none \u003c vary: Accept-Encoding \u003c * TLSv1.2 (IN), TLS header, Supplemental data (23): 주어진 tls.txt 결과는 클라이언트(curl)가 dns.google 서버와 HTTPS (TLS) 연결을 수립하는 과정을 상세하게 보여줍니다. 이미 TCP 핸드셰이크가 완료되었다는 가정하에, 이 로그를 TLS 핸드셰이크, 키 도출, 그리고 데이터 전송의 세 가지 주요 TLS 단계에 맞춰 분석하고 해석해 드리겠습니다. 서버 측에서 TLS 1.3을 사용하고 있는 것이 확인됩니다."},"title":"HTTPS와 비대칭 키 초기 설정부터 데이터 전송까지의 모든 과정 simulation"},"/02.inbox/ios-%ED%84%B0%EB%AF%B8%EB%84%90-%EC%A0%91%EA%B7%BC/":{"data":{"":"","a-shell#a-shell":"파일의 구조가 일반적인 unix 구조와 다르다 (샌드박스 정책 때문에)\n패지키 관리\npkg {install | remove | list search } pakage-name 제공하는 패키지 종류 서버\nm\npickFolder : 먼저 apple 이 제공하는 api 를 통해 외부에 접근할 곳을 지정한다 지정한 곳은 bookmark 라는 a-shell 이 관리하는 공간에 저장된다\npickFolder 파일 선택 창이 나오고 연결한 포인트를 설정하면 bookmard 에 폴더이름으로 북마크 이름이 된다\nshowmarks # 모든 북마크 보기 jump {북마크 이름}` 또는 `cd ~{북마크 이름} # 북마크 이동 deletemarks {북마크 이름} renamemarks {예전 이름} {바꿀 이름} bookmark {정할 이름} # 현재 디렉토리에 대한 북마크를 추가 다른앱 연결\nopen {file-name} # 파일 공유 view {file-name} # 파일 뷰어 play {file-name} # 미디어 파일 재생 internalbrowser {https://google.com} # 내부 브라우저 사용","ish#ISH":"mount -t ios . {마운트할 path} 를 통해 파일앱의 폴더를 마운트 할 수 있다","외부-접근#외부 접근":"ios 는 모바일 운영체제로서 샌드박스 형태의 아키텍쳐를 취하고 있다 즉 앱 하나하나다 일종의 User 로서 로그인하게 되고 유저의 home 영역을 제외한 곳은 읽기 조차 금지 되어있다 하지만 android 는 초창기 부터 다른 A 앱에서 B 앱의 접근을 api 로서 허용하고 있으며 이를 활용해 삼성의 ‘내파일’ ‘사진’ ‘한글뷰어’ 과 같은 앱들은 android 가 제공하는 공용 공간에 접근 api 를 사용하여 동일한 공간에 사용자의 파일을 몰아넣고 데스크탑과 비슷한 환경을 구축해놓았다 하지만 ios 의 경우에는 이런것이 매우 부족하다 하지만 ios 13 부터였나(?) 이러한 api 가 개발자들에게 지원되기 시작했고 이를 이를 통해 할 수 있는 포텐셜이 늘어나게 되었다","터미널의-구현#터미널의 구현":"ios 에서 터미널을 구현한 인기있는 앱 2가지 종류가 보이는 것 같았다\nISH : 시스템 콜 수준의 변환을 통한 터미널 구현 : ios 와 리눅스의 시스템 콜의 호환성만 일치시키면 어떠한 아키텍쳐든 구현이 가능하고 이것을 실현시킨 앱이다 장점 : 사용자 수준에서 느껴지는 운영체제의 수준이 완벽하게 실행되며 데스크탑 운영체제에서 할 수 있는 모든 행동이 구현 가능하다 단점 : 느리다 a-shell : 실제로는 safari 의 브라우저 엔진인 webkit 을 사용하고 있으며 git, gawk 등등의 앱들은 웹어셈블리로 컴파일되어진 앱들이며 a-shell 에서 돌아간다 또한 웹 어셈블리로 다른 앱들을 컴파일하여 돌릴 수 있다 장점 : 위에보다는 훨씬 빠르다 (웹어셈블리는 네이티브 속도의 60% ~ 95% 속도를 보여준다고 알려저 있다) 단점 어셈블리어로 컴파일 되어 있는 앱들만 사용가능하다"},"title":"ios 터미널 접근"},"/02.inbox/ipc-massage-passing/":{"data":{"":"아래는 Unix에서 사용되는 다양한 프로세스 간 통신(Inter-Process Communication, IPC) 방식들에 대한 자세한 설명입니다.\n주요 내용은 다음과 같은 IPC 기법들을 포함합니다:\nOrdinary Pipe (일반 파이프) Named Pipe (FIFO) UNIX Domain Socket","-1-ordinary-pipe-일반-파이프#🔹 1. Ordinary Pipe (일반 파이프)":"","-2-named-pipe-fifo-first-in-first-out#🔹 2. Named Pipe (FIFO: First In First Out)":"","-3-unix-domain-socket-로컬-소켓#🔹 3. UNIX Domain Socket (로컬 소켓)":"","-fifo-생성자#🧱 FIFO 생성자":"#include #include #include #include int main() { mkfifo(\"myfifo\", 0666); // 권한 0666으로 myfifo 생성 return 0; }","-개념#✅ 개념":"pipe() 시스템 콜을 통해 생성됨 두 개의 파일 디스크립터(file descriptor) 반환: 하나는 쓰기 전용(write-end) 하나는 읽기 전용(read-end) 데이터는 쓰기 쪽으로 넣고, 읽기 쪽에서 뺌 → Producer-Consumer 패턴 단방향(unidirectional) 통신만 지원","-개념-1#✅ 개념":"이름을 가진 파일 형태의 파이프 mkfifo() 함수로 생성되며, 실제 파일처럼 /tmp/myfifo 같은 경로에 존재함 여러 프로세스 간 통신 가능 (부모-자식 관계 필요 없음)","-개념-2#✅ 개념":"로컬 머신 내에서만 사용되는 소켓 파일 시스템 경로(/tmp/mysocket)를 주소로 사용함 TCP/IP 소켓과 비슷하지만, 커널 내부에서 처리되어 더 빠름","-성능-비교-내부-구현-기준#🚀 성능 비교 (내부 구현 기준)":"Ordinary Pipe \u003e Unix Domain Socket \u003e Named Pipe (FIFO) \u003e Network Socket Ordinary Pipe : 가장 빠르고 간단 (커널 내부 버퍼 사용) Unix Domain Socket : 양방향, full-duplex, 네트워크 소켓처럼 사용 가능 Named Pipe (FIFO) : 파일 시스템 기반이므로 약간 느림 Network Socket : TCP/IP 오버헤드가 있어 가장 느림","-쓰기writer#📝 쓰기(writer)":"#include #include #include int main() { int fd = open(\"myfifo\", O_WRONLY); // Blocking 모드 write(fd, \"Hello from writer\", 17); close(fd); return 0; }","-예제-코드#✅ 예제 코드":"#include #include #include int main() { int pipefd[2]; pid_t pid; char buf; if (pipe(pipefd) == -1) { perror(\"Pipe failed\"); exit(EXIT_FAILURE); } pid = fork(); if (pid \u003c 0) { // Fork 실패 perror(\"Fork failed\"); exit(EXIT_FAILURE); } if (pid == 0) { // 자식 프로세스 (reader) close(pipefd[1]); // 쓰기 fd 닫기 while (read(pipefd[0], \u0026buf, 1) \u003e 0) write(STDOUT_FILENO, \u0026buf, 1); close(pipefd[0]); } else { // 부모 프로세스 (writer) close(pipefd[0]); // 읽기 fd 닫기 write(pipefd[1], \"Hello from parent\", 17); close(pipefd[1]); wait(NULL); // 자식 기다리기 } return 0; } 이 코드는 부모가 메시지를 보내고 자식이 그것을 출력하는 간단한 파이프 예제입니다.","-예제-코드-1#✅ 예제 코드":"","-예제-코드-2#✅ 예제 코드":"#include #include #include #include #include int main() { int sv[2]; // 소켓 페어 char buffer[100]; if (socketpair(AF_UNIX, SOCK_STREAM, 0, sv) == -1) { perror(\"Socketpair failed\"); return 1; } pid_t pid = fork(); if (pid \u003c 0) { perror(\"Fork failed\"); return 1; } if (pid == 0) { // 자식 프로세스 (수신) close(sv[0]); // 부모 쪽 fd 닫기 read(sv[1], buffer, sizeof(buffer) - 1); printf(\"Child received: %s\\n\", buffer); close(sv[1]); } else { // 부모 프로세스 (송신) close(sv[1]); // 자식 쪽 fd 닫기 write(sv[0], \"Hello my child\", 15); close(sv[0]); wait(NULL); // 자식 종료 대기 } return 0; }","-요약#💬 요약":"Ordinary Pipe: 부모-자식 간 단방향 통신, 가장 간단하고 빠름 Named Pipe (FIFO): 파일처럼 생성하여 여러 프로세스 간 통신 가능 UNIX Domain Socket: 로컬 머신 내에서 네트워크 소켓처럼 사용되는 고성능 통신 수단","-읽기reader#📖 읽기(reader)":"#include #include #include int main() { char buffer[80]; int fd = open(\"myfifo\", O_RDONLY); read(fd, buffer, sizeof(buffer)); printf(\"Received: %s\\n\", buffer); close(fd); return 0; } 위 코드를 실행하려면 세 개의 터미널 창에서 각각 순서대로 실행해야 합니다:\n$ ./creator $ ./reader # reader 먼저 실행하고 대기 $ ./writer # writer가 메시지 전송","-전체-비교표#📊 전체 비교표":"항목 Ordinary Pipe Named Pipe (FIFO) Unix Domain Socket 통신 범위 부모-자식 프로세스 모든 프로세스 모든 프로세스 존속성 일시적 영구적 (파일 시스템에 남음) 영구적 (경로로 지정된 파일) 방향성 단방향 단방향/양방향 가능 양방향(full-duplex) 방식 Direct Indirect Indirect 동기화 기본 blocking 기본 blocking 기본 blocking 비동기 지원 가능 가능 가능 성능 매우 빠름 중간 빠름 복잡성 낮음 중간 약간 복잡 사용 목적 간단한 parent-child 통신 여러 프로세스 간 안정적인 통신 고성능 로컬 멀티프로세스 통신","-특징#✅ 특징":"항목 내용 범위 부모와 자식 프로세스 간만 가능 (fork 이후 공유) 존속성 프로세스 종료 시 사라짐 방향성 단방향 (한쪽에서만 보내고 한쪽에서만 받음) 사용 예시 쉘 명령어 연결 (ls | grep \"txt\")","-특징-1#✅ 특징":"항목 내용 범위 관련 없는 모든 프로세스 간 통신 가능 존속성 프로세스 종료 후에도 유지됨 (수동 삭제 필요) 방향성 기본 단방향, 하지만 양방향도 가능 (두 FIFO 사용하면 됨) 형태 파일 시스템 상에 물리적으로 존재하는 파일","-특징-2#✅ 특징":"항목 내용 범위 동일 머신 내의 프로세스 간 존속성 프로세스 종료 후에도 파일 유지(삭제 필요) 방향성 양방향(full-duplex), 스트림 또는 데이터그램 방식 가능 성능 일반 파이프보다 느리지만 네트워크 소켓보다 빠름"},"title":"IPC (massage passing)"},"/02.inbox/ipv4-vs-ipv6/":{"data":{"":"","-ipv4-vs-ipv6-헤더-비교표-기능별-분류#📊 \u003cstrong\u003eIPv4 vs IPv6 헤더 비교표 (기능별 분류)\u003c/strong\u003e":"","-ipv4-헤더-필드#📋 \u003cstrong\u003eIPv4 헤더 필드\u003c/strong\u003e":"필드 이름 크기 간단 설명 Version 4비트 IP 버전 (예: IPv4, IPv6) 지정 Header Length (IHL) 4비트 헤더 길이 (옵션 유무에 따라 달라짐) Type of Service (TOS) 8비트 QoS 설정 (DSCP + ECN 포함) Total Length 16비트 전체 패킷 크기 (헤더 + 데이터) Identification 16비트 프래그먼트 식별을 위한 고유 번호 Flags 3비트 프래그먼트 가능 여부 표시 (예: DF, MF) Fragment Offset 13비트 조각난 패킷의 위치 정보 Time To Live (TTL) 8비트 패킷 수명 (라우터 통과 시 감소, 0이 되면 폐기) Protocol 8비트 상위 계층 프로토콜 (TCP=6, UDP=17 등) Header Checksum 16비트 헤더 오류 검출용 체크섬 Source IP Address 32비트 보낸 사람 IP 주소 Destination IP Address 32비트 받는 사람 IP 주소 Options (선택적) 가변 추가 기능 제공 (보통 사용 안 함) Data (Payload) 가변 실제 전송할 데이터 (TCP/UDP 세그먼트 등)","-ipv6-헤더-필드#📋 \u003cstrong\u003eIPv6 헤더 필드\u003c/strong\u003e":"필드 이름 크기 간단 설명 Version 4비트 IP 버전 번호 (IPv6이므로 값은 항상 6) Traffic Class 8비트 트래픽 우선순위 지정 (IPv4의 TOS/DSCP와 유사, QoS 지원) Flow Label 20비트 특정 패킷 흐름(예: 실시간 음성/영상) 식별용 라벨 (QoS 및 Flow 기반 처리 지원) Payload Length 16비트 헤더 이후 데이터(payload)의 길이 (바이트 단위) Next Header 8비트 다음 헤더의 타입을 지정 (TCP=6, UDP=17 등, IPv4의 Protocol 필드와 유사) Hop Limit 8비트 패킷이 지나갈 수 있는 최대 라우터 수 (IPv4의 TTL 필드와 동일한 역할) Source Address 128비트 보낸 호스트의 IPv6 주소 Destination Address 128비트 받는 호스트의 IPv6 주소 Data (Payload) 가변 실제 전송되는 데이터 (TCP/UDP 세그먼트 또는 다른 프로토콜 데이터)","-요약-비교-요약표#✅ \u003cstrong\u003e요약 비교 요약표\u003c/strong\u003e":"항목 IPv4 IPv6 특징 주소 길이 32비트 128비트 IPv6는 주소 고갈 문제 해결 헤더 길이 가변 (20~60바이트) 고정 (40바이트) IPv6는 단순화된 헤더 구조 QoS 지원 TOS (DSCP + ECN) Traffic Class (DSCP + ECN)\nFlow Label IPv6가 더 세밀한 QoS 지원 프래그먼트 중간 노드에서 가능 소스/목적지만 가능 IPv6는 라우터 부담 감소 체크섬 헤더 체크섬 있음 없음 IPv6는 TCP/UDP에서 처리 확장 기능 Options 필드 Extension Headers IPv6가 더 유연한 확장 구조 다음 헤더 Protocol 필드 Next Header 유사한 역할 수행","1--버전-및-기본-정보#1. ✅ \u003cstrong\u003e버전 및 기본 정보\u003c/strong\u003e":"기능 그룹 IPv4 필드 크기 설명 IPv6 필드 크기 설명 IP 버전 Version 4비트 IP 버전 식별 (IPv4=4, IPv6=6) Version 4비트 IP 버전 식별 (IPv6=6) 헤더 길이 Header Length (IHL) 4비트 헤더 총 길이 (옵션 포함 여부에 따라 다름) - - IPv6는 고정 헤더 길이 (40바이트) 전체 패킷 크기 Total Length 16비트 헤더 + 데이터 전체 크기 Payload Length 16비트 헤더 이후 데이터(payload) 길이만 지정","2--주소-지정-및-라우팅#2. 🎯 \u003cstrong\u003e주소 지정 및 라우팅\u003c/strong\u003e":"기능 그룹 IPv4 필드 크기 설명 IPv6 필드 크기 설명 출발지 주소 Source IP Address 32비트 송신자 IPv4 주소 Source Address 128비트 송신자 IPv6 주소 목적지 주소 Destination IP Address 32비트 수신자 IPv4 주소 Destination Address 128비트 수신자 IPv6 주소 다음 헤더 - - - Next Header 8비트 다음 헤더 유형 지정 (TCP/UDP/확장헤더 등)","3--qos-및-트래픽-관리#3. ⚙️ \u003cstrong\u003eQoS 및 트래픽 관리\u003c/strong\u003e":"기능 그룹 IPv4 필드 크기 설명 IPv6 필드 크기 설명 트래픽 우선순위 Type of Service (TOS) 8비트 DSCP(6비트) + ECN(2비트), QoS 설정 Traffic Class 8비트 DSCP(6비트) + ECN(2비트), QoS 설정 흐름 식별 - - - Flow Label 20비트 특정 흐름(flow) 식별용 라벨 (실시간 서비스 지원)","4--패킷-처리-및-포워딩#4. 🔄 \u003cstrong\u003e패킷 처리 및 포워딩\u003c/strong\u003e":"기능 그룹 IPv4 필드 크기 설명 IPv6 필드 크기 설명 생존 시간 Time To Live (TTL) 8비트 패킷의 최대 홉 수 (라우터 통과 시 감소) Hop Limit 8비트 동일한 기능 (IPv4 TTL과 동일) 체크섬 검사 Header Checksum 16비트 헤더 오류 검출용 (매 라우터마다 재계산) - - IPv6에서는 헤더 체크섬 제거 (TCP/UDP에서 처리) 프래그먼트 처리 Identification\nFlags\nFragment Offset 16+3+13비트 패킷 분할 및 조립 정보 - - IPv6에서는 프래그먼트 처리 소스/목적지에서만 가능","5--확장성-및-추가-기능#5. 🔧 \u003cstrong\u003e확장성 및 추가 기능\u003c/strong\u003e":"기능 그룹 IPv4 필드 크기 설명 IPv6 필드 크기 설명 확장 옵션 Options 가변 선택적 기능 제공 (보통 사용 안 함) Extension Headers 가변 Next Header로 연결되는 확장 헤더 구조 데이터 영역 Data (Payload) 가변 실제 전송 데이터 (TCP/UDP 등) Data (Payload) 가변 실제 전송 데이터 (TCP/UDP 등)","ip-헤더-필드별로-데이터-평면--제어-평면-사용-여부-정리#\u003cstrong\u003eIP 헤더 필드별로 데이터 평면 / 제어 평면 사용 여부 정리\u003c/strong\u003e":"필드 이름 크기 간단 설명 사용되는 평면 Version 4비트 IP 버전 (예: IPv4, IPv6) 지정 데이터 평면\n(패킷 포워딩 시 해석 필요) Header Length (IHL) 4비트 헤더 길이 (옵션 유무에 따라 달라짐) 데이터 평면\n(헤더 파싱 및 데이터 위치 식별) Type of Service (TOS) 8비트 QoS 설정 (DSCP + ECN 포함) 데이터 평면\n(QoS 기반 포워딩 정책 적용) Total Length 16비트 전체 패킷 크기 (헤더 + 데이터) 데이터 평면\n(패킷 처리 및 메모리 관리를 위해 사용) Identification 16비트 프래그먼트 식별을 위한 고유 번호 데이터 평면\n(프래그먼트 재조립 시 사용) Flags 3비트 프래그먼트 가능 여부 표시 (예: DF, MF) 데이터 평면\n(패킷 분할 및 재조합 결정) Fragment Offset 13비트 조각난 패킷의 위치 정보 데이터 평면\n(패킷 재조립 시 사용) Time To Live (TTL) 8비트 패킷 수명 (라우터 통과 시 감소, 0이 되면 폐기) 데이터 평면\n(패킷 생존 시간 관리 및 폐기 결정) Protocol 8비트 상위 계층 프로토콜 (TCP=6, UDP=17 등) 데이터 평면\n(상위 계층으로 전달 시 필요) Header Checksum 16비트 헤더 오류 검출용 체크섬 데이터 평면\n(패킷 손상 검사 후 전달 결정) Source IP Address 32비트 보낸 사람 IP 주소 데이터 평면, 제어 평면\n→ 포워딩에는 직접 사용되지 않지만, 로깅/필터링, 라우팅 프로토콜에서 활용 Destination IP Address 32비트 받는 사람 IP 주소 제어 평면, 데이터 평면\n→ 가장 핵심적인 필드\n→ 제어 평면: 경로 계산 (라우팅 테이블 매칭)\n→ 데이터 평면: 다음 홉 선택 및 포워딩 Options (선택적) 가변 추가 기능 제공 (보통 사용 안 함) 데이터 평면\n(특수한 경우에만 처리됨) Data (Payload) 가변 실제 전송할 데이터 (TCP/UDP 세그먼트 등) 데이터 평면\n(포워딩 대상인 실제 데이터)","데이터평면-제어-평면#데이터평면, 제어 평면":"데이터 평면 (Data Plane)\n→ 실제 데이터 패킷을 전달하는 역할 (패킷 포워딩) 제어 평면 (Control Plane)\n→ 어떤 경로로 패킷을 보낼지 결정하는 역할 (라우팅) 항목 데이터 평면 (Data Plane) 제어 평면 (Control Plane) 목적 패킷 전달 (포워딩) 경로 결정 (라우팅) 수행 작업 패킷 수신 → 목적지 주소 확인 → 다음 홉 선택 → 전달 라우팅 프로토콜 실행, 경로 계산, 라우팅 테이블 업데이트 처리 속도 매우 빠름 (마이크로초 이하) 상대적으로 느림 사용 메커니즘 포워딩 테이블 (FIB), 캐시 등 라우팅 프로토콜 (RIP, OSPF, BGP 등) 주요 구성 요소 라우터의 포워딩 엔진 라우터의 CPU, 라우팅 프로토콜 모듈 보안 영향 직접적인 패킷 유출/손실 영향 라우팅 정보 변조, 네트워크 다운 위험"},"title":"ipv4 vs ipv6"},"/02.inbox/java-%EB%A6%AC%ED%94%8C%EB%A0%89%EC%85%98reflection/":{"data":{"":"클래스 인터페이스의 메타 정보를 java.lang.Class 클래스 객체에서 관리한다 이를 통해 런타임 시점에 클래스의 정보를 확인할 수 있다\nClass class = 클래스 이름.class; // 클래스 이름을 통해 얻는다 Class class = Class.forName(클래스 이름); // 클래스 이름을 통해 얻는다 Class class = 객체 참조 변수.getClass(); // 객체의 이름을 통해 얻는다 이렇게 얻어진 객체로 부터 여러가지 정보를 확인할 수 있다\n메서드 info Package getPackage() 패키지 정보 읽기 String getSimpleName() 패키지를 제외한 타입 이름 String getName() 패키지를 포함한 전체 타입 이름 Constuctor[] getDeclaredConstructors() 생성자 정보 읽기 Method[] getDeclaredMethod() 메서드 정보 읽기 Field[] getDeclaredField() 필드 정보 읽기 등등 많은 것들 을 얻을 수 있다 제네릭은 런타임에는 타입을 알지 못한다"},"title":"java 리플렉션(reflection)"},"/02.inbox/java-%EB%A9%94%EB%AA%A8%EB%A6%ACmemory/":{"data":{"":""},"title":"java 메모리(memory)"},"/02.inbox/java-%EC%96%B4%EB%85%B8%ED%85%8C%EC%9D%B4%EC%85%98anotation/":{"data":{"":"어노테이션 적용대상 @Target 클래스 필드 메서드 또다른 어노테이션 어노테이션 유지정책 SOURCE=컴파일까지 컴파일 시점에 적용 CLASS=메모리 로딩때 까지 이후 제거 RUNTIME=계속 유지"},"title":"java 어노테이션(anotation)"},"/02.inbox/java-%EC%A0%9C%EB%84%A4%EB%A6%ADgeneric/":{"data":{"":"java 는 제네릭 배열을 생성하지 못한다\njava generic 원리 중요!!!\nInteger \u003c: Number Double \u003c: Number ArrayList\u003cE\u003e \u003c: List\u003cE\u003e Collection\u003cE\u003e \u003c: Iterable\u003cE\u003e Super type : Number 는 Integer 에 대해 Super type 이다 Sub type : Integer 는 Number 에 대해 Sub type 이다 variant 공변 : Number 와 Integer 는 공변한다 Invariant 불공변 : Integer 와 String 는 공변하지 않는다 Java에서는 해당 경우에 Substitution Principle을 적용하지 않습니다\npublic class Main{ public void static main(int argc, String[] argv){ List\u003cInteger\u003e ints = new ArrayList\u003c\u003e(); ints.add(1); ints.add(2); List\u003cNumber\u003e nums = ints //Compile 에러 발생 nums.add(3.14); // 이와 같은 연산을 막기 위해 위에서 미리 방지한다 } } 즉 List\u003cInteger\u003e는 List\u003cNumber\u003e의 Subtype이 아니다 하지만 List\u003cE\u003e는 Collection\u003cE\u003e를 상속받으므로 List\u003cInteger\u003e는 Collection\u003cInteger\u003e의 Subtype이다.\njava는 지정된 generic type parametor에 대해서는 invariant 하다 단 상위경계타입 파라미터를 통해 가능하다\n=upper-bound Type Parameter\nclass Data{ private List\u003cNumber\u003e list; public void addAll(List\u003cNumber\u003e cols){ this.list.addAll(cols); } } public class Main { public static void main(String[] args) { Data data = new Data(); List\u003cInteger\u003e ints = Arrays.asList(1, 2, 3); List\u003cDouble\u003e dbls = Arrays.asList(1.0, 2.8); List\u003cNumber\u003e nums = Arrays.asList(5,4.5); data.addAll(ints); //Compile 에러 발생 data.addAll(dbls); //Compile 에러 발생 data.addAll(nums); } } 아래와 같이 코드를 변경\nclass Data{ private List\u003cNumber\u003e list; public void addAll(List\u003cNumber\u003e cols){ this.list.addAll(cols); } } public class Main { public static void main(String[] args) { Data data = new Data(); List\u003cInteger\u003e ints = Arrays.asList(1, 2, 3); List\u003cDouble\u003e dbls = Arrays.asList(1.0, 2.8); List\u003cNumber\u003e nums = Arrays.asList(5,4.5); data.addAll(ints); //Compile 에러 발생 data.addAll(dbls); //Compile 에러 발생 data.addAll(nums); } }"},"title":"java 제네릭(generic)"},"/02.inbox/java-%EC%BB%AC%EB%A0%89%EC%85%98collections-framework/":{"data":{"":"리스트 : 배열의 확장 배열리스트 : 크기를 내부에서 자동으로 정해주는 배열 (vector) 링크드리스트 : 인접한 위치에 저장되지 않고 포인터를 사용하여 연결되는 선형 데이터 구조 큐 : 선입선출 set : 집합 중복 불가 map = dictionary : key value 한쌍 구조"},"title":"java 컬렉션(Collections Framework)"},"/02.inbox/javascript-%EC%9E%90%EB%A3%8C%ED%98%95/":{"data":{"":"var let const 재선언 o x x 업데이트 o o x 호이스팅 o o o 자동 초기화 o x x 호이스팅: let, const 는 오류 발생(호이스팅은 되어도 자동 초기화 안해서 오류 발생)\nconsole.log(a) 변환 -\u003e var a console.log(a) // undefined 기준 원시(primitive) number boolean null undifined 참조(reference) BigInt object array function 자바스크립트에서는 원시 타입(primitive type) 참조 타입(reference type)이라는 두 가지 자료형을 제공한다.\n숫자, 불린값, null과 undefined는 원시 타입이다. 객체, 배열, 함수는 참조 타입이다."},"title":"javascript 자료형"},"/02.inbox/javascript-%ED%95%A8%EC%88%98/":{"data":{"":"var let const 재선언 o x x 업데이트 o o x 호이스팅 o o o 자동 초기화 o x x 호이스팅: let, const 는 오류 발생(호이스팅은 되어도 자동 초기화 안해서 오류 발생)\nconsole.log(a) 변환 -\u003e var a console.log(a) // undefined 기준 원시(primitive) number boolean null undifined 참조(reference) BigInt object array function 자바스크립트에서는 원시 타입(primitive type) 참조 타입(reference type)이라는 두 가지 자료형을 제공한다.\n숫자, 불린값, null과 undefined는 원시 타입이다. 객체, 배열, 함수는 참조 타입이다."},"title":"javascript 함수"},"/02.inbox/linux-locale-setting/":{"data":{"":"","systemd-기반-리눅스-배포판#systemd 기반 리눅스 배포판":"localectl 명령은 systemd 기반 리눅스 배포판 에서 사용할 수 있는 시스템 관리 도구로, 로케일(locale), 키보드 레이아웃, 가상 콘솔(Console) 설정 등을 관리하는 데 사용됩니다.\n1. 로케일 및 키보드 설정 확인\n# localectl System Locale: LANG=en_US.UTF-8 VC Keymap: n/a X11 Layout: us X11 Model: pc105 형식 의미 System Locale 현재 설정되어 있는 로케일(Locale)을 표시합니다. VC Keymap 가상콘솔에서 사용하는 키맵을 표시합니다. X11 Layout Xwindows에서 사용되는 키보드 레이아웃을 표시합니다. X11 Model 키보드 모델을 표시 합니다. 2. 설정 가능한 로케일(Locale) 확인\n# localectl list-locales C.UTF-8 en_US.UTF-8 localectl 명령어로 list-locales 옵션을 사용하면 설정이 가능한 로케일(Locale) 목록을 출력합니다.\n3. 로케일(Locale) 설정\n사용법 : localectl set-locale \"[Locale]\" # localectl set-locale \"en_US.UTF-8\" localectl 명령어에 set-locale 옵션을 사용하여 로케일(Locale)을 설정할 수 있습니다.\n4. 시스템에 설정되어 있는 로케일 정보 확인\n# locale LANG=en_US.UTF-8 LANGUAGE= LC_CTYPE=\"en_US.UTF-8\" LC_NUMERIC=\"en_US.UTF-8\" LC_TIME=\"en_US.UTF-8\" LC_COLLATE=\"en_US.UTF-8\" LC_MONETARY=\"en_US.UTF-8\" LC_MESSAGES=\"en_US.UTF-8\" LC_PAPER=\"en_US.UTF-8\" LC_NAME=\"en_US.UTF-8\" LC_ADDRESS=\"en_US.UTF-8\" LC_TELEPHONE=\"en_US.UTF-8\" LC_MEASUREMENT=\"en_US.UTF-8\" LC_IDENTIFICATION=\"en_US.UTF-8\" LC_ALL= locale 명령어를 사용하면 LANG를 포함하여 설정되어 있는 전체 로케일(Locale) 정보를 확인할 수 있습니다.\n5. 사용가능한 로케일 확인\n# locale -a locale 명령어에서 -a 옵션을 사용하면 사용 가능한 로케일(Locale)를 확인하실 수 있으며, 원하시는 로케일(Locale) 이 없으신 경우 별도로 설치해야 됩니다."},"title":"linux locale setting"},"/02.inbox/mac-java-%EA%B4%80%EB%A6%AC/":{"data":{"":"apple 에서 관리되는 방식이므로 brew 패키지 관리자를 통해 하는 방법이 아니다\n설치된 java 보기\n/usr/libexec/java_home -verbose 모든 JDK는 기본 위치인 /Library/Java/JavaVirtualMachines에 놔두어집니다. 시스템은 기본적으로 가장 높은 버전을 선택합니다. 기본 선택에서 제외하려면 해당 JDK의 Contents/Info.plist 파일 이름을 Info.plist.disabled로 변경합니다. 이렇게 하면 $JAVA_HOME이 해당 JDK를 가리키거나 스크립트나 설정에서 명시적으로 참조할 때 해당 JDK를 여전히 사용할 수 있습니다. 단지 시스템의 java 명령어에서는 무시됩니다. 시스템 런처는 Info.plist 파일이 있는 JDK 중 가장 높은 버전을 사용합니다. 삭제할 때 여기도 확인\nsudo rm -fr /Library/Internet\\ Plug-Ins/JavaAppletPlugin.plugin sudo rm -fr /Library/PreferencePanes/JavaControlPanel.prefPane"},"title":"mac java 관리"},"/02.inbox/meterialize-view-%EC%9D%98-%EC%A7%91%EA%B3%84%EC%97%B0%EC%82%B0%EC%97%90%EC%84%9C-%EC%82%BD%EC%9E%85-%EC%82%AD%EC%A0%9C%EC%97%90-%EB%94%B0%EB%A5%B8-%EB%B3%80%ED%99%94/":{"data":{"":"아래는 집계 연산에서 count, sum, avg, min, max의 삽입 및 삭제에 따른 변화를 중심으로 설명하겠습니다.","1-count#1. Count":"","2-sum#2. Sum":"","3-average-avg#3. Average (avg)":"","4-min-and-max#4. Min and Max":"","삭제#삭제":"동작: 삭제할 튜플이 있을 때, 해당 튜플의 그룹을 찾아 카운트를 감소시킵니다. 카운트 감소: 만약 카운트가 0이 된다면, 해당 그룹을 v에서 삭제합니다.","삭제-1#삭제":"동작: 삭제할 튜플이 있을 때, 해당 튜플의 그룹에서 값을 빼줍니다. 합계 감소: 만약 특정 그룹의 합계가 0이 되면, 해당 그룹을 v에서 삭제합니다. 하지만 합계가 0일 때 단순히 삭제할 수 없는 이유는 다른 튜플이 여전히 존재할 수 있기 때문입니다.","삭제-2#삭제":"동작: 만약 삭제할 튜플이 최소 최대이면 해당 그룹의 다른 튜플들을 확인하여 새로운 최소값 또는 최대값을 찾아야 합니다. 비용 발생: 이 과정은 다른 튜플을 스캔해야 하므로 비용이 더 발생합니다.","삽입#삽입":"동작: 새로운 튜플이 삽입되면, 해당 튜플의 그룹이 이미 존재하는지 확인합니다. 존재하는 경우: 해당 그룹의 카운트를 1 증가시킵니다. 존재하지 않는 경우: 새로운 그룹을 추가하고 카운트를 1로 설정합니다.","삽입-1#삽입":"동작: 새로운 튜플이 삽입되면, 해당 그룹의 값을 합산합니다. 존재하는 경우: 그룹의 합계에 새로운 튜플의 값을 추가합니다. 존재하지 않는 경우: 새로운 그룹을 추가하고 합계를 해당 튜플의 값으로 설정합니다.","삽입-2#삽입":"동작: 새로운 튜플이 삽입될 때, 해당 그룹의 최소값과 최대값을 업데이트합니다. 최소값/최대값 변경: 새로운 값이 기존의 최소값보다 작거나 최대값보다 클 경우, 해당 값을 업데이트합니다.","예시#예시":"초기 상태: v = { (1, 2), (2, 3) } (그룹 1의 카운트 2, 그룹 2의 카운트 3) 삽입: 튜플 (1)이 추가되면, v는 { (1, 3), (2, 3) }로 변경됩니다. 삭제: 튜플 (2)가 삭제되면, v는 { (1, 3), (2, 2) }로 변경됩니다.","예시-1#예시":"초기 상태: v = { (1, 50), (2, 60) } (그룹 1의 합계 50, 그룹 2의 합계 60) 삽입: 튜플 (1, 20)이 추가되면, v는 { (1, 70), (2, 60) }로 변경됩니다. 삭제: 튜플 (1, 50)가 삭제되면, v는 { (1, 20), (2, 60) }로 변경됩니다.","예시-2#예시":"초기 상태: 그룹 1의 합계 50, 카운트 2 (평균 25) 삭제: 튜플 (1, 20)가 삭제되면, 그룹 1의 합계는 30, 카운트는 1이 되어 평균은 30이 됩니다.","예시-3#예시":"초기 상태: v = { (1, min=10, max=20), (2, min=30, max=40) } 삽입: 튜플 (1, 5)가 추가되면, 그룹 1의 최소값이 5로 업데이트됩니다. 삭제: 튜플 (1, 20)가 삭제되면, 그룹 1의 최대값을 찾기 위해 다른 튜플들을 확인해야 하므로 비용이 발생합니다.","처리-방법#처리 방법":"합계와 카운트 별도 유지: 평균을 계산하기 위해서는 합계와 카운트를 별도로 유지합니다. 삭제 시: 특정 그룹의 튜플이 삭제되면, 해당 그룹의 합계에서 삭제된 값만큼 빼고, 카운트도 감소시킵니다."},"title":"meterialize view 의 집계연산에서 삽입 삭제에 따른 변화"},"/02.inbox/mysql-%EB%AA%85%EB%A0%B9-%EB%AA%A8%EC%9D%8C/":{"data":{"":"mysql 로그인\nmysql -u {name} -p # name 유저로 -p 패스워드를 사용해 로그인 하겠다 mysql 유저 생성(외부에서)\nmysqladmin -u {name} mysql 유저 정보 확인\nUSE mysql; SELECT user, host FROM user; /* mysql 유저 정보 확인 */ mysql 유저 권한 추가\nGRANT ALL privileges ON DB명.* TO username@hostname IDENTIFIED BY '비밀번호'; mysql 유저 권환 확인\nSHOW GRANTS FOR username@hostname; SHOW VARIABLES LIKE \"general_log%\"; 서버 관리를 하다보면 mysql 사용자 계정을 추가해 줄때가 있다."},"title":"mysql 명령 모음"},"/02.inbox/oracle-database-%EA%B6%8C%ED%95%9C/":{"data":{"":"Oracle 데이터베이스에서 사용자의 권한을 설정할 때 사용할 수 있는 다양한 권한(privileges)과 역할(roles)의 예시는 아래와 같습니다. 권한은 크게 시스템 권한과 객체 권한으로 나뉩니다. 아래는 그 주요 예들입니다.","1-시스템-권한-system-privileges#\u003cstrong\u003e1. 시스템 권한 (System Privileges)\u003c/strong\u003e":"시스템 권한은 데이터베이스 전체에서 특정 작업을 수행할 수 있도록 허용합니다.\n권한 설명 CREATE SESSION 데이터베이스에 연결할 수 있는 권한. CREATE TABLE 새 테이블을 생성할 수 있는 권한. CREATE VIEW 새 뷰(View)를 생성할 수 있는 권한. CREATE MATERIALIZED VIEW 새 물리화된 뷰(Materialized View)를 생성할 수 있는 권한. CREATE PROCEDURE 프로시저, 함수 또는 패키지를 생성할 수 있는 권한. CREATE SEQUENCE 새 시퀀스를 생성할 수 있는 권한. CREATE TRIGGER 트리거(Trigger)를 생성할 수 있는 권한. CREATE USER 새로운 사용자를 생성할 수 있는 권한. CREATE ROLE 새로운 역할(Role)을 생성할 수 있는 권한. CREATE INDEX 새로운 인덱스를 생성할 수 있는 권한. CREATE SYNONYM 새로운 동의어(Synonym)를 생성할 수 있는 권한. CREATE PUBLIC SYNONYM 공용 동의어(Public Synonym)를 생성할 수 있는 권한. CREATE DATABASE LINK 데이터베이스 링크(Database Link)를 생성할 수 있는 권한. ALTER USER 사용자의 속성(예: 비밀번호, 테이블스페이스 등)을 변경할 수 있는 권한. DROP USER 사용자를 삭제할 수 있는 권한. DROP ANY TABLE 모든 테이블을 삭제할 수 있는 권한. SELECT ANY TABLE 모든 테이블에 대해 SELECT 쿼리를 실행할 수 있는 권한. UPDATE ANY TABLE 모든 테이블의 데이터를 업데이트할 수 있는 권한. DELETE ANY TABLE 모든 테이블의 데이터를 삭제할 수 있는 권한. INSERT ANY TABLE 모든 테이블에 데이터를 삽입할 수 있는 권한. EXECUTE ANY PROCEDURE 모든 프로시저와 함수를 실행할 수 있는 권한. MANAGE TABLESPACE 테이블스페이스를 관리할 수 있는 권한.","2-객체-권한-object-privileges#\u003cstrong\u003e2. 객체 권한 (Object Privileges)\u003c/strong\u003e":"객체 권한은 특정 객체(예: 테이블, 뷰, 시퀀스 등)에 대해 작업을 수행할 수 있는 권한입니다.\n권한 설명 SELECT 테이블 또는 뷰에서 데이터를 조회할 수 있는 권한. INSERT 테이블에 데이터를 삽입할 수 있는 권한. UPDATE 테이블 데이터를 수정할 수 있는 권한. DELETE 테이블 데이터를 삭제할 수 있는 권한. REFERENCES 다른 테이블에서 외래 키 제약 조건을 생성할 때 참조할 수 있는 권한. INDEX 테이블의 인덱스를 생성할 수 있는 권한. EXECUTE 특정 프로시저, 함수, 또는 패키지를 실행할 수 있는 권한. ALTER 특정 객체(테이블, 뷰 등)를 수정할 수 있는 권한. GRANT 다른 사용자에게 객체 권한을 부여할 수 있는 권한.","3-역할-roles#\u003cstrong\u003e3. 역할 (Roles)\u003c/strong\u003e":"역할은 권한의 집합으로, 여러 권한을 하나의 그룹으로 묶어 효율적으로 관리할 수 있습니다.\n역할(Role) 설명 CONNECT 기본 연결 권한. RESOURCE 데이터베이스 객체(테이블, 뷰, 시퀀스 등)를 생성할 수 있는 권한 세트. DBA 데이터베이스 관리자가 사용하는 모든 권한 세트. READ ONLY 데이터베이스를 읽기 전용으로 접근할 수 있는 역할. READ WRITE 읽기 및 쓰기 권한을 포함하는 역할. PUBLIC 모든 사용자에게 적용되는 기본 역할.","4-특정-권한-부여-예시#\u003cstrong\u003e4. 특정 권한 부여 예시\u003c/strong\u003e":"다양한 권한 부여 예시는 아래와 같습니다:\n-- 테이블 관련 권한 부여 GRANT SELECT, INSERT, UPDATE ON employees TO user_name; -- 프로시저 실행 권한 부여 GRANT EXECUTE ON my_procedure TO user_name; -- 테이블스페이스 관리 권한 부여 GRANT UNLIMITED TABLESPACE TO user_name; -- 모든 테이블에 대한 SELECT 권한 부여 GRANT SELECT ANY TABLE TO user_name; -- 특정 데이터베이스 링크 생성 권한 부여 GRANT CREATE DATABASE LINK TO user_name; -- 역할(Role) 부여 GRANT CONNECT TO user_name; GRANT RESOURCE TO user_name; GRANT DBA TO user_name;","5-고급-권한-관리#\u003cstrong\u003e5. 고급 권한 관리\u003c/strong\u003e":"Oracle에서는 특정 작업에 대해 더 세부적으로 권한을 관리할 수 있습니다:\n권한 회수: REVOKE 명령을 사용하여 권한을 회수할 수 있습니다.\nREVOKE CREATE TABLE FROM user_name; 권한 전달 허용: WITH GRANT OPTION을 추가하면 사용자가 다른 사용자에게 권한을 다시 부여할 수 있습니다.\nGRANT SELECT ON employees TO user_name WITH GRANT OPTION; 이 예시들을 기반으로, 사용자의 역할과 요구 사항에 맞는 권한 구성을 설계할 수 있습니다."},"title":"Oracle database 권한"},"/02.inbox/pragma/":{"data":{"":"사용할 일은 잦은데~ 너무 무관심한 척 한 것 같다~ 매번 매번 사용해도 헷갈리는 pragma의 용법에 대해 모아 총정리 하였다.\n#pragma는 define 이나 include와 같이 #으로 시작하는 전처리구문(precompiler)의 하나이다. 컴파일러에 종속적인 구문이라 컴파일러가 변경되었을 경우 제대로된 동작을 보장하지 못하므로 프로젝트 진행중에 서로 다른 컴파일러를 사용한다면 사용하지 않음이 바람직 하겠다. - 대신 대체하는 문법을 사용해야 되겠다.\n**#pragma once ** 이것은 “컴파일러에게 한번만 컴파일해!” 라고 명령한다. 헤더의 중복을 막아준다. 무슨말인가 하면\na.h를 구현한 a.cpp, a.h는 독립적이다.(include가 없다.) b.h를 구현한 b.cpp, c.h, a.h순서로 include c.h를 구현한 c.cpp, a.h를 include\n컴파일하면 b.h에서 c.h를 포함시키라고 되어있네? 하고 c.h에 들어가고 어? a.h를 포함하라고 그러네? 이러고 a.h를 포함한 c.h가 b.h로 돌아온다 그리고 a.h를 포함하라는 명령을 받고 a.h를 추가하다보면 같은 변수와 함수선언이 되어있다. 에러에러~ 같은 선언이 두 번 반복되니 당연히 충돌이 난다. 컴파일러가 똑똑하여 단순히 경고 처리만 해주고 알아서 하나로 종합해줄 수도 있지만 대부분의 기본적인 컴파일러는 이건 아니잖아~ 한다.\n이럴 때 써주는 것이다. pragma once 이는 c기본문법을 사용하여 구현할 수 있다.\n#ifdef _MYCOMPILECK #define _MYCOMPILECK // 헤더 파일의 내용 선언 #endif **#pragma comment() **기본적인 pragma comment()의 형식은 다음과 같다.\n#pragma comment( comment-type, [“comment string”] )\n[] 안의 구문은 comment-type에 따라 필요할 경우 사용하는 것이다. comment type에는 compiler, exestr, lib, linker, user 등이 올 수 있다. #pragma comment( linker, “/subsystem:windows” ) #pragma comment( linker, “/subsystem:console” )\nlinker 를 사용하면 프로젝트를 console application인지 win32 application인지 명시해줄 수 있다.\n또한 섹션의 설정을 할 수 있다.\n#pragme comment( linker, “SECTION:.SHAREDATA,RWS” )\n#pragma data_seg(“SHAREDATA”) 와 함께 사용하여 공유 메모리를 생성한다. 위의 명령어 대신 def 파일 안에 아래와 같이 해주어도 된다.\nSECTIONS SHAREDATA READ WRITE SHARED 이 중 가장 대표적인 사용법은 명시적인 라이브러리의 링크이다.\n#pragma comment(lib, “xxxx.lib”)\n와 같이 사용하여 해당 라이브러리를 링크시켜 준다. 여러사람이 같이 수행하는 프로젝트의 경우 이와 같은 방법을 사용하여 lib를 링크하는 것이 라이브러리가 링크되어있다는 사실을 알기에도 좋고 굳이 주석다라 설명할 필요도 없어 좋지 않나 싶다. (있다는 사실은 알지만 아직 프로젝트 수행중 실제로 사용해 본적은 없음)\n**#pragma data_seg() **pragma data_seg()의 형식은 다음과 같다.\n#pragma data_seg( [“section-name”[, “section-class”] ] )\n#pragma data_seg( “SHAREDATA” ) int x; char y; #pragma data_seg()\nDLL 파일을 만들어보면서 제일 많이 사용해 보았고 가장 헷갈려 했던 부분이기도 하다. DLL의 데이터 공유를 하기 위해 사용한다. 공유할 섹션을 만드는 것이다. 위의 명령어는 필수적으로 위에서 사용된 두 가지중 한가지 방법과 함께 사용 되어야 한다.\n#pragme comment( linker, “SECTION:.SHAREDATA,RWS” )\nSECTIONS SHAREDATA READ WRITE SHARED 둘 다 해당 SECTION(SHAREDATA)의 허용 범위(?속성?)를 설정하는 것이다. READ, WRITE, SHARED 세 가지를 쓴다는 의미~ 해당 사항에 대해 msdn에서 자세한 정보를 발견하지 못해 적지 못하였다(검색능력의 부족!!) 이제 변수 x와 y는 해당 dll을 사용하는 외부 파일과 같이 공유할 수 있는 변수가 되었다.(외부에서 접근 가능하게 되었다.)\n이렇게 공유하는 변수는 물론 new로 메모리를 할당한 변수도 공유 가능하다. 특히 new 나 memalloc(이건 아직 미확인이지만 같은 메모리 할당이므로 가능할 것으로 본다)으로 메모리할당한 변수들은 dll외부에서도 해제(delete) 가능하다. #pragma warning 특정 경고를 끄고 싶을 때 사용한다. 비쥬얼 스튜디오의 버전이 다르기 때문에 뜨는 경고는 더더욱이 귀찮은 존재이다.(하지만 수정해서 손해볼 것은 없다. 그것이 곧 버그로 이어질 수 있기 때문이다. 특히 형변환의 경우 강제 캐스팅하여 확실히 명시해주는 것이 좋다. 일부러 그 값을 떼어낸다는 프로그래머의 의지를 컴파일러에게 보여주자. 부지런할수록 후에 손이 가는 일이 적어진다. 노력하자~)\n형식은 이와 같다.\n#pragma warning( warning-specifier : warning-number-list [; warning-specifier : warning-number-list…] ) #pragma warning( push[ ,n ] ) #pragma warning( pop )\n실제 사용은 아래와 같이 한다.\n#pragma warning( disable:4996 )\n**#pragma message() **컴파일 중에 메세지를 뿌려준다. 말이 필요없다-.-/\n#pragma message(“merong”)\nTakes from: http://mayu.tistory.com/8 선행처리기중의 하나인 pragma에 관한 사용법을 정리하여 올립니다. 문법은 다음과 같습니다.\n#pragma directive-name\n#pragma는 이것을 지원하는 다른 compiler에서 방해가 없이 C++ Builder에서 원하는 지시어를 정의할 수 있도록 해줍니다. 만일 지시명을 인식하지 못한다면 에러 또는 경고 메세지를 수반하지 않고서 #pragma의 지시를 무시하게 됩니다.\nBorland C++ Builder에서 지원하는 #pragma지시어는 모두 18가지가 있습니다. 이제부터 그것들을 하나 하나 살펴보기로 하겠습니다.\n1. #pragma anon_struct . 사용법 #pragma anon_struct on #pragma anon_struct off . Class에 익명의 구조체를 포함하여 compile하는것을 허락할 것인지를 지시합니다. 익명이란 tag를 갖지 않는다는것을 의미합니다. ex) #pragma anon_struct on struct S { int i; struct { // 익명구조체를 포함한다. int j ; float x ; }; class { // 익명 클래스를 포함한다. public: long double ld; }; S() { i = 1; j = 2; x = 3.3; ld = 12345.5;} }; #pragma anon_struct off\nvoid main() { S mystruct; mystruct.x = 1.2; // 포함된 data에 값을 할당한다. }\n//————————————————————————– 2. #pragma argsused . argsused 프라그마는 함수 정의 사이에서만 허용되고 바로 다음 함수에만 영향을 미치며 경고 메세지를 disable시킵니다. 이 pragma를 사용하지 않은 경우 사용되지 않은 argument가 있으면 “Parameter name is never used in function func-name” 라는 경고 메세지를 표시하게 됩니다. ex) #pragma argsused void __fastcall TImageForm::FileEditKeyPress(TObject* Sender, Char \u0026Key) { if (Key == 0x13) { FileListBox1-\u003eApplyFilePath(FileEdit-\u003eText); Key = 0x0; } } 위의 예에서는 함수내에서 Sender라는 인수가 사용되지 않았지만 경고 메세지가 표시되지 않습니다.\n//————————————————————————– **3. #pragma codeseg ** . 사용법 #pragma codeseg \u003cseg_name\u003e \u003c“seg_class”\u003e . codeseg 프라그마는 함수들을 위치시킬 group, class 또는 segment의 이름을 줄수 있도록 지시합니다. 만일 option없이 사용하였다면 함수의 배치를 위해서 default code segment가 사용되어질것입니다. 결국 이 pragma를 사용하지 않는 경우와 동일한 결과를 가져옵니다.\n//————————————————————————–\n**4. #pragma comment ** . 사용법 #pragma comment (comment type, “string”) . comment 프라그마는 출력되어지는 file에 주석을 기록시킬것을 지시합니다. comment type에 올수 있는 값들은 다음중의 하나가 될것입니다. * exestr linker가 “.OBJ” file에 string을 기록합니다. 이렇게 기록된 string은 실행파일내부에 기록되어지며, 이것은 결코 메모리로 load되지 않습니다. 하지만 적당한 파일 검색 유틸리티를 사용하여 실행파일에서 string을 찾아볼 수 있습니다. * lib “.OBJ” file에 주석의 내용을 기록합니다. library에 새로운 module을 추가하는 경우 에만 comment 프라그마를 사용하여 linker에게 결과 file에 명시할 수 있도록 지시할 수 있습니다. 다시 말하면 기존에 작성되어진 module에는 comment 프라그마를 사용하여 string을 추가 시킬수 없습니다. 새롭게 library를 작성한다면 예외일 수 있겠지요. linker는 최종의 library에서 string에 명시된 library module 이름을 포함 합니다. 여러개의 module들도 이름지어질 수 있으며 이름을 만들기 위하여 linke되어집니다.\n예) comment ( lib, * ) : comment로 사용할 수 있는 명령은 여러 개 있는데, 그중 가장 대표적인 것이 lib 으로, 해당 라이브러리를 링크시켜준다 .\n즉, 지정된 라이브러리 화일을 포함하여 컴파일한다. 프로젝트 설정에 라이브러리를 포함하는 것과 같다.\n예2) comment( lib, “ws2_32” ) 이것은, 컴파일시 ws2_32.lib 파일을 링크하라는 명령입니다. 보통 Visual studio같은 IDE 개발환경에서는, 프로젝트 셋팅에서 해주지만, 혹 그런부분을 빼먹거나 환경이 바뀔때를 대비해서 이렇게 해두면 편하죠.\n예3) #pragma comment( “comment-type” [, commentstring] )\ncomment type에는 compiler, exestr, lib, linker, user 등이 올 수 있습니다.\n그 중 질문에서의 lib는 library file을 지정하는 것이라고 생각하시면 됩니다. comment string이라는 부분에는 file의 이름이나 path를 넣으시면 됩니다. “.lib” file 아시죠?\n그러니까 굳이 project settings에서 link tab에 있는 input에 .lib file을 쓰지 않고 #pragma comment ( lib, “xxx.lib” ) 라고 써도 된다는 거죠..\n* user compiler는 “.OBJ” file에 string을 기록합니다. 하지만 linker에 의해 string은 무시되어집니다. object 파일에만 그 내용이 남게 됩니다.\n//————————————————————————–\n**5. #pragma exit ** . 사용법 #pragma startup function-name #pragma exit function-name . 이들 두 프라그마는 프로그램이 프로그램 시동시(main이 호출되기 전) 호출 되어야 할 함수와 프로그램 탈출(프로그램이 _exit를 통해 종료하기 바로 전) 을 명시할 수 있도록 합니다. 명시된 function-name은 반드시 인수를 취하지 않고 void를 return하는 미리 선언된 함수여야합니다. 다시 말하면 다음과 같이 선언될 수 있습니다. void func (void); priority는 반드시 64-255의 범위 내에 있는 정수여야하며 최상의 우선권은 0입니다. 0-63사이의 priority는 C library에서 사용하므로 사용자가 이를 사용해서는 안됩니다. 최상위 우선권을 가진 함수는 시동시에 맨 먼저 호출 되고 탈출시에 맨 마지막으로 호출됩니다. 우선권을 명시해 주지 않을 경우 기본적으로 100의 우선권을 갖게 됩니다. pragma startup 또는 exit에 사용된 함수명은 반드시 프라그마 라인에 도달하기 전에 정의(또는 선언)되어야함에 주의하십시요. ex) #include \u003cstdio.h\u003e void startFunc(void) { printf(“Startup Function.\\n”); } #pragma startup startFunc 64 //우선권 64로 시동시에 맨 먼저 호출됩니다.\nvoid exit Func(void) { pirntf(“Wrapping up execution.\\n”); } #pragma exit exitFunc //기본적으로 우선권이 100으로 지정됩니다.\nvoid main(void) { printf(“This is main.\\n”); }\n//————————————————————————–\n6. #pragma hdrfile . 사용법 #pragma hdrfile “filename.CSM” . 이 지시어는 프리컴파일된 헤더를 저장할 파일의 이름을 설정합니다. IDE 프로젝트를 위한 디폴트 파일명은 .CSM이고 command line용 으로는 BC32DEF.CSM이라는 이름을 갖습니다. 프리컴파일된 헤더를 사용하지 않으면 이 지시어는 효력이 없으며 명령라인 컴파일러 옵션 -H=filename 또는 프리 컴파일된 헤더를 사용하면 프리 컴파일된 헤더를 저장하기 위해 사용되는 파일명을 변경할 수 있습니다. 명령라인 옵션은 다음과 같습니다. * 프리컴파일드 헤더를 사용하는 경우 -H=filename * 프리컴파일드 헤더를 사용은 하지만 새로운 프리컴파일드 헤더파일을 변환하지 않는 경우 -Hu * 프리컴파일드 헤더를 사용하지 않거나 새로운 프리컴파일드 헤더파일을 변환하지 않는 경우. (기본값) -H-\n//————————————————————————–\n7. #pragma hdrstop . 사용법 #pragma hdrstop . 이 지시어는 프리컴파일에 적합한 헤더 파일의 목록을 종료시키는데, 이것을 사용하면 프리컴파일된 헤더가 사용하는 디스크 공간의 양을 줄일 수 있습니다. 프리컴파일드 헤더파일은 #pragma hdrstop이 선언되기 전에 #include를 사용하여 포함된 헤더파일들을 동일하게 프로젝트 내의 source들간에 공유시킬 수 있습니다. 그러므로 #pragma hdrstop전에 일반적인 헤더파일들을 포함하면 최상의 콤파일러의 성능을 얻을 수 있습니다. 확실하게 #pragma hdrstop 전에 #include를 사용한다면 모든 source file들에게 동일하게 적용되거나 아주 조그마한 변화만이 있을 것입니다. IDE 환경에서는 강화된 프리컴파일드 헤더의 성능을 가지는 코드로 변환합니다. 예를 들자면 다음의 New Application의 소스 파일인 “Unit1.cpp\"는 다음과 같이 될것입니다.\n#include \u003cvcl.h\u003e // 일반적인 헤더파일 #pragma hdrstop // 헤더파일의 리스트는 여기서 끝난다.\n#include “Unit1.h” // 헤더파일의 명시 //…. 이 pragma 지시어는 오직 source file에서만 사용하며, 헤더파일에서 사용했다 면 아무런 효과도 없을 것입니다.\n//————————————————————————–\n**8. #pragma inline ** . 사용법 #pragma inline . 이 지시어는 명령 라인 콤파일러 옵션 -B 또는 IDE의 인라인 옵션과 동일 합니다. 이것은 컴파일러에게 프로그램 내에 인라인 어셈블리 언어 코드가 있음을 알려줍니다. 컴파일러는 #pragma inline을 만날때 -B옵션을 사용하여 스스로 재시동하므로 이 지시어는 파일의 상단에 배치되는 것이 최선입니다. 실제로 -B옵션과 #pragma inline을 모두 off시켜둘 수 있습니다. 그러면 컴파일러는 asm문을 만나자마자 스스로 재시동합니다. 이 옵션과 지시어의 목적은 컴파일 시간을 다소 절약하는 것입니다.\n//————————————————————————–\n**9. #pragma intrinsic ** . 사용법 #pragma intrinsic [-]function-name . #pragma intrinsic를 사용하면 함수의 inline화를 위해 command-line 스위치나 IDE의 옵션이 무시되어집니다. intrinsic함수를 인라인화할 때는 그 함수를 사용하기 전에 반드시 그것을 위한 원형을 포함시켜야만 합니다. 이것은 인라인화 할 때 컴파일러가 인라인화한 함수를 내부적으로 인식하는 함수로 개명하는 매크로를 실제로 생성하기 때문입니다. 가령 strcpy 함수를 인라인 화 하기 위하여 다음과 같은 문장을 사용하였다면 #pragma intrinsic strcpy 컴파일러는 다음과 같은 매크로를 생성합니다. #define strcpy __strcpy__ 컴파일러는 두 선행 밑줄과 두 후미 밑줄을 사용하여 함수 호출을 인식하고 그 함수의 원형을 내부적으로 저장해 둔 원형과 부합시키려 합니다. 그러므로 원형을 공급하지 않거나 공급한 원형이 콤파일러 내부의 원형과 부합되지 않을 경우, 콤파일러는 그 함수를 인라인화 하려는 시도를 불식시키고 에러를 발생시킵니다. 이 프라그마 사용의 궁극적인 목적은 함수 호출에 대한 오버헤드를 줄위기 위한것입니다. 함수호출은 빨라지겠지만 그만큼 크기는 증가하게 될것입니다. ex) #pragma intrinsic strcpy #pragma intrinsic -strcpy\n//————————————————————————–\n10.#pragma link . 사용법 #pragma link “[path]modulename[.ext]” . 이 지시어는 실행화일에 파일을 링크시킬것을 링커에세 지시합니다. 기본적으로 링커는 -L옵션으로 지정된 패스와 로칼 디렉토리에서 modulename을 찾습니다. path 아규먼트를 이용하여 디렉토리를 지정할 수도 있습니다. 또한 링커는 확장자를 “.obj\"를 기본으로 간주합니다.\n//————————————————————————–\n11. #pragma message\n컴파일 도중에 지정된 내용을 VC의 아웃풋 윈도우에 출력시켜 준다. 컴파일시 특정 문장을 표시 . 사용법 #pragma message (“text” [“text”[“text” …]]) #pragma message text . #pragma message는 프로그램 코드 내에서 사용자 정의 메세지를 명시합니다. 첫번째 형식은 하나 이상의 스트링 상수들로 구성된 문장을 필요로 하고 메세지는 괄호안에 싸여있어야만 합니다.(이 형식은 MSC와 호환됩니다.) 두번째 형식은 경고 메세지의 문장을 위해 #pragma에 연속되는 문장을 사용합니다. #pragma의 두가지 형태와 함께 다른 메크로의 참조는 메세지가 디스플레이 되기전에 확장되어집니다. 사용자 정의 메세지가 디스플레이 되는것은 기본치이며 명령 라인 옵션의 Show Warnings를 사용하여 on/off 시킬 수 있습니다. 이 옵션은 콤파일러의 -wmsg에 해당합니다.\nex) // msacm.h #if defined(UNICODE) \u0026\u0026 !defined(_UNICODE) #ifndef RC_INVOKED #pragma message(“MSACM.H: defining _UNICODE because application defined UNICODE”) #endif #define _UNICODE #endif\n// ustring.h #pragma message osl/ustring.h has been replaced by winsys/string.h #include \u003cwinsys/string.h\u003e\n//————————————————————————–\n12.#pragma obsolete . 사용법 #pragma obsolete identifier . #pragma obsolete 프로그램 코드에서 pragma의 선언 이후에 마주치게 되는 identifier의 첫번째 사용에 대해서 경고를 발생합니다. 경고는 identifier를 쓸모없는 상태로 만듭니다. ex) // io.h #if !defined(RC_INVOKED)\n/* Obsolete functions */ #pragma obsolete _chmod #pragma obsolete _close #pragma obsolete _creat #pragma obsolete _open #pragma obsolete _read #pragma obsolete _write\n/* restore default packing */ #pragma pack(pop)\n#if defined(__STDC__) #pragma warn .nak #endif\n#endif /* !RC_INVOKED */\n//————————————————————————–\n**13.#pragma option ** . 사용법 #pragma option options #pragma option push options #pragma option pop . #pragma option은 프로그램 원시 코드 내에 명령라인 옵션을 포함시키고자 할 때 사용하며 push 또는 pop 옵션과 함께 사용되어질 수 있습니다. options는 임의의 명령라인 옵션(단, 아래에 수록된 것은 제외합니다.)이며 하나의 지시어 내에서 여러개의 option들을 나타낼 수 있습니다. 예를 들자면 다음과 같습니다.\n#pragma option -C #pragma option -C -A\ntoggle option(-a, -K같은)은 comman line에서 on/off될수 있습니다. 이들 toggle option들은 option 다음에 마침표를 두면 그 명령라인, 구성 파일, 옵션 메뉴 설정값에 대해 옵션을 리털할 수 있으며 이를 이용하면 정확한 설정값을 기억하지 않고도(혹은 알 필요가 없거나) 옵션을 임시로 변경했다가 다시 그것을 디폴트로 복귀시킬 수 있습니다.\npragma optino에 포함하여 나타날 수 없는 옵션들은 다음과 같습니다. -B -c -dname -Dname=string -efilename -E -Fx -h -lfilename -lexset -M -o -P -Q -S -T -Uname -V -X -Y 다음의 경우에 #pragmas, #indluces, #define과 약간의 #ifs를 사용할 수 있습니다. * #if, #ifdef, #ifndef 또는 #elif지시어 내에서 두 밑줄로 시작하는 매크로명 (그리고 그에 따른 내장 매크로도 가능합니다.)의 사용 전. * 첫번째 실재 token이 발생하기 전(첫번째 C 또는 C++ 선언문)\n특정 명령 라인 옵션은 이들 사건 앞의 #pragma option 내에서만 나타날 수 있는데 그러한 option들은 다음과 같습니다. -Efilename -f -i# -m* -npath -ofilename -u -W -z\n다른 option들은 어디서나 변경될 수 있는데 다음 option들은 함수 또는 대상 선언문 사이에서 변경될 경우 컴파일러에만 영향을 미칩니다. -1 -h -r -2 -k -rd -a -N -v -ff -O -y -G -p -Z\n다음의 option들은 언제든지 변경될 수 있으며 즉시 영향을 미칠 수 있습니다. -A -gn -zE -b -jn -zF -C -K -zH -d -wxxx 이들 option들은 그 명령 라인 상태로 재설정하기 위해 점(.)앞에 추가로 나타날 수 있습니다.\npush 또는 pop을 사용한 #pragma option 18:41, 21 February 2007 (PST)18:41, 21 February 2007 (PST)18:41, 21 February 2007 (PST)18:41, 21 February 2007 (PST)18:41, 21 February 2007 (PST)18:41, 21 February 2007 (PST)18:41, 21 February 2007 (PST)~~ 또한 콤파일러 지시어들을 쉽게 변경할 수 있도록 push 그리고 pop 아규먼트들 과 함께 #pragma option 지시어를 사용할 수도 있습니다.\n잠재적으로 많은 컴파일러 옵션과 경고들을 변경하는 파일들을 포함하기 위해 #pragma option push를 사용할 수 있고, #pragma option pop은 단일 문장으로서 이전의 상태를 되돌려준다. 예를 들자면 다음과 같다.\n#pragma option push #include \u003ctheworld.h\u003e #pragma option pop #include “mystuff.h”\n#pragma option push 지시어는 첫번째로 모든 콤파일러 옵션들과 경고 설정들을 스택에 push한 후에 다른 옵션들이 존재한다면 이를 처리한다. 다음의 예는 #pragma option push가 옵션들을 사용하거나 혹은 그렇지 않을수 있음을 보여줍니다.\n#pragma option push -C -A #pragma option push\n#pragma option pop directive은 스택으로부터 옵션들과 경고들의 마지막 설정 을 pop함으로서 컴파일러 옵션과 경고들을 변경합니다. 만일 스택이 비어있고 option pop과 일치하는 option push가 없으며 아무것도 발생하지 않은경우 경고가 주어집니다. 다음은 빈 스택에대해서 경고를 발생시킵니다.\n#pragma option push #pragma option pop #pragma option pop /* 경고가 발생합니다.\n권장하지는 않지만 지시어를 사용하여 이 경고를 off시킬 수 있습니다. #pragma warn -nop.\n만일 pop의 다음에 어떤 옵셥들을 명시할려고 한다면 에러가 발생하게되며 pragma option pop 다음에는 어떤것도 허락하지 않습니다. 예를 들면, 다음은 에러를 발생합니다.\n#pragma option pop -C /* ERROR 만일 push된 옵션들의 스택이 파일의 시작과 마지막이 동일하지 않다면 다음과 같은 경고메세지가 발생합니다.\nPrevious options and warnings not restored.\n이 경고메세지를 off시키기 위하여 지시어 #pragma nopushoptwarn를 사용할 수 있습니다.\n//————————————————————————–\n14. #pragma pack\n변수 정렬을 인위적으로 변경시킨다.(보통은 4바이트로 지정되어 있다.) . 사용법 #pragma pack(n)\n위에서, n의 값으로, 1,2,4,8등이 올수 있으며, 특히 네트웍통신쪽을 개발할때 구조체의 멤버들 align할때 사용하는 것으로서, 빈번하게 사용됩니다. 구조체 정렬부분은 중요하지만, 여기서는 그쪽까지 언급하기에는 양이 많아서 여기까지만 설명함. #pragma pack(push, n)\n#pragma pack(pop) . #pragma pack 지시어는 콤파일러 옵션 -a와 함께 #pragma option을 사용하는 것과 동일합니다. n은 콤파일러가 저장된 메모리에 데이터를 정렬하는 방법을 결정하는 byte의 정렬이다. 보다 자세한 사항은 -a 콤파일러 옵션에 관한 내용을 참고하십시요. #pragma pack은 또한 #pragma option지시어에 push나 pop을 사용하는것과 동일한 기능을 제공 하도록 push나 pop 아규먼트와 함께 사용할 수 있습니다. 아래의 내용은 #pragma pack과 #pragma option을 비교한 내용입니다. ━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━ #pragma pack ┃ #pragma option ━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━ #pragma pack(n) ┃ #pragma option -an #pragma pack(push, n) ┃ #pragma option push -an #pragma pack(pop) ┃ #pragma option pop ━━━━━━━━━━━━━┻━━━━━━━━━━━━━━━━━━━\n예) #pragma pack(push, before_pack, 1) 구조체 정렬을 1 바이트로 만든다. 1 바이트로 맞추기 전의 정렬 기준을 before_pack에 저장한다\n#pragma pack(pop, before_pack) 위와 같이 한쌍으로 사용된다. before_pack에 저장된 정렬 기준으로 복원한다.\n다음과 같이 사용할 수도 있다. #pragma pack(push, 1) #pragma pack(pop)\n다음과 같이 복원없이 지정할 수도 있다. #pragma pack(1)\n예) #pragma pack(pop) 이라…아마 이거랑 쌍이 되는게 있을텐데요 #pragma pack(push,1) 이라던지요. 이건 구조체를 1바이트로 바이트 정렬하는 겁니다. 디폴트로는 8바이트로 되어 있을겁니다. 뭐 구조체 크기가 실제로 계산한 것과 맞지 않는 경우가 있는데..이 바이트 정렬 떄문입니다. 따라서..반드시 맞아야 할 경우는… 위의 코드를 구조체 아래위로 써야 합니다. //————————————————————————–\n**15.#pragma package ** . 사용법 #pragma package(smart_init) #pragma package(smart_init, weak) . smart_init 아규먼트 #pragma package(smart_init)는 패키지된 유닛들이 의존할 순서를 결정하기위해 초기화 되어집니다.(패키지 소스파일 내에 기본적으로 포함됩니다.) 일반적으로, 패키지들을 생성하는 .CPP 파일들에 #pragma package를 사용할 수 있습니다. 이 프라크마는 유닛을 콤파일하는기위한 초기의 순서에 영향을 미칩니다. 초기화는 다음의 순서에 의하여 발생합니다. 1. 만일 unitA가 unitB에 의존한다면 unitB는 반드시 unitA전에 초기화 되어져야만하는 사용(“uses”)에 의존합니다. 2. 링크의 순서(The link order) 3. unit에서의 우선권의 순서.(Priority order within the unit.)\n보통의 .OBJ 파일들은(unit들로 생성하지 않은), 첫째로 우선권의 순서에 따라 초기화가 일어나고서 링크가 됩니다. .OBJ 파일들의 링크 순서의 변경은 글로발 오브젝트가 호출되어져 생성되는 순서에 의해 변경됩니다.\n다음의 예는 보통의 .OBJ 파일들과 unit들의 초기화에 어떤 차이점이 있는가를 보여줍니다. 세개의 unit 파일들 A,B,C가 #pragma package(smart_init)를 사용하여 “smart initialized\"되고 우선권은 10, 20, 30의 값을 갖는다고 예를 듭니다. 함수는 우선권의 값과 parent .OBJ에 의하여 이름지어져 a10, a20, a30, b10등과 같은 이름을 갖습니다. 세가지는 모두 unit들이며 A는 B와 C를 사용하며 A,B,C의 순서로 링크되고 초기화의 순서는 다음과 같습니다. B10 B20 B30 C10 C20 C30 A10 A20 A30 위와 같이 되었다면 .OBJ 파일들은 (unit들이 아니다)다음의 순서가 되어질 것입니다. A10 B10 C10 A20 B20 C20 A30 B30 C30 #pragma package(smart_init)를 사용한 .CPP 파일들은 또한 #pragma package (smart_init)를 정의한 .CPP 파일로부터 다른 .OBJ 파일들을 참조하는 #pragma link를 필요로 하며 unit에 의해 결정되어져야만 합니다. #pragma link는, 결정 되지 않은 .OBJ는 라이브러리 등에 의하여 여전히 결정되어질 수 있도록 참조 할 수 있습니다. . weak packages #pragma package(smart_init, weak)지시어는 .OBJ 파일이 패키지의 .BPI와 .BPL 파일들에 정장되는 방법에 영향을 미칩니다. 만일 #pragma package(smart_ init, weak)가 unit파일 내에 나타난다면 콤파일러는 가능하다면 BPL들로부터 unit을 생략하고, 다른 에플리케이션이나 패키지에 의해 필요로 할 때면 비 패키지화된(non-packaged) 로칼 복사본의 unit을 생성합니다. 유닛이 이 지시어와 함께 콤파일 되었다는 것은 약하게 패키지화 되었음을 이야기 합니다. (“weakly packaged”) #pragma package(smart_init, weak)는 동일한 외부 라이브러리(external librar y)들에 의존할수 있는 여러 패키지들 사이에서의 충돌을 제거하는데 사용되어 집니다. #pragma package(smart_init, weak) 지시어를 가지는 unit 파일들은 글로발 변수들을 갖지 않아야 합니다.\n//————————————————————————– 16.#pragma resource . 사용법 #pragma resource “*.dfm” . 이 프라그마는 form unit에 의해 선정되어지는 파일로서 일치되는 .DFM 파일과 헤더파일을 필요로 합니다. 이러한 모든 파일들은 IDE에 의해 관리되어집니다. 만일 폼을 위한 다른 변수들을 필요로한다면 pragma resource가 사용되어지고난 후에 즉시 선언되어져야만 합니다. 선언은 반드시 form이 되어져야만 합니다. TFormName *Formname;\n//————————————————————————– **17.#pragma startup ** . 사용법 #pragma startup function-name #pragma exit function-name . #pragma exit의 내용을 참조하십시요.\n//————————————————————————– 18.#pragma warn . 사용법 #pragma warn [+:-:.]www . warn지시어를 이용하면 특정 명령라인 옵션 -wxxx를 우선할 수 있습니다. #pragma warn -aus 스위치를 사용하면 함수 단위로 취급됩니다. 개별적인 변수들을 위해서 함수 내부에서 경고를 off시킬수는 없습니다. 함수 전체를 off시키거나 혹은 그렇지 않거나 둘중 하나입니다. ex) #pragma warn +xxx #pragma warn -yyy #pragma warn .zzz\n위의 예에서는 xxx경고문은 on되고 yyy경고문은 off되며 zzz경고문은 파일의 컴파일이 시작할 때 갖고 있던 값으로 재저장됩니다.\n//—– End of Document —————————————————- 19. #pragma once\n1. 한번 컴파일 되면 더 이상 컴파일 하지 않는다는 뜻입니다. 여러개의 cpp파일이 있을때, 하나의 cpp화일이 수정되면, 그 화일만 컴파일하고 나머지는 하지말아란 뜻이죠. ( 여러 번 인클루드 되는 것을 컴파일러 차원에서 막아줌 )\n2. #ifndef ~ #endif 와 같은 역할을 한다.\n3. 매크로들의 중복 정의를 막고, 전역변수에 static 키워드를 써줄 필요가 없어짐.\n4. VC++ 에서는 되고, 다른 컴파일러는 안될 수도 있음.\n5. 분할 컴파일시\n이것을 사용하면 빌드시 컴파일러에 의해 해당 파일을 단 한번만 열게 된다… 그러므로 컴파일 타임을 줄일 수 있고 모듈에서 가장 먼저 나온 #include문에서 해당 파일을 열게 되므로 재정의에 의한 오류를 방지할 수 있다…\n예제)\n// exam.h file\n#ifndef __EXAM__\n#define __EXAM__\n…\n#endif\n-\u003e\n// exam.h file\n#pragma once\n…\n//————————————————————————–\n20. #pragma data_seg\ndll에서 데이터 공유하고자 할 때 쓰임\n예) 실행파일에는 코드영역과 데이터영역이 구분되어 있다는 것은 아시지요. ┌───────┐ │ │ │ │ │ 데이터영역 │ │ │ │ │ ├───────┤ │ │ │ │ │ 코드 영역 │ │ │ │ │ └───────┘ 이런 식의 그림은 아마 어디선가 많이 보셨을겁니다.(그림이 깨지네요.편집할 땐 제대로 보였는데…) 이런 영역을 section이라고 하지요. 위의 설명에 나오는 section이라는 용어가 이것입니다. 실제로 데이터 영역과 코드 영역외에도 exe나 dll에는 여러 section을 포함할 수 있습니다. 이건 dumpbin이라는 툴로 살펴볼 수 있습니다. 제 컴(Windows XP)에서 dumpbin c:\\windows\\notepadd.exe 를 해 보았더니\n2000 .data 2000 .rsrc 7000 .text\n이렇게 나오는 군요.\n여기서 .data에는 초기화된 데이터가 .rsrc에는 리소스들이, .text에 코드가 들어갑니다. 이러한 .data, .rsrc, .text 등은 일반적으로 정해져 있는 것들입니다. 위 MSDN의 설명에 있는 section-name이라는 것이 바로 .data, .rsrc, .text 등을 뜻하는 겁니다. 즉, #pragma code_seg( .data ) 처럼 사용한다는 거지요. 그리고 Specifies a code section where functions are to be allocated.라는 설명은 Specifies a section where functions or data or etc. are to be allocated. 이렇게 이해하면 더 나을 듯 하네요.\n그런데 이런 정해진 이름말고도 사용자가 새로운 영역을 정할 수 있습니다.\n#pragma data_seg(“Shared”) DWORD g_dwThreadIdPMRestore = 0; HWND g_hwnd = NULL; #pragma data_seg()\n이런 식으로 하면 g_dwThreadIdPMRestored와 g_hwnd가 디폴트 데이터 섹션인 .data에 배치되지 않고, Shared라는 이름으로 만들어진 섹션에 배치되는 것입니다.\n//————————————————————————–\n21. #pragma warning\n컴파일시에 어떤 조건(#if, #ifndef)에의해 개발자에게 어떤것을 알려주고 싶을 경우 사용.\n예) #pragma warning(disable:xxxx) 지정된 xxxx번대의 경고 메세지를 디스플레이하는 것을 막는다. (xxxx는 번호)\nwarning( disable : 4705 )\n: 특정 warnning 을 체크하지 않음, 이럴 경우 4705번 warnning은 나타나지 않는다\n#pragma warning(default:xxxx) 지정된 xxxx번의 경고 메세지의 설정을 원래의 프로젝트 설정으로 복원한다\n//————————————————————————–\n22. #pragma code_seg\nMSDN에 있는 내용 #pragma code_seg( [“section-name”[,“section-class”] ] )\nSpecifies a code section where functions are to be allocated. The code_seg pragma specifies the default section for functions. You can, optionally, specify the class as well as the section name. Using #pragma code_seg without a section-name string resets allocation to whatever it was when compilation began.\n//————————————————————————–\n23. #pragma deprecated\nC#의 Obsolete attribute와 비슷한 의미입니다. 즉, 경고가 발생한 클래스 혹은 메서드 등이 이후에는 지원되지 않음을 나타내는 의미입니다. 그러므로 당장은 문제가 없습니다.\n컴파일러 specific 한..그런 옵션 지시자라고 보시면 됩니다.\n//————————————————————————–\n#pragma는 표준 C/C++ 문법인데 각 compiler 마다 다른 명령을 제공한다… 고로 Linux나 Unix의 cc에서는 작동하지 않을 수도 있다는 것! (Visual C++에선 언제나 call…)\npragma 는 #로 시작하는 전처리구문 지시자 중 컴파일러에 종속적인 명령으로, 컴파일러에 특정한 옵션 명령을 내리기 위해 사용한다. 이것은 컴파일러에 종속적이기 때문에 컴파일러를 변경했을 경우 실행을 보장하지 못한다.\npragma 의 의미를 action 으로 많이들 알고 계시는데, 인터넷에서 제가 알아본바로는, 사전적인 의미는 “만능” 입니다. 어원설명 원문은, 아래를 참고하세요.\nA pragma (from the Greek word meaning action) is used to direct the actions of the compiler in particular ways, but has no effect on the semantics of a program (in general).\nPragmas are used to control listing, to define an object configuration (for example, the size of memory), to control features of the code generated (for example, the degree of optimization or the level of diagnostics), and so on.\nSuch directives are not likely to be related to the rest of the language in an obvious way. Hence the form taken should not intrude upon the language, but it should be uniform.\nThus, the general form of pragmas is defined by the language. They start with the reserved word pragma followed by a pragma identifier, optionally followed by a list of arguments enclosed by parentheses, and terminated by a semicolon.\nThe overall syntax of the pragma identifier and arguments is similar to that of a procedure call. Pragmas are allowed at places where a declaration or a statement is allowed; also at places where other constructs that play the role of declarations (for example clauses) are allowed.\npragma 는 컴파일에게 그 뒤에오는 내용에 따라 어떤일을 하라는 전처리명령입니다.\nC++는 컴파일하고 나면 함수의 이름이 바뀌게 되는데 이것을 name mangling이라고 합니다.\n그래서 만일 dll로 작성한 함수를 불러 사용하게 되면 같은 이름을 찾을 수 없다는 오류가 나게 됩니다.\n만일 dll에서 printString라는 함수를 만들었다고 가정을 합니다. 그러면 컴파일하고 난 후의 함수의 이름은 printString@@YAXXZ와 같은 형태로 만들어 집니다. 그런데 이 함수를 불러 사용하는 곳은 printString이라는 것만 알지 위의 것과 같은 알지 못합니다. 그래서 #pragma라는 키워드를 사용해서 name mangling을 방지하게 되는 것입니다. 이 mangling된 이름을 찾기 위해서는 VC++ Tool에 보면 depends를 실행하고 만들dll을 drag\u0026drop하면 이것을 찾을 수 있습니다.\npragma comment(linker, “/export:printString=?printString@@YAXXZ”)와 같이사용하면됩니다. 즉 #pragma는 원래의 함수 이름을 c++의 암호명에 대한 별칭으로 추가하도록 지시하며 링커에게 /export옵션을 전달해 주는것입니다. 그리고 dll에서는 원래의 함수를 export(수출??말이 좀 이상하지만 대부분 이렇게 많이 쓰니까..^^)해야 하고 이 함수를 호출하는 쪽에서는 import(수입) 옵션을 써 주어야만 함수를 제대로 호출할 수 있습니다.\npragma 앞에 #이 있는 걸 보면 아시겠지만 pragma는 precompiler입니다.\ncompile할 때 platform이 틀려지거나 cpu가 틀려지거나 할 때 compile option을 주게 됩니다.\nvc++을 써보셨으면 아실텐데, project settings( ALT+F7 )에서 c/c++ tab에 보면 project options이 있습니다. link tab에도 project options가 있죠.\npragma가 바로 그런 역할을 하는 precompiler입니다.\nvc++이야 ide니까 project settings라는 편한 환경을 지원하지만 만약 code호환성을 생각한다면 pragma를 쓰는 게 좋죠.\n\u003c api나 mfc의 구분과 관계없이 해당 컴파일러에서 사용하는 명령 \u003e\n#pragma warn- // warning 디스어블\npragma warn+ // warning 인에이블\npragma opt- // 최적화 안 함\npragma opt+ // 최적화 함\npragma savereg- // 레지스터 저장 안 함\npragma savereg+ // 레지스터 저장 함\npragma library mylib.lib // 링크 라이브러리 지정\n※ MSDN / “Programming Applications for Microsoft Windows”(Jeffrey Richer 저) 참조"},"title":"pragma"},"/02.inbox/python-%EA%B8%B0%EB%B3%B8-%EA%B0%80%EC%83%81%ED%99%98%EA%B2%BD-venv/":{"data":{"":"python -m venv 가상환경이름 이제 가상 환경을 활성화합니다. 운영체제에 따라 활성화 방법이 다릅니다.","1-macos-경우#(1) MacOS 경우":"source 가상환경이름/bin/activate","2-windowos-경우#(2) WindowOS 경우":"source 가상환경이름/Scripts/activate 정상적으로 가상환경이 실행되었다면, 터미널에서 현재 디렉토리 맨 앞에 상환경 이름이 괄호 안에 출력됩니다.\n가상 환경을 비활성화하는 방법입니다.\ndeactivate 생성했던 가상 환경을 삭제하는 방법입니다.\nsudo rm -rf 가상환경이름"},"title":"python 기본 가상환경 venv"},"/02.inbox/python-%EB%9E%8C%EB%8B%A4lambda/":{"data":{"":"익명함수로도 불리운다\n인수는 무제한 가능 함수 이름(생략 가능) = lambda"},"title":"python 람다(lambda)"},"/02.inbox/python-%EB%A7%A4%EA%B0%9C%EB%B3%80%EC%88%98-%EC%A0%84%EB%8B%AC/":{"data":{"":"파이썬의 매개변수 전달 방식 : 혼합 방식\n파이썬은 모든 것이 객체이며 다음 2 종류가 있음 불변 객체 (immutable object) : int, float, complex, tuples, string, bytes 등 가변 객체 (mutable object) : list, dict, set, bytearray 등 불변 객체가 매개변수로 전달될 때는 call-by-value 로 전달 가변 객체가 매개변수로 전달될 때는 call-by-reference 로 전달 참조\nCall-by-value : 실 매개변수의 값이 전달되며, 함수 내에서 형식 매개변수의 값을 변경해도 실 매개변수의 값은 변하지 않음 Call-by-reference : 실 매개변수의 주소가 전달"},"title":"python 매개변수 전달"},"/02.inbox/python-%EC%97%B0%EC%82%B0%EC%9E%90-%EC%9A%B0%EC%84%A0%EC%88%9C%EC%9C%84/":{"data":{"":""},"title":"python 연산자 우선순위"},"/02.inbox/python-%EC%9D%B4%EB%A6%84%EA%B3%B5%EA%B0%84namespace/":{"data":{"":"이름공간과 스코프 두가지 개념을 인지 %20image%2020240428050441.png)\npython 에는 포인터 개념이 내부적으로 작동\ntext=\"PythonGeeks\" print(\"id of text is:\",id(text)) print(\"id of PythonGeeks is:\",id(\"PythonGeeks\")) id of text is: 140569298174960 id of PythonGeeks is: 140569298174960 c/cpp 과 완벽히 동일\nnamespace\n네임스페이스(Namespaces)는 이름을 객체에 매핑(mapping)하는 것으로, 파이썬에서는 변수가 실제 객체를 참조하는 이름의 집합을 의미한다\nscope\n변수(variable)나 함수(function)와 같은 식별자(identifier)들이 유효(valid)하고, 접근(access) 가능한 범위(range)를 말한다\nnamespace 의 종류\nbuilt in namespace : 인터프리터가 시작될 때 생성 global namespace : 모든 전역 객체 local namespace : 함수 내부 def func(): var1 = 3 print(\"지역공간 namespace : \" , locals()) var = 3 print(\"built in namespace : \" , dir()) print(\"전역공간 namespace : \" , globals()) func() built in namespace : built in namespace : ['ArithmeticError', 'AssertionError', 'AttributeError', 'BaseException', 'BaseExceptionGroup', 'BlockingIOError', 'BrokenPipeError', 'BufferError', 'BytesWarning', 'ChildProcessError', 'ConnectionAbortedError', 'ConnectionError', 'ConnectionRefusedError', 'ConnectionResetError', 'DeprecationWarning', 'EOFError', 'Ellipsis', 'EncodingWarning', 'EnvironmentError', 'Exception', 'ExceptionGroup', 'False', 'FileExistsError', 'FileNotFoundError', 'FloatingPointError', 'FutureWarning', 'GeneratorExit', 'IOError', 'ImportError', 'ImportWarning', 'IndentationError', 'IndexError', 'InterruptedError', 'IsADirectoryError', 'KeyError', 'KeyboardInterrupt', 'LookupError', 'MemoryError', 'ModuleNotFoundError', 'NameError', 'None', 'NotADirectoryError', 'NotImplemented', 'NotImplementedError', 'OSError', 'OverflowError', 'PendingDeprecationWarning', 'PermissionError', 'ProcessLookupError', 'RecursionError', 'ReferenceError', 'ResourceWarning', 'RuntimeError', 'RuntimeWarning', 'StopAsyncIteration', 'StopIteration', 'SyntaxError', 'SyntaxWarning', 'SystemError', 'SystemExit', 'TabError', 'TimeoutError', 'True', 'TypeError', 'UnboundLocalError', 'UnicodeDecodeError', 'UnicodeEncodeError', 'UnicodeError', 'UnicodeTranslateError', 'UnicodeWarning', 'UserWarning', 'ValueError', 'Warning', 'ZeroDivisionError', '__build_class__', '__debug__', '__doc__', '__import__', '__loader__', '__name__', '__package__', '__spec__', 'abs', 'aiter', 'all', 'anext', 'any', 'ascii', 'bin', 'bool', 'breakpoint', 'bytearray', 'bytes', 'callable', 'chr', 'classmethod', 'compile', 'complex', 'copyright', 'credits', 'delattr', 'dict', 'dir', 'divmod', 'enumerate', 'eval', 'exec', 'exit', 'filter', 'float', 'format', 'frozenset', 'getattr', 'globals', 'hasattr', 'hash', 'help', 'hex', 'id', 'input', 'int', 'isinstance', 'issubclass', 'iter', 'len', 'license', 'list', 'locals', 'map', 'max', 'memoryview', 'min', 'next', 'object', 'oct', 'open', 'ord', 'pow', 'print', 'property', 'quit', 'range', 'repr', 'reversed', 'round', 'set', 'setattr', 'slice', 'sorted', 'staticmethod', 'str', 'sum', 'super', 'tuple', 'type', 'vars', 'zip'] 전역공간 namespace : {'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': \u003c_frozen_importlib_external.SourceFileLoader object at 0x7f2a74ccb350\u003e, '__spec__': None, '__annotations__': {}, '__builtins__': \u003cmodule 'builtins' (built-in)\u003e, '__file__': '/home/shinnk/source_main/personal/python/class/namepace.py', '__cached__': None, 'func': \u003cfunction func at 0x7f2a74c704a0\u003e, 'var': 3} 지역공간 namespace : {'var1': 3} 함수 내부에서\na. Built-in scope: 모든 식별자들에 영향을 끼친다\nb. Global scope: 모든 식별자에 영향을 끼친다\nc. Local scope: 함수 내부의 식별자들에 영향을 끼친다\nd. Enclosed or nonlocal scope: 위치된 곳과 내부의 함수에 영향을 끼친다\nglobal 로 변수를 선언하면 변수를 조회할때 global namespace 부터 조회하게 된다 nonlocal 키워드를 사용하면 변수를 조회할때 한단계 위의 namespace 부터 조회하게 된다\na = 3 print(locals()) print(globals()) locals() # 위치한곳의 namespace 조회 globals() # global name space 조회 print(__builtins__.__dict__) # biltins name 조회 dir() # namespace 조회 아님 하지만 builtins 의 경우 이미 저장되어 있으므로 이렇게 조회함 객체.__dict__() # 객체의 namespace 조회 Title\n변수가 호출되면 어떠한 객체와 연결되어 있는지 확인하기 위해 가장 가까운 scope 부터 확인 만약 함수 내부의 변수라면 local -\u003e enclosed -\u003e global -\u003e built-in namespace 순으로 확인하며 먼저 발견되면 그것을 사용한다 global 은 현제 파일의 전역 이름과 모듈의 전역 이름이 있는데 현제 파일의 전역파일이 먼저 조회된다"},"title":"python 이름공간(namespace)"},"/02.inbox/python-%EC%9D%B8%EC%88%98-%EA%B7%9C%EC%B9%99/":{"data":{"":"def print( *values: object, sep: str | None = \" \", end: str | None = \"\\n\", file: SupportsWrite[str] | None = None, flush: Literal[False] = False ) -\u003e None 파이썬의 print 내장함수 구현체이다\n가변인자 를 사용함 정확하게는 위치 가변인자를 사용하였다 object 매개변수의 올 수 있는 타입을 지정하여 오류를 막는다 : str | None str 또는 None 가 올 수 있다는 이야기이다 = \" \" None 일때의 기본값을 지정해준다"},"title":"python 인수 규칙"},"/02.inbox/raid/":{"data":{"":"하드웨어 RAID\n소프트웨어 RAID\n여기서는 소프트웨어 RAID 를 이야기 한다 linear RAID : 디스크 여러개를 단순히 이어서 사용한다\nRAID 0 : 순서대로 저장하는 것이 아니라 동시에 사용 속도를 나누어 사용하므로 속도가 N 개 만큼 빠르다\nRAID 1 : 복사본 생성\nRAID 5 : 1개 오류 허용\nRAID 6 :\nmdadm은 Linux에서 md 장치(일명 RAID 배열)를 구축, 관리 및 모니터링하기 위해 사용됩니다.","개별-확인#개별 확인":"--detail [/dev/md{숫자}]","단일-장치-제거#단일 장치 제거":"[장치를 제거할 /dev/md{숫자}] --remove [제거할 장치명]","레이드-구성#레이드 구성":"--create [만들 /dev/md{숫자}] --level=[레이드버전] --raid-devices=[장치수] [레이드 만들 장치명1] [레이드 만들 장치명2]… or -C [만들 /dev/md{숫자}] -l [레이드 버전] -n [장치 수] [레이드 만들 장치명1] [레이드 만들 장치명2]…****","슈퍼블록-제거--메타데이터-제거-#슈퍼블록 제거 ( 메타데이터 제거 )":"zero-superblock [해제할 /dev/md{숫자}]\n추가\n–zero-superblock 사용이유\nRAID 0을 구성했었던, /dev/sdc1 이나 /dev/sdd1을 이용해 다른\nRAID를 구성하려고 하면\n“appears to be part of a raid array” 이렇게\n다른 레이드의 구성요소로 보인다고 하며 뭐라 뜨는데\n이건 파일시스템에서 배웠었던 메타데이터인\n“슈퍼블록”\n이 남아있어서 그럽니다.\n즉\n“mdadm –create\"로 디스크들을 한번이라도 레이드로 묶으면\n각 디스크에는\n이 디스크는 RAID 0의 장치중 하나이고, 512KB씩 데이터를 분산저장해라\n이런식의\n“사용설명서(슈퍼블록)”\n같은 것이 남있는것이죠\n그래서\n”–zero-superblock\"\n이란 명령어를 이용해\n완전하게 슈퍼블록까지 지워준 다음 새로운 RAID를 만들어줘야 합니다","전체-확인#전체 확인":"\"/proc/mdstat\" 파일 mdadm —detail —scan","정지--야-mdadm-너-devmd0-계산-그만해-#정지 ( \u0026ldquo;야 mdadm, 너 /dev/md0 계산 그만해\u0026rdquo; )":"stop [해제할 /dev/md{숫자}]","추가#추가":"[장치를 추가할 /dev/md{숫자}] --add [추가할 장치명]","파일-시스템#파일 시스템":"mkfs.ext4","파티션-생성#파티션 생성":"fdisk 명령 + 리눅스 raid raid outo { 16진수 : fd } 로"},"title":"RAID"},"/02.inbox/real-my-sql/00.%EC%B4%88%EA%B8%B0-%EC%84%A4%EC%A0%95/":{"data":{"":"","계정#계정":"SUSTEM_USER 권한을 부여하면 시스템계정 이외에는 일반계정 비밀번호 유효성검사 INSTALL COMPONENT 'file://component_validate_password'; UNINSTALL COMPONENT 'file://component_validate_password';\n권한\nGRANT (권한 목록) ON (객체) TO (유저); SHOW GRANTS FOR 'username'@'host'; REVOKE ALL PRIVILEGES ON *.* FROM 'username'@'host';\n객체는 데이터베이스, table 이 될수 있다 정적권한을 줄때는 객체를 명시하지 말아야 한다 정적권한 동적권한 기본적으로 role 은 활성화 되지 않음: activate_all_roles_on_login=ON mysql.default_roles, mysql.role_edges mysql.user 의 account_locked 속성이 Y 이면 role, N 이면 user","서버#서버":"$ apt install mysql-server, mysql-common update-alternatives: using /var/lib/mecab/dic/ipadic-utf8 to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode Setting up mysql-server-8.0 (8.0.40-0ubuntu0.22.04.1) ... update-alternatives: using /etc/mysql/mysql.cnf to provide /etc/mysql/my.cnf (my.cnf) in auto mode Renaming removed key_buffer and myisam-recover options (if present) mysqld will log errors to /var/log/mysql/error.log mysqld is running as pid 13348 Created symlink /etc/systemd/system/multi-user.target.wants/mysql.service → /lib/systemd/system/mysql.service. Setting up mysql-server (8.0.40-0ubuntu0.22.04.1) ... Processing triggers for man-db (2.10.2-1) ... Processing triggers for libc-bin (2.35-0ubuntu3.8) ... 동작 확인 : nc -zv localhost(host/ip) mysql(port/service name)\nmysql 서버 업그레이드\n인프레이스 업그레이드 : 물리적 파일을 그대로 두고 업그레이드 논리적 업그레이드 : 덤프(mysqldump) 시스템 변수 : show GLOBAL VARIABLES\n적용 범위에 따른 구분: 글로벌 변수(전체 적용, my.cnf를 사용해 영구적 변경가능)와 세션 변수(세션별로 적용) both(전체 기본값은 설 global : 영구 변경, 모든 세션에 동등하게 영향끼침 session : 각 세션별 변경가능 both : 영구 변경가능하면서 세션별로 따로 설정 가능 정적 변수 동적 변수 : 서버가 동작중인 상태에서 변경가능 여부 : 정적변수my.cnf 를 변경해야 정적으로 변경되고(즉 재시작) 동적변수 : set 명령으로 동적으로 변경할 수 있다 db 전용 서버 설정\n[mysqld] server—id=l user=mysql datadir=/data/mysql/ default_storage_engine=innodb defaul_tmp_storage_engine=innodb table_open_cache=30000 table_open_cache_instances=16 open-fi1es-limit=65535 default—time-zone='+09:00' socket=/tmp/mysq local_infi1e=0FF block_encryption_mode='aes-256-ecb' core_file innodb_buffer_pool_in_core_file=OFF max_allowed_packet=67108864 explicit_defaults_for_timestamp=ON sql-mode= \"STRICT_TRANS_TABLES,NO_ZERO_IN_DATE, NO_ZERO_DATE, ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE SUBSTITUTION\" character-set-server-utf8mb4 character-set-filesystem-utf8mb4 collation_server-utf8mb4_0900_ai_ci skip-character-set-client-handshake max_connections=8000 max_connect_errors=999999 activate_all_roles_on_login=1 skip-name-resolve ngram_token_size=2 max_heap_table_size=10M tmp_table_size=10M tmpdir=/data/mytmp/ secure-file-priv=/data/securefile/ default_password_lifetime=0 sysdate-is-now ### InnoDB innodb_sort_buffer_size=64M innodb_data_home_dir=/data/mysql/ innodb_data_file_path=ibdata1:100M:autoextend innodb_temp_data_file_path=ibtmp1:12M: autoextend innodb_log_group_home_dir=/log/innodb-log innodb_log_files_in_group=3 innodb_log_file_size=2048M innodb_file_per_table=ON innodb_undo_directory=/log/innodb-undo/ innodb_rollback_segments=64 innodb_undo_tablespaces=2 innodb_max_undo_log_size=536870912 innodb_undo_log_truncate ON innodb_status_output_locks=ON innodb_print_all_deadlocks-ON innodb_adaptive_hash_index=OFF innodb_buffer_pool_size=206 innodb_buffer_pool_instances=10 innodb_doublewrite=OFF innodb_checksun_algorithm=CRC32 innodb_flush_log_at_trx_commit=0 innodb_flush_method=0_DIRECT_NO_FSYNC innodb_io_capacity=1000 innodb_io_capacity_max=5000 innodb_ft_enable_stopword-OFF innodb_cmp_per_index_enabled=ON ### Performance schema performance_schema=ON performance-schema-instrument=\"stage/%=ON\" performance-schema-instrument='memory/%=ON' performance-schema-instrument='wait/%=ON' performance-schema-consumer-events_stages_current=ON performance-schema-consumer-events_stages_history=ON performance-schema-consumer-events_stages_history_long=ON performance-schema-consumer-events_statements_history-OFF performance-schema-consumer-events_statements_history_long=ON performance-schema-consumer-events_waits_current=ON performance-schema-consumer-events_waits_history=ON performance-schena-consumer-events_waits_history_long=ON performance_schema_events_stages_history_long_size=50000 performance_schema_events_stages_history_size=10 performance_schema_events_statements_history_long_size=50000 performance_schena_events_statements_history_size=10 performance_schema_events_waits_history_long_size=50000 performance_schema_events_waits_history_size=10 ### TDE (Encryption) early-plugin-load-keyring_file.so keyring_file_data = /data/tde/tde_master.key ### Password validate password_history=5 validate_password.length=8 validate_password.mixed_case_count=2 validate_password.number_count=2 validate_password. special_char_count=2 validate_password.dictionary_file-prohibitive_dictionary.data validate_password.policy=STRONG ### MySQL BinLog log-bin=/log/mysql-bin/mysql-bin sync_binlog=0 enforce_gtid_consistency=ON gtid-mode=ON binlog_checksum=CRC32 binlog_order_commits=ON binlog_format=ROW binlog_row_image=MINIMAL max_binlog_size=104857600 ### MySQL Replica Options slave_parallel_type=LOGICAL_CLOCK slave_parallel_workers=4 slave_preserve_commit_order=1 binlog_rows_query_log_events=ON log_slave_updates ### Relay Log relay-log-/log/relay-bin/relay-bin relay_log_info_repository=TABLE relay_log_recovery=ON relay_log_purge=ON ### MySQL ErrorLog log-error-/log/mysql-err.log log_error_verbosity=1 ### MySQL Slow Log slow-query-log=1 long_query_time=1 log_slow_extra=1 log_slow_admin_statements=1 log_slow_slave_statements=1 slow_query_log_file=/log/mysql-slow.log ### MySQL Log Expire binlog_expire_logs_seconds=259200 log-raw log_timestamps=SYSTEM [client] socket /tmp/mysql.sock"},"title":"00.초기 설정"},"/02.inbox/real-my-sql/04.%EC%95%84%ED%82%A4%ED%85%8D%EC%B3%90/":{"data":{"":"mysql 엔진 : 커넥션핸들러, sql 파서, 전처리기, 옵티마이저 스토리지 엔진 : 데이터를 스토리지에 W 또는 R =\u003e 키캐시(MyISAM) 또는 버퍼풀기능\nmysql 엔진 -\u003e 스토리지 엔진으로 요청시 헨들러 api 사용\nSHOW GLOBAL STATUS LIKE 'handler%'; 실행중인 스레드 목록\nSELECT thread_id, name, type, processlist_user, processlist_host FROM performance_schema.threads ORDER BY thread_id; 플러그인 시스템 컴포넌트 시스템 차이 플러그인 : show plugins; 컴포넌트 : select * from mysql.component;","innodb#innodb":"데드락 감지 스레드(innodb_deadlock_detect) 을 OFF 하고 deadlock 발생을 시간(특정 데이터의 xlock 요청에 의한 잠김시간)으로 감지해서 요청 실패로 처리가능 innodb_lock_wait_timeout","innodb-buffer-pool#innodb buffer pool":"nodb_buffer_pool_size = innodb_buffer_pool_chunk_size * innodb_buffer_pool_instances 청크는 128MB 단위 pool size 기본값 128M 즉 인스턴스 1 show variables like '%innodb_buffer%';\nLRU(LRU+MRU) 플러쉬(flush) 프리(free) SHOW engine innodb status innodb_page_cleaners : 이 변수는 더티 페이지를 디스크에 동기화하는 클리너 스레드의 수를 설정합니다 이 변수의 값은 버퍼 풀 인스턴스 수보다 작아야 한다 innodb_max_dirty_pages_pct_lwm : 이 변수는 더티 페이지의 비율이 이 값 이하로 떨어질 때까지 클리너 스레드가 더티 페이지를 디스크에 기록. LWM(Low Water Mark)은 페이지가 낮은 임계값에 도달했을 때 동작을 시작하는 기준. innodb_max_dirty_pages_pct : 이 변수는 버퍼 풀 내에서 더티 페이지가 차지할 수 있는 최대 비율을 설정. 이 비율을 초과하면 InnoDB는 더티 페이지를 디스크에 플러시하여 비율을 줄이려 한다. 기본값은 75% innodb_io_capacity : 이 변수는 InnoDB가 I/O 작업을 수행할 수 있는 최대 용량을 설정한다. 디스크의 I/O 성능에 따라 이 값을 조정하여 성능을 최적화할 수 있다. 기본값은 200. \u003c= 실제 디스크 성능보다는 db 서버가 사용할 수 있는 속도 innodb_io_capacity_max : 이 변수는 InnoDB가 I/O 작업을 수행할 수 있는 최대 I/O 용량을 설정. innodb_io_capacity보다 큰 값을 설정할 수 있으며, 주로 고속 SSD와 같은 스토리지 장치를 사용할 때 유용. innodb_adaptive_flushing : 이 변수는 InnoDB가 플러시 작업을 적응적으로 조절할 수 있도록 설정합니다. 이 기능을 활성화하면 시스템의 현재 부하에 따라 플러시 빈도를 조절하여 성능을 최적화할 수 있습니다. innodb_adaptive_flushing_lwm : 이 변수는 적응형 플러싱이 활성화된 경우, 더티 페이지 비율이 이 값 이하로 떨어질 때까지 플러시 작업을 수행하도록 설정합니다. LWM이 낮을수록 더티 페이지를 더 자주 플러시하게 됩니다. innodb_flush_neighbors : 이 변수는 InnoDB가 페이지를 디스크에 플러시할 때, 해당 페이지의 이웃 페이지도 함께 플러시할지 여부를 결정. 값이 1이면 이웃 페이지를 플러시하고, 0이면 플러시하지 않는다. SSD와 같은 스토리지에서는 0으로 설정(활성화 하지 않음 랜덤 읽기 성능이 뛰어나므로)하는 것이 성능에 유리할 수 있음 각 테이블의 인덱스별 데이터 페이지가 얼만큼 Innodb buffer pool 에 적제되어 있는가\nSELECT it.name table_name, ii.name index_name, ici.n_cached_pages n_cached_pages FROM information_schema. innodb_tables it INNER JOIN information_schema. innodb_indexes ii ON ii. table_id = it.table_id INNER JOIN information_schema.innodb_cached_indexes ici ON ici.index_id = ii.index_id WHERE it.name=CONCAT('employees', '/', 'employees'); 테이블 전체 페이지 중에서 어느정도의 비율이 Innodb 버퍼풀에 적재되어 있는가\nSELECT (SELECT SUM(ici.n_cached_pages) n_cached_pages FROM information_schema.innodb_tables it INNER JOIN information_schema.innodb_indexes ii ON ii. table_id = it. table_id INNER JOIN information_schema.innodb_cached_indexes ici ON ici.index_id = ii.index_id WHERE it.name=CONCAT(t.table_schema, '/', t.table_name)) as total_cached_pages, ((t.data_length + t.index_length - t.data_free)/@@innodb_page_size) as total_pages FROM information_schema.tables t WHERE t.table_schema='employees' AND t.table_name='employees'; 리두로그에는 변경된 단일 데이터? double write buffer 에는 변경된 전체 페이지\n언두 레코드 건수\nSELECT count FROM information_schema.innodb_metrics WHERE SUBSYSTEM='transaction' AND NAME='trx_rseg_history_len';"},"title":"04.아키텍쳐"},"/02.inbox/register-x64/":{"data":{"":"%20image%2020240417101228.png)","vscode-c-디버깅-시에-나오는-레지스터-종류#vscode c 디버깅 시에 나오는 레지스터 종류":"other register : x0 - x28 fp w0 - w28 v0 - v31 fpsr fpsr far esr exception cpu lr sp pc cpsr IEEE single s0 - s31 IEEE double d0 - d31"},"title":"register x64"},"/02.inbox/spring-controller-%EC%B6%94%EC%83%81%ED%99%94-%EB%8B%A8%EA%B3%84%EB%B3%84-%EC%96%B4%EB%85%B8%ED%85%8C%EC%9D%B4%EC%85%98-%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0/":{"data":{"":"","level-1-servlet-api-직접-사용-lowest-abstraction#Level 1: Servlet API 직접 사용 (Lowest Abstraction)":"이 단계에서는 Spring의 도움을 최소한으로 받고, Java Servlet의 핵심 객체를 직접 다룹니다.\n파라미터 문법 예시 설명 HttpServletRequest public void method(HttpServletRequest request) HTTP 요청 정보를 모두 담고 있는 객체입니다. 헤더, 파라미터, 쿠키, 세션, Body 등 모든 요청 데이터에 직접 접근할 수 있습니다. (request.getParameter(\"name\")처럼 사용) HttpServletResponse public void method(HttpServletResponse response) HTTP 응답을 제어하는 객체입니다. 응답 상태 코드(Status Code), 헤더, 쿠키를 설정하거나 응답 Body에 직접 데이터를 쓸 수 있습니다. (response.getWriter().write(\"hello\")처럼 사용) HttpSession public void method(HttpSession session) 세션 객체를 직접 다룰 때 사용합니다. 세션에 데이터를 저장(session.setAttribute(...))하거나 조회(session.getAttribute(...))할 수 있습니다.","level-1-servlet-api-직접-사용-가장-낮은-추상화-단계#Level 1: Servlet API 직접 사용 (가장 낮은 추상화 단계)":"이 단계는 Spring의 도움을 최소한으로 받고, Java Servlet의 핵심 객체를 직접 다루는 방식입니다. HTTP 요청/응답의 모든 요소를 바닥부터 제어해야 할 때, 또는 기존 Servlet 기반 코드를 Spring으로 마이그레이션할 때 유용합니다.\nHttpServletRequest (예시: public void method(HttpServletRequest request)) HTTP 요청 정보를 모두 담고 있는 객체입니다. 헤더, 파라미터, 쿠키, 세션, Body, 요청 URI, 원격지 IP 등 모든 요청 데이터에 직접 접근할 수 있습니다.\n기본 사용: String name = request.getParameter(\"name\"); String userAgent = request.getHeader(\"User-Agent\"); 추가 예시: 동일 이름의 여러 파라미터 받기: String[] interests = request.getParameterValues(\"interest\"); (예: ?interest=coding\u0026interest=music 요청 시) 모든 헤더 이름 조회: Enumeration headerNames = request.getHeaderNames(); 요청 Body 직접 읽기 (JSON): String jsonBody = request.getReader().lines().collect(Collectors.joining(System.lineSeparator())); HttpServletResponse (예시: public void method(HttpServletResponse response)) HTTP 응답을 제어하는 객체입니다. 응답 상태 코드(Status Code), 헤더, 쿠키를 설정하거나 응답 Body에 직접 데이터를 쓸 수 있습니다.\n기본 사용: response.setStatus(HttpServletResponse.SC_CREATED); (201 상태 코드 설정) response.getWriter().write(\"hello world\"); 추가 예시: 커스텀 헤더 추가: response.setHeader(\"X-Custom-Auth\", \"some-token\"); 파일 다운로드를 위한 헤더 설정: response.setContentType(\"application/octet-stream\"); response.setHeader(\"Content-Disposition\", \"attachment; filename=\\\"data.csv\\\"\"); 에러 응답 보내기: response.sendError(400, \"Invalid parameter\"); HttpSession (예시: public void method(HttpSession session)) 세션 객체를 직접 다룰 때 사용합니다. 세션에 데이터를 저장(setAttribute), 조회(getAttribute), 무효화(invalidate)할 수 있습니다.\n기본 사용: session.setAttribute(\"cart\", new Cart()); Cart cart = (Cart) session.getAttribute(\"cart\"); session.invalidate(); 추가 예시: 세션 타임아웃 설정: session.setMaxInactiveInterval(1800); (30분) 세션 생성 시간 확인: long creationTime = session.getCreationTime(); java.security.Principal (예시: public String getUsername(Principal principal)) 현재 인증된 사용자 정보를 담고 있는 객체입니다. Spring Security와 함께 사용할 경우, principal.getName()을 통해 로그인한 사용자의 ID를 얻을 수 있습니다.\n참고: 최신 Spring Security에서는 @AuthenticationPrincipal 어노테이션을 사용하여 더 타입-세이프하게 사용자 객체를 주입받는 것을 권장합니다. java.util.Locale (예시: public void method(Locale locale)) 요청의 지역 정보를 담고 있는 객체입니다. 클라이언트의 Accept-Language 헤더를 기반으로 결정되며, 다국어 처리 시 현재 언어에 맞는 메시지를 보여주는 데 사용됩니다.\n예시: locale.getLanguage()는 “ko”, locale.getCountry()는 “KR”, locale.toString()는 “ko_KR” 등을 반환할 수 있습니다. InputStream / Reader (예시: public void method(InputStream input, Reader reader)) 요청 Body의 내용을 직접 스트림으로 읽을 때 사용합니다. 대용량 파일을 처리하거나, Spring의 메시지 컨버터를 거치지 않은 원본 데이터를 읽고 싶을 때 유용합니다.\n예시 (파일 업로드 처리): Files.copy(input, new File(\"uploaded-file.dat\").toPath()); OutputStream / Writer (예시: public void method(OutputStream output, Writer writer)) 응답 Body에 직접 스트림으로 데이터를 쓸 때 사용합니다. 대용량 파일을 다운로드시키거나, 특정 형식의 응답을 수동으로 구성할 때 사용됩니다.\n예시 (대용량 CSV 생성): try (PrintWriter printWriter = new PrintWriter(writer)) { printWriter.println(\"id,name\"); printWriter.println(\"1,John\"); }","level-2-기본-매핑과-요청-데이터-추출#Level 2: 기본 매핑과 요청 데이터 추출":"URL과 메서드를 연결하고, URL의 특정 부분을 파라미터로 쉽게 가져옵니다.\n어노테이션/파라미터 문법 예시 설명 @Controller @Controller public class MyController { ... } 클래스 레벨에 붙이며, 해당 클래스가 Spring MVC의 컨트롤러임을 나타냅니다. Spring이 이 클래스를 스캔하여 웹 요청을 처리하는 핸들러로 사용합니다. @RequestMapping @RequestMapping(\"/hello\") or @RequestMapping(value=\"/hello\", method=RequestMethod.GET) 특정 URL 경로와 HTTP 메서드를 처리할 메서드에 연결(매핑)합니다. 클래스와 메서드 레벨 모두에 사용할 수 있습니다. HTTP 메서드를 명시하지 않으면 모든 메서드(GET, POST 등)를 허용합니다. @RequestParam public void method(@RequestParam(\"name\") String name) URL의 쿼리 파라미터(?name=John)나 form-data 값을 메서드 파라미터에 바인딩합니다. required (기본값 true), defaultValue 속성을 통해 필수 여부나 기본값을 지정할 수 있습니다. @PathVariable @RequestMapping(\"/users/{userId}\") public void method(@PathVariable(\"userId\") Long id) URL 경로의 일부를 변수로 사용할 때 씁니다. (/users/123 에서 123을 id 변수에 바인딩). RESTful API에서 리소스를 식별할 때 주로 사용됩니다.","level-2-기본-매핑과-요청-데이터-추출-1#Level 2: 기본 매핑과 요청 데이터 추출":"이 단계에서는 URL과 메서드를 연결하고, URL이나 헤더 등에서 원하는 값을 편리하게 추출할 수 있습니다.\n@Controller (예시: @Controller public class MyController { ... }) 클래스 레벨에 붙이며, 해당 클래스가 Spring MVC의 컨트롤러임을 나타냅니다. Spring이 이 클래스를 스캔하여 웹 요청을 처리하는 핸들러로 사용합니다.\n@RequestMapping (예시: @RequestMapping(value=\"/users\", method=RequestMethod.POST, consumes=\"application/json\", produces=\"application/json\")) 특정 URL 경로와 HTTP 메서드를 처리할 메서드에 연결(매핑)합니다.\n속성 상세:\nparams: 특정 파라미터가 있을 때만 매핑 (예: params=\"mode=edit\"). headers: 특정 헤더가 있을 때만 매핑 (예: headers=\"X-API-VERSION=2\"). consumes: 요청의 Content-Type을 제한. (예: application/json) produces: 응답의 Content-Type을 지정. (예: application/xml) 추가 예시 (클래스/메서드 조합):\n@RequestMapping(\"/users\") public class UserController { @RequestMapping(\"/{id}\") public void getUser() { /* -\u003e /users/{id} */ } } @RequestParam (예시: public void search(@RequestParam(value=\"q\", required=false, defaultValue=\"spring\") String query)) URL의 쿼리 파라미터(?q=...)나 x-www-form-urlencoded 형식의 form-data 값을 메서드 파라미터에 바인딩합니다.\n추가 예시: 모든 파라미터 받기: public void allParams(@RequestParam Map paramMap) 여러 값 받기: public void listParams(@RequestParam List interest) (예: ?interest=a\u0026interest=b) Java 8 Optional 사용: public void optionalParam(@RequestParam Optional query) @PathVariable (예시: @RequestMapping(\"/users/{userId}/orders/{orderId}\") public void method(@PathVariable Long userId, @PathVariable Long orderId)) URL 경로의 일부를 변수로 사용할 때 씁니다. (예: /users/123/orders/456 에서 123과 456을 각각 userId, orderId 변수에 바인딩).\n추가 예시: 변수명 다를 때: @PathVariable(\"userId\") Long id 정규식으로 제한: @GetMapping(\"/members/{memberId:[0-9]+}\") public void getMember(@PathVariable Long memberId) Map으로 받기: @GetMapping(\"/{var1}/{var2}\") public void pathVars(@PathVariable Map pathVarMap) @RequestHeader (예시: public void method(@RequestHeader(\"User-Agent\") String userAgent, @RequestHeader(name=\"Accept-Language\", required=false) String lang)) 요청 헤더의 특정 값을 파라미터로 받아옵니다.\n추가 예시: 모든 헤더 받기 (Map): @RequestHeader Map headerMap 모든 헤더 받기 (객체): @RequestHeader MultiValueMap multiValueMap, @RequestHeader HttpHeaders headers @CookieValue (예시: public void method(@CookieValue(value=\"JSESSIONID\", required=false) String sessionId)) 요청에 포함된 쿠키의 값을 파라미터로 받아옵니다.\n추가 예시: 쿠키가 없을 때 예외: required=true (기본값)이고 쿠키가 없으면 MissingRequestCookieException 발생. 기본값 설정: @CookieValue(defaultValue = \"guest\") String visitorId","level-3-데이터-바인딩-및-응답-데이터-처리#Level 3: 데이터 바인딩 및 응답 데이터 처리":"요청 데이터를 객체에 자동으로 담거나, View에 전달할 데이터를 편리하게 관리합니다.\n어노테이션/파라미터 문법 예시 설명 @ModelAttribute public String method(@ModelAttribute UserDto userDto) 여러 요청 파라미터를 객체(DTO, VO)의 필드에 자동으로 바인딩합니다. 예를 들어 ?name=John\u0026age=30 요청이 오면, name과 age 필드를 가진 UserDto 객체를 생성하고 값을 채워줍니다. 또한, 이 어노테이션이 붙은 객체는 자동으로 Model에 추가되어 View에서 사용할 수 있습니다. Model / Map public String method(Model model) View에 전달할 데이터를 담는 컨테이너 역할을 합니다. 메서드 파라미터로 선언하면 Spring이 자동으로 객체를 주입해줍니다. model.addAttribute(\"key\", value) 형태로 데이터를 추가하면 View(JSP, Thymeleaf 등)에서 해당 데이터를 사용할 수 있습니다. Map도 동일하게 동작합니다. ModelAndView public ModelAndView method() { return new ModelAndView(\"viewName\"); } Model과 View를 하나로 합친 객체입니다. 처리 결과를 보여줄 View의 이름과 View에 전달할 데이터를 함께 담아 반환할 수 있습니다. 최근에는 Model 파라미터와 String (View 이름) 반환을 더 선호하는 추세입니다.","level-3-데이터-바인딩-및-응답세션-처리#Level 3: 데이터 바인딩 및 응답/세션 처리":"이 단계에서는 요청 데이터를 객체에 자동으로 담거나, View에 전달할 데이터 및 세션을 편리하게 관리할 수 있습니다.\n@ModelAttribute (예시 1: public String saveUser(@ModelAttribute UserDto userDto), 예시 2: @ModelAttribute(\"categories\") public List getCategories() { ... })\n1. (파라미터에서 사용 시) 여러 요청 파라미터를 객체(DTO, VO)의 필드에 자동으로 바인딩합니다. (예: ?name=John\u0026age=30 -\u003e UserDto 객체). 생략 가능합니다.\n2. (메서드에 사용 시) 특정 메서드 위에 붙이면, 해당 컨트롤러의 모든 요청 처리 전에 이 메서드가 먼저 실행되고 반환값이 Model에 자동으로 추가됩니다.\n추가 예시 (수정 폼):\n@ModelAttribute(\"user\") public User findUser(@PathVariable Long id) { return userRepository.findById(id); } public String updateUser(@ModelAttribute(\"user\") User user) { /* ... */ } (위 예시는 findUser로 DB에서 user를 조회해 모델에 넣고, 요청 파라미터로 그 user 객체를 덮어씁니다.)\nModel / ModelMap / Map (예시: public String method(Model model)) View에 전달할 데이터를 담는 컨테이너 역할을 합니다. model.addAttribute(\"key\", value) 형태로 데이터를 추가하면 View(JSP, Thymeleaf 등)에서 해당 키로 데이터를 사용할 수 있습니다. Model, ModelMap, Map은 사실상 동일하게 동작합니다.\nModelAndView (예시: public ModelAndView method() { ModelAndView mav = new ModelAndView(\"user/profile\"); mav.addObject(\"user\", user); return mav; }) Model과 View를 하나로 합친 객체입니다. 처리 결과를 보여줄 View의 이름과 View에 전달할 데이터를 함께 담아 반환할 수 있습니다.\n추가 예시 (상태 코드 설정): mav.setStatus(HttpStatus.CREATED); @SessionAttributes (예시: @Controller @SessionAttributes(\"user\")) 컨트롤러 클래스 레벨에 사용하여, Model에 추가된 특정 이름의 속성을 HTTP 세션에도 저장하도록 지정합니다. 여러 페이지에 걸쳐 특정 객체(ex: 장바구니, 폼 데이터)를 유지해야 할 때 편리합니다.\nSessionStatus와 함께 사용: public String complete(SessionStatus status) { status.setComplete(); return \"redirect:/\"; } (세션 데이터 정리) @SessionAttribute (예시: public void method(@SessionAttribute(name=\"user\", required=false) User loggedInUser)) HTTP 세션에 저장된 특정 속성을 직접 파라미터로 받아올 때 사용합니다. @SessionAttributes와 달리, 세션에 있는 값을 직접 조회하는 용도입니다. 다른 곳(e.g., 필터)에서 세션에 넣은 값을 꺼낼 때 유용합니다.\nRedirectAttributes (예시: public String save(RedirectAttributes redirectAttributes) { redirectAttributes.addFlashAttribute(\"message\", \"저장되었습니다!\"); return \"redirect:/users\"; }) 리다이렉트 시 데이터를 전달하는 데 특화된 객체입니다.\naddFlashAttribute: 1회성 데이터로, 리다이렉트된 페이지에서만 사용되고 세션에서 즉시 사라집니다. (Post-Redirect-Get 패턴에 유용). URL에 노출되지 않습니다. addAttribute: URL 쿼리 파라미터로 추가됩니다. (예: return \"redirect:/users/{id}\" 와 함께 사용 시 {id}에 바인딩, 나머지는 쿼리 파라미터)","level-4-rest-api를-위한-추상화#Level 4: REST API를 위한 추상화":"JSON/XML과 같은 메시지 기반 통신을 위한 핵심적인 추상화입니다.\n어노테이션/파라미터 문법 예시 설명 @RequestBody public void method(@RequestBody UserDto userDto) 요청의 Body에 담겨 오는 데이터(주로 JSON, XML)를 Java 객체로 변환(역직렬화, Deserialization)해줍니다. 내부적으로 HttpMessageConverter(주로 Jackson)가 동작하여 이 변환 과정을 자동으로 처리합니다. 클라이언트가 JSON 데이터를 보내면, 해당 JSON 구조와 일치하는 DTO 객체에 값을 채워줍니다. @ResponseBody @ResponseBody public UserDto method() { ... } 메서드가 반환하는 Java 객체를 HTTP 응답 Body에 직접 써넣도록 지시합니다. View를 찾는 것이 아니라, 반환된 객체를 JSON이나 XML 등의 데이터 형식으로 변환(직렬화, Serialization)하여 클라이언트에 전송합니다. REST API의 응답을 만들 때 필수적입니다. ResponseEntity public ResponseEntity method() { ... } @ResponseBody의 확장판으로, 응답 데이터(Body)뿐만 아니라 HTTP 상태 코드(Status Code)와 헤더(Header)까지 세밀하게 제어하여 반환하고 싶을 때 사용합니다. ResponseEntity.ok(body), ResponseEntity.created(uri).build() 와 같이 유연한 응답 구성이 가능합니다.","level-4-rest-api를-위한-추상화-1#Level 4: REST API를 위한 추상화":"이 단계는 전통적인 HTML View 반환이 아닌, JSON/XML과 같은 데이터 자체를 응답하는 RESTful API 개발에 특화된 고수준 추상화입니다.\n@RequestBody (예시: public UserDto createUser(@RequestBody CreateUserRequest request)) 요청의 Body에 담겨 오는 데이터(주로 JSON, XML)를 Java 객체로 변환(역직렬화)합니다. 내부적으로 HttpMessageConverter(주로 Jackson 라이브러리)가 동작합니다.\n추가 예시: 유효성 검사: public void create(@Valid @RequestBody UserDto userDto, BindingResult bindingResult) Raw 데이터 받기: public void rawJson(@RequestBody String jsonString) Map으로 받기: public void mapBody(@RequestBody Map dataMap) @ResponseBody (예시: @ResponseBody @GetMapping(\"/api/users/1\") public UserDto getUser() { ... }) 메서드가 반환하는 Java 객체를 HTTP 응답 Body에 직접 써넣도록 지시합니다. View를 찾는 것이 아니라, 반환된 객체를 JSON이나 XML 등의 데이터 형식으로 변환(직렬화)하여 클라이언트에 전송합니다.\nHttpEntity (예시: public String process(HttpEntity httpEntity) { String body = httpEntity.getBody(); HttpHeaders headers = httpEntity.getHeaders(); ... }) 요청의 헤더와 바디를 함께 감싼 객체입니다. @RequestBody와 @RequestHeader를 합친 것과 유사하며, 요청의 모든 요소를 한 번에 받아 분석할 때 유용합니다. 응답 시에도 사용 가능합니다.\nResponseEntity (예시: public ResponseEntity getUser(@PathVariable Long id) { UserDto user = userService.findById(id); HttpHeaders headers = new HttpHeaders(); headers.add(\"X-Custom-Header\", \"value\"); return new ResponseEntity\u003c\u003e(user, headers, HttpStatus.OK); }) @ResponseBody의 확장판으로, 응답 데이터(Body)뿐만 아니라 **HTTP 상태 코드(Status Code)**와 **헤더(Header)**까지 세밀하게 제어하여 반환하고 싶을 때 사용합니다.\n추가 예시 (빌더 패턴): 성공: return ResponseEntity.ok(user); 생성됨: URI location = ...; return ResponseEntity.created(location).build(); 콘텐츠 없음: return ResponseEntity.noContent().build(); 요청 오류: return ResponseEntity.badRequest().body(\"Error message\"); @ResponseStatus (예시: @ResponseStatus(HttpStatus.CREATED) @PostMapping(\"/users\") public void createUser(...)) 성공적인 응답의 HTTP 상태 코드를 지정하는 어노테이션입니다. void를 반환하거나 데이터만 반환하면서도 상태 코드를 200 OK가 아닌 201 Created, 204 No Content 등으로 설정하고 싶을 때 간편하게 사용합니다.\n추가 예시 (예외 클래스에 적용):\n@ResponseStatus(value = HttpStatus.NOT_FOUND, reason = \"User not found\") public class UserNotFoundException extends RuntimeException {}","level-5-편의성을-위한-조합-및-축약-highest-abstraction#Level 5: 편의성을 위한 조합 및 축약 (Highest Abstraction)":"자주 사용되는 패턴을 하나의 어노테이션으로 묶어 코드의 가독성과 생산성을 높입니다.\n어노테이션/파라미터 문법 예시 설명 @RestController @RestController public class MyApiController { ... } @Controller + @ResponseBody 의 조합입니다. 이 어노테이션을 클래스에 붙이면, 해당 컨트롤러의 모든 메서드에는 기본적으로 @ResponseBody가 적용됩니다. 따라서 모든 메서드가 View를 반환하는 대신 데이터(JSON 등)를 반환하게 되므로, REST API를 만들 때 매우 편리합니다. @GetMapping @GetMapping(\"/users/{id}\") @RequestMapping(method = RequestMethod.GET) 의 축약형입니다. HTTP GET 요청을 처리하는 핸들러를 간결하게 매핑할 수 있습니다. @PostMapping @PostMapping(\"/users\") @RequestMapping(method = RequestMethod.POST) 의 축약형입니다. HTTP POST 요청을 처리합니다. @PutMapping @PutMapping(\"/users/{id}\") @RequestMapping(method = RequestMethod.PUT) 의 축약형입니다. HTTP PUT 요청을 처리합니다. @DeleteMapping @DeleteMapping(\"/users/{id}\") @RequestMapping(method = RequestMethod.DELETE) 의 축약형입니다. HTTP DELETE 요청을 처리합니다. @PatchMapping @PatchMapping(\"/users/{id}\") @RequestMapping(method = RequestMethod.PATCH) 의 축약형입니다. HTTP PATCH 요청을 처리합니다.","level-5-편의성을-위한-조합-및-축약-가장-높은-추상화-단계#Level 5: 편의성을 위한 조합 및 축약 (가장 높은 추상화 단계)":"이 단계에서는 자주 사용되는 패턴을 하나의 어노테이션으로 묶어 코드의 가독성과 생산성을 높입니다. ‘문법적 설탕(Syntactic Sugar)‘의 대표적인 예시들입니다.\n@RestController (예시: @RestController @RequestMapping(\"/api/users\") public class UserApiController { ... }) @Controller + @ResponseBody 의 조합입니다. 이 어노테이션을 클래스에 붙이면, 해당 컨트롤러의 모든 메서드에는 기본적으로 @ResponseBody가 적용됩니다. 따라서 모든 메서드가 View를 반환하는 대신 데이터(JSON 등)를 반환하게 되므로, REST API를 만들 때 매우 편리합니다.\n@GetMapping (예시: @GetMapping(\"/{id}\")) @RequestMapping(method = RequestMethod.GET) 의 축약형입니다.\n@PostMapping (예시: @PostMapping) @RequestMapping(method = RequestMethod.POST) 의 축약형입니다.\n@PutMapping (예시: @PutMapping(\"/{id}\")) @RequestMapping(method = RequestMethod.PUT) 의 축약형입니다.\n@DeleteMapping (예시: @DeleteMapping(\"/{id}\")) @RequestMapping(method = RequestMethod.DELETE) 의 축약형입니다.\n@PatchMapping (예시: @PatchMapping(\"/{id}\")) @RequestMapping(method = RequestMethod.PATCH) 의 축약형입니다.\n@ControllerAdvice / @RestControllerAdvice (예시: @RestControllerAdvice public class GlobalExceptionHandler { @ExceptionHandler(IllegalArgumentException.class) @ResponseStatus(HttpStatus.BAD_REQUEST) public ErrorResponse handleIllegalArgument(Exception e) { ... } }) 전역 설정을 위한 고수준 추상화입니다.\n@ExceptionHandler: 여러 컨트롤러에서 발생하는 특정 예외를 한 곳에서 공통으로 처리합니다. @ModelAttribute: 모든 컨트롤러에 공통으로 필요한 모델 데이터를 추가합니다. @InitBinder: 모든 컨트롤러에 적용될 데이터 바인딩 설정을 합니다. @RestControllerAdvice는 @ControllerAdvice와 @ResponseBody를 합친 것으로, 예외 처리 결과 자체를 JSON 같은 데이터로 응답할 때 사용합니다.","상세-설명-낮은-추상화---높은-추상화-순#상세 설명 (낮은 추상화 -\u0026gt; 높은 추상화 순)":"","요약-추상화의-흐름#요약: 추상화의 흐름":"Servlet API (HttpServletRequest) -\u003e “이 URL을 이 메서드에 연결해줘” (@RequestMapping) -\u003e “URL 파라미터는 이 변수에 넣어줘” (@RequestParam) -\u003e “여러 파라미터를 이 객체에 알아서 채워줘” (@ModelAttribute) -\u003e “요청 Body의 JSON을 이 객체로 바꿔줘” (@RequestBody) -\u003e “메서드 반환값을 바로 JSON으로 응답해줘” (@ResponseBody) -\u003e “이 컨트롤러는 전부 REST API용이니 모든 메서드에 @ResponseBody를 붙여줘” (@RestController) -\u003e “@RequestMapping(method=GET) 대신 @GetMapping으로 간단히 쓰자” (@GetMapping 등)\n이처럼 Spring은 개발자가 저수준의 반복적인 작업을 하지 않고, 비즈니스 로직에 집중할 수 있도록 점점 더 편리하고 높은 수준의 추상화를 제공하는 방향으로 발전해왔습니다.","요약-추상화의-흐름-1#요약: 추상화의 흐름":"Spring은 개발자가 저수준의 반복적인 작업을 하지 않고, 비즈니스 로직에 집중할 수 있도록 점점 더 편리하고 높은 수준의 추상화를 제공하는 방향으로 발전해왔습니다.\nServlet API (HttpServletRequest)\n“HTTP 요청의 모든 것을 내가 직접 다룰게.”\n→ @RequestMapping\n“이 URL을 이 메서드에 연결하는 건 Spring에게 맡길게.”\n→ @RequestParam, @RequestHeader, @CookieValue\n“요청에서 값 꺼내는 귀찮은 일도 Spring이 알아서 해줘.”\n→ @ModelAttribute\n“파라미터가 많아도 괜찮아. 객체로 한 번에 받을 수 있어.”\n→ @RequestBody\n“요청 Body의 JSON을 이 객체로 바꾸는 건 이제 신경 안 쓸래.”\n→ @ResponseBody\n“메서드 반환값을 바로 JSON으로 응답해줘. Java 객체를 다시 JSON으로 바꾸는 것도 Spring이 알아서 해줘.”\n→ @RestController\n“매번 @ResponseBody 붙이기 귀찮으니 이 컨트롤러는 전부 REST API용으로 @RestController만 선언할게.”\n→ @GetMapping 등 HTTP 메서드별 축약 어노테이션\n“코드를 더 짧고 명확하게 만들자.”\n→ @RestControllerAdvice\n“모든 컨트롤러에서 발생하는 예외는 여기서 한 번에 처리하자. 중복되는 예외 처리 코드는 한 곳에 모아서 관리할래.”\n각 단계의 특징을 이해하면 상황에 맞는 최적의 도구를 선택하여 효율적으로 개발할 수 있습니다.","추상화-단계별-설명#추상화 단계별 설명":"Level 1: Servlet API 직접 사용 (가장 낮은 추상화 단계)\nSpring이 있기 전, Java 웹 개발의 근간인 Servlet API를 직접 사용하는 방식입니다. Spring Controller에서도 이 객체들을 직접 파라미터로 받아 모든 것을 수동으로 제어할 수 있습니다. Level 2: 기본 매핑과 요청 데이터 추출\nServlet API를 직접 다루는 불편함을 줄이고, 특정 URL 요청을 특정 메서드에 연결(매핑)하고 요청 데이터를 쉽게 추출하는 단계입니다. Level 3: 데이터 바인딩 및 응답 데이터 처리\n요청 파라미터들을 객체(DTO)에 자동으로 담아주거나, 응답할 데이터를 모델에 담아 View로 전달하는 등 데이터 처리를 자동화하는 단계입니다. Level 4: REST API를 위한 추상화\n전통적인 HTML View 반환이 아닌, JSON/XML 같은 데이터 자체를 응답하는 RESTful API 개발에 특화된 고수준 추상화 단계입니다. Level 5: 편의성을 위한 조합 및 축약 (가장 높은 추상화 단계)\n여러 어노테이션의 기능을 하나로 합치거나, 코드를 더 간결하게 만들어주는 ‘문법적 설탕(Syntactic Sugar)’ 단계입니다.","추상화-단계별-설명-1#추상화 단계별 설명":"Spring 프레임워크는 개발자가 웹 개발의 복잡한 저수준 세부 사항에서 벗어나 비즈니스 로직에 집중할 수 있도록 다양한 수준의 추상화를 제공합니다. 여기서는 가장 낮은 추상화 단계부터 높은 추상화 단계까지, Spring이 어떻게 개발 경험을 간소화하는지 단계별로 살펴보겠습니다."},"title":"spring controller 추상화 단계별 어노테이션 파라미터"},"/02.inbox/spring-handleradapter-%EA%B5%AC%ED%98%84%EC%B2%B4/":{"data":{"":"스프링 MVC의 **HandlerAdapter**는 다양한 유형의 핸들러(컨트롤러)를 실행하는 인터페이스입니다.\n각 HandlerAdapter 구현체는 특정 유형의 핸들러를 지원합니다.\n아래에서 언급된 6가지 구현체를 체계적으로 설명합니다:","-요약#📌 \u003cstrong\u003e요약\u003c/strong\u003e":"어댑터명 처리 대상 주요 사용 사례 HandlerFunctionAdapter HandlerFunction 함수형 라우팅(람다 기반) HttpRequestHandlerAdapter HttpRequestHandler 서블릿 API 기반 레거시 코드 RequestMappingHandlerAdapter @RequestMapping 기반 컨트롤러 현대적인 REST API 개발 SimpleControllerHandlerAdapter Controller 인터페이스 과거 버전 호환용 컨트롤러 SimpleServletHandlerAdapter 일반 서블릿 기존 서블릿 통합","-핵심-포인트#💡 \u003cstrong\u003e핵심 포인트\u003c/strong\u003e":"현대적인 개발에서는 RequestMappingHandlerAdapter 가 주력으로 사용됩니다. 함수형 프로그래밍은 HandlerFunctionAdapter 로 처리합니다. 레거시 코드 통합 시 HttpRequestHandlerAdapter 또는 SimpleServletHandlerAdapter를 사용합니다. SimpleControllerHandlerAdapter는 거의 사용되지 않으며, @Controller 애노테이션으로 대체되었습니다.","1-abstracthandlermethodadapter#1. \u003cstrong\u003e\u003ccode\u003eAbstractHandlerMethodAdapter\u003c/code\u003e\u003c/strong\u003e":"역할: 메서드 기반 핸들러 어댑터의 추상 클래스. 특징: HandlerMethod를 처리하는 어댑터의 기본 기능을 제공합니다. RequestMappingHandlerAdapter의 상위 클래스로, 메서드 단위 처리 로직을 공통화합니다. 사용 예시:\n구체적인 구현체(RequestMappingHandlerAdapter)에서 확장되어 사용됩니다.","2-handlerfunctionadapter#2. \u003cstrong\u003e\u003ccode\u003eHandlerFunctionAdapter\u003c/code\u003e\u003c/strong\u003e":"역할: 함수형 프로그래밍 스타일 핸들러(HandlerFunction)를 지원합니다. 특징: RouterFunction과 함께 사용되며, 람다 표현식으로 핸들러를 정의합니다. Spring 5+에서 도입된 함수형 엔드포인트를 처리합니다. 예시: @Bean public RouterFunction\u003cServerResponse\u003e route() { return RouterFunctions.route() .GET(\"/api/users\", request -\u003e ServerResponse.ok().body(...)) .build(); }","3-httprequesthandleradapter#3. \u003cstrong\u003e\u003ccode\u003eHttpRequestHandlerAdapter\u003c/code\u003e\u003c/strong\u003e":"역할: HttpRequestHandler 인터페이스 구현체를 처리합니다. 특징: 서블릿 API(HttpServletRequest, HttpServletResponse)를 직접 사용하는 레거시 코드와 호환됩니다. @Controller 애노테이션 없이도 핸들러를 등록할 수 있습니다. 예시: public class LegacyHandler implements HttpRequestHandler { @Override public void handleRequest(HttpServletRequest request, HttpServletResponse response) { // 직접 응답을 생성합니다. } }","4-requestmappinghandleradapter#4. \u003cstrong\u003e\u003ccode\u003eRequestMappingHandlerAdapter\u003c/code\u003e\u003c/strong\u003e":"역할: 애노테이션 기반 컨트롤러(@RequestMapping, @RestController)를 처리합니다. 특징: @GetMapping, @PostMapping, @PathVariable, @RequestBody 등을 지원합니다. 현대적인 스프링 애플리케이션에서 가장 많이 사용되는 어댑터입니다. 예시: @RestController public class UserController { @GetMapping(\"/users\") public List\u003cUser\u003e getUsers() { return userService.findAll(); } }","5-simplecontrollerhandleradapter#5. \u003cstrong\u003e\u003ccode\u003eSimpleControllerHandlerAdapter\u003c/code\u003e\u003c/strong\u003e":"역할: Controller 인터페이스 구현체를 처리합니다. 특징: 과거에 사용되던 방식으로, Controller 인터페이스의 handleRequest() 메서드를 호출합니다. @Controller 애노테이션 없이 빈으로 등록해야 합니다. 예시: public class OldController implements Controller { @Override public ModelAndView handleRequest(HttpServletRequest request, HttpServletResponse response) { return new ModelAndView(\"viewName\"); } }","6-simpleservlethandleradapter#6. \u003cstrong\u003e\u003ccode\u003eSimpleServletHandlerAdapter\u003c/code\u003e\u003c/strong\u003e":"역할: 일반 서블릿(javax.servlet.Servlet)을 핸들러로 사용합니다. 특징: 기존 서블릿을 스프링 MVC에서 재사용할 수 있도록 합니다. 서블릿의 service() 메서드를 직접 호출합니다. 예시: @WebServlet(\"/legacy\") public class LegacyServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest req, HttpServletResponse res) { res.getWriter().write(\"Legacy Servlet Response\"); } }"},"title":"spring HandlerAdapter 구현체"},"/02.inbox/spring-requestmapping-%EA%B5%AC%ED%98%84%EC%B2%B4/":{"data":{"":"스프링 MVC의 HandlerMapping 구현체는 다양한 방식으로 요청을 핸들러(컨트롤러)에 매핑합니다. 각 클래스의 역할과 특징을 체계적으로 정리했습니다:","-요약#📌 \u003cstrong\u003e요약\u003c/strong\u003e":"클래스명 주요 역할 AbstractHandlerMapping 모든 HandlerMapping의 기본 기능(인터셉터 처리 등) 제공 AbstractUrlHandlerMapping URL 기반 매핑의 추상화 BeanNameUrlHandlerMapping 빈 이름을 URL로 매핑 SimpleUrlHandlerMapping 정적 URL과 핸들러를 직접 연결 RequestMappingHandlerMapping 애노테이션 기반 컨트롤러 매핑 RouterFunctionMapping 함수형 라우팅(RouterFunction) 지원 WebSocketHandlerMapping WebSocket 엔드포인트 매핑","-핵심-포인트#💡 \u003cstrong\u003e핵심 포인트\u003c/strong\u003e":"현대적인 스프링 앱에서는 RequestMappingHandlerMapping 과 RouterFunctionMapping 이 주로 사용됩니다. 레거시 시스템에서는 BeanNameUrlHandlerMapping 또는 SimpleUrlHandlerMapping을 볼 수 있습니다. WebSocket이나 특수 프로토콜은 WebSocketHandlerMapping으로 처리합니다.","1-abstracthandlermapping#1. \u003cstrong\u003e\u003ccode\u003eAbstractHandlerMapping\u003c/code\u003e\u003c/strong\u003e":"역할: 모든 HandlerMapping의 기반 추상 클래스. 특징: 인터셉터(HandlerInterceptor) 관리 및 실행 로직을 제공합니다. getHandler() 메서드를 구현해 실제 핸들러를 찾는 로직을 정의합니다. 사용 예시:\n다른 구체적인 HandlerMapping 클래스들이 이 클래스를 상속받아 확장합니다.","10-abstracthandlermethodmapping#10. \u003cstrong\u003e\u003ccode\u003eAbstractHandlerMethodMapping\u003c/code\u003e\u003c/strong\u003e":"역할: 메서드 단위 매핑을 위한 추상 클래스. 특징: @RequestMapping과 같은 애노테이션을 메서드 단위로 분석합니다. RequestMappingHandlerMapping의 상위 클래스로, 메서드-URL 매핑 정보를 관리합니다.","2-abstracturlhandlermapping#2. \u003cstrong\u003e\u003ccode\u003eAbstractUrlHandlerMapping\u003c/code\u003e\u003c/strong\u003e":"역할: URL 기반 매핑을 위한 추상 클래스. 특징: URL 패턴과 핸들러를 연결하는 공통 로직을 제공합니다. urlMap 또는 handlerMap을 사용해 URL-핸들러 매핑 정보를 저장합니다. 하위 클래스: BeanNameUrlHandlerMapping SimpleUrlHandlerMapping AbstractDetectingUrlHandlerMapping","3-beannameurlhandlermapping#3. \u003cstrong\u003e\u003ccode\u003eBeanNameUrlHandlerMapping\u003c/code\u003e\u003c/strong\u003e":"역할: 스프링 빈 이름을 URL로 매핑합니다.\n특징:\n빈 이름이 /로 시작하는 경우, 해당 URL로 매핑됩니다. XML 또는 자바 설정으로 빈을 등록할 때 이름을 URL로 지정합니다. 예시:\n@Component(\"/hello\") // URL: /hello public class HelloController implements Controller { ... }","4-simpleurlhandlermapping#4. \u003cstrong\u003e\u003ccode\u003eSimpleUrlHandlerMapping\u003c/code\u003e\u003c/strong\u003e":"역할: 정적 URL 매핑을 명시적으로 설정합니다.\n특징:\nURL과 핸들러를 직접 연결하는 urlMap을 제공합니다. XML/자바 설정으로 유연하게 매핑할 수 있습니다. 예시:\n@Bean public SimpleUrlHandlerMapping handlerMapping() { SimpleUrlHandlerMapping mapping = new SimpleUrlHandlerMapping(); Map\u003cString, Object\u003e urlMap = new HashMap\u003c\u003e(); urlMap.put(\"/api/products\", productController()); return mapping; }","5-abstractdetectingurlhandlermapping#5. \u003cstrong\u003e\u003ccode\u003eAbstractDetectingUrlHandlerMapping\u003c/code\u003e\u003c/strong\u003e":"역할: 자동 URL 감지를 위한 추상 클래스. 특징: 빈의 이름이나 메타데이터를 분석해 URL을 자동으로 생성합니다. 주로 레거시 시스템이나 특정 프레임워크에서 사용됩니다. 하위 클래스: ControllerClassNameHandlerMapping (클래스 이름을 URL로 매핑, 예: HelloController → /hello*)","6-requestmappinghandlermapping#6. \u003cstrong\u003e\u003ccode\u003eRequestMappingHandlerMapping\u003c/code\u003e\u003c/strong\u003e":"역할: 애노테이션 기반 컨트롤러 매핑 (가장 일반적).\n특징:\n@RequestMapping, @GetMapping, @PostMapping 등을 분석해 URL을 매핑합니다. @Controller 또는 @RestController로 선언된 클래스의 메서드를 처리합니다. 예시:\n@RestController public class UserController { @GetMapping(\"/users\") public List\u003cUser\u003e getUsers() { ... } }","7-requestmappinginfohandlermapping#7. \u003cstrong\u003e\u003ccode\u003eRequestMappingInfoHandlerMapping\u003c/code\u003e\u003c/strong\u003e":"역할: @RequestMapping 메타데이터 기반 매핑. 특징: RequestMappingHandlerMapping의 상위 클래스로, RequestMappingInfo 객체를 사용해 세부적인 매핑 조건(HTTP 메서드, 헤더 등)을 처리합니다. 내부적으로 RequestMappingHandlerMapping에서 확장되어 사용됩니다.","8-routerfunctionmapping#8. \u003cstrong\u003e\u003ccode\u003eRouterFunctionMapping\u003c/code\u003e\u003c/strong\u003e":"역할: 함수형 프로그래밍 스타일로 라우팅을 정의합니다.\n특징:\nRouterFunction과 HandlerFunction을 사용해 람다 기반 라우팅을 구현합니다. Spring WebFlux 또는 반응형 프로그래밍에서 주로 사용됩니다. 예시:\n@Bean public RouterFunction\u003cServerResponse\u003e route() { return RouterFunctions.route() .GET(\"/api/users\", request -\u003e ServerResponse.ok().body(...)) .build(); }","9-websockethandlermapping#9. \u003cstrong\u003e\u003ccode\u003eWebSocketHandlerMapping\u003c/code\u003e\u003c/strong\u003e":"역할: WebSocket 요청 처리를 위한 매핑.\n특징:\nWebSocket 엔드포인트(/websocket)와 WebSocketHandler를 연결합니다. @EnableWebSocket과 함께 사용됩니다. 예시:\n@Configuration @EnableWebSocket public class WebSocketConfig implements WebSocketConfigurer { @Override public void registerWebSocketHandlers(WebSocketHandlerRegistry registry) { registry.addHandler(myHandler(), \"/websocket\"); } }"},"title":"spring RequestMapping 구현체"},"/02.inbox/spring-view-%EA%B5%AC%ED%98%84%EC%B2%B4/":{"data":{"":"스프링 MVC의 **View**는 모델 데이터를 클라이언트에게 렌더링하는 최종 형식을 결정하는 인터페이스입니다.\n아래에서 언급된 21개의 View 구현체를 목적별로 체계적으로 정리했습니다:","-요약#📌 \u003cstrong\u003e요약\u003c/strong\u003e":"뷰 클래스 주요 형식 사용 사례 MappingJackson2JsonView JSON REST API 응답 AbstractPdfView PDF 계약서, 보고서 생성 AbstractXlsxView Excel(.xlsx) 데이터 분석 리포트 FreeMarkerView HTML 동적 웹 페이지 RedirectView HTTP 리다이렉트 Post-Redirect-Get 패턴","-핵심-포인트#💡 \u003cstrong\u003e핵심 포인트\u003c/strong\u003e":"JSON/XML은 MappingJackson2JsonView 로 처리합니다. PDF/Excel은 AbstractPdfView, AbstractXlsxView 를 확장해 구현합니다. 리다이렉트는 RedirectView 를 사용합니다. 템플릿 엔진은 각각 전용 뷰 클래스(예: FreeMarkerView)를 사용합니다.","1-기본-추상-클래스#1. \u003cstrong\u003e기본 추상 클래스\u003c/strong\u003e":"","11-abstractview#1.1 \u003cstrong\u003e\u003ccode\u003eAbstractView\u003c/code\u003e\u003c/strong\u003e":"역할: 모든 뷰 구현체의 기본 추상 클래스. 특징: render() 메서드를 구현해 모델 데이터를 응답으로 변환합니다. 커스텀 뷰를 만들 때 상속받아 사용합니다. 사용 예시: public class CustomCsvView extends AbstractView { @Override protected void renderMergedOutputModel(Map\u003cString, Object\u003e model, HttpServletRequest request, HttpServletResponse response) { // CSV 생성 로직 } }","2-피드feed-뷰#2. \u003cstrong\u003e피드(Feed) 뷰\u003c/strong\u003e":"","21-abstractatomfeedview#2.1 \u003cstrong\u003e\u003ccode\u003eAbstractAtomFeedView\u003c/code\u003e\u003c/strong\u003e":"역할: Atom 형식의 피드를 생성합니다. 특징: Atom 1.0 스펙을 준수하는 XML 피드를 생성합니다. Rome 라이브러리를 내부적으로 사용합니다. 예시: 블로그 글 목록을 Atom 피드로 제공.","22-abstractrssfeedview#2.2 \u003cstrong\u003e\u003ccode\u003eAbstractRssFeedView\u003c/code\u003e\u003c/strong\u003e":"역할: RSS 형식의 피드를 생성합니다. 특징: RSS 2.0 스펙을 준수하는 XML 피드를 생성합니다. Rome 라이브러리를 사용합니다. 예시: 뉴스 사이트의 RSS 피드.","23-abstractfeedview#2.3 \u003cstrong\u003e\u003ccode\u003eAbstractFeedView\u003c/code\u003e\u003c/strong\u003e":"역할: Atom/RSS 피드의 공통 로직을 제공합니다. 특징: AbstractAtomFeedView와 AbstractRssFeedView의 부모 클래스입니다.","3-jsonxml-뷰#3. \u003cstrong\u003eJSON/XML 뷰\u003c/strong\u003e":"","31-mappingjackson2jsonview#3.1 \u003cstrong\u003e\u003ccode\u003eMappingJackson2JsonView\u003c/code\u003e\u003c/strong\u003e":"역할: JSON 형식의 응답을 생성합니다. 특징: Jackson 2 라이브러리를 사용해 모델 데이터를 JSON으로 변환합니다. @ResponseBody 대신 뷰를 통해 JSON을 반환할 때 사용됩니다. 예시: @Bean public View jsonView() { return new MappingJackson2JsonView(); }","32-mappingjackson2xmlview#3.2 \u003cstrong\u003e\u003ccode\u003eMappingJackson2XmlView\u003c/code\u003e\u003c/strong\u003e":"역할: XML 형식의 응답을 생성합니다. 특징: Jackson 2의 XML 확장을 사용해 모델 데이터를 XML로 변환합니다. 예시: 레거시 시스템과의 XML 통신.","33-marshallingview#3.3 \u003cstrong\u003e\u003ccode\u003eMarshallingView\u003c/code\u003e\u003c/strong\u003e":"역할: XML/JSON 변환을 위한 마샬링 뷰. 특징: JAXB, Castor 등 다양한 마샬러를 지원합니다. Marshaller 인터페이스를 구현한 라이브러리를 사용합니다.","4-pdf-뷰#4. \u003cstrong\u003ePDF 뷰\u003c/strong\u003e":"","41-abstractpdfview#4.1 \u003cstrong\u003e\u003ccode\u003eAbstractPdfView\u003c/code\u003e\u003c/strong\u003e":"역할: PDF 문서를 생성합니다. 특징: iText 라이브러리를 사용해 PDF를 생성합니다. 모델 데이터를 테이블, 텍스트 등으로 렌더링합니다. 예시: public class InvoicePdfView extends AbstractPdfView { @Override protected void buildPdfDocument(Map\u003cString, Object\u003e model, Document document, PdfWriter writer) { // PDF 문서 생성 로직 } }","42-abstractpdfstamperview#4.2 \u003cstrong\u003e\u003ccode\u003eAbstractPdfStamperView\u003c/code\u003e\u003c/strong\u003e":"역할: 기존 PDF 템플릿에 데이터 채우기. 특징: iText의 PdfStamper를 사용해 정적 PDF 양식을 동적으로 채웁니다. 계약서, 청구서 등 고정된 양식에 데이터를 입력할 때 사용됩니다.","5-엑셀-뷰#5. \u003cstrong\u003e엑셀 뷰\u003c/strong\u003e":"","51-abstractxlsview#5.1 \u003cstrong\u003e\u003ccode\u003eAbstractXlsView\u003c/code\u003e\u003c/strong\u003e":"역할: 레거시 Excel(.xls) 파일 생성. 특징: Apache POI 라이브러리를 사용해 Excel 97-2003 형식(.xls)을 생성합니다. 예시: 재무 데이터 보고서.","52-abstractxlsxview#5.2 \u003cstrong\u003e\u003ccode\u003eAbstractXlsxView\u003c/code\u003e\u003c/strong\u003e":"역할: Excel 2007+ 형식(.xlsx) 파일 생성. 특징: Apache POI의 XSSF API를 사용해 최신 Excel 형식을 지원합니다.","53-abstractxlsxstreamingview#5.3 \u003cstrong\u003e\u003ccode\u003eAbstractXlsxStreamingView\u003c/code\u003e\u003c/strong\u003e":"역할: 대용량 Excel 파일 스트리밍. 특징: 메모리 사용을 최소화하기 위해 데이터를 스트리밍 방식으로 작성합니다. 수십만 행의 데이터를 처리할 때 유용합니다.","6-템플릿-뷰#6. \u003cstrong\u003e템플릿 뷰\u003c/strong\u003e":"","61-freemarkerview#6.1 \u003cstrong\u003e\u003ccode\u003eFreeMarkerView\u003c/code\u003e\u003c/strong\u003e":"역할: FreeMarker 템플릿을 렌더링합니다. 특징: FreeMarkerViewResolver와 함께 사용됩니다. HTML, 텍스트 등 다양한 형식을 지원합니다. 예시: 동적 HTML 페이지 생성.","62-groovymarkupview#6.2 \u003cstrong\u003e\u003ccode\u003eGroovyMarkupView\u003c/code\u003e\u003c/strong\u003e":"역할: Groovy 템플릿을 렌더링합니다. 특징: Groovy Markup Template을 사용해 뷰를 생성합니다. 간결한 문법으로 XML/HTML을 생성합니다.","63-scripttemplateview#6.3 \u003cstrong\u003e\u003ccode\u003eScriptTemplateView\u003c/code\u003e\u003c/strong\u003e":"역할: 스크립트 기반 템플릿(예: React, Nashorn)을 지원합니다. 특징: JavaScript 엔진을 사용해 뷰를 렌더링합니다. 서버 측에서 React 컴포넌트를 렌더링할 때 사용됩니다.","7-jsp리소스-뷰#7. \u003cstrong\u003eJSP/리소스 뷰\u003c/strong\u003e":"","71-internalresourceview#7.1 \u003cstrong\u003e\u003ccode\u003eInternalResourceView\u003c/code\u003e\u003c/strong\u003e":"역할: JSP 파일을 렌더링합니다. 특징: InternalResourceViewResolver와 함께 사용됩니다. JstlView의 부모 클래스입니다.","72-jstlview#7.2 \u003cstrong\u003e\u003ccode\u003eJstlView\u003c/code\u003e\u003c/strong\u003e":"역할: JSTL 태그를 지원하는 JSP 뷰. 특징: JSTL의 , 등을 사용할 수 있습니다.","8-특수-목적-뷰#8. \u003cstrong\u003e특수 목적 뷰\u003c/strong\u003e":"","81-redirectview#8.1 \u003cstrong\u003e\u003ccode\u003eRedirectView\u003c/code\u003e\u003c/strong\u003e":"역할: HTTP 리다이렉트를 수행합니다. 특징: redirect:/newPath 또는 외부 URL(https://example.com)로 이동합니다. Post/Redirect/Get 패턴 구현에 사용됩니다. 예시: return new ModelAndView(new RedirectView(\"/home\"));","82-xsltview#8.2 \u003cstrong\u003e\u003ccode\u003eXsltView\u003c/code\u003e\u003c/strong\u003e":"역할: XML 데이터를 XSLT로 변환합니다. 특징: XML 데이터와 XSLT 스타일시트를 결합해 HTML 등을 생성합니다."},"title":"spring View 구현체"},"/02.inbox/spring-viewresolver-%EA%B5%AC%ED%98%84%EC%B2%B4/":{"data":{"":"스프링 MVC의 ViewResolver 는 뷰 이름을 실제 View 객체로 변환하는 역할을 합니다.\n다양한 구현체가 있으며, 각각의 특징과 사용 사례를 체계적으로 정리했습니다:","-요약#📌 \u003cstrong\u003e요약\u003c/strong\u003e":"리졸버명 주요 기능 InternalResourceViewResolver JSP 뷰 처리 (가장 일반적) FreeMarkerViewResolver FreeMarker 템플릿 처리 ContentNegotiatingViewResolver 요청 형식(JSON/XML)에 따라 뷰 선택 BeanNameViewResolver 스프링 빈 이름으로 뷰 조회 ViewResolverComposite 다중 리졸버 조합 XsltViewResolver XML을 XSLT로 변환","-핵심-포인트#💡 \u003cstrong\u003e핵심 포인트\u003c/strong\u003e":"JSP는 InternalResourceViewResolver 로 처리합니다. 템플릿 엔진(FreeMarker, Groovy)은 각각 전용 리졸버를 사용합니다. 다중 포맷 지원(JSON, XML)은 ContentNegotiatingViewResolver 로 구현합니다. 커스텀 뷰는 BeanNameViewResolver 또는 ResourceBundleViewResolver로 관리합니다.","1-abstractcachingviewresolver#1. \u003cstrong\u003e\u003ccode\u003eAbstractCachingViewResolver\u003c/code\u003e\u003c/strong\u003e":"역할: 뷰 캐싱 기능을 제공하는 추상 클래스. 특징: 뷰 객체를 캐시하여 반복적인 뷰 생성을 방지합니다. 하위 클래스(예: UrlBasedViewResolver)가 캐싱 로직을 재사용할 수 있도록 합니다. 사용 예시:\nInternalResourceViewResolver가 이 클래스를 상속받아 JSP 뷰 캐싱을 처리합니다.","10-urlbasedviewresolver#10. \u003cstrong\u003e\u003ccode\u003eUrlBasedViewResolver\u003c/code\u003e\u003c/strong\u003e":"역할: URL 기반 뷰를 직접 매핑합니다. 특징: 뷰 이름을 URL 경로로 직접 변환합니다. InternalResourceViewResolver의 부모 클래스입니다. 예시: @Bean public UrlBasedViewResolver urlBasedViewResolver() { UrlBasedViewResolver resolver = new UrlBasedViewResolver(); resolver.setViewClass(JstlView.class); resolver.setPrefix(\"/WEB-INF/views/\"); resolver.setSuffix(\".jsp\"); return resolver; }","11-viewresolvercomposite#11. \u003cstrong\u003e\u003ccode\u003eViewResolverComposite\u003c/code\u003e\u003c/strong\u003e":"역할: 다중 ViewResolver를 조합합니다. 특징: 여러 리졸버를 순차적으로 실행해 적절한 뷰를 찾습니다. 우선순위를 설정할 수 있습니다. 예시: @Bean public ViewResolverComposite compositeResolver() { ViewResolverComposite composite = new ViewResolverComposite(); composite.addResolver(new InternalResourceViewResolver()); composite.addResolver(new FreeMarkerViewResolver()); return composite; }","12-xmlviewresolver#12. \u003cstrong\u003e\u003ccode\u003eXmlViewResolver\u003c/code\u003e\u003c/strong\u003e":"역할: XML 파일로 뷰를 정의합니다. 특징: views.xml과 같은 XML 설정 파일에서 뷰 빈을 로드합니다. ResourceBundleViewResolver와 유사하지만 XML 형식을 사용합니다. 예시:","13-xsltviewresolver#13. \u003cstrong\u003e\u003ccode\u003eXsltViewResolver\u003c/code\u003e\u003c/strong\u003e":"역할: XSLT(XML 변환) 뷰를 처리합니다. 특징: XML 데이터를 XSLT 스타일시트로 변환합니다. XsltView 클래스를 사용해 렌더링합니다. 예시: @Bean public XsltViewResolver xsltViewResolver() { XsltViewResolver resolver = new XsltViewResolver(); resolver.setPrefix(\"/WEB-INF/xsl/\"); resolver.setSuffix(\".xsl\"); return resolver; }","2-abstracttemplateviewresolver#2. \u003cstrong\u003e\u003ccode\u003eAbstractTemplateViewResolver\u003c/code\u003e\u003c/strong\u003e":"역할: 템플릿 기반 뷰(예: JSP, Thymeleaf)를 처리하는 추상 클래스. 특징: 템플릿 엔진 설정(예: prefix, suffix)을 공통으로 관리합니다. UrlBasedViewResolver와 함께 사용됩니다. 사용 예시:\nFreeMarkerViewResolver가 이 클래스를 상속받아 FreeMarker 템플릿을 처리합니다.","3-beannameviewresolver#3. \u003cstrong\u003e\u003ccode\u003eBeanNameViewResolver\u003c/code\u003e\u003c/strong\u003e":"역할: 스프링 빈 이름으로 뷰를 조회합니다. 특징: 뷰 이름이 스프링 빈 이름과 일치하는 View 객체를 찾아 반환합니다. 커스텀 뷰(예: PDF 생성 뷰)를 빈으로 등록해 사용할 때 유용합니다. 예시: @Bean public View pdfView() { return new AbstractPdfView() { // PDF 뷰 구현 @Override protected void buildPdfDocument(Map\u003cString, Object\u003e model, Document document, PdfWriter writer) { // PDF 생성 로직 } }; }","4-contentnegotiatingviewresolver#4. \u003cstrong\u003e\u003ccode\u003eContentNegotiatingViewResolver\u003c/code\u003e\u003c/strong\u003e":"역할: 요청의 Accept 헤더 또는 쿼리 파라미터에 따라 뷰를 선택합니다. 특징: 클라이언트가 원하는 형식(JSON, XML, HTML 등)에 맞는 뷰를 반환합니다. 내부적으로 다른 ViewResolver를 조합해 동작합니다. 예시: @Configuration public class WebConfig implements WebMvcConfigurer { @Override public void configureViewResolvers(ViewResolverRegistry registry) { registry.enableContentNegotiation(new JsonView(), new XmlView()); } }","5-freemarkerviewresolver#5. \u003cstrong\u003e\u003ccode\u003eFreeMarkerViewResolver\u003c/code\u003e\u003c/strong\u003e":"역할: FreeMarker 템플릿을 처리합니다. 특징: 뷰 이름을 FreeMarker 템플릿 파일 경로(예: views/user.ftl)로 변환합니다. FreeMarkerConfigurer와 함께 설정됩니다. 예시: @Bean public FreeMarkerViewResolver freeMarkerViewResolver() { FreeMarkerViewResolver resolver = new FreeMarkerViewResolver(); resolver.setPrefix(\"/WEB-INF/views/\"); resolver.setSuffix(\".ftl\"); return resolver; }","6-groovymarkupviewresolver#6. \u003cstrong\u003e\u003ccode\u003eGroovyMarkupViewResolver\u003c/code\u003e\u003c/strong\u003e":"역할: Groovy 템플릿을 처리합니다. 특징: Groovy Markup Template(예: user.tpl)을 렌더링합니다. GroovyMarkupConfigurer로 템플릿 설정을 관리합니다. 예시: @Bean public GroovyMarkupViewResolver groovyViewResolver() { GroovyMarkupViewResolver resolver = new GroovyMarkupViewResolver(); resolver.setPrefix(\"/views/\"); resolver.setSuffix(\".tpl\"); return resolver; }","7-internalresourceviewresolver#7. \u003cstrong\u003e\u003ccode\u003eInternalResourceViewResolver\u003c/code\u003e\u003c/strong\u003e":"역할: JSP 뷰를 처리하는 가장 일반적인 리졸버. 특징: 뷰 이름을 JSP 파일 경로(예: /WEB-INF/views/home.jsp)로 변환합니다. prefix와 suffix로 경로를 설정합니다. 예시: @Bean public InternalResourceViewResolver viewResolver() { InternalResourceViewResolver resolver = new InternalResourceViewResolver(); resolver.setPrefix(\"/WEB-INF/views/\"); resolver.setSuffix(\".jsp\"); return resolver; }","8-resourcebundleviewresolver#8. \u003cstrong\u003e\u003ccode\u003eResourceBundleViewResolver\u003c/code\u003e\u003c/strong\u003e":"역할: 프로퍼티 파일로 뷰를 정의합니다. 특징: views.properties 파일에 뷰 이름과 클래스 정보를 저장합니다. 다국어 뷰 또는 외부 설정이 필요한 경우에 사용됩니다. 예시: # views.properties home.class=org.springframework.web.servlet.view.JstlView home.url=/WEB-INF/views/home.jsp","9-scripttemplateviewresolver#9. \u003cstrong\u003e\u003ccode\u003eScriptTemplateViewResolver\u003c/code\u003e\u003c/strong\u003e":"역할: 스크립트 기반 템플릿(예: Nashorn, React)을 처리합니다. 특징: JavaScript 또는 다른 스크립트 엔진으로 뷰를 렌더링합니다. ScriptTemplateConfigurer로 스크립트 엔진을 설정합니다. 예시: @Bean public ScriptTemplateViewResolver scriptViewResolver() { ScriptTemplateViewResolver resolver = new ScriptTemplateViewResolver(); resolver.setPrefix(\"templates/\"); resolver.setSuffix(\".jsx\"); return resolver; }"},"title":"spring ViewResolver 구현체"},"/02.inbox/sql-%EC%97%90%EC%84%9C-%EB%B0%B1%ED%8B%B1-%EC%9E%91%EC%9D%80%EB%94%B0%EC%98%B4%ED%91%9C-%ED%81%B0%EB%94%B0%EC%98%B4%ED%91%9C-%EC%9D%98%EB%AF%B8/":{"data":{"":"각 데이터베이스 관리 시스템(DBMS)에서 백틱(`), 작은따옴표(’), 그리고 큰따옴표(\")의 사용과 의미는 조금씩 다릅니다","mysql#MySQL":"백틱(`): 테이블 이름이나 컬럼 이름 같은 식별자를 묶는 데 사용됩니다. MySQL에서는 특별한 문자나 예약어, 공백 등이 포함된 식별자를 백틱으로 묶어 사용할 수 있습니다. 작은따옴표(’): 문자열 리터럴을 정의하는 데 사용됩니다. 큰따옴표(\"): 기본 설정(SQL 모드)에 따라 다르지만, ANSI_QUOTES SQL 모드가 활성화되어 있을 때 식별자를 묶는 데 사용될 수 있습니다. 그렇지 않은 경우에는 작은따옴표와 같이 문자열 리터럴을 정의하는 데 사용됩니다.","oracle#Oracle":"백틱(`): Oracle에서는 백틱을 사용하지 않습니다. 특별한 의미를 가지지 않으며, 식별자나 문자열을 나타내는 데 사용되지 않습니다. 작은따옴표('): 문자열 리터럴을 정의하는 데 사용됩니다. 예를 들어, SELECT '문자열' FROM DUAL;과 같이 사용할 수 있습니다. 큰따옴표(\"): 식별자(테이블 이름, 컬럼 이름 등)를 정의하는 데 사용됩니다. 대소문자를 구분하며, 기본적으로 Oracle은 대소문자를 구분하지 않지만, 큰따옴표로 묶인 식별자는 대소문자를 구분합니다. 예를 들어, SELECT \"Column\" FROM \"MyTable\";과 같이 사용할 수 있습니다.","postgresql#PostgreSQL":"백틱(`): PostgreSQL에서는 백틱을 사용하지 않습니다. 특별한 의미를 가지지 않으며, 식별자나 문자열을 나타내는 데 사용되지 않습니다. 작은따옴표(’): 문자열 리터럴을 정의하는 데 사용됩니다. 큰따옴표(\"): 식별자를 묶는 데 사용됩니다. PostgreSQL에서는 큰따옴표로 묶인 식별자가 대소문자를 구분합니다. 예를 들어, SELECT \"Column\" FROM \"MyTable\";에서 “MyTable\"과 “Column\"은 대소문자를 구분하는 식별자입니다."},"title":"sql 에서 백틱, 작은따옴표, 큰따옴표 의미"},"/02.inbox/sse-server-sent-event/":{"data":{"":"","back#Back":"package com.example.sse.controller; import org.springframework.http.MediaType; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.servlet.mvc.method.annotation.SseEmitter; import java.io.IOException; import java.util.Random; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; @RestController public class SseController { private final Random random = new Random(); @GetMapping(value = \"/sse\", produces = MediaType.TEXT_EVENT_STREAM_VALUE) public SseEmitter handleSse() { SseEmitter emitter = new SseEmitter(60_000L); // 타임아웃 설정 // ExecutorService executor = Executors.newSingleThreadExecutor(); executor.execute(() -\u003e { try { for (int i = 0; i \u003c 10; i++) { // 10번의 무작위 이벤트 int delay = random.nextInt(3000) + 1000; // 1~4초 사이 랜덤 지연 Thread.sleep(delay); String eventData = \"Event at \" + System.currentTimeMillis(); emitter.send(eventData); } emitter.complete(); } catch (IOException | InterruptedException e) { emitter.completeWithError(e); } finally { executor.shutdown(); } }); return emitter; } } produces = MediaType.TEXT_EVENT_STREAM_VALUE: 클라이언트에게 text/event-stream 형식의 데이터를 보낸다는 의미 → SSE 방식. 반환형은 SseEmitter 객체이며, 서버에서 클라이언트로 일방향 통신을 가능하게 합니다. SseEmitter emitter = new SseEmitter(60_000L); // 타임아웃 60초 클라이언트가 60초 동안 응답을 받지 않으면 연결이 종료됩니다. 별도의 스레드에서 비동기적으로 작업 수행. 총 10번의 이벤트를 랜덤한 시간 간격(1~4초)으로 전송. emitter.send(data)로 클라이언트에게 데이터를 실시간 전송.","front#Front":"\u003c!DOCTYPE html\u003e \u003chtml lang=\"ko\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003eSSE 실시간 이벤트\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003ch2\u003e실시간 이벤트 수신\u003c/h2\u003e \u003cul id=\"eventList\"\u003e\u003c/ul\u003e \u003cscript\u003e const eventSource = new EventSource(\"/sse\"); eventSource.onmessage = function(event) { const li = document.createElement(\"li\"); li.textContent = event.data; document.getElementById(\"eventList\").appendChild(li); }; eventSource.onerror = function(err) { console.error(\"SSE 오류:\", err); }; \u003c/script\u003e \u003c/body\u003e \u003c/html\u003e"},"title":"sse (server sent event)"},"/02.inbox/tcp-telnet-%ED%86%B5%EC%8B%A0-%EA%B3%BC%EC%A0%95-%EC%8B%9C%EB%AE%AC%EB%A0%88%EC%9D%B4%EC%85%98/":{"data":{"":"","telnet-tcp-기반-패킷-이동-시뮬레이션-senderreceiver-윈도우-및-패킷-내용#Telnet (TCP 기반) 패킷 이동 시뮬레이션: Sender/Receiver 윈도우 및 패킷 내용":"Telnet은 애플리케이션 계층 프로토콜이며, 전송 계층에서는 **TCP(Transmission Control Protocol)**를 사용합니다. TCP는 신뢰성 있는 데이터 전송을 보장하기 위해 연결 설정(3-way handshake), 데이터 전송(슬라이딩 윈도우, 확인 응답), 연결 해제(4-way handshake) 과정을 거칩니다.\n아래는 Telnet 클라이언트(Sender)가 Telnet 서버(Receiver)에 접속하여 간단한 데이터를 주고받는 과정을 가상으로 시뮬레이션한 결과입니다. 실제 환경에서는 윈도우 크기 변화, 패킷 손실 및 재전송 등 더 복잡한 상황이 발생할 수 있습니다.\n용어 설명:\nSender (송신자): Telnet 클라이언트 (사용자 측) Receiver (수신자): Telnet 서버 Seq: Sequence Number (순서 번호). 보내는 데이터의 바이트 순서를 나타냅니다. Ack: Acknowledgment Number (확인 응답 번호). 다음에 받아야 할 데이터의 시작 순서 번호를 나타냅니다. (즉, Ack-1 까지는 잘 받았다는 의미) Win: Window Size (윈도우 크기). 수신 버퍼의 남은 공간 크기를 알려주어 흐름 제어(Flow Control)에 사용됩니다. 송신자는 이 크기만큼만 확인 응답 없이 데이터를 보낼 수 있습니다. Flags: TCP 제어 플래그 (SYN, ACK, FIN, PSH 등) Payload: 실제 전송되는 데이터 (Telnet 명령어, 서버 응답 등) 시뮬레이션 시작 (가정):\nSender의 초기 Sequence Number (ISN): X Receiver의 초기 Sequence Number (ISN): Y Sender의 초기 수신 윈도우 크기: Win_C Receiver의 초기 수신 윈도우 크기: Win_S 1. 연결 설정 (3-Way Handshake)\n단계 방향 TCP Flags Seq Ack Win Payload 설명 1 Sender -\u003e Receiver [SYN] X 0 Win_C - 연결 요청. 자신의 초기 순서 번호(X)와 수신 윈도우 크기(Win_C) 전송. 2 Receiver -\u003e Sender [SYN, ACK] Y X+1 Win_S - 연결 수락 및 요청 확인. 자신의 초기 순서 번호(Y), Sender의 요청 확인(X+1), 자신의 수신 윈도우 크기(Win_S) 전송. 3 Sender -\u003e Receiver [ACK] X+1 Y+1 Win_C - Receiver의 연결 수락 확인(Y+1). 연결 성립 완료. 2. 데이터 전송 (Telnet: 서버가 로그인 프롬프트 전송 -\u003e 클라이언트가 사용자 이름 입력)\n상황: 연결 후 Telnet 서버(Receiver)가 로그인 프롬프트를 보냅니다. (예: “Login: “) 단계 방향 TCP Flags Seq Ack Win Payload 설명 4 Receiver -\u003e Sender [PSH, ACK] Y+1 X+1 Win_S “Login: \" (7 bytes) 서버가 데이터를 보냄 (Push 플래그 설정 가능). Seq=Y+1 (이전 ACK 다음 번호), Ack=X+1 (이전 Sender의 Seq+1). Payload 포함. 5 Sender -\u003e Receiver [ACK] X+1 Y+8 Win_C - Sender가 서버 데이터 수신 확인. Ack=Y+1+7 = Y+8 (다음 받을 번호). 윈도우 크기는 Sender의 현재 버퍼 상황에 따라 업데이트될 수 있음. 상황: Telnet 클라이언트(Sender)가 사용자 이름 “user1\\n” (6 bytes)을 입력하여 서버로 전송합니다. 단계 방향 TCP Flags Seq Ack Win Payload 설명 6 Sender -\u003e Receiver [PSH, ACK] X+1 Y+8 Win_C “user1\\n” (6 bytes) 클라이언트가 데이터를 보냄. Seq=X+1 (이전 ACK 이후 첫 데이터), Ack=Y+8 (이전 Receiver의 Seq+Payload 길이). Payload 포함. 7 Receiver -\u003e Sender [ACK] Y+8 X+7 Win_S - Receiver가 클라이언트 데이터 수신 확인. Ack=X+1+6 = X+7 (다음 받을 번호). 윈도우 크기는 Receiver의 현재 버퍼 상황에 따라 업데이트될 수 있음. 3. 연결 해제 (4-Way Handshake - 클라이언트가 먼저 종료 요청)\n상황: Telnet 클라이언트(Sender)가 연결 종료를 원합니다. 단계 방향 TCP Flags Seq Ack Win Payload 설명 8 Sender -\u003e Receiver [FIN, ACK] X+7 Y+8 Win_C - 연결 종료 요청 (FIN). 마지막으로 보낸 데이터의 다음 Seq 번호(X+7). 마지막으로 받은 데이터의 다음 번호(Y+8)를 Ack. 9 Receiver -\u003e Sender [ACK] Y+8 X+8 Win_S - Sender의 종료 요청(FIN) 확인. Ack=X+7+1 = X+8. (서버는 아직 데이터를 보낼 수 있는 상태 - Half-Close) 상황: Telnet 서버(Receiver)도 데이터를 모두 보냈고, 연결 종료를 원합니다. 단계 방향 TCP Flags Seq Ack Win Payload 설명 10 Receiver -\u003e Sender [FIN, ACK] Y+8 X+8 Win_S - 서버 측 연결 종료 요청 (FIN). 마지막으로 보낸 데이터의 다음 Seq 번호(Y+8). 마지막으로 받은 데이터의 다음 번호(X+8)를 Ack. 11 Sender -\u003e Receiver [ACK] X+8 Y+9 Win_C - 서버의 종료 요청(FIN) 확인. Ack=Y+8+1 = Y+9. 연결 종료 완료. Sender는 TIME_WAIT 상태로 잠시 대기. 핵심 요약:\nSeq/Ack 번호: 데이터의 순서를 맞추고, 빠진 데이터 없이 잘 받았는지 확인하는 데 사용됩니다. Ack 번호는 ‘다음에 받을 것으로 예상되는 Seq 번호’를 의미합니다. 윈도우 크기 (Win): 수신 측의 버퍼 여유 공간을 송신 측에 알려주어, 송신 측이 과도하게 많은 데이터를 보내지 않도록 조절합니다 (흐름 제어). 수신 측의 처리 속도나 버퍼 상태에 따라 동적으로 변할 수 있습니다. TCP Flags: 연결 설정(SYN), 데이터 전송(PSH, URG), 확인 응답(ACK), 연결 종료(FIN, RST) 등 TCP 연결의 상태를 제어하는 데 사용됩니다. 이 시뮬레이션은 Telnet 통신 중 TCP 레벨에서 패킷이 어떻게 교환되는지 기본적인 흐름을 보여줍니다. 실제 네트워크 환경에서는 지연, 혼잡 제어(Congestion Control) 알고리즘, 재전송 등으로 인해 윈도우 크기 변화나 패킷 교환 순서가 더 복잡해질 수 있습니다."},"title":"TCP TELNET 통신 과정 시뮬레이션"},"/02.inbox/terminal-auto-logging/":{"data":{"":"","-주요-개선-사항-및-작동-원리#💡 주요 개선 사항 및 작동 원리":"2-Script 구조의 안정성:\n메인 스크립트(terminal_auto_logger.sh)는 환경 검사와 설정만 담당하여 역할이 명확합니다. exec를 통해 쉘 프로세스가 Executor 스크립트(_tal_executor.sh)로 완전히 대체됩니다. Executor는 script가 종료될 때까지 기다린 후, 그 종료 상태(성공/실패)를 확인하여 후처리(파일명 변경)를 수행합니다. 이 구조 덕분에 세션 종료 시점의 정보를 파일명에 안정적으로 반영할 수 있습니다. 정확한 파일명 생성:\n세션이 시작되면 .tmp 확장자를 가진 임시 파일에 로그가 기록됩니다. 사용자가 exit 등으로 정상 종료하면 script는 종료 코드 0을 반환하고, 파일명은 ... (시작시간 ~ 종료시간).log 형식으로 변경됩니다. 세션이 kill 명령으로 강제 종료되거나 비정상적으로 끝나면, script는 0이 아닌 종료 코드를 반환하고, 파일명은 ... (시작시간 ~ aborted).log 형식으로 변경되어 문제 상황을 명확히 알려줍니다. 예측 가능한 동작:\ntmux/screen 환경이나 이미 로깅 중인 세션에서는 중복 실행되지 않아 충돌을 원천적으로 방지합니다. 환경 변수명을 TERMINAL_AUTO_LOGGER_ACTIVE로 명확하게 지정하여 다른 프로그램과의 잠재적 충돌 가능성을 최소화했습니다. 로그 디렉토리와 스크립트 위치를 ~/.local 아래로 표준화하여 시스템을 깔끔하게 유지합니다. 이 개선된 솔루션은 요구하신 모든 사항을 만족시키면서, 예측 불가능한 상황에 더욱 잘 대처할 수 있도록 설계되었습니다. 안정적이고 신뢰도 높은 터미널 활동 기록 시스템으로 활용하실 수 있습니다.","1-executor-스크립트-생성#1. \u003cstrong\u003eExecutor 스크립트 생성: \u003ccode\u003e_tal_executor.sh\u003c/code\u003e\u003c/strong\u003e":"이 스크립트는 실제 로깅을 실행하고 세션 종료 후 파일명 변경을 담당하는 핵심 로직입니다. 사용자가 직접 실행하는 것이 아닌, 메인 스크립트에 의해 호출됩니다.\n파일 위치: ~/.local/bin/_tal_executor.sh\n#!/bin/bash # 이 스크립트는 terminal_auto_logger.sh에 의해 호출되는 내부 헬퍼입니다. # 사용자가 직접 실행하지 마세요. # 인자 파싱 TEMP_LOG_FILE=\"$1\" LOG_DIR=\"$2\" PID=\"$3\" TTY_NAME=\"$4\" START_TIMESTAMP=\"$5\" # 'script' 명령으로 실제 로깅 세션 시작 # -q: 시작/종료 메시지 숨김 # -f: 실시간으로 버퍼를 비워 파일에 기록 # -a: 파일에 이어쓰기 (메타데이터를 먼저 기록했으므로 필수) script -qfa \"$TEMP_LOG_FILE\" EXIT_CODE=$? # script 명령의 종료 코드 캡처 # 세션 종료 후 로그 파일 이름 변경 # 임시 로그 파일이 존재하고 내용이 있을 때만 이름 변경을 시도 if [ -s \"$TEMP_LOG_FILE\" ]; then END_TIMESTAMP=$(date +\"%Y%m%d_%H%M%S\") # 종료 코드에 따라 최종 파일명 결정 if [ \"$EXIT_CODE\" -eq 0 ]; then # 정상 종료 (exit, logout 등) END_PART=\"$END_TIMESTAMP\" else # 비정상 종료 (kill, 시스템 다운 등) END_PART=\"aborted\" fi FINAL_LOG_FILE=\"${LOG_DIR}/terminal_(${START_TIMESTAMP} ~ ${END_PART})_${PID}_${TTY_NAME}.log\" mv \"$TEMP_LOG_FILE\" \"$FINAL_LOG_FILE\" else # 세션 동안 아무런 출력이 없었으면 임시 파일 삭제 rm -f \"$TEMP_LOG_FILE\" fi","2-메인-스크립트-개선#2. \u003cstrong\u003e메인 스크립트 개선: \u003ccode\u003eterminal_auto_logger.sh\u003c/code\u003e\u003c/strong\u003e":"이 스크립트는 쉘 설정 파일(.bashrc, .zshrc)에서 호출되며, 모든 안정성 검사와 환경 설정을 담당합니다.\n파일 위치: ~/.local/bin/terminal_auto_logger.sh\n#!/bin/bash # --- 안정성 검사 --- # 1. 'script' 명령어가 없으면 즉시 종료 if ! command -v script \u0026\u003e /dev/null; then echo \"Terminal Auto Logger: 'script' command not found. Logging disabled.\" \u003e\u00262 return 1 fi # 2. 이미 로깅 중이거나(재귀 방지), tmux/screen 세션 내에서는 실행하지 않음 if [ -n \"$TERMINAL_AUTO_LOGGER_ACTIVE\" ] || [ -n \"$TMUX\" ] || [[ \"$TERM\" == screen* ]]; then return 0 fi # --- 로깅 준비 --- # 로그 디렉토리 생성 LOG_DIR=\"$HOME/.local/log/terminal_auto_log\" mkdir -p \"$LOG_DIR\" # 로그 파일명에 사용할 변수 설정 TTY_NAME=$(tty | sed 's|/|_|g' | sed 's|[^a-zA-Z0-9_-]||g') START_TIMESTAMP=$(date +\"%Y%m%d_%H%M%S\") PID=$$ # 종료 후 이름이 변경될 임시 로그 파일 TEMP_LOG_FILE=\"${LOG_DIR}/session_${START_TIMESTAMP}.tmp\" # --- 로깅 시작 --- # 로깅 세션 메타데이터를 임시 파일에 기록 { echo \" SCRIPT_SESSION_START\" echo \"=================================================\" echo \" Project: Terminal Auto Logger\" echo \" User: $(whoami)\" echo \" Host: $(hostname)\" echo \" TTY: $(tty)\" echo \" Shell: $SHELL\" echo \" Started: $(date)\" echo \" Ended: \" echo \"=================================================\" } \u003e \"$TEMP_LOG_FILE\" # 이어쓰기가 아닌 새로 쓰기 # 재귀 실행 방지를 위한 환경 변수 설정 export TERMINAL_AUTO_LOGGER_ACTIVE=1 # 현재 쉘을 Executor 스크립트로 대체하여 실행 # 필요한 모든 정보를 인자로 전달 exec ~/.local/bin/_tal_executor.sh \\ \"$TEMP_LOG_FILE\" \\ \"$LOG_DIR\" \\ \"$PID\" \\ \"$TTY_NAME\" \\ \"$START_TIMESTAMP\"","3-설치-및-설정#3. \u003cstrong\u003e설치 및 설정\u003c/strong\u003e":"1단계: 디렉토리 생성 사용자 로컬 바이너리 디렉토리와 로그 디렉토리를 생성합니다. (~/.local/bin은 많은 시스템에서 자동으로 PATH에 추가됩니다.)\nmkdir -p ~/.local/bin mkdir -p ~/.local/log/terminal_auto_log 2단계: 스크립트 저장 및 권한 설정 위에서 작성한 두 스크립트 코드를 각각 ~/.local/bin/terminal_auto_logger.sh와 ~/.local/bin/_tal_executor.sh에 저장한 후, 실행 권한을 부여합니다.\nchmod +x ~/.local/bin/terminal_auto_logger.sh chmod +x ~/.local/bin/_tal_executor.sh 3단계: 쉘 설정 파일에 적용 (~/.bashrc 또는 ~/.zshrc) 쉘 설정 파일 가장 아래쪽에 다음 코드를 추가합니다.","bash-사용자-bashrc#Bash 사용자 (\u003ccode\u003e~/.bashrc\u003c/code\u003e):":"# Terminal Auto Logger (안정성 강화 버전) # ~/.local/bin 이 PATH에 있는지 확인하고, 없다면 추가 if [[ \":$PATH:\" != *\":$HOME/.local/bin:\"* ]]; then export PATH=\"$HOME/.local/bin:$PATH\" fi if [[ -t 1 \u0026\u0026 -z \"$TERMINAL_AUTO_LOGGER_ACTIVE\" ]]; then source ~/.local/bin/terminal_auto_logger.sh fi","terminal-auto-logger#Terminal Auto Logger":"","zsh-사용자-zshrc#Zsh 사용자 (\u003ccode\u003e~/.zshrc\u003c/code\u003e):":"# Terminal Auto Logger (안정성 강화 버전) # ~/.local/bin 이 PATH에 있는지 확인하고, 없다면 추가 if [[ \":$PATH:\" != *\":$HOME/.local/bin:\"* ]]; then export PATH=\"$HOME/.local/bin:$PATH\" fi if [[ -o interactive \u0026\u0026 -z \"$TERMINAL_AUTO_LOGGER_ACTIVE\" ]]; then source ~/.local/bin/terminal_auto_logger.sh fi 4단계: 적용 source ~/.bashrc (또는 source ~/.zshrc)를 실행하거나 새 터미널을 열면 로깅이 자동으로 시작됩니다.","프로젝트-개요#프로젝트 개요":"프로젝트 이름: terminal auto logger 로그 디렉토리: ~/.local/log/terminal_auto_log 핵심 동작: terminal_auto_logger.sh: 쉘 시작 시 실행되어 로깅 환경을 설정하고, 실제 로깅을 담당하는 Executor 스크립트를 호출합니다. _tal_executor.sh: script 명령을 직접 실행하고, 세션이 종료된 후 로그 파일의 이름을 최종적으로 결정합니다. (내부 헬퍼 스크립트)"},"title":"terminal auto logging"},"/02.inbox/time-%EB%AA%85%EB%A0%B9%EC%96%B4/":{"data":{"":"실제 경과 시간을 나타내는 “Real”, 프로세스에서 사용된 CPU 시간만을 나타내는 “User” 및 “Sys\"는 커널 내에서 실행되는 코드에서 사용된 CPU 시간을 나타냅니다.\nReal(실제 시간): 호출의 시작에서 끝까지의 경과 시간으로, 다른 프로세스에 의해 사용된 시간 조각과 프로세스가 차단된 시간(예를 들어 I/O 완료를 기다리는 경우)을 포함한 모든 경과 시간입니다.\nUser(사용자 모드 시간): 프로세스 내에서 사용자 모드 코드(커널 외부)에서 소비한 CPU 시간입니다. 이는 프로세스를 실행하는 데 사용된 실제 CPU 시간만을 나타냅니다. 다른 프로세스 및 프로세스가 차단된 시간은 이 숫자에 포함되지 않습니다.\nSys(커널 모드 시간): 프로세스 내에서 커널 내에서 실행된 CPU 시간으로, 커널 내에서 시스템 콜 내에서 실행된 CPU 시간을 의미합니다. 이는 여전히 사용자 공간에서 실행되는 라이브러리 코드와는 대조적입니다. “User\"와 마찬가지로 이는 프로세스에 의해 사용된 CPU 시간만을 나타냅니다.\nUser+Sys(사용자 및 커널 모드 시간 합): 이것은 프로세스가 실제로 사용한 CPU 시간을 나타냅니다. 여러 스레드가 있는 경우 (이 프로세스가 여러 프로세서를 가진 컴퓨터에서 실행 중인 경우) 이 값은 일반적으로 “Real\"에서 보고된 경과 시간을 초과할 수 있습니다.\ntime 명령어로 보고된 이 통계는 다양한 시스템 호출로부터 수집됩니다. ‘User’ 및 ‘Sys’는 wait(2) 또는 times(2) (POSIX)에서 나올 수 있습니다. ‘Real’은 gettimeofday(2) 호출에서 얻은 시작 및 종료 시간에서 계산됩니다.\n커널 모드와 사용자 모드에 대한 간단한 소개에서 ‘커널’ 또는 ‘슈퍼바이저’ 모드는 CPU가 운영 중인 특권 모드를 나타냅니다. 일부 특권된 동작은 CPU가 이 모드에서 작동할 때만 수행할 수 있으며 이러한 동작은 응용 프로그램 코드에서 사용할 수 없습니다. “System” 호출은 사용자 모드에서 실행되는 코드를 가지며 이는 C 프로그램에서 직접 호출됩니다. 그러나 뒷면에서는 I/O와 같은 특정 서비스를 수행하기 위해 하나 이상의 시스템 호출을 커널에 발행할 수 있습니다.\n마지막으로 ‘sys’에 대한 추가 정보로 “sys” 시간은 사용자 모드에서 수행할 수 없는 작업들을 나타냅니다. 메모리 할당이나 하드웨어(하드디스크, 네트워크 등)에 접근하는 것과 같은 작업은 커널의 지도에서 수행되며 이 작업은 ‘sys’ 시간으로 계산됩니다. 그러나 단순한 “모든 malloc 호출이 ‘sys’ 시간에 포함될 것\"이라고 할 수는 없습니다. malloc 호출은 자체적인 처리를 수행하며 그 중간에 어딘가에서 커널을 호출할 것입니다. 그 후 커널 호출에서 반환한 후에도 ‘user’ 시간이 일부 소요됩니다. 언제 이 전환이 발생하고 얼마나 많은 것이 커널 모드에서 소요되는지는 구현에 따라 다를 수 있습니다."},"title":"time 명령어"},"/02.inbox/udp%EC%99%80-tcp-demultiplexing-%EC%9D%98-%EC%9D%B4%ED%95%B4/":{"data":{"":"디멀티플렉싱은 수신된 네트워크 패킷을 분석하여 해당 패킷이 어떤 소켓으로 전달되어야 하는지를 결정하는 과정\n멀티플렉싱은 여러 응용 프로그램에서 생성된 데이터를 하나의 네트워크 인터페이스로 전송하는 과정\nUDP와 TCP 디멀티플렉싱의 비교 분석 UDP는 디멀티플렉싱을 위해 목적지 IP 주소와 목적지 포트 번호라는 2-튜플을 사용하는 반면 8, TCP는 송신지 IP 주소, 송신지 포트 번호, 목적지 IP 주소, 목적지 포트 번호로 구성된 4-튜플을 사용합니다 이러한 차이는 각 프로토콜의 연결 지향성 여부에서 비롯됩니다. TCP는 연결 지향적인 특성상 각 연결의 상태를 추적해야 하며, 이는 고유한 4-튜플을 통해 이루어집니다 TCP 연결은 두 특정 호스트의 두 특정 프로세스 간의 전용 통신 채널을 의미하므로, 더 자세한 식별 정보가 필요합니다. TCP의 신뢰성 있는 데이터 전송과 순서 보장 기능은 이러한 연결 상태 유지에 의존합니다. 반면, UDP는 각 데이터그램을 독립적인 단위로 취급하는 비연결형 프로토콜이므로 데이터그램을 올바른 포트에서 수신 대기 중인 애플리케이션에 전달하는 데 목적지 정보만으로 충분합니다. UDP의 이러한 단순성은 디멀티플렉싱 과정을 더 빠르고 효율적으로 만들어줍니다 이는 속도가 중요하고 일부 데이터 손실이 허용되는 애플리케이션(예: 스트리밍, 온라인 게임)에 UDP가 적합한 이유입니다. 반대로, TCP의 복잡한 디멀티플렉싱 방식은 여러 동시 연결을 통해 데이터를 안정적이고 순서대로 전달하는 데 필수적이며 3, 웹 브라우징, 파일 전송, 이메일과 같이 데이터 무결성이 중요한 애플리케이션에 적합합니다.","c-언어-구현#C 언어 구현":"C 언어로 간단한 서버를 작성해 차이를 체험할 수 있습니다.","linux-명령어-사용하기#Linux 명령어 사용하기":"Linux에서 nc(netcat)와 ss 명령어를 사용해 차이를 관찰할 수 있습니다:","tcp-관찰#\u003cstrong\u003eTCP 관찰\u003c/strong\u003e":"TCP 서버 시작: nc -l 12345 다른 터미널에서 연결: nc 127.0.0.1 12345 후 데이터 입력(예: “Hello” 입력). TCP 소켓 확인: ss -t -a 듣기 중인 소켓과 특정 클라이언트 IP, 포트와 연결된 확립된 연결을 볼 수 있습니다. 이 과정에서 UDP는 단일 소켓으로 여러 클라이언트의 데이터를 처리하지만, TCP는 각 연결마다 별도의 소켓을 생성하는 것을 알 수 있습니다.\nESTAB 0 0 127.0.0.1:37479 127.0.0.1:12345 # UDP LISTEN 0 1 0.0.0.0:12345 0.0.0.0:* # TCP ESTAB 0 0 127.0.0.1:12345 127.0.0.1:50972 # TCP","tcp-서버-예제#\u003cstrong\u003eTCP 서버 예제\u003c/strong\u003e":"#include #include #include #include #include #include #define PORT 12345 #define BUFFER_SIZE 1024 int main() { int listenfd, connfd; struct sockaddr_in server_addr, client_addr; char buffer[BUFFER_SIZE]; socklen_t addr_len = sizeof(client_addr); listenfd = socket(AF_INET, SOCK_STREAM, 0); if (listenfd \u003c 0) { perror(\"socket creation failed\"); exit(EXIT_FAILURE); } memset(\u0026server_addr, 0, sizeof(server_addr)); server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = INADDR_ANY; server_addr.sin_port = htons(PORT); if (bind(listenfd, (struct sockaddr*)\u0026server_addr, sizeof(server_addr)) \u003c 0) { perror(\"bind failed\"); exit(EXIT_FAILURE); } if (listen(listenfd, 5) \u003c 0) { perror(\"listen failed\"); exit(EXIT_FAILURE); } printf(\"TCP server listening on port %d\\n\", PORT); while (1) { connfd = accept(listenfd, (struct sockaddr*)\u0026client_addr, \u0026addr_len); if (connfd \u003c 0) { perror(\"accept failed\"); continue; } printf(\"Accepted connection from %s:%d\\n\", inet_ntoa(client_addr.sin_addr), ntohs(client_addr.sin_port)); int n = read(connfd, buffer, BUFFER_SIZE); if (n \u003e 0) { buffer[n] = '\\0'; printf(\"Received: %s\\n\", buffer); } close(connfd); } return 0; } TCP 서버는 각 클라이언트 연결마다 새로운 소켓(connfd)을 생성하며, 이는 4-튜플로 식별됩니다.","udp-관찰#\u003cstrong\u003eUDP 관찰\u003c/strong\u003e":"UDP 서버 시작: nc -u -l 12345 다른 터미널에서 데이터 전송: echo \"Hello\" | nc -u 127.0.0.1 12345 UDP 소켓 확인: ss -u -a 포트 12345에서 듣고 있는 단일 UDP 소켓을 볼 수 있으며, 여러 출처에서 데이터를 받을 수 있습니다.","udp-서버-예제#\u003cstrong\u003eUDP 서버 예제\u003c/strong\u003e":"#include #include #include #include #include #include #define PORT 12345 #define BUFFER_SIZE 1024 int main() { int sockfd; struct sockaddr_in server_addr, client_addr; char buffer[BUFFER_SIZE]; socklen_t addr_len = sizeof(client_addr); sockfd = socket(AF_INET, SOCK_DGRAM, 0); if (sockfd \u003c 0) { perror(\"socket creation failed\"); exit(EXIT_FAILURE); } memset(\u0026server_addr, 0, sizeof(server_addr)); server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = INADDR_ANY; server_addr.sin_port = htons(PORT); if (bind(sockfd, (struct sockaddr*)\u0026server_addr, sizeof(server_addr)) \u003c 0) { perror(\"bind failed\"); exit(EXIT_FAILURE); } printf(\"UDP server listening on port %d\\n\", PORT); while (1) { int n = recvfrom(sockfd, buffer, BUFFER_SIZE, 0, (struct sockaddr*)\u0026client_addr, \u0026addr_len); if (n \u003c 0) { perror(\"recvfrom failed\"); continue; } buffer[n] = '\\0'; printf(\"Received from %s:%d: %s\\n\", inet_ntoa(client_addr.sin_addr), ntohs(client_addr.sin_port), buffer); } return 0; } 이 코드는 단일 소켓으로 모든 클라이언트의 데이터그램을 처리합니다.","udp와-tcp의-demultiplexing-이해하기#UDP와 TCP의 Demultiplexing 이해하기":"UDP와 TCP의 demultiplexing 차이는 각 프로토콜의 연결 방식에서 비롯됩니다. UDP는 비연결형으로, 각 데이터그램을 독립적으로 처리하며 목적지 포트만으로 충분히 데이터를 전달할 수 있습니다. 반면, TCP는 연결 지향형으로, 두 호스트 간의 특정 프로세스 쌍을 식별하기 위해 더 많은 정보(4-튜플)가 필요합니다.\n이를 실제로 느끼기 위해 Linux 명령어를 사용하거나 C 언어로 간단한 서버를 구현할 수 있습니다. 아래에서 단계별로 설명하겠습니다.","udp와-tcp의-비교#UDP와 TCP의 비교":"항목 UDP TCP Demultiplexing Key 목적지 IP, 목적지 포트 (2-튜플) 송신지 IP, 송신지 포트, 목적지 IP, 목적지 포트 (4-튜플) 연결 모델 비연결형, 상태 없음 연결 지향형, 상태 유지 소켓 동작 모든 클라이언트가 하나의 소켓 사용 각 연결마다 별도 소켓 생성 적합한 애플리케이션 스트리밍, 온라인 게임 (속도 중요, 일부 데이터 손실 허용) 웹 브라우징, 파일 전송 (신뢰성, 순서 보장 중요) ss 명령어 출력 “UNCONN” 상태, 하나의 소켓만 표시 수신 대기 및 여러 개의 확립된 연결 표시 이 표에서 알 수 있듯이, UDP는 간단한 방식으로 데이터를 전달하지만 신뢰성이 낮고, TCP는 보다 복잡한 방식으로 데이터를 관리하여 신뢰성을 보장합니다.","멀티-클라이언트-실험#\u003cstrong\u003e멀티 클라이언트 실험\u003c/strong\u003e":"UDP의 경우, 여러 개의 클라이언트에서 nc -u를 사용해 데이터를 전송하면 하나의 소켓에서 모든 데이터를 받을 수 있습니다. TCP의 경우, 여러 개의 클라이언트가 연결하면 ss -t -a 명령어에서 각 클라이언트와 서버 간에 생성된 개별 연결을 확인할 수 있습니다.","추가-고려-사항#추가 고려 사항":"","패킷-분석-도구-사용#\u003cstrong\u003e패킷 분석 도구 사용\u003c/strong\u003e":"Wireshark와 같은 네트워크 패킷 분석기를 사용하면 UDP와 TCP의 패킷 헤더를 직접 확인할 수 있습니다. strace 명령어를 사용하여 시스템 호출을 분석하면, 각각의 프로토콜이 어떻게 소켓을 다루는지 더 깊이 이해할 수 있습니다. 이제 UDP와 TCP의 demultiplexing 방식이 어떻게 다른지, 그리고 그것이 실제 네트워크 애플리케이션에 어떤 영향을 미치는지 직접 체험할 수 있습니다."},"title":"UDP와 TCP Demultiplexing 의 이해"},"/02.inbox/utf-8/":{"data":{"":"GEEK News 꼭 읽어보기 바람\n예시 1: 문자 A는 아스키 문자이며 유니코드 값은 65로, 이는 16진수 0x41(0100 0001)인데, 7비트 이내로 표현 가능하므로 UTF-8로도 0x41로 표현된다. 예시 2: 문자 π는 유니코드 값이 7비트를 벗어난다. 그러나 11비트 이내에 표현이 가능한 비교적 앞쪽에 위치한 문자며, 따라서 그림과 같이 2바이트에 표현이 가능 하다. 예시 3: 문자 한은 한글 문자로 16비트를 모두 사용한다. 마지막 16비트가 1이며 따라서 이를 표현하기 위해서는 그림과 같이 3바이트를 사용해야 한다. 참고로 유니코드에는 완성형 한글 11,172자뿐만 아니라 조합형 자모가 모두 포함되어 있으며, 이처럼 한글의 UTF-8 인코딩 값은 모두 각 문자당 3바이트를 차지한다. 한글 조합형 자모는 (https://namu.wiki/w/UTF-8#s-3]] 영역에 위치한다. 한글 완성형 자모는 U+3130~318F 영역에 위치한다. 한글 완성형 글자는 U+AC00~D7A3(https://namu.wiki/w/UTF-8#fn-8) 영역에 위치한다. 예를 들어 ‘갑’의 유니코드값은 16진수 0xAC11(1010 1100 0001 0001)인데, 이는 총 16비트가 필요하므로 1110 1010 1011 0000 1001 0001 으로 표현한다. 완성형 글자 하나도 3바이트인데, 조합형은 자모 하나하나가 각각 3바이트씩(글자 하나당 6~9바이트) 사용한다. 따라서 일반적으로 완성형 글자를 사용하고, 조합형은 완성형에 없는 옛 한글 등을 쓰기 위해서 사용하는 것이 효율이 좋다. 유니코드 변환기 https://ko.rakko.tools/tools/89/"},"title":"UTF 8"},"/02.inbox/wsl-%EC%97%90%EC%84%9C-%ED%8F%B4%EB%8D%94%EA%B0%80-%EC%B4%88%EB%A1%9D%EC%83%89-%EB%B0%B0%EA%B2%BD%EC%9C%BC%EB%A1%9C-%EB%B3%B4%EC%9D%B4%EB%8A%94-%EC%9D%B4%EC%9C%A0/":{"data":{"":"전제조건 초록색 이유 선택 전제 조건 윈도우 파일과 유닉스 파일의 파일 시스템 차이","ls_clolors-의-ow-변수#LS_CLOLORS 의 ow 변수":"env | grep \"LS_COLORS\" |grep ow 라고 입력하면 ow 변수에 입력된 값이 보인다 (ow=34;42 나의 경우 이미 설정된 값은 이렇다) 이것은 34(전경색 파란색) 42(배경색 초록색) 이다 그러면 ow 쓰기가능한 디렉토리\n조금더 명확히 이해하기 이해해보기 위해 LS_COLORS 을 정확하게 이해해보자 아까 보았던 ~/.bashrc 파일의 일부이다\nif [ -x /usr/bin/dircolors ]; then test -r ~/.dircolors \u0026\u0026 eval \"$(dircolors -b ~/.dircolors)\" || eval \"$(dircolors -b)\" alias ls='ls --color=auto' #alias dir='dir --color=auto' #alias vdir='vdir --color=auto' alias grep='grep --color=auto' alias fgrep='fgrep --color=auto' alias egrep='egrep --color=auto' fi dircolors 명령이 실행가능할 때 AND .dircolos 폴더가 있으면 그것을 사용하고 없으면 dircolors 기본 설정을 사용한다는 의미이다 즉 dircolors가 LS_COLORS 를 설정한다 이후 The LS_COLORS environment variable can change the settings. Use the dircolors command to set it. ls manual 페이지에 처럼 ls 명령이 LS_COLORS 환경변수를 통해 적절히 출력되게 된다\ndircolors 수동 설정 시 적용가능한 변수목록 론: bashrc 파일에서 dircolors 존재하는지 확인 -\u003e dircolors 이 LS_COLORS 변수 설정 -\u003e ls 명령 시행시에 LS_COLORS 변수를 사용해서 출력\n실제 LS_COLORS 를 통해 파일이 보이는 방식을 보여주는 스크립트\necho \"$LS_COLORS\" | sed 's/:/\\n/g' | while IFS== read -r key value; do if [[ -n \"$value\" ]]; then printf \"\\e[${value}m%s\\e[m (%s)\\n\" \"$key\" \"$value\" fi done 또는\ndeclare -A descriptions=( [bd]=\"block device\" [ca]=\"file with capability\" [cd]=\"character device\" [di]=\"directory\" [do]=\"door\" [ex]=\"executable file\" [fi]=\"regular file\" [ln]=\"symbolic link\" [mh]=\"multi-hardlink\" [mi]=\"missing file\" [no]=\"normal non-filename text\" [or]=\"orphan symlink\" [ow]=\"other-writable directory\" [pi]=\"named pipe, AKA FIFO\" [rs]=\"reset to no color\" [sg]=\"set-group-ID\" [so]=\"socket\" [st]=\"sticky directory\" [su]=\"set-user-ID\" [tw]=\"sticky and other-writable directory\" ) # Split LS_COLORS by colon IFS=':' color_prev=\"\" for ls_color in $LS_COLORS; do # Extract color code and file type color=\"${ls_color#*=}\" type=\"${ls_color%=*}\" # Get description if available desc=\"${descriptions[$type]}\" # Print newline when color changes (except first) if [ -n \"$color_prev\" ] \u0026\u0026 [ \"$color\" != \"$color_prev\" ]; then echo fi # Print colored type + description printf '\\e[%sm%s%s\\e[m ' \"$color\" \"$type\" \"${desc:+ ($desc)}\" # Remember last color color_prev=\"$color\" done echo","윈도우-파일시스템ntfs-와-유닉스-파일시스템#윈도우 파일시스템(NTFS) 와 유닉스 파일시스템":"NTFS 파일 시스템은 기본적으로 Windows 운영 체제에서 사용되는 파일 시스템입니다. 유닉스 기반 시스템에서 NTFS 파일 시스템을 마운트하고 접근할 때 권한 설정은 다음과 같은 방식으로 처리됩니다:\nNTFS-3G 드라이버 사용: 대부분의 리눅스 배포판은 NTFS 파일 시스템을 읽고 쓸 수 있는 NTFS-3G 드라이버를 사용합니다. 이 드라이버는 NTFS 파일 시스템의 파일과 디렉터리에 접근할 수 있게 해줍니다.\n마운트 옵션: NTFS-3G를 사용하여 NTFS 파일 시스템을 마운트할 때, 기본적으로 모든 파일과 디렉터리가 특정 사용자의 소유로 설정됩니다. 일반적으로 uid와 gid 마운트 옵션을 사용하여 파일과 디렉터리의 소유자와 그룹을 지정할 수 있습니다.\nsudo mount -t ntfs-3g /dev/sdX1 /mnt/ntfs -o uid=1000,gid=1000 위 명령어에서 /dev/sdX1은 NTFS 파티션, /mnt/ntfs는 마운트 지점, uid=1000과 gid=1000은 특정 사용자의 UID와 GID를 의미합니다.\n권한 설정: NTFS 파일 시스템은 유닉스 파일 시스템과는 다르게 파일 권한을 저장하지 않습니다. 그래서 마운트할 때 지정한 UID와 GID가 모든 파일과 디렉터리의 소유자와 그룹으로 설정됩니다. 또한, umask, fmask, dmask 옵션을 사용하여 파일과 디렉터리의 권한을 설정할 수 있습니다.\nsudo mount -t ntfs-3g /dev/sdX1 /mnt/ntfs -o uid=1000,gid=1000,umask=022 여기서 umask=022는 파일과 디렉터리의 기본 권한을 설정합니다.\n권한 변경: NTFS 파일 시스템은 유닉스 파일 시스템과 달리 파일 시스템 수준에서 파일 권한을 저장하지 않기 때문에, NTFS 파일 시스템에 있는 파일의 권한을 변경하려고 하면 실제로는 변경되지 않습니다. 마운트 옵션을 통해서만 권한을 제어할 수 있습니다.\ntput colors stty -a 위의 두개는 뭐야?? #ModificationRequired","전제조건#전제조건":"wsl 우분투 배포판을 기준 debian 계열은 거이 비슷\nwsl 측에서 바라본 윈도우 파일 시스템(ntfs) 를 wsl 환경에서 윈도우측 파일시스템을 /mnt 폴더 아래에 보조메모리 디바이스 장치 이름 으로 마운트 되어있다 #ModificationRequired\nshinnk@DESKTOP-KRSG68U:/mnt$ mount C:\\ on /mnt/c type 9p (rw,noatime,dirsync,aname=drvfs;path=C:\\;uid=1000;gid=1000;symlinkroot=/mnt/,mmap,access=client,msize=65536,trans=fd,rfd=5,wfd=5) ls, dir, grep, 등등의 명령은 화면에 적절한 색깔을 입혀서 표시할 필요가 있는데 이때 LS_COLORS 라는 환경변수를 참조해서 적절히 색깔을 입혀서 출력한다\n그렇다면 LS_COLORS 환경변수를 확인해보자 set | grep \"LS_COLORS\" 명령을 통해 확인해보면 여러가지 설정이 지정되어있는 것을 확인 할 수 있다 예를 들어 di=01;34: 를 보면 di(directory) 라는 변수에 01;34 라는 변수가 할당되어 있고 (: 는 구분자이다) 01;34는 SRG(select graphic rendition) 의 문법을 따른 방식이다) ANSI escape code 를 참조\n01 굵은 글꼴 bold 효과 ; =\u003e 속성 구분자 34 =\u003e 3비트 컬러 표시에서 전경색(글자색) 34번 색상 파란색 을 나타낸다 shinnk@DESKTOP-KRSG68U:~$ set | grep \"LS_COLORS\" LS_COLORS='rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31' 잠깐 추가적으로 LS_COLORS 환경변수는 정적으로 로드된 것일까?? 최소한 우분투에서는 dircolors 라는 실행파일을 통해 로그인 셸이 실행될 때각 셸(sh, zsh, bash 등등)에 맞는 설정을(LS_COLORS 환경변수에 적절한 값을 로드) 하도록 만든다 아래는 .bashrc 파일의 일부이다 셸에 로그인 될때 .bashrc 가 실행되고 이 파일에서 dircolors 를 실행시킨다 또한 LS_COLORS 를 사용하는 ls,grep 와 같은 프로그램에 옵션을 기본적으로 추가시켜 alias 시켜둔다\n# enable color support of ls and also add handy aliases if [ -x /usr/bin/dircolors ]; then test -r ~/.dircolors \u0026\u0026 eval \"$(dircolors -b ~/.dircolors)\" || eval \"$(dircolors -b)\" alias ls='ls --color=auto' #alias dir='dir --color=auto' #alias vdir='vdir --color=auto' alias grep='grep --color=auto' alias fgrep='fgrep --color=auto' alias egrep='egrep --color=auto' fi echo $TERM # `TERM` 변수의 출력이 `xterm-256color`, `screen-256color`, `tmux-256color`와 같은 값이면 256색을 지원하는 터미널입니다. 실제로는 이렇게 출력 되더락도 24비트 컬러(16,777,216가지 색상)를 지원한다 for i in {0..255}; do printf \"\\x1b[38;5;${i}mcolour${i}\\n\" done # 모든 컬러 확인 모든 디렉토리는 굵은 파란색으로 보여지게 하고 있다\n그렇다면 모든 사용자에게 w 쓰기 권한이 주어진다면 왜 초록색 배경으로 보이게 될까","초록색으로-보이는-이유#초록색으로 보이는 이유":"env | grep \"LS_COLORS\" |grep ow 라고 입력하면 ow 변수(모든 사용자가 쓰기가능한 디렉토리)에 입력된 값이 보인다 아까 보았던 LS_COLORS 에 설정된 값중 ow 변수를 확인해 보았다 (ow=34;42 나의 경우 이미 설정된 값은 이렇다) 이것은 34(전경색 파란색) 42(배경색 초록색) 이다 윈도우 파일시스템인 ntfs 의 경우 유닉스에서 관리하는 일반적인 ext4 zfs 등등의 파일시스템과는 달리 파일의 권한을 저장하는 방식이 다르다 (ACL 이라고 하는데 아직 모르겠다) 그런데 wsl 측에서 윈도우 파일 시스템을 마운트 할 때 모든 파일(폴더 포함)에 쓰기 권한을 (rwx 중 x 를 설정 해두었다) wsl 의 사용자와 윈도우 사용자가 다르기 때문에 파일 이동 및 수정을 자유롭게 하기 위해서 이렇게 한것 같다 그래서 ow 변수에 설정된 값이 작동하는 것이다 말이 매우 길었지만 결론은 매우 간단하다(?)\n윈도우측 사용자와 wsl linux 측 사용자의 차이로 인한 파일 이동 및 수정에 불편함을 만들지 않기 위해 모든 사용자가 쓰기 가능한 디렉토리라고 정하였고 이때 linux 에서는 윈도우 측 파일에 외부 사용자의 쓰기(x) 권한이 등록 되어 있으므로 사용자가 이것을 건들 가능성이 있으니 보안의 목적으로 특별한 색깔로 보였던 것이다","추가-전제-조건#추가 전제 조건":""},"title":"wsl 에서 폴더가 초록색 배경으로 보이는 이유"},"/02.inbox/x86-64-%EB%A0%88%EC%A7%80%EC%8A%A4%ED%84%B0-%EC%B5%9C%EC%86%8C-%EC%84%A4%EB%AA%85/":{"data":{"":"x86-64 아키텍처에서 각 레지스터는 특정 목적이나 일반적인 연산에 사용됩니다. 이들은 64비트 레지스터이며, 일부는 하위 32비트, 16비트, 8비트 단위로도 사용할 수 있습니다. 여기서는 주요 레지스터와 그 역할을 설명하겠습니다.","1-windows-x64-abi#\u003cstrong\u003e1. Windows x64 ABI\u003c/strong\u003e":"첫 번째~네 번째 인수: RCX, RDX, R8, R9 레지스터에 전달 반환값: RAX 레지스터 나머지 인수: 스택에 저장","2-linux-x64-abi-system-v#\u003cstrong\u003e2. Linux x64 ABI (System V)\u003c/strong\u003e":"첫 번째~여섯 번째 인수: RDI, RSI, RDX, RCX, R8, R9 레지스터에 전달 반환값: RAX 레지스터 나머지 인수: 스택에 저장","레지스터-크기#\u003cstrong\u003e레지스터 크기\u003c/strong\u003e":"x86-64에서 각 레지스터는 이름에 따라 하위 크기를 참조할 수 있습니다.\n레지스터 이름 크기 (비트) 설명 RAX 64비트 전체 레지스터 EAX 32비트 하위 32비트 AX 16비트 하위 16비트 AH/AL 8비트 상위 8비트(AH) / 하위 8비트(AL) 예를 들어, RAX의 하위 16비트에 접근하려면 AX를 사용하며, 하위 8비트는 AL을, 상위 8비트는 AH를 통해 접근할 수 있습니다.","범용-레지스터-general-purpose-registers#\u003cstrong\u003e범용 레지스터 (General-Purpose Registers)\u003c/strong\u003e":"레지스터 역할/사용 목적 RAX - 주로 산술 연산(곱셈, 나눗셈)의 결과 저장\n- 함수 호출 시 반환값 저장 RBX - 일반 데이터 저장 (callee-saved: 함수 호출 후 유지됨) RCX - 반복 연산의 카운터로 사용 (loop 명령어에서 사용)\n- 함수 호출 시 세 번째 인수 전달 (Windows x64 ABI 기준) RDX - 입출력 연산 및 곱셈/나눗셈에서 사용- 함수 호출 시 두 번째 인수 전달 RSI - 문자열 조작에서 소스 주소 (Source Index)\n- 함수 호출 시 첫 번째 인수 전달 (Linux x86-64 ABI 기준) RDI - 문자열 조작에서 대상 주소 (Destination Index)\n- 함수 호출 시 첫 번째 인수 전달 (Windows x64 ABI 기준) RBP - 베이스 포인터 (Base Pointer)\n- 함수 호출 시 스택 프레임을 추적 RSP - 스택 포인터 (Stack Pointer)\n- 현재 스택의 최상단을 가리킴 R8~R15 - 추가 범용 레지스터\n- 함수 호출 시 추가 인수 전달 (Linux 및 Windows x64 ABI)","세그먼트-레지스터#\u003cstrong\u003e세그먼트 레지스터\u003c/strong\u003e":"레지스터 역할/사용 목적 CS 코드 세그먼트 (Code Segment) DS 데이터 세그먼트 (Data Segment) SS 스택 세그먼트 (Stack Segment) ES, FS, GS 추가 세그먼트\n- 주로 OS 및 특정 상황에서 사용","실제-사용-예시#\u003cstrong\u003e실제 사용 예시\u003c/strong\u003e":"산술 연산\nmov rax, 5 ; RAX에 5 저장 add rax, 3 ; RAX에 3 더하기 함수 호출\nmov rdi, 10 ; 첫 번째 인수에 10 전달 (Linux x64 기준) call my_function ; 함수 호출 스택 사용\npush rax ; RAX 값을 스택에 저장 pop rbx ; 스택에서 값을 가져와 RBX에 저장 레지스터와 스택의 관계 또는 함수 호출 규약에 대해 더 알고 싶다면 말씀해주세요!","특수-목적-레지스터#\u003cstrong\u003e특수 목적 레지스터\u003c/strong\u003e":"레지스터 역할/사용 목적 RIP - 명령 포인터 (Instruction Pointer)\n- 현재 실행 중인 명령어의 주소 RFLAGS - 플래그 레지스터\n- 연산 결과의 상태(예: 캐리, 오버플로, 제로 등) 저장 RSP - 스택 포인터\n- 함수 호출 및 지역 변수 할당 관리 RBP - 베이스 포인터\n- 스택 프레임의 기준점 역할","함수-호출-규약-calling-convention#\u003cstrong\u003e함수 호출 규약 (Calling Convention)\u003c/strong\u003e":""},"title":"x86 64 레지스터 최소 설명"},"/02.inbox/xmap-%EC%B6%9C%EB%A0%A5/":{"data":{"":"%20image%2020241207204591.png)\n2910149: ./a.out 프로세스 ID 2910149의 실행 파일 ./a.out에 대한 메모리 맵입니다. Address Kbytes RSS Dirty Mode Mapping 각 열의 의미: Address: 메모리 주소 Kbytes: 해당 영역의 크기(KB) RSS: 실제 메모리에 올라간 크기(KB) Dirty: 수정된 페이지 수(KB) Mode: 메모리 접근 권한 Mapping: 매핑된 파일이나 영역의 설명 0000561ff3b48000 4 4 4 r---- a.out 실행 파일의 읽기 전용 영역입니다. 0000561ff3b49000 4 4 4 r-x-- a.out 실행 권한이 있는 코드 영역입니다. 0000561ff3b4a000 4 4 4 r---- a.out 추가적인 읽기 전용 데이터 영역입니다. 0000561ff3b4b000 4 4 4 r---- a.out 또 다른 읽기 전용 영역입니다. 0000561ff3b4c000 4 4 4 rw--- a.out 쓰기 및 읽기 가능한 데이터 영역입니다(예: 전역 변수). 0000561ff4380000 132 4 4 rw--- [ anon ] 익명 메모리 매핑 영역으로 힙(heap) 영역일 수 있습니다. 00007f79538e0000 4 0 0 ----- [ anon ] 보호된 메모리 영역입니다. 00007f79538e1000 8192 8 8 rw--- [ anon ] 스레드 스택 영역으로 8MB의 크기를 갖습니다. 그 이후 줄들은 각 스레드별 스택 영역을 나타냅니다(스레드마다 약 8MB씩 할당): 00007f79547fa000부터 00007f7956fff000까지 반복적으로 나타나는 8MB 크기의 rw--- [ anon ] 영역들은 각 스레드의 스택입니다. 마지막 부분:\n00007f795d0e6000부터 00007f795d356000까지는 라이브러리(libc.so.6, ld-linux-x86-64.so.2)의 메모리 매핑 영역입니다. 00007ffc9bac7000 132 16 16 rw--- [ stack ]는 메인 스레드의 스택입니다. 00007ffc9bbd2000부터는 환경 변수나 프로그램 인자들이 저장된 영역일 수 있습니다. void* child_routine(void* param) { int id = (int)param; printf(\"My thread ID %i\\n\", id); sleep(100); pthread_exit(0); } int main() { pthread_t thread[NUMTHREAD]; int param[NUMTHREAD]; void* return_value[NUMTHREAD]; for (int i = 0; i \u003c NUMTHREAD; i++) { param[i] = i; pthread_create(\u0026thread[i], 0, child_routine, (void*)param[i]); } for (int i = 0; i \u003c NUMTHREAD; i++) { pthread_join(\u0026thread[i], 0); } } shinnk@DESKTOP-KRSG68U:~$ ./a.out \u0026 [1] 2910149 shinnk@DESKTOP-KRSG68U:~$ My thread ID 0 My thread ID 1 My thread ID 2 My thread ID 3 My thread ID 4 My thread ID 5 My thread ID 6 My thread ID 7 My thread ID 8 My thread ID 9 pmap -x 2910149 2910149: ./a.out Address Kbytes RSS Dirty Mode Mapping 0000561ff3b48000 4 4 4 r---- a.out 0000561ff3b49000 4 4 4 r-x-- a.out 0000561ff3b4a000 4 4 4 r---- a.out 0000561ff3b4b000 4 4 4 r---- a.out 0000561ff3b4c000 4 4 4 rw--- a.out 0000561ff4380000 132 4 4 rw--- [ anon ] 00007f79538e0000 4 0 0 ----- [ anon ] 00007f79538e1000 8192 8 8 rw--- [ anon ] 00007f79547f9000 4 0 0 ----- [ anon ] 00007f79547fa000 8192 8 8 rw--- [ anon ] 00007f7954ffa000 4 0 0 ----- [ anon ] 00007f7954ffb000 8192 8 8 rw--- [ anon ] 00007f79557fb000 4 0 0 ----- [ anon ] 00007f79557fc000 8192 8 8 rw--- [ anon ] 00007f7955ffc000 4 0 0 ----- [ anon ] 00007f7955ffd000 8192 8 8 rw--- [ anon ] 00007f79567fd000 4 0 0 ----- [ anon ] 00007f79567fe000 8192 8 8 rw--- [ anon ] 00007f7956ffe000 4 0 0 ----- [ anon ] 00007f7956fff000 8192 8 8 rw--- [ anon ] 00007f79577ff000 4 0 0 ----- [ anon ] 00007f7957800000 8192 2048 2048 rw--- [ anon ] 00007f7958000000 132 4 4 rw--- [ anon ] 00007f7958021000 65404 0 0 ----- [ anon ] 00007f795c0e1000 4 0 0 ----- [ anon ] 00007f795c0e2000 8192 8 8 rw--- [ anon ] 00007f795c8e2000 4 0 0 ----- [ anon ] 00007f795c8e3000 8204 16 16 rw--- [ anon ] 00007f795d0e6000 160 160 0 r---- libc.so.6 00007f795d10e000 1620 1024 0 r-x-- libc.so.6 00007f795d2a3000 352 128 0 r---- libc.so.6 00007f795d2fb000 4 0 0 ----- libc.so.6 00007f795d2fc000 16 16 16 r---- libc.so.6 00007f795d300000 8 8 8 rw--- libc.so.6 00007f795d302000 52 20 20 rw--- [ anon ] 00007f795d31a000 8 4 4 rw--- [ anon ] 00007f795d31c000 8 8 0 r---- ld-linux-x86-64.so.2 00007f795d31e000 168 168 0 r-x-- ld-linux-x86-64.so.2 00007f795d348000 44 44 0 r---- ld-linux-x86-64.so.2 00007f795d354000 8 8 8 r---- ld-linux-x86-64.so.2 00007f795d356000 8 8 8 rw--- ld-linux-x86-64.so.2 00007ffc9bac7000 132 16 16 rw--- [ stack ] 00007ffc9bbd2000 16 0 0 r---- [ anon ] 00007ffc9bbd6000 8 4 0 r-x-- [ anon ] ---------------- ------- ------- ------- total kB 150272 3772 2236"},"title":"xmap 출력"},"/02.inbox/yt-dlp-%EB%AA%85%EB%A0%B9%EC%96%B4-%EB%AA%A8%EC%9D%8C/":{"data":{"":"yt-dlp -F # 다운받을 수 있는 모든 포멧종류 yt-dlp -f [{포멧 id},{확장자}] # 포멧 지정 다운 yt-dlp -x --audio-format [오디오 포맷] [URL]","-f-표시-목록#-F 표시 목록":"ID: 동영상 화질/오디오 옵션의 고유 식별자입니다. EXT: 파일 확장자입니다. 일반적으로 mp4, webm, m4a 등이 사용됩니다. RESOLUTION: 동영상의 해상도입니다. 예를 들어 1920x1080은 1080p, 1280x720은 720p를 의미합니다. FPS: 동영상의 프레임 레이트입니다. 초당 프레임 수를 나타냅니다. CH: 오디오 채널 수입니다. 일반적으로 2채널 스테레오 오디오가 사용됩니다. FILESIZE: 파일 크기입니다. TBR: 평균 비트레이트(Transmission Bitrate)입니다. 동영상 및 오디오의 평균 데이터 전송률을 나타냅니다. PROTO: 동영상 스트리밍 프로토콜입니다. 일반적으로 https, m3u8 등이 사용됩니다. VCODEC: 동영상 코덱입니다. 예를 들어 avc1.4D401F는 H.264 코덱을 의미합니다. VBR: 동영상 비트레이트입니다. ACODEC: 오디오 코덱입니다. 예를 들어 mp4a.40.2는 AAC 코덱을 의미합니다. ABR: 오디오 비트레이트입니다. ASR: 오디오 샘플링 레이트입니다. MORE INFO: 추가 정보입니다. 화질, 오디오 옵션 등에 대한 설명이 포함됩니다. 이 정보를 통해 동영상의 화질, 오디오 품질, 파일 크기 등을 확인할 수 있습니다. 사용자의 네트워크 환경이나 기기 성능에 따라 적절한 옵션을 선택할 수 있습니다."},"title":"yt dlp 명령어 모음"},"/02.inbox/zone.identifier-%EC%82%AD%EC%A0%9C/":{"data":{"":". 현재 폴더 아래의 “:Zone.Identifier” 이 뒤에 붙은 모든 파일을 삭제\nfind . -name \"*:Zone.Identifier\" -type f -delete 어떤 기능을 하는 명령어인지 알아봅시다."},"title":"Zone.Identifier 삭제"},"/06.university/%EC%95%84%ED%82%A4%ED%85%8D%EC%B3%90-%EA%B8%B0%EB%A7%90%EA%B3%A0%EC%82%AC-%EB%B2%94%EC%9C%84/":{"data":{"":"기말 고사 범위는 다음과 같습니다. 컴퓨터아키텍쳐 (0773) 6/10 (화) 오후 7시 ~ 8시 제5공학관 Y5120 컴퓨터아키텍쳐 (0774) 6/11 (수) 오후 3시 ~ 4시 창조관 Y2446\n2장 2.3 명령어 파이프라이닝 5장 기억장치 5.7 차세대 비활성 기억장치는 제외 8장 고성능 컴퓨터시스템 구조\n교과서 3장과 5장에서 다음을 제외합니다. 3.5.4 준안정성 3.5.5 동기화기 3.5.6 분해능 시간 유도 3.6 병렬처리 5.2.1에서 전치가산기 관련 부분 5.6 논리배열 HDL 관련부분도 제외합니다."},"title":"아키텍쳐 기말고사 범위"},"/06.university/%EC%BA%90%EC%8B%9C-%EB%A7%A4%ED%95%91-%EB%B0%A9%EC%8B%9D%EC%9D%98-%EC%9D%B4%ED%95%B4/":{"data":{"":"","-1-직접-사상-방식-direct-mapping### 1. 직접 사상 방식 (Direct Mapping)":"직접 사상 방식에서는 주기억장치의 각 블록이 캐시의 정해진 단 하나의 라인에만 저장될 수 있습니다.\n주소 구조\n캐시 라인이 16개이므로, 라인 번호를 지정하기 위해 log2​(16)=4비트가 필요합니다 (Line 필드). 나머지 비트는 Tag가 됩니다: 12−4(Line)−4(Word)=4비트. | Tag (4비트) | Line (4비트) | Word (4비트) |\n| :———: | :———-: | :———-: |\n동작 예시\nCPU가 메모리 주소 150번지(0000 1001 0110₂)의 데이터를 요청합니다. 주소를 분해합니다: Tag: 0000 Line: 1001 (9번 라인) Word: 0110 캐시는 9번 라인으로 가서 Tag를 확인합니다. 만약 9번 라인의 Tag가 0000과 일치하면 **캐시 히트(Hit)**가 발생하고, 해당 블록의 6번째(0110₂) 바이트를 CPU에 전달합니다. Tag가 다르거나 라인이 비어있으면 **캐시 미스(Miss)**가 발생합니다. 주기억장치의 150번지가 포함된 블록(9번 블록, 144~159번지)을 통째로 가져와 캐시의 9번 라인에 저장하고, Tag 필드를 0000으로 갱신합니다.","-2-완전-연관-사상-방식-fully-associative-mapping### 2. 완전 연관 사상 방식 (Fully Associative Mapping)":"완전 연관 사상 방식에서는 주기억장치의 블록이 캐시의 어떤 라인으로든 저장될 수 있습니다.\n주소 구조\n정해진 라인이 없으므로 Line 필드가 없습니다. Tag가 주소의 대부분을 차지합니다: 12−4(Word)=8비트. Tag (8비트) Word (4비트) 동작 예시\nCPU가 메모리 주소 150번지(0000 1001 0110₂)의 데이터를 요청합니다. 주소를 분해합니다: Tag: 0000 1001 Word: 0110 캐시는 모든 16개 라인의 Tag를 동시에 비교하여 0000 1001과 일치하는 Tag가 있는지 찾습니다. 일치하는 Tag를 찾으면 **캐시 히트(Hit)**가 발생하고, 해당 블록의 6번째(0110₂) 바이트를 CPU에 전달합니다. 일치하는 Tag가 없으면 **캐시 미스(Miss)**가 발생합니다. 주기억장치에서 해당 블록(144~159번지)을 가져와 캐시의 비어있는 아무 라인에 저장합니다. 만약 빈 라인이 없다면, 특정 교체 정책(예: LRU)에 따라 기존 라인 중 하나를 교체합니다.","-3-세트-연관-사상-방식-set-associative-mapping### 3. 세트 연관 사상 방식 (Set-Associative Mapping)":"세트 연관 사상은 직접 사상과 완전 연관 사상을 절충한 방식입니다. 캐시 라인들을 여러 개의 **세트(Set)**로 묶고, 블록은 정해진 세트 안의 어떤 라인으로든 저장될 수 있습니다.\n여기서는 2-Way 세트 연관 사상을 예시로 들겠습니다. (하나의 세트가 2개의 라인을 가짐)\n세트 계산\n세트의 수 = 라인 수 / Way 수 = 16/2=8개의 세트. 주소 구조\n세트 번호를 지정하기 위해 log2​(8)=3비트가 필요합니다 (Set 필드). 나머지 비트는 Tag가 됩니다: 12−3(Set)−4(Word)=5비트. | Tag (5비트) | Set (3비트) | Word (4비트) |\n| :———: | :———: | :———-: |\n동작 예시\nCPU가 메모리 주소 150번지(0000 1001 0110₂)의 데이터를 요청합니다. 주소를 분해합니다: Tag: 0000 1 Set: 001 (1번 세트) Word: 0110 캐시는 1번 세트로 갑니다. 1번 세트에는 2개의 라인이 있습니다. 이 두 라인의 Tag만을 비교하여 0000 1과 일치하는지 확인합니다. 일치하는 Tag를 찾으면 **캐시 히트(Hit)**가 발생합니다. 일치하는 Tag가 없으면 **캐시 미스(Miss)**가 발생합니다. 주기억장치에서 해당 블록을 가져와 1번 세트 내의 비어있는 라인에 저장합니다. 만약 1번 세트의 두 라인이 모두 사용 중이라면, 교체 정책에 따라 둘 중 하나를 교체합니다.","-요약-비교### 요약 비교":"구분 주소 구조 (Tag-Index-Offset) 특징 장점 단점 직접 사상 4 - 4 - 4 블록 → 특정 라인 (1:1) 구현이 간단하고 빠름 특정 라인에 충돌이 잦음 (Conflict Miss) 완전 연관 8 - 없음 - 4 블록 → 모든 라인 (1:N) 매우 유연하여 히트율이 높음 모든 태그를 비교해야 하므로 회로가 복잡하고 비쌈 세트 연관 5 - 3 - 4 블록 → 특정 세트 (1:K) 직접 사상과 완전 연관의 장점을 절충함 직접 사상보다 복잡하고 완전 연관보다 히트율이 낮을 수 있음","공통-시스템-환경-설정#\u003cstrong\u003e공통 시스템 환경 설정\u003c/strong\u003e":"주기억장치 용량: 4KB (4096 바이트). 따라서 주소는 12비트가 필요합니다 (212=4096). 워드(Word)의 크기: 4 바이트. (32비트 시스템에서 흔히 볼 수 있는 구조) 블록(Block) 및 캐시 라인(Line) 크기: 4 워드. 즉, 4워드×4바이트/워드=16바이트 입니다. 캐시 메모리 크기: 256 바이트. 캐시 라인의 수: 256바이트/16바이트/라인=16개의 라인을 가집니다. 메모리 주소는 12비트이며, 이 주소를 어떻게 Tag, Line(or Set), Word(or Offset) 필드로 나누는지가 각 사상 방식의 핵심입니다.\nWord(Offset) 필드: 블록 크기가 16바이트이므로, 블록 내 특정 바이트를 가리키기 위해 log2​(16)=4비트가 필요합니다."},"title":"캐시 매핑 방식의 이해"},"/06.university/databaseuniversity/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EB%94%94%EC%9E%90%EC%9D%B8/":{"data":{"":"","1정규화#1정규화":"앨범이름 가수명 곡명 1집 에일라 A,B,C,D … 1FN : 테이블을 구성하는 모든 요소들이 atomic(원자적이다) 즉 분해 불가능하다 위의 엘범 테이블의 경우 곡명에 여러가지 곡이 들어가 있고 만약 각각을 parsing 해서 사용하게 되면 첫번째 정규화 규칙을 지키지 못하게 된다 하지만 여기서 나는 곡명을 파싱하지 않고 그냥 통째로만 사용할 꺼야 라고 한다면 제 1정규화가 되어있지 않다고 말할 수 없다","boyce-codd-normal-form-bcnf#Boyce-Codd Normal Form BCNF":"trivial 하지 않은 모든 함수종속에서 결정자가 superKey인 경우 BCNF","lossless-join-decomposition-revisited#Lossless-join Decomposition Revisited":"R1 과 R2 의 교집합 attribute 가 superkey 일 때 원본으로 되돌릴수 있다 즉 분해할 때 superkey 를 각각 가져가야 한다 3단계일때","meterialized-view#meterialized view":"from 의 경우 미리 1번만 조인 시켜서 작동하게 되는데 즉 1회성으로 메모리에 하지만 meterialized view 는 물리적으로 보조메모리에 저장시킨다\nBCNF 는 데이터중복을 방지하여 어노몰리 문제가 사라지지만 함수 의존성을 보장하지 못할 수도 있다 그래서 3NF 를 사용하여 데이터 중복이 되더라도 즉 어노몰리 문제가 발생하더라도 함수의존성을 보존하는 것을 목표로 한다\n분해 문제 풀어보기 3nf 는 일정수준의 중복이 필연적으로 발생하게 된다","third-normal-form-motivation#Third Normal Form: Motivation":"","기능적-종속성-functional-dependency#기능적 종속성 functional dependency":"a -\u003e b\na functionally determines b a, b : set of attributes 집합이 가능하다 two tuples with same a have same b a가 정해지면 반드시 b가 정해진다. a 값이 같은데 b 값이 다를 수 없다 실제 Application의 규칙에 의해 정해짐(실 세계의 규칙을 반영)\n예시) student 테이블 student = {ID, name, gen, …} ID -\u003e name gen … ID 는 이름 성별 등등을 결정한다 즉 id가 같은 tuple 은 다른 이름을 가질 수 없다\ntrivial 이라는 것은 customer-name, loan-number →customer-name customer-name →customer-name 당연히 기능적 종속성을 만족하는 관계이다\nclosure set of functional dependency F : 함수 종속의 집합 F+ : F 로 부터 추론 가능한 모든 집합\nattribute set closure (AG)+ 는 AG 로 만들 수 있는 모든 Attrubute 집합이다 AG 가 후보키 인지 확인법\n슈퍼키가 맞는가 즉 AG 를 통해 R 을 구성할 수 있는가 AG 의 부분집합이 존재하는가 함수 분해를 통해 무손실 분해를 증명할 수 있다","나쁜-디자인과-좋은-디자인#나쁜 디자인과 좋은 디자인":"$R = in_dept(ID, name, salary, dept_name, building, budget)$\n나쁜 디자인 정보의 중복: 중복 데이터는 아래의 이상현상에서 자세히 나타난다 dept_name -\u003ebuilding, budget : functional dependency 관계로 building, budget 은 정보의 중복이 발생할 수 있다 이상 현상: Anomaly Insertion Anomaly:loan-number 없이branch-name 등 insert 불가 Deletion Anomaly: 어떤 branch의 마지막 loan을 delete하면 branch 자체가 사라짐 Update Anomaly: 어떤 특정한 branch의 정보(예: Downtown의assets) 를 update하면 해당되는 튜플들을 모두 업데이트해야 함 한개라도 실패하면 안된다 Decomposition 이 필요하다는 결론 중복 데이터를 최소화 정보를 보존 하면서 분리 함수 종속성 유지 (BCNF) functional dependency 는 현실의 실세계의 돌아가는 법칙을 반영한 것이다","손실분해-lossy-decomposition#손실분해 Lossy Decomposition":"분해를 할 때 정보를 모두 저장되어 있는 채로 분리할 수 있어야 한다\nBranch = (b_name, b_city, asset), Loan = (loan#, c_name, amount)\n문제점: 상관 관계가 없어짐 (연결 정보의 손실) Called a Connection Trap Branch = (b_name, b_city, asset), Loan = (loan#, c_name, amount, b_city) natural join시 tuple 증가 information(relationship) 상실 잘못된 상관 관계(b_city) 정확하지 않은 정보가 늘어나는 것 또한 손실분해라고 한다\n즉 분해를 할 때 Lossless-join Decomposition 을 해야한다 분해를 하면 자연조인시(공통 attribute 가 존재할 때) 본래의 원본 테이블보다 크거나 같다 같을 때 만을 Lossless-join Decomposition 이라고 한다 분해를 할 때 아래의 것을 본래는 고려하면서 분해를 해야한다\nFunctional Dependencies multivalued dependencies (we will not cover this!) : 어떤 함수 종속도 존재하지 않은 분해의 무손실 분해를 보장할 수 있는 다중값 종속","정규화#정규화":"1NF : 데이터는 원자적이어야 한다(Domain is atomic if its elements are considered to beindivisible) 2NF second nomal form 3NF BCNF 4NF"},"title":"데이터베이스 디자인"},"/06.university/databaseuniversity/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EC%9A%A9%EC%96%B4-%EC%A0%95%EC%9D%98-%EB%B0%8F-relation-algebra/":{"data":{"":"","additional-operation#additional operation":"set intersection(교집합): $r\\cap s = r -(r-s)$ Natural join(자연 조인): $r \\bowtie s = \\sigma_{r.A_1 = S.A_1 \\land r.A_2 = s.A_2 \\land \\ldots \\land r.A_n = s.A_n}(R \\times S)$ product 중복 제거 cartecian product 에서 동일 attribute 또는 동일 domain 의 값을 Theta join(세타 조인) Equi join(등가 조인): $r \\bowtie s$, $r\\bowtie_\\theta s = \\sigma_\\theta(r \\times s)$ select + product 지정된 조건을 만족하는 모든 튜플 조합 특히 조건에 = 등호의 조건이 들어갈 때 equi join 이라고 부른다 Assignment Operation(대입 연산) : $temp1 \\leftarrow r \\times s$ 일종의 변수 설정 Outer join(외부 조인) : ⟕, ⟖, ⟗ 좌측 우측 양쪽 순서로 table 을 null 값이 들아가더라도 join 하여 projection 한다","additional-operation의-primitive-opration-을-통한-구현#additional operation의 primitive opration 을 통한 구현":"$r \\bowtie s = \\pi_{R.A_1, R.A_2, \\ldots, R.A_n, S.B_1, S.B_2, \\ldots, S.B_m}(\\sigma_{R.A_i = S.A_i}(r \\times s))$","advanced-topics#advanced topics":"Division(): $r\\div s$ table S의 모든 tuple 과 관련있는 R 의 tuple 반환 여러 행으로부터 단일 결과 값을 계산하는데 사용된다","create-table-table-생성#create table (table 생성)":"","database-language#database language":"","database-의-수학적-해석#database 의 수학적 해석":"","entity---relationship-model#Entity - relationship model":"","extended-relational-algebra-operations#Extended Relational-Algebra Operations":"primitive operation 으로는 표현할 수 없는 연산들\nGeneralized Projection( 일반화 수직선택(투영) ) : $\\Pi_{F_1,F_2,….,Fn}(r)$ projection 에서의 $\\Pi_a(r)$ a 는 attribute 명이 들어가지만, 속성 값을 계산하거나 수정하는 산술식 대입이 가능하다 또한 상수 또한 들어갈 수 있다 (상수의 경우 ) Aggregate function ( 집계 함수 ) : ${G_1,G_2,G_3,G_4} \\Gamma{F_1(A_1), F_2(A_2), F_3(A_3), F_4(A_4)}(R)$ G1: attribute =\u003e 어떠한 그룹(단위)로 연산을 적용할 것이냐 F1(A1): 연산적용을 통해 새로 만들어진 attribute value 들의 평균, 최소, 최대, 합, 개수 를 새로운 attribute 로 하여 table 을 생성 ex) ${dept_name} \\Gamma{avg(salary)\\ as\\ avg_sal}(R)$ : dept_name, avg_sal attribute 를 갖는 table","netraul-join-과-inner-join-의-차이#netraul join 과 inner join 의 차이":"netural join 의 경우 동일한 attribute 이름을 기준으로 서로를 묶지만 inner join 의 경우 임의로 어떠한 attribute 를 같은 기준으로 join 할지 선택할 수 있다","null#NULL":"null 의 산술연산은 null 이다 Aggregate function ( 집계 함수 ) 는 avg max 등 계산시에 null을 무시한다 비교 연산에서 NULL 과의 비교는 새로운 진리값 (unknown) 을 반환한다 (“1 \u003c null”) (unknown or true) = true (unknown or false) = unknown (unknown or unknown) = unknown (true and unknown) = unknown, (false and unknown) = false, (unknown and unknown) = unknown (not unknown) = unknown","outer-join-에-대한-이해#outer join 에 대한 이해":"^a02478 cartasian product 의 경우 모든 가능한 조합을 모두 표기하기 때문에 이러한 일이 발생하지 않는다 하지만 동일한 두개의 attribute value 하나의 value 로 join (netural join 등) 할 때 가능하지 않은 조합 null 도 표기하고 싶을 때 문제가 발생한다 즉 정보 손실을 방지하는 조인 연산의 확장","procedural-language#Procedural language":"sql(non procedural) 문이 내부적으로 처리하는 언어","procedural-language-relation-algebra-문제#procedural language (relation algebra) 문제":"컴퓨터공학과, 교수, 교번 관계는 교수 table 만으로 확인 가능하다 $\\Pi_{\\text{교수.교 번,교수.이름}}(\\sigma_{\\text{교수.학과} = \\text{“컴퓨터공학과”}}(교수))$ and 의 표시는 , 가 아닌 $\\land$ 표기가 맞다 학과명 학과장 이름 교수 table 과 학과 table 을 동시에 확인해야 한다 $\\Pi_{\\text{교수.학과,교수.이름}}(\\sigma_{\\text{교수.학과=학과.학과명,교수.교번=학과.학과장 }}(교수 \\times 학과))$ //product 구현 $\\Pi_{\\text{교수.학과,교수.이름}}({\\text{교수}}\\bowtie{\\text{학과}} )$ // join구현 최적화가 가능한가?? primitive 연산으로는 불가능하지 않나?? 학생 교수의 번호, 이름 =\u003e 학생 교수 table 동시 확인(rename 후 합집합) $(\\rho_{\\text{학생(번호,이름)}}(\\Pi_{학생.학번, 학생.이름}(학생)))\\cup(\\rho_{\\text{교수(번호,이름)}}(\\Pi_{교수.교번, 교수.이름}(교수)))$ $\\cup, -, \\times, \\bowtie$ binary 연산 이후 table 의 이름은 무었인가?? 교집합 $R \\cap S$ 을 primitive operation 으로만 표현하라 $R \\cup S - (R-S) - (S-R) = R \\cap S$ natural join $R \\bowtie S$ 을 primitive operation 으로만 표현하라 $R \\bowtie S = \\sigma_{R.A_1 = S.A_1 \\land R.A_2 = S.A_2 \\land \\ldots \\land R.A_n = S.A_n}(R \\times S)$ 가장 높은 연봉을 받는 교수의 이름을 말하시오 모든사람과 비교시 한번이라도 연봉이 딸리는 사람 $\\Pi_{instructor.name}(\\sigma_{instructor.salary","relation-algebra#relation algebra":"","relation-algebra-와-sql-의-차이#relation algebra 와 sql 의 차이":"순수한 relation algebra 는 중복을 제거한다 예를 들어 pojection 의 결과가 동일한 튜플이 생기면 1개로 표기한다 multiset relation algebra 는 sql 문으로 부터 중복을 유지한다 즉 아래의 구분 multiset relation algebra 와 sql 은 완벽하게 의미가 일치한다 Problem\nselect $A_1, A_2, A_3 \\dots A_n$ from $r_1, r_2, r_3, \\dots r_n$ where P $\\Pi_{A_1, A_2, A_3, \\dots A_n}(\\sigma_P(r_1 \\times r_2 \\times \\dots \\times r_n))$\nProblem\nselect $A_1, A_2$ sum($A_3$) from $r_1, r_2, r_3 \\dots r_m$ where P group by $A_1, A_2$ ${A_1, A_2}\\Gamma{sum(A_3)}(\\sigma_P(r_1 \\times r_2 \\times \\dots \\times r_m))$\nmultiset : 컴퓨터/통신 멀티셋, 동일 항목이 여러 개 출현하는 것을 허락하는 집합체.","six-basicprimitive-operators#Six basic/primitive operators":"select: $\\sigma_c(r)$ 선택 =\u003e 수평 선택 c 조건을 만족하는 R table tuple 의 부분 집합을 선택한다 project: $\\Pi_a(r)$ 투영 =\u003e 수직 선택 cartesian product: $r \\times s$ tuple의 가능한 모든 조합 (동일 attribute 일 경우 r table 의 rB, s table dml sB 라고 표기하여 두집합의 attribute를 다르게 판단한다) rename: $\\rho_s(r)$ 또는 $\\rho_{s(A1,A2,A3)}(r)$ rename 이름을 다시 짓는다 R을 S로 여기서 table 이름만 재설정 할 수도 attribute 의 이름을 재설정 할 수도 있다","transaction-management트랜젝션#Transaction Management(트랜젝션)":"","기본-용어-정의#기본 용어 정의":"","데이터베이스-설계-방식#데이터베이스 설계 방식":"","비정규화-된-데이터베이스의-문제#비정규화 된 데이터베이스의 문제":"","예시-1-최소한-두-종류의-상품을-구매한-고객-찾기#예시 1: 최소한 두 종류의 상품을 구매한 고객 찾기":"Query 1 $(\\pi_{CustomerName}(\\sigma_{ProductName=“Book”}(Purchases)) \\cap \\pi_{CustomerName}(\\sigma_{ProductName=“Laptop”}(Purchases)))$\nQuery 2 $(\\pi_{customer-name, product-name} (Purchases) \\div \\rho_{temp(product-name)} ({(“Book”), (“Laptop”)}))$","예시-2-두-지점에서-대출을-받은-고객-찾기#예시 2: 두 지점에서 대출을 받은 고객 찾기":"Query 1 (\\pi_{CN}(\\sigma_{BN=“East Branch”}(borrower loan)) \\cap \\pi_{CN}(\\sigma_{BN=“West Branch”}(borrower loan)))\nQuery 2 (\\pi_{customer-name, branch-name} (borrower loan) \\div \\rho_{temp(branch-name)} ({(“East Branch”), (“West Branch”)}))","은행-데이터베이스#은행 데이터베이스":"$d$","정규화-이론#정규화 이론":"","참조-무결성-제약-조건과-외래키-제약-조건#참조 무결성 제약 조건과 외래키 제약 조건":"=\u003e $참조 무결성 제약 조건 \\supset 외래키 제약 조건$\n제약 조건이란 데이터의 입력 조건을 말한다 외래키 제약 조건 : 참조하는 값이 참조되는 값의 attribute의 domain 중 하나에 나와야 한다 \u0026 참조되는 값은 pk 의 구성 속성중 하나이다 참조 무결성 제약 조건 : 참조하는 값이 참조되는 값의 attribute의 domain 중 하나에 나와야 한다 pk 구성요소라는 추가되는 조건에 의해 외래키 제약 조건이 더 엄격하다 현재 dbms 는 외래키 제약조건은 지원하지만 참조되는 속성이 주 키가 아닌 참조 무결성 제약조건은 언제나 깨질 수가 있다 즉 두 관계의 차집합의 사례에 대해서는 지원하지 않는다","표기-관습#표기 관습":"","학교-시스템-데이터베이스#학교 시스템 데이터베이스":"기본 용어 정의 attribute : culume(열)의 이름 rable(레이블) domain(도메인) : attribute가 가질수 있는 값(value)들의 집합(null 은 모든 domain 의 원소이다) row == record == tuple : 가로 value 의 집합 entity : 하나의 tuple 을 통해 표현하고 싶은 객체 arity : attribute 의 개수 relation(table) : tuple 의 집합 ( table 을 통해 표현하는 것은 entity 간의 차이를 나타내므로 관계 라고 명칭 ) database : table 의 집합 NULL 은 0 이나 \"\" 이 아님 nonvalue 임 모든 domain 은 명시하지 않는 한 NULL 을 포함\nschema : 논리적 구조 일종의 data type == 테이블의 기본적 구조 == attribute 가 모두 동일 모든 attribute 의 domain instance : 특정시점의 entity 들의 상태(dbms 의 상태) key : tuple 을 구별하기 위한 Attribute 조합의 집합 tuple을 구별하지 못해도 만들어진 목적은 tuple 을 구별하기위해 만들어짐 결국 모든 Attribute 의 모든 가능한 부분 집합 Super key : relation 에서 tuple 을 구별하기 위한 unique 한 Attribute 의 집합 attribute 를 여러개 묶던지 tuple 들이 모두 구별만 되면 성립 Candidate Key(후보키) : Superkey 중 minimal 한 key 집합 attribute 를 하나만 빼더라도 tuple 들이 구별이 되지않는 집합의 원소가 최소가 되는 집합 Primary key : Candidate key 중 하나 (relation 을 정의할 떄 선택) NULL 값 부여 불가 Foreign key : 타 table의 value 을 참조하는 Attribute 집합 참조하는 주체는 key 가 아닐 수 있지만 참조되는 객체의 value 는 primary key 의 value reference integrity :참조된 table의 primary key 의 값들 중 하나이거나 NULL만 가능하다 학생 table 에서 super key : {학번, 이름, 주민등록번호} , {학번}, {주민등록번호, 지도교수} …. 등등 candidate key : {학번} , {주민등록번호} primary key : 학번 =\u003e db 설계자가 임의 지정 forigen key : 지도교수 교수 table 에서 super key : {교번, 이름} {교번} {교번, 학과} candidate key : {교번} forigen key : 없음\n표기 관습 relation 은 소문자 r relation 의 스키마는 대문자 R 속성의 집합은 그리스 영문자 $\\alpha, \\beta$ 속성의 집합이 슈퍼키일 때 K : K 는 r(R) 의 슈퍼키 r 이라고 하면 특정 시점의 r(R) 의 인스턴스 값을 표시한다\nEntity - relationship model table 들의 관계로 얽혀 있는 database 를 관계를 중심으로 보기편하게 시각화를 시도하는 모델\n위에서 학생과 교수의 table 의 관계를 예시로 들자 학생의 attribute들 중 지도교수라는 attribute 가 있고 들어갈 수 있는 value 는 교수의 primary key 인 교번이 들어가게 된다 이때 이러한 테이블의 관계를 아래처럼 표현한다 둘의 관계는 advisor 관계이며 이 관계를 visual 하게 보여줄 수 있다\ndatabase 의 수학적 해석 $공식적으로, 도메인 집합 (D_1, D_2, \\ldots, D_n)이 주어졌을 때$ $관계 (r)은 (D_1 \\times D_2 \\times \\ldots \\times D_n)의 부분집합입니다.$ $따라서, 관계는 (n)-튜플 ((a_1, a_2, \\ldots, a_n))의 집합이며, 여기서 각 (a_i)는 (D_i)에 속합니다.$\ndatabase language Data Definition Language (DDL) create Database Schema를 정의하는 언어 create table (table 생성) drop table r alter table r alter table r add A D alter table r drop A ( 지원하는 dbms 별로 없음 ) Data Manipulation Language (DML) modification Database의 data를 조작(schema는 불변)하는 언어 Retrieve(조회) : select {} from {} where … Insert(저장) : insert into r values (smith, 00102 …) Delete(삭제) : delete from r where … Change(변경) : Data Control Language (DCL) system Database의 constraint를 제어하는 언어 priviliege 여기서 말하는 제약조건은 attribute value 의 제약조건(not null 등 )이 아닌 db 사용자 관리 접근 ip 허용 등 아닌 시스템적인 제약조건을 말한다 Procedural vs. nonprocedural sql 이 대표적인 nonprocedural 언어이다 내부적으로는 sql 문은 해석하여 procedural 로 변환하여 순차적 처리를 위한 언어 Transaction Management(트랜젝션) 계좌 A 에서 계좌 B 로 50 달러를 옮기는 상황을 생각해 보자 논리적인 행동 하나로 보이지만 프로그래밍에서는 계좌 A 의 50 달러를 전체 남아있는 계좌 액수 에서 빼는 행동, 계좌 B 에 50 달러를 추가하는 행동 이 있다 이때 A 계좌에 남아있는 계좌의 액수가 부족 또는 네트워크 불완전 등 일련의 문제 발생으로 인해 하나의 행위가 실패했다고 가정하자 이 때 하나의 행동만 성공 적으로 처리되게 된다면 문제가 심각해진다(둘다 못하는 것이 낮다) 그래서 두가지의 행동을 하나로 묶어 실패 할꺼면 둘다 실패하던가 성공할시 둘다 성공해야하는 것으로 두개의 논리적 행동을 하나의 논리적 행동으로 묶어 처리할 필요가 있는데 이렇게 개별적이고 분할할 수 없는 작업으로 구분되는 정보 처리 과정을 Transaction 이라고 한다\nDB 또한 이러한 것을 지원한다\n정규화 이론 위의 그림과 아래의 그림을 비교해볼때 위는 table을 적절히 나눈 경우 모두 하나의 table 로 관리하는 경우의 예시이다\n예를 들어 physics 의 예산을 7000 에서 8000 으로 변경할 때 id 33456 tuple 또한 바꾸어야 하는데 이렇게 중복이 발생하게 되면 성능상 오버헤드를 낳는다 비정규화 된 데이터베이스의 문제 정보가 중복 저장 =\u003e 보조 기억 장치 오버헤드 업데이트시 여려개의 tuple 을 건드려야 한다\n데이터베이스 설계 방식 ER (Entity - relationship) model 통하여 설계를 접근한다 Normalization Theory(정규화 이론) : 어떤 디자인이 나쁜 디자인 인지 공식화 학교 시스템 데이터베이스 화살표 기준 출발 하는 부분이 Foreign attribute"},"title":"데이터베이스 용어 정의 및 relation algebra"},"/06.university/databaseuniversity/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EC%9D%B8%EB%8D%B1%EC%8A%A4/":{"data":{"":"인덱스 : data에 빠르게 접근하기 위한 수단","1-모든-루트에서-리프까지의-경로-길이가-동일하다-all-paths-from-root-to-leaf-are-of-the-same-length#1. 모든 루트에서 리프까지의 경로 길이가 동일하다 (All paths from root to leaf are of the same length)":"","2-루트나-리프가-아닌-각-노드는-n2에서-n개의-자식-노드를-가진다-each-node-that-is-not-a-root-or-a-leaf-has-between-n2-and-n-children-where-n-is-the-number-of-pointers-in-a-node#2. 루트나 리프가 아닌 각 노드는 n/2에서 n개의 자식 노드를 가진다 (Each node that is not a root or a leaf has between n/2 and n children, where n is the number of pointers in a node)":"","3-리프-노드는-n12에서-n1개의-값을-가진다-a-leaf-node-has-between-n12-and-n1-values#3. 리프 노드는 (n–1)/2에서 n–1개의 값을 가진다 (A leaf node has between (n–1)/2 and n–1 values)":"","a-루트가-리프가-아닌-경우-최소한-2개의-자식-노드를-가져야-한다-if-the-root-is-not-a-leaf-it-has-at-least-2-children#a. 루트가 리프가 아닌 경우, 최소한 2개의 자식 노드를 가져야 한다 (If the root is not a leaf, it has at least 2 children)":"","b-tree-b-tree-에-비한-장단점#B-tree B+-tree 에 비한 장단점":"Advantages of B-Tree indices:\nmay use less tree nodes than a corresponding B+-Tree sometimes possible to find search-key value before reaching leaf node Disadvantages of B-Tree indices: only a small fraction of all search-key values are found early 일부분만 일찍 찾는다 non-leaf nodes are larger, so fan-out is reduced → B-Trees typically have greater depth than corresponding B+-Tree b-tree b+-tree 에 비해 non leaf 노드는 각 key 들의 포인터 뿐만 아니라 자식 노드 포인터도 가지고 있으므로 노드에서 엣지로 나아가는 선(fan out)들이 적어진다 선이 적어진다는 말은 tree 의 높이가 높아지게 되고 이것은 성능상 불리한 점을 가져온다 insertion and deletion are more complicated than B+-Trees implementation is harder than B+-Trees Typically, advantages of B-Trees do not outweigh disadvantages!","b-루트가-리프인-경우-0에서-n1개의-값을-가질-수-있다-if-the-root-is-a-leaf-it-can-have-between-0-and-n1-values#b. 루트가 리프인 경우, 0에서 (n–1)개의 값을 가질 수 있다 (If the root is a leaf, it can have between 0 and (n–1) values)":"","dense-index-sparse-index#Dense index, sparse index":"Dense index : index file(index entry)에 모든 search key 값이 나타난다 access time 적어짐 insetion time, Deletion time 커짐 space overhead 커짐 spase index : index file(index entry)에 search key 값이 단지 몇 개만 나타나다 access time 많아짐 insertion time, Deletion time 작아짐 space overhead 작아짐","ordered-index#Ordered index":"primary index (clustering index) : 검색 키의 값을 파일과 동일하게 정렬된 순서로 저장 일반적인 상황에서는 primary index 의 search key 가 primary key 인 경우가 많지만 무조건 그럴 필요는 없다 secondary index (non clustering index) : 검색 키의 값과 파일의 순서가 동일한 순서가 아님","기본#기본":"","두개의-조합#두개의 조합":"primary index 이면서 dense index : 데이터의 정렬 순서와 맞으면서 모든 search key 값이 index entry 에 출현 primary index 이면서 sparce index : 데이터의 정렬 순서와 맞으면서 search key 값이 몇 개만 출현 1번과 2번의 비교 즉 dence 와 sparce 의 비교 primary \u0026 Dense primary \u0026 sparce leafnode 는 덴스인덱스\n루트에서 leaf 까지는 미만이면 좌측 이상이면 우측 leaf 에서는 모든 값을 가지고 있다 DENSE leaf 에서 실제 값을 찾을 때는 좌측에 있다\n노드의 하나의 크기는 운영체제가 관리하는 block 과 동일하다\ntree 의 깊이를 최대한 낮추어야 한다\nAll paths from root to leaf are of thesame length Each node that is not a root or a leaf has betweenn/2 andn children (n = number of pointers in a node) A leaf node has between (n–1)/2 andn–1 values","멀티키-접근#멀티키 접근":"하나의 key를 기준으로 가져온후 조건을 확인하거나 두개의 key를 각각 가져와서 교집합 하던가 후자가 더 느린 경우가 생긴다 인덱스를 쓴다고 빨라진다고 보장할 수 없다\n그래서 composite search keys 생김 두개의 search key를 사용해서 찾으므로","비트맵-인덱스#비트맵 인덱스":"online analytics 데이터 분석용 db?? b+-tree 도 아니다\n성능이 낮은 쿼리는 무었인가 인덱스가 2개에서 쿼리 순서에 따른 문제","인덱스-파일index-entriy의-구조#인덱스 파일(index entriy)의 구조":"search key 검색키 : record 를 찾는 데 사용되는 속성이나 속성들의 집합","인덱스-평가-지표#인덱스 평가 지표":"Access types(접근 유형) 지정된 value 를 통해 즉각적으로 record 를 찾기 지정된 value 를 통해 범위를 통해 record 를 찾기 Access time(접근 시간) : 특정한 data 혹은 data 집합 접근에 걸리는 시간 Insertion time(삽입 시간) 새로운 데이터 삽입 + 인덱스 구조 업데이트 Deletion time(삭제 시간) 데이터 삭제 + 인덱스 구조 업데이트 Space overhead(공간 부담) : 인덱스 구조가 차지하는 추가적인 공간","인덱스의-종류#인덱스의 종류":"Ordered indices : record가 정렬된 순서와 동일하게 정렬된 search key Hash indices : buckets 범위 안에서 값이 일정하게 분배로 된어 있다 값이 할댕","특수-경우-special-cases#특수 경우 (Special cases)":""},"title":"데이터베이스 인덱스"},"/06.university/databaseuniversity/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EC%A7%88%EB%AC%B8-%EB%AA%A9%EB%A1%9D/":{"data":{"":"[!question1] unary 연산이후에는 rename 을 제외하고는 table의 이름이 바뀌지 않았다 하지만 $\\cup, -, \\times, \\bowtie$ 등의 binary 연산 이후 table 의 이름은 무었인가요??\nQuestion\nnot null 은 제약조건에 속하는데 왜 modify 에서 변경하며 add,drop constraint 구문에서는 not null 변경이 안되는 이유\nCREATE TABLE 예시테이블 ( 컬럼명1 데이터타입 [NOT] NULL, 컬럼명2 데이터타입, ... CONSTRAINT 제약조건이름 PRIMARY KEY (컬럼명1, 컬럼명2), CONSTRAINT 제약조건이름 FOREIGN KEY (컬럼명2) REFERENCES 다른테이블(컬럼명), CONSTRAINT 제약조건이름 UNIQUE (컬럼명3), CONSTRAINT 제약조건이름 CHECK (조건식) ); 과 같이 table 수준의 제약조건에서는 NOT NULL 조건 부여 불가\nALTER TABLE PLAYER2 DROP CONSTRAINT PLAYER_FK2; ALTER TABLE table_name MODIFY column_name data_type NOT NULL; 과 같이 drop contraint 구문에서도 NOT NULL 조건 부여 불가\ndefault 구문도 제약조건인건가요??\n애초에 말이 안되는 함수 종속성 규칙이지만 여기서 처음부터 F 가 F={이름 -\u003e 시 ; 이름 -\u003e 도} 라고 주어진다면 좌측처럼 분해된다면 lossy decomposition이고 우측이라면 무손실 분해이다\n위는 AG가 후보키가 된다는 증명과정 그렇다면 AG 를 찾는 과정은 모든 조합을 다 확인해야 하는다2^6 -1\n3NF 의 2번째 정의??\n이것의 후보키를 구해보자"},"title":"데이터베이스 질문 목록"},"/06.university/databaseuniversity/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-sql/":{"data":{"":"","aggregate-function#aggregate function":"여러 행을 한행으로 결과치를 만들어 낸다 여러행을 한행으로 만드는 성질 때문에 1행만 나오게 되고 많은 경우에 실제 사용시에는 group by 와 함께 사용되게 된다\n위의 where 절의 null 의 설명을 참조: count 를 제외한 avg, min, max, sum 의 경우에는 필연적으로 산술연산 또는 비교연산이 들어가게 되고 이러한 점 때문에 count 를 제외한 연산자의 경우에는 null 값을 제거하고 연산하게 된다\ncount 의 경우 count(*) =\u003e null 포함 모든 값 갯수 count(column 명) =\u003e null 제외 값의 개수\nsalary null null 10000 20000 10000 select count(*), count(salary), count(distinct salary), avg(salary), from '위의 테이블' -- 결과 : 5, 3, 2","alter-table-ddl#ALTER TABLE DDL":"컬럼 이름, constraint, datatype, default 등등 컬럼의 속성이 변경 대상이다\nADD : ALTER TABLE 테이블명 ADD (추가할 칼럼명과 속성들); =\u003e ALTER TABLE PLAYER2 ADD (ADDRESS VARCHAR2(80))\nMODIFIY (이름을 제외한 컬럼의 속성 변경) : ALTER TABLE 테이블명 MODIFY (칼럼명1 데이터 유형 [DEFAULT 식] [NOT NULL], 칼럼명2 데이터 유형 ...); =\u003e ALTER TABLE PLAYER2 MODIFY (JOIN_YYYY VARCHAR2(8) DEFAULT '20020129' NOT NULL);\nDROP COLUMN : ALTER TABLE 테이블명 DROP COLUMN 삭제할 칼럼명; =\u003e ALTER TABLE PLAYER2 DROP COLUMN ADDRESS;\nADD CONSTRAINT : ALTER TABLE 테이블명 ADD CONSTRAINT 제약조건명 (칼럼명); =\u003e ALTER TABLE PLAYER2 ADD CONSTRAINT PLAYER_FK2 FOREIGN KEY (TEAM_ID) REFERENCES TEAM(TEAM_ID);\nDROP CONSTRAINT : ALTER TABLE 테이블명 DROP CONSTRAINT 제약조건명 =\u003e ALTER TABLE PLAYER2 DROP CONSTRAINT PLAYER_FK2;","case-표현식#case 표현식":"CASE SIMPLE_CASE_EXPRESSION 조건 ELSE 표현절 END CASE SEARCHED_CASE_EXPRESSION 조건 ELSE 표현절 END DECODE(expr, value1, return1 [, value2, return2, ... , default]) --Oracle Only. SELECT ENAME, EMPNO, MGR, CASE some_column WHEN 'value1' THEN 'result1' WHEN 'value2' THEN 'result2' ELSE 'default_result' END FROM EMP; SELECT ENAME, EMPNO, MGR, CASE WHEN some_column \u003e 100 THEN 'Greater than 100' WHEN some_column = 100 THEN 'Equal to 100' ELSE 'Less than 100' END FROM EMP; 두 table의 동일 속성에서 누가 fk 가 될것인가 fk 로 엮여있는 table 에서 pk를 어떻게 설정할 것인가 student 와 instructor 의 advisor 의 예","comment#comment":"dbms 는 테이블에 또는 컬럼에 즉 attributte 에 상세정보와 같은 comment 를 달 수 있다\noracle, postgresql comment 만들기\n--생성시 에는 주석을 만들수 없음 COMMENT ON TABLE your_table_name IS 'your_comment'; -- table 주석달기 COMMENT ON COLUMN your_table_name.your_column_name IS 'your_comment'; -- column 주석달기 ``` mysql commnet 만들기 ```sql create table test( pid\tINT\tNOT NULL COMMENT '제품ID', -- 생성시 열에 commnet ... ) comment '임시 테이블입니다' -- 생성시 table 에 commnet ALTER TABLE products COMMENT '상품정보'; -- 변경시 table에 comment ALTER TABLE products MODIFY prod_name VARCHAR(100) NULL COMMENT '제품이름'; -- 변경시 열에 commnet 확인은 모든 dbms 가 각각 다름","create-table-ddl#CREATE TABLE DDL":"CREATE TABLE 테이블이름 ( 컬럼이름 datatype [DEFAULT기본값] [컬럼제약조건], 컬럼이름 datatype [DEFAULT기본값] [컬럼제약조건], … [테이블 제약조건] … ); table 이름은 reserbed word 는 사용 불가 이름의 시작은 문자로 그리고 A~Z, a~z, 0~9, _, $, # 문자만 허용\nculumn 제약 조건 : 컬럼 제약조건: [CONSTRAINT이름] constraint_type\ntable 제약 조건 : 테이블 제약조건: [CONSTRAINT이름] constraint_type(column,..)\n제약조건 이름을 넣지 않으면 시스템이 알아서 임의 의 제약 조건의 이름을 만들어준다\n제약조건\nNOT NULL : 컬럼 제약조건만 가능 테이블 제약조건을 가능 하지 않음 UNIQUE : NULL 의 중복은 괜찮음, 자동으로 인덱스 생성 PRIMARY KEY = NOT NULL + UNIQUE 복합 컬럼의 경우 순서가 인덱스 생성시 사용되게 되고 자주 사용하는 column 을 순서가 앞쪽에 배치되어야 search 가 빠르다 #ModificationRequired (인덱스 원리를 넣어보자) FOREIGN KEY : 참조 무결성 제약 참조하는 PK 가 사라질 때 행동 양식을 정해 줄 수 있다 뒤에 붙여주면 된다 정하지 않고 PK 를 삭제하려고 할 때 그 PK 값을 참조하는 FK 가 참조오류가 발생해서 오류를 내뱉는다 ON DELETE CASCADE: 해당하는 FK를 가진 참조행도 삭제 ON DELETE SET NULL: 해당하는 FK를 NULL로 바꿈(PK 는 NULL 이 안되지만 이렇게 해서 정보를 유지시킨다 db 의 지속성에 문제를 일으키므로 주의해서 사용해야 한다) CHECK : 사용자 임의 조건 제약조건 추가 ALTER TABLE테이블이름 ADD CONSTRAINT … NOT NULL은 추가하지 못함 ALTER TABLE emp ADD CONSTRAINT emp_mgr_fk FOREIGN KEY(mgr) REFERENCES emp(empno); 제약조건 삭제 ALTER TABLE테이블이름 DROP CONSTRAINT제약조건이름 PRIMARY KEY의 경우 FK 조건이 걸린 경우에는 CASCADE로 삭제 해야함 ALTER TABLE book DROP CONSTRAINT c_emp_u; ALTER TABLE dept DROP PRIMARY KEY CASCADE; subquery 를 통한 테이블 생성\nCREATE TABLE empSALES AS SELECT * FROM emp WHERE job = ‘SALES’; -- 일반적으로 임시 테이블을 만들 때 사용된다 -- not null 제약 조건만 상속 pk fk 제약 조건의 경우 사라진다 -- pk fk 가 들어가면 다른 테이블에 영향을 끼치기 때문에 의도적인 동작이다","delete-dml#DELETE DML":"DELETE FROM 테이블이름 [WHERE조건];","delete-truncate-drop#Delete, Truncate, Drop":"컬럼\n컬럼 추가 ALTER TABLE 테이블명 ADD (추가할 칼럼명);\nALTER TABLE book ADD (pubs VARCHAR2(50)); 컬럼 수정 ALTER TABLE 테이블명 MODIFY (칼럼명1 데이터 유형 [DEFAULT 식] [NOT NULL], 칼럼명2 데이터 유형 …)\nALTER TABLE PLAYER2 MODIFY (JOIN_YYYY VARCHAR2(8) DEFAULT '20020129' NOT NULL) 컬럼 이름 수정 ALTER TABLE 테이블명 RENAME COLUMN 변경해야 할 칼럼명 TO 새로운 칼럼명;\nALTER TABLE PLAYER2 RENAME COLUMN PLAYER_ID TO TEMP_ID; 컬럼 삭제 ALTER TABLE 테이블명 DROP COLUMN 삭제할 칼럼명;\nALTER TABLE book DROP COLUMN author ; UNUSED 컬럼 (SET UNUSED -\u003e DROP UNUSED COLUMES)\nALTER TABLE boosek SET UNUSED (author); ALTER TABLE book DROP UNUSED COLUMNS; 임시로 컬럼을 사용하지 않는 상태로 대기해 두었다가 이후 안정성 확보 이후 완전히 지운다 이 쿼리는 오라클만 지원한다","dml-참고#DML 참고":"","domain-types#Domain Types":"char(n) : 고정 길이 문자열 varchar(n) : 가변 길이 문자열 int : integer 정수 하위 집합 smallint : 작은 int numeric(p, d) : p=숫자 전체 길이, d=소수점 아래자리수 ex) numeric(3,1) : 0.1 부터 99.9 까지 저장 가능 더 정밀한 소수점은 버려짐 real, double precision : 부동 소수점 숫자 float(n) : n 자리 정밀도 소수","drop-table-ddl#DROP TABLE DDL":"","for-set-cardinality-#for set cardinality :":"","for-set-comparisons---some-all-비교용#for set comparisons  : some, all 비교용":"","for-set-membership--not-in--집합용#for set membership : [not] in =\u0026gt; 집합용":"","from절-join#FROM절 (join)":"기본적으로 FROM문에서 작동 cross join : cartasian product : 모든 조합\n, 또는 join 이라고 적어도 같은말 sql 에서는 cross join 이다 inner join == null 이 안나오게 조건을 만족하는 모든 튜플 결국 의미상 theta join 과 비슷\ntheta join == 임의의 조건에 의한 조인 결국 의미상 inner join 과 비슷\nequi join == theta join 의 조건이 같다는 조건일 떄\n{left,right,full} outer join == 조건을 만족하지 않아도 null 과 함께 나옴 outer join 의 대한 이해\nnatural join == equi join(=) \u0026\u0026 동일한 column명 중복 제거\nself join 자기 자신과 조인\nas 구문을 통해 임시로 attribute 이름을 만들 수 있다 old-name as new-name\n의미의 명확성을 위해 조인 조건은 on 또는 using() 문을 통해 완성하자\ntheta join 이면서 equi join 이 아닌 경우 : 한 테이블에는 사람들의 정보가, 다른 테이블에는 도시의 정보가 저장되어 있다고 가정해봅시다. 이때, 사람들의 나이가 특정 도시에 속한 사람들의 평균 나이보다 큰 경우만을 선택하는 조건을 사용하여 두 테이블을 조인하고 싶다면, 이러한 경우에는 θ-join을 사용할 수 있습니다. 즉, “=” 대신에 “\u003e” 연산자를 조인 조건으로 사용합니다.","function#Function":"Character Function : LOWER : 문자열를 받아서 모두 소문자로 UPPER : 문자열를 받아서 모두 소문자로 CONCAT : 문자열 2 개를 받아서 이어준다 SUBSTR(문자, 시작인덱스, 길이) : substring 시작 인덱스 부터 길이만큼 추출 LENGTH : 문자열을 받아서 길이를 반환 from dual 를 사용 LTRIM : LTRIM(‘xxxYYZZxYZ’,‘x’) = ‘YYZZxYZ’ RTRIM : RTRIM(‘XXYYzzXYzz’,‘z’) = ‘XXYYzzXY’ RTRIM(‘XXYYZZXYZ ‘) = ‘XXYYZZXYZ’ 우측 공백제거 TRIM : TRIM(‘x’ FROM ‘xxYYZZxYZxx’) = ‘YYZZxYZ’ ASCII Number function ABS : Absolute 숫자의 절대값을 반환합니다. 예를 들어, -5의 절대값은 5입니다 MOD : Modulo 두 숫자를 나눈 나머지를 반환합니다. 예를 들어, 10 MOD 3은 1을 반환합니다. ROUND : Round 숫자를 반올림합니다. 예를 들어, ROUND(5.67)은 6을 반환합니다. TRUNC : Truncate 소수점 이하를 버립니다. 예를 들어, TRUNC(5.67)은 5를 반환합니다. SIGN : 숫자의 부호를 반환합니다. 양수이면 1, 음수이면 -1, 0이면 0을 반환합니다. CHR/CHAR : 아스키 코드 값을 해당 문자로 변환합니다. 예를 들어, CHR(65)는 ‘A’를 반환합니다. CEIL : 주어진 숫자보다 크거나 같은 가장 작은 정수를 반환합니다. 예를 들어, CEIL(4.2)는 5를 반환합니다. FLOOR : 주어진 숫자보다 작거나 같은 가장 큰 정수를 반환합니다. 예를 들어, FLOOR(4.8)는 4를 반환합니다. EXP : Exponential 주어진 숫자의 자연 지수 함수 값을 반환합니다. 예를 들어, EXP(1)은 약 2.718을 반환합니다. LOG : Logarithm 주어진 숫자의 로그 값을 반환합니다. 예를 들어, LOG(100, 10)은 2를 반환합니다 (밑이 10일 때). LN : Natural Logarithm 주어진 숫자의 자연 로그 값을 반환합니다. 예를 들어, LN(2.718)은 1을 반환합니다 POWER : 주어진 숫자를 제곱합니다. 예를 들어, POWER(2, 3)은 8을 반환합니다. SIN : COS : TAN : Date function SYSDATE : 데이터베이스 서버의 현재 날짜와 시간 EXTRACT : 날짜나 시간 값에서 특정 부분(연도, 월, 일, 시, 분, 초 등)을 추출합니다. 예를 들어, EXTRACT(YEAR FROM date_column)은 주어진 날짜에서 연도를 추출합니다. TO_NUMBER(TO_CHAR(d,‘DD’|‘MM’|‘YY’)) TO_CHAR(date_column, 'DD'): 날짜에서 일을 문자열로 추출합니다 TO_NUMBER(TO_CHAR(date_column, 'DD')): 날짜에서 일을 숫자로 변환하여 추출합니다. TO_CHAR(date_column, 'MM'): 날짜에서 월을 문자열로 추출합니다. TO_NUMBER(TO_CHAR(date_column, 'MM')): 날짜에서 월을 숫자로 변환하여 추출합니다. TO_CHAR(date_column, 'YY'): 날짜에서 연도의 마지막 두 자리를 문자열로 추출합니다. TO_NUMBER(TO_CHAR(date_column, 'YY')): 날짜에서 연도의 마지막 두 자리를 숫자로 변환하여 추출합니다 Conversion function TO_CHAR : TO_CHAR(date_column, 'YYYY-MM-DD') mysql 안되노 TO_NUMBER TO_NUMBER('12345') TO_DATE / CAST: 문자열을 날짜로 변환합니다 TO_DATE('2024-05-17', 'YYYY-MM-DD'), CAST(some_column AS VARCHAR(20)) CONVERT : 한 데이터 타입을 다른 데이터 타입으로 변환 CONVERT(VARCHAR, some_date, 23) Null-Related function NVL/ISNULL : NVL(column, 'default') default 반환 첫 번째 인수가 NULL인 경우 두 번째 인수를 반환 NULLIF :: NULLIF(a, b)는 a와 b가 같으면 NULL을 반환하고, 다르면 a를 반환 COALESCE : Coalesce COALESCE(column1, column2, 'default')는 column1이 NULL이 아니면 그 값을 반환하고, NULL이면 column2를 반환하며, column2도 NULL이면 ‘default’를 반환합니다. 인수 중에서 첫 번째로 NULL이 아닌 값을 반환합니다","group-by#group by":"group by 에 참여하지 않은 attribute 는 논리상 select 문에서 그냥은 참여할 수 없다 having, order by 도 마찬가지 aggreate function parameter 로써는 가능하다","having#having":"Aggregation 결과에 대해 다시 condition을 적용할 때 사용","inline-view#inline view":"임시 공간에 테이블을 생성하여 사용하는 View 와 비슷함\n-- 평균 급여 42000 이상인 부서와 그 평균 급여 select dept_name,avg_salary from (select dept_name, avg (salary) as avg_salary from instructor group by dept_name ) where avg_salary \u003e 42000;","insert-into-dml#INSERT INTO DML":"INSERT INTO 테이블이름 [(컬럼리스트)] VALUES (값리스트)","mysql#MySQL":"TINYINT: 1바이트 정수 (-128 ~ 127 또는 0 ~ 255) SMALLINT: 2바이트 정수 (-32,768 ~ 32,767 또는 0 ~ 65,535) MEDIUMINT: 3바이트 정수 (-8,388,608 ~ 8,388,607 또는 0 ~ 16,777,215) INT (INTEGER): 4바이트 정수 (-2,147,483,648 ~ 2,147,483,647 또는 0 ~ 4,294,967,295) BIGINT: 8바이트 정수 (-9,223,372,036,854,775,808 ~ 9,223,372,036,854,775,807 또는 0 ~ 18,446,744,073,709,551,615) FLOAT: 4바이트 부동 소수점 수 (가변 소수점) DOUBLE: 8바이트 부동 소수점 수 (가변 소수점) DECIMAL (NUMERIC): 고정 소수점 수 (정밀도와 소수 자릿수 지정 가능)","nested-subquery#nested subquery":"쿼리 내부의 쿼리\nselect A1,A2, ...,An from r1,r2, ...,rm where P 이러한 sql 문이 있을 때\n$A_i$ : 단일 값을 반환하는 subquery 로 대체될 수 있다 $r_i$ : 유효한 subquery 로 대체될 수 있다 p : B \u003c [not] in,\u003e (subquery) 형태의 표현식에 들어갈 수 있다 각각에 subquery 의 위치에 따라 가능한 형태가 다르고 표현도 다르다 이러한 것들의 별칭 또한 존재한다","not-null-제약조건과-다른-제약조건의-차이#NOT NULL 제약조건과 다른 제약조건의 차이":"CREATE TABLE 예시테이블 ( 컬럼명1 데이터타입 [NOT] NULL, 컬럼명2 데이터타입deafault 10, ... CONSTRAINT 제약조건이름 PRIMARY KEY (컬럼명1, 컬럼명2), CONSTRAINT 제약조건이름 FOREIGN KEY (컬럼명2) REFERENCES 다른테이블(컬럼명), CONSTRAINT 제약조건이름 UNIQUE (컬럼명3), CONSTRAINT 제약조건이름 CHECK (조건식) ); 과 같이 table 수준의 제약조건에서는 NOT NULL 조건 부여 불가\nALTER TABLE PLAYER2 DROP CONSTRAINT PLAYER_FK2; ALTER TABLE table_name MODIFY column_name data_type NOT NULL; 과 같이 drop contraint 구문에서도 NOT NULL 조건 부여 불가 modify 구문에서 변경해야함","null#null":"null 산술연산 = null ex) 5 + null = null null 비교 연산 = unknown : 새로운 진리값 만들어짐 OR (unknown or true) =true (unknown or false) =unknown (unknown or unknown) =unknown AND (true and unknown) =unknown (false and unknown) =false (unknown and unknown) =unknown NOT (not unknown) =unknown 참조\nwhere 절에서 unknown 값이 나오면 false 와 동일하게 처리한다 즉 where salary = null 이라고 쓰면 모든 값의 비교에서 unknown 이 반환되고 모든값이 false 와 같이 처리된다 그러므로 where salary is null 에서의 (is null)과 같은 새로운 is, is not 조건 연산자가 만들어졌다","oracle#Oracle":"NUMBER: 가변 정밀도와 소수 자릿수를 갖는 숫자 (정밀도와 소수 자릿수 지정 가능) BINARY_FLOAT: 4바이트 부동 소수점 수 (가변 소수점) BINARY_DOUBLE: 8바이트 부동 소수점 수 (가변 소수점) FLOAT: NUMBER의 동의어로 사용되며, 정밀도 지정 가능","order--by#order  by":"특이하게 논리상 이후에 수행될 select 문에 select student.name \"학생이름\" 처럼 alias 한 이름이 사용될 수 있다 group by 절에서 select 문의 alias 를 사용하지 못한다 그런데 order by 에서는 사용 가능하다","postgresql#PostgreSQL":"SMALLINT: 2바이트 정수 (-32,768 ~ 32,767) INTEGER (INT): 4바이트 정수 (-2,147,483,648 ~ 2,147,483,647) BIGINT: 8바이트 정수 (-9,223,372,036,854,775,808 ~ 9,223,372,036,854,775,807) REAL: 4바이트 부동 소수점 수 (가변 소수점) DOUBLE PRECISION: 8바이트 부동 소수점 수 (가변 소수점) NUMERIC: 고정 소수점 수 (정밀도와 소수 자릿수 지정 가능) DECIMAL: NUMERIC의 동의어","rename-table-ddl#RENAME TABLE DDL":"RENAME : RENAME 변경전_테이블명 TO 변경후_테이블명 =\u003e ALTER TABLE PLAYER2 RENAME COLUMN PLAYER_ID TO TEMP_ID;","scalar-subquery#Scalar subquery":"select 문에서 함수처럼 단일값을 반환하는 query\nselect dept_name, ( select count(*) from instructor where department.dept_name =instructor.dept_name ) as num_instructors from department; dept_name num_instructors 물리학과 6 컴공학과 12 철학과 8 from에서 tuple 이 하나하나씩 넘어 올 때 마다 dept_name 내부에 들어가는 값이 일종의 parameter 처럼 계속 바뀌면서 다른 출력을 낸다","select-dml#select DML":"-- select 기본 구조 SELECT [ALL | DISTINCT] 열_리스트 [FROM 테이블_리스트] [USING(열_리스트) | ON 조건] [WHERE 조건] [GROUP BY 열_리스트 [HAVING 조건]] [ORDER BY 열_리스트 [ASC | DESC]];","select-문#SELECT 문":"산술 연산 사용 가능","set-operator#set operator":"두 질의에 결과에 대한 연산 수행 다른 연산과는 다르게 중복을 제거한다 중복을 제거하려면 union all 같이 all 을 붙인다 UNION [ ALL ] : 합집합 EXCEPT [ ALL ]: 차집합 (minus : 연산은 몇몇 dbms는 지원하지 않는다(posgresql, msql) execpt 연산이 표준) INTERSECT [ALL] : 교집합 참조\n다른 연산과는 다르게 중복을 제거한다 중복을 제거하려면 union all 같이 all 을 붙인다 r 의 어떤 튜플x가 m번 존재, s의 어떤 튜플 x가 n 번 존재한다면 r union s =\u003e x 1회 등장 r uinon all s =\u003e x m+n회 등장","sql#SQL":"DDL (data definition laguage) 쿼리 Create Table Drop Table Truncate Table Alter Table alter table r {add, add constraint, modifiy, drop colume, set unused, drop unused colume} A rename Data Type Constraint (NOT NULL, DEFAULT, CHECK, REFERENCE) DML (data manipulation language) select select from where group by having order by delete insert update","sql-실행-순서#sql 실행 순서":"","sql-연산자-우선순위#sql 연산자 우선순위":"Arithmetic operators : 산술 연산 Concatenation operator Comparison conditions : 비교 연산 IS [NOT] NULL, LIKE, [NOT] IN [NOT] BETWEEN NOT logical condition AND logical condition OR logical condition","update-dml#UPDATE DML":"UPDATE 테이블이름 SET 변경내용 [WHERE조건]","where-내부의-suquery#where 내부의 suquery":"주로 테스트 용도로 사용됨\n집합 [not] in 비교 some, all, [not] exits, unique","where-문#WHERE 문":"추가 조건 연산\n문자열 매치 where name like '%dar%' % : 문자열과 매칭 _ : 하나의 문자와 매칭 like '100\\%' escape '\\' : excape 를 통해 special 문자를 일반 문자로 처리할 수 있다 즉 100% 문자열와 완벽히 일치하는 value 는 true 로 반환된다","with-절#with 절":"from 절 subquery inline view 의 발전된 방향으로서\n재사용성: WITH 절을 통해 정의된 Common Table Expression(CTE)는 쿼리 내에서 여러 번 참조될 수 있습니다. 이는 복잡한 쿼리를 여러 부분으로 나누어 각 부분을 한 번만 계산하고, 그 결과를 여러 번 재사용함으로써 성능을 향상시킬 수 있습니다.\n가독성과 유지 보수: 쿼리가 더 읽기 쉽고 이해하기 쉬워지므로, 성능 최적화를 위한 수정이 필요할 때 쉽게 변경할 수 있습니다. 잘 구조화된 쿼리는 성능 문제를 진단하고 해결하는 데도 도움이 됩니다.\n실행 계획 최적화: 데이터베이스의 쿼리 최적화기는 WITH 절을 사용함으로써 더 효율적인 실행 계획을 생성할 수 있습니다. 이는 데이터베이스 시스템에 따라 다르지만, WITH 절이 제공하는 명확한 논리적 구조는 최적화기가 더 좋은 결정을 내리는 데 도움이 될 수 있습니다.\nwith max_budget (value) as (select max(budget) from department) select department.dept_name from department,max_budget where department.budget = max_budget.value;","기타-ddl#기타 DDL":"truncate table rename drop table"},"title":"데이터베이스 sql"},"/06.university/databaseuniversity/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A42-%EC%A0%95%EA%B7%9C%ED%99%94/":{"data":{"":"정규화 시에 제대로 분해 되었는지 확인하는 2가지 개념\n손실분해가 일어나지 않게 중복 data 가 존재하는가 (redundency) 종속성이 보존되게","functional-dependencies#functional dependencies":"trivial functional dependencies {주민등록번호} =\u003e {주민등록번호, 성별} // 당연한 이야기 {주민등록번호} =\u003e {주민등록번호} // 당연한 이야기 {주민등록번호} =\u003e 공집합 // 수학적으로 당연한 이야기","무손실-분해lossless-decomposition#무손실 분해(lossless decomposition)":"무손실 분해의 예시이다\n이것을 보장하게 하는 것을 위해 아래의 함수 종속 개념을 사용하여 보장하게 된다","분해#분해":"나쁜 디자인 특정 정보를 표현 불가 -\u003e 대출이 없는 지점은 오픈할 수 없다 정보의 중복 -\u003e 동일 지점에서 빌린 여러개의 대출 정보의 손실 anomaly (update, insertion, deletion) update : loan-number 없이 branch-name 등 insert 불가 delete : 어떤 branch의 마지막 loan을 delete하면 branch 자체가 사라짐 update : 어떤 특정한 branch의 정보(예: Downtown의assets)를 update하면 해당하는 튜플들을 모두 업데이트해야 함 좋은 디자인 정보의 중복을 피한다 정보의 관계가 표현된다 무결성 제약 조건 분해를 안하면 업데이트시 여러개의 동시에 업데이트해야하는 문제가 발생\n싱크시에 트래픽 발생, 싱크 실패 확율 그렇다면 분해는 쉬운가? 그렇지 않다","손실분해lossy-decomposition#손실분해(lossy decomposition)":"손실 분해의 예시이다","정규화#정규화":"BCNF : 함수 종속 $\\alpha -\u003e \\beta$ 에서 $\\alpha$는 슈퍼키이다\nr(R) relation을 BCNF 조건을 어긋나게 하는 함수종속 $\\alpha\\ \\rightarrow\\ \\beta$ 의 각 속성조합인 $r_1 =\\alpha\\ \\cup\\ \\beta$ 와 $r_2=R\\ - (\\beta\\ -\\ \\alpha)$ 2개로 나눈다 즉 알파를 볼모로 잡고 나머지를 다른 table 로 분리 3정규형 : 함수 종속 $\\alpha -\u003e \\beta$ 에서 $\\alpha$는 슈퍼키 이거나 $\\beta-\\alpha$ 는 후보키에 속한다 정규화 과정\nBCNF 목표 lossless join Dependency preservation\n1차 정규화\n모든 entity 는 원자적이어야 한다 2차 정규화\n1차 정규화 완료 모든 key 가 아닌 attrivutes 는 완전하게 PK 종속되어야 한다 3차 정규화 쉬운 정의\n2차 정규화 완료 transitively dependent(a -\u003e b \u0026\u0026 b-\u003e c) 가 없어야 한다"},"title":"데이터베이스2 정규화"},"/06.university/databaseuniversity/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A42-%EC%BF%BC%EB%A6%AC-%EA%B3%BC%EC%A0%95/":{"data":{"":"쿼리 비용 측정 관계 대수 평가 알고리즘 개별 연산을 결합하는 알고리즘","selection#selection":"$h_i$ = 트리 높이 $h_i(t_T+t_S)$ : 트리 통과 시간 b : 조건에 들어가는 record 이 차지하는 블록 개수 n : 조건에 들어가는 record 개수\nA1 : Linear Search : $t_s+b_rt_T$ //br 개의 블락에 걸쳐 존재 A1 , Equal on key : $t_s+b_rt_T$ // 동등하면 평균적으로 1/2 A2 : Primary index, Equal on key : $(h_i+1)(t_T+t_S)$ // 트리 통과 + 1개의 튜플 찾기 A3 : Primary index, Equal on nonkey (중복 존재 가능): $h_i\\times(t_T+t_S)+b\\times t_T + t_S$ A4 : Secondary index, Equal on key $(h_i+1)(t_T+t_S)$ // 1개만 가능하니까 바로 찾음 A4 : Secondary index, Equal on nonkey $(h_i+n)(t_T+t_S)$ // n개의 중복 튜플 , cost 큼 A5 : Pirmary index, comparison : $h_i\\times(t_T+t_S)+b\\times t_T + t_S$ A6 : Secondary index, comparison : $(h_i+n)(t_T+t_S)$ // cost 큼 A7 : conjunctive selection using index : 최소 비용 조건을 먼저 이후는 메모리에서 A8 : conjunctive selection composite index : 가능하다면 복합 인덱스 사용 A9 : conjunctive selection by intersection of identifiers : 나오는 리프 노드의 포인터 record 의 교집합 A10 : disjunctive selection by union of identifiers : 리프노트 포인터 합집합 또는 리니어 서치","sorting#sorting":"sorting 사용 이유\noutput 출력시 사용\njoin 시에 정렬이 되있을 때 편한 사용\nNested loop join\nBlock Nested loop join\nindex join\nmerge join\nhash join\nr = b_r 개의 블록, n_r 개의 튜플 s = b_s 개의 블록, n_s 개의 튜플\nnested-loop join s 관점 n_r * b_r 개의 transfer r 관점 b_r 개의 transfer s 관점 n_r 번 seek r 관점 b_r 개 seek\nblock nested-loop join n_r 을 b_r 로 교체","쿼리-비용-측정#쿼리 비용 측정":"단순하게 disk 만 고려함 disk io 가 가장 큰 요소\nseek(디스크에서 찾기) + transfer(메모리로 가져오기)\nseek를 통해 시작 위치를 찾는다(instructor table 의 시작 data 위치) transfer\n$t_T$ : time to transfer one block assuming for simplicity that write cost is same as read cost typically, cost to write a block is greater than read cost, since data is read back after being written to ensure that the write was successful $t_S$ : time for one seek 크게 selection 과 join 을 쓰기 위해 발행하는 cost 를 계한해 본다"},"title":"데이터베이스2 쿼리 과정"},"/06.university/databaseuniversity/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A42-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/":{"data":{"":"직원 100 : 70개발자 마케팅, 경영관리, 연구개발 프로젝트 일정기간 투입가능 프로젝트의 직무 PM"},"title":"데이터베이스2 프로젝트"},"/06.university/databaseuniversity/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A42-er-model/":{"data":{"":"27, 51, 52page\nentity\n전제조건 : ER 모델 추상화된 모델로서 name = (first_name, middle_initial, last_name) 이렇게 여러가지 속성들을 같이 가지고 있는 속성을 분해하지 않고 1개의 속성으로 나타내도 된다","course-section#course section":"둘의 관계는 one to many : 한 과목은 여러개의 강좌가 개설될 수 있다 한 강좌는 1개의 과목이다 과목은 course_sec 에 partial 하고 있다 : 과목으로 개설된 강좌가 없을 수 있다 강좌는 course_sec 에 total 하고 있다 : 모든 강좌는 과목을 가진다 strong weak : 과목은 강좌 없이도 구별될 수 있다, 강좌는 과목 없이는 구별될 수 없다","er-diagram---relation-schemes-결론#ER diagram -\u0026gt; relation schemes 결론":"이진관계기준!!!\nmany to many 다대다 관계 : 관계집합 \bentity 생성시 : 양 엔티티 집합의 기본 키의 합이 관계집합 최소 슈퍼키가 되어 이것을 기본 키로 선택 관계집합 entity 생성안할 때 : 브릿지를 만들지 않는한 불가 one to many 일대다 및 다대일 관계 : 관계집합 entity 생성시 : “많은 쪽 엔티티 집합\"의 기본 키가 관계 집합 최소 슈퍼키 이것을 기본 키로 사용","er-diagram---relation-schemes-예시#ER diagram -\u0026gt; relation schemes 예시":"중복 속성은 고유한 속성이 아닌데 가지고 있는 entity set 부분을 FK 로 한다","er-diagram-for-a-university-database#ER diagram for a university database":"","er-모델-entity-set#ER 모델 entity set":"entity set ~= relation(table) =\u003e customer, Account value set ~= domain (entity 가 가질 수 있는 value 들의 집합) =\u003e {이름들, A-***} simple attribute vs composite attribute simple : 분해 불가능한 속성 (id, dept) composite : 분해가능한 속성 (이름: 성과 이름 2개로 이루어짐) single-valued attribute vs multivalued attribute single-valued : 아이디, 소속학과 multivalued attribute : 아이들{철수, 영희} Derived attributes : 계산하기 전 : 만나이 = (현재 날짜 - 생일)","er-모델-relationship#ER 모델 Relationship":"Relationship Sets : Entity들의 상호연관관계 =\u003e depositor Role : Relationship sets에서 각 entity의 역할 =\u003e access-date","er-모델-relationship-cardinality관계-수#ER 모델 Relationship Cardinality(관계 수)":"Relationship Cardinality(entiy 가 몇개냐?): 엔터티와 연관될 수 있는 엔터티의 수 :\none to many : instructor vs student : 1명의 교수는 여러 학생을 지도한다 반대로 1명의 학생은 1명의 지도교수를 가진다 one to one : 와이프 vs 남편 : 이혼이 없다는 가정하에 ER-model : one 측에 화살표(-\u003e), many 측에 직선이 그어진다 erwin :\nparticipation 참여율 : 모든 entiy가 relationship에 참여하는 개념인가 왼쪽 그림은 a라는 엔터티 집합은 b라고 하는 엔터티의 집합과의 관계에 partial participation을 하고 있고 b의 집합은 a 집합과의 관계에 total participation을 한다 오른쪽 그림은 a라는 집합은 b라고 하는 엔터티의 집합과의 관계에 total participation을 하고 있고 b의 집합도 a 집합과의 관계에 total participation을 한다 total total 은 dbms 에서 구현 불가능 ER-model : 두줄 직선은 total participation, 한줄직선은 Partial participation 이다 erwin 에서는 : 1:many 관계에서 relationship entity set 은 many entity set 에 붙는다","er-모델-weak-entity-set#ER 모델 Weak entity set":"1 to many, partial total\n자체적으로 독립하기 어려운 집합\nweak entity set 의 master entity 가 정해저야 정해진다 weak entity set 의 pk = master entity set 기본키 + 구별자 식별과 존재를 모두 의존 실무모델링에서는 식별관계 weak relation 관계이다","goal-for-decomposition#goal for decomposition":"Lossless-join decomposition No redundancy Dependency preservation","instructor-department#instructor department":"둘의 관계는 many to one : 한명의 교수는 하나의 학과를 가지고 있다 하나의 학과는 여러명의 교수가 있다 학과는 inst_dept 에 partial 하고 있다 : 학과는 교수를 가지지 않을 수 있다 교수는 inst_dept 에 total 하고 있다 : 교수는 학과를 무조건 갖는다\nmany측에 즉 교수측에 dept_name 이 fk 로 들어가면 table 을 따로 만들지 않아도 된다","instructor-student#instructor student":"둘의 관계는 one to many : 한명의 교수는 여러명의 학생을 지도교수로 하고 있다 한명의 학생은 한명의 지도교수를 가진다 교수는 advisor에 partial 하고 있다 : 교수는 학생을 한명도 지도하지 않을 수 있다 학생은 advisor에 total 하고 있다 : 학생은 지도 교수를 한명도 안 가질 수 있다 strong strong","관계집합-entity-생성안할-때--많은-쪽이-one-측의-기본-키를-가져가서-그것을-왜래키로-사용해도-관계집합이-충분히-표현#관계집합 entity 생성안할 때 : 많은 쪽이 one 측의 기본 키를 가져가서 그것을 왜래키로 사용해도 관계집합이 충분히 표현":"one to one 일대일 관계 : 관계집합 entity 생성시 : 참여하는 ㅡ엔티티 집합 중 어느 쪽의 기본키 모두 관계집합 최소 슈퍼키 가능 이것을 기본 키를 선택 관계집합 entity 생성안할 때 : 아무 entity 집합이나 상대측의 pk 를 자신의 fk 로 사용하면 가능 relationship cardinarity의 각각의 경우\nmany to many \u0026\u0026 partial partial \u0026\u0026 strong strong (m:m, p:p, s:s) 양쪽의 attribute를 모두 pk 로 entity set 을 만든다 one to many \u0026\u0026 partial total \u0026\u0026 strong strong (o:m, p:t, s:s) many측의 attribute가 pk이자 fk, one 측의 attribute 가 fk 인 entity set 을 만든다 total 이므로 not null 조건이 있어야 한다 many측이 total이면 one측에 있는 pk를 가져다가 many측에 붙인다 on to many \u0026\u0026 one to many \u0026\u0026 total total : 불가능 one to many \u0026\u0026 partial total \u0026\u0026 strong weak (o:m, p:t, s:w) many 측의 attribute가 pk 이자 fk, one 측의","기호-설명#기호 설명":"직사각형 (Rectangles): 개체 집합(entity set)을 나타냅니다. 개체 집합의 이름이 직사각형 안에 적혀 있으며, 해당 개체 집합의 모든 속성(attributes)도 나열됩니다. 다이아몬드 (Diamonds): 관계 집합(relationship set)을 나타냅니다. 관계 집합의 이름이 다이아몬드 안에 적혀 있습니다. 비분할 직사각형 (Undivided Rectangles): 관계 집합의 속성을 나타냅니다. 관계의 주요 키(primary key)의 일부인 속성은 밑줄로 표시됩니다. 선 (Lines): 개체 집합과 관계 집합을 연결합니다. 이 선은 개체와 관계 간의 연관성을 나타냅니다. 점선 (Dashed Lines): 관계 집합의 속성과 그 관계 집합을 연결합니다. 속성이 관계에 포함됨을 나타냅니다. 이중선 (Double Lines): 개체가 관계 집합에 완전하게 참여(total participation)하고 있음을 나타냅니다. 즉, 해당 개체는 반드시 이 관계에 포함되어야 합니다. 이중 다이아몬드 (Double Diamonds): 약한 개체 집합(weak entity set)과 연결된 식별 관계 집합(identifying relationship set)을 나타냅니다. 약한 개체는 독립적으로 식별될 수 없고, 반드시 다른 개체와의 관계를 통해 식별됩니다. 화살표 one, 직선 many\n식별관계 vs 비 식별관계\ntotal participation - total participation 1 many 불가\nA \u003c= relation ship = B 이것을 ddl 로 강제할 방법이 없다"},"title":"데이터베이스2 ER model"},"/06.university/databaseuniversity/%EC%9A%94%EA%B5%AC%EC%82%AC%ED%95%AD%EB%AA%85%EC%84%B8%EC%84%9C/":{"data":{"":"우리 회사는 100명의 직원을 둔 SI 업체로, 30명의 마케팅, 경영관리 및 연구개발 직원을 제외하 면 70명의 개발자가 월평균 10개 정도의 프로젝트를 수행하고 있다. 개발자들은 프로젝트에 초기부 터 종료 시까지 투입되기도 하고, 프로젝트에 일정 기간만 투입되기도 한다. 프로젝트에 투입되는 개발자들은 경력과 기술 등급에 따라서 PM, PL, 분석자, 설계자, 프로그래머, 테스터 등 다양한 직무를 맡는다. 우리 회사가 수행하는 프로젝트에 대해 프로젝트번호, 프로젝트명, 프로젝트 착수일자/종료일자, 발주처 등을 관리하고, 직원들에 대해서는 직원번호, 직원명, 주민등록번호, 최종학력을 관리하며, 특히 프로젝트 투입 직원들에 대해서는 경력과 경험한 기술(Skill Set)들을 관리하고자 한다. 직원은 회원가입 페이지를 통해 자신의 정보를 데이터베이스에 저장하고 수정/변경할 수 있어야 한다. 직원 사번은 정해진 규칙에 따라서 자동으로 부여하는 것으로 가정하며, 회원가입 시 회원 로그인은 중복 체크 기능을 추가하여 이미 등록된 ID로 회원가입 신청을 할 경우 에러 메시지를 출력하고 중복되지 않는 신규 ID를 입력할 수 있어야 한다. 경영진은 현재 우리 회사가 몇 개의 프로젝트를 수행하고 있고, 직원들이 현재 어느 프로젝트에 몇 명이나 투입되어 있으며, 그들이 각각 어떤 직무를 수행하고 있고, 투입 기간이 어떻게 되는지 등을 체계적으로 관리하길 원하고 있다. 이를 통해서 과거 특정 시점에 어떤 직원이 어느 프로젝트 에 어떤 직무로 참여했었는지도 알 수 있고, 개인별 경력관리는 물론 인센티브 지급을 위한 기초 자료까지 추출할 수 있다. 그러므로 경영진은 일반직원과는 다르게 타 직원들의 정보를 검색할 수 있는 권한이 있어야 한다. 직원들이 참여한 각 프로젝트에서는 프로젝트 종료 시점에 평가를 시행한다. 평가에는 고객 평가, PM 평가, 동료 평가 등이 존재한다. 각 평가는 평가자와 피평가자가 존재하고 평가 항목으로는 업무 수행 평가, 커뮤니케이션 능력 평가가 있으며, 각 평가 항목 당 평점과 평가 내용을 관리한다. 고객 평가는 고객이 프로젝트에 참여한 참여사 직원들에 대해서 평가하는 것을 말한다. 프로젝트를 종 료하는 시점에 PM이 주관하여 고객사의 담당자로부터 평가서를 의뢰하고 결과를 회사에 보고해야 한다. 동료 평가는 프로젝트에 참여한 각 멤버들이 자기 이외의 프로젝트 참여자에 대해서 평가하 는 것이다. 이 중에서 PM 평가는 PM이 프로젝트팀원을 평가하는 것을 말한다. 이러한 평가 결과는 회사 내부에서 인사고과와 인사 평가의 근거 자료로 활용된다 추가) 1. 설계단계에서 ER 다이어그램 마케팅 경영관리 연구개발 개발자테스터 이것은 슈퍼 서브 타입으로 표현한다 2. 평가는 고객 PM 동료 이것은 슈퍼 서브로 표현 발주처는 fk 즉 발주처 entity set 이 존재 3. MM 관계는 지양 4. 1 to M and total total 관계는 지양 5. 추가 엔티티 = 조원 수 서브타입 추가는 금지 6. 마지막 데모 시나리오 = 조원수 / 2 =\u003e 2개 이상의 table 을 조합, 추가 엔티티를 1개의 데모에는 무조건 사용 , 성능 향상 기법(인덱싱, metirial view, 반정규화) person(100) 마케팅 경영관리 연구개발 개발자(70) PM PL 분석자 설계자 프로그래머 테스터 project id name start_date end_date 발주처 member 직원번호 직원명 주민등록번호 최종학력 평가 평가자 피평가자","관계-relationships#관계 (Relationships)":"직원 - 프로젝트 (Participates)\n관계: 직원은 여러 프로젝트에 참여할 수 있으며, 각각의 프로젝트에 여러 직원이 참여할 수 있음 (다대다 관계) 프로젝트 - 고객 (Evaluates)\n관계: 고객은 특정 프로젝트에 대해 평가를 수행함 (일대다 관계) 프로젝트 - PM (Managed By)\n관계: 각 프로젝트는 하나의 PM에 의해 관리됨 (일대일 관계) 직원 - 평가 (Receives)\n관계: 직원은 여러 평가를 받을 수 있으며, 각 평가는 여러 직원에 대해 수행될 수 있음 (다대다 관계) 평가 - 평가 항목 (Includes)\n관계: 각 평가는 여러 평가 항목을 포함할 수 있음 (일대다 관계) 직원 - 평가 (Gives)\n관계: 직원은 다른 직원에 대한 평가를 수행함 (다대다 관계)","엔터티-세트-entity-sets#엔터티 세트 (Entity Sets)":"직원 (Employee)\n속성: 직원 ID, 이름, 직책, 부서 등 프로젝트 (Project)\n속성: 프로젝트 ID, 프로젝트 이름, 시작일, 종료일 등 고객 (Client)\n속성: 고객 ID, 고객 이름, 연락처 등 평가 (Evaluation)\n속성: 평가 ID, 평가 날짜, 평가 내용 등 평가 항목 (Evaluation Criteria)\n속성: 항목 ID, 항목 이름 (업무 수행, 커뮤니케이션 능력 등)","요약#요약":"직원: 여러 프로젝트에 참여 (Participates)\n프로젝트: 고객에 의해 평가됨 (Evaluates), PM에 의해 관리됨 (Managed By)\n평가: 여러 평가 항목을 포함 (Includes), 직원에 의해 수행됨 (Gives)\nEmployee ↔ EmployeeSkill: 1:N (하나의 직원이 여러 기술을 가질 수 있음)\nSkillSet ↔ EmployeeSkill: 1:N (하나의 기술이 여러 직원에게 연결될 수 있음)","추가-요구사항#추가 요구사항":"설계단계에서 ER 다이어그램 마케팅 경영관리 연구개발 개발자테스터 이것은 슈퍼 서브 타입으로 표현한다 평가는 고객 PM 동료 이것은 슈퍼 서브로 표현 발주처는 fk 즉 발주처 entity set 이 존재 MM 관계는 지양 1 to M and total total 관계는 지양 추가 엔티티 = 조원 수 서브타입 추가는 금지 마지막 데모 시나리오 = 조원수 / 2 =\u003e 2개 이상의 table 을 조합, 추가 엔티티를 1개의 데모에는 무조건 사용 , 성능 향상 기법(인덱싱, metirial view, 반정규화) 프로젝트 하나에 참여하는 직원은 모두 개발자인가?\nER 다이어그램을 설계하기 위해서 주어진 정보에 기반하여 엔터티 세트와 관계를 정의할 수 있습니다. 다음은 이를 기반으로 한 엔터티와 관계입니다."},"title":"요구사항명세서"},"/06.university/databaseuniversity/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-sample-data-%ED%86%B5%EA%B3%84/":{"data":{"":"","개발자-70-명-나머지-30명#개발자 70 명 나머지 30명":"","월별-평균-10개-정도의-프로젝트-진행#월별 평균 10개 정도의 프로젝트 진행":"SELECT EXTRACT(YEAR FROM month) AS PROJECT_YEAR, EXTRACT(MONTH FROM month) AS PROJECT_MONTH, COUNT(p.project_id) AS PROJECT_COUNT FROM (SELECT ADD_MONTHS(TRUNC(DATE '2021-01-01', 'MM'), LEVEL - 1) AS month FROM dual CONNECT BY LEVEL \u003c= 47) m LEFT JOIN project p ON (p.start_date \u003c LAST_DAY(m.month) + 1 AND (p.end_date \u003e LAST_DAY(m.month) OR p.end_date IS NULL)) GROUP BY EXTRACT(YEAR FROM month), EXTRACT(MONTH FROM month) ORDER BY PROJECT_YEAR, PROJECT_MONTH;"},"title":"프로젝트 sample data 통계"},"/06.university/databaseuniversity/%ED%95%99%EA%B5%90-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4/":{"data":{"":"table mean student 학생 instructor 교수 advisor 지도관계 department 학과 course 과목 prereq 선이수관계 section 특정 강좌 teaches 강의교수 takes 수강 classroom 강의실 time_slot 시간표 우측부터 설명\nstudent(학생) 말그대로 학생 ID=PK dept_name(학과명)=FK advisor(지도관계) 학생과 교수의 지도관계 s_id(학생ID)=PK, FK i_id(교수ID)=FK 학생의 지도교수가 아직 배정 받지 못한 경우가 있을 수 있음 NULL 값 부여불가 기능을 사용 s_id 만 PK 이므로 모든 학생이 들어가고 학생의 중복은 불가능하다 instructor(교수) department(학과) course(과목): 학과에 존재하는 모든 과목 prereq(선이수 관계) : 학과에 존재하는 과목의 모든 선이수 관계 모든 값이 PK 이면서 FK couse_id, prereq_id 묶어서 하나의 PK section(강의) : course 와 달리 실제 강의를 의미함 teaches(강의 교수) classroom(강의실) tasks(수강신청 목록) prereq 의 두 attribute 가 하나의 PK 를 이루는가 즉 집합인가?\nsuperkey candidatekey primarykey foreignkey =\u003e 이것만 하나의 attribute 인가??\nteaches\n-- 학교 시스템 데이터베이스 생성 DDL 스크립트 -- primary key만 존재하는 table부터 생성해야 foreign key가 존재하는 table을 생성할 때 문제가 없다. 즉 생성의 순서가 존재한다 --department table --student table --instuctor table --advisor table --course table --prereq table --classroom table --time_slot table --section table --takes table --teaches table -- 지울떄는 반대로 DROP Table `teaches`; DROP Table `takes`; DROP Table `section`; DROP Table `time_slot`; DROP Table `classroom`; DROP Table `prereq`; DROP Table `course`; DROP Table `advisor`; DROP Table `instructor`; DROP Table `student`; DROP Table `department`; --생성 CREATE TABLE `department` ( `dept_name` varchar(20), `building` varchar(15), `budget` numeric(12,2) CHECK (`budget` \u003e 0), PRIMARY KEY (`dept_name`) ) CREATE TABLE `student` ( `ID` varchar(5), `name` varchar(20) NOT NULL, `dept_name` varchar(20), `tot_cred` numeric(3,0) CHECK (`tot_cred` \u003e= 0), PRIMARY KEY (`ID`), FOREIGN KEY (`dept_name`) REFERENCES `department` (`dept_name`) ON DELETE SET NULL ) CREATE TABLE `instructor` ( `ID` varchar(5), `name` varchar(20) NOT NULL, `dept_name` varchar(20), `salary` numeric(8,2) CHECK (salary \u003e 29000), PRIMARY KEY (`ID`), FOREIGN KEY (`dept_name`) REFERENCES `department` (`dept_name`) ON DELETE SET NULL ) CREATE TABLE `advisor`( `s_ID` varchar(5), `i_ID` varchar(5), PRIMARY KEY (`s_ID`), FOREIGN KEY (`i_ID`) REFERENCES instructor (ID) ON DELETE SET NULL, FOREIGN KEY (`s_ID`) REFERENCES student (ID) ON DELETE CASCADE ) CREATE TABLE `course` ( `course_id` varchar(8), `title` varchar(50), `dept_name` varchar(20), `credits` numeric(2,0) CHECK (credits \u003e 0), PRIMARY KEY (`course_id`), FOREIGN KEY (`dept_name`) REFERENCES `department` (`dept_name`) ON DELETE SET NULL ) CREATE TABLE `prereq` ( `course_id` varchar(8), `prereq_id` varchar(8), PRIMARY KEY (`course_id`,`prereq_id`), FOREIGN KEY (`course_id`) REFERENCES `course` (`course_id`), FOREIGN KEY (`prereq_id`) REFERENCES `course` (`course_id`) ) CREATE TABLE `classroom` ( `building` varchar(15), `room_number` VARCHAR(7), `capacity` numeric(4,0), PRIMARY KEY (`building`,`room_number`) ) CREATE TABLE `time_slot`( `time_slot_id` varchar(4), `day` varchar(1), `start_hr` numeric(2) CHECK (start_hr \u003e= 0 AND start_hr \u003c 24), `start_min` numeric(2) CHECK (start_min \u003e= 0 AND start_min \u003c 60), `end_hr` numeric(2) CHECK (end_hr \u003e= 0 AND end_hr \u003c 24), `end_min` numeric(2) CHECK (end_min \u003e= 0 AND end_min \u003c 60), PRIMARY KEY (`time_slot_id`, `day`, `start_hr`, `start_min`) ) CREATE TABLE `section` ( `course_id` varchar(8), `sec_id` varchar(8), `semester` varchar(6) CHECK (semester in ('Fall', 'Winter', 'Spring', 'Summer')), `year` numeric(4,0) CHECK (year \u003e 1701 and year \u003c 2100), `building` varchar(15), `room_number` varchar(7), `time_slot_id` varchar(4), PRIMARY KEY (`course_id`,`sec_id`,`semester`,`year`), FOREIGN KEY (`course_id`) REFERENCES `course` (`course_id`) ON DELETE CASCADE, FOREIGN KEY (`building`,`room_number`) REFERENCES `classroom` (`building`,`room_number`) ON DELETE SET NULL ) CREATE TABLE `takes` ( `ID` varchar(5), `course_id` varchar(8), `sec_id` varchar(8), `semester` varchar(6), `year` numeric(4,0), `grade` varchar(2), PRIMARY KEY (`ID`,`course_id`,`sec_id`,`semester`,`year`), FOREIGN KEY (`course_id`,`sec_id`,`semester`,`year`) REFERENCES `section` (`course_id`,`sec_id`,`semester`,`year`) ON DELETE CASCADE, FOREIGN KEY (`ID`) REFERENCES `student` (`ID`) ON DELETE CASCADE ) CREATE TABLE `teaches`( `ID` varchar(5), `course_id` varchar(8), `sec_id` varchar(8), `semester` varchar(6), `year` numeric(4,0), PRIMARY KEY (`ID`, `course_id`, `sec_id`, `semester`, `year`), FOREIGN KEY (`course_id`,`sec_id`, `semester`, `year`) REFERENCES `section` (`course_id`, `sec_id`, `semester`, `year`) ON DELETE CASCADE, FOREIGN KEY (ID) REFERENCES `instructor` (`ID`) ON DELETE CASCADE ) INSERT INTO classroom VALUES('Packard','101',500); INSERT INTO classroom VALUES('Painter','514',10); INSERT INTO classroom VALUES('Taylor','3128',70); INSERT INTO classroom VALUES('Watson','100',30); INSERT INTO classroom VALUES('Watson','120',50); INSERT INTO department VALUES('Biology','Watson',90000); INSERT INTO department VALUES('Comp. Sci.','Taylor',100000); INSERT INTO department VALUES('Elec. Eng.','Taylor',85000); INSERT INTO department VALUES('Finance','Painter',120000); INSERT INTO department VALUES('History','Painter',50000); INSERT INTO department VALUES('Music','Packard',80000); INSERT INTO department VALUES('Physics','Watson',70000); INSERT INTO course VALUES('BIO-101','Intro. to Biology','Biology',4); INSERT INTO course VALUES('BIO-301','Genetics','Biology',4); INSERT INTO course VALUES('BIO-399','Computational Biology','Biology',3); INSERT INTO course VALUES('CS-101','Intro. to Computer Science','Comp. Sci.',4); INSERT INTO course VALUES('CS-190','Game Design','Comp. Sci.',4); INSERT INTO course VALUES('CS-315','Robotics','Comp. Sci.',3); INSERT INTO course VALUES('CS-319','Image Processing','Comp. Sci.',3); INSERT INTO course VALUES('CS-347','Database System Concepts','Comp. Sci.',3); INSERT INTO course VALUES('EE-181','Intro. to Digital Systems','Elec. Eng.',3); INSERT INTO course VALUES('FIN-201','Investment Banking','Finance',3); INSERT INTO course VALUES('HIS-351','World History','History',3); INSERT INTO course VALUES('MU-199','Music Video Production','Music',3); INSERT INTO course VALUES('PHY-101','Physical Principles','Physics',4); INSERT INTO instructor VALUES('10101','Srinivasan','Comp. Sci.',65000); INSERT INTO instructor VALUES('12121','Wu','Finance',90000); INSERT INTO instructor VALUES('15151','Mozart','Music',40000); INSERT INTO instructor VALUES('22222','Einstein','Physics',95000); INSERT INTO instructor VALUES('32343','El Said','History',60000); INSERT INTO instructor VALUES('33456','Gold','Physics',87000); INSERT INTO instructor VALUES('45565','Katz','Comp. Sci.',75000); INSERT INTO instructor VALUES('58583','Califieri','History',62000); INSERT INTO instructor VALUES('76543','Singh','Finance',80000); INSERT INTO instructor VALUES('76766','Crick','Biology',72000); INSERT INTO instructor VALUES('83821','Brandt','Comp. Sci.',92000); INSERT INTO instructor VALUES('98345','Kim','Elec. Eng.',80000); INSERT INTO section VALUES('BIO-101','1','Summer',2017,'Painter','514','B'); INSERT INTO section VALUES('BIO-301','1','Summer',2018,'Painter','514','A'); INSERT INTO section VALUES('CS-101','1','Fall',2017,'Packard','101','H'); INSERT INTO section VALUES('CS-101','1','Spring',2018,'Packard','101','F'); INSERT INTO section VALUES('CS-190','1','Spring',2017,'Taylor','3128','E'); INSERT INTO section VALUES('CS-190','2','Spring',2017,'Taylor','3128','A'); INSERT INTO section VALUES('CS-315','1','Spring',2018,'Watson','120','D'); INSERT INTO section VALUES('CS-319','1','Spring',2018,'Watson','100','B'); INSERT INTO section VALUES('CS-319','2','Spring',2018,'Taylor','3128','C'); INSERT INTO section VALUES('CS-347','1','Fall',2017,'Taylor','3128','A'); INSERT INTO section VALUES('EE-181','1','Spring',2017,'Taylor','3128','C'); INSERT INTO section VALUES('FIN-201','1','Spring',2018,'Packard','101','B'); INSERT INTO section VALUES('HIS-351','1','Spring',2018,'Painter','514','C'); INSERT INTO section VALUES('MU-199','1','Spring',2018,'Packard','101','D'); INSERT INTO section VALUES('PHY-101','1','Fall',2017,'Watson','100','A'); INSERT INTO teaches VALUES('10101','CS-101','1','Fall',2017); INSERT INTO teaches VALUES('10101','CS-315','1','Spring',2018); INSERT INTO teaches VALUES('10101','CS-347','1','Fall',2017); INSERT INTO teaches VALUES('12121','FIN-201','1','Spring',2018); INSERT INTO teaches VALUES('15151','MU-199','1','Spring',2018); INSERT INTO teaches VALUES('22222','PHY-101','1','Fall',2017); INSERT INTO teaches VALUES('32343','HIS-351','1','Spring',2018); INSERT INTO teaches VALUES('45565','CS-101','1','Spring',2018); INSERT INTO teaches VALUES('45565','CS-319','1','Spring',2018); INSERT INTO teaches VALUES('76766','BIO-101','1','Summer',2017); INSERT INTO teaches VALUES('76766','BIO-301','1','Summer',2018); INSERT INTO teaches VALUES('83821','CS-190','1','Spring',2017); INSERT INTO teaches VALUES('83821','CS-190','2','Spring',2017); INSERT INTO teaches VALUES('83821','CS-319','2','Spring',2018); INSERT INTO teaches VALUES('98345','EE-181','1','Spring',2017); INSERT INTO student VALUES('00128','Zhang','Comp. Sci.',102); INSERT INTO student VALUES('12345','Shankar','Comp. Sci.',32); INSERT INTO student VALUES('19991','Brandt','History',80); INSERT INTO student VALUES('23121','Chavez','Finance',110); INSERT INTO student VALUES('44553','Peltier','Physics',56); INSERT INTO student VALUES('45678','Levy','Physics',46); INSERT INTO student VALUES('54321','Williams','Comp. Sci.',54); INSERT INTO student VALUES('55739','Sanchez','Music',38); INSERT INTO student VALUES('70557','Snow','Physics',0); INSERT INTO student VALUES('76543','Brown','Comp. Sci.',58); INSERT INTO student VALUES('76653','Aoi','Elec. Eng.',60); INSERT INTO student VALUES('98765','Bourikas','Elec. Eng.',98); INSERT INTO student VALUES('98988','Tanaka','Biology',120); INSERT INTO takes VALUES('00128','CS-101','1','Fall',2017,'A'); INSERT INTO takes VALUES('00128','CS-347','1','Fall',2017,'A-'); INSERT INTO takes VALUES('12345','CS-101','1','Fall',2017,'C'); INSERT INTO takes VALUES('12345','CS-190','2','Spring',2017,'A'); INSERT INTO takes VALUES('12345','CS-315','1','Spring',2018,'A'); INSERT INTO takes VALUES('12345','CS-347','1','Fall',2017,'A'); INSERT INTO takes VALUES('19991','HIS-351','1','Spring',2018,'B'); INSERT INTO takes VALUES('23121','FIN-201','1','Spring',2018,'C+'); INSERT INTO takes VALUES('44553','PHY-101','1','Fall',2017,'B-'); INSERT INTO takes VALUES('45678','CS-101','1','Fall',2017,'F'); INSERT INTO takes VALUES('45678','CS-101','1','Spring',2018,'B+'); INSERT INTO takes VALUES('45678','CS-319','1','Spring',2018,'B'); INSERT INTO takes VALUES('54321','CS-101','1','Fall',2017,'A-'); INSERT INTO takes VALUES('54321','CS-190','2','Spring',2017,'B+'); INSERT INTO takes VALUES('55739','MU-199','1','Spring',2018,'A-'); INSERT INTO takes VALUES('76543','CS-101','1','Fall',2017,'A'); INSERT INTO takes VALUES('76543','CS-319','2','Spring',2018,'A'); INSERT INTO takes VALUES('76653','EE-181','1','Spring',2017,'C'); INSERT INTO takes VALUES('98765','CS-101','1','Fall',2017,'C-'); INSERT INTO takes VALUES('98765','CS-315','1','Spring',2018,'B'); INSERT INTO takes VALUES('98988','BIO-101','1','Summer',2017,'A'); INSERT INTO takes VALUES('98988','BIO-301','1','Summer',2018,NULL); INSERT INTO advisor VALUES('00128','45565'); INSERT INTO advisor VALUES('12345','10101'); INSERT INTO advisor VALUES('23121','76543'); INSERT INTO advisor VALUES('44553','22222'); INSERT INTO advisor VALUES('45678','22222'); INSERT INTO advisor VALUES('76543','45565'); INSERT INTO advisor VALUES('76653','98345'); INSERT INTO advisor VALUES('98765','98345'); INSERT INTO advisor VALUES('98988','76766'); INSERT INTO time_slot VALUES('A','M',8,0,8,50); INSERT INTO time_slot VALUES('A','W',8,0,8,50); INSERT INTO time_slot VALUES('A','F',8,0,8,50); INSERT INTO time_slot VALUES('B','M',9,0,9,50); INSERT INTO time_slot VALUES('B','W',9,0,9,50); INSERT INTO time_slot VALUES('B','F',9,0,9,50); INSERT INTO time_slot VALUES('C','M',11,0,11,50); INSERT INTO time_slot VALUES('C','W',11,0,11,50); INSERT INTO time_slot VALUES('C','F',11,0,11,50); INSERT INTO time_slot VALUES('D','M',13,0,13,50); INSERT INTO time_slot VALUES('D','W',13,0,13,50); INSERT INTO time_slot VALUES('D','F',13,0,13,50); INSERT INTO time_slot VALUES('E','T',10,30,11,45); INSERT INTO time_slot VALUES('E','R',10,30,11,45); INSERT INTO time_slot VALUES('F','T',14,30,15,45); INSERT INTO time_slot VALUES('F','R',14,30,15,45); INSERT INTO time_slot VALUES('G','M',16,0,16,50); INSERT INTO time_slot VALUES('G','W',16,0,16,50); INSERT INTO time_slot VALUES('G','F',16,0,16,50); INSERT INTO time_slot VALUES('H','W',10,0,12,30); INSERT INTO prereq VALUES('BIO-301','BIO-101'); INSERT INTO prereq VALUES('BIO-399','BIO-101'); INSERT INTO prereq VALUES('CS-190','CS-101'); INSERT INTO prereq VALUES('CS-315','CS-101'); INSERT INTO prereq VALUES('CS-319','CS-101'); INSERT INTO prereq VALUES('CS-347','CS-101'); INSERT INTO prereq VALUES('EE-181','PHY-101'); 임의 데이터 무작위 생성 참조\nimport sqlite3 import random import string conn = sqlite3.connect('test_db.sqlite') cursor = conn.cursor() cursor.execute(''' CREATE TABLE IF NOT EXISTS test_table ( id INTEGER PRIMARY KEY, name TEXT, value INTEGER ) ''') for i in range(10000): name = ''.join(random.choices(string.ascii_letters, k=5)) # 랜덤 이름 생성 value = random.randint(1, 100) # 랜덤 값 생성 cursor.execute('INSERT INTO test_table (name, value) VALUES (?, ?)', (name, value)) conn.commit() conn.close()"},"title":"학교 시스템 데이터베이스"},"/06.university/databaseuniversity/schema_diagram-%EB%B0%8F-%EB%B3%B4%EA%B3%A0%EC%84%9C/":{"data":{"":"열쇠표시 : primary key 좌측 : FK, 우측:PK\n목표로 하는 데이터베이스 시스템에 대한 설명 마트에 방문하는 고객의 거래를 관리하기 위한 db 시스템 데이터베이스 스키마 다이어그램 표현 (“Schema_Diagram.pdf” 참조) 상단에 위치 데이터베이스를 구성하는 테이블들의 명세 표현 (“테이블정의서.xls” 참조) 파일로 첨부 주요 질의서(Query) 세트 및 각각에 대한 설명","-고객의-구매-내역-조회#{??} 고객의 구매 내역 조회":"SELECT c.customer_name, p.product_name, ti.quantity, p.price, (ti.quantity * p.price) AS total_price FROM customer c JOIN visit v ON c.customer_id = v.customer_id JOIN transaction t ON v.visit_id = t.visit_id JOIN transaction_item ti ON t.transaction_id = ti.transaction_id JOIN product p ON ti.product_id = p.product_id WHERE c.customer_name = '고객 이름' ORDER BY t.transaction_date DESC;","-이름-손님이-머무른-시간의-평균을-조회하시오#{??} 이름 손님이 머무른 시간의 평균을 조회하시오.":"SELECT AVG(t.transaction_date - v.visit_date) * 24 AS \"avg_time(hour)\" from ( select customer_name, visit_id, visit_date from customer inner join visit on customer.customer_id = visit.customer_id where customer_name = '{??}' ) v inner join transaction t on v.visit_id = t.visit_id;","-종류의-상품의-이름을-조회하시오#{??} 종류의 상품의 이름을 조회하시오.":"select product_name from product where class = '{??}';","-형식-yyyy-mm-dd-일자에-방문한-고객들의-이름을-조회하시오#{??} 형식 YYYY-MM-DD 일자에 방문한 고객들의 이름을 조회하시오.":"SELECT c.customer_name FROM customer c INNER JOIN visit v ON c.customer_id = v.customer_id WHERE TRUNC(v.visit_date) = DATE '{??}';","결론-및-시사점#결론 및 시사점":"쿼리문을 만드는데에는 크게 어렵지 않았지만 설계를 하는것이 훨씬 어려웠던것 같다 설계에서 테이블간의 단순하게 한개의 PK FK 관계로 연결되다 보니 쿼리문이 길어지고 복잡했던것 같다","고객이-거래-1회당-산-의-갯수의-평균을-조회하시오#고객이 거래 1회당 산 {??}의 갯수의 평균을 조회하시오.":"SELECT SUM(quantity) AS total_quantity FROM transaction_item WHERE product_id = ( SELECT product_id FROM product WHERE product_name = ?","시에-사는-고객들의-이름과-나이를-조회하시오#{??}시에 사는 고객들의 이름과 나이를 조회하시오":"select customer_name, age from customer where address like '%{??}시%';","웹-인터페이스#웹 인터페이스":"","추가#추가":"생성및 제거 DDL\nCREATE TABLE customer ( customer_id INT PRIMARY KEY, customer_name VARCHAR2(50) NOT NULL, age INT NOT NULL, address VARCHAR2(100), enrollment_date DATE DEFAULT CURRENT_DATE ); CREATE TABLE visit ( visit_id INT PRIMARY KEY, customer_id INT, transportation varchar(30) check ( transportation in ('car','public transportation','walk')), visit_date DATE DEFAULT CURRENT_DATE, FOREIGN KEY (customer_id) REFERENCES customer(customer_id) ); CREATE TABLE product ( product_id INT PRIMARY KEY, product_name VARCHAR2(50) NOT NULL, class VARCHAR2(15) check ( class in ('grain', 'dairy', 'meet', 'fish', 'vagitable', 'fruit', 'favorite food') ), price INT NOT NULL ); -- 음식 마트 종류: 유제품, 곡물, 과일, 채소, 고기, 생선, 가공식품 순으로 나열하였습니다. -- CREATE TABLE transaction ( transaction_id INT PRIMARY KEY, visit_id INT NOT NULL, transaction_date DATE DEFAULT CURRENT_DATE, FOREIGN KEY (visit_id) REFERENCES visit(visit_id) ); CREATE TABLE transaction_item ( item_id INT PRIMARY KEY, transaction_id INT, product_id INT NOT NULL, quantity INT NOT NULL, FOREIGN KEY (transaction_id) REFERENCES transaction(transaction_id), FOREIGN KEY (product_id) REFERENCES product(product_id) ); -- 만들어 보자 예시로 -- 1. customer 테이블 시간은 마음대로 하되 순서대로 TRUNCATE TABLE customer; INSERT INTO customer (customer_id, customer_name, age, address, ENROLLMENT_DATE) VALUES (1, '홍길동', 30, '서울시 강남구', TO_DATE('2024-04-30 10:00:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO customer (customer_id, customer_name, age, address, ENROLLMENT_DATE) VALUES (2, '김철수', 25, '용인시 처인구', TO_DATE('2024-04-30 10:30:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO customer (customer_id, customer_name, age, address, ENROLLMENT_DATE) VALUES (3, '이영희', 28, '서울시 송파구', TO_DATE('2024-04-30 11:00:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO customer (customer_id, customer_name, age, address, ENROLLMENT_DATE) VALUES (4, '박민수', 35, '용인시 처인구', TO_DATE('2024-04-30 11:30:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO customer (customer_id, customer_name, age, address, ENROLLMENT_DATE) VALUES (5, '최유리', 22, '서울시 용산구', TO_DATE('2024-04-30 12:00:00', 'YYYY-MM-DD HH24:MI:SS')); -- 2. visit 테이블 TRUNCATE TABLE visit; INSERT INTO visit (visit_id, customer_id, transportation, visit_date) VALUES (1, 1, 'car', TO_DATE('2024-05-01 11:00:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO visit (visit_id, customer_id, transportation, visit_date) VALUES (2, 2, 'public transportation', TO_DATE('2024-05-01 12:00:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO visit (visit_id, customer_id, transportation, visit_date) VALUES (3, 3, 'walk', TO_DATE('2024-05-02 13:00:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO visit (visit_id, customer_id, transportation, visit_date) VALUES (4, 4, 'car', TO_DATE('2024-05-02 20:10:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO visit (visit_id, customer_id, transportation, visit_date) VALUES (5, 5, 'public transportation', TO_DATE('2024-05-02 21:00:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO visit (visit_id, customer_id, transportation, visit_date) VALUES (6, 1, 'walk', TO_DATE('2024-05-02 21:30:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO visit (visit_id, customer_id, transportation, visit_date) VALUES (7, 2, 'car', TO_DATE('2024-05-03 15:00:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO visit (visit_id, customer_id, transportation, visit_date) VALUES (8, 3, 'public transportation', TO_DATE('2024-05-03 20:00:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO visit (visit_id, customer_id, transportation, visit_date) VALUES (9, 4, 'walk', TO_DATE('2024-05-04 08:00:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO visit (visit_id, customer_id, transportation, visit_date) VALUES (10, 5, 'car', TO_DATE('2024-05-04 11:00:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO visit (visit_id, customer_id, transportation, visit_date) VALUES (11, 1, 'public transportation', TO_DATE('2024-05-06 12:00:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO visit (visit_id, customer_id, transportation, visit_date) VALUES (12, 2, 'walk', TO_DATE('2024-05-08 11:00:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO visit (visit_id, customer_id, transportation, visit_date) VALUES (13, 3, 'car', TO_DATE('2024-05-08 13:00:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO visit (visit_id, customer_id, transportation, visit_date) VALUES (14, 4, 'public transportation', TO_DATE('2024-05-08 21:00:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO visit (visit_id, customer_id, transportation, visit_date) VALUES (15, 5, 'walk', TO_DATE('2024-05-10 09:00:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO visit (visit_id, customer_id, transportation, visit_date) VALUES (16, 1, 'car', TO_DATE('2024-05-10 10:00:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO visit (visit_id, customer_id, transportation, visit_date) VALUES (17, 2, 'public transportation', TO_DATE('2024-05-10 11:00:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO visit (visit_id, customer_id, transportation, visit_date) VALUES (18, 3, 'walk', TO_DATE('2024-05-10 12:00:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO visit (visit_id, customer_id, transportation, visit_date) VALUES (19, 4, 'car', TO_DATE('2024-05-10 19:00:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO visit (visit_id, customer_id, transportation, visit_date) VALUES (20, 5, 'public transportation', TO_DATE('2024-05-10 21:00:00', 'YYYY-MM-DD HH24:MI:SS')); -- 3. product 테이블 TRUNCATE TABLE product; INSERT INTO product (product_id, product_name, class, price) VALUES (1, '쌀', 'grain', 2000); INSERT INTO product (product_id, product_name, class, price) VALUES (2, '우유', 'dairy', 1500); INSERT INTO product (product_id, product_name, class, price) VALUES (3, '소고기', 'meet', 10000); INSERT INTO product (product_id, product_name, class, price) VALUES (4, '방어', 'fish', 8000); INSERT INTO product (product_id, product_name, class, price) VALUES (5, '당근', 'vagitable', 1200); INSERT INTO product (product_id, product_name, class, price) VALUES (6, '사과', 'fruit', 3000); INSERT INTO product (product_id, product_name, class, price) VALUES (7, '피자', 'favorite food', 5000); INSERT INTO product (product_id, product_name, class, price) VALUES (8, '빵', 'grain', 2500); INSERT INTO product (product_id, product_name, class, price) VALUES (9, '요거트', 'dairy', 1600); INSERT INTO product (product_id, product_name, class, price) VALUES (10, '돼지고기', 'meet', 11000); INSERT INTO product (product_id, product_name, class, price) VALUES (11, '고등어', 'fish', 8500); INSERT INTO product (product_id, product_name, class, price) VALUES (12, '양배추', 'vagitable', 1300); INSERT INTO product (product_id, product_name, class, price) VALUES (13, '바나나', 'fruit', 3500); INSERT INTO product (product_id, product_name, class, price) VALUES (14, '라면', 'favorite food', 5500); INSERT INTO product (product_id, product_name, class, price) VALUES (15, '옥수수', 'grain', 2700); -- 4. transaction 테이블 TRUNCATE TABLE transaction; INSERT INTO transaction (transaction_id, visit_id, transaction_date) VALUES (1, 1, TO_DATE('2024-05-01 12:00:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO transaction (transaction_id, visit_id, transaction_date) VALUES (2, 2, TO_DATE('2024-05-01 12:34:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO transaction (transaction_id, visit_id, transaction_date) VALUES (3, 3, TO_DATE('2024-05-02 14:00:00', 'YYYY-MM-DD HH24:MI:SS')); -- 수정 INSERT INTO transaction (transaction_id, visit_id, transaction_date) VALUES (4, 4, TO_DATE('2024-05-02 20:45:00', 'YYYY-MM-DD HH24:MI:SS')); -- 수정 INSERT INTO transaction (transaction_id, visit_id, transaction_date) VALUES (5, 5, TO_DATE('2024-05-02 21:45:00', 'YYYY-MM-DD HH24:MI:SS')); -- 수정 INSERT INTO transaction (transaction_id, visit_id, transaction_date) VALUES (6, 6, TO_DATE('2024-05-02 22:00:00', 'YYYY-MM-DD HH24:MI:SS')); -- 수정 INSERT INTO transaction (transaction_id, visit_id, transaction_date) VALUES (7, 7, TO_DATE('2024-05-03 16:30:00', 'YYYY-MM-DD HH24:MI:SS')); -- 수정 INSERT INTO transaction (transaction_id, visit_id, transaction_date) VALUES (8, 8, TO_DATE('2024-05-03 21:00:00', 'YYYY-MM-DD HH24:MI:SS')); -- 수정 INSERT INTO transaction (transaction_id, visit_id, transaction_date) VALUES (9, 9, TO_DATE('2024-05-04 09:30:00', 'YYYY-MM-DD HH24:MI:SS')); -- 수정 INSERT INTO transaction (transaction_id, visit_id, transaction_date) VALUES (10, 10, TO_DATE('2024-05-04 12:00:00', 'YYYY-MM-DD HH24:MI:SS')); -- 수정 INSERT INTO transaction (transaction_id, visit_id, transaction_date) VALUES (23, 3, TO_DATE('2024-05-02 15:30:00', 'YYYY-MM-DD HH24:MI:SS')); -- 수정 INSERT INTO transaction (transaction_id, visit_id, transaction_date) VALUES (11, 11, TO_DATE('2024-05-06 12:00:00', 'YYYY-MM-DD HH24:MI:SS')); INSERT INTO transaction (transaction_id, visit_id, transaction_date) VALUES (12, 12, TO_DATE('2024-05-08 11:45:00', 'YYYY-MM-DD HH24:MI:SS')); -- 수정 INSERT INTO transaction (transaction_id, visit_id, transaction_date) VALUES (13, 13, TO_DATE('2024-05-08 15:00:00', 'YYYY-MM-DD HH24:MI:SS')); -- 수정 INSERT INTO transaction (transaction_id, visit_id, transaction_date) VALUES (14, 14, TO_DATE('2024-05-08 22:30:00', 'YYYY-MM-DD HH24:MI:SS')); -- 수정 INSERT INTO transaction (transaction_id, visit_id, transaction_date) VALUES (15, 15, TO_DATE('2024-05-10 09:45:00', 'YYYY-MM-DD HH24:MI:SS')); -- 수정 INSERT INTO transaction (transaction_id, visit_id, transaction_date) VALUES (24, 4, TO_DATE('2024-05-02 21:30:00', 'YYYY-MM-DD HH24:MI:SS')); -- 수정 INSERT INTO transaction (transaction_id, visit_id, transaction_date) VALUES (16, 16, TO_DATE('2024-05-10 12:30:00', 'YYYY-MM-DD HH24:MI:SS')); -- 수정 INSERT INTO transaction (transaction_id, visit_id, transaction_date) VALUES (17, 17, TO_DATE('2024-05-10 12:45:00', 'YYYY-MM-DD HH24:MI:SS')); -- 수정 INSERT INTO transaction (transaction_id, visit_id, transaction_date) VALUES (18, 18, TO_DATE('2024-05-10 14:00:00', 'YYYY-MM-DD HH24:MI:SS')); -- 수정 INSERT INTO transaction (transaction_id, visit_id, transaction_date) VALUES (19, 19, TO_DATE('2024-05-10 20:30:00', 'YYYY-MM-DD HH24:MI:SS')); -- 수정 INSERT INTO transaction (transaction_id, visit_id, transaction_date) VALUES (20, 20, TO_DATE('2024-05-10 22:30:00', 'YYYY-MM-DD HH24:MI:SS')); -- 수정 -- 5. transaction_item 테이블 TRUNCATE TABLE transaction_item; -- transaction_item 무작위 테이블 데이터 생성 BEGIN FOR transaction_id IN 1..20 LOOP FOR i IN 1..(1 + DBMS_RANDOM.VALUE(0, 4)) LOOP INSERT INTO transaction_item (item_id, transaction_id, product_id, quantity) VALUES (transaction_id * 10 + i, transaction_id, ROUND(DBMS_RANDOM.VALUE(1, 15)), ROUND(DBMS_RANDOM.VALUE(1, 5))); END LOOP; END LOOP; END; / COMMIT; / -- 제거 -- DROP TABLE transaction_item; -- DROP TABLE transaction; -- DROP TABLE product; -- DROP TABLE visit; -- DROP TABLE customer;"},"title":"Schema Diagram 및 보고서"},"/06.university/mju_ecs-project/%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EC%A2%85%EB%A5%98/":{"data":{"":"컨테이너는 2가지 종류가 있다 실행하고 바로 꺼지는 컨테이너 실행하면 계속 백그라운드로 살아있는 컨테이너 ubuntu 가 바로 꺼지는 컨테이너 이므로 -it 옵션을 통해서 bash 셸의 출력을 내가 사용하고 있는 터미널로 붙이게 되면 계속 사용할 수 있다 단 이것도 ctrl + d 를 통해 나가게 되면 종료되어 버린다","터미널을-붙여야-실행되는-컨테이너#터미널을 붙여야 실행되는 컨테이너":"docker run -it --name myubuntu ubuntu /bin/bash (exit) or (ctrl + d) docker start -ai myubuntu OR\ndocker run -it --name myubuntu ubuntu /bin/bash (exit) or (ctrl + d) docker start -it myubuntu OR\ndocker run -d --name myubuntu ubuntu sleep infinity docker exec -it myubuntu bash exit docker stop myubuntu # 프로세스 1 번을 종료 즉 연결된 것이 없다면 완전 정지 docker start myubuntu # 다시 실행 docker stop myubuntu # 정지 docker rm myubuntu # 컨테이너 삭제 3번방식이 가장 적절한 것 같다","터미널을-붙이지-않아도-실행되는-컨테이너#터미널을 붙이지 않아도 실행되는 컨테이너":"docker start --name my"},"title":"컨테이너 종류"},"/06.university/mju_ecs-project/%ED%95%99%EA%B5%90-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%A7%9D-traceroute/":{"data":{"":"학교 강의실별 와이파이 접속시\n[ ~/source/projects/ryugod master ] $ traceroute google.com traceroute to google.com (172.217.161.238), 64 hops max, 40 byte packets 1 192.168.0.1 (192.168.0.1) 4.016 ms 10.352 ms 4.851 ms 2 117.17.157.1 (117.17.157.1) 12.000 ms 5.915 ms 5.870 ms 3 10.10.13.254 (10.10.13.254) 12.100 ms 3.874 ms 8.998 ms 4 202.30.111.4 (202.30.111.4) 3.789 ms 8.036 ms 3.908 ms 5 202.30.111.20 (202.30.111.20) 7.132 ms 3.753 ms 8.286 ms mjuwlan 와이파이 접속시\n[ ~/source/projects/ryugod master ] $ traceroute google.com traceroute to google.com (142.250.76.142), 64 hops max, 40 byte packets 1 192.168.42.253 (192.168.42.253) 5.708 ms 4.067 ms 3.655 ms 2 10.10.10.254 (10.10.10.254) 5.003 ms 4.274 ms 3.686 ms 3 * * *"},"title":"학교 네트워크 망 traceroute"},"/06.university/mju_ecs-project/dockerpty-document/dockerpty-pty/":{"data":{"":"","1-winchhandler#1. \u003cstrong\u003eWINCHHandler\u003c/strong\u003e":"목적: 터미널 창 크기가 변경될 때 동적으로 PTY를 조정하기 위해 SIGWINCH 신호를 처리합니다. 메서드: __init__(self, pty): PTY를 참조하여 핸들러를 초기화합니다. start(self): SIGWINCH 신호를 트랩하고 PTY를 조정합니다. stop(self): SIGWINCH 신호 트랩을 중지하고 이전 신호 핸들러를 복원합니다. __enter__(self) \u0026 __exit__(self, *_): start() 및 stop() 메서드를 호출하는 컨텍스트 관리 메서드입니다.","2-operation-추상-기본-클래스#2. \u003cstrong\u003eOperation (추상 기본 클래스)\u003c/strong\u003e":"목적: Docker 컨테이너 또는 exec 관련 작업을 위한 추상 기본 클래스로 사용됩니다. 메서드: israw(self, **kwargs): 해당 작업이 raw 모드로 작동해야 하는지 여부를 결정합니다 (즉, 컨테이너/exec에 TTY가 할당되었는지 확인). start(self, **kwargs): 작업 실행을 시작합니다 (하위 클래스에서 구현해야 함). resize(self, height, width, **kwargs): PTY를 조정합니다 (하위 클래스에서 구현해야 함). sockets(self): 입력/출력 스트림에 대한 소켓을 반환합니다 (하위 클래스에서 구현해야 함).","3-runoperation#3. \u003cstrong\u003eRunOperation\u003c/strong\u003e":"목적: docker run-like 명령을 관리하기 위해 Operation 인터페이스를 구현합니다.\n초기화:\nRunOperation(client, container, interactive=True, stdout=None, stderr=None, stdin=None, logs=None) client: Docker 클라이언트 인스턴스. container: Docker에서 반환된 컨테이너 사전. interactive: 세션이 대화형으로 작동해야 하는지 여부 (기본값: True). stdout, stderr, stdin: 표준 출력, 오류 및 입력 스트림 (기본값은 sys.stdout, sys.stderr, sys.stdin). logs: 컨테이너 로그를 포함할지 여부 (설정되지 않으면 폐기 예정 경고 발생). 주요 메서드:\nstart(self, sockets=None, **kwargs): PTY를 설정하고 호스트와 컨테이너 간 데이터 전송을 시작합니다. israw(self, **kwargs): 컨테이너가 tty=True로 시작되었는지 확인합니다. sockets(self): stdin, stdout, stderr에 대한 소켓을 반환합니다. resize(self, height, width, **kwargs): 컨테이너의 PTY를 조정합니다. _container_info(self): 컨테이너에 대한 자세한 정보를 검색합니다.","4-execoperation#4. \u003cstrong\u003eExecOperation\u003c/strong\u003e":"목적: docker exec-like 명령을 관리하기 위해 Operation 인터페이스를 구현합니다.\n초기화:\nExecOperation(client, exec_id, interactive=True, stdout=None, stderr=None, stdin=None) client: Docker 클라이언트 인스턴스. exec_id: client.exec_create를 사용하여 생성된 exec 인스턴스 ID. interactive: 세션이 대화형으로 작동해야 하는지 여부 (기본값: True). stdout, stderr, stdin: 표준 출력, 오류 및 입력 스트림 (기본값은 sys.stdout, sys.stderr, sys.stdin). 주요 메서드:\nstart(self, sockets=None, **kwargs): exec 프로세스를 시작하고 데이터 펌프를 설정합니다. israw(self, **kwargs): exec 프로세스가 tty=True로 시작되었는지 확인합니다. sockets(self): exec 프로세스의 모든 I/O 스트림에 대한 단일 소켓을 반환합니다. resize(self, height, width, **kwargs): exec 프로세스의 PTY를 조정합니다. is_process_tty(self): exec 프로세스에 TTY가 할당되어 있는지 확인합니다. _exec_info(self): exec 인스턴스에 대한 자세한 정보를 검색합니다.","5-pseudoterminal#5. \u003cstrong\u003ePseudoTerminal\u003c/strong\u003e":"목적: Docker 컨테이너 또는 exec 프로세스를 위한 PTY의 라이프사이클을 관리합니다.\n초기화:\nPseudoTerminal(client, operation) client: Docker 클라이언트 인스턴스. operation: RunOperation 또는 ExecOperation 인스턴스. 주요 메서드:\nsockets(self): 기본 작업의 sockets() 메서드에 위임합니다. start(self, sockets=None): PTY 세션을 시작하고, 호스트와 컨테이너 간 입력/출력 스트림을 관리하며, 터미널 크기를 조정합니다. resize(self, size=None): 현재 터미널 크기 또는 지정된 크기에 따라 PTY를 조정합니다. _hijack_tty(self, pumps): 호스트와 컨테이너 간 데이터를 읽고 쓰기 위한 주요 루프를 관리합니다.","exec_create#\u003ccode\u003eexec_create\u003c/code\u003e":"목적: 컨테이너에 대해 exec 인스턴스를 생성합니다.\n시그니처:\nexec_create(client, container, command, interactive=True) client: Docker 클라이언트 인스턴스. container: 대상 컨테이너. command: 컨테이너 내에서 실행할 명령. interactive: 세션이 대화형으로 작동해야 하는지 여부 (기본값: True).","결론#\u003cstrong\u003e결론\u003c/strong\u003e":"dockerpty 모듈은 Docker 컨테이너와 의사 터미널을 통한 상호작용을 위한 견고한 프레임워크를 제공합니다. PTY를 활용하여 컨테이너화된 애플리케이션을 터미널 기반 워크플로우로 원활히 통합할 수 있으며, 로컬 터미널 세션과 유사한 사용자 경험을 보장합니다.","문서-dockerpty-모듈-개요#문서: \u003ccode\u003edockerpty\u003c/code\u003e 모듈 개요":"제공된 코드는 dockerpty라는 Python 모듈을 나타내며, 특히 pty.py 파일에 초점을 맞추고 있습니다. 이 문서에서는 모듈의 주요 구성 요소와 기능을 설명합니다.","소개#\u003cstrong\u003e소개\u003c/strong\u003e":"dockerpty 모듈은 Docker 컨테이너와 의사 터미널(PTY) 인터페이스를 통해 상호작용하는 것을 용이하게 설계되었습니다. 사용자가 로컬 터미널 세션과 유사한 방식으로 Docker 컨테이너 터미널에 연결하고 제어할 수 있도록 합니다.\n이 모듈의 주요 목적은 PTY의 라이프사이클을 관리하는 것인데, 호스트와 컨테이너 간의 입력/출력 스트림을 처리하며 터미널 창 크기를 조정하는 작업을 포함합니다.","예제-사용법#\u003cstrong\u003e예제 사용법\u003c/strong\u003e":"import docker from dockerpty import PseudoTerminal # Docker 클라이언트 초기화 client = docker.Client() # 컨테이너 생성 container = client.create_container( image='busybox:latest', stdin_open=True, tty=True, command='/bin/sh', ) # 컨테이너의 PTY 시작 pty = PseudoTerminal(client, RunOperation(client, container)) pty.start()","종속성#\u003cstrong\u003e종속성\u003c/strong\u003e":"표준 라이브러리: sys: 표준 입력/출력/오류 스트림에 접근하기 위해. signal: SIGWINCH 신호를 처리하기 위해. warnings: 폐기 경고를 발행하기 위해. ssl.SSLError: SSL 관련 오류를 처리하기 위해. 내부 모듈: dockerpty.io: 저수준 I/O 작업 및 스트림 관리를 처리합니다. dockerpty.tty: 터미널 조작 유틸리티를 제공합니다.","주요-클래스-및-기능#\u003cstrong\u003e주요 클래스 및 기능\u003c/strong\u003e":"","헬퍼-함수#\u003cstrong\u003e헬퍼 함수\u003c/strong\u003e":""},"title":"dockerpty pty"},"/06.university/mju_ecs-project/mju-ecs-%ED%95%B4%EC%95%BC%ED%95%A0-%EA%B2%83/":{"data":{"":"","container-table-과-ttyd-table#container table 과 ttyd table":"container table 과 ttyd table 2개로 분리할 필요 없이 1개의 테이블에 있어도 되는 거 아닌가? (실시간 status 시) tydContainerId; //ttyd 컨테이너 ID\nprivate String ttydHostPort; //ttyd 호스트 포트\n// ttyd 컨테이너의 컨테이너 포트의 경우 고정되어 있으므로 필요 없음 필요 status status 에 ttyd 접근 포트 필요함","건혁님#건혁님":"forword endpoint\nstatus\nhostname\nvscode (version 1.100)","나#나":"ttyd 실행시 포트 설정 =\u003e 직접 포트 접근 막기\nhttps://chat.qwen.ai/c/633a43de-01b2-4739-abbd-13139669c810\n명령어 이해 상세 -p 127.0.0.1:hostPort:containerPort 로컬에서만 접근 가능 host url 이 달라져도 localhost 로만 접근 docker template 만들기\ndocker document 만들기\n서버 클라이언트 api 호환 마지막","미해결-과제#미해결 과제":"포트 연결시 TCP 인지 UDP 인지도 선택여부에 두어야 하는가? 컨테이너 삭제시 ttyd 또한 삭제가 필요 현재는 그대로 방치됨 도커 볼륨 관련 현재 container.js 에서 너무 많은 일을 하고 있어 new_container.js 와 container.js 로 분리해줘","수정사항#수정사항":"PortAllocator (포트 배정 서비스 추가) 단순 http 요청 docker status 추가 용어 정리 (용어 혼재 사용) hostPort -\u003e containerPo","현재-도커-터미널-관련-아키텍쳐#현재 도커 터미널 관련 아키텍쳐":"터미널에 접근하는 것을 ttyd 로 했는데 1개의 터미널당 1개의 ttyd 컨테이너가 필요하고 ttyd 가 각 컨테이너의 프록시 역할을 해\n이것은 아키텍쳐 적으로 너무 복잡해\n이것을 고치기 위해\nwebsocket 프론트 부분은 terminal.html?containerId={containerId}\n프론트 부분은 xterm.js 로 구성\n백엔드 부분은 spring websocket 으로 구성 (특정 도커와 적절히 연결)\n마지막에 기존 ttyd 의존성 완전 삭제\n백엔드\nWebSocket 설정 WebSocketConfig.java 터미널 핸들러 작성 TerminalWebSocketHandler.java 컨테이너 터미널 세션 관리 클래스 DockerTerminalSessionManager.java 실제 터미널 실행 클래스 DockerTerminalSession.java Docker Java 클라이언트 확장 기능DockerJavaClient.java - 일부 메서드 추가 OutputStream 커스텀 클래스 프론트엔드"},"title":"mju ecs 해야할 것"},"/06.university/mju_ecs-project/mjuecs-%EB%B0%9C%ED%91%9C-%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/":{"data":{"":"mjuecs 호스트 비밀번호 564738291\nsejonng univ auth github shinnk.iptime.org 에서 ppt 다운 명지대 전산정보원\n안녕하세요 5조 발표 시작하겠습니다\n먼저 목차입니다\n설명…\n프로젝트 주제 선정이유 입니다\n해당 프로젝트는 컴공또는 정통 학생들이 학교 수업 또는 프로젝트 진행중 발생할 수 있는 여러 개발환경의 세팅의 어려움을 해결하기 위해 해당 주제를 선정하였습니다\n일반적으로 개발환경의 세팅의 어려운 예시는 다음과 같습니다\n먼저 아카텍쳐 차이로 인해 발생하는 문제인데요 가장 먼저 예시를 들면 oracle database 입니다 해당 소프트웨어의 경우 database 수업시 표준적으로 사용하는 db 임에도 불구하고 상용프로그램이면서 intel, amd 진영에서 사용하는 아키텍쳐인 x64 cisc 기반의 컴퓨터를 지원하는데 최근 점점 risc 기반의 arm 기반 아키텍쳐를 개인 컴퓨터로 사용하는 경우가 늘고 있습니다 특히 mac 의 경우 apple silicon 이 도입되면서 해당 x64 기반의 소프트웨어가 명령어 해석기로 돌아간다고 해도 완벽히 작동하는 것이 아니므로 해당 oracle database 는 구동되지 못합니다\n또한 system programming 실습시 리눅스 systemcall 을 배우는 방식으로 수업이 진행되는데 일반적인 systemcall 의 경우 동일하지만 sys_write 와 같은 systemcall 은 번호가 다르게 배정되어있어 미묘한 차이가 발생합니다\n이러한 문제는 저수준 수업을 들으면 들을 수록 더 크게 다가오는데요 컴퓨터 하드웨어 수업시 오랬동안 산업 표준으로 여겨저온 x64 기반의 어셈블리를 배우게 되는데 타 아키텍쳐와는 완전히 문법이 달라 개인컴퓨터에서 실습조차 구동하기가 쉽지 않다는 문제가 있습니다\n지금까지 타 아키텍쳐로 발생하는 문제만들 이야기 했지만 개발과정에서 많이 사용하는 서버측 os 인 리눅스와 개인 pc 에서 사용하는 window macos와 같이 운영체제 가 달라 발생하는 여러 개발환경의 어려움도 발생합니다\n이것은 저의 개인적 경헙인데요 프로젝트 진행시 외부에 db 를 공유해 사용한다면 dummy data test 또한 쉽게 가능하다는 장점이 있습니다\n위의 여러가지 문제를 통해 저희는 명지대 학생만 무료로 접근할 수 있는 컨테이너 기반 클라우드 서비스를 기획하였습니다\n실제 프로젝트 구현내용및 원래 목표와의 차이 입니다\n해당 프로젝트를 통해 저희는 실제로 사용하기 위해 학교 인프라를 그대로 사용하여 학교내에서 ip 를 받는등 여러 시도들을 해보았는데요\n하지만 여러가지 조건들에 막혀 초기 계획인 학교내에 해당 프로젝트를 실행한다는 것은 실패하였습니다. 어떠한 문제조건에 막혀 프로젝트를 진행하지 못하였는제 설명드리면\n왼쪽에 보이는 이미지가 학교에서 실제로 사용하고 있는 공인 IP 목록 입니다 명지대 전산원 신청서를 통해 2048개의 공인 ip 중 1개를 받아서 사용할 수 있 단 조건이 필요합니다\n전화를 통해 질의한 결과 명지대학교라는 네트워크 망내부에서 공인 ip 를 받기 위해서는 외부 인바운드 시에는 방화벽을 통과해야 하는데 해당 방화벽을 완전 open 하는 것은 불가능하다는 답변을 받았습니다 저희 프로젝트의 경우 학생이 컨테이너를 생성하는 경우 포트를 2개 씩 동적으로 배정받는데 이렇게 방화벽이 존재한다면 프로젝트의 진행이 차질히 생깁니다\n그래서 조건을 바꾸어서 학교 내에서 와이파이를 잡을때 만이라도 구동이 된다면 어떨까 했을때는 오른쪽을 보시면 되는데요 오른쪽은 현재 학교 네트워크 망을 간단히 그려본 것입니다 10.10.xx.xx 대역의 망을 중심으로 하위에 MJUWLAN, 강의실 마다 존재하는 y5401 등등의 iptime 공유기 NAT 가 존재합니다 만약 저희가 10.10.xx.xx 망의 ip를 받을 수 있다면 학교내에서는 사용할 수 있다는 결론이 나오지만 10.10.xx.xx 를 받는 것또한 실패하였습니다\n그래서 현재는 home 서버 형태로 구성되어 있는 상태입니다\n프로젝트 진행시 가장 어려웠던 점 및 해결과정입니다\n학교 수업중 여러번 다루어지는 주제인 Coherency 문제입니다 db 에서 특정 행을 조회할때나 운영체제에서 cache 를 접근할 때 많이 다루어지는 유명한 문제인데 접근하는 정보가 진실임을 보장하지 않을 때 inconsistency 가 발생하는 문제입니다 저희도 똑같은 문제를 경험했는데요.\ndocker deamon 과 db 에서 조회하는 정보가 다를때 인데요\n모든 crud 작업을 docker deamon 에서 직접 처리하도록 한다면 해당 문제를 발생하지 않을 것인데 이렇게만 처리한다면 docker deamon 에 큰 부담을 주게 됩니다\n그림은 정상 프로세스 진행과 비정상 프로세스 진행입니다\n.. …\n이러한 문제를 저희는 여러 논리를 붙여서 해결했는데요 하지만 이러한 해결 접근은 근본적인 해결책은 아니라고 느꼈습니다 해당 문제를 해결할 때 사용하는 주된 용어가 source of truth 라는 개념인데요 접근하는 정보가 진실임을 보장하는 의미 입니다\n기존 db 를 사용자 인증 관리에만 국한하고 컨테이너의 생성, 상태, 소유권 등 모든 운영 정보는 각 Docker 호스트로부터 실시간으로 조회하여 메인 API 서버(Python Flask)의 인메모리 캐시에 저장 및 관리하며 . 컨테이너와 사용자의 매핑은 엄격한 컨테이너 네이밍 규칙을 통해 이루어진다. 이는 Docker 호스트의 실제 상태를 시스템의 유일한 진실 공급원(Source of Truth)으로 삼아 DB와 실제 상태 간의 불일치 가능성을 원천적으로 제거하려는 설계의도 입니다\n2번째는 프로젝트 시연할 때 받은 피드백인데요\n현재 이미지의 경우 저희가 만들어둔 것 이외에는 수동으로 만들어야 하는데 커뮤니티 기능을 활성화 하여 사용자끼리 공유가 되게 만들면 더 좋겠다는 생각을 하였습니다\n마지막으로 보안 이유 및 법적 검토인데요 최근 skt 보안 사고 발생으로 한번 고민해볼 만한 주제라고 판단되어 해당 주제를 들고 와봤는데요\n먼저 저희 프로젝트의 login 프로세스를 짚고 나머지를 설명드리겠습니다\n…\n이러한 방식으로 프로세스가 진행되는데 해당 아이디어와 비슷하게 구현한 세종대 github 를 발견하였고 제작자에게 문의를 하여보았습니다\n사이트를 보여주면서\n질의 내용의 결론은 이렇습니다\n학번을 db 에 저장하면서 부터 개인정보 처리자로 인식된다 저희가 만든 프로젝트는 개인정보 보호법과 해당 학교의 이용약관 보안 정책에 대한 이행의무를 가진다 학교의 이용약관 및 보안정책 이행에 있어서는 문제가 없고 개인정보 보호법에는 약간의 수정을 거친다면 문제가 없도록 만들수 있다 위의 결론은 법적 자문을 받지는 않았기 때문데 보증을 할 수 없지만 큰 축에서는 엇나가지 않을 것이라고 판단됩니다\n…\n저희 프로젝트는 사용자의 비밀번호를 저장하지 않지만 찾아보는 김에 정리를 해보았는데요\n…\n지금까지 들어주셔서 감사합니다"},"title":"mjuecs 발표 스크립트"},"/06.university/mju_ecs-project/mjuecs-%EC%B5%9C%EC%A2%85-%EB%B0%9C%ED%91%9C/":{"data":{"":"실제 시연 =\u003e oracle database 연결, 김직수 교수 클라우드 등등 기술적 검토 로그인시 명지대 서버와 통신하는 과정 법적 검토 =\u003e 최근 skt 보안 사고로 인해 이것을 조금 확실하게 따질 필요가 있어 보임 실제 프로덕트를 운영하더라도 수익이 없고 학생들이 한 프로젝트를 제제하는 경우는 잘 없음(세종대) 하지만 초기에는 학번만 저장하면 실제 서비스해도 법적인 문제가 발생하지 않을 것이라는 생각을 하였음 현제 해당 프로젝트는 학교의 비밀번호 아이디를 입력하여 로그인 할 수 있도록 만들어 두었음 비밀번호의 경우 당연히 민감한 개인정보라고 생각하여 초기 설계부터 완전히 저장하지 않는 방향으로 설계하였음 하지만 학교의 학번이 민감한 개인정보인 경우 이것이 법적으로 문제가 될수 있다는 생각을 하였고 해당하는 학교에 로그인이 가능한 프로젝트를 구현한 세종대 github 프로젝트(sejong-univ-auth) 에 직접 질문을 통해 법적 내용을 공유받아 해당 내용을 공유하려고함 실제로 내가 질문한 내용 이슈 접근방식 제공모듈 자체는 개인정보 처리자로 인식되지 않아 상관없지만 해당 모듈(방법론)을 사용하여 프로젝트를 진행할 경우 개인정보 처리자로 인식이 되며 관련 법규에 대한 제제를 받는다 서비스 사업자는 개인정보 법률 및 해당대학교 이용약관 보안정책에 대한 이행의무를 가진다 현재 학번을 database 평문저장하고 있음 개인정보 법률 -\u003e 정확한 판단이 불가 아이디 -\u003e github 등 여러가지 사이트가 이미 아이디를 공개적인 검색으로 사용 학번 단독으로 저장되었는데 이 경우 개인정보로 보아도 되는가? 실제 명지대 보안 정책 -\u003e 학교의 보안정책은 괜찮다 3장 6조 1항 학교는 이용자가 이 약관의 의무를 위반하거나 서비스의 정상적인 운영을 방해한 경우, 경고, 일시정지, 영구이용정지 등으로 서비스 이용을 단계적으로 제한할 수 있다. 동일 계정으로 계속 요청을 하면 일정 시간(10분) 자동으로 막힘으로 고려할 필요가 없다 3장 9조 5항 아호 학교의 동의 없이 영리를 목적으로 서비스를 사용하는 행위 해당 법적인 검토를 통해 실제 프로덕션 상황에서 실제 어떠한 문제가 발생할 수 있는지 간접적인 경험이 되었음"},"title":"mjuecs 최종 발표"},"/06.university/mju_ecs-project/mjuecs-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-%EB%B0%9C%ED%91%9C/":{"data":{"":"","futre-works-고도화-방안#Futre Works (고도화 방안)":"데이터베이스(DB)의 역할을 사용자 인증 정보 관리에만 국한하고, 컨테이너의 생성, 상태, 소유권 등 모든 운영 정보는 각 Docker 호스트로부터 실시간으로 조회하여 백엔드 서버측의 인메모리 캐시에 올려두고(캐싱) 저장 및 관리 컨테이너와 사용자의 매핑은 엄격한 컨테이너 네이밍 규칙 또는 container labeling 기능을 활용하여 이는 Docker 호스트의 실제 상태를 시스템의 유일한 진실 공급원(Source of Truth)으로 삼아 DB와 실제 상태 간의 불일치 가능성을 원천적으로 제거하려는 설계 docker host 를 메인 서버와 분리하여 scale out 이 가능하게 설계한다면 이것은 네트워크 3계층 네트워크 계층의 데이터 플레인 계층과 제어 플레인 계층의 구분과 역할에 많은 공통점이 있다고 판단함 네트워크 에서의 영감을 받아 해당 프로젝트를 고도화 하고자 하는 방향이 있음 커뮤니티 기능을 활성화 하여 image 템플릿을 사용자간 공유 업로드 하여 사용할 수 있다면 더욱 활성화가 가능할 것으로 보임 참고 : mjuecs 발전 방향 및 고도화 아키텍쳐 설계서","기타-프로젝트-성과를-잘-설명할-수-있는-사항들#기타 프로젝트 성과를 잘 설명할 수 있는 사항들":"Danger\n법적 검토 : 최근 SKT 의 보안 사고 이슈\n현재 해당 프로젝트의 기능중 하나인 학교 아이디와 비밀번호로 로그인이 가능하게 하였는데\n해당 기능과 비슷하게 세종대에서 구현한 모델이 있어 소개하고 해당 프로젝트를 설계 및 구현한 사람에게 법률 관련 문의를 질의함\n학교 로그인 프로젝트 github\nConclusion\n해당 프로젝트는 개인정보 보호법과 해당 학교의 이용약관 및 보안정책에 대한 이행의무를 가진다 학교의 이용약관에서는 문제가 없다고 판단이 되고 개인정보 보호법에는 약간의 수정을 거친다면 문제가 없을 수 있다고 판단된다 하지만 해당 판단은 법률지식이 없는 공대생 입장이므로 법률 전문가의 질의가 필요하다고 판단된다","따져봐야할-지점---사용자의-학번은-db-에-평문으로-저장#따져봐야할 지점  : 사용자의 학번은 db 에 평문으로 저장":"비밀번호의 경우 암호화 저장이 맞지만 아이디의 경우 평문저장이 문제가 되지 않는다 (해당 id(학번)은 웹사이트내에서 사용됨으로 평문으로 필요)\n하지만 사용자의 id 가 db 에 저장되는 순간 법적으로 개인정보 처리자로 인식, 또한 학교구성원의 정보 임으로 학교 이용약관의 이행의무 또한 가지고 있음\n학교 정보 처리 이용 약관\n3장 6조 1항 학교는 이용자가 이 약관의 의무를 위반하거나 서비스의 정상적인 운영을 방해한 경우, 경고, 일시정지, 영구이용정지 등으로 서비스 이용을 단계적으로 제한할 수 있다. =\u003e 의도적으로 서버측에 과도한 요청을 날리는 문제인데 동일 계정으로 서버측에 요청을 하면 일정 시간 자동으로 막힘 따로 제한할 필요가 없다 3장 9조 5항 아호 학교의 동의 없이 영리를 목적으로 서비스를 사용하는 행위 =\u003e 영리를 목적으로 사용하지 않으므로 상관이 없음 사용자의 정보를 저장하는 경우 사용자에게 개인정보 처리 방침을 공시하여야 한다\n개인정보 보호법 제29조 (안전조치 의무) 개인정보 처리자는 개인정보가 분실·도난·유출·변조·훼손되지 않도록 안전성 확보에 필요한 기술적·관리적 조치를 해야 함. Tip\n별점 -\u003e 비밀번호 저장 방침\n사용자의 정보중 비밀번호를 저장하려고 하는 경우\n정보통신망법 제28조 (개인정보의 보호조치) 이용자의 개인정보를 보호하기 위해 비밀번호는 암호화하여 저장해야 하고, 해킹이나 유출 우려가 없도록 접근통제·방화벽 구축 등의 조치를 해야 함. 개인정보의 기술적·관리적 보호조치 기준 (행정안전부 고시) 비밀번호는 복호화가 불가능한 **단방향 암호화(SHA-256 이상)**로 저장할 것. 가능하면 비밀번호 정책(복잡성, 최소 길이, 변경 주기) 도 설정해야 함.","목차#목차":"프로젝트 주제 선정 이유 및 구현하려고 했던 목표 실제 프로젝트 구현 내용 및 원래 목표와의 차이 (목표 대비 미흡한 점 혹은 초과 달성한 성과 등) 프로젝트 진행시 가장 어려웠던 점 및 해결 과정 프로젝트 결과 아쉬웠다고 생각되는 점 및 성과라고 생각되는 점 Futre Works (고도화 방안) 기타 프로젝트 성과를 잘 설명할 수 있는 사항들 (자유롭게)","비정상-프로세스#비정상 프로세스":"docker demon 에서 컨테이너의 상태가 up, db 또한 컨테이너의 상태가 up 상태라고 저장되어 있음 사용자가 터미널에서 kill -9 1 입력 최상위 프로세스를 종료 (bare machine 의 init 프로세스는 아니지만 컨테이너 최상위 프로세스임) docker 컨테이너 상태가 정지됨 하지만 db 에는 그대로 up 상태임을 나타냄","실제-프로젝트-구현-내용-및-원래-목표와의-차이#실제 프로젝트 구현 내용 및 원래 목표와의 차이":"학교 망 내부에서 해당 프로젝트를 구성해서 실제 구동 및 유비보수 비용이 들지 않도록 만들려고 했지만 학교 내부에서 방화벽 없이 사용할 수 있는 ip 를 받지 못함\nInfo\n학교 공인 IP 대역\n서브넷 마스크 : 255.255.248.0 IP 개수 : 2(32 - 21) = 2048개 (첫 번째와 마지막 주소 포함) 네트워크 주소 : 117.17.150.0, 브로드캐스트 주소 : 117.17.157.255, 사용 가능한 호스트 주소 범위 : 117.17.150.1 ~ 117.17.157.254\n학교 내부망의 경우 10.xx.xx.xx 망을 중심으로 Tree 형태로 구성되어 있다\n하위에 192.168 사설 망(Y5401, Y5445, MJUWLAN)들이 존재","정상-프로세스#정상 프로세스":"docker demon 에서 컨테이너의 상태가 up, db 또한 컨테이너의 상태가 up 상태라고 저장되어 있음 사용자가 웹 화면에서 정지 버튼을 누름 docker 컨테이너 상태가 정지됨 하지만 db 또한 stop 상태로 업데이트","캡스톤-디자인1-최종-발표-mjuecs#캡스톤 디자인1 최종 발표 MJUECS":"","프로젝트-주제-선정-이유-및-구현하려고-했던-목표#프로젝트 주제 선정 이유 및 구현하려고 했던 목표":"Warning\n컴공 또는 정통 수업에서 실습시 개발환경 구성하기가 쉽지 않는 경우가 많음\n아키텍쳐 문제 apple silicon 은 aarch64 기반, database 수업시 oracle database 기반으로 수업이 많이 진행됨 oracle databse 의 경우 amd64 아키텍쳐만 지원 클라우드 컴퓨팅(하둡, spark system 이미지), system 최근은 이러한 경우가 많이 사라졌지만 여전히 이와 같이 아키텍쳐에 종족적인 경우가 많음 system programming 에서 시스템 콜 실습시에 sys_write 번호는 x86-64에서 1, AArch64에서도 64입니다. 컴퓨터 구조론, 컴퓨터 아키텍쳐와 같은 저수준을 다루는 수업에서는 일반적으로 오랬동안 산업계에서 절대적인 위치를 가져왔던 amd64 아키텍쳐가 기본적으로 사용됨 자동화 문제 Warning\n프로젝트 진행시에 공동 db 를 만들어 두고 개발시 dummy data 같은 것들을 미리 넣어두고 사용하면 테스트시 편리함\nGoal\n목표 : 명지대 학생만 무료로 사용할 수 있는 컨테이너 기반 클라우스 서비스","프로젝트-진행시-가장-어려웠던-점-및-해결-과정#프로젝트 진행시 가장 어려웠던 점 및 해결 과정":"컨테이너의 상태를 db 에서 관리하고 있는데 도커 데몬 출력과의 데이터 불일치가 일어날 가능성이 존재\n사용자가 터미널에서 컨테이너를 강제로 정지시킬때 kill -9 1 해당 문제가 발생","해결#해결":"해당 문제를 전형적인 Cache Inconsistency 와 비슷한 문제 로 판단하여 여러 논리들을 붙여서 해결했지만 근본적인 해결 책이 아니라고 느낌, source of Truth 아키텍쳐로 설계해야 옳다는 결론"},"title":"mjuecs 프로젝트 발표"},"/06.university/mju_ecs-project/mjuecs-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/":{"data":{"":"mux","-docker-api-컨테이너-상태stats-실시간-보기#📈 docker api 컨테이너 상태(Stats) 실시간 보기":"curl --unix-socket /var/run/docker.sock http://localhost:2375/containers/{containerId}/stats CPU 사용률, 메모리, 네트워크 I/O, 디스크 I/O 등의 실시간 데이터를 스트리밍 방식으로 반환합니다. 로컬에서 Docker API 사용해보기 (Unix 소켓 기반):\n# 컨테이너 목록 보기 curl --unix-socket /var/run/docker.sock http://localhost/containers/json # 특정 컨테이너 로그 보기 curl --unix-socket /var/run/docker.sock http://localhost/containers/my_container/logs?stdout=1 # 컨테이너 시작 curl -X POST --unix-socket /var/run/docker.sock http://localhost/containers/my_container/start","배포#배포":"사용자가 docker 그룹에 존재하는가 sudo usermod -aG docker $USER my-ttyd-docker 이미지가 존재하는가 =\u003e docker build -t my-ttyd-docker .\nh2 기본 db 를 만들었는가 java -cp h2-2.3.232.jar org.h2.tools.Shell h2 database 사용법\nselect * from STUDENT; select * from DOCKER_CONTAINER; select * from TTYD_CONTAINER;","프로젝트-개요#프로젝트 개요":"mju_ecs는 명지대 학생들을 대상으로 컨테이너 컴퓨팅 자원을 빌려주는 서비스 입니다.\naws 의 컨테이너 서비스인 ecs 서비스와 일정 부분 비슷하지만 무료 유료 부분, 규모에서 차이가 있습니다"},"title":"mjuecs 프로젝트"},"/06.university/mju_ecs-project/mjuecs-2/":{"data":{"":"","1-개요#1. 개요":"본 문서는 AWS ECS(Elastic Container Service)와 유사한 사용자 맞춤형 컨테이너 기반 컴퓨팅 자원 제공 서비스를 구축하기 위한 상세 설계안을 기술한다. 사용자는 본 서비스를 통해 독립된 Docker 컨테이너 환경을 할당받아 원하는 애플리케이션을 실행할 수 있다.\n본 서비스의 가장 큰 기술적 특징은 데이터베이스(DB)의 역할을 사용자 인증 정보 관리에만 국한하고, 컨테이너의 생성, 상태, 소유권 등 모든 운영 정보는 각 Docker 호스트로부터 실시간으로 조회하여 메인 API 서버(Python Flask)의 인메모리 캐시에 저장 및 관리하는 것이다. 컨테이너와 사용자의 매핑은 엄격한 컨테이너 네이밍 규칙을 통해 이루어진다. 이는 Docker 호스트의 실제 상태를 시스템의 유일한 진실 공급원(Source of Truth)으로 삼아 DB와 실제 상태 간의 불일치 가능성을 원천적으로 제거하려는 설계 의도를 반영한다.\n주요 기능:\n사용자 가입 및 인증 사용자별 Docker 컨테이너 생성, 조회, 시작, 중지, 삭제 컨테이너 자원 제한 (CPU, 메모리) 컨테이너 자동 배치 (스케줄링) 사용자별 컨테이너 생성 개수 제한 주기적인 컨테이너 상태 검사 및 정책 기반 관리","1-서론#1. 서론":"본 보고서는 제시된 “컨테이너 기반 컴퓨팅 제공 서비스 프로젝트 설계서”(이하 설계서)에 대한 심층 분석을 제공하고, 잠재적인 문제점, 개선 방안, 그리고 추가적으로 고려해야 할 사항들을 다각적으로 제시하는 것을 목적으로 합니다. 설계서의 핵심은 AWS ECS와 유사한 컨테이너 관리 플랫폼을 구축하되, 데이터베이스의 역할을 사용자 인증 정보 관리에만 국한하고, 컨테이너 관련 모든 운영 정보는 Docker 호스트로부터 실시간으로 조회하여 API 서버의 인메모리 캐시에 저장 및 관리하는 것입니다. 이 방식은 Docker 호스트를 시스템의 ‘단일 진실 공급원(Source of Truth)‘으로 삼아 데이터 불일치 가능성을 원천적으로 제거하려는 독창적인 접근 방식을 취하고 있습니다.\n본 보고서는 설계서의 주요 특징과 장점을 먼저 살펴본 후, 아키텍처, 데이터 관리, 보안, 확장성, 안정성 등 다양한 측면에서 발생할 수 있는 도전 과제와 한계점을 분석할 것입니다. 이를 바탕으로 시스템의 완성도와 지속 가능성을 높이기 위한 구체적인 개선 방안과 추가 고려 사항을 제안하여, 성공적인 프로젝트 구현에 기여하고자 합니다. 특히, “단일 API 서버 인스턴스” 및 “300명 이내 사용자\"라는 초기 운영 규모 제약을 고려하여 현실적인 분석과 제안을 드리도록 하겠습니다.","10-사용자-인터페이스-ui#10. 사용자 인터페이스 (UI)":"사용자가 서비스를 편리하게 이용할 수 있도록 웹 기반 UI를 제공 UI는 별도의 프론트엔드 프로젝트(예: React, Vue.js, Angular 사용)로 개발하여 API를 호출한다 UI 주요 기능: 회원가입, 로그인 컨테이너 목록 보기 (이름, 상태, 포트 등) 새 컨테이너 생성 폼 (이미지 선택, 이름 접미사 입력, 포트 설정 등) 컨테이너 제어 버튼 (시작, 중지, 삭제) 컨테이너 터미널 연결 컨테이너 로그 보기 (옵션)","11-주요-도전-과제-및-한계점-본-설계-방식-채택-시#11. 주요 도전 과제 및 한계점 (본 설계 방식 채택 시)":"전적인 메모리 의존성 및 상태 유실 위험: Flask API 서버의 인메모리 캐시에 모든 컨테이너 운영 상태가 의존한다. 서버 장애 또는 재시작 시 모든 캐시 정보가 유실되며, Docker 호스트를 전수 조사하여 상태를 재구성하는 “웜업” 과정이 필수적이다. 이 과정 동안 서비스의 일시적 불안정성이 발생할 수 있다. 단일 인스턴스 확장성 제약: 현재 아키텍처는 API 서버의 수평적 확장이 어렵다. 여러 인스턴스가 각자의 메모리 캐시를 가지면 상태 불일치가 발생하므로, 고가용성 및 부하 분산을 위한 일반적인 웹 서비스 확장 전략 적용에 한계가 있다. (외부 공유 캐시 도입 시 설계 원칙 변경) 하지만 본 프로젝트는 1개의 망에서만 동작하며 동시접속자 수나 사용자 수가 300 명 이내 설계이므로 상관없다 데이터 영속성 및 감사 추적의 어려움: 컨테이너가 시스템에서 삭제되면, 해당 컨테이너의 과거 존재 이력이나 상세 설정 정보가 메모리에서 완전히 사라진다. 문제 발생 시 과거 상태를 추적하거나 정교한 감사 로그를 확보하기 위해서는 매우 철저하고 별도의 로깅 시스템에 의존해야 한다. 성능 병목 가능성: 관리하는 Docker 호스트 및 전체 컨테이너 수가 크게 증가할 경우, 주기적인 전체 상태 폴링, 대규모 캐시 관리, 메모리 내에서의 빈번한 필터링 작업 등이 Flask API 서버의 성능 병목 지점이 될 수 있다. 본 설계는 “DB에는 최소한의 정보만, 모든 운영 상태는 실시간 조회 및 메모리 캐시\"라는 핵심 원칙 하에 작성되었다. 이로 인해 얻는 실시간성과 단순함의 이면에는 위에서 언급된 도전 과제들이 존재함을 명확히 인지하고, 시스템 개발 및 운영 단계에서 이에 대한 면밀한 고려와 대비가 필요하다.","2-설계서-주요-특징-및-장점-분석#2. 설계서 주요 특징 및 장점 분석":"설계서는 몇 가지 주목할 만한 특징과 그에 따른 장점을 가지고 있습니다.\nSource of Truth로서의 Docker 호스트 및 실시간 상태 반영: 컨테이너의 실제 상태 정보를 각 Docker 호스트에서 직접 가져와 인메모리 캐시에 반영하는 방식은 이론적으로 데이터베이스와 실제 상태 간의 불일치 문제를 원천적으로 방지할 수 있습니다. 이는 시스템 상태의 정확성과 신뢰성을 높이는 데 기여합니다. DB는 오직 사용자 인증이라는 명확하고 제한된 역할만 수행하므로, 시스템의 복잡도가 낮아지고 특정 컴포넌트에 대한 의존성이 줄어듭니다. 간결한 데이터 모델 및 DB 부하 최소화: 사용자 인증 정보만을 DB에 저장함으로써, DB 스키마가 매우 단순해지고 DB 관련 작업 부하가 현저히 줄어듭니다. 컨테이너의 빈번한 상태 변경, 생성, 삭제 등의 이벤트가 DB 트랜잭션을 유발하지 않으므로 DB 성능 병목 현상 발생 가능성을 최소화합니다. 엄격한 네이밍 규칙 및 라벨 기반 소유권 관리: 컨테이너 이름에 [user_id]를 포함하고, owner_user_id 라벨을 통해 소유권을 명확히 하는 방식은 직관적이며, 사용자별 자원 격리 및 관리를 용이하게 합니다. 이는 인메모리 캐시에서 사용자별 컨테이너를 필터링하고 제어하는 로직을 단순화합니다. Python Flask 및 Docker SDK 활용: 검증된 기술 스택인 Python Flask와 docker SDK를 활용함으로써 개발 생산성을 높이고, 풍부한 라이브러리 생태계를 활용할 수 있습니다. Nginx, PostgreSQL/MySQL 등 표준적인 오픈소스 기술을 채택하여 비용 효율적인 시스템 구축이 가능합니다. 명확한 역할 분담: 제어 플레인(API 서버, DB, 웹 서버)과 데이터 플레인(Docker 호스트)의 역할이 비교적 명확하게 구분되어 있어, 각 구성 요소의 독립적인 관리 및 확장이 용이한 구조의 기반을 마련하고 있습니다. 이러한 특징들은 특히 초기 개발 단계에서 빠른 프로토타이핑과 구현을 가능하게 하며, 소규모 환경에서는 충분히 효과적으로 운영될 수 있는 잠재력을 가지고 있습니다.","2-시스템-아키텍처#2. 시스템 아키텍처":"2.1. 구성 요소\n물리적/가상 머신 구성 (최초 제안 기반): 컴퓨터 1 (제어 플레인): 사용자 인증 데이터베이스: PostgreSQL 또는 MySQL 사용. 사용자 계정 정보만 저장. 메인 API 서버: Python Flask 기반으로 개발. 모든 비즈니스 로직, Docker 호스트 연동, 인메모리 캐시 관리 수행. 웹 서버/리버스 프록시: Nginx 사용. SSL/TLS 종료, 로드 밸런싱(단일 Flask 인스턴스 환경에서는 주로 정적 파일 서빙 및 리버스 프록시 역할), 요청 포워딩. 컴퓨터 2, 3, 4 … (데이터 플레인 - Docker 호스트): Docker Engine 설치 및 실행. 실제 사용자 컨테이너들이 구동되는 환경. host 상태를 주기적으로 확인 및 전송할 수 있는 서비스( Grafana, Prometheus, node-exporter) 필요에 따라 수평적으로 확장 가능. 소프트웨어 스택: OS: Linux 백엔드: Python (Flask 프레임워크) 웹 서버: Nginx 컨테이너 기술: Docker Engine 데이터베이스: PostgreSQL 또는 MySQL 라이브러리: docker (Python Docker SDK), APScheduler (백그라운드 작업), bcrypt (비밀번호 해시), JWT 관련 라이브러리 (예: PyJWT). 2.2. 데이터 흐름\n사용자 요청: 클라이언트(웹 UI 또는 API 클라이언트)가 서비스 API를 호출한다. Nginx: 요청을 수신하여 필요한 경우 SSL/TLS 처리를 수행하고, Flask API 서버로 요청을 전달한다. Flask API 서버 (인증): 인증이 필요한 요청의 경우, 요청 헤더의 JWT 토큰을 검증한다. 로그인/가입 시에는 DB의 사용자 테이블을 조회/수정한다. Flask API 서버 (컨테이너 관련 요청): 조회/상태 확인: 관리 중인 컨테이너 정보는 자체 인메모리 캐시에서 조회한다. 생성/삭제/제어: 스케줄링 로직에 따라 대상 Docker 호스트를 결정하고, 해당 호스트의 Docker Engine API를 직접 호출하여 작업을 수행한다. 작업 결과 및 최신 상태는 즉시 인메모리 캐시에 반영된다. Docker 호스트: Flask API 서버의 요청에 따라 컨테이너를 생성, 시작, 중지, 삭제하고 그 결과를 반환한다. 응답: Flask API 서버는 처리 결과를 Nginx를 통해 클라이언트에게 반환한다. 2.3. 네트워크 구성\nFlask API 서버\n모든 docker host 의 ip 와 접근가능한 포트를 구성파일에 기록해둔다\n{ \"server1\":{ \"ip\" : \"192.168.0.56\", \"port_range\" : [ 10000, 11999 ] }, \"server2\":{ \"ip\" : \"192.168.0.57\", \"port_range\" : [ 12000, 13999 ] }, \"server3\":{ \"ip\" : \"192.168.0.58\", \"port_range\" : [ 14000, 15999 ] }, \"server4\":{ \"ip\" : \"192.168.0.56\", \"port_range\" : [ 16000, 17999 ] }, \"server5\":{ \"ip\" : \"192.168.0.56\", \"port_range\" : [ 18000, 19999 ] }, \"server6\":{ \"ip\" : \"192.168.0.56\", \"port_range\" : [ 20000, 11999 ] } } Flask API 서버 - Docker 호스트 간 통신:\nDocker Engine API는 기본적으로 TCP 포트(예: 2375 - 비암호화, 2376 - TLS 암호화)를 통해 노출된다. TLS를 사용한 암호화 통신을 강력히 권장한다. 각 Docker 호스트의 방화벽에서 Flask API 서버의 IP 주소에서만 Docker API 포트로의 접근을 허용하도록 설정한다. 사용자 - 생성된 컨테이너 간 접근:\n사용자는 원하는 컨테이너 특정 내부포트를 정할 수 있고 개수의 경우 규칙을 따른다(max 4개) 컨테이너 생성 시 docker host port_range 중에서 임의로 특정 포트를 컨테이너 내부 포트에 매핑한다 (예: 호스트 포트 30001 -\u003e 컨테이너 포트 80). 사용자는 [호스트IP]:[매핑된_호스트포트] 와 같은 방식으로 컨테이너에 접근한다. 포트 충돌 방지를 위해 동적 포트 할당이 필요하다.","3-데이터베이스-설계-사용자-인증-전용#3. 데이터베이스 설계 (사용자 인증 전용)":"데이터베이스 시스템: PostgreSQL, MySQL, sqlite 테이블 정의: users 테이블: user_id (VARCHAR(255), Primary Key): 사용자가 직접 입력하는 ID (평문 저장). hashed_password (VARCHAR(255), Not Null): bcrypt 또는 Argon2를 사용해 해시된 비밀번호. last_login (TIMESTAMP, Default CURRENT_TIMESTAMP): 마지막 login 시간. template 테이블 template_id (VARCHAR(255), Primary Key) user_id : 만든 사용자 is_administrator : 관리자 유무 json 파일 : DB 사용 원칙: 오직 사용자 가입 여부 확인 및 비밀번호 검증을 통한 인증 처리에만 사용된다. 컨테이너 관련 정보(ID, 상태, 소유권, 설정 등)는 이 DB에 일절 저장하지 않는다.","3-설계서의-잠재적-문제점-및-한계점-심층-분석#3. 설계서의 잠재적 문제점 및 한계점 심층 분석":"설계서의 독창적인 접근 방식은 여러 장점을 제공하지만, 동시에 몇 가지 중요한 잠재적 문제점과 한계점을 내포하고 있습니다.\n3.1. 인메모리 캐시 의존성의 위험 및 상태 유실\n단일 장애점 (Single Point of Failure): API 서버의 인메모리 캐시는 시스템의 모든 운영 상태를 담고 있는 핵심 요소입니다. 만약 API 서버(Flask 애플리케이션)에 장애가 발생하거나 재시작될 경우, 캐시된 모든 정보가 유실됩니다. 이는 서비스 전체의 즉각적인 중단 또는 심각한 기능 장애로 이어집니다. “단일 API 서버 인스턴스\"를 전제로 하므로, 이 서버의 안정성이 전체 시스템의 안정성과 직결됩니다. 웜업(Warm-up) 시간 및 서비스 불안정성: API 서버 재시작 시, 모든 Docker 호스트에 접속하여 현재 실행 중인 컨테이너 정보를 수집하고 캐시를 재구성하는 “웜업” 과정이 필수적입니다. 관리하는 호스트 및 컨테이너 수가 증가함에 따라 이 웜업 시간은 길어질 수 있으며, 이 시간 동안 API 서버는 불완전한 정보를 제공하거나 정상적인 서비스 처리가 불가능할 수 있습니다. 300명 사용자 규모에서는 컨테이너 수가 수백 개에 이를 수 있으며, 각 컨테이너 정보를 상세히 가져오는 과정은 수십 초에서 수 분이 소요될 가능성이 있습니다. 데이터 영속성 부재: 인메모리 캐시는 휘발성이므로, 컨테이너가 삭제된 후에는 해당 컨테이너의 과거 설정, 상태 변화 이력, 통계 정보 등이 시스템에서 완전히 사라집니다. 이는 감사 추적, 장애 원인 분석, 사용량 기반 과금 정책 수립 등에 심각한 제약을 초래합니다. 로깅에 전적으로 의존해야 하지만, 로그 데이터만으로는 정형화된 과거 상태 조회가 어렵습니다. 3.2. 확장성 제약\nAPI 서버 수평 확장 불가: 현재 설계는 API 서버가 모든 상태 정보를 자체 메모리에 가지므로, 여러 인스턴스로 수평 확장(scale-out)하는 것이 불가능합니다. 각 인스턴스가 독립적인 캐시를 가지면 상태 불일치가 발생하여 시스템이 오작동하게 됩니다. 사용자가 300명 이내로 제한되어 있고 단일 망에서 동작한다고 언급되었지만, 향후 서비스 성장에 따른 트래픽 증가나 처리 용량 증설 요구에 유연하게 대응하기 어렵습니다. 단일 인스턴스의 처리 용량을 넘어서는 요청이 발생하면 성능 저하 및 서비스 장애로 이어질 수 있습니다. 폴링 부하 증가: Docker 호스트 및 컨테이너 수가 증가할수록, 주기적인 상태 폴링 작업은 API 서버와 Docker 호스트 모두에 상당한 부하를 유발할 수 있습니다. 특히, 각 컨테이너의 실시간 자원 사용량(stats API)까지 주기적으로 수집한다면 네트워크 트래픽과 API 서버의 처리 부담이 크게 늘어납니다. 폴링 주기가 너무 길면 정보의 실시간성이 떨어지고, 너무 짧으면 시스템 부하가 가중되는 트레이드오프가 존재합니다. 3.3. 데이터 관리 및 감사 추적의 어려움\n상세 로깅의 중요성 및 부담: 설계서에서도 언급했듯이, 컨테이너 정보를 DB에 저장하지 않으므로 모든 활동에 대한 상세한 로깅이 필수적입니다. 이는 로깅 시스템 설계, 로그 데이터 저장 및 관리, 검색 및 분석에 대한 추가적인 부담으로 작용합니다. 로그 데이터의 양이 방대해질 수 있으며, 필요한 정보를 효율적으로 추출하고 분석하기 위한 별도의 시스템(예: ELK Stack) 구축 및 운영이 요구됩니다. 이력 추적의 한계: 로깅만으로는 특정 시점의 시스템 전체 스냅샷, 특정 컨테이너의 상세한 생명주기 이력, 설정 변경 이력 등을 체계적으로 추적하고 분석하기 어렵습니다. 이는 운영 중 문제 해결이나 사용자 지원 시 어려움으로 작용할 수 있습니다. 3.4. 네트워크 구성 및 포트 관리\n동적 포트 할당 및 충돌 방지 로직의 복잡성: 사용자가 요청한 컨테이너 내부 포트를 Docker 호스트의 특정 포트 범위 내에서 동적으로 매핑할 때, 사용 가능한 포트를 정확히 찾아 할당하고 중복 할당을 방지하는 로직이 API 서버 내에 견고하게 구현되어야 합니다. 여러 컨테이너가 동시에 생성 요청될 경우 경쟁 조건(race condition)이 발생하여 포트 충돌이 일어날 수 있습니다. 이에 대한 정교한 동기화 메커니즘이 필요합니다. IP 주소 변경 및 호스트 관리의 번거로움: Docker 호스트의 IP 주소가 변경되거나 호스트가 추가/삭제될 때마다 API 서버의 구성 파일을 수동으로 업데이트해야 합니다. 이는 운영 편의성을 저해하고 오류 발생 가능성을 높입니다. 3.5. 보안 고려 사항 심층 분석\nDocker API 접근 제어의 중요성: Flask API 서버만이 Docker 호스트의 API에 접근할 수 있도록 방화벽 설정을 하는 것은 기본이지만, API 서버 자체가 공격자에게 침해당할 경우 모든 Docker 호스트에 대한 통제권을 탈취당할 수 있는 위험이 있습니다. TLS 통신은 필수적이며, 인증서 관리 또한 중요합니다. 컨테이너 이름 및 라벨 의존성의 잠재적 취약점: 현재 컨테이너 이름([user_id]_[name_suffix])과 라벨(owner_user_id)을 통해 소유권을 판단합니다. 만약 이름 생성 규칙이나 라벨 주입 과정에 논리적 허점이 있거나, 사용자가 name_suffix에 특수문자나 예상치 못한 패턴을 입력하여 파싱 오류를 유발할 수 있다면, 의도치 않은 접근이나 정보 노출이 발생할 가능성을 배제할 수 없습니다. 입력값 검증이 매우 중요합니다. 이미지 보안 관리: 사용자가 임의의 Docker 이미지를 사용할 수 있도록 허용한다면, 악성 코드가 포함된 이미지나 보안 취약점이 있는 이미지를 통해 시스템 전체 또는 다른 사용자의 컨테이너에 영향을 미칠 위험이 있습니다. 이미지 검증 프로세스나 승인된 이미지 목록 사용 정책이 강력히 권장됩니다. 3.6. 장애 시나리오 및 복구 전략의 구체성\nDocker 호스트 장애: 호스트 장애 시 해당 호스트의 컨테이너가 “unreachable\"로 표시되는 것은 좋으나, 해당 컨테이너에 의존하는 사용자 서비스는 중단됩니다. 자동 복구(다른 호스트로 이전)는 초기 범위에 없다고 명시되었지만, 장애 발생 시 수동 복구 절차나 사용자 알림, 데이터 복구(만약 컨테이너 내부에 중요한 데이터가 있었다면) 방안에 대한 구체적인 계획이 부족합니다. 네트워크 장애: API 서버와 Docker 호스트 간, 또는 Nginx와 API 서버 간 네트워크 문제 발생 시 시스템 전체가 불안정해질 수 있습니다. 이에 대한 감지 및 대응 방안이 필요합니다. 3.7. 컨테이너 자원 관리의 세부 사항\n디스크 사용량 제한의 모호성: “50GB 가이드라인\"은 실제 강제적인 제한이 아니므로, 특정 사용자가 과도한 디스크 공간을 점유하여 호스트 전체의 디스크 부족을 유발할 수 있습니다. Docker 볼륨을 사용한 크기 제한은 관리 복잡성을 증가시키지만, 보다 명확한 통제가 가능합니다. 스토리지 드라이버 수준의 쿼터 설정은 환경에 따라 적용 가능성이 다릅니다. 컨테이너 자동 배치(스케줄링)의 제한: 사용자가 직접 호스트를 선택하는 방식은 단순하지만, 호스트의 현재 부하 상태나 자원 가용성을 고려하지 않아 특정 호스트에 부하가 집중될 수 있습니다. 이는 시스템 전체의 효율성을 저해할 수 있습니다.","4-api-서버-설계-python-flask#4. API 서버 설계 (Python Flask)":"4.1. 주요 기능 및 책임\n사용자 인증 관리: JWT 기반 토큰 인증 시스템 (가입, 로그인, 로그아웃, 토큰 검증). Docker 호스트 연동: docker Python SDK를 사용하여 각 Docker 호스트의 API와 통신. 컨테이너 생명주기 관리(생성, 시작, 중지, 삭제, 정보 조회, 로그 조회 등) 수행. 인메모리 캐시 관리: 모든 Docker 호스트로부터 컨테이너 및 호스트 상태 정보를 주기적으로 수집하여 자체 메모리에 캐싱. 이 캐시를 서비스 운영의 주 데이터 소스로 활용. 컨테이너 스케줄링: 사용자에게 전적으로 부여 , 생성시 원하는 host 를 선택할 수 있도록 함 자원 및 정책 관리: 사용자별 컨테이너 생성 개수 제한(예: 사용자당 2개), 컨테이너별 자원 할당(예: CPU 2개, 메모리 3GB) 등의 정책 시행. 컨테이너 터미널 : 컨테이너 터미널의 접근을 위해 websocket + xtermjs 을 사용하여 터미널접속이 사이트 내에서 가능하도록 한다 백그라운드 작업: APScheduler 등을 사용하여 주기적인 작업(예: 호스트 상태 폴링, 비활성 컨테이너 정리 등) 수행. 4.2. 인메모리 캐시 전략\n캐시 내용:\n컨테이너 정보: 각 Docker 호스트에 있는 모든 컨테이너의 상세 정보. host_name (실행 중인 Docker 호스트 식별자) docker_container_id (Docker가 부여한 ID) name (컨테이너 이름 - [user_id]_[사용자가 원하는 이름] 형식) owner_user_id (컨테이너 이름에서 파싱한 소유자 ID) image_name (사용된 이미지) status (running, exited, paused 등) ports (매핑 정보) created_at_docker (Docker가 기록한 컨테이너 생성 시간) cpu_usage_percent, memory_usage_mb (실시간 자원 사용량 - stats API 기반) last_polled_at (캐시 정보 갱신 시간) 호스트 정보: 각 Docker 호스트의 현재 상태. host_name (식별자) ip_address total_cpu, available_cpu total_memory_mb, available_memory_mb num_containers (해당 호스트에서 실행 중인 컨테이너 수) is_reachable (폴링 성공 여부) last_polled_at 캐시 갱신:\n설정된 주기(예: 3초 ~ 10초, 시스템 부하에 따라 조절 가능)마다 모든 등록된 Docker 호스트에 병렬적/순차적으로 API를 호출하여 정보를 가져와 캐시를 업데이트한다. 컨테이너 생성/삭제 등 주요 상태 변경 작업 시에는 즉시 해당 정보를 캐시에 반영한다. 캐시 구조: Python의 dict를 중첩하여 사용하거나, 필요시 직접 정의한 클래스 객체들을 저장.Python\n# 예시: # self.all_containers_cache = {\"docker_id_1\": ContainerInfo(...), \"docker_id_2\": ContainerInfo(...)} # self.host_status_cache = {\"host_A\": HostInfo(...), \"host_B\": HostInfo(...)} 애플리케이션 재시작 시 캐시 복구 (“웜업”):\nFlask 애플리케이션 시작 시, 인메모리 캐시는 비어있는 상태이다. 시작 루틴에서 설정된 모든 Docker 호스트에 접속하여 현재 실행 중인 모든 컨테이너 정보와 호스트 상태를 조회하고, 이를 파싱하여 전체 인메모리 캐시를 재구성한다. 이 과정은 호스트 및 컨테이너 수에 따라 시간이 소요될 수 있으며, 완료 전까지 서비스는 불완전한 정보를 제공할 수 있다. 4.3. 컨테이너-사용자 매핑 (라벨 기반)\n규칙: 모든 사용자가 소유한 컨테이너에는 owner_user_id=[user_id] 형식의 라벨이 반드시 포함되어야 한다. [user_id]는 컨테이너를 생성한 사용자의 ID이다. API 서버는 컨테이너 생성 시 인증된 사용자의 user_id를 사용하여 이 라벨을 자동으로 추가한다. 소유권 판단: API 서버는 Docker 호스트로부터 가져온 컨테이너 목록에서 각 컨테이너의 라벨(Docker API 응답의 Labels 필드)을 확인한다. owner_user_id 라벨 값을 해당 컨테이너의 owner_user_id로 간주한다. 사용자 관련 API 요청(예: 내 컨테이너 목록 조회) 처리 시, 인증된 사용자의 user_id와 캐시된 컨테이너의 owner_user_id (라벨에서 추출)를 비교하여 필터링한다. 컨테이너 이름: 컨테이너 이름은 사용자가 원하는 이름 4.4. API 엔드포인트 (예시)\n인증 API (/api/auth): POST /register: 사용자 가입 POST /login: 로그인 (JWT 토큰 발급) POST /logout: 로그아웃 (토큰 무효화 - 클라이언트 측에서 토큰 삭제 또는 서버 측 블랙리스트 관리) 컨테이너 API (/api/containers): GET /: 현재 인증된 사용자의 모든 컨테이너 목록 조회. POST /: 새 컨테이너 생성 요청. Request Body: { \"image\": \"ubuntu:latest\", \"name_suffix\": \"my_server\", \"ports\": {\"80/tcp\": null} } (포트는 null로 주면 동적 할당) GET /: 특정 컨테이너 상세 정보 조회. (이름은 [user_id]_[name_suffix] 형태) DELETE /: 특정 컨테이너 삭제. POST //start: 중지된 컨테이너 시작. POST //stop: 실행 중인 컨테이너 중지. 관리자용 API (/api/admin - 별도 인증 필요): GET /hosts/status: 모든 Docker 호스트의 현재 상태 및 캐시 정보 조회. GET /cache/inspect: Flask API 서버의 전체 인메모리 캐시 내용 조회 (디버깅용). POST /cache/refresh: 강제로 전체 캐시 갱신 수행.","4-개선-제안#4. 개선 제안":"앞서 분석된 문제점과 한계점을 보완하고 시스템의 안정성과 효율성을 높이기 위한 몇 가지 개선 방안을 제안합니다.\n4.1. 상태 관리 및 데이터 영속성 강화\n경량 외부 캐시/저장소 도입 고려 (원칙 수정 가능성 검토): “DB 외 다른 저장소 사용 안 함\"이라는 원칙이 시스템의 핵심 제약사항이라면 이를 존중해야 합니다. 그러나 API 서버의 단일 장애점 및 상태 유실 위험을 완화하기 위해, Redis와 같은 인메모리 키-값 저장소를 캐시의 보조 저장소 또는 짧은 주기의 스냅샷 저장 용도로 사용하는 방안을 신중히 검토해볼 수 있습니다. 장점: API 서버 재시작 시 Redis로부터 빠르게 상태를 복구하여 웜업 시간을 대폭 단축할 수 있습니다. 또한, 분산 락(Distributed Lock) 구현이 용이해져 동시성 제어 로직을 단순화할 수 있습니다. 트레이드오프: 초기 설계 원칙에서 벗어나며, Redis 관리 포인트가 추가됩니다. 대안 (원칙 유지 시): API 서버 시작 시 병렬/비동기 웜업 로직을 고도화하고, 웜업 진행 중임을 명확히 API 응답에 표시하여 사용자 혼란을 줄입니다. 주기적으로 인메모리 캐시의 스냅샷을 파일 시스템에 백업하고, 재시작 시 이 스냅샷을 우선 로드 후 Docker 호스트와 동기화하는 방안도 고려할 수 있습니다. (단, 파일 I/O 성능 및 일관성 문제 고려 필요) 이벤트 소싱(Event Sourcing) 패턴의 경량화된 적용: 컨테이너 생성, 삭제, 상태 변경 등의 주요 이벤트를 단순 로그 이상의 구조화된 형태로 파일 또는 경량 메시지 큐(예: SQLite를 활용한 로컬 큐)에 기록합니다. 이는 완전한 이벤트 소싱 시스템은 아니지만, 장애 발생 시 특정 컨테이너의 이력을 추적하거나 상태를 재구성하는 데 도움이 될 수 있습니다. 4.2. 안정성 및 가용성 향상 (단일 인스턴스 환경 내에서)\nAPI 서버 프로세스 관리 강화: Gunicorn 또는 uWSGI 사용 시 워커 프로세스 수를 적절히 설정하고, 워커 프로세스 비정상 종료 시 자동 재시작 등의 기능을 활성화하여 단일 머신 내에서의 안정성을 최대한 확보합니다. 정교한 헬스 체크 엔드포인트: API 서버 자체의 상태(예: /health/live), 주요 서브시스템(예: Docker 호스트 연결성, 캐시 상태 - /health/ready)을 확인할 수 있는 상세한 헬스 체크 엔드포인트를 구현합니다. 이는 모니터링 시스템과의 연동을 통해 빠른 장애 감지 및 대응을 가능하게 합니다. 비동기 처리 적극 도입: Flask 자체는 동기 방식이지만, 오래 걸리는 I/O 작업(특히 다수의 Docker 호스트에 API 호출)은 비동기적으로 처리하여 API 서버의 응답성을 향상시킬 수 있습니다. Flask 내에서 gevent나 asyncio와 함께 사용할 수 있는 라이브러리를 활용하거나, 오래 걸리는 작업은 Celery와 같은 별도의 태스크 큐 시스템으로 분리하는 것을 고려할 수 있습니다. (단, 태스크 큐 도입은 관리 포인트 증가) 4.3. 로깅 및 모니터링 시스템 고도화\n구조화된 로깅 (Structured Logging): JSON이나 key-value 형태의 구조화된 로그를 사용하여 로그 파싱 및 분석의 효율성을 높입니다. 로그 내용에는 타임스탬프, 사용자 ID, 컨테이너 ID, 요청 ID, 이벤트 유형, 성공/실패 여부, 오류 메시지 등을 명확히 포함합니다. 중앙 집중식 로깅 시스템 도입: 설계서에서 언급된 ELK Stack 또는 Grafana Loki + Promtail 조합은 300명 사용자 규모에서도 장기적으로 로그 관리의 효율성을 크게 높여줍니다. 초기에는 파일 기반 로깅으로 시작하더라도, 향후 확장을 염두에 두고 로그 포맷을 표준화하는 것이 좋습니다. 인메모리 캐시 모니터링 지표 추가: 캐시 크기(항목 수, 메모리 점유량), 웜업 소요 시간, 캐시 적중률(만약 캐시 미스가 발생할 수 있는 로직이 있다면), 폴링 주기별 처리 시간 등의 내부 메트릭을 Prometheus 등을 통해 노출하여 캐시 동작 상태를 면밀히 관찰합니다. 4.4. 네트워크 및 포트 관리 개선\n포트 할당 데이터베이스화 (경량): API 서버의 인메모리 캐시 내에 각 호스트별로 할당된 포트와 사용 중인 포트 목록을 실시간으로 관리하고, 컨테이너 삭제 시 즉시 반환 처리합니다. 포트 할당 로직에는 사용자 ID 또는 컨테이너 ID 기반의 락(Lock)을 적용하여 동시 요청 시에도 충돌을 방지합니다. (예: threading.Lock 사용, 분산 환경 고려 시 외부 락 필요) 호스트 정보 외부 설정 및 동적 로딩: Docker 호스트 목록을 JSON 설정 파일에서 읽어오되, API 서버가 특정 신호(예: SIGHUP)를 받거나 관리자 API를 통해 이 설정을 다시 로드할 수 있도록 하여, API 서버 재시작 없이 호스트 정보를 업데이트할 수 있는 유연성을 확보합니다. 4.5. 보안 강화\nAPI 서버 보안 강화: 모든 API 엔드포인트에 대해 입력값 유효성 검증(길이, 타입, 허용 문자 등)을 철저히 수행합니다. (Pydantic, Marshmallow 등 활용) 요청 속도 제한(Rate Limiting) 및 악의적 요청 패턴 감지/차단 기능을 Nginx 또는 API 게이트웨이(만약 도입한다면) 수준에서 적용합니다. JWT 토큰 탈취에 대비한 짧은 만료 시간 설정 및 리프레시 토큰 메커니즘 도입을 고려합니다. (로그아웃 시 서버 측 토큰 블랙리스트 관리는 단일 인스턴스에서는 가능하나, 복잡도 증가) 컨테이너 격리 강화 심화: --cap-drop=ALL 외에, no-new-privileges 옵션을 컨테이너 실행 시 추가하여 컨테이너 내부 프로세스가 추가적인 권한을 획득하는 것을 방지합니다. 읽기 전용 루트 파일시스템 (--read-only) 옵션을 적용하고, 필요한 경로만 쓰기 가능한 볼륨으로 마운트하는 방안을 고려합니다. AppArmor/Seccomp 프로필은 설정 및 관리가 복잡할 수 있으나, 높은 수준의 보안이 필요하다면 검토할 가치가 있습니다. 초기에는 적용하지 않더라도 향후 강화 방안으로 남겨둘 수 있습니다. 비밀(Secrets) 관리: Docker API 접근을 위한 TLS 인증서/키, DB 패스워드 등의 민감 정보는 코드나 설정 파일에 하드코딩하지 않고, 환경 변수, 또는 HashiCorp Vault와 같은 외부 비밀 관리 도구를 통해 안전하게 주입합니다. (단일 서버 환경에서는 환경 변수나 암호화된 설정 파일이 현실적일 수 있음) 4.6. 컨테이너 관리 로직 심화\n스케줄링 유연성 확보: 사용자가 호스트를 직접 선택하는 기능 외에, “자동 선택” 옵션을 제공하여 API 서버가 호스트의 현재 자원 가용성(CPU, 메모리, 실행 중인 컨테이너 수 등 - 캐시된 정보 기반)을 고려하여 최적의 호스트를 추천하거나 자동으로 배치하는 기능을 추가할 수 있습니다. 이는 사용자 편의성을 높이고 시스템 자원 활용 효율을 개선합니다. 디스크 사용량 제한의 현실적 접근: 주기적 모니터링 및 알림: docker system df 또는 개별 컨테이너의 docker exec df -h 결과를 주기적으로 수집/분석하여, 특정 컨테이너나 사용자가 과도한 디스크를 사용하는 경우 관리자 및 사용자에게 알림을 보냅니다. Docker 스토리지 드라이버 옵션 활용 (주의): 일부 스토리지 드라이버(예: overlay2)는 프로젝트 쿼터와 유사한 크기 제한 옵션(size)을 제공할 수 있으나, 이는 Docker 버전 및 시스템 환경에 따라 지원 여부나 안정성이 다를 수 있어 충분한 테스트가 필요합니다. 이미지 크기 사전 고지: 컨테이너 생성 시 사용될 이미지의 크기를 사용자에게 미리 알려주고, 남은 예상 작업 공간을 안내하는 것도 도움이 됩니다. 4.7. 사용자 경험(UX) 개선 사항\n실시간 알림: 컨테이너 생성 완료, 시작/중지, 오류 발생 등의 주요 이벤트 발생 시 웹 UI를 통해 사용자에게 실시간으로 알림을 제공합니다. (WebSockets 활용) 컨테이너 생성 템플릿: 자주 사용되는 애플리케이션 유형(예: 웹 서버, DB)에 대한 사전 정의된 컨테이너 설정 템플릿을 제공하여 사용자가 더 쉽게 컨테이너를 생성할 수 있도록 지원합니다. 상세한 오류 메시지 및 문제 해결 가이드: API 오류 발생 시, 단순한 HTTP 상태 코드 외에 사용자 친화적인 오류 메시지와 가능한 해결 방법을 안내합니다.","5-추가-고려-사항#5. 추가 고려 사항":"라이선스 및 비용: 사용되는 모든 오픈소스 소프트웨어의 라이선스를 확인하고 준수해야 합니다. 향후 클라우드 환경으로 확장하거나 상용 솔루션을 도입할 경우 관련 비용을 고려해야 합니다. 개발 및 운영 인력의 기술 스택: 현재 설계는 Python, Docker, Linux 등에 대한 숙련도를 요구합니다. 팀원의 기술 역량을 고려하여 현실적인 기술 선택과 교육 계획이 필요합니다. 테스트 전략: 단위 테스트, 통합 테스트, API 테스트, 부하 테스트 등 각 단계별 테스트 전략을 수립하고 자동화하여 시스템의 안정성을 확보해야 합니다. 특히 인메모리 캐시 로직, Docker 호스트 연동 로직, 동시성 제어 로직 등은 철저한 테스트가 필요합니다. 향후 기능 확장 로드맵: 초기 버전 출시 이후 고려할 수 있는 기능들(예: 영구 볼륨 관리, 사용자 정의 네트워크, CI/CD 연동, 고급 모니터링 대시보드, 과금 시스템 연동 등)에 대한 장기적인 로드맵을 구상해두는 것이 좋습니다. 이는 현재 아키텍처 설계 시 미래의 확장성을 어느 정도 고려해야 할지 판단하는 데 도움이 됩니다.","5-컨테이너-관리-로직#5. 컨테이너 관리 로직":"5.1. 컨테이너 생성 (사용자 요청 처리 상세)\n사용자 인증: API 요청 헤더의 JWT 토큰을 검증하여 유효한 사용자인지 확인한다. 생성 개수 제한 검사: 인증된 사용자의 user_id를 기준으로, 현재 인메모리 캐시에 있는 컨테이너 중 해당 사용자가 소유한 (이름 접두사 일치) 컨테이너 수를 센다. 설정된 최대 개수(예: 2개)를 초과했는지 확인한다. 요청 자원 확인: 사용자가 요청한 이미지, 포트 매핑, 이름 접미사 등을 파싱한다. 기본 자원 할당량(CPU 2개, 메모리 3GB)을 설정한다. 스케줄링 (호스트 선택): 사용자가 원하는 host 에 컨테이너를 생성할 수 있도록 한다 고유 컨테이너 이름 생성: [인증된_user_id]_[사용자요청_name_suffix] 형식으로 기본 이름을 구성한다. 만약 name_suffix가 제공되지 않거나, 동일 사용자 내에서는 이름을 중복할 수 없다 중복되게 생성한다면 적절한 오류 메세지를 반환한다 Docker API 호출 (컨테이너 생성): 선택된 호스트의 Docker Engine API (/containers/create, 이후 /containers/{id}/start)를 호출한다. 파라미터: 생성된 컨테이너 이름, 사용할 이미지, 포트 매핑 설정, CPU 및 메모리 제한 (HostConfig 내 CpuQuota, CpuPeriod, Memory 등) 등을 포함한다. 결과 처리 및 캐시 업데이트: Docker API로부터 생성 성공/실패 응답을 받는다. 성공 시: 사용자에게 적절한 성공 메세지를 반환한다 실패 시: 사용자에게 적절한 오류 메시지를 반환한다. 동시 생성 요청 제어: 한 사용자가 동시에 여러 생성 요청을 보내는 것을 방지하기 위해, 사용자별로 “생성 진행 중” 플래그를 관리한다 (Flask 세션, 또는 간단한 인메모리 딕셔너리 활용. 분산 환경에서는 Redis 등의 외부 Lock 필요). 5.2. 컨테이너 자원 제한\nCPU: Docker 생성 시 HostConfig의 CpuPeriod와 CpuQuota를 설정한다. 예를 들어, 2개의 CPU 코어 효과를 내려면 CpuPeriod=100000 (기본값), CpuQuota=200000 (2 * 100000)으로 설정할 수 있다. 메모리: HostConfig의 Memory (바이트 단위)를 설정한다 (예: 3 * 1024 * 1024 * 1024 for 3GB). MemorySwap을 Memory와 동일하게 설정하여 스왑 사용을 제한할 수 있다. 디스크 (50GB - 가이드라인): Docker 자체만으로 컨테이너별 엄격한 디스크 사용량 쿼터를 적용하는 것은 스토리지 드라이버 및 OS 설정에 따라 복잡하다. 본 설계에서는 “50GB\"를 사용 가능한 총 이미지 크기 + 컨테이너의 쓰기 가능한 레이어에서 사용할 수 있는 예상 작업 공간의 가이드라인으로 간주한다. 또는, 컨테이너 생성 시 특정 크기의 Docker 볼륨을 생성하여 마운트하는 방식을 고려할 수 있으나, 이는 볼륨 관리 기능 추가 및 스토리지 플러그인 연동이 필요할 수 있다. 초기에는 명시적 제한보다는 사용량 모니터링 및 가이드라인 제공에 초점을 맞춘다. 5.3. 일일 검사 및 정책 적용\nAPScheduler를 사용하여 매일 특정 시간에 백그라운드 작업 실행. 작업 내용: 인메모리 캐시의 모든 컨테이너 정보를 순회한다. 각 컨테이너에 대해 정의된 규칙을 검사한다: 예: 7일 이상 exited 상태로 방치된 컨테이너. 예: 관리자가 정의한 특정 금지된 이미지를 사용한 컨테이너 (이미지 이름 검사). 예: 과도한 네트워크 트래픽을 유발하는 것으로 의심되는 컨테이너 (별도 모니터링 데이터 연동 필요 - 고급). 규칙에 해당하는 컨테이너에 대해 자동 조치(예: 중지, 사용자에게 경고 알림)를 수행하거나 관리자에게 보고한다. 조치 내역은 상세히 로깅한다.","6-docker-호스트-관리#6. Docker 호스트 관리":"호스트 목록 관리: Flask 애플리케이션의 설정 파일(config.py)이나 환경 변수를 통해 관리할 Docker 호스트의 목록(IP 주소, API 포트, TLS 인증서 경로 등)을 정의한다. 상태 폴링: APScheduler를 이용한 백그라운드 작업으로, 설정된 주기마다 각 호스트에 대해 다음 Docker API 엔드포인트를 호출하여 정보를 수집하고 인메모리 캐시를 갱신한다. GET /info: 호스트 전체 정보 (OS, CPU/메모리 총량, Docker 버전 등). GET /containers/json?all=true: 해당 호스트의 모든 컨테이너 목록 (간략 정보). (필요시) GET /containers/{id}/stats?stream=false: 개별 컨테이너의 실시간 자원 사용량. 호스트 장애 감지: 폴링 시 특정 호스트로부터 응답이 없거나 오류가 발생하면, 해당 호스트를 “unreachable” 상태로 캐시에 표시하고, 이 호스트에서 실행 중이던 컨테이너들도 접근 불가능 상태임을 인지한다. 사용자에게 해당 컨테이너가 일시적으로 사용할 수 없음을 알릴 수 있다. 자동 장애 복구(다른 호스트로 컨테이너 이전)는 본 설계의 초기 범위에는 포함되지 않는다 (복잡도 매우 높음).","6-결론#6. 결론":"제시된 “컨테이너 기반 컴퓨팅 제공 서비스 프로젝트 설계서\"는 Docker 호스트를 단일 진실 공급원으로 삼고 API 서버의 인메모리 캐시를 적극적으로 활용하는 독창적이고 흥미로운 접근 방식을 제시합니다. 이 설계는 데이터 일관성 확보와 DB 의존성 최소화라는 명확한 장점을 가지며, 특히 명시된 “단일 API 서버 인스턴스, 300명 이내 사용자\"라는 제한된 초기 운영 환경에서는 충분히 실현 가능하고 효율적일 수 있습니다.\n하지만, 인메모리 캐시에 대한 높은 의존성은 API 서버 장애 시 상태 유실, 웜업 시간, 수평 확장 제약 등의 본질적인 한계를 내포하고 있습니다. 또한, 데이터 영속성 부재로 인한 감사 추적의 어려움, 폴링 부하 관리, 보안 강화 등은 신중하게 다뤄야 할 도전 과제입니다.\n본 보고서에서 제안된 개선 방안들은 이러한 문제점들을 완화하고 시스템의 안정성, 효율성, 보안성, 그리고 사용자 경험을 향상시키는 데 초점을 맞추고 있습니다. 특히, 경량 외부 캐시/저장소의 제한적 도입 고려, 비동기 처리 강화, 정교한 로깅 및 모니터링 시스템 구축, 보안 계층 심화, 그리고 보다 유연한 컨테이너 관리 로직 추가 등은 시스템의 완성도를 높이는 데 기여할 수 있을 것입니다.\n가장 중요한 것은 설계의 핵심 원칙과 현실적인 제약 조건 사이에서 균형을 찾는 것입니다. 초기 설계의 단순함과 명확성을 유지하면서도, 잠재적인 위험 요소를 최소화하고 향후 성장에 대비할 수 있는 유연성을 확보하는 방향으로 설계를 발전시켜 나가는 것이 바람직합니다. 철저한 테스트와 점진적인 기능 개선을 통해 안정적이고 사용자 친화적인 컨테이너 서비스를 성공적으로 구축할 수 있기를 기대합니다.","7-보안-고려-사항#7. 보안 고려 사항":"API 인증 및 권한 부여: 모든 API 엔드포인트는 JWT 토큰을 통해 인증된 사용자만 접근 가능하도록 하며, 자신의 자원에만 접근할 수 있도록 철저한 권한 검사를 수행한다. 입력값 검증: SQL Injection, Command Injection, XSS 등의 공격을 방지하기 위해 모든 사용자 입력(API 파라미터, 요청 본문)에 대해 Flask 레벨에서 또는 Pydantic, Marshmallow 같은 라이브러리를 사용하여 엄격한 유효성 검사를 수행한다. Docker Daemon API 보안: 반드시 TLS를 활성화하여 Flask API 서버와 Docker 호스트 간의 모든 통신을 암호화한다. Docker 호스트의 방화벽에서 Flask 서버의 IP 주소에서만 Docker API 포트(일반적으로 TCP 2376)로의 접근을 허용한다. 컨테이너 격리 강화: 컨테이너 내부에서 실행되는 애플리케이션은 가능한 최소한의 권한을 가진 사용자(non-root user)로 실행되도록 Dockerfile을 작성한다. 컨테이너에 불필요한 Linux capabilities를 제거한다 (--cap-drop=ALL). 필요한 최소한의 capability만 선택적으로 추가한다 (--cap-add=...). (고급) AppArmor 또는 Seccomp 프로필을 적용하여 컨테이너가 수행할 수 있는 시스템 콜을 제한하고 파일 시스템 접근을 제어하여 보안 계층을 강화할 수 있다. 이미지 보안: 서비스에서 사용할 수 있는 Docker 이미지 목록을 관리자가 사전에 승인하고 제공하는 방식(Curated List)을 강력히 권장한다. 만약 사용자가 임의의 이미지를 지정할 수 있게 한다면, 이미지 스캔 도구(예: Trivy, Clair)를 사용하여 알려진 보안 취약점을 검사하는 프로세스를 도입하거나, 위험성을 사용자에게 명확히 고지해야 한다. 네이밍 규칙 악용 방지: 컨테이너 이름 생성 시, 시스템은 인증된 사용자의 user_id를 이름의 접두사로 강제한다. API를 통해 컨테이너 정보를 조회하거나 조작할 때, 항상 인증된 사용자의 user_id를 기준으로 필터링하므로, 다른 사용자가 악의적으로 유사한 이름의 컨테이너를 생성하더라도 타인의 컨테이너에 접근하거나 영향을 줄 수 없다.","8-확장성-및-안정성#8. 확장성 및 안정성":"API 서버 (Flask): 단일 인스턴스 제약: 현재 설계(모든 상태를 Flask 앱 메모리에 저장)는 단일 Flask 인스턴스 환경에 최적화되어 있다. Gunicorn이나 uWSGI를 사용하여 여러 워커 프로세스를 실행할 수 있지만, 이는 단일 머신 내에서의 병렬 처리 능력 향상이며, 여러 머신으로 Flask 앱을 확장하는 것과는 다르다. 확장 시 문제점: 여러 Flask 인스턴스로 확장할 경우, 각 인스턴스가 자신만의 독립된 인메모리 캐시를 가지게 되어 상태 불일치가 발생하고 서비스가 오작동할 수 있다. 이를 해결하려면 Redis와 같은 외부 공유 분산 캐시 시스템을 도입해야 하며, 이는 “DB 외에 다른 저장소를 사용하지 않겠다\"는 초기 설계 원칙과 상충될 수 있다. 따라서 본 설계는 단일 API 서버 인스턴스 운영을 기본 전제로 한다. 데이터베이스: 사용자 인증용으로만 사용되므로 상대적으로 부하가 적어 초기에는 단일 인스턴스로 충분하다. 사용자 수가 매우 많아질 경우 DB 읽기 복제 등을 고려할 수 있다. Docker 호스트: 필요에 따라 더 많은 Docker 호스트 머신을 추가하여 수평적으로 쉽게 확장할 수 있다. Flask API 서버 설정에 새 호스트 정보를 추가하면 된다. 애플리케이션 재시작 및 장애: Flask API 서버가 재시작되면 인메모리 캐시가 모두 소실되므로, 모든 Docker 호스트를 스캔하여 캐시를 재구축하는 “웜업” 과정이 필요하다. 이 시간 동안 서비스 응답이 지연되거나 불완전할 수 있다. Docker 호스트 자체의 장애는 폴링 메커니즘을 통해 감지된다. 해당 호스트의 컨테이너는 “unreachable” 상태로 처리된다. 자동화된 컨테이너 재배치(self-healing)는 구현 복잡도가 높아 현재 설계 범위에는 포함되지 않는다.","9-로깅-및-모니터링#9. 로깅 및 모니터링":"로깅: 컨테이너 정보를 DB에 저장하지 않으므로, 모든 활동에 대한 상세한 로깅이 시스템의 상태 추적 및 문제 해결에 매우 중요하다. Flask API 서버 로깅: 모든 API 요청(엔드포인트, 파라미터, 사용자 ID), 응답(성공/실패, 상태 코드), 주요 내부 동작(캐시 업데이트, 스케줄링 결정, Docker API 호출 내역), 오류 및 예외 상황 등을 파일 또는 표준 출력으로 상세히 기록한다. 컨테이너 이벤트 로깅: 컨테이너 생성, 삭제, 시작, 중지 등의 주요 이벤트 발생 시 관련 정보(사용자 ID, 컨테이너 이름, 호스트 등)를 명확히 로깅한다. 주기적 작업 로깅: 호스트 상태 폴링 결과, 일일 검사 및 정책 적용 결과 등을 로깅한다. 중앙 집중식 로깅 시스템 고려: 운영 규모가 커지면 ELK Stack(Elasticsearch, Logstash, Kibana) 또는 Grafana Loki 같은 중앙 집중식 로깅 시스템을 도입하여 로그를 효율적으로 수집, 검색, 분석하는 것을 고려한다. 모니터링: API 서버 성능: Flask 애플리케이션의 응답 시간, RPS(requests per second), 오류율, CPU/메모리 사용량 등을 모니터링한다. (예: Prometheus flask_exporter) Docker 호스트 상태: 각 Docker 호스트의 CPU/메모리/디스크/네트워크 사용량, 실행 중인 컨테이너 수 등을 모니터링한다. (예: Prometheus node_exporter, cAdvisor) 인메모리 캐시 상태: 캐시 크기, 갱신 빈도, 웜업 시간 등을 모니터링할 수 있는 내부 메트릭을 노출할 수 있다. 시각화 및 알림: 수집된 메트릭은 Grafana를 사용하여 시각화하고, 주요 지표에 대한 임계치 기반 알림(Alerting)을 설정하여 문제 발생 시 신속하게 대응한다.","컨테이너-기반-컴퓨팅-제공-서비스-프로젝트-설계서#컨테이너 기반 컴퓨팅 제공 서비스 프로젝트 설계서":"","컨테이너-기반-컴퓨팅-제공-서비스-프로젝트-설계서-분석-및-제언-보고서#컨테이너 기반 컴퓨팅 제공 서비스 프로젝트 설계서 분석 및 제언 보고서":""},"title":"mjuecs 2"},"/06.university/mju_ecs-project/mjuecs-project-%EB%B0%9C%EC%A0%84%EB%B0%A9%ED%96%A5/":{"data":{"":"aws 의 ecs 서비스와 같이 컴퓨팅 을 제공\n유저 정보만 db 에 기록하고 나머지는 모두 docker demon 에 요청 정보로 처리한다 유저 id 는 평문 저장 비밀번호는 암호화 저장\n물리적 컴퓨터로 해당 서비스를 서비스한다 컴퓨터1 : db, python flask, nginx , 컴퓨터2 : docker 구동, host 상태 서버 컴퓨터3 : docker 구동, host 상태 서버 즉 2개의 프로젝트가 개발되어야 한다 매인 프로젝트 사용자별 docker 컨테이너 생성 조회 삭제 서비스 (어려움) host 의 상태 정보를 요청 받으면 보내주는 서비스 (쉬움) python 웹서버 설정란에 docker host ip 를 적고 해당 ip 를 통해 컨테이너를 생성 조회 삭제를 한다 3초에 한번씩 모든 docker 를 구성하는 host 컴퓨터들에게 요청을 보내서 메모리에 저장(캐시)\n사용자는 생성할때 마다 특정 규칙에 따라 생성한다 (ex 1인당 컨테이너 2개등등) 이때 저장된 캐시가 갱신된것을 확인하고 갱신됬으면 특정 규칙에 따라 검사하고 생성 허용을 할 지 안할지 정한다 초기 사용자가 컨테이너를 생성할 때 여러개의 docker host 중에 적절한 서버를 고르고 해당 서버에서 컨테이너를 생성할 수 있도록 한다 컨테이너 생성시에는 유저는 1번의 생성 요청이 끝나야 다른 생성 요청을 할 수 있다 사용자별 컨테이너 자원제한 2cpu, 3memory, 50GB disk 하루에 한번씩 사용자들의 컨테이너를 검사하고 규칙에 따라 컨테이너를 정지할지 말지 고를 수 있다"},"title":"mjuecs project 발전방향"},"/06.university/mju_ecs-project/mjuecs-project/":{"data":{"":"","api#api":"METHOD endpoint 설명 POST /api/docker/run POST /api/docker/start POST /api/docker/restart /api/docker/stop /api/docker/status /api/auth/login /api/auth/","로그인-처리#로그인 처리":"나의 경우는 mju 에 로그인이 가능한 사람을 기준으로 했지만 어떠한 방식으로 로그인처리를 할 지 고를 수 있어야함","물리-환경#물리 환경":"db,backend,frontend 컴퓨터 1대 여러대의 docker host","필요-요구-사항#필요 요구 사항":"사용자가 새로운 컨테이너를 만들려고 할 때 docker host 컴퓨터들의 상태 (cpu, memory, …) 을 보고 그곳에 컨테이너를 생성 가능(일종의 aws 의 리전개념) 사용자가 백엔드는 백엔드에서 관리하고 있는 모든 host 의 정보(사용량, 컨테이너 사용량 등등)를 순차적으로 돌아가며 가져와서 메모리에 저장해두었다가 사용자에게 갱신해 주면 됨 back 엔드에서는 사용자 정보만 db 에 저장하고 컨테이너 상태와 같은것들은 가져오지 않아야 한다 사용자 마다 전체 컨테이너의 개수 max 제한이 있어야 함 사용자가 1개의 컨테이너를 생성중에 있을 때는 컨테이너가 만들어지고 난 후 생성가능 컨테이너에 터미널 접근을위해 websocket 을 사용 터미널 창은 tab 으로 구성되며 첫 탭은 컨테이너 log 만 존재하는 tab 으로 상호작용은 없는 탭 사용자는 초기 화면에서 자신의 컨테이너 상태를 확인 할 수 있어야 한다(실시간 sse 활용) 사용자는 특정 컨테이너 정보 창에서 상세한 컨테이너 stats 을 확인할 수 있어야 한다(실시간 sse 활용) front 의 경우 onepage 로 만들어 구성이 쉽도록 한다"},"title":"mjuecs project"},"/06.university/mju_ecs-project/mjuecs-system-programming-ubuntu-%EC%9D%B4%EB%AF%B8%EC%A7%80-%EC%84%A4%EB%AA%85/":{"data":{"-각-패키지의-활용-예시-간단히#🔍 각 패키지의 활용 예시 (간단히)":"패키지 예제 사용법 설명 gcc gcc hello.c -o hello C 코드 컴파일 make make all Makefile 기반 전체 빌드 gdb gdb ./hello → run, break main, step 디버깅 시작, 중단점 설정 등 valgrind valgrind --leak-check=yes ./hello 메모리 누수 체크 strace strace ./hello 실행 중 시스템 콜 확인 ltrace ltrace ./hello 외부 라이브러리 함수 호출 보기 pkg-config gcc prog.c -o prog $(pkg-config --cflags --libs openssl) OpenSSL 사용 시 편리한 컴파일 옵션 자동 삽입 manpages-dev man 2 read 또는 man 3 printf 시스템 콜(read)이나 라이브러리 함수(printf) 설명 보기","-설치-명령어-예시#💡 설치 명령어 예시:":"sudo apt update sudo apt install build-essential gcc g++ make gdb valgrind strace ltrace pkg-config libssl-dev manpages-dev","-시스템-프로그래밍을-위한-리눅스-패키지-목록#📦 시스템 프로그래밍을 위한 리눅스 패키지 목록":"패키지명 설명 주요 용도 build-essential C/C++ 컴파일 및 빌드에 필요한 핵심 도구 묶음 기본 개발 환경 구축 gcc GNU C Compiler C 언어 소스 코드 컴파일 g++ GNU C++ Compiler C++ 언어 소스 코드 컴파일 make Makefile 기반 자동 빌드 도구 여러 파일로 구성된 프로젝트 빌드 관리 gdb GNU Debugger 실행 중인 프로그램 디버깅 (변수, 메모리, 스택 등 확인) valgrind 메모리 디버깅 및 성능 분석 도구 메모리 누수, 잘못된 접근 감지 strace 시스템 콜 추적 도구 프로그램이 어떤 시스템 호출을 사용하는지 분석 ltrace 공유 라이브러리 함수 호출 추적 외부 라이브러리 함수 호출 내역 확인 pkg-config 라이브러리 정보 제공 도구 컴파일 시 필요한 옵션, 경로 등을 자동으로 불러옴 libssl-dev OpenSSL 개발 라이브러리 SSL/TLS 관련 네트워크 프로그래밍에 필요 manpages-dev 개발자용 매뉴얼 페이지 (man 2, man 3) 시스템 콜과 C 라이브러리 함수 문서 제공","mjuecs-system-programming-ubuntu-이미지-설명#mjuecs-system-programming-ubuntu 이미지 설명":"mjuecs-system-programming-ubuntu 이미지 설명 본 이미지는 mjuecs-ubuntu 이미지에서 system-programming 실습시 필요할 거 같은 패키지들을 추가로 설치해놓은 추가 변형 이미지 입니다 아래는 해당 패키지에 대한 설명이 추가 되어 있습니다."},"title":"mjuecs system programming ubuntu 이미지 설명"},"/06.university/mju_ecs-project/mjuecs-ubuntu-%EB%AC%B8%EC%84%9C/":{"data":{"-mjuecs-ubuntu-ubuntu-2204-기반-docker-컨테이너-가이드#🐧 mjuecs ubuntu (Ubuntu 22.04 기반) Docker 컨테이너 가이드":"🐧 mjuecs ubuntu (Ubuntu 22.04 기반) Docker 컨테이너 가이드 이미지 출처: ubuntu (Docker Hub))","1-1-템플릿-선택#1-1. 템플릿 선택":"mjuecs ubuntu 템플릿을 선택합니다. 이 템플릿은 Ubuntu 22.04를 기반으로 하며, SSH 서버와 사용자 계정 생성 custom 이 되어 있습니다","1-2-환경변수-설정#1-2. 환경변수 설정":"컨테이너 생성 시 다음 환경변수를 설정해야 합니다:\n환경변수 설명 ROOT_PASSWORD 루트 계정의 비밀번호 (예: rootpass123) USERNAME 생성할 일반 사용자 계정명 (예: student01) PASSWORD 해당 사용자 비밀번호 (예: studentpass123) ![Pasted image 2023002975.png) 이 설정에 따라 컨테이너 최초 실행 시 자동으로 사용자 계정이 생성되고 sudo 권한이 부여됩니다.","1-3-컨테이너-정보-접근#1-3. 컨테이너 정보 접근":"컨테이너가 생성된 후, 해당 컨테이너 정보 페이지로 이동합니다.","1-4-웹터미널-접근-준비#1-4. 웹터미널 접근 준비":"웹터미널 접근 비밀번호 복사 버튼을 클릭하여 복사합니다. 그 후 웹터미널 열기 버튼을 클릭하여 웹터미널을 실행합니다.","1-5-웹터미널-로그인#1-5. 웹터미널 로그인":"아이디: 학번 비밀번호: 위에서 복사한 웹터미널 접근 비밀번호","1-컨테이너-생성#1. 컨테이너 생성":"","2-1-vs-code-확장-설치#2-1. VS Code 확장 설치":"VS Code 실행 Extensions(확장) 메뉴에서 Remote - SSH 검색 및 설치","2-2-ssh-접속#2-2. SSH 접속":"vscode 에서 ctrl + p 접근 이후 ssh 입력 새로운 host 연결 컨테이너 생성시 입력한 사용자 이름, 외부 접근포트의 경우 컨테이너 정보창 외부 접근 포트 번호 config 는 아무거나 설정 (전역 설정, 유저 설정) 연결 비빌번호 입력 -\u003e 접속 완료","2-3-이후-접속#2-3. 이후 접속":"VS Code 하단의 녹색 버튼 클릭 → Remote-SSH: Connect to Host mjuecs.gonetis.com 선택 비밀번호 입력 → 접속 완료","2-vs-code에서-원격-ssh-연결#2. VS Code에서 원격 SSH 연결":"해당 컨테이너는 ssh 설정과 유저 생성이 자동으로 이루어지며 바로 vscode 연결이 가능합니다"},"title":"mjuecs ubuntu 문서"},"/06.university/mju_ecs-project/oracle-database/":{"data":{"-oracle-11-버전인-경우#✅ Oracle 11 버전인 경우:":"","-oracle-18--21-버전인-경우#✅ Oracle 18 / 21 버전인 경우:":"","1-1-템플릿-선택#1-1. 템플릿 선택":"","1-2-환경변수-설정#1-2. 환경변수 설정":"","1-3-컨테이너-정보-접근#1-3. 컨테이너 정보 접근":"","1-4-웹터미널-접근-준비#1-4. 웹터미널 접근 준비":"","1-5-웹터미널-로그인#1-5. 웹터미널 로그인":"","1-컨테이너-생성#1. 컨테이너 생성":"","2-1-sqlplus-접속#2-1. SQL*Plus 접속":"","2-2-사용자-생성-및-권한-부여#2-2. 사용자 생성 및 권한 부여":"","2-사용자-및-db-생성#2. 사용자 및 DB 생성":"","3-외부-연결-확인#3. 외부 연결 확인":"","oracle-database-docker-컨테이너-가이드#Oracle Database Docker 컨테이너 가이드":"","pasted-image-20250522221749#📷 예시 \u003cimg src=\"../../08.media/20250522221749.png\" alt=\"Pasted image 20250522221749\"\u003e":"Oracle Database Docker 컨테이너 가이드 이미지 출처: gvenzl/oracle-xe (Docker Hub))\n1. 컨테이너 생성 1-1. 템플릿 선택 Oracle Database 11, 18, 21 중 하나를 선택합니다. 1-2. 환경변수 설정 필수: ORACLE_PASSWORD 환경변수에 관리자 비밀번호를 입력 나머지 변수는 선택 📷 예시ed%20image%2020250517080578.png)\n1-3. 컨테이너 정보 접근 컨테이너 정보 페이지로 이동합니다. 1-4. 웹터미널 접근 준비 웹터미널 접근 비밀번호 복사 버튼을 클릭하여 비밀번호를 복사 이후 웹터미널 열기 버튼 클릭 1-5. 웹터미널 로그인 아이디: 학번 비밀번호: 위에서 복사한 웹터미널 접근 비밀번호 2. 사용자 및 DB 생성 변수 설명 아래 명령어들에서 사용하는 변수들은 자신에게 맞게 대체합니다.\n변수명 설명 $ORACLE_PASSWORD 컨테이너 생성 시 설정한 관리자 비밀번호 $USER_NAME 생성할 사용자 이름 $USER_PASSWORD 생성할 사용자 비밀번호 $ACCESS_IP DB 접근용 IP 주소(mjuecs.gonetis.com) $ACCESS_PORT DB 접근용 포트 번호 2-1. SQL*Plus 접속 터미널에서 관리자 계정으로 SQL*Plus 접속:\nsqlplus sys/$ORACLE_PASSWORD as SYSDBA 2-2. 사용자 생성 및 권한 부여 ✅ Oracle 11 버전인 경우: CREATE USER $USER_NAME IDENTIFIED BY $USER_PASSWORD; GRANT CREATE SESSION TO $USER_NAME; GRANT CONNECT, RESOURCE TO $USER_NAME; GRANT CREATE MATERIALIZED VIEW TO $USER_NAME; ALTER USER $USER_NAME DEFAULT TABLESPACE users QUOTA UNLIMITED ON users; ✅ Oracle 18 / 21 버전인 경우: ALTER SESSION SET \"_ORACLE_SCRIPT\"=true; CREATE USER $USER_NAME IDENTIFIED BY $USER_PASSWORD; GRANT CREATE SESSION TO $USER_NAME; GRANT CONNECT, RESOURCE TO $USER_NAME; GRANT CREATE MATERIALIZED VIEW TO $USER_NAME; ALTER USER $USER_NAME DEFAULT TABLESPACE users QUOTA UNLIMITED ON users; 3. 외부 연결 확인 설정한 IP(url)와 포트를 이용해 Oracle 클라이언트 도구 또는 SQL Developer로 접속 테스트 📷 예시","변수-설명#변수 설명":""},"title":"oracle database"},"/06.university/mju_ecs-project/ryugod-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B82/":{"data":{"":"mysql template 자료 : https://hub.docker.com/_/mysql postgres template 자료 : https://hub.docker.com/_/postgres mongoDB template 자료 : https://hub.docker.com/_/mongo …","api#API":"컨테이너 생성 : POST /api/{userId}/container 요청 본문:\n{ \"image\": \"ubuntu:22.04\", \"type\": \"template\", // 또는 \"manual\" 현재는 menual 만 사용 \"container_port\" : \"3306\", // 컨테이너 내부에서 사용하는 서비스 포트 22는 자동 \"env\" : [] // mysql 의 경우 MYSQL_ROOT_PASSWORD 변수가 필수로 필요하다 } 응답:\n{ \"status\" : \"success\", \"container_id\": \"c123456789\", \"container_name\": \"MjuEcs-username-1\" } 터미널 세션 API : POST /api/terminals/create"},"title":"ryugod 프로젝트2"},"/06.university/mju_ecs-project/untitled/":{"data":{"":"%20image%2020250513062286.png)\n[고건혁] [오전 1:16] 포워딩 방식을 지금 하려고 하니까 생각난 궁금증이 일단 ttyd컨테이너는 외부 접근을 차단하고 포워딩 방식으로 한다고 하면\n도커 컨테이너(커스텀컨테이너)에 대한 접근은 어떤 식으로 하는건가요?\n아래 사진과 같은 방식중 첫번째 방식을 사용하려고 하였습니다 [고건혁] [오전 1:17] 포워딩 방식을 사용하는 이유가 단순히 다른 사용자가 남의 컨테이너에 접근하는데 그냥 localhost:9000치고 들어가버리면 안되니까 그런건데\n예를 들어서 ttyd웹 환경에서 안하고 다른사람이 남의 컨테이너 포트 번호를 아는상태에서 VsCode나 로컬 터미널 환경에서 접근하는건 어떻게 막는건가요?\n상단에 설명한 것 처럼 허용하는 ip 만 접근 가능한거여서 포워딩 방식으로 접근하지 않는 한 접근 할 수 없습니다 [고건혁] [오전 2:26] 포워딩 방식이 여전히 spring에서는 ws을 전달하지 못하는 문제가 있어서 새로 구현한 방식이 일단 기존 학교 msi나 lms같이 처음부터 모든 포트를 닫고 사용자가 인증에 성공한 경우에만 지속적으로 ping을 보내서 포트를 열어두고 사용자가 사용을 중지하면 포트를 닫아서 보안을 유지하는 방식으로 변경했습니다\n기본구조가 이제 사용자가 로그인-\u003e컨테이너 생성(생성될때 포트 할당 및 맵핑만 하고 닫아둠)-\u003e사용자가 로그인한 토큰을 가진채로 internal/unlock/{**}에 인증-\u003e연결된 ttyd포트 (localhost:9000같은 주소)주소 응답-\u003e사용자를 internal/ping/{**}으로 넘기고 지속적으로 핑응답하도록-\u003e사용자는 ping페이지와 localhost탭이 같이 켜져있으면 지속적으로 사용가능-\u003eping탭이 닫히면 3분안에 포트를 다시 닫음 이런식으로 만들었습니다\n3가지 방법중 3번 방법인 것 같은데 사용자가 터미널을 사용하고 있을 때는 외부 사람들도 접근 가능한거 아닌가요 [고건혁] [오전 2:28] 근데 구현은 일단했는데 포트 닫는 port DROP명령어가 macOS에는 없어서 현재 테스트가 안됩니다..아마 저희가 올리는 서버는 리눅스 기반이면 “iptables -D INPUT -p tcp —dport \" + port + \" -j DROP\"이 명령어 실행이 가능해서 (관리자 권한으로 실행되어야함)가능할거 같긴한데 지금은 모르겠네요..\n이거는 해봐야 알 수 있을거 같은데 was 에서 관리자권한이 필요한 명령이 실행가능한지는 모르겠어요 [고건혁] [오전 6:21] 컨테이너 상세 상태 stats연결 해보여고 했는데 현재 docker-java에서 2375포트 통해서 데몬 열고 받아오는 수 밖에 없어서 그걸 초간격으로 주기적으로 실행하면 기존에 열린 포트랑 충돌 나서 불가능 할거 같아요\n이 말이 정확히 무슨 말인지 이해가 안되는데 한 번에 여러 개의 stats 연결을 동시에 여는 게 어려움 이런 말인가요? \u003c- 이 문제는 조금 중요한 거 같아서 회의를 한번 해봐야 할 거 같아요 [고건혁] [오전 6:26] 기본적인 상태 전송은 어차피 ping방식으로 해서 요청을 보내니까 그 요청의 응답으로 상태 전송하면 좋을거 같아서 ping엔트포인트에 응답으로 pong상태를 보내는 식으로 만들고 있습니다\nstatus 또는 stat 을 poling 또는 long Poiling 방식으로 구현하신다는 거죠?"},"title":"Untitled"},"/06.university/network/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EC%A1%B1%EB%B3%B4-%EB%AC%B8%EC%A0%9C-%ED%92%80%EC%9D%B4/":{"data":{"":"네트워크 라우터의 패킷 서비스 순서 문제패킷 크기는 모두 동일하며, 다음 순서로 도착하여 큐에 이미 들어가 있다고 가정합니다:\nP1, P2, P3, P4, P5, P6, P7, P8, P9, P10, P11, P12\n각 패킷은 아래와 같이 클래스(Class) 별로 분류되어 있습니다:\nClass 1: P2, P4, P7, P12 Class 2: P3, P5, P10 Class 3: P1, P6, P8, P9, P11 5. Round Robin Scheduling (5점) 서비스는 Class 3 큐부터 시작됩니다. 각 클래스 내부에서는 패킷 번호 순서대로 서비스가 진행됩니다. 요구사항: Round Robin 스케줄링 방식에 따라 패킷이 실제로 서비스되는 순서를 기술하시오.\n6. Weighted Fair Queueing (WFQ) Scheduling (5점) 각 클래스의 가중치: Class 1: 3 Class 2: 2 Class 3: 4 패킷 전송 시간은 동일하다고 가정합니다. 가중치 계산 결과가 동일한 경우, 번호가 작은 패킷이 우선으로 서비스됩니다. 요구사항: WFQ 스케줄링 방식에 따라 패킷이 실제로 서비스되는 순서를 기술하시오.\n각 스케줄링 기법에 따른 패킷 서비스 순서는 다음과 같습니다.\n5. 라운드 로빈(Round Robin) 스케줄링 서비스 순서: P1, P2, P3, P6, P4, P5, P8, P7, P10, P9, P12, P11\n설명 라운드 로빈 스케줄링은 각 클래스 큐를 순서대로 돌아가며 공평하게 한 번씩 서비스하는 방식입니다. 문제의 조건에 따라 Class 3부터 시작하여 Class 1, Class 2 순서(3 → 1 → 2)로 순환하며 각 큐의 첫 번째 패킷을 서비스합니다.\n1차 순환: Class 3의 P1, Class 1의 P2, Class 2의 P3 2차 순환: Class 3의 P6, Class 1의 P4, Class 2의 P5 3차 순환: Class 3의 P8, Class 1의 P7, Class 2의 P10 (이후 Class 2는 비어있음) 4차 순환: Class 3의 P9, Class 1의 P12 (이후 Class 1은 비어있음) 5차 순환: Class 3에 남은 P11을 서비스합니다. 6. WFQ(Weighted Fair Queueing) 스케줄링 서비스 순서: P1, P2, P3, P6, P4, P8, P5, P7, P9, P11, P12, P10","-계산-과정#📜 계산 과정":"준비: 생성자 G = 1001는 4비트이므로 데이터 D = 10111001010 뒤에 4 - 1 = 3개의 0을 추가합니다.\n나눗셈 대상 데이터: 10111001010000 이진 나눗셈 (XOR 연산):\n10101100011 \u003c- 몫 (중요하지 않음) ____________ 1001 | 10111001010000 1001 ---- 01010 1001 ----- 00111 0000 ----- 01110 1001 ----- 01110 1001 ----- 01111 1001 ----- 01100 1001 ----- 01010 1001 ----- 00110 0000 ----- 01100 1001 ----- 0101 \u003c- 최종 나머지 (Remainder) **수정된 계산:** 10111001010000 G= 1001 XOR 1001 ---- 001010 0000 ---- 1010 1001 ---- 00110 0000 ---- 1100 1001 ---- 1011 1001 ---- 0100 000 ---- 1000 1001 ---- 001 \u003c- 최종 나머지 (Remainder) 결과: 계산된 최종 나머지 001이 CRC 체크섬(FCS) 값입니다. 이 값을 원본 데이터 뒤에 붙여 10111001010**001**을 전송합니다. 다음은 주어진 내용을 바탕으로 정리된 마크다운 형식의 문제입니다:","-네트워킹-관련-문제-정답-및-풀이#📝 네트워킹 관련 문제 정답 및 풀이":"","-데이터-전송-시-crcerror-detection-계산-문제#📝 데이터 전송 시 CRC(Error Detection) 계산 문제":"","-설명#📜 설명":"Match: s3 스위치로 들어오는 패킷을 검사하는 조건입니다. in_port=1: h1, h2가 연결된 방향의 포트에서 들어온 패킷. eth_type=0x0800: IPv4 패킷. ipv4_src: 출발지 IP 주소가 h1 또는 h2인 경우. Action: Match 조건이 일치할 때 수행할 동작입니다. output:2: s2 스위치와 연결된 2번 포트로 패킷을 전달(Forwarding)합니다.","-예시-형식#🔍 예시 형식":"데이터: D = 10111001010 생성자: G = 1001 (4비트) CRC 길이: G의 비트 수 - 1 = 3비트 따라서 데이터 뒤에 3개의 0을 붙여서 나눗셈 수행 나머지를 CRC 값으로 하여 데이터에 첨가","-풀이-과정#📜 풀이 과정":"호스트 비트 계산: 각 서브넷에 20개의 호스트가 필요하므로, 2^h - 2 ≥ 20 공식을 만족하는 호스트 비트(h)를 찾아야 합니다. 2^h ≥ 22 이므로, h=5가 됩니다 (2^5 = 32). 즉, 각 서브넷은 5개의 호스트 비트를 가져야 합니다. 서브넷 비트 계산: 주어진 네트워크 212.20.100.0/25는 기본적으로 7개의 호스트 비트(32-25=7)를 가집니다. 여기서 새로운 호스트 비트로 5개를 사용하면, 서브넷을 만드는 데 사용할 수 있는 비트는 7 - 5 = 2비트입니다. 최종 계산: 최대 서브넷 수: 2^2 = 4개 서브넷당 사용 가능 호스트 수: 2^5 - 2 = 30개 전체 사용 가능 호스트 수: 30개/서브넷 * 4개 서브넷 = 120개","-풀이-과정-1#📜 풀이 과정":"필요한 호스트 수 계산: 약 500개의 호스트를 지원하려면 2^H ≥ 500을 만족하는 호스트 비트(H)가 필요합니다. 2^9 = 512이므로, 총 9개의 호스트 비트가 필요합니다. 슈퍼넷 마스크 결정: 9개의 호스트 비트를 사용하면 새로운 네트워크의 프리픽스는 32 - 9 = 23이 됩니다. 즉, /23 네트워크를 만들어야 합니다. 네트워크 통합: /23 네트워크는 512개의 IP 주소를 포함하며, 이는 2개의 /24 네트워크를 합친 크기입니다. 주어진 212.20.100.0/25는 212.20.100.0/24 블록에 포함됩니다. 212.20.100.0/24와 인접한 블록인 212.20.101.0/24를 합치면 212.20.100.0/23 슈퍼넷이 생성됩니다.","10-슈퍼네팅-supernetting-문제#10. 슈퍼네팅 (Supernetting) 문제":"필요한 다른 네트워크 주소: 212.20.101.0/24 합쳐진 단일 네트워크 주소: 212.20.100.0/23","10-슈퍼네팅-supernetting-문제-5점#10. 슈퍼네팅 (Supernetting) 문제 (5점)":"문제:\n212.20.100.0/25 네트워크에 다른 네트워크를 합쳐서 약 500대 규모의 단일 네트워크(호스트 수 약 500개)를 만들기 위해 슈퍼네팅(Supernetting)을 수행하려고 합니다.","11-sdnopenflow-flow-table-문제#11. SDN/OpenFlow Flow Table 문제":"s3 스위치의 Flow Table에 다음과 같은 2개의 엔트리를 추가합니다. (h1 IP: 10.0.0.1, h2 IP: 10.0.0.2로 가정, 포트는 상황에 맞게 가정)\nEntry Match (매치 조건) Action (동작) 1 in_port=1, eth_type=0x0800, ipv4_src=10.0.0.1 output:2 2 in_port=1, eth_type=0x0800, ipv4_src=10.0.0.2 output:2","11-sdnopenflow-flow-table-문제-5점#11. SDN/OpenFlow Flow Table 문제 (5점)":"문제:\nSDN 환경에서 다음과 같은 네트워크 구성이 있습니다:\n호스트: h1, h2, h3, h4 스위치: s1, s2, s3 호스트 h1과 h2에서 보낸 데이터그램들이 s3 스위치를 거쳐 s2로 보내져, 최종적으로 h3 또는 h4로 전달되도록 하고자 합니다.\ns3 스위치의 OpenFlow Flow Table에 이 기능을 처리할 수 있는 2개의 엔트리(match \u0026 action)를 작성하시오.","12-nat-network-address-translation-문제#12. NAT (Network Address Translation) 문제":"NAT 테이블 예시: (3개 호스트가 동시에 8.8.8.8:443에 접속하는 경우) 내부 출발지 IP:Port 외부(공인) 출발지 IP:Port 외부 목적지 IP:Port 192.168.0.1:1001 210.100.10.5:4000 8.8.8.8:443 192.168.0.2:2002 210.100.10.5:4001 8.8.8.8:443 192.168.0.3:3003 210.100.10.5:4002 8.8.8.8:443 응답 패킷 전달 방법: 외부 서버에서 온 응답 패킷이 NAT 라우터의 공인 IP(210.100.10.5)로 도착하면, 라우터는 패킷의 목적지 포트 번호를 확인합니다. 예를 들어, 목적지 포트가 4001이라면, 라우터는 NAT 테이블을 조회하여 이 포트가 내부 호스트 192.168.0.2:2002와 매핑된 것을 확인합니다. 그 후, 패킷의 목적지 IP와 포트를 192.168.0.2:2002로 변환하여 해당 내부 호스트에게 정확히 전달합니다.","12-nat-network-address-translation-문제-5점#12. NAT (Network Address Translation) 문제 (5점)":"문제:\n다음 그림과 같은 NAT 라우터가 있다고 가정합니다.\n내부 네트워크 IP 대역: 192.168.0.0/24 외부 공인 IP 주소: 210.100.10.5 포트 번호 할당 범위: 4000 ~ 65535 라우터는 아래와 같은 방식으로 연결된 세 호스트의 패킷을 처리하고 있습니다:\n호스트 내부 IP 외부 목적지 IP H1 192.168.0.1 172.16.0.10 H2 192.168.0.2 10.10.10.10 H3 192.168.0.3 8.8.8.8","13-네트워크-설정-정보-확인-문제#\u003cstrong\u003e13. 네트워크 설정 정보 확인 문제\u003c/strong\u003e":"호스트가 속한 네트워크 주소: 호스트 D의 IP 주소 110.0.0.2와 서브넷 마스크 255.255.254.0를 AND 연산하면 네트워크 주소를 알 수 있습니다.\n정답: 110.0.0.0 외부 인터넷과 데이터그램 송수신을 담당할 기기(게이트웨이) 인터페이스의 주소: 호스트 D가 속한 네트워크의 게이트웨이는 라우터 R3입니다. R3의 해당 인터페이스 IP 주소는 110.0.0.1이며, 서브넷 마스크 255.255.254.0는 23비트를 사용하므로 CIDR 표기법으로는 /23입니다.\n정답: 110.0.0.1/23","13-네트워크-설정-정보-확인-문제-5점#13. 네트워크 설정 정보 확인 문제 (5점)":"D 호스트가 새로 접속한 네트워크에서 인터넷 사용을 위해 네트워크 관련 설정을 시행하고 있습니다.","14-dhcp-request-frame-전송-문제#\u003cstrong\u003e14. DHCP Request Frame 전송 문제\u003c/strong\u003e":"DHCP를 통해 IP 주소를 할당받기 전이므로, 호스트 D는 네트워크에 있는 모든 기기에게 요청을 보내기 위해 브로드캐스트 주소를 사용해야 합니다. Layer 2(이더넷) 환경에서의 브로드캐스트 주소는 정해져 있습니다.\n정답: FF-FF-FF-FF-FF-FF","14-dhcp-request-frame-전송-문제-5점#14. DHCP Request Frame 전송 문제 (5점)":"D 호스트가 새로 접속한 네트워크는 이더넷이며, 인터넷 사용을 위해 DHCP를 사용하여 네트워크 관련 설정을 수행합니다.","15-arp-protocol-활용-문제#\u003cstrong\u003e15. ARP Protocol 활용 문제\u003c/strong\u003e":"프로토콜의 정식 명칭: IP 주소를 이용해 동일 네트워크 내의 상대방 MAC 주소(Layer 2 주소)를 알아내기 위해 사용하는 프로토콜은 주소 결정 프로토콜(ARP)입니다.\n정답: Address Resolution Protocol (ARP) 알아낸 Layer 2 주소: D 호스트는 게이트웨이인 R3의 IP 주소(110.0.0.1)에 해당하는 MAC 주소를 알아내야 합니다. 구성도에서 R3의 해당 인터페이스 MAC 주소를 확인할 수 있습니다.\n정답: 2C-DA-5B-FF-E6-AB","15-arp-protocol-활용-문제-5점#15. ARP Protocol 활용 문제 (5점)":"D 호스트가 www.neighbor.com의 IP 주소를 알아내기 위해 응용 계층(Application Layer)의 질의를 보낸 후, 해당 질의가 링크 계층(Link Layer)까지 도달했습니다.\n이제 이 질의를 외부 인터넷으로 내보내야 하는 상황입니다.\nD 호스트는 외부 인터넷과 데이터그램 송수신을 담당할 기기 인터페이스의 IP 주소는 알고 있지만, 해당 주소에 대응되는 Layer 2 주소(MAC 주소)는 모르고 있습니다.","16-dns-질의-응답-패킷의-source-ip-문제#\u003cstrong\u003e16. DNS 질의 응답 패킷의 Source IP 문제\u003c/strong\u003e":"DNS 서버 S1(100.0.0.5)이 보낸 응답 패킷은 라우터를 거치면서 Layer 2 헤더(MAC 주소)는 계속 바뀌지만, 일반적인 라우팅 환경(NAT가 없다는 가정 하에)에서 Layer 3 헤더의 Source IP와 Destination IP는 바뀌지 않습니다. 따라서 R2를 통과할 때도 패킷의 출발지 IP 주소는 S1의 주소입니다.\n정답: 100.0.0.5","16-dns-질의-응답-패킷의-source-ip-문제-5점#16. DNS 질의 응답 패킷의 Source IP 문제 (5점)":"D 호스트가 www.neighbor.com의 IP 주소를 알아내기 위해 보낸 DNS 질의에 대한 응답 패킷이 라우터 R2에 도착했습니다.\n이후 R2에서 해당 네트워크 계층(IP Datagram) 패킷을 외부로 보낼 때 사용하는 source IP 주소는 무엇입니까?","17-tcp-연결-설정-시-ack-segment의-source-layer-2-주소-문제#\u003cstrong\u003e17. TCP 연결 설정 시 ACK Segment의 Source Layer 2 주소 문제\u003c/strong\u003e":"ACK 세그먼트가 R3에 도착하여 외부 인터넷(R2 방향)으로 나갈 때, R3는 새로운 Layer 2 프레임을 만듭니다. 이때 프레임의 출발지(source) 주소는 패킷을 내보내는 R3 인터페이스의 MAC 주소가 됩니다.\n정답: 00-A0-CC-23-AF-4A","17-tcp-연결-설정-시-ack-segment의-source-layer-2-주소-문제-5점#17. TCP 연결 설정 시 ACK Segment의 Source Layer 2 주소 문제 (5점)":"D 호스트가 www.neighbor.com의 IP 주소를 알아낸 후, 홈페이지 요청을 위한 TCP 연결 설정을 시작했습니다.\n이때 전송된 ACK 세그먼트(TCP Segment)가 라우터 R3에 도착했고, 이후 R3에서 외부로 보내는 링크 계층(Layer 2) 프레임에서 사용되는 source 주소는 무엇입니까?","18-웹-서버-응답-패킷의-destination-layer-2-주소-문제#\u003cstrong\u003e18. 웹 서버 응답 패킷의 Destination Layer 2 주소 문제\u003c/strong\u003e":"문제의 시나리오(웹 서버 S2의 응답이 R2에 도착)는 실제 구성과 맞지 않지만, 질문의 의도(“라우터를 거쳐 D 호스트에게 최종적으로 전달되는 프레임의 목적지”)를 고려하여 풀이합니다. 외부에서 온 패킷이 마지막 라우터(R3)를 거쳐 최종 목적지인 호스트 D에게 전달될 때, 이 마지막 구간에서 사용되는 Layer 2 프레임의 목적지 주소는 호스트 D의 MAC 주소입니다.\n정답: 88-82-2F-54-1A-0F","18-웹-서버-응답-패킷의-destination-layer-2-주소-문제-5점#18. 웹 서버 응답 패킷의 Destination Layer 2 주소 문제 (5점)":"D 호스트의 홈페이지 요청에 대해, 웹 서버(www.neighbor.com)로부터 온 응답 패킷이 라우터 R2에 도착했습니다.\n이후 R2에서 D 호스트로 보내는 링크 계층(Layer 2) 프레임에서 사용되는 destination 주소는 무엇입니까?\n필요하시면 각 문제에 대한 풀이 예시 및 설명도 함께 제공해 드릴 수 있습니다.\n풀이 원하시는 문제 번호를 알려주세요 😊\n네, 주어진 네트워크 구성도와 문제를 바탕으로 각 질문에 대한 답변을 정리해 드립니다.","5-round-robin-scheduling-5점#5. Round Robin Scheduling (5점)":"","5-라운드-로빈round-robin-스케줄링#5. 라운드 로빈(Round Robin) 스케줄링":"","6-weighted-fair-queueing-wfq-scheduling-5점#6. Weighted Fair Queueing (WFQ) Scheduling (5점)":"","6-wfqweighted-fair-queueing-스케줄링#6. WFQ(Weighted Fair Queueing) 스케줄링":"","7-dijkstras-algorithm-10점#7. Dijkstra’s Algorithm (10점)":"요구사항:\nnode u에서 출발하여 Dijkstra’s algorithm을 사용해 각 노드(t, v, w, x, y, z)까지의 least cost path를 찾는 과정을 다음 표에 작성하시오.\n만약 동일 Step에서 비용이 같은 경우, 알파벳 순서가 빠른 노드를 먼저 선택합니다.","8-bellman-ford-algorithm-10점#8. Bellman-Ford Algorithm (10점)":"요구사항:\nnode u에서 출발하여 Bellman-Ford algorithm을 사용하여 hop 수를 증가시키며 각 노드(t, v, w, x, y, z)까지의 least cost path를 찾는 과정을 다음 표에 작성하시오.\n각 단계에서 어떤 이웃(neighbor)에게 전달해야 하는지도 함께 기술하시오.","9-서브넷팅-subnetting-문제#9. 서브넷팅 (Subnetting) 문제":"최대 서브넷 개수: 4개 최대 사용 가능 호스트 개수: 120개","9-서브넷팅-subnetting-문제-5점#9. 서브넷팅 (Subnetting) 문제 (5점)":"문제:\n212.20.100.0/25 네트워크에서 각 서브넷당 20개의 호스트가 사용할 수 있도록 서브넷팅(Subnetting)을 수행하려고 합니다.\n이때, 최대한 많은 서브넷을 생성하기 위한 조건에 따라 다음 질문에 답하시오.","crcerror-detection-계산-문제#CRC(Error Detection) 계산 문제":"계산된 CRC 체크섬(FCS) 값: 001","네트워크-구성-및-통신-관련-문제-총-30점#네트워크 구성 및 통신 관련 문제 (총 30점)":"","네트워크-라우터의-패킷-서비스-순서-문제#네트워크 라우터의 패킷 서비스 순서 문제":"","네트워크-정보#네트워크 정보":"주어진 간선(링크)와 비용(Cost):\nut : 5 uv : 6 ux : 2 tw : 2 vx : 2 xw : 2 xw : 4 (중복된 링크, 동일 노드 간 두 개의 연결 존재) xy : 3 xz : 2 wz : 1 yz : 1 각 점에서의 least cost path를 찾는 문제입니다.\n총 20점 (문제 7: 10점, 문제 8: 10점)","네트워크-최단-경로-문제#네트워크 최단 경로 문제":"","네트워킹-관련-문제-총-20점#네트워킹 관련 문제 (총 20점)":"","문제-내용#문제 내용":"데이터 D = 10111001010을 전송할 때, 순환 중복 검사(CRC, Cyclic Redundancy Check)를 사용하여 오류를 탐지하려고 합니다.\n이때 사용하는 생성자(Generator Polynomial)는 G = 1001입니다.","설명#설명":"","설명-1#설명":"WFQ 스케줄링은 가중치를 기반으로 각 패킷의 가상 종료 시간(Virtual Finish Time)을 계산하고, 이 값이 가장 작은 패킷을 우선적으로 서비스합니다. 가상 종료 시간은 이전 패킷의 종료 시간 + (패킷 전송 시간 / 가중치) 공식으로 계산됩니다. 모든 패킷의 크기가 동일하므로 ‘패킷 전송 시간’을 임의의 값(예: 12)으로 가정하여 계산할 수 있습니다.\n주어진 가중치: Class 1 = 3, Class 2 = 2, Class 3 = 4 시작: 각 큐의 첫 패킷(P1, P2, P3)의 가상 종료 시간을 계산합니다.\nP1(C3, w=4): 12 / 4 = 3 P2(C1, w=3): 12 / 3 = 4 P3(C2, w=2): 12 / 2 = 6 ➡️ P1 선택 (값이 가장 작음) 다음: P1이 서비스된 Class 3의 다음 패킷(P6)의 가상 종료 시간을 계산합니다.\nP6(C3): 3 (P1의 값) + 12 / 4 = 6 P2(C1): 4 P3(C2): 6 ➡️ P2 선택 다음: P2가 서비스된 Class 1의 다음 패킷(P4)을 계산합니다.\nP4(C1): 4 (P2의 값) + 12 / 3 = 8 P6(C3): 6 P3(C2): 6 ➡️ P3와 P6의 값이 같으므로 패킷 번호가 낮은 P3 선택 이와 같은 방식으로 모든 패킷의 가상 종료 시간을 순차적으로 계산하고 비교하여 전체 서비스 순서를 결정합니다.","요구-사항#요구 사항":"이 데이터에 CRC 값을 추가하기 위해 필요한 체크섬(FCS, Frame Check Sequence) 필드 값을 계산하시오 계산 과정과 결과 값을 명확히 보이시오\n(5점)","요구사항#요구사항:":"","요구사항-1#요구사항:":"","제시된-표-형식#제시된 표 형식:":"Step N’ D(t),p(t) D(v),p(v) D(w),p(w) D(x),p(x) D(y),p(y) D(z),p(z) 0 u 1 2 3 4 5 6 D(n) : node n까지의 누적 최소 비용 p(n) : 이전(predecessor) 노드","제시된-표-형식-1#제시된 표 형식:":"From u Cost to, (to neighbor of u) t v w x y z up to 1 hop up to 2 hops up to 3 hops up to 4 hops","주어진-조건-요약#주어진 조건 요약":"S3: 다른 호스트들이 사용하는 서버 S1: DNS 서버 S2: 웹 서버 (www.neighbor.com) D: 호스트가 subnet mask 255.255.254.0인 네트워크에 새로 접속 D는 웹 브라우저에서 www.neighbor.com을 요청하는 상황을 기반으로 문제 해결","질문#질문:":"생성되는 최대 서브넷의 개수는 얼마입니까? 이렇게 만든 모든 서브넷을 사용할 경우, 실제 사용 가능한 최대 호스트의 개수는 몇 개인가요?","질문-1#질문:":"슈퍼네팅에 필요한 다른 네트워크 주소와 합쳐진 단일 네트워크 주소를 CIDR 표기법으로 각각 제시하시오.","질문-2#질문:":"각 호스트가 동시에 동일한 외부 서버(예: 8.8.8.8)에 접속할 때, NAT 테이블에 저장되어야 하는 정보를 포함한 예시를 작성하시오. NAT 라우터가 외부에서 들어오는 응답 패킷을 올바른 내부 호스트로 전달하는 방법을 설명하시오.","질문-3#질문:":"호스트가 속한 네트워크 주소(실제 숫자)를 쓰시오. 외부 인터넷과 데이터그램 송수신을 담당할 기기 인터페이스의 주소를 CIDR 표기법으로 쓰시오.","질문-4#질문:":"이때 전송되는 DHCP Request 메시지가 담긴 Layer 2 프레임의 destination 주소는 무엇입니까?","질문-5#질문:":"이 문제를 해결하기 위해 사용하는 프로토콜의 정식 명칭을 쓰시오. 해당 프로토콜을 사용해서 알아낸 Layer 2 주소(MAC 주소)를 쓰시오."},"title":"네트워크 족보 문제 풀이"},"/06.university/network/%EB%AC%B4%EC%A0%9C/":{"data":{"":"알겠습니다. 컴퓨터공학 전공자로서 기술적 내용에 중점을 둔 5G 및 6G 네트워크 통신 기술 보고서를 작성해 드리겠습니다. 먼저 요청하신 대로 목차를 다시 제시하고, 이어서 각 항목에 대한 기술 중심의 설명을 제공하겠습니다.","1-서론#1. 서론":"","1-서론-1#1. 서론":"","11-5g를-넘어-6g로-차세대-네트워크의-비전과-사회-변화의-기대감#1.1. 5G를 넘어 6G로: 차세대 네트워크의 비전과 사회 변화의 기대감":"우리는 불과 몇 년 전 4세대 이동통신(4G LTE)이 제공하는 모바일 광대역 서비스를 통해 스마트폰으로 언제 어디서나 인터넷에 접속하고 다양한 정보를 소비하는 시대를 맞이했습니다. 이제 우리는 5세대 이동통신(5G)의 상용화를 넘어, 그 다음 세대인 6세대 이동통신(6G) 기술을 향한 기대감 속에 살아가고 있습니다. 5G는 단순히 더 빠른 속도의 통신을 의미하는 것을 넘어, 초고속(eMBB), 초저지연(URLLC), 초연결(mMTC)이라는 세 가지 핵심 특징을 바탕으로 가상현실(VR), 증강현실(AR), 스마트 팩토리, 자율주행 등 과거에는 상상하기 어려웠던 혁신적인 서비스들을 우리 생활과 산업 현장 곳곳에 스며들게 하고 있습니다.\n이러한 5G의 성과를 발판 삼아, 6G는 한층 더 진화된 기술을 통해 인간과 사물, 공간 모두가 유기적으로 연결되고 지능화되는 새로운 차원의 시대를 열 것으로 전망됩니다. 테라헤르츠(THz)와 같은 초고주파 대역 활용을 통한 초고속·대용량 데이터 전송, 인공지능(AI)의 네트워크 전반 적용을 통한 완전 자동화 및 지능형 서비스 제공, 통신과 센싱 기능의 융합을 통한 현실 세계의 디지털 복제(디지털 트윈) 및 상호작용 강화 등은 6G가 가져올 미래 사회의 모습을 어렴풋이 보여주고 있습니다. 이러한 차세대 네트워크 기술의 발전은 우리 삶의 방식, 사회 시스템, 그리고 경제 구조 전반에 걸쳐 이전과는 비교할 수 없는 거대한 변화를 예고하며 큰 기대감을 불러일으키고 있습니다.","11-차세대-이동통신-기술의-등장-배경-및-기술적-요구사항#1.1. 차세대 이동통신 기술의 등장 배경 및 기술적 요구사항":"이동통신 기술은 지난 수십 년간 비약적인 발전을 거듭하며 우리 생활과 산업 전반에 혁명적인 변화를 가져왔습니다. 1세대(1G) 아날로그 음성 통화에서 시작하여, 2세대(2G) 디지털 음성 및 문자 메시지, 3세대(3G) 모바일 인터넷 접속, 4세대(4G) LTE를 통한 모바일 광대역 서비스로 진화해왔습니다. 특히 4G LTE는 스마트폰의 대중화를 이끌며 다양한 모바일 애플리케이션과 서비스의 기반이 되었습니다.\n그러나 모바일 데이터 트래픽의 폭발적인 증가, 사물인터넷(IoT) 기기의 확산, 증강현실(AR)·가상현실(VR)과 같은 실감형 미디어 서비스의 등장, 자율주행차, 스마트 팩토리 등 새로운 산업 분야의 출현은 기존 4G 기술의 한계를 드러내기 시작했습니다. 이러한 배경 속에서 더 높은 전송 속도(throughput), 더 짧은 지연 시간(latency), 그리고 더 많은 기기를 동시에 수용할 수 있는 연결성(connectivity) 이라는 명확한 기술적 요구사항과 함께 5G 기술이 등장하게 되었습니다.\n5G는 단순히 4G보다 빠른 기술을 넘어, 다양한 산업 분야와의 융합을 통해 새로운 가치를 창출하고 디지털 전환(Digital Transformation)을 가속화하는 핵심 인프라로 주목받고 있습니다. 나아가 현재 활발히 연구가 진행 중인 6G는 5G의 성능을 극한으로 끌어올리는 동시에, 인공지능(AI)과의 완전한 통합, 통신과 센싱의 융합, 공간 제약 없는 통신 등을 목표로 하여 더욱 혁신적인 미래 사회의 청사진을 제시하고 있습니다.","12-연구의-목적-5g6g-핵심-기술-이해와-실생활-사회-경제적-영향-다각적-분석#1.2. 연구의 목적: 5G/6G 핵심 기술 이해와 실생활, 사회, 경제적 영향 다각적 분석":"본 보고서의 목적은 현재 우리 사회의 디지털 전환을 이끌고 있는 5G 네트워크 통신 기술과 다가올 미래의 핵심 인프라가 될 6G 네트워크 통신 기술의 주요 특징과 핵심 기술들을 이해하는 데 있습니다. 더 나아가, 이러한 첨단 통신 기술의 발전이 단순한 기술적 진보를 넘어 우리들의 구체적인 실생활, 사회 구조 및 기능, 그리고 경제 산업 전반에 걸쳐 어떠한 긍정적 변화와 기회를 가져다주는 동시에, 어떠한 부정적 영향이나 해결해야 할 과제들을 안겨줄 수 있는지 다각적인 관점에서 심층적으로 분석하고자 합니다.\n특히 컴퓨터공학 전공자로서 기술의 원리를 이해하는 것을 바탕으로, 이러한 기술들이 실제로 어떻게 구현되고 활용될 수 있는지, 그리고 그 과정에서 발생할 수 있는 긍정적·부정적 파급 효과들을 구체적인 예를 통해 제시하고, 이에 대한 본인의 비판적이고 건설적인 의견을 제시하는 것을 목표로 합니다.","12-연구의-목적-및-기술적-범위-정의#1.2. 연구의 목적 및 기술적 범위 정의":"본 보고서의 목적은 현재 상용화되어 우리 생활 깊숙이 들어오고 있는 5G 네트워크 통신 기술의 핵심 요소와 아키텍처를 기술적으로 심층 분석하고, 차세대 기술로 연구개발이 진행 중인 6G의 비전과 예상 핵심 기술들을 조망하는 데 있습니다.\n이를 위해 5G의 경우, 3GPP 표준화 문서를 기반으로 한 핵심 성능 지표, 새로운 무선 접속 기술(NR), 5G 코어 네트워크(5GC) 아키텍처 및 주요 서비스 시나리오별 기술적 요구사항을 상세히 다룰 것입니다. 특히 mmWave 주파수 활용, Massive MIMO, 네트워크 슬라이싱, 모바일 엣지 컴퓨팅 등 5G를 특징짓는 핵심 기술들의 원리와 구현 방식을 중심으로 설명합니다.\n6G에 대해서는 현재 논의되고 있는 비전과 성능 목표를 제시하고, 테라헤르츠 대역 통신, AI/ML 기반 네트워크 지능화, 공간 통신 기술, 네트워크-컴퓨팅-센싱 융합 등 유력한 후보 기술들의 개념과 연구 동향, 그리고 예상되는 기술적 난제들을 살펴볼 것입니다.\n궁극적으로 이러한 기술 분석을 바탕으로 5G 및 6G 기술이 가져올 실생활, 사회, 경제 전반의 긍정적·부정적 영향을 기술적 관점에서 구체적인 예를 들어 예측하고, 컴퓨터공학도로서 기술적 과제를 해결하고 바람직한 미래를 만들어가기 위한 방안을 제시하고자 합니다. 본 보고서는 인문학적 접근보다는 기술의 원리, 구현 방식, 성능 지표, 그리고 기술적 파급 효과에 초점을 맞추어 전개될 것입니다.","13-보고서의-구성-및-범위-제어-평면-기술을-포함한-핵심-기술과-그-파급-효과-중심#1.3. 보고서의 구성 및 범위 (제어 평면 기술을 포함한 핵심 기술과 그 파급 효과 중심)":"본 보고서는 먼저 5G 및 6G 네트워크의 핵심 기술 요소들을 살펴보고, 특히 네트워크의 유연성, 지능성, 자동화를 가능하게 하는 핵심 요소인 제어 평면(Control Plane) 기술의 진화(예: 소프트웨어 정의 네트워킹 - SDN, 네트워크 기능 자동화 - NETCONF/YANG 등)에 주목하여 기술적 배경을 설명할 것입니다. 제공된 “Network Layer: Control Plane” PPT 자료의 핵심 개념들을 바탕으로, 이러한 제어 평면 기술이 어떻게 5G/6G의 혁신적인 서비스들을 가능하게 하는지 연관 지어 이해를 돕고자 합니다.\n이러한 기술적 이해를 바탕으로, 5G 및 6G 기술이 우리 실생활에 가져올 편리함과 새로운 경험, 사회 시스템의 효율화와 공공 서비스 개선, 그리고 신산업 창출과 경제 성장과 같은 긍정적 측면을 구체적인 예시와 함께 제시할 것입니다. 동시에, 디지털 격차 심화, 프라이버시 침해, 일자리 변화, 사이버 보안 위협 증가, 그리고 기술의 오용 가능성과 같은 잠재적인 부정적 영향과 우려 사항들에 대해서도 균형 있는 시각으로 조명할 것입니다.\n마지막으로, 이러한 분석을 종합하여 5G와 6G 기술이 만들어갈 미래 사회가 더욱 바람직한 방향으로 나아가기 위해 필요한 노력과 컴퓨터공학도로서 기여할 수 있는 부분에 대한 본인의 의견을 제시하며 보고서를 마무리하고자 합니다. 본 보고서는 기술적 설명의 깊이를 일정 수준으로 유지하면서도, 기술이 사회 전반에 미치는 영향에 대한 폭넓은 이해를 돕는 데 중점을 둘 것입니다.","2-5g-네트워크-통신-기술-분석#2. 5G 네트워크 통신 기술 분석":"","21-5g의-핵심-성능-지표kpi-및-표준화-동향-3gpp-릴리즈-기반#2.1. 5G의 핵심 성능 지표(KPI) 및 표준화 동향 (3GPP 릴리즈 기반)":"5G 이동통신 기술은 국제전기통신연합(ITU)에서 정의한 IMT-2020 표준을 기반으로 하며, 주요 기술 규격은 이동통신 표준화 기술협력기구인 3GPP(3rd Generation Partnership Project)를 통해 개발되고 있습니다. 5G의 주요 핵심 성능 지표(KPI)는 다음과 같습니다.\n최대 전송 속도 (Peak Data Rate): 다운링크 20 Gbps, 업링크 10 Gbps 사용자 체감 전송 속도 (User Experienced Data Rate): 다운링크 100 Mbps, 업링크 50 Mbps (도심 밀집 환경 기준) 주파수 효율 (Spectrum Efficiency): LTE 대비 3배 향상 (eMBB 기준) 이동성 (Mobility): 최대 500 km/h 속도에서도 통신 지원 지연 시간 (Latency): 무선 구간 1ms (URLLC 기준), 종단간(E2E) 1ms 목표 연결 밀도 (Connection Density): 1 km² 당 100만 개 기기 연결 지원 (mMTC 기준) 에너지 효율 (Network Energy Efficiency): LTE 대비 100배 향상 면적 당 트래픽 용량 (Area Traffic Capacity): 1 m² 당 10 Mbps (eMBB 실내 핫스팟 기준) 3GPP는 5G 표준을 여러 릴리즈(Release)를 통해 순차적으로 개발해왔습니다.\n릴리즈 15 (Rel-15): 2018년 완료. 5G NR의 초기 표준(Phase 1)으로, Non-Standalone (NSA) 운영 (LTE 코어망 활용) 및 Standalone (SA) 운영 (5G 코어망 활용)을 모두 지원합니다. eMBB 서비스에 중점을 두었습니다. 릴리즈 16 (Rel-16): 2020년 완료. 5G NR Phase 2 표준으로, URLLC 기능 강화, 산업용 IoT(IIoT) 지원, V2X(Vehicle-to-Everything) 통신, 비면허 대역 기반 5G NR(NR-U) 등을 포함합니다. 릴리즈 17 (Rel-17): 2022년 완료. 위성 통신 연동(NTN: Non-Terrestrial Networks), NR-Light(RedCap: Reduced Capability)을 통한 중급 IoT 지원, 사이드링크 기능 강화, XR(확장현실) 지원 향상 등을 포함합니다. 릴리즈 18 (Rel-18): 현재 진행 중. “5G-Advanced\"의 시작으로, AI/ML 기술의 네트워크 적용, 센싱 기능 통합, XR 기능 심화 등을 목표로 합니다.","22-5g-핵심-기술-요소-상세-분석#2.2. 5G 핵심 기술 요소 상세 분석":"","221-새로운-무선-접속-기술-nr-new-radio#2.2.1. 새로운 무선 접속 기술 (NR: New Radio)":"5G NR은 다양한 서비스 요구사항을 만족시키기 위해 유연하고 확장 가능한 무선 인터페이스를 제공합니다.\n2.2.1.1. 주파수 대역 확장 (Sub-6GHz, mmWave) 및 특성:\nSub-6GHz (FR1: Frequency Range 1): 410MHz ~ 7.125GHz 대역. 기존 LTE 대역을 포함하며, 넓은 커버리지 확보에 유리하지만, 가용 대역폭이 제한적입니다. 주로 전국망 커버리지 및 기본적인 5G 서비스 제공에 활용됩니다. 밀리미터파 (mmWave, FR2: Frequency Range 2): 24.25GHz ~ 52.6GHz 대역. 매우 넓은 대역폭(수백 MHz ~ 수 GHz)을 활용하여 초고속 데이터 전송이 가능하지만, 직진성이 강하고 장애물 투과율이 낮아 커버리지가 좁고 구축 비용이 높습니다. 핫스팟, 인빌딩, 특정 산업 현장 등에서 주로 활용됩니다. mmWave는 대기 중 산소나 수증기에 의한 흡수 손실, 경로 손실이 크다는 기술적 과제가 있습니다. 2.2.1.2. Massive MIMO (Multiple-Input Multiple-Output) 및 빔포밍 (Beamforming):\nMassive MIMO: 기지국에 수십에서 수백 개의 안테나 소자를 집적하여 공간 다중화(Spatial Multiplexing) 이득을 극대화하고, 여러 사용자에게 동시에 데이터를 전송하거나 특정 사용자에게 집중적으로 전송하는 기술입니다. 이를 통해 주파수 효율과 셀 용량을 크게 향상시킬 수 있습니다. 안테나 수가 증가함에 따라 채널 추정의 복잡성 증가, RF 체인 비용 증가 등의 기술적 고려사항이 있습니다. 빔포밍: 다수의 안테나에서 방사되는 신호의 위상과 진폭을 조절하여 특정 방향으로 전파 에너지를 집중시키는 기술입니다. 이를 통해 특정 사용자에게 신호 강도를 높이고, 다른 사용자에 대한 간섭을 줄일 수 있습니다. mmWave 대역의 높은 경로 손실을 극복하고 커버리지를 확보하는 데 필수적인 기술입니다. 아날로그 빔포밍, 디지털 빔포밍, 하이브리드 빔포밍 방식이 있으며, 복잡도와 성능 간의 트레이드오프가 존재합니다. 2.2.1.3. 유연한 프레임 구조 및 OFDM 변형 기술 (예: CP-OFDM, DFT-s-OFDM):\n5G NR은 다양한 서비스 시나리오(eMBB, URLLC, mMTC)와 주파수 대역(Sub-6GHz, mmWave)에 유연하게 대응하기 위해 가변적인 부반송파 간격(SCS: Subcarrier Spacing), 슬롯 길이, 미니-슬롯(mini-slot) 등을 지원하는 유연한 프레임 구조를 채택했습니다. SCS는 15kHz, 30kHz, 60kHz, 120kHz, 240kHz 등 다양하게 설정 가능하며, 이는 지연 시간에 민감한 서비스(URLLC)나 고주파 대역(mmWave) 운영에 적합합니다. CP-OFDM (Cyclic Prefix Orthogonal Frequency Division Multiplexing): 대부분의 5G 다운링크 및 업링크 전송에 사용되는 기본 파형입니다. 다중 경로 페이딩에 강하고 주파수 효율이 높습니다. DFT-s-OFDM (Discrete Fourier Transform spread OFDM): 업링크 전송에서 단말기의 PAPR(Peak-to-Average Power Ratio)을 낮추기 위해 선택적으로 사용됩니다. 이는 단말기의 전력 증폭기 효율을 높이고 배터리 소모를 줄이는 데 기여합니다. 2.2.1.4. 고급 채널 코딩 (LDPC, Polar Codes):\n데이터 전송 시 발생하는 오류를 정정하기 위해 강력한 채널 코딩 기술을 사용합니다. LDPC (Low-Density Parity-Check) 부호: 데이터 채널(eMBB)에 주로 사용되며, 높은 코딩 이득과 병렬 처리 용이성으로 고속 데이터 전송에 적합합니다. Polar 부호: 제어 채널(URLLC의 일부 제어 정보)에 주로 사용되며, 상대적으로 짧은 블록 길이에서도 우수한 성능을 보입니다.","222-5g-코어-네트워크-5gc-아키텍처#2.2.2. 5G 코어 네트워크 (5GC) 아키텍처":"5GC는 다양한 서비스 요구사항을 효율적으로 지원하기 위해 클라우드 네이티브 기술을 기반으로 설계되었습니다.\n2.2.2.1. 서비스 기반 아키텍처 (SBA: Service-Based Architecture):\n기존 4G EPC(Evolved Packet Core)의 점대점(Point-to-Point) 인터페이스 방식 대신, 각 네트워크 기능(NF: Network Function)들이 잘 정의된 API를 통해 서로 서비스를 제공하고 소비하는 방식으로 구성됩니다. 이는 마이크로서비스 아키텍처(MSA)와 유사하며, 네트워크 기능의 모듈화, 유연성, 확장성을 높여줍니다. 주요 NF로는 AMF(Access and Mobility Management Function), SMF(Session Management Function), UPF(User Plane Function), AUSF(Authentication Server Function1), NRF(NF Repository Function) 등이 있습니다. 2.2.2.2. 네트워크 슬라이싱 (Network Slicing):\n하나의 물리적인 네트워크 인프라를 다수의 독립적인 가상 네트워크(네트워크 슬라이스)로 분할하여 각 슬라이스마다 특정 서비스(eMBB, URLLC, mMTC 등)에 최적화된 특성을 제공하는 기술입니다. 각 슬라이스는 독립적인 네트워크 자원(RAN, 코어, 전송망) 할당, 토폴로지, 기능 등을 가질 수 있으며, 서비스 맞춤형 네트워크를 온디맨드(on-demand) 방식으로 제공할 수 있게 합니다. 이를 통해 통신 사업자는 다양한 버티컬 산업의 요구사항을 효과적으로 만족시킬 수 있습니다. 슬라이스 간 격리(isolation) 보장 및 효율적인 자원 관리가 기술적 핵심입니다. 2.2.2.3. 모바일 엣지 컴퓨팅 (MEC: Multi-access Edge Computing):\n데이터 처리 및 서비스 기능을 사용자 단말과 가까운 네트워크 엣지(edge)에 분산 배치하여, 데이터 전송 지연을 최소화하고 네트워크 부하를 줄이는 기술입니다. URLLC 서비스(예: 자율주행, 스마트 팩토리)나 대용량 콘텐츠 전송(예: AR/VR)에 필수적입니다. MEC 플랫폼은 애플리케이션 개발자에게 개방되어 새로운 엣지 기반 서비스를 창출할 수 있는 기반을 제공합니다. 2.2.2.4. NFV (Network Functions Virtualization) 및 SDN (Software-Defined Networking) 적용:\nNFV: 라우터, 방화벽, 로드밸런서 등 기존 하드웨어 기반의 네트워크 장비 기능을 소프트웨어 형태로 가상화하여 범용 하드웨어(서버, 스토리지, 스위치)에서 실행하는 기술입니다. 이를 통해 장비 도입 비용 절감, 서비스 배포 시간 단축, 운영 유연성 향상이 가능합니다. 5GC의 NF들은 NFV 기반으로 구현됩니다. SDN: 네트워크 제어부(Control Plane)와 데이터 전달부(Data Plane 또는 User Plane)를 분리하고, 제어부를 중앙 집중화하여 네트워크 전체를 소프트웨어로 프로그래밍하고 관리하는 기술입니다. 네트워크 자원의 효율적인 할당, 트래픽 최적화, 신규 서비스 도입 용이성 등을 제공합니다. UPF와 SMF 간의 제어 인터페이스 등에서 SDN 원리가 활용됩니다.","23-5g-주요-서비스-시나리오별-기술적-요구사항#2.3. 5G 주요 서비스 시나리오별 기술적 요구사항":"2.3.1. eMBB (Enhanced Mobile Broadband): 고대역폭, 고속 데이터 전송\n기술적 요구사항: 매우 높은 데이터 전송률, 넓은 대역폭, 높은 스펙트럼 효율. 주요 기술: mmWave, Massive MIMO, 캐리어 어그리게이션(CA), LDPC 코딩. 활용 예: 초고화질 동영상 스트리밍, AR/VR, 고속 모바일 인터넷. 2.3.2. URLLC (Ultra-Reliable Low Latency Communications): 고신뢰성, 저지연 통신\n기술적 요구사항: 극도로 낮은 지연 시간 (1ms 이내), 매우 높은 신뢰도 (99.999% 이상). 주요 기술: 미니-슬롯, Grant-free 전송, 중복 전송(Duplication), MEC, 네트워크 슬라이싱, Polar 코딩. 활용 예: 원격 수술, 자율주행차 제어, 스마트 팩토리 로봇 제어, 공공 안전 통신. 2.3.3. mMTC (Massive Machine Type Communications): 대규모 디바이스 연결\n기술적 요구사항: 매우 높은 연결 밀도, 저전력 소모, 저비용 단말기. 주요 기술: NB-IoT(Narrowband-IoT), LTE-M(LTE for Machine-Type Communication)의 진화, Power Saving Mode (PSM), Extended Discontinuous Reception (eDRX), 단순화된 프로토콜 스택. 활용 예: 스마트 미터링, 스마트 시티 센서, 환경 모니터링, 스마트 농업.","24-5g-상용화-현황-및-기술적-과제#2.4. 5G 상용화 현황 및 기술적 과제":"5G는 전 세계적으로 빠르게 상용화되고 있으며, NSA 방식에서 SA 방식으로 전환이 이루어지고 있습니다. 주요 도시를 중심으로 mmWave 망 구축도 진행 중이지만, 다음과 같은 기술적 과제들이 존재합니다.\n커버리지 확보: 특히 mmWave 대역은 회절성이 낮고 장애물 투과 손실이 커서 넓은 지역에 균일한 커버리지를 제공하기 어렵습니다. 이를 해결하기 위해 더 많은 기지국(스몰셀) 설치, 중계기 활용, RIS(Reconfigurable Intelligent Surfaces)와 같은 신기술 연구가 필요합니다. 장비 호환성 및 비용: 다양한 벤더의 장비 간 상호 운용성 확보는 여전히 중요한 문제이며, mmWave 장비 및 단말기의 가격이 높아 보급 확대에 걸림돌이 될 수 있습니다. 간섭 문제: 다양한 주파수 대역 사용, 특히 비면허 대역 활용(NR-U) 시 기존 시스템과의 간섭 또는 5G 시스템 내 간섭 관리가 중요합니다. 에너지 효율성: 기지국 및 단말기의 에너지 소모를 줄이는 것은 네트워크 운영 비용 절감 및 환경 보호 측면에서 중요합니다. Massive MIMO, mmWave 등은 에너지 소모를 증가시키는 요인이 될 수 있어 효율적인 전력 관리 기술이 요구됩니다. 보안: 네트워크 슬라이싱, 가상화된 코어 네트워크 등 새로운 아키텍처 도입에 따른 보안 위협에 대한 대비가 필요합니다.","3-6g-네트워크-통신-기술-전망#3. 6G 네트워크 통신 기술 전망":"5G가 본격적으로 확산되는 가운데, 학계와 산업계에서는 이미 다음 세대 이동통신 기술인 6G에 대한 연구 개발을 시작했습니다. 6G는 2030년경 상용화를 목표로 하며, 5G의 성능을 비약적으로 향상시키는 동시에 새로운 차원의 서비스를 제공할 것으로 기대됩니다.","31-6g-비전-및-주요-성능-목표-5g-대비-향상점-중심#3.1. 6G 비전 및 주요 성능 목표 (5G 대비 향상점 중심)":"6G의 비전은 “모든 것이 연결되고 지능적으로 융합되는 세상(Connecting Everything with Ambient Intelligence)” 등으로 요약될 수 있습니다. 주요 성능 목표는 5G 대비 더욱 극한의 성능을 추구합니다.\n최대 전송 속도: 1 Tbps (5G 대비 50배) 사용자 체감 전송 속도: 1 Gbps (5G 대비 10배) 지연 시간: 무선 구간 0.1ms (5G 대비 1/10), 종단간 1ms 이하의 초저지연 지속 신뢰도: 99.99999% (Six-nines) 이상의 초고신뢰도 (URLLC 보다 한 단계 높은 수준) 연결 밀도: 1 km² 당 1,000만 개 기기 (5G 대비 10배) 이동성: 1,000 km/h 이상 (고속철도, 항공기 등 지원) 주파수 효율: 5G 대비 2~3배 향상 에너지 효율: 5G 대비 10~100배 향상 (목표치가 다양함) 정밀 측위: cm 수준의 실내외 정밀 측위 (현재 GPS는 수 m 수준) 센싱 기능: 통신 네트워크 자체를 센서로 활용하여 주변 환경 감지","32-6g-예상-핵심-기술-후보군-및-연구-동향#3.2. 6G 예상 핵심 기술 후보군 및 연구 동향":"6G는 5G의 기술을 기반으로 더욱 혁신적인 기술들을 통합할 것으로 예상됩니다.\n3.2.1. 테라헤르츠(THz) 및 서브-THz 대역 통신 기술:\n100GHz ~ 10THz 사이의 주파수 대역을 활용하여 Tbps급의 초고속 데이터 전송을 목표로 합니다. THz파는 매우 넓은 가용 대역폭을 제공하지만, mmWave보다 더 심각한 전파 손실, 대기 흡수, 부품 기술의 미성숙 등의 기술적 난제가 존재합니다. 초소형 안테나 어레이, 고효율 RF 부품 개발, 새로운 파형 및 신호 처리 기술 연구가 활발히 진행 중입니다. 3.2.2. AI/ML 기반 네트워크 지능화 및 자동화 (예: AI 기반 RAN, 코어망 운영):\n네트워크 설계, 구축, 운영, 최적화 전반에 AI/ML 기술을 깊숙이 통합하여 네트워크의 자율성과 효율성을 극대화합니다. 예를 들어, AI 기반 빔포밍 최적화, 동적 네트워크 슬라이스 관리, 예측 기반 자원 할당, 지능형 간섭 제거, 이상 트래픽 탐지 및 자동 복구 등이 가능해집니다. 이를 위해 경량화된 AI 모델, 실시간 학습 및 추론 기술, 데이터 수집 및 관리 플랫폼 구축이 중요합니다. 3.2.3. 공간 통신 기술 (예: 위성 통합, 무인항공기(UAV) 활용, Reconfigurable Intelligent Surfaces - RIS):\n위성 통합 (NTN: Non-Terrestrial Networks): 저궤도(LEO), 중궤도(MEO), 정지궤도(GEO) 위성 통신망을 지상망과 통합하여 음영 지역 없는 글로벌 커버리지를 제공합니다. 5G Rel-17에서 시작된 NTN 연구가 6G에서는 더욱 심화될 것입니다. UAV 활용: 드론이나 HAPS(High Altitude Platform Station)를 이동형 기지국 또는 중계기로 활용하여 재난 지역 통신 지원, 임시 커버리지 확장 등에 사용됩니다. RIS (Reconfigurable Intelligent Surfaces): 전파 환경을 동적으로 제어할 수 있는 메타표면(metasurface)을 건물 벽면이나 유리창 등에 설치하여, 전파를 원하는 방향으로 반사하거나 투과시켜 통신 품질을 개선하고 음영 지역을 해소하는 기술입니다. 수동형 RIS와 능동형 RIS 연구가 진행 중입니다. 3.2.4. 네트워크-컴퓨팅-센싱 융합 (예: ISAC - Integrated Sensing and Communication):\n통신 신호를 이용하여 주변 환경에 대한 정보를 감지(sensing)하고, 이 정보를 다시 통신 성능 향상이나 새로운 서비스 제공에 활용하는 기술입니다. 예를 들어, 기지국이 전파를 이용해 주변의 물체, 사람, 환경 변화 등을 감지하고, 이를 자율주행, 스마트 시티, 재난 감지 등에 활용할 수 있습니다. 통신과 센싱 기능을 동일한 하드웨어 및 주파수 자원에서 효율적으로 통합하는 것이 핵심입니다. 3.2.5. 차세대 코어 네트워크 및 아키텍처 (예: 분산형 AI, 양자 통신 연동 가능성):\n6G 코어 네트워크는 AI 기능을 내재화하고, 더욱 분산된 컴퓨팅 환경을 지원하며, 극한의 서비스 요구사항을 만족시키기 위한 새로운 아키텍처가 필요합니다. 데이터 중심 설계, 지능형 서비스 오케스트레이션, 종단간 보안 강화 등이 중요하며, 장기적으로는 양자 컴퓨팅 및 양자 통신 기술과의 연동 가능성도 탐색되고 있습니다. 3.2.6. 고정밀 측위 및 동기화 기술:\n센티미터(cm) 수준의 초정밀 실내외 위치 정보를 제공하여, 자율주행, 로보틱스, XR 등 다양한 위치 기반 서비스의 정확도를 향상시킵니다. 이를 위해 넓은 대역폭 신호, Massive MIMO, AI 기반 측위 알고리즘 등이 활용될 수 있습니다. 또한, 네트워크 전체의 정밀한 시간 동기화는 URLLC 및 분산 시스템 운영에 필수적입니다.","33-6g-기술의-표준화-로드맵-및-기술적-난제#3.3. 6G 기술의 표준화 로드맵 및 기술적 난제":"6G 기술의 표준화는 ITU-R의 IMT-2030 프레임워크 논의를 시작으로, 3GPP에서는 릴리즈 20 이후부터 본격적으로 다뤄질 것으로 예상됩니다. 상용화는 2028년~2030년경으로 전망되고 있습니다.\n기술적 난제는 다음과 같습니다.\nTHz 대역 기술 성숙도: THz RF 부품의 성능 및 집적도 향상, 채널 모델링, 효율적인 신호 처리 기술 확보가 시급합니다. AI 기술의 신뢰성 및 설명 가능성: 네트워크 운영에 AI를 적용할 때, AI 결정의 신뢰성, 안정성, 그리고 설명 가능성(explainability) 확보가 중요합니다. 네트워크 복잡도 증가: 다양한 기술의 융합으로 인해 네트워크 설계 및 운영의 복잡도가 크게 증가할 수 있습니다. 에너지 효율성 확보: Tbps급 속도, 초연결 환경에서도 지속 가능한 에너지 효율을 달성해야 합니다. 글로벌 표준화 및 주파수 확보 경쟁: 국가별, 지역별 이해관계에 따른 표준화 및 주파수 확보 경쟁이 예상됩니다. 사회적 수용성: 새로운 기술에 대한 사회적, 윤리적 논의와 합의 과정이 필요합니다.","4-5g-및-6g-기술의-기술적-파급-효과-및-영향-분석#4. 5G 및 6G 기술의 기술적 파급 효과 및 영향 분석":"5G 및 6G 기술은 단순히 통신 속도를 높이는 것을 넘어, 다양한 기술과 융합하여 실생활, 사회 인프라, 경제/산업 구조 전반에 걸쳐 광범위하고 심층적인 변화를 가져올 것입니다.","41-긍정적-영향-기술적-구현-가능성-및-새로운-서비스-창출-중심#4.1. 긍정적 영향 (기술적 구현 가능성 및 새로운 서비스 창출 중심)":"","411-실생활-변화-기술적-진보가-가져올-구체적-서비스-변화#4.1.1. 실생활 변화: 기술적 진보가 가져올 구체적 서비스 변화":"4.1.1.1. 완전 몰입형 XR (확장현실) 서비스: 5G의 eMBB(초고속)와 URLLC(초저지연)는 AR/VR/MR 서비스의 품질을 크게 향상시킵니다. 6G에서는 Tbps급 전송 속도와 0.1ms 수준의 초저지연을 통해 시각, 청각뿐만 아니라 촉각까지 포함하는 완전 몰입형 XR 경험(예: 고해상도 햅틱 피드백 연동)이 가능해질 것입니다. 이는 게임, 엔터테인먼트는 물론 원격 교육, 가상 쇼핑, 협업 등 다양한 분야에 활용될 수 있습니다. MEC 기술은 XR 콘텐츠 렌더링 및 데이터 처리를 엣지에서 수행하여 단말기의 부담을 줄이고 반응 속도를 높이는 데 기여합니다.\n4.1.1.2. 홀로그래픽 통신: 6G의 초고대역폭과 초저지연은 3차원 공간 정보를 실시간으로 전송하고 재현하는 홀로그래픽 통신을 현실화할 수 있습니다. 이는 원격 회의, 원격 진료, 실감형 교육 등에 활용되어 물리적 거리의 제약을 극복하는 새로운 소통 방식을 제공할 것입니다. Massive MIMO와 빔포밍 기술은 홀로그램 데이터와 같은 대용량 정보를 안정적으로 전송하는 데 필요합니다.\n4.1.1.3. 디지털 트윈 및 사이버 물리 시스템(CPS) 고도화: 현실 세계의 사물이나 시스템을 가상 공간에 동일하게 복제하는 디지털 트윈은 5G의 mMTC(초연결) 및 URLLC를 통해 실현 가능성이 높아졌습니다. 6G에서는 ISAC(통합 센싱 및 통신) 기술과 초정밀 측위 기술을 통해 더욱 정교하고 실시간성이 높은 디지털 트윈 구축이 가능해집니다. 이를 통해 도시, 공장, 인체 등의 복잡한 시스템을 시뮬레이션하고, 예측, 최적화, 원격 제어하는 CPS의 고도화가 이루어질 것입니다.\n4.1.1.4. 브레인-컴퓨터 인터페이스(BCI) 연동 가능성 (장기적 관점): 6G의 초저지연, 초고신뢰 통신은 뇌파와 같은 생체 신호를 실시간으로 분석하고, 이를 통해 기기를 제어하거나 의사소통하는 BCI 기술의 발전에 기여할 수 있습니다. 이는 의료, 재활 분야뿐만 아니라 새로운 사용자 인터페이스로서의 가능성을 열어줄 수 있으나, 기술적, 윤리적 과제가 많이 남아있는 장기적인 전망입니다.","412-사회-인프라-변화-지능형-인프라-구축-및-운영-효율화#4.1.2. 사회 인프라 변화: 지능형 인프라 구축 및 운영 효율화":"4.1.2.1. 자율주행 네트워크 및 지능형 교통 시스템 (ITS)의 완전 자율화: 5G의 V2X 통신은 차량 간(V2V), 차량-인프라 간(V2I) 통신을 지원하여 자율주행의 안전성을 높입니다. 6G에서는 더욱 향상된 URLLC, eMBB, 그리고 ISAC 기술을 통해 차량이 주변 환경을 보다 정밀하게 인지하고, 실시간으로 복잡한 교통 상황에 대응하는 완전 자율주행(레벨 5)의 실현을 앞당길 것입니다. 네트워크 슬라이싱은 자율주행차량의 안전 관련 통신에 높은 우선순위와 품질을 보장하는 데 활용됩니다.\n4.1.2.2. 원격 로봇 수술 및 정밀 의료 서비스 확대: 5G URLLC는 원격 로봇 수술 시 촉각 정보 전달과 정밀 제어를 가능하게 합니다. 6G에서는 지연 시간이 더욱 단축되고 신뢰도가 극대화되어, 수술의 정밀도와 안정성이 향상될 것입니다. 또한, AI 기반 의료 영상 분석, 웨어러블 기기를 통한 실시간 건강 모니터링 및 맞춤형 원격 진료 서비스가 고도화될 것입니다.\n4.1.2.3. 스마트 시티 운영 시스템의 실시간 최적화: 5G mMTC는 도시 전역에 설치된 수많은 센서와 기기를 연결하여 데이터를 수집하고, 6G에서는 AI 기반 분석 및 ISAC 기술을 통해 도시 운영의 효율성을 극대화합니다. 교통 흐름 최적화, 에너지 사용량 관리, 환경 오염 모니터링, 재난 예측 및 대응 시스템 등이 실시간으로 지능화될 것입니다.","413-경제산업-구조-변화-기술-기반-신산업-및-생산-방식-혁신#4.1.3. 경제/산업 구조 변화: 기술 기반 신산업 및 생산 방식 혁신":"4.1.3.1. 산업용 IoT(IIoT) 및 스마트 팩토리의 초지능화: 5G URLLC와 네트워크 슬라이싱은 스마트 팩토리 내 로봇 제어, 공정 자동화, 실시간 품질 관리 등을 지원합니다. 6G에서는 AI와 디지털 트윈 기술이 결합되어, 생산 라인의 완전 자율 운영, 예지 보전, 맞춤형 대량 생산 등이 가능해질 것입니다. THz 대역을 활용한 고정밀 센싱은 제조 공정의 미세한 오류까지 감지하는 데 기여할 수 있습니다.\n4.1.3.2. UAM(도심항공교통) 등 신규 모빌리티 산업 지원 인프라: UAM과 같은 차세대 모빌리티는 안전한 운항을 위해 매우 높은 신뢰성과 저지연성을 갖춘 통신 인프라가 필수적입니다. 5G-Advanced 및 6G의 NTN(위성 통합), 고정밀 측위, URLLC 기술은 UAM의 관제, 자율 비행, 충돌 방지 시스템 등을 지원하는 핵심 인프라가 될 것입니다.\n4.1.3.3. 데이터 중심 경제 가속화 및 AI 기반 서비스 확산: 5G 및 6G 환경에서는 엄청난 양의 데이터가 생성, 수집, 분석될 것입니다. 이는 AI 모델 학습 및 서비스 개발을 위한 핵심 자원이 되며, 데이터 기반의 새로운 비즈니스 모델과 서비스가 다양한 산업 분야에서 확산될 것입니다. 엣지 컴퓨팅은 데이터 처리의 분산화와 실시간성을 높여 이러한 변화를 가속화합니다.","42-부정적-영향-및-기술적-해결-과제-보안-프라이버시-에너지-효율-등#4.2. 부정적 영향 및 기술적 해결 과제 (보안, 프라이버시, 에너지 효율 등)":"","421-기술적-문제점-및-우려#4.2.1. 기술적 문제점 및 우려":"4.2.1.1. 보안 취약성 증대: mMTC로 인해 연결되는 디바이스 수가 기하급수적으로 증가하고, 네트워크 슬라이싱, NFV/SDN, MEC 등 아키텍처가 복잡해지면서 잠재적인 공격 표면(attack surface)이 크게 확대됩니다. IoT 디바이스의 보안 취약점, 가상화 환경의 보안 문제, 슬라이스 간 격리 실패 등이 새로운 보안 위협으로 대두될 수 있습니다. 엔드-투-엔드 암호화 강화, AI 기반 이상행위 탐지, 제로 트러스트(Zero Trust) 보안 모델 도입 등 다층적인 보안 기술 개발이 시급합니다.\n4.2.1.2. 프라이버시 침해 가능성: 6G의 ISAC, 고정밀 측위, AI 기반 데이터 분석 기술은 개인의 위치, 행동, 생체 정보 등 민감한 데이터를 이전보다 훨씬 정밀하게 수집하고 분석할 수 있게 합니다. 이는 프라이버시 침해의 위험을 크게 높일 수 있습니다. 데이터 익명화/가명화 기술, 차등 프라이버시(Differential Privacy), 연합 학습(Federated Learning)과 같은 프라이버시 강화 기술(PET: Privacy Enhancing Technologies)의 연구 및 적용이 중요합니다.\n4.2.1.3. 네트워크 및 단말기의 에너지 소비 증가 문제: Tbps급 전송 속도, THz 대역 활용, Massive MIMO 안테나 수 증가, AI 연산량 증가는 네트워크 장비와 단말기의 전력 소비를 크게 증가시킬 수 있습니다. 이는 통신 사업자의 운영 비용 증가뿐만 아니라 탄소 배출량 증가 등 환경 문제로 이어질 수 있습니다. 저전력 RF 부품 개발, 에너지 효율적인 파형 및 프로토콜 설계, AI 기반 지능형 전력 관리 기술 등 에너지 효율성 확보를 위한 다각적인 노력이 필요합니다.\n4.2.1.4. 전파 인체 유해성 논란 (특히 고주파 대역) 및 기술적 검증 필요성: mmWave 및 THz와 같은 고주파 대역의 전자파가 인체에 미치는 영향에 대한 사회적 우려가 존재합니다. 이에 대한 과학적이고 객관적인 연구를 통해 안전 기준을 마련하고, 대중과의 투명한 소통을 통해 기술적 신뢰를 확보해야 합니다. 또한, 전파 노출을 최소화할 수 있는 빔포밍 기술, 저출력 통신 기술 등의 연구도 병행되어야 합니다.\n4.2.1.5. 기술 구현의 복잡성 및 상호 운용성 확보 문제: 6G는 다양한 첨단 기술들이 복합적으로 융합되기 때문에 시스템 설계 및 구현의 복잡성이 매우 높습니다. 이종 기술 간, 서로 다른 벤더 장비 간의 원활한 상호 운용성을 확보하기 위한 표준화 노력과 철저한 검증 과정이 필수적입니다.","422-사회경제적-문제점-기술적-관점에서-파생되는-문제#4.2.2. 사회·경제적 문제점 (기술적 관점에서 파생되는 문제)":"4.2.2.1. 기술 격차 (Digital Divide) 심화: 고도화된 5G/6G 인프라 구축에는 막대한 비용이 소요되므로, 경제적 여건에 따라 국가별, 지역별, 계층별 기술 접근성과 활용 수준에 격차가 발생할 수 있습니다. 이는 정보 불평등을 심화시키고 사회적 양극화를 초래할 수 있습니다. 포용적인 인프라 구축 전략과 디지털 리터러시 교육 강화가 필요합니다.\n4.2.2.2. 고용 구조 변화 가속화: AI 기반 자동화, 스마트 팩토리, 자율주행 등 5G/6G 기술이 가져올 산업 혁신은 기존 일자리를 대체하고 고용 구조에 큰 변화를 야기할 수 있습니다. 새로운 기술에 적응하기 위한 재교육 프로그램 확대 및 사회 안전망 강화가 중요합니다.\n4.2.2.3. 인프라 투자 비용 및 유지보수 부담 증가: THz 대역 활용을 위한 초고밀도 셀 구축, AI 연산을 위한 고성능 컴퓨팅 인프라 확보 등은 막대한 초기 투자 비용을 요구합니다. 또한, 고도로 복잡해진 네트워크의 유지보수 및 운영 비용도 증가할 수 있어, 효율적인 투자 및 운영 모델 개발이 필요합니다.","5-결론-기술적-과제와-미래-전망-본인-의견-포함#5. 결론: 기술적 과제와 미래 전망 (본인 의견 포함)":"","51-5g-및-6g-기술의-핵심적-의의-및-기술-발전-방향-요약#5.1. 5G 및 6G 기술의 핵심적 의의 및 기술 발전 방향 요약":"5G 기술은 초고속, 초저지연, 초연결이라는 3대 핵심 성능을 바탕으로 모바일 브로드밴드의 고도화를 넘어 다양한 산업 분야와의 융합을 가능하게 하는 디지털 전환의 핵심 인프라로서의 의의를 지닙니다. mmWave, Massive MIMO, 네트워크 슬라이싱, MEC 등의 핵심 기술들은 이러한 성능 목표를 달성하고, 스마트 팩토리, 자율주행, 실감형 미디어 등 새로운 서비스를 현실화하는 기반을 제공했습니다.\n6G 기술은 5G의 성능을 극한으로 끌어올려 Tbps급 전송 속도, 0.1ms 수준의 지연 시간, cm급 정밀 측위 등을 목표로 하며, 여기에 더해 AI/ML의 완전한 네트워크 내재화, 통신-센싱-컴퓨팅의 융합, 위성을 포함한 공간 통신이라는 새로운 차원의 기술적 진보를 추구합니다. THz 통신, RIS, ISAC 등의 기술은 6G가 단순히 통신망을 넘어 지능형 인프라 플랫폼으로 진화하는 데 핵심적인 역할을 할 것으로 기대됩니다. 이는 현실 세계와 가상 세계를 완벽하게 연결하고, 모든 사물과 공간에 지능을 부여하여 인간의 삶과 산업의 방식을 근본적으로 변화시킬 잠재력을 가지고 있습니다.\n기술 발전 방향은 단순히 성능 지표를 높이는 것을 넘어, 네트워크의 유연성, 개방성, 지능성, 그리고 지속 가능성을 확보하는 방향으로 나아가고 있습니다. 클라우드 네이티브 아키텍처, 오픈랜(Open RAN)과 같은 개방형 인터페이스, AI 기반의 자율 운영, 에너지 효율성 극대화 등이 주요 기술 트렌드가 될 것입니다.","52-기술적-난제-극복-및-지속-가능한-발전을-위한-컴퓨터공학도의-역할과-제언#5.2. 기술적 난제 극복 및 지속 가능한 발전을 위한 컴퓨터공학도의 역할과 제언":"5G 및 6G 기술이 가져올 혁신적인 미래는 매우 기대되지만, 동시에 해결해야 할 기술적 난제와 사회적 고려 사항도 산적해 있습니다. 이러한 과제를 극복하고 지속 가능한 기술 발전을 이루기 위해 컴퓨터공학도로서 다음과 같은 역할과 노력이 필요하다고 생각합니다.\n5.2.1. 보안 및 프라이버시 강화 기술 개발의 중요성:\n의견: 초연결, 초지능화된 네트워크 환경에서는 보안과 프라이버시가 기술의 성패를 좌우하는 가장 중요한 요소 중 하나가 될 것입니다. 단순히 기능 구현에 그치지 않고, 설계 단계부터 보안(Security by Design)과 프라이버시(Privacy by Design)를 핵심 원칙으로 고려해야 합니다. 기술적 제언: 차세대 암호 기술 연구: 양자컴퓨팅 시대에도 안전한 양자내성암호(PQC), 동형암호, 영지식증명 등 첨단 암호 기술을 네트워크 프로토콜 및 서비스에 적극적으로 적용해야 합니다. AI 기반 보안 위협 탐지 및 대응 시스템 고도화: 네트워크 트래픽, 시스템 로그 등을 AI로 분석하여 알려지지 않은 공격(Zero-day attack)이나 지능형 지속 위협(APT)을 실시간으로 탐지하고 자동 대응하는 기술 개발이 중요합니다. 프라이버시 강화 기술(PET) 적용 확대: 데이터 수집 및 활용 과정에서 개인정보를 보호하기 위해 연합 학습, 차등 프라이버시, 안전한 다자간 계산(Secure Multi-Party Computation) 등의 기술을 실제 서비스에 효과적으로 통합하는 연구가 필요합니다. 5.2.2. 에너지 효율적인 네트워크 및 단말 기술 연구:\n의견: 6G의 성능 목표를 달성하기 위한 기술들은 자칫 엄청난 에너지 소비를 초래할 수 있습니다. 이는 환경 문제뿐만 아니라 네트워크 운영 비용 증가로 이어져 기술 보급의 장벽이 될 수 있습니다. 따라서 성능 향상과 동시에 에너지 효율을 극대화하는 것은 기술적 성숙도를 판단하는 중요한 기준이 될 것입니다. 기술적 제언: 저전력 반도체 및 RF 부품 개발: THz 대역 통신, Massive MIMO 등을 지원하면서도 에너지 효율이 높은 반도체 및 RF 부품 기술 개발에 집중해야 합니다. AI 기반 지능형 전력 관리: 트래픽 상황, 사용자 요구 등을 AI로 예측하여 기지국, 네트워크 장비, 단말기의 전력 소모를 동적으로 최적화하는 기술을 개발해야 합니다. (예: 특정 시간대나 지역의 트래픽이 적을 경우 일부 셀을 슬립 모드로 전환) 에너지 효율적인 네트워크 아키텍처 및 프로토콜 설계: 데이터 전송 경로 최적화, 불필요한 신호 송수신 최소화 등 에너지 효율을 고려한 네트워크 아키텍처 및 통신 프로토콜 연구가 필요합니다. 5.2.3. 개방형 표준 및 오픈소스 생태계 활성화를 통한 기술 혁신 가속화:\n의견: 과거 이동통신 기술은 특정 대기업 중심의 폐쇄적인 기술 개발 경향이 있었습니다. 그러나 5G부터 오픈랜(O-RAN) 등의 논의가 활발해졌으며, 6G에서는 이러한 개방성이 더욱 중요해질 것입니다. 개방형 표준과 오픈소스는 다양한 아이디어의 접목을 촉진하고, 중소기업 및 스타트업의 참여를 확대하여 기술 혁신을 가속화하며, 특정 벤더에 대한 종속성을 줄일 수 있습니다. 기술적 제언: 오픈랜 및 개방형 인터페이스 표준화 적극 참여 및 기여: 국제 표준화 단체 활동에 적극적으로 참여하고, 국내 기술이 표준에 반영될 수 있도록 노력해야 합니다. 오픈소스 소프트웨어 개발 및 커뮤니티 활성화: 6G 네트워크 기능, AI 모델, 관리 도구 등을 오픈소스로 공개하고, 국내외 개발자 커뮤니티와의 협력을 통해 생태계를 확장해야 합니다. 모듈화된 소프트웨어 아키텍처 설계: 네트워크 기능을 모듈화하고 표준 API를 통해 연동함으로써 다양한 솔루션의 조합과 빠른 서비스 개발을 지원해야 합니다. 5.2.4. AI 기술의 책임감 있는 활용 및 통제 방안 연구 (네트워크 오작동 방지 등):\n의견: 6G는 AI가 네트워크 전반에 깊숙이 통합되는 “AI-Native Network\"를 지향합니다. AI는 네트워크 효율성과 자율성을 크게 향상시키지만, 동시에 AI 모델의 편향성, 예측 불가능성, 오작동 가능성 등 새로운 위험 요소도 내포하고 있습니다. 따라서 AI 기술의 책임감 있는 활용과 통제 방안 마련이 필수적입니다. 기술적 제언: 설명 가능한 AI(XAI) 기술 적용: 네트워크 운영에 사용되는 AI 모델의 의사결정 과정을 인간이 이해할 수 있도록 설명 가능성을 확보하여, 문제 발생 시 원인 분석 및 해결을 용이하게 해야 합니다. AI 모델의 견고성(Robustness) 및 안전성 검증 기술 개발: AI 모델이 예기치 않은 입력이나 악의적인 공격에도 안정적으로 동작하고, 심각한 네트워크 장애를 유발하지 않도록 검증하는 기술이 필요합니다. 인간 통제(Human-in-the-loop) 시스템 설계: 완전 자율 운영을 지향하더라도, 중요한 결정이나 비상 상황에서는 인간 운영자가 개입하여 통제할 수 있는 안전장치를 마련해야 합니다. 컴퓨터공학도로서 우리는 이러한 기술적 과제 해결에 적극적으로 참여하고, 끊임없는 학습과 연구를 통해 5G와 6G 기술이 인류 사회에 긍정적으로 기여할 수 있도록 노력해야 할 것입니다. 기술의 발전은 결국 인간을 위한 것이어야 하며, 그 과정에서 발생할 수 있는 문제점들을 예측하고 선제적으로 대응하는 자세가 중요하다고 생각합니다.","5g와-6g-네트워크-통신-기술-현재와-미래-그리고-우리-삶에-미칠-영향#5G와 6G 네트워크 통신 기술: 현재와 미래, 그리고 우리 삶에 미칠 영향":"","6-참고문헌#6. 참고문헌":"본 보고서는 일반적인 5G 및 6G 기술 동향과 전망에 대한 공개된 자료(학술 논문, 기술 백서, 전문 기사, 국제 표준화 기구 문서 등)를 종합하여 작성되었으며, 특정 문서를 직접 인용하지는 않았습니다. 실제 보고서 작성 시에는 구체적인 출처를 명시해야 합니다. 제공해주신 “James F. Kurose_ Keith W. Ross - Computer Networking_ A Top-down Approach-Pearson (2020).pdf” 파일은 네트워크의 계층적 구조, 링크 계층, LAN 기술 등에 대한 포괄적인 내용을 담고 있어, 5G/6G의 하부 네트워크 인프라 및 프로토콜을 이해하는 데 배경 지식으로 참고할 수 있습니다. 특히, 데이터센터 네트워킹, 이더넷 기술, MAC 주소 및 ARP, 스위치 및 VLAN 등의 내용은 5G/6G 네트워크가 구축되고 운영되는 물리적, 논리적 환경을 이해하는 데 도움이 됩니다. 다만, 해당 PDF는 5G/6G 기술 자체를 직접적으로 다루고 있지는 않아 본 보고서의 핵심 내용에 대한 직접적인 인용은 제한적입니다. 알겠습니다. 제공해주신 “Chapter_5_v8.0-NetworkLayer_ControlPlane수정.pptx” 자료를 기반으로 5G 및 6G 네트워크 통신 기술, 특히 네트워크 제어 평면(Control Plane) 에 초점을 맞춰 범위를 좁히고 각 개별 기술에 대해 더 깊이 있는 분석을 제공하는 보고서를 작성하겠습니다.\n먼저, PPT 내용을 반영하여 새롭게 구성한 목차를 제안 드립니다. 이 목차는 전통적인 제어 평면 기술부터 SDN, 네트워크 관리 자동화 기술(NETCONF/YANG)이 5G/6G 환경에서 어떻게 적용되고 발전하는지에 대한 심층적인 내용을 다룰 것입니다.","목차#목차":"서론 1.1. 차세대 이동통신 기술의 등장 배경 및 기술적 요구사항\n1.2. 연구의 목적 및 기술적 범위 정의\n5G 네트워크 통신 기술 분석 2.1. 5G의 핵심 성능 지표(KPI) 및 표준화 동향 (3GPP 릴리즈 기반)\n2.2. 5G 핵심 기술 요소 상세 분석\n2.2.1. 새로운 무선 접속 기술 (NR: New Radio)\n2.2.1.1. 주파수 대역 확장 (Sub-6GHz, mmWave) 및 특성\n2.2.1.2. Massive MIMO (Multiple-Input Multiple-Output) 및 빔포밍\n2.2.1.3. 유연한 프레임 구조 및 OFDM 변형 기술 (예: CP-OFDM, DFT-s-OFDM)\n2.2.1.4. 고급 채널 코딩 (LDPC, Polar Codes)\n2.2.2. 5G 코어 네트워크 (5GC) 아키텍처\n2.2.2.1. 서비스 기반 아키텍처 (SBA: Service-Based Architecture)\n2.2.2.2. 네트워크 슬라이싱 (Network Slicing)\n2.2.2.3. 모바일 엣지 컴퓨팅 (MEC: Multi-access Edge Computing)\n2.2.2.4. NFV (Network Functions Virtualization) 및 SDN (Software-Defined Networking) 적용\n2.3. 5G 주요 서비스 시나리오별 기술적 요구사항\n2.3.1. eMBB (Enhanced Mobile Broadband): 고대역폭, 고속 데이터 전송\n2.3.2. URLLC (Ultra-Reliable Low Latency Communications): 고신뢰성, 저지연 통신\n2.3.3. mMTC (Massive Machine Type Communications): 대규모 디바이스 연결\n2.4. 5G 상용화 현황 및 기술적 과제 (예: 커버리지, 장비 호환성, 간섭 문제)\n6G 네트워크 통신 기술 전망 3.1. 6G 비전 및 주요 성능 목표 (5G 대비 향상점 중심)\n3.2. 6G 예상 핵심 기술 후보군 및 연구 동향\n3.2.1. 테라헤르츠(THz) 및 서브-THz 대역 통신 기술\n3.2.2. AI/ML 기반 네트워크 지능화 및 자동화 (예: AI 기반 RAN, 코어망 운영)\n3.2.3. 공간 통신 기술 (예: 위성 통합, 무인항공기(UAV) 활용, Reconfigurable Intelligent Surfaces - RIS)\n3.2.4. 네트워크-컴퓨팅-센싱 융합 (예: ISAC - Integrated Sensing and Communication)\n3.2.5. 차세대 코어 네트워크 및 아키텍처 (예: 분산형 AI, 양자 통신 연동 가능성)\n3.2.6. 고정밀 측위 및 동기화 기술\n3.3. 6G 기술의 표준화 로드맵 및 기술적 난제\n5G 및 6G 기술의 기술적 파급 효과 및 영향 분석 4.1. 긍정적 영향 (기술적 구현 가능성 및 새로운 서비스 창출 중심)\n4.1.1. 실생활 변화: 기술적 진보가 가져올 구체적 서비스 변화\n4.1.1.1. 완전 몰입형 XR (확장현실) 서비스: 초고대역폭, 초저지연 통신 기반\n4.1.1.2. 홀로그래픽 통신: 대용량 데이터 실시간 전송 및 처리\n4.1.1.3. 디지털 트윈 및 사이버 물리 시스템(CPS) 고도화: 정밀 센싱, 실시간 제어\n4.1.1.4. 브레인-컴퓨터 인터페이스(BCI) 연동 가능성 (장기적 관점)\n4.1.2. 사회 인프라 변화: 지능형 인프라 구축 및 운영 효율화\n4.1.2.1. 자율주행 네트워크 및 지능형 교통 시스템 (ITS)의 완전 자율화\n4.1.2.2. 원격 로봇 수술 및 정밀 의료 서비스 확대\n4.1.2.3. 스마트 시티 운영 시스템의 실시간 최적화\n4.1.3. 경제/산업 구조 변화: 기술 기반 신산업 및 생산 방식 혁신\n4.1.3.1. 산업용 IoT(IIoT) 및 스마트 팩토리의 초지능화\n4.1.3.2. UAM(도심항공교통) 등 신규 모빌리티 산업 지원 인프라\n4.1.3.3. 데이터 중심 경제 가속화 및 AI 기반 서비스 확산\n4.2. 부정적 영향 및 기술적 해결 과제 (보안, 프라이버시, 에너지 효율 등)\n4.2.1. 기술적 문제점 및 우려\n4.2.1.1. 보안 취약성 증대: 연결성 확장 및 복잡도 증가로 인한 공격 표면 확대\n4.2.1.2. 프라이버시 침해 가능성: 방대한 데이터 수집 및 AI 분석에 따른 위험\n4.2.1.3. 네트워크 및 단말기의 에너지 소비 증가 문제: 고성능화에 따른 전력 효율성 확보 과제\n4.2.1.4. 전파 인체 유해성 논란 (특히 고주파 대역) 및 기술적 검증 필요성\n4.2.1.5. 기술 구현의 복잡성 및 상호 운용성 확보 문제\n4.2.2. 사회·경제적 문제점 (기술적 관점에서 파생되는 문제)\n4.2.2.1. 기술 격차 (Digital Divide) 심화: 고도화된 기술 접근성 불평등\n4.2.2.2. 고용 구조 변화 가속화: 자동화 및 AI 대체에 따른 일자리 문제\n4.2.2.3. 인프라 투자 비용 및 유지보수 부담 증가\n결론: 기술적 과제와 미래 전망 (본인 의견 포함) 5.1. 5G 및 6G 기술의 핵심적 의의 및 기술 발전 방향 요약\n5.2. 기술적 난제 극복 및 지속 가능한 발전을 위한 컴퓨터공학도의 역할과 제언\n5.2.1. 보안 및 프라이버시 강화 기술 개발의 중요성 (예: 차세대 암호 기술, 연합 학습 등)\n5.2.2. 에너지 효율적인 네트워크 및 단말 기술 연구\n5.2.3. 개방형 표준 및 오픈소스 생태계 활성화를 통한 기술 혁신 가속화\n5.2.4. AI 기술의 책임감 있는 활용 및 통제 방안 연구 (네트워크 오작동 방지 등)\n6. 참고문헌\n이제 각 목차 항목에 대한 내용을 기술 중심으로 작성해 드리겠습니다.","목차-ppt-내용-기반-심층-분석안#목차 (PPT 내용 기반 심층 분석안)":"서론 1.1. 5G/6G 시대, 네트워크 제어 평면의 혁신과 그 중요성\n1.1.1. 다양한 서비스 요구사항(eMBB, URLLC, mMTC)과 제어 평면의 역할\n1.1.2. 네트워크 유연성, 자동화, 지능화를 위한 제어 평면 기술의 필요성\n1.2. 연구 목적 및 범위\n1.2.1. PPT “Network Layer: Control Plane” 핵심 기술 심층 분석\n1.2.2. 분석된 기술의 5G/6G 적용 방안 및 심화된 기술적 고찰\n네트워크 제어 평면의 구성 원리 및 핵심 프로토콜 (PPT 내용 심층 탐구) 2.1. 제어 평면의 두 가지 접근 방식: 전통적 방식 vs. SDN\n2.1.1. 라우터별 제어 (Per-router control) 방식 분석 (PPT p-6)\n2.1.2. 논리적 중앙 집중형 제어 (Logically centralized control - SDN) 방식 분석 (PPT p-6)\n2.2. 라우팅 알고리즘 심층 분석 (PPT p-40)\n2.2.1. 라우팅 알고리즘의 목표 및 분류 (PPT p-9)\n2.2.2. 링크 상태 (Link State, LS) 라우팅 알고리즘 (PPT p-20)\n2.2.2.1. 다익스트라 (Dijkstra) 알고리즘 상세 분석 및 예제\n2.2.2.2. LS 알고리즘의 메시지 복잡도 및 특성\n2.2.3. 거리 벡터 (Distance Vector, DV) 라우팅 알고리즘 (PPT p-31)\n2.2.3.1. 벨만-포드 (Bellman-Ford) 방정식 및 알고리즘 상세 분석\n2.2.3.2. DV 알고리즘의 문제점 (라우팅 루프, Count-to-infinity) 및 해결책 (포이즌 리버스)\n2.2.4. LS vs. DV 비교 분석 (PPT p)\n2.2.5. 계층적 라우팅 (Hierarchical Routing)의 필요성 및 개념 (PPT p-35)\n2.3. 인터넷에서의 라우팅 프로토콜: 실제 구현 사례 (PPT p-71)\n2.3.1. 자율 시스템 (Autonomous Systems, AS) 내부 라우팅: OSPF (PPT p-52)\n2.3.1.1. OSPF의 특징 (개방형, LS 기반, 계층 구조 지원 등)\n2.3.1.2. OSPF 동작 방식 및 보안 (인증)\n2.3.2. 자율 시스템 간 라우팅: BGP (PPT p-70)\n2.3.2.1. BGP의 역할 및 기본 동작 (eBGP, iBGP)\n2.3.2.2. 경로 속성(Path attributes) 및 경로 선택 정책\n2.3.2.3. BGP 라우팅 정책의 중요성 및 예시\n2.3.3. 왜 내부/외부 라우팅 프로토콜을 분리하는가? (PPT p)\n소프트웨어 정의 네트워킹(SDN)과 5G/6G 제어 평면 (PPT p-92) 3.1. SDN의 핵심 개념 및 아키텍처 (PPT p-78)\n3.1.1. 제어 평면과 데이터 평면의 분리\n3.1.2. 데이터 평면 스위치 (플로우 테이블 기반 포워딩)\n3.1.3. SDN 컨트롤러 (네트워크 OS) 의 역할 및 기능\n3.1.4. 제어 평면 API (Northbound) 및 데이터 평면 API (Southbound - 예: OpenFlow)\n3.2. OpenFlow 프로토콜 심층 분석 (PPT p-83 내외 OpenFlow 관련 내용)\n3.2.1. 플로우 테이블 항목 (매치 필드, 액션, 카운터 등)\n3.2.2. OpenFlow 메시지 유형 (컨트롤러-스위치 간)\n3.3. SDN 컨트롤러 실제 사례 (PPT p ODL, ONOS 등 언급)\n3.4. 5G/6G 네트워크에서의 SDN 적용 심화\n3.4.1. 5G SBA(Service Based Architecture)와 SDN의 연관성 분석\n3.4.2. 네트워크 슬라이싱(Network Slicing) 구현을 위한 SDN의 역할 상세 분석\n3.4.3. MEC(Multi-access Edge Computing) 트래픽 관리 및 자원 할당에서의 SDN 활용\n네트워크 관리 및 자동화와 5G/6G 제어 평면 (PPT p-98) 4.1. ICMP (Internet Control Message Protocol) (PPT p-94)\n4.1.1. ICMP 메시지 유형 (오류 보고, 질의) 및 기능\n4.1.2. Traceroute 프로그램에서의 ICMP 활용 예시\n4.1.3. 5G/6G 네트워크 진단 및 모니터링에서의 ICMP 활용 방안\n4.2. 네트워크 관리 프레임워크 개요 (PPT p)\n4.3. 차세대 네트워크 설정 및 관리: NETCONF와 YANG (PPT p-98)\n4.3.1. NETCONF 프로토콜 심층 분석 (PPT p)\n4.3.1.1. 목표 및 동작 원리 (RPC 기반)\n4.3.1.2. 주요 오퍼레이션 (, 등) 및 XML 기반 메시지 구조\n4.3.2. YANG 데이터 모델링 언어 심층 분석 (PPT p)\n4.3.2.1. YANG의 역할 및 특징 (데이터 구조, 구문, 의미론 정의)\n4.3.2.2. YANG 모듈 구조 및 주요 키워드 (container, list, leaf 등)\n4.3.2.3. 데이터 제약 조건 표현 및 유효성 검증\n4.3.3. 5G/6G 네트워크 자동화 및 오케스트레이션에서의 NETCONF/YANG 활용\n4.3.3.1. 가상화된 네트워크 기능(VNF) 및 네트워크 슬라이스 설정 자동화\n4.3.3.2. 제로 터치 프로비저닝(Zero Touch Provisioning) 구현\n5G/6G 제어 평면 기술의 영향, 과제 및 미래 전망 5.1. 제어 평면 기술 혁신이 가져올 기술적 파급 효과\n5.1.1. 네트워크 프로그래머빌리티 향상 및 서비스 민첩성 증대\n5.1.2. 자원 효율성 극대화 및 운영 비용 절감\n5.1.3. 지능형 네트워크 서비스 및 맞춤형 네트워크 제공 능력 강화\n5.2. 기술적 과제 및 심층적 해결 방안\n5.2.1. 중앙 집중형 제어의 확장성, 성능, 안정성 확보 문제 (SDN 컨트롤러)\n5.2.2. 제어 평면 보안 위협 (DDoS 공격, 설정 오류를 통한 네트워크 마비 등) 및 능동적 방어 전략\n5.2.3. 다양한 벤더 장비 및 기술 간 상호 운용성 확보의 어려움\n5.2.4. 6G를 향한 제어 평면의 지능화: AI/ML 통합 시 고려사항 (데이터, 알고리즘, 신뢰성)\n5.3. 결론: 미래 제어 평면 기술 발전을 위한 컴퓨터공학도의 심층적 역할 (본인 의견 포함)\n5.3.1. 개방형 인터페이스 및 표준화 기여를 통한 생태계 확장\n5.3.2. 고신뢰/고성능 제어 알고리즘 및 AI 모델 개발\n5.3.3. End-to-End 네트워크 슬라이싱 및 자동화 기술 심화 연구\n참고자료 6.1. 제공된 PPT: Chapter_5_v8.0-NetworkLayer_ControlPlane수정.pptx\n6.2. (필요시 추가 문헌)\n위 목차를 바탕으로 각 항목에 대한 심층적인 기술 분석 보고서를 작성해 드리겠습니다. PPT의 슬라이드 번호를 일부 명시하여 내용의 근거를 찾기 쉽도록 하였습니다. 다음 단계로 첫 번째 항목인 “1. 서론\"부터 내용을 전개해 나가겠습니다. 원하시면 특정 부분부터 시작할 수도 있습니다.\n알겠습니다. 사용자의 요청에 맞춰 기술적인 깊이를 약간 조절하고, 실생활, 사회, 경제적 영향에 대한 내용을 더 보강하여 목차를 수정했습니다. PPT 슬라이드 번호는 본문 내용 작성 시에는 생략하도록 하겠습니다.\n수정된 목차를 바탕으로 보고서 작성을 시작하겠습니다.","목차-수정안#목차 (수정안)":"서론 1.1. 5G를 넘어 6G로: 차세대 네트워크의 비전과 사회 변화의 기대감\n1.2. 연구의 목적: 5G/6G 핵심 기술 이해와 실생활, 사회, 경제적 영향 다각적 분석\n1.3. 보고서의 구성 및 범위 (제어 평면 기술을 포함한 핵심 기술과 그 파급 효과 중심)\n5G 및 6G 네트워크의 핵심 기술과 제어 평면의 진화 2.1. 5G 네트워크의 주요 특징과 서비스 시나리오\n2.1.1. 초고속(eMBB), 초저지연(URLLC), 초연결(mMTC)의 기술적 기반 개요\n2.1.2. 서비스 기반 아키텍처(SBA) 및 네트워크 슬라이싱의 개념과 중요성\n2.2. 6G 네트워크의 지향점과 예상 핵심 기술\n2.2.1. 5G 성능의 확장과 새로운 차원 (AI 통합, 센싱 융합, THz 통신 등)\n2.3. 지능적이고 유연한 네트워크를 위한 제어 평면의 역할 (네트워크 제어 평면 PPT 핵심 내용 연계)\n2.3.1. 전통적 라우팅에서 SDN(소프트웨어 정의 네트워킹)으로의 전환의 의미\n2.3.1.1. SDN의 기본 원리: 제어부-데이터부 분리와 중앙 집중형 제어를 통한 네트워크 유연성 확보\n2.3.1.2. 5G/6G에서 SDN을 활용한 네트워크 프로그래밍, 동적 자원 할당 및 서비스 맞춤화\n2.3.2. 네트워크 관리 자동화: NETCONF/YANG 프로토콜의 역할과 중요성\n2.3.2.1. 복잡다단한 5G/6G 네트워크의 효율적 설정, 모니터링 및 관리 자동화의 필요성\n2.3.2.2. NETCONF/YANG을 통한 자동화된 오케스트레이션, 신속한 서비스 배포 및 제로터치 운영 가능성\n5G 및 6G 기술이 실생활, 사회, 경제에 미치는 영향 (긍정적 및 부정적 측면) 3.1. 우리들의 실생활 변화\n3.1.1. 긍정적 영향:\n3.1.1.1. 현실과 가상을 넘나드는 몰입형 엔터테인먼트 및 초실감형 소통 (XR, 홀로그램, 메타버스 등)\n3.1.1.2. 생활 편의를 극대화하는 개인 맞춤형 스마트 환경 (지능형 스마트 홈, 실시간 원격 헬스케어, AI 기반 맞춤형 교육)\n3.1.1.3. 시공간의 제약을 허무는 이동성의 혁신 (완전 자율주행차 상용화, 도심항공교통(UAM)의 대중화 기반 마련)\n3.1.2. 부정적 영향:\n3.1.2.1. 디지털 정보 격차 심화 및 새로운 형태의 정보 소외 계층 발생 가능성\n3.1.2.2. 개인 식별 정보 및 생체 정보 등 민감 데이터의 프라이버시 침해 및 오용 우려 증가\n3.1.2.3. 과도한 기술 의존으로 인한 사회성 약화 및 사이버 중독, 디지털 피로감 확산\n3.2. 사회 구조 및 기능 변화\n3.2.1. 긍정적 영향:\n3.2.1.1. 도시 전체가 유기적으로 연결되는 지능형 도시(스마트 시티) 구현 가속화 및 도시 문제 해결 기여\n3.2.1.2. 원격 근무 및 분산형 교육 시스템 보편화, 일과 삶의 균형 및 교육 기회 확대\n3.2.1.3. AI와 빅데이터 기반의 재난안전 시스템 고도화 및 국민 생활 안전망 강화\n3.2.2. 부정적 영향:\n3.2.2.1. AI 및 로봇 기술 발전으로 인한 특정 직군의 자동화 가속화, 일자리 구조 변화 및 고용 불안정 심화\n3.2.2.2. 사이버 공격, 가짜 정보(딥페이크 등) 유포 등 기술 악용 범죄의 지능화·고도화로 인한 사회 혼란 야기\n3.2.2.3. 개인의 모든 활동이 데이터화되면서 발생하는 감시 사회에 대한 우려 증폭 및 통제 강화 가능성\n3.3. 경제 구조 및 산업 발전 변화\n3.3.1. 긍정적 영향:\n3.3.1.1. 메타버스, 인공지능 서비스, 실감형 콘텐츠 등 새로운 디지털 산업 창출 및 국가 성장 동력 확보\n3.3.1.2. 전통 산업(제조, 의료, 농업, 물류 등)의 디지털 전환 가속화 및 생산성 혁신 (스마트 팩토리, 원격 정밀 의료, 스마트팜, 지능형 물류 시스템)\n3.3.1.3. 데이터 기반 경제 활성화 및 전 산업의 서비스화 촉진, 글로벌 경쟁력 강화\n3.3.2. 부정적 영향:\n3.3.2.1. 전국적인 5G/6G 인프라 구축 및 유지보수에 요구되는 막대한 초기 투자 비용과 재원 확보 문제\n3.3.2.2. 핵심 기술 및 장비의 해외 의존도 심화 시 국가 산업 경쟁력 약화 및 기술 종속 우려\n3.3.2.3. 소수의 거대 플랫폼 기업에 의한 시장 독과점 심화 및 불공정 경쟁 문제 발생 가능성\n5G/6G 시대의 바람직한 미래를 위한 제언 (본인 의견 중심) 4.1. 기술 발전과 사회적 가치의 조화로운 추구\n4.1.1. 포용적 기술 발전 전략: 디지털 접근성 강화 및 정보 격차 해소를 위한 정책적 노력\n4.1.2. 신뢰할 수 있는 디지털 환경 구축: 강력한 개인정보보호 및 사이버 보안 시스템 마련, 기술 윤리 확립\n4.1.3. 지속 가능한 발전 지향: 차세대 네트워크의 에너지 효율성 극대화 및 환경 영향 최소화 노력\n4.2. 미래 사회 변화에 대한 능동적이고 선제적인 대응\n4.2.1. 창의적 융합 인재 양성을 위한 교육 시스템 혁신 및 평생 학습 체계 구축\n4.2.2. 기술 발전에 따른 법제도 정비 및 새로운 사회적 규범과 윤리적 가이드라인 확립\n4.2.3. 기술의 혜택이 사회 전체에 공정하게 공유될 수 있도록 사회적 합의 도출 및 공동체적 노력 강화\n결론 5.1. 5G/6G 기술의 핵심적 가치와 무한한 잠재력 요약\n5.2. 기술이 주도하는 미래 사회의 희망과 우려, 그리고 우리의 능동적 준비 자세 강조"},"title":"무제"},"/06.university/network/3%EC%9E%A5-%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%ED%8A%B8-%EA%B3%84%EC%B8%B5-transport/":{"data":{"":"packet 이름 : segment\nudp 의 패킷을 특수하게 네트워크 계층에서 사용하는 패킷의 이름인 datagram 이라는 이름을 사용할 때도 있다\n개괄 udp, tcp 공통 기능\n프로세스대 프로세드 데이터 전달(multiplexing, demultiplexing) 오류 검출(check sum) tcp 특수 기능\n신뢰적인 데이터 전송 흐름제어 순서번호 확인응답 타이머 혼잡제어 프로세스대 프로세드 데이터 트랜스포트 계층 다중화, 역 다중화 : 호스트대 호스트 전달을 프로세스대 프로세스 전달로 확장하는 과정\n네트워크 소켓의 식별자 포멧\ntransport -\u003e socket (-\u003e application(process)) : depmultiplexing 적절한 소켓으로 데이터를 전송 : 분리하는 과정 socket -\u003e transport (-\u003e network) : multiplexing 소켓으로 부터 받은 데이터를 패킷화(segment) 해서 아래 계층으로 보낸다 udp 식별자\nsource port destination port 상황 : udp 소켓 19157을 가진 호스트 A 의 프로세스가 호스트 B 의 UDP 소켓 46428을 가진 프로세스에게 애플리케이션 데이터 전송을 원한다고 가정하자.\n호스트 A 의 트랜스포트 계층은 애츨리케이션 데이터, 출발지 포트 번호(19157), 목적지 포트번호(46428), 그리고 2개의 다른값 #ModificationRequired 을 포함하는 트랜스포트계층 세그먼트를 생성한다. 트랜스포트 계층은 만들어진 세그먼트를 네트워크 계층으로 전달한다. 네트워크 계층은 세그먼트를 IP 데이터그램으로 캡술화하고 best-effort 서비스로 수신 호스트로 전달한다. … 이동중 … 수신호스트에서 네트워크 계층에서 받은 segment는 트랜스포트계층에서 목적지 포트번호 46428을 검사하고 그 세그먼트를 포트 46428로 식별되는 소켓에 전달한다\n호스트 A의 소켓: (A의 IP 주소, 19157) 호스트 B의 소켓: (B의 IP 주소, 46428) checksum 헤더의 checksum 필드는은 16비트로 이루어져있음\n송신자는 data의 모든 16비트 워드의 합산에 대해 다시 1의 보수를 수행해서 checksum 에 넣는다 합산시에는 윤회식 합산(wrap around)를 수행한다\n수신자는 data의 모든 16비트 워드합산과 checksum 을 합치면 1111111111111111 이 나오면 오류가 없다고 판단한다(0이 한개라도 있으면 오류가 발생했다고 판단한다)\n신뢰적인 data전송 rdt 1.0 완벽하게 신뢰적인 채널 상에서의 데이터 전송\n비트오류 없음 패킷로스가 없음 rdt 2.0 (전송 후 대기 stop-and-wait) 비트 오류가 있는 채널상에서의 신뢰적인 데이터 전송\n패킷로스가 없음 필요기능\n오류검출 수신자 피드백 재전송 긍정확인응답(ACK), 부정확인응답(NAK)\n만약 ack, nak 응답자체가 훼손되었을 경우는 어떻게 하는가?\nrdt 2.1 체크섬(checksum) 비트를 충분히 추가하여 송신자가 수신된 패킷의 오류를 검출할 뿐만 아니라, 오류를 직접 수정할 수 있도록 합니다. 송신자는 ack, nak 를 받지 않는 모든 패킷을 재전송 한다 중복 패킷 처리 문제 수신자는 ACK 또는 NAK가중복된 데이터 패킷이 도착할 가능성이 있습니다. 데이터 패킷에 새로운 필드를 추가하고 필드안에 순서번호(sequence number)를 삽입하는 방식으로 데이터 패킷에 송신자가 번호를 붙이는 것이다 1개의 비트 즉 2개의 상태번호만 있으면 된다\n2.0 상태에서 2배 크기의 fsm 이다 sequence number 개수로 인해\nnak 대신 이전패킷의 비정상 수신의 ack 를 보내도 되지 않을까? nak 대신 last recived ok\nrdt 2.2 ack 자체에 순서번호(sequence number)를 포함해서 보내도록 하고 nak 는 필요없다\nrdt3.0 (alternating-bit protocol) 비트 오류와 패킷로스가 있는 채널상에서의 신뢰적인 데이터 전송\nrdt3.0 송신자 측에서 (오류 발생이나 이전 패킷에) 대한 ack 가 발생하면 바로 재전송하지 않고 timeout 까지 기다리고 그렇게 하는 이유가 2번 연속으로 보내는 경우가 발생할 수 있다 인데 이것의 예시가 떠오르지 않아 질문드립니다\npipelining 필요기능 :\nsequence number 의 범위가 커져야 한다\n프로토콜의 송신측과 수신측은 패킷 1개 이상을 버퍼링 해야 한다\nL (Packet Size) : 패킷의 크기(packet size)\nR (Transmission Rate) : 송신 속도 (1Gbps)\nRTT (Round-Trip Time) : 데이터 패킷이 발신자에서 수신자로 전달된 후, ACK가 다시 발신자에게 돌아오는 데 걸리는 전체 왕복 시간\nGBN (go back N) 특정 조건에서 송신자가 이미 전송한 여러 패킷(N개)을 다시 전송해야 하는 특징 Selective Repeat (SR) 손실된 패킷만 재전송하는 특징\n🔄 1. GBN vs SR: 개요 요약 항목 Go-Back-N (GBN) Selective Repeat (SR) ACK 방식 누적적 ACK (Cumulative ACK) 개별 ACK 패킷 재전송 타임아웃된 패킷부터 window 내 모든 패킷 재전송 오직 손실/에러 난 패킷만 재전송 Receiver 버퍼링 불필요 (out-of-order 패킷 모두 폐기) 필요 (out-of-order 패킷 저장 후 순서 정렬) Window 크기 제한 N (window size) 최대 2^k-1 / 2 (sequence number space 절반) 🧱 2. 시나리오 설정 (공통) 최대 SEQ 번호: 7 (즉, k=3 bits) Window Size (N): 4 전송해야 할 패킷: pkt0, pkt1, pkt2, pkt3, pkt4, pkt5 pkt2 유실 ACK 수신 순서: ACK0, ACK1, ACK2 지연됨 → timeout 발생 🟩 3. Go-Back-N (GBN) 시뮬레이션","-1-gbn-vs-sr-개요-요약#🔄 \u003cstrong\u003e1. GBN vs SR: 개요 요약\u003c/strong\u003e":"","-2-시나리오-설정-공통#🧱 \u003cstrong\u003e2. 시나리오 설정 (공통)\u003c/strong\u003e":"","-3-go-back-n-gbn-시뮬레이션#🟩 \u003cstrong\u003e3. Go-Back-N (GBN) 시뮬레이션\u003c/strong\u003e":"","-4-selective-repeat-sr-시뮬레이션#🟦 \u003cstrong\u003e4. Selective Repeat (SR) 시뮬레이션\u003c/strong\u003e":"","-5-주요-비교-요약#📊 \u003cstrong\u003e5. 주요 비교 요약\u003c/strong\u003e":"항목 Go-Back-N Selective Repeat ACK 종류 누적 ACK 개별 ACK 재전송 범위 window 내 전체 손실된 패킷만 Receiver 버퍼 필요 없음 필요함 채널 효율성 packet error 많으면 낮음 packet error 많아도 높음 복잡도 낮음 높음 사용 예 UDP 기반 간단한 RDT TCP (유사 구조)","-receiver-측#❌ \u003cstrong\u003eReceiver 측\u003c/strong\u003e":"수신 패킷 expectedseqnum 결과 ACK 전송 pkt0 0 in-order ACK0 pkt1 1 in-order ACK1 pkt3 2 out-of-order ACK1 재전송 pkt4 2 out-of-order ACK1 재전송 pkt5 2 out-of-order ACK1 재전송 pkt2 2 in-order (마침내) ACK2 전송 pkt3 3 in-order ACK3 전송 pkt4 4 in-order ACK4 전송 pkt5 5 in-order ACK5 전송 ⚠️ GBN Receiver: 잘못된 순서의 패킷은 무시하고 마지막으로 받은 in-order 패킷에 대한 ACK 계속 송신.","-receiver-측-1#✅ \u003cstrong\u003eReceiver 측\u003c/strong\u003e":"수신 패킷 expectedseqnum 결과 ACK 전송 버퍼 내용 pkt0 0 in-order ACK0 - pkt1 1 in-order ACK1 - pkt3 2 out-of-order ACK3 pkt3 save pkt4 2 out-of-order ACK4 pkt4 save pkt5 2 out-of-order ACK5 pkt5 save pkt2 2 in-order ACK2 pkt3, pkt4, pkt5 deliver 가능 (after ACK2) 6 - - buffer empty 💡 SR Receiver: out-of-order 패킷을 버퍼링하여 순서 복구 후 일괄 전달 (in-order delivery)","-sender-측#✅ \u003cstrong\u003eSender 측\u003c/strong\u003e":"Event Window (base ~ nextseqnum - 1) Sent Packets Status Notes 초기 상태 [0, 0] 없음 대기 base = 0, nextseqnum = 0 rdt_send(data0) [0, 0] → [0, 0] pkt0 보냄 전송 nextseqnum = 1 rdt_send(data1) [0, 1] pkt1 보냄 전송 nextseqnum = 2 rdt_send(data2) [0, 2] pkt2 보냄 전송 nextseqnum = 3 rdt_send(data3) [0, 3] pkt3 보냄 전송 nextseqnum = 4 ACK0 수신 [1, 3] - base = 1 타이머 재시작 ACK1 수신 [2, 3] - base = 2 타이머 재시작 Timeout (pkt2 미수신) [2, 3] pkt2~pkt3 재전송 재전송 타이머 리셋 ACK2 수신 [3, 3] - base = 3 타이머 중지 ACK3 수신 [4, 3] → [4, 4] - base = 4 다음 패킷 보낼 수 있음 🔁 GBN 특징: 누적 ACK를 기준으로 window sliding하며, 한번 유실되면 window 내 모든 패킷 재전송.","-sender-측-1#✅ \u003cstrong\u003eSender 측\u003c/strong\u003e":"Event Window (base ~ nextseqnum - 1) Sent Packets Status Notes 초기 상태 [0, 0] 없음 대기 base = 0, nextseqnum = 0 rdt_send(data0) [0, 0] → [0, 0] pkt0 보냄 전송 nextseqnum = 1 rdt_send(data1) [0, 1] pkt1 보냄 전송 nextseqnum = 2 rdt_send(data2) [0, 2] pkt2 보냄 전송 nextseqnum = 3 rdt_send(data3) [0, 3] pkt3 보냄 전송 nextseqnum = 4 ACK0 수신 [1, 3] - base = 1 타이머 재시작 ACK1 수신 [2, 3] - base = 2 타이머 재시작 ACK3 수신 [2, 3] - 아직 base = 2 pkt2는 미수신 Timeout (pkt2) [2, 3] pkt2 재전송 only pkt2 재전송 타이머 리셋 ACK2 수신 [3, 3] - base = 3 모든 ack 받음 rdt_send(data4) [3, 4] pkt4 보냄 전송 nextseqnum = 5 📦 SR 특징: 누적 ACK 아님 → 각각의 패킷에 대해 독립적으로 확인 가능. loss가 하나뿐이라면 그 하나만 재전송.","-결론#🧾 \u003cstrong\u003e결론\u003c/strong\u003e":"GBN은 간단하지만 비효율적입니다. 하나의 패킷 유실 시 window 내 모든 패킷을 다시 보내야 해서 네트워크 과부하를 유발할 수 있습니다. SR은 더 복잡하지만 효율적입니다. 손실된 패킷만 재전송하고, receiver 측에서 out-of-order 패킷을 적절히 버퍼링하여 순서 정렬 후 전달합니다.","1-gbn과-유사한-특징#\u003cstrong\u003e(1) GBN과 유사한 특징\u003c/strong\u003e":"TCP는 누적 ACK를 사용하며, 중간에 손실된 세그먼트가 있더라도 이후 세그먼트를 개별적으로 ACK하지 않습니다. TCP 송신자는 가장 오래된 미확인 바이트(SendBase)와 다음에 보낼 바이트(NextSeqNum)만 추적합니다. 이는 GBN의 특징과 유사합니다.","1-애플리케이션으로부터-데이터-수신#\u003cstrong\u003e(1) 애플리케이션으로부터 데이터 수신\u003c/strong\u003e":"TCP는 애플리케이션 계층으로부터 데이터를 받아 이를 TCP 세그먼트로 캡슐화합니다. 각 세그먼트에는 시퀀스 번호(sequence number)가 포함됩니다. 이는 세그먼트 내 첫 바이트의 바이트 스트림 번호를 나타냅니다. 타이머가 이미 실행 중이 아니라면, 세그먼트를 IP 계층으로 전달할 때 타이머를 시작합니다.","1-타임아웃-및-재전송#\u003cstrong\u003e(1) 타임아웃 및 재전송\u003c/strong\u003e":"TCP는 각 세그먼트에 대해 타임아웃 간격(TimeoutInterval) 을 설정합니다. TimeoutInterval은 EstimatedRTT(예상 왕복 시간)과 DevRTT(왕복 시간 편차)를 기반으로 계산됩니다. 만약 특정 세그먼트에 대한 ACK가 타임아웃 내에 도착하지 않으면, 해당 세그먼트를 재전송합니다. 지수 백오프 알고리즘: 타임아웃이 발생할 때마다 다음 타임아웃 간격은 이전 값의 두 배로 설정됩니다. 예를 들어, 초기 타임아웃 간격이 0.75초라면, 첫 번째 재전송 후에는 1.5초, 두 번째 재전송 후에는 3.0초로 증가합니다. 이는 네트워크 혼잡 상태를 완화하기 위한 제한된 형태의 혼잡 제어입니다.","1-하프-오픈half-open-상태#\u003cstrong\u003e1. 하프 오픈(Half-Open) 상태\u003c/strong\u003e":"서버는 연결이 활성화된 상태로 판단하고 리소스를 할당하지만, 클라이언트는 이미 연결을 종료한 상태입니다. 이로 인해 서버는 불필요한 자원을 낭비하며, “하프 오픈” 상태의 커넥션을 유지하게 됩니다.","2-sr과-유사한-특징#\u003cstrong\u003e(2) SR과 유사한 특징\u003c/strong\u003e":"일부 TCP 구현은 순서가 맞지 않는 세그먼트를 버퍼링합니다. 이는 SR의 핵심 특징 중 하나입니다. 예를 들어, 송신자가 세그먼트 1, 2, …, N을 전송했고, 세그먼트 n의 ACK가 손실되었지만 나머지 ACK가 타임아웃 전에 도착했다고 가정합니다. 이 경우: GBN은 세그먼트 n부터 모든 세그먼트(n, n+1, …, N)를 재전송합니다. TCP는 최대 한 개의 세그먼트(n)만 재전송하며, 세그먼트 n+1의 ACK가 타임아웃 전에 도착했다면 세그먼트 n조차 재전송하지 않을 수 있습니다.","2-way-handshake의-동작-방식#\u003cstrong\u003e2-Way Handshake의 동작 방식\u003c/strong\u003e":"2-Way Handshake는 연결 설정을 위해 두 번의 메시지 교환만으로 완료됩니다:\n클라이언트 → 서버: SYN(연결 요청) 서버 → 클라이언트: ACK(연결 수락) 이 과정에서 서버는 클라이언트의 연결 요청(SYN)을 받고, 즉시 연결이 확립되었다고 간주합니다. 하지만 이 방식은 신뢰성 있는 연결 설정을 보장하지 못하며, 특히 네트워크 지연이나 중복 패킷(Duplicate Packet)로 인해 문제가 발생할 수 있습니다.","2-누적-ackcumulative-acknowledgment#\u003cstrong\u003e(2) 누적 ACK(Cumulative Acknowledgment)\u003c/strong\u003e":"TCP는 기본적으로 누적 ACK 방식을 사용하여 수신자가 받은 데이터를 확인합니다. 예: 수신자가 ACK = y를 보내면, 이는 “바이트 번호 y 이전의 모든 데이터가 성공적으로 수신되었음\"을 의미합니다. 이를 통해 송신자는 손실된 세그먼트를 빠르게 감지하고 재전송할 수 있습니다. 하이브리드 특징: 일부 TCP 구현은 순서가 맞지 않는(out-of-order) 세그먼트를 버퍼링하며, 선택적 ACK(SACK, Selective Acknowledgment) [RFC 2018]를 사용하여 특정 세그먼트를 개별적으로 ACK할 수 있습니다. 이를 통해 SR 스타일의 선택적 재전송이 가능해집니다.","2-데이터-송수신-실패#\u003cstrong\u003e2. 데이터 송수신 실패\u003c/strong\u003e":"서버는 클라이언트로부터 추가 데이터를 기다리지만, 클라이언트는 이미 연결을 종료했으므로 데이터를 보내지 않습니다. 결과적으로 서버는 데이터를 받지 못하고, 결국 타임아웃(Time-out) 후 연결을 강제로 종료해야 합니다.","2-타임아웃-발생#\u003cstrong\u003e(2) 타임아웃 발생\u003c/strong\u003e":"타임아웃이 발생하면, TCP는 해당 세그먼트를 재전송합니다. 이후 타이머를 다시 시작합니다.","3-ackacknowledgment-수신#\u003cstrong\u003e(3) ACK(Acknowledgment) 수신\u003c/strong\u003e":"수신자로부터 ACK가 도착하면, TCP는 ACK 필드 값 y와 SendBase를 비교합니다. SendBase: 가장 오래된 미확인 바이트의 시퀀스 번호. y \u003e SendBase라면, 하나 이상의 세그먼트가 성공적으로 전달되었음을 의미합니다. TCP는 SendBase를 업데이트하고, 아직 확인되지 않은 세그먼트가 남아 있다면 타이머를 다시 시작합니다.","3-단일-타이머-관리#\u003cstrong\u003e(3) 단일 타이머 관리\u003c/strong\u003e":"효율성을 위해 TCP는 단일 타이머만 사용합니다. 이 타이머는 가장 오래된 미확인 세그먼트와 연결됩니다. 새로운 ACK가 도착하거나 타임아웃이 발생하면 타이머를 조정합니다. Fast Retransmit: 타임아웃을 기다리지 않고도 중복 ACK(duplicate ACK)를 활용하여 손실된 세그먼트를 빠르게 재전송할 수 있습니다. 예를 들어, 동일한 ACK가 3번 이상 도착하면 송신자는 해당 세그먼트가 손실되었음을 판단하고 즉시 재전송합니다.","3-선택적-acksack#\u003cstrong\u003e(3) 선택적 ACK(SACK)\u003c/strong\u003e":"선택적 ACK(SACK)를 사용하면 수신자가 특정 세그먼트를 개별적으로 ACK할 수 있습니다. 이를 통해 송신자는 이미 수신된 세그먼트를 재전송하지 않으며, SR 스타일의 선택적 재전송이 가능해집니다.","3-재전송retransmission-문제#\u003cstrong\u003e3. 재전송(Retransmission) 문제\u003c/strong\u003e":"클라이언트는 초기 SYN 패킷이 서버에 도착하지 않았다고 판단하여 재전송을 시도할 수 있습니다. 이러한 재전송된 SYN 패킷이 서버에 도착하면, 서버는 이를 또 다른 새로운 연결 요청으로 오인할 가능성이 큽니다. 이로 인해 서버는 여러 개의 유효하지 않은 연결을 생성하며, 자원을 더욱 낭비하게 됩니다.","3way-handshake-vs-2way-handshake#3way handshake vs 2way handshake":"2-Way Handshake의 문제를 설명한 내용을 다시 정리하고, 핵심적인 문제점과 그로 인해 발생하는 상황을 상세히 설명하겠습니다.","checksum#checksum":"","gbn-go-back-n#GBN (go back N)":"","pipelining#pipelining":"","rdt-10#rdt 1.0":"","rdt-20-전송-후-대기-stop-and-wait#rdt 2.0 (전송 후 대기 stop-and-wait)":"","rdt-21#rdt 2.1":"","rdt-22#rdt 2.2":"","rdt30-alternating-bit-protocol#rdt3.0 (alternating-bit protocol)":"","rtt#RTT":"Sample RTT 대략적인 RTT","rtt-문제#RTT 문제":"아래는 **Exponential Weighted Moving Average (EWMA)**와 관련된 TCP의 Round-Trip Time (RTT) 추정 및 Timeout Interval 계산을 다루는 문제 3개입니다. 각 문제는 초기값과 샘플 데이터를 제공하며, 여러분이 주어진 공식을 적용하여 값을 계산하도록 설계되었습니다.","selective-repeat-sr#Selective Repeat (SR)":"","tcp#TCP":"","tcp-flow-control-and-congestion-control#TCP flow control and congestion control":"목적1 : 혼잡제어","tcp는-gbn인가-sr인가#\u003cstrong\u003eTCP는 GBN인가, SR인가?\u003c/strong\u003e":"TCP의 에러 복구 메커니즘은 GBN과 SR의 혼합형이라고 할 수 있습니다. 이를 구체적으로 살펴보겠습니다:","tcp의-기본-동작-원리#TCP의 기본 동작 원리**":"TCP는 세 가지 주요 이벤트를 처리하며, 각 이벤트에 따라 특정 작업을 수행합니다:","tcp의-신뢰성-보장-메커니즘#\u003cstrong\u003eTCP의 신뢰성 보장 메커니즘\u003c/strong\u003e":"TCP는 데이터 전송의 신뢰성을 보장하기 위해 다양한 기법을 사용합니다. 이 과정에서 TCP는 **Go-Back-N(GBN)**과 Selective Repeat(SR) 프로토콜의 특징을 혼합한 하이브리드 방식으로 동작합니다. 이를 아래와 같이 상세히 설명하겠습니다.","개괄#개괄":"","결론#\u003cstrong\u003e결론\u003c/strong\u003e":"TCP의 에러 복구 메커니즘은 기본적으로 GBN 스타일로 동작하지만, SACK와 Fast Retransmit을 통해 SR 스타일의 기능을 추가로 제공합니다. 따라서 TCP는 GBN과 SR의 하이브리드 모델로 분류됩니다.\n핵심 요약:\n기본적으로 GBN과 유사: 누적 ACK, 단일 타이머 사용. 선택적 ACK(SACK)와 Fast Retransmit을 통해 SR의 장점을 통합. 결과적으로 TCP는 GBN과 SR의 장점을 결합한 유연한 프로토콜입니다.","결론-1#\u003cstrong\u003e결론\u003c/strong\u003e":"2-Way Handshake는 간단하지만, 네트워크 지연 또는 중복 패킷으로 인해 문제가 발생할 수 있습니다. 특히, 하프 오픈 상태와 재전송 문제로 인해 서버 자원이 낭비되고, 데이터 송수신 실패 등의 문제가 생길 수 있습니다.\n따라서 TCP에서는 3-Way Handshake를 통해 신뢰성 있는 연결 설정을 보장하며, 이러한 문제를 효과적으로 해결합니다.","문제-1-estimatedrtt-계산#\u003cstrong\u003e문제 1: EstimatedRTT 계산\u003c/strong\u003e":"주어진 정보:\n초기 EstimatedRTT = 100ms α (가중치 계수) = 0.125 (즉, ( $\\alpha = 1/8$ )) SampleRTT 값: 첫 번째 SampleRTT = 120ms 두 번째 SampleRTT = 90ms 세 번째 SampleRTT = 110ms 질문:\n첫 번째 SampleRTT를 기반으로 업데이트된 EstimatedRTT를 계산하세요. 두 번째 SampleRTT를 기반으로 다시 업데이트된 EstimatedRTT를 계산하세요. 세 번째 SampleRTT를 기반으로 최종 EstimatedRTT를 계산하세요.","문제-1-예시-답안#\u003cstrong\u003e문제 1 예시 답안:\u003c/strong\u003e":"첫 번째 EstimatedRTT: $\\text{EstimatedRTT} = 0.875 \\cdot 100 + 0.125 \\cdot 120 = 101.25 , \\text{ms}$ 두 번째 EstimatedRTT: $\\text{EstimatedRTT} = 0.875 \\cdot 101.25 + 0.125 \\cdot 90 = 100.625 , \\text{ms}$ 세 번째 EstimatedRTT: $\\text{EstimatedRTT} = 0.875 \\cdot 100.625 + 0.125 \\cdot 110 = 101.094 , \\text{ms}$","문제-2-devrtt-rtt-변동성-계산#\u003cstrong\u003e문제 2: DevRTT (RTT 변동성) 계산\u003c/strong\u003e":"주어진 정보:\n초기 DevRTT = 0ms β (가중치 계수) = 0.25 위에서 계산한 EstimatedRTT 값들: 첫 번째 EstimatedRTT = 101.25ms 두 번째 EstimatedRTT = 100.625ms 세 번째 EstimatedRTT = 101.094ms SampleRTT 값: 첫 번째 SampleRTT = 120ms 두 번째 SampleRTT = 90ms 세 번째 SampleRTT = 110ms 질문:\n첫 번째 SampleRTT를 기반으로 업데이트된 DevRTT를 계산하세요. 두 번째 SampleRTT를 기반으로 다시 업데이트된 DevRTT를 계산하세요. 세 번째 SampleRTT를 기반으로 최종 DevRTT를 계산하세요.","문제-2-예시-답안#\u003cstrong\u003e문제 2 예시 답안:\u003c/strong\u003e":"첫 번째 DevRTT: $\\text{DevRTT} = 0.75 \\cdot 0 + 0.25 \\cdot |120 - 101.25| = 2.5 , \\text{ms}$ 두 번째 DevRTT: $\\text{DevRTT} = 0.75 \\cdot 2.5 + 0.25 \\cdot |90 - 100.625| = 2.1875 , \\text{ms}$ 세 번째 DevRTT: $\\text{DevRTT} = 0.75 \\cdot 2.1875 + 0.25 \\cdot |110 - 101.094| = 2.34375 , \\text{ms}$","문제-3-timeoutinterval-계산#\u003cstrong\u003e문제 3: TimeoutInterval 계산\u003c/strong\u003e":"주어진 정보:\n위에서 계산한 최종 EstimatedRTT = 101.094ms 위에서 계산한 최종 DevRTT = 2.34375ms TimeoutInterval 공식: $\\text{TimeoutInterval} = \\text{EstimatedRTT} + 4 \\cdot \\text{DevRTT}$ 질문:\n최종 TimeoutInterval을 계산하세요. 만약 Timeout이 발생했다면, TimeoutInterval은 어떻게 업데이트되나요? (초기 TimeoutInterval = 1초) Timeout 이후에 새로운 SampleRTT = 105ms가 측정되었고, EstimatedRTT와 DevRTT가 업데이트되었다고 가정할 때, TimeoutInterval을 재계산하세요.","문제-3-예시-답안#\u003cstrong\u003e문제 3 예시 답안:\u003c/strong\u003e":"최종 TimeoutInterval: $\\text{TimeoutInterval} = 101.094 + 4 \\cdot 2.34375 = 110.5875 , \\text{ms}$ Timeout 발생 시: $\\text{TimeoutInterval} = 2 \\cdot 110.5875 = 221.175 , \\text{ms}$ Timeout 이후 재계산: (새로운 EstimatedRTT와 DevRTT를 기반으로 다시 계산) 이 문제들은 EWMA와 TCP 타임아웃 메커니즘을 이해하고 실제 계산 능력을 테스트하기 위해 설계되었습니다. 문제를 풀면서 주어진 공식을 잘 적용해 보세요! 😊","문제-발생-시나리오#\u003cstrong\u003e문제 발생 시나리오\u003c/strong\u003e":"","발생하는-문제#\u003cstrong\u003e발생하는 문제\u003c/strong\u003e":"","시나리오-old-duplicate-syn-패킷#\u003cstrong\u003e시나리오: Old Duplicate SYN 패킷\u003c/strong\u003e":"클라이언트가 서버에 연결 요청(SYN)을 보냄\n클라이언트는 서버와의 연결을 위해 SYN 패킷을 전송합니다. 그러나 이 패킷은 네트워크 지연 또는 손실로 인해 서버에 도착하지 않거나, 재전송되며 지연됩니다. 서버가 SYN 패킷을 수신하고 연결 수락(ACK)\n서버는 클라이언트의 SYN 패킷을 수신하고, 연결 요청을 수락하기 위해 ACK 패킷을 클라이언트에게 전송합니다. 이로써 서버는 연결이 성공적으로 확립되었다고 판단합니다. 클라이언트와 서버가 데이터를 주고받으며 연결 종료\n클라이언트와 서버는 데이터 통신을 완료하고 연결을 종료합니다. 클라이언트는 더 이상 해당 연결을 사용하지 않습니다. 지연된 SYN 패킷이 서버에 도착\n초기에 전송되었던 SYN 패킷이 네트워크 지연으로 인해 이제야 서버에 도착합니다. 서버는 이 패킷을 새로운 연결 요청으로 오인합니다. 서버가 잘못된 연결 상태를 유지\n서버는 지연된 SYN 패킷에 대해 ACK를 전송하며, 새로운 연결이 확립되었다고 판단합니다. 하지만 실제로 클라이언트는 이미 연결을 종료했으므로, 서버는 “상대방이 없는 커넥션\"을 유지하게 됩니다.","신뢰적인-data전송#신뢰적인 data전송":"","예상-답안-형식#\u003cstrong\u003e예상 답안 형식\u003c/strong\u003e":"","왜-이런-문제가-발생할까#\u003cstrong\u003e왜 이런 문제가 발생할까?\u003c/strong\u003e":"2-Way Handshake는 단순히 “요청 → 응답\"의 구조로 동작하기 때문에, 연결 요청이 실제로 현재 유효한 요청인지 확인할 방법이 없습니다.\n특히 네트워크 지연이나 중복 패킷이 존재할 경우, 다음과 같은 이유로 문제가 발생합니다:\nOld Duplicate Packet 처리 불가능: 2-Way Handshake는 지연된 패킷을 구분할 방법이 없어, 이를 새로운 연결 요청으로 오인합니다. 상태 동기화 부족: 클라이언트와 서버 간의 연결 상태가 완벽히 동기화되지 않아, 한쪽이 연결을 종료한 상태에서도 다른 쪽이 연결이 활성화된 것으로 판단할 수 있습니다.","풀이-방법-안내#\u003cstrong\u003e풀이 방법 안내\u003c/strong\u003e":"EstimatedRTT 계산: 아래 공식을 사용합니다. $\\text{EstimatedRTT} = (1 - \\alpha) \\cdot \\text{EstimatedRTT} + \\alpha \\cdot \\text{SampleRTT}$ DevRTT 계산: 아래 공식을 사용합니다. $\\text{DevRTT} = (1 - \\beta) \\cdot \\text{DevRTT} + \\beta \\cdot |\\text{SampleRTT} - \\text{EstimatedRTT}|$ TimeoutInterval 계산: 아래 공식을 사용합니다. $\\text{TimeoutInterval} = \\text{EstimatedRTT} + 4 \\cdot \\text{DevRTT}$","프로세스대-프로세드-데이터#프로세스대 프로세드 데이터":"","해결책-3-way-handshake#\u003cstrong\u003e해결책: 3-Way Handshake\u003c/strong\u003e":"3-Way Handshake는 2-Way Handshake의 문제를 해결하기 위해 추가적인 단계를 포함합니다:\n클라이언트 → 서버: SYN(연결 요청) 서버 → 클라이언트: SYN+ACK(연결 수락 및 확인 요청) 클라이언트 → 서버: ACK(최종 확인) 이 과정에서 클라이언트와 서버는 서로의 상태를 명확히 동기화하며, 다음과 같은 장점을 제공합니다:\nOld Duplicate Packet 무시: 지연된 SYN 패킷이 도착해도, 최종 ACK 단계가 없으면 연결이 확립되지 않습니다. 상태 동기화 보장: 클라이언트와 서버가 모두 연결 확립을 확인하므로, 하프 오픈 상태를 방지합니다. 신뢰성 있는 연결 설정: 재전송된 패킷을 유효하게 처리하거나 무시할 수 있어, 혼란을 줄입니다.","힌트#\u003cstrong\u003e힌트\u003c/strong\u003e":"계산 과정에서 소수점 처리를 정확히 해야 합니다. TimeoutInterval이 두 배로 증가하는 경우는 Timeout이 발생했을 때만 해당됩니다. 모든 계산은 단계별로 진행하고, 중간 결과를 기록하세요."},"title":"3장 트랜스포트 계층 (transport)"},"/06.university/network/4%EA%B3%84%EC%B8%B5-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EA%B3%84%EC%B8%B5-network/":{"data":{"":"data plain : 단일 기기에서 어떤 input -\u003e output control plain : 라우팅 , 전체 경로 결정 전통적 방법 SDN hello world\ndhll eowld\nhello world\nhello world","data-plain#DATA PLAIN":""},"title":"4계층 네트워크 계층 (network)"},"/06.university/network/network-2%EC%B0%A8-%EA%B3%BC%EC%A0%9C/":{"data":{"-http-09--http-11-까지-알아보는-통신-기술#🌐 HTTP 0.9 ~ HTTP 1.1 까지 알아보는 통신 기술":"🌐 HTTP 0.9 ~ HTTP 1.1 까지 알아보는 통신 기술\nHTTP의 시작은 1989년 **팀 버너 리(Tim Berners-LEE)**에 의해 제안된 인터넷의 하이퍼 텍스트 시스템이다.\n초기 버전인 HTTP/0.9는 매우 단순한 프로토콜이었다.\n가능한 메서드는 하이퍼텍스트 문서(html)를 가져오기만 하는 GET 동작이 유일했으며, 헤더(header)도 없어 요청과 응답이 극히 단순 명료 하였다. 또한 상태 코드(status code)도 없었기 때문에 문제가 발생한 경우 특정 html 파일을 오류에 대한 설명과 함께 보내졌다.\nA very simple HTML page HTTP 0.9 스펙을 요약하면 다음과 같다.\nTCP/IP 링크 위에서 동작하는 ASCII 프로토콜 Get 메서드만 지원 HTTP 헤더 X, 상태 코드 X 응답도 HTML 파일 자체만 보내줌 서버와 클라이언트 간의 연결은 모든 요청 후에 닫힘(closed) 사실 초기에는 버전 번호가 존재하지 않았지만, 이후에 다른 http 버전들과 구분하기 위해서 0.9라는 버전을 붙이게 되었다고 한다.\nHTTP는 이러한 비교적 단순한 형태로 1991년에 시작되어, 이후 빠르게 진화하고 발전하게 되어지기 시작 했다.","-http-20-소개--통신-기술-알아보기#🌐 HTTP 2.0 소개 \u0026amp; 통신 기술 알아보기":"HTTP 2.0은 기존 HTTP 1.1 버전의 성능 향상에 초점을 맞춘 프로토콜이다. 인터넷 프로토콜 표준의 대체가 아닌 확장으로써, HTTP 1.1의 성능 저하 부분과 비효율적인 것들을 개선되어 탄생한 것이 HTTP 2.0라고 생각하면 된다. HTTP 1.1까지는 한번에 하나의 파일만 전송이 가능했다. 비록 파이프라이닝 기술이 있었지만, 여러 파일을 전송할 경우 선행하는 파일의 전송이 늦어지면 HOLB(Head Of Line Blocking)이 발생하였다.\n따라서 HTTP 2.0에서는 이 문제를 해결하기 위해 여러 파일을 한번에 병렬로 전송한다.\n그래서 일반적으로 HTTP/2를 사용만해도 웹 응답 속도가 HTTP/1/1에 비해 15~50% 향상 된다고 한다.\n아래는 동일 이미지를 웹사이트에 로딩시켜 HTTP/1.1과 HTTP/2의 속도를 비교한 결과이다.\n이러한 혁신적인 속도에 대부분의 사이트들은 HTTP 2를 지원한다.\n크롬 개발자 도구 네트워크 탭에서 우측 클릭하고 Protocol 탭을 활성화 시키면 각 요청에 대한 프로토콜을 볼 수 있다.\nh2 가 http/2.0 약자라고 보면 된다","-http-30-소개--통신-기술-알아보기#🌐 HTTP 3.0 소개 \u0026amp; 통신 기술 알아보기":"HTTP 2.0 의 등장과 함께 기존의 프로토콜 데이터 체계를 프레임과 스트림 개념으로 재구축한 결과 기존 보다 혁신적으로 성능이 향상되게 되었다. 하지만 여전히 HTTP는 TCP 기반 위에서 동작되기 때문에, TCP 자체의 핸드쉐이크 과정에서 발생하는 지연 시간과, 기본적으로 TCP는 패킷이 유실되거나 오류가 있을때 재전송을하는데 이 재전송하는 패킷에 지연이 발생하면 결국 HOLB(Head Of Line Blocking) 문제가 발생되었다.\n즉, HTTP 2.0은 TCP/IP 4 계층의 애플리케이션 계층(L4)에서 HTTP의 HOLB를 해결하였지만, 전송 계층(L3)에서의 TCP HOLB 를 해결한건 아니기 때문이다.\n애초에 TCP로 인터넷 통신을 하는 것이 발목을 잡은 것이다.\n점점 기술이 발전하고 다채로운 휴대 통신 기기가 널리 보급되면서 기업들은 다양한 컨텐츠를 여러 기기에 신속하게 전달하기 위해 TCP의 한계를 극복하고 최적화하는 것이 급선무의 과제였다.\n그러자 IT 기업의 선두주자인 구글은 SPDY 프로토콜에 이어 새로운 UDP 기반인 QUIC 프로토콜을 고안하게 된다. 그리고 이 새로운 QUIC 프로토콜이 TCP/IP 4계층에도 동작시키기 위해 설계된 것이 바로 HTTP 3.0 이다.\n즉, HTTP/1.1과 HTTP/2는 TCP를 전송에 사용하지만, **HTTP/3은 UDP(QUIC)**를 사용한다고 보면 된다.\nHTTP 3.0은 HTTP 2.0가 가지는 장점들을 모두 가지면서 TCP가 가지는 원초적인 단점을 보완하는데 중점으로 개발되었다. 그래서 지금까지 거론되었던 HTTP/2 의 문제를 거의 해결하였다고 보면 된다. RTT(Round Trip Time)를 제로 수준으로 줄였고, 패킷 손실에 대한 빠른 대응, 사용자 IP가 바뀌어도 연결이 유지되는 것이 특징이다.\n통신 인프라가 빈약한 나라에서는 큰 차이가 느껴질지도 모르겠지만, 사실 한국에서 HTTP/2를 사용하든 HTTP/3를 사용하든 워낙에 땅이 좁은데다 통신 인프라는 세계에서 끝내주게 잘되어 있기 때문에 소비자들은 체감을 못 할 것이다.\n그렇지만 2022년 11월 15일 한국 최초로 네이버가 HTTP/3을 도입하였다고 한다. (당연히 구글은 이미 도입했다)\nhttps://n.news.naver.com/mnews/article/022/0003754517?sid=101\n개발자 도구의 네트워크 탭에서 표 항목에 Protocol을 활성화하면 각 요청에 대한 프로토콜을 볼 수 가 있다.\n사진상에서 h3이라고 쓰여져 있는 것이 http 3.0 이며 http 2.0 과 간혹 http 1.1 도 보인다.\n개발자 도구 네트워크 탭에서 우측 클릭하고 Protocol 탭을 활성화 시킨다","-tcp는-구조상-한계로-개선해도-여전히-느리다#\u003cstrong\u003e💬 TCP는 구조상 한계로 개선해도 여전히 느리다\u003c/strong\u003e":"사실 TCP는 인류가 지금과 같이 엄청난 속도로 발전할 것이라곤 상상 할 수 없는 시기에 만들어졌다. TCP가 만들어지던 시절에 클라이언트와 서버가 동시 다발적으로 여러 개 파일의 데이터 패킷을 교환할 것이라고 상상하지 못했기 때문이다.\n그래서 모바일 기기와 같이 네트워크 환경을 바꾸어가면서 서버와 클라이언트가 소통할 수 있을 것이라고 생각하지 못했다. 그 때문에 와이파이를 바꾸면 다시 새로운 커넥션을 맺어야 되서 끊김 현상이 일어나는 것이다.\n또한 TCP를 사용한 통신에선 패킷은 신뢰성을 위해 무조건 순서대로 처리되어야 한다. 또한 패킷이 처리되는 순서 또한 정해져있으므로 이전에 받은 패킷을 파싱하기 전까지는 다음 패킷을 처리할 수도 없다. 만일 중간에 패킷이 손실되어 수신 측이 패킷을 제대로 받지 못했으면 다시 보내야 한다.\n이렇게 패킷이 중간에 유실되거나 수신 측의 패킷 파싱 속도가 느리다면 통신에 병목이 발생하게 되는데, 이러한 현상을**HOLB(Head of line Blocking)**라고 부른다.\n이 HOLB는 TCP 설계도상 어쩔수 없이 발생하는 문제이기 때문에 HTTP/1.1 뿐만 아니라 HTTP/2도 가지고 있는 아주 고질적인 문제였다.\n따라서 이런 고질적인 문제들을 해결하기 위해 HTTP/3는 TCP를 버리고 UDP를 선택하였다.","-udp는-신뢰성이-없는게-아니라-탑재를-안했을-뿐이다#\u003cstrong\u003e💬 UDP는 신뢰성이 없는게 아니라 탑재를 안했을 뿐이다\u003c/strong\u003e":"처음 TCP와 UDP에 대해서 배웠을때, UDP는 하얀 도화지 같이 기능이 거의 없어서 빠르지만 대신에 신뢰성이 낮기 때문에, 인터넷 통신에선 조금 느리더라도 신뢰성이 높은 TCP를 사용한다라고 배웠을 것이다.\nTCP UDP 연결 방식 연결 지향형 프로토콜 비 연결 지향형 프로토콜 전송 순서 보장 보장하지 않음 신뢰성 높음 낮음 전송속도(상대적) 느림 빠름 혼잡제어 O X 헤더 크기 20바이트 8 바이트 UDP는 User Datagram Protocol이라는 이름에서도 알 수 있듯이 데이터그램 방식을 사용하는 프로토콜이기 때문에 패킷의 목적지만 정해져있다면 중간 경로는 신경쓰지 않기 때문에 핸드쉐이크 과정이 필요없다.\nTCP(좌) - UDP(우)\n결론으로는 UDP는 TCP가 신뢰성을 얻기 위해 내제된 과정을 거치지 않기 때문에 속도가 더 빠를 수 밖에 없다는 것인데, 그렇다면 UDP를 사용하게되면 빠르지만 신뢰성과 패킷의 무결성을 보증할 없다는 뜻인데 이것을 인터넷 통신에 사용해도 문제가 없는 걸까?\n이부분은 오해인것이, UDP는 신뢰성이 없는게 아니라 탑재를 안했을 뿐이다.\nUDP의 진짜 장점은 커스터마이징이 가능하다는 점이다.\n즉, 아래 사진과 같이 UDP 자체는 헤더에 들은게 없어 신뢰성이 낮고 제어 기능도 없지만, 이후 개발자가 애플리케이션에서 구현을 어떻게 하냐에 따라서 TCP와 비슷한 수준의 기능을 가질 수도 있다는 말이다.\nUDP 헤더 구성","-아예-새로운-프로토콜은-안되는가#\u003cstrong\u003e💬 아예 새로운 프로토콜은 안되는가?\u003c/strong\u003e":"TCP가 문제이고 UDP도 애매하면 아예 다른 프로토콜을 만들거나 채용한다는 선택지도 있을 것이다. 이론적으로도 네트워크 스택에서 UDP와 TCP 옆에 새로운 전송 프로토콜을 만들 수 있다. 아니면 이미 있는 전송 프로토콜인 SCTP를 사용할 수도 있다. 그러나 새 프로토콜 배포는 그렇게 녹록치만은 않은데, 사용자와 서버 사이에 있는 TCP와 UDP만 허용하는 방화벽, NAT, 라우터 등의 설정에 따라 차단 될 수 있기 때문이다. 이를 프로토콜 고착화(ossification)라고 부른다.\n게다가 네트워크 스택의 전송 프로토콜 계층에서 뭔가를 바꾼다는 것은 새로운 운영체제 커널을 갱신하고 프로토콜을 구현해 배포하는 것은 상당한 노력이 필요한 과정이다. 그래서 이미 표준화된 수많은 TCP 개선사항도 광범위하게 지원되지 않아서 널리 배포되거나 사용되지 않고 있는 것이다.","binay-framing-layer#\u003cstrong\u003eBinay Framing Layer\u003c/strong\u003e":"HTTP 1.1과 HTTP 2.0의 주요한 차이점은 HTTP 메세지가 1.1에서는 text로 전송되었던 것과 달리, 2.0에서는 binary frame로 인코딩되어 전송된다는 점이다.\n기존 text 방식으로 HTTP 메세지를 보내는 방식은, 본문은 압축이 되지만 헤더는 압축이 되지 않으며 헤더 중복값이 있다는 문제 때문에 HTTP 2.0에서는 바이너리로 변경 되었다.\n또한 HTTP 헤더에 대해서 배웠을때 헤더와 바디를 \\r 이나 \\n 과 같은 개행 문자로 구분한다고 하였는데, HTTP/2.0에서 부터는 헤더와 바디가 layer로 구분된다.\n이로인해 데이터 파싱 및 전송 속도가 증가하였고 오류 발생 가능성이 줄어들었다.","connection-id#\u003cstrong\u003eConnection ID\u003c/strong\u003e":"반면 QUIC은 Connection ID를 사용하여 서버와 연결을 생성한다.\nConnction ID는 각 연결은 연결 식별자나 연결 ID를 가지므로 이를 통해 연결을 식별한다.\nConnection ID는 랜덤한 값일 뿐, 클라이언트의 IP와는 전혀 무관한 데이터이기 때문에 클라이언트의 IP가 변경되더라도 기존의 연결을 계속 유지할 수 있다. 그래서 새로 연결을 생성할 때 거쳐야하는 핸드쉐이크 과정을 생략할 수 있다. 따라서 휴대폰으로 인터넷을 할 때, 중간에 와이파이에서 LTE로 변경해도 스트림이 계속 유지가 된다. 하지만 똑같은 Connection ID만 사용한다면 해커가 네트워크를 통해 사용자를 추적하여 보안 문제가 일어날 수도 있을 것이다. 그래서 QUIC는 새 네트워크가 사용될 때마다 Connection ID를 변경한다.\n위의 말과 행동이 다르겠다고 생각하겠지만, 내부적으로 클라이언트와 서버가 모두 연결을 위해 무작위로 생성한 Connection ID에 대해 인지하고 있고, 네트워크가 바뀔때 Connection ID를 바꾸더라도 이게 이전 Connectin ID와 동일하다고 인지하여 연결을 유지하는 것이다.","domain-sharding#\u003cstrong\u003eDomain Sharding\u003c/strong\u003e":"파이프라이닝을 대체하기 위한 차선책으로 나온 기술이며, 브라우저들은 하나의 도메인에 대해 여러 개의 Connection을 생성해서 병렬로 요청을 보내고 받는 방식으로 성능을 개선했다.\n한 도메인당 6~13개의 TCP 연결들을 동시 생성해 여러 리소스를 한 번에 다운로드 하는 것이다. 이를 Domain Sharding이라고 부른다. 하지만 도메인의 주소를 찾기 위해 DNS Lookup 과정에서 시간을 잡아먹을수도 있으며, 브라우저별로 Domain당 Connection 개수의 제한이 존재하여 근본적인 해결책은 아니었다.","holb-head-of-line-blocking#\u003cstrong\u003eHOLB (Head Of Line Blocking)\u003c/strong\u003e":"위에서 소개한 파이프 라이닝은 어찌보면 정말 혁신적인 기술이지만, 보낸 요청 순서대로 응답을 받아야하는 규칙 부분에서 문제가 생기게 된다.\n마치 FIFO(선입선출) 처럼 생각하면 되는데, 문제는 요청하는 데이터의 크기는 제각각 이기 때문에, 첫번째로 요청한 데이터가 용량이 큰 데이터라면, 두번째, 세번째 데이터가 아무리 빨리 처리되어도 우선순위 원칙에 따라 첫번째 데이터의 응답 속도가 늦어지면 후 순위에 있는 데이터 응답속도도 덩달아 늦어지게 되는 것이다.\n이해가 잘 되지 않는다면 아래 그림을 살펴보자.\n첫번째 http request에서는 하나의 요청당 응답을 받아야 다음 요청을 보내는 오래된 방법으로 time 길이를 보면 오래 걸려 길다. 그래서 pipelining을 통해 동시 요청을 통해 time을 감소 시켰지만, 문제는 첫번째 요청에 대한 응답이 오래걸릴 경우 그 뒤의 응답도 같이 늦게 되서 결과적으로 총 time이 길어지게 되는 비효율적인 상황이 발생하게 되는 것이다.\n따라서 위의 문제점과 더불어 구현 복잡성에 의해 파이프 라이닝은 활용이 매우 제한적이었으며, 대부분의 브라우저에서는 여러개의 tcp 연결을 만들어 병렬적으로 이용하는 방식을 많이 사용하였지만 이 역시 추가 메모리와 리소스를 낭비하는 단점이 있었다.","http--10#\u003cstrong\u003eHTTP / 1.0\u003c/strong\u003e":"인터넷의 성장이 날이 갈수록 거대해지면서, 1994년 W3C가 만들어지며 HTML의 발전을 도모하게 되었고, 이와 비슷하게 HTTP 프로토콜 개선에 초점을 맞추기 위해 **HTTP-WG(HTTP Working Group)**가 설립되었다.\n웹 브라우저, 인터넷 인프라가 빠르게 진화하며 이제는 단순히 하이퍼텍스트 문서 뿐만 아니라 멀티미디어 데이터나 메타데이터 등 다양하고 상세한 컨텐츠가 필요해짐으로써, 기존의 HTTP 0.9로는 다양한 요구사항들을 채울수 없는 한계에 봉착하게 되었다.\n그러다 1996년 HTTP-WG는 HTTP/1.0 구현의 일반적인 사용을 문서화한 RFC 1945를 발표하게 된다.\nRFC 1945는 어렵게 생각할 필요없이 HTTP 1.0 프로토콜 통신 스펙에 관한 기술 문서 정도로 생각하면 된다.\n컨텐츠 인코딩, 다양한 글자 지원, 멀티파트 타입, 인가, 캐싱, 프록시, 날짜 형식 등을 문서화 하였다.\n이는 다음과 같은 익숙한 형태의 요청과 응답 포맷으로 구성되었다.\nRequest 메세지에는 GET 요청이 시작되는 줄에 PATH와 HTTP 버젼 그리고 다음 줄로 이어지는 헤더값을 가지며, Response 메세지에는 200 OK 이후 응답 상태로 이어지는 응답 헤더값을 가지는 걸 볼 수 있다.\n이른바 HTTP 포맷 형태의 시초라고 보면 된다.\n이렇게 발표된 HTTP 1.0 스펙을 요약하면 다음과 같다.\n기본적인 HTTP 메서드와 요청/응답 헤더 추가 HTTP 버전 정보가 각 요청 사이내로 전송되기 시작 (HTTP/1.0 이 GET 라인에 붙은 형태로) 상태 코드(status code)가 응답의 시작 부분에 붙어 전송되어, 브라우저가 요청에 대한 성공과 실패를 알 수 있고 그 결과에 대한 동작을 할 수 있게 되었다. (특정 방법으로 로컬 캐시를 갱신하거나 ..등) 응답 헤더의 Content-Type 덕분에 HTML 파일 형식 외에 다른 문서들을 전송하는 기능이 추가되었다. 단기커넥션 : connection 하나당 1 Request \u0026 1 Response 처리 가능","http--11#\u003cstrong\u003eHTTP / 1.1\u003c/strong\u003e":"HTTP 1.0의 몇가지 단점을 커버하기 위해 HTTP 1.0이 출시된지 6개월 만에 1997년 1월에 공식적으로 HTTP/1.1이 릴리즈 되게 된다. HTTP 1.1은 현재 가장 많이 쓰이는 프로토콜 버젼이며, 우리가 HTTP를 학습할때 배우는 기본 베이스 지식이기도 하다.\nHTTP 1.1 표준은 이전 버전에서 발견 된 많은 프로토콜 모호성을 해결하고 몇 가지 크리티컬한 성능 개선을 도입했다.\n좀더 보완된 특징은 다음과 같다.\n지속 연결(Persistent connection) : 지정한 timeout 동안 연속적인 요청 사이에 커넥션을 닫지 않음. 기존 연결에 대해서 handshake 생략 가능 파이프 라이닝(pipelining) : 이전 요청에 대한 응답이 완전히 전송되기 전에 다음 전송을 가능하게 하여, 여러 요청을 연속적으로 보내 그 순서에 맞춰 응답을 받는 방식으로 지연 시간을 줄이는 방식 (불안정하여 사장됨) HOST 헤더 추가 : 동일 IP 주소에 다른 도메인을 호스트하는 기능 가능 Chunk Encoding 전송 : 응답 조각 바이트 범위 요청 캐시 제어 메커니즘 도입","http-10-문제점#\u003cstrong\u003eHTTP 1.0 문제점\u003c/strong\u003e":"","http-11-통신-과정#\u003cstrong\u003eHTTP 1.1 통신 과정\u003c/strong\u003e":"HTTP 1.1에서는 한 TCP 커넥션을 통해 요청을 보냈을 때, 그에 대한 응답이 도착하고 나서야 같은 TCP 커넥션으로 다시 요청을 보낼 수 있다. 따라서 웹브라우저들은 회전 지연을 줄이기 위해 여러 개의 TCP 커넥션을 만들어 동시에 여러 개의 요청을 보내는 방법을 사용하였다. 그러나 그렇다고 TCP 커넥션을 무한정 만들 수는 없기에, 한 페이지에 보내야 할 요청이 수십개에서 수백개에 달하는 요즘 시대에는 한계가 있었다.\nRequest 1을 전송 받기 위해 하나의 TCP Connection 1 을 열고 요청/응답한다. 다음으로 Request 2, 3, 4을 요청하는데 빠르게 전송받기 위해 여러개의 커넥션 TCP Connection 2 와 TCP Connection 3을 만들어 요청/응답한다. 하지만 커넥션을 무한정으로 만들수없어 이러한 방식은 한계가 존재한다.","http-11을-개선한-http-20#\u003cstrong\u003eHTTP 1.1을 개선한 HTTP 2.0\u003c/strong\u003e":"HTTP 2.0은 기존 HTTP 1.1 버전의 성능 향상에 초점을 맞춘 프로토콜이다.\n기존의 HTTP 1.1의 내부적인 통신 구조를 다른 개념으로 송두리째 바꿔버렸는데, 웹 응답 속도가 HTTP/1/1에 비해 15~50% 향상 되었다.\n아래 그림을 보면 고용량 이미지에 대해서 응답속도 비교를 한눈에 볼 수 있다.","http-20--push-통신-과정#\u003cstrong\u003eHTTP 2.0 + Push 통신 과정\u003c/strong\u003e":"서버가 클라이언트로부터 Request 1을 전송 받으면, index.html 에 있는 자원들을 파싱한다. 클라이언트가 따로 요청하지 않아도, 서버가 알아서 미리 자원들을 클라이언트에 보낸다. 따라서 총 로드 시간이 줄어드는 이점이 있다.","http-20-개선점#\u003cstrong\u003eHTTP 2.0 개선점\u003c/strong\u003e":"","http-20-문제점#\u003cstrong\u003eHTTP 2.0 문제점\u003c/strong\u003e":"","http-20-통신-과정#\u003cstrong\u003eHTTP 2.0 통신 과정\u003c/strong\u003e":"반면, HTTP 2에서는 하나의 커넥션에 여러 개의 스트림이 동시에 요청/응답 한다.\nHTTP 1.1은 요청과 응답이 메시지라는 단위로 구분되어 있었지만, HTTP 2부터는 Stream을 통해 요청과 응답이 묶일 수 있어 다수 개의 요청을 병렬적으로 처리가 가능해졌다. 따라서 응답 프레임들은 요청 순서에 상관없이 먼저 완료된 순서대로 클라이언트에 전달이 가능하다.\nRequest 1을 전송 받기 위해, 우선 Framing Layer을 통해 바이너리 프레임 단위로 쪼개고 하나의 TCP Connection을 만들고 통신한다. 다음으로 Request 2, 3, 4을 요청하는데 기존의 커넥션을 이용하며, 쪼개진 프레임들은 메세지 통로를 통해 동시다발적으로 요청/응답 받는다. 커넥션 낭비도 없고 병렬적으로 자원이 전송받기에 매우 빠르다.","http-20을-개선한-http-30#\u003cstrong\u003eHTTP 2.0을 개선한 HTTP 3.0\u003c/strong\u003e":"위의 HTTP 2.0의 문제점을 한마디로 요약하자면 TCP가 문제이다. (HTTP는 TCP 기반 위에서 동작된다)\n최근에 나온 HTTP 3.0 버전은 TCP를 버리고 UDP를 채택하였다. 정확히 말하면 UDP를 개조한 QUIC 라는 프로토콜을 새로 만들었다.\n기존 TCP는 클라이언트와 서버 간에 세션을 설정하기 위해 핸드쉐이크가 필요하며, 인증서인 TLS도 세션이 보호되도록 자체 핸드셰이크도 필요하다. 하지만 QUIC는 보안 세션을 설정하기 위해 한 번의 핸드셰이크만 필요하다. 아래 그림만 봐도 한번 통신하는데 드는 시간 세로축 차이가 어마어마하게 난다는 것을 볼 수 있다.\nHTTP 3.0에 대한 자세한 스펙을 보려면 아래 포스팅을 참고하길 바란다.","http-30-개선점#\u003cstrong\u003eHTTP 3.0 개선점\u003c/strong\u003e":"","http-30-우려점#\u003cstrong\u003eHTTP 3.0 우려점\u003c/strong\u003e":"HTTP 3.0 과 QUIC 프로토콜이 이렇게 좋은 많은 것들을 제공해 주고 있지만, 아직 전세계의 기업들이 이를 막상 도입하지 않는 현실적인 이유가 존재한다.","http-header-data-compression#\u003cstrong\u003eHTTP Header Data Compression\u003c/strong\u003e":"HTTP 1.1 에서 헤더는 아무런 압축 없이 그대로 전송되었다. 이를 개선하기 위해 HTTP 2.0에서는 HTTP 메시지의 헤더를 압축하여 전송한다.\n또한 HTTP 1.1 에서는 연속적으로 요청되는 HTTP 메세지들에게서 헤더값이 중복되는 부분이 많아 역시 메모리가 낭비되었는데, HTTP 2.0 에서는 이전 Message의 헤더의 내용 중 중복되는 필드를 재전송하지 않도록하여 데이터를 절약할 수 있게 되었다. 만일 메세지 헤더에 중복값이 존재하는 경우, 위의 그림에서 Static / Dynamic Header Table 개념을 사용하여 중복 헤더를 검출하고, 중복된 헤더는 index값만 전송하고 중복되지 않은 Header 정보의 값은 호프만 인코딩(Huffman Encoding) 기법을 사용하는 HPACK 압축 방식으로 인코딩 처리 하여 전송하여, 데이터 전송 효율을 높였다고 보면 된다.","http11-문제점#\u003cstrong\u003eHTTP/1.1 문제점\u003c/strong\u003e":"","http의-holb-head-of-line-blocking#\u003cstrong\u003eHTTP의 HOLB (Head Of Line Blocking)\u003c/strong\u003e":"기존 HTTP/1.1 같은 경우 파이프라인(pipeline) 기술을 통해 병렬적으로 리소스를 빠르게 얻도록 하려고 하였지만, 만일 첫번째 요청에 딜레이가 생기면 나머지 요청이 빨리 처리됬음에도 불구하고 딜레이가 되는 심각한 현상이 있었다.\n예를들어 3개의 이미지 a.png, b.png, c.png 를 받는다고 가정한다면 다음과 같이 첫번째 a.png 를 받는 과정에서 오래걸리게 된다면 b와 c 이미지가 아무리 빨리 처리되더라도 결과적으로 늦게 받게 되게 된다.\n그래서 이를 극복하기 위해 HTTP/2 에서는 리소스들을 하나의 커넥션에서 병렬적으로 보내도록 개선하였다. 따라서 a.png 가 시간이 걸리더라도 b 와 c 이미지는 먼저 받아서 보여줄 수 있었다.","keep-alive-동작-과정#\u003cstrong\u003e\u003cstrong\u003ekeep-alive 동작 과정\u003c/strong\u003e\u003c/strong\u003e":"Keep-Alive는 원리는 단순하다.\n지정한 timeout동안 연결을 끊지 않게 지정해서, HTTP 요청과 응답 시 다수의 TCP 연결 handshake를 줄이는 것에 초점을 둔다.\nHTTP/1.1부터는 keep-alive가 기본으로 세팅되어 자동으로 Persistent Connection 연결이 된다. 하지만 기본적으로 HTTP/1.0 connection은 하나의 request에 응답할 때마다 connection을 close하도록 설정돼있다.\n따라서 HTTP/1.0+ 기반에서 TCP 연결의 재사용을 원할때 아래처럼 요청 헤더 Connection 속성에 keep-alive를 세팅해야 한다는 특징이 있다.\nrequest header\n만약 서버에서 keep-alive connection을 지원하는 경우에는 동일한 헤더를 response에 담아 보내주고, 지원하지 않으면 헤더에 담아 보내주지 않는다. 만약 서버의 응답에 해당 헤더가 없을 경우 client는 지원하지 않는다고 가정하고 connection을 재사용하지 않게 된다.\nmax : keep-alive을 통해서 주고받을 수 있는 request의 최대 갯수. 이 수보다 더 많은 요청을 주고 받을 경우에는 connection은 close된다. timeout : keep-alive가 얼마동안 유지될 것인가를 의미한다. 이 시간이 지날 동안 request가 없을 경우에 connection은 close된다 keep-alive를 이용한 통신은 위의 설정에 따라 클라이언트나 서버 중 한쪽이 다음 헤더를 부여해 접속을 끊거나 타임아웃될 때까지 연결이 유지된다. 그래서 만일 필요한 자원을 모두 할당받고 더이상 keep-alive 연결을 유지할 필요가 없을 경우 요청 헤더에서 Connection 속성을 close로 설정해 서버로 보내게 되면, TCP 지속 연결을 끊게 된다.","keep-alive-메세지-통신#\u003cstrong\u003e\u003cstrong\u003ekeep-alive 메세지 통신\u003c/strong\u003e\u003c/strong\u003e":"다음은 두개의 요청에 대한 HTTP 메세지 예시이다.\n먼저 HTML 페이지에 대한 요청을 하고 그다음 아이콘 이미지에 대한 요청을 한다. 이 2가지 요청은 모두 한 개의 keep-alive 연결을 통해 전달된다.\n1. HTML 파일 요청 (인코딩, charset과 쿠키 메타데이터와 함께)\n2. HTML 요청에 대한 응답\n3. 동일한 TCP 연결에 발생한 icon 파일 요청 (icon 파일을 받고나면 서버에게 해당 연결이 재사용되지 않을 것임을 알리기 위에 Connection 헤더값을 close로 설정)\n4. icon 응답과 연결 종료","multiplexing#\u003cstrong\u003eMultiplexing\u003c/strong\u003e":"바로 위에서 frame - message - stream - connection 그림에서 봤듯이, HTTP 헤더 메세지를 바이너리 형태의 프레임으로 나누고 하나의 커넥션으로 동시에 여러개의 메세지 스트림을 응답 순서에 상관없이 주고 받는 것을 **멀티플렉싱(multiplexing)**이라고 한다.\nHTTP/1.1의 Connection Keep-Alive, Pipelining, Head Of Line Blocking을 개선했다. latency만 줄여주는게 아니라 결국 네트워크를 효율적으로 사용할 수 있게 하고 그 결과 네트워크 비용을 줄여준다. 특히 클라우드 시스템을 이용한다면 비용과 직결된다.","persistent-connection#\u003cstrong\u003ePersistent Connection \u003cstrong\u003e(keep-alive)\u003c/strong\u003e\u003c/strong\u003e":"HTTP는 TCP 연결 기반 위에서 동작하는 프로토콜로 신뢰성 확보를 위해 연결을 맺고 끊는 데 있어서 3 way Handshake 가 이루어진다. 그런데 HTTP는 기본적으로 비연결성(connecitonless) 프로토콜이기 때문에 한 번의 요청과 응답을 하고 응답이 끝나면 연결을 끊어 버리는데, 자원을 요청할때 마다 연결을 맺고 끊어버려 오버헤드(overhead))가 생기게 된다.\n그래서 HTTP/1.1에서 Persistent Connection 기능이 추가됨으로써, 한 번 맺어졌던 연결을 끊지 않고 지속적으로 유지하여 불필요한 Handshake를 줄여 성능을 개선하였다.\n연결을 유지함으로써 Handshake 과정을 생략해 빠르게 자원을 받아올 수 있다. 불필요한 연결의 맺고 끊음을 최소화시켜 네트워크 부하를 줄 일 수 있다. 클라이언트 측에서 요청에 keep-alive 헤더를 담아 보내야 한다. 정확한 Content-length 헤더를 사용해야 한다. 하나의 connection을 계속해서 재사용해야 하는데, 특정 요청의 종료를 판단할 수 없기 때문이다. Connection 헤더를 지원하지 않는 proxy에는 사용할 수 없다. 가끔 HTTP 지속 연결을 persistent connection 혹은 keep-alive connection 으로 용어를 혼재하는데, 정확히는 persistent connection이 맞다.\nkeep-alive는 HTTP 1.0+�� persistent connection을 연결하기 위해, 헤더에 명시해 사용하는 단어라고 보면 된다.","pipelining#\u003cstrong\u003ePipelining\u003c/strong\u003e":"파이프 라이닝은 여러개의 요청을 보낼때 처음 요청이 응답될 때까지 기다리지 않고 바로 요청을 한꺼번에 보내는 것을 의미한다. 즉, 여러개의 요청을 한꺼번에 보내서 응답을 받음으로서 대기시간을 줄이는 기술이다.\nkeep-alive를 전제로 하며, 서버 간 요청의 응답속도를 개선시키기 위해 적용 서버는 요청이 들어온 순서대로(FIFO) 응답을 반환한다. 하지만 응답 순서를 지키기 위해 응답 처리를 미루기 때문에 Head Of Line Blocking 문제가 발생하여, 그래서 모던 브라우저들은 대부분 파이프라이닝을 사용하지 못하도록 막아 놓았다. HTTP 2에서는 멀티플렉싱 알고리즘으로 대체되었다.","quic-프로토콜#\u003cstrong\u003eQUIC 프로토콜\u003c/strong\u003e":"HTTP/3의 가장 큰 특징은 기존의 HTTP/1, HTTP/2와는 다르게 UDP 기반의 프로토콜인 **QUIC(Quick UDP Internet Connections)**을 사용하여 통신하는 프로토콜이라는 점이다. ‘Quick UDP Internet Connections’ 라는 이름에서 알수 있듯이 말 그대로 UDP를 사용하여 빠르게 인터넷 연결을 하는 새로운 프로토콜이다. (참고로 ‘퀵’ 이라고 읽는다)\nHTTP/2의 기반이 되는 SPDY는 사장되었지만, HTTP/3의 기반이 되는 QUIC는 RFC 9000으로 표준화되어 있다는 점도 다르다.","quic는-cpu를-너무-사용함#\u003cstrong\u003eQUIC는 CPU를 너무 사용함\u003c/strong\u003e":"QUIC은 너무 많은 CPU 시간을 차지한다.\n따라서 보급형 스마트폰과 IoT 장치같은 마이크로 애플리케이션들은 이용에 어려움을 겪을 수도 있다.\n물론 시간이 지나면 개선될수도 있다. 다만 문제는 추가적인 CPU 사용이 배포자에게 얼마나 영향을 끼치는가 이다.","quic의-계층-위치#\u003cstrong\u003eQUIC의 계층 위치\u003c/strong\u003e":"위의 TCP/IP 4 Layer에서 볼 수 있듯이 HTTP/3은 계층 형태는 약간 특이하다.\n왜냐하면 QUIC은 TCP + TSL + HTTP의 기능을 모두 구현한 프로토콜이기 때문이다. TCP의 프로토콜의 무결성 보장 알고리즘과 SSL이 이식됨으로써 높은 성능과 동시에 신뢰성을 충족시켰다고 보면 된다. 그래서 계층 위치도 약간 비스듬하게 걸쳐 있게 표현된 것이다. 쉽게 말하자면, Application 계층의 HTTP/3은 QUIC를 동작시키기 위해 있는 것이라고 보면 되고, 위에서 배웠다시피 QUIC는 UDP 기반으로 만들어졌기에 Transport 계층의 UDP 위에서 동작한다고 보면된다.","rtt-round-trip-time#\u003cstrong\u003eRTT (Round Trip Time)\u003c/strong\u003e":"RTT(Round Trip Time)란, 요청(SYN)을 보낼 때부터 요청에 대한 응답(SYN+ACK)을 받을 때까지의 왕복 시간을 의미한다.\n즉, 아무리 keep-alive 라고 하지만 결국 TCP상에서 동작하는 HTTP의 특성상 Handshake 가 반복적으로 일어나게 되어 불필요한 RTT증가로 인해 네트워크 지연을 초래하여 성능이 저하되게 된다.\n예전에는 컨텐츠가 지금처럼 많지 않았기에 큰 부담은 아니었지만, 점점 컨텐츠가 증가하면서 이러한 레이턴시도 부담스러워 졌다.","server-push#\u003cstrong\u003eServer Push\u003c/strong\u003e":"HTTP 2.0에서는 클라이언트의 요청에 대해 미래에 필요할것 같은 리소스를 똑똑하게 미리 보낼 수 있다. 예를 들어 클라이언트로부터 HTML 문서를 요청하는 하나의 HTTP 메세지를 받은 서버는 그 HTML 문서가 링크하여 사용하고 있는 이미지, CSS 파일, JS 파일 등의 리소스를 스스로 파악하여 클라이언트에게 미리 push해�� 미리 브라우저의 캐시에 가져다 놓는다.\n즉, 서버는 요청하지도 않은 리소스를 미리 보내어 가까운 미래에 특정 개체가 필요할때 바로 사용 되도록 성능 향상을 이끌어 내는 것이다. 그래서 클라이언트가 HTML 문서를 파싱해서 필요한 리소스를 다시 요청하여 발생하게 되는 트래픽과 회전 지연을 줄여준다는 장점이 있다.","short-lived-connection#\u003cstrong\u003eShort-lived Connection\u003c/strong\u003e":"HTTP 1.0의 문제점은 비연결성(connectionless)로 인한 단기 커넥션(Short-lived connenction) 특징이다.\n즉, 커넥션 하나당 하나의 요청 하나의 응답 처리가 가능한 것을 말하는데, 서버에 자원을 요청할때마다 매번 새로운 연결을 해주어야 했다.\n1 Request \u0026 1 response 매번 새로운 연결로 성능 저하 매번 새로운 연결로 서버 부하 비용 증가 예를들어 웹페이지를 요청하면 html과 그에 딸린 css나 js 및 이미지 등등 수 많은 자원들이 다운로드되어 화면에 띄울 텐데, 각 자원들을 따로 따로 매번 TCP 연결하고 다운받고 연결 끊고 다시 연결하고 다운 받고 연결 끊는 것이다.\n그래서 HTTP 초기에는 모든 자료에 대해서 비연결성으로 각각의 자원에 대해 연결/응답/종료를 반복하다보니 느렸다.","spdy-프로토콜#\u003cstrong\u003eSPDY 프로토콜\u003c/strong\u003e":"사실 HTTP/2.0의 원조는 구글이 만든 새로운 프로토콜인 2009년 중반에 발표된 SPDY(스피디) 이다.\nHTTP/1.1의 메시지 포맷은 구현의 단순성과 접근성에 주안점을 두고 최적화 된 프로토콜이다 보니 성능은 어느 정도 희생시키지 않을 수 없었다. 때문에 더 효율적이고 빠른 HTTP가 필요했고, 이러한 요구에 만들어진 것이 구글의 SPDY 프로토콜이다. SPDY는 HTTP를 대체하는 프로토콜이 아니고 HTTP를 통한 전송을 재 정의하는 형태로 구현 되었다. 그래서 전송 계층의 구현만 변경하면 기존 HTTP 서버 프로그램을 그대로 SPDY에서 사용할 수 있었다.\n혁신적인 성능 향상에 힘입어 SPDY를 사용하는 사이트가 늘어나게 되었고, 이러한 상황을 주시하고 있던 HTTP-WG(HTTP working group)는 HTTP/2 표준을 선보이려는 노력을 했고 이 프로토콜의 초안을 SPDY 프로토콜을 채택하였다.\n이렇게 2012년부터 2015년까지 3년간의 노력으로 HTTP/2 표준이 발행되게 되었다. 그리고 몇년간 함께 발전해온 SPDY는 지원을 중단하며, HTTP2가 널리 채택된다는 말을 남기고 사라지게 되었다.","stream-prioritization#\u003cstrong\u003eStream Prioritization\u003c/strong\u003e":"HTTP 1.1에서 파이프라이닝 이라는 혁신적인 기술이 있었지만, 우선 순위 문제 때문에 HOLB(Head Of Line Blocking)가 발생하여 사장되었다고 HTTP 1.1 글에서 소개했었다.\nHTTP 2에서는 리소스간 의존관계(우선순위)를 설정하여 이런 문제를 해결하였다.\n위에서 봤던 것 처럼 HTTP 메세지가 개별 바이너리 프레임으로 분할되고, 여러 프레임을 멀티플렉싱 할 수 있게 되면서 요청과 응답이 동시에 이루어져 비약적인 속도 향상이 되었다.\n하지만 하나의 연결에 여러 요청과 응답이 뒤섞여 버려 패킷 순서가 엉망 징창이 되었다. 따라서 스트림들의 우선순위를 지정할 필요가 생겼는데, 클라이언트는 우선순위 지정 트리를 사용하여 스트림에 식별자를 설정함으로써 해결 하였다.\n각각의 스트림은 1-256 까지의 가중치를 갖음 하나의 스트림은 다른 스트림에게 명확한 의존성을 갖음 우선순위 지정 트리","stream-과-frame-단위#\u003cstrong\u003eStream 과 Frame 단위\u003c/strong\u003e":"HTTP/1.1에서는 HTTP 요청와 응답은 통짜 텍스트 Message 단위로 구성되어 있었다.\nHTTP/2 로 오면서 Message라는 단위 외에 Frame, Stream이라는 단위가 추가되었다.\nFrame : HTTP/2에서 통신의 최소 단위이며, Header 혹은 Data 가 들어있다. Message : HTTP/1.1과 마찬가지로 요청 혹은 응답의 단위이며 다수의 Frame으로 이루어진 배열 라인 Stream : 연결된 Connection 내에서 양방향으로 Message를 주고 받는 하나의 흐름 즉, HTTP/2 는 HTTP 요청을 여러개의 Frame들로 나누고, 이 frame들이 모여 요청/응답 Message가 되고, 그리고 Message는 특정 Stream에 속하게 되고, 여러개의 Stream은 하나의 Connection에 속하게 되는 구조이다.\nframe - message - stream - connection\n이 처럼 프레임 단위로 이루어진 요청과 응답 메세지는 하나의 스트림을 통해 이루어지며, 이러한 스트림들이 하나의 커넥션 내에서 병렬적로 처리된다. 하나의 커넥션에서 여러개의 스트림이 동시에 열리니 속도가 빠를수밖에 없다.\n좀더 Stream 통신 방식에 대해 깊이 파보자면, 모든 스트림은 31비트의 무부호 정수로 된 고유한 식별자를 갖는데, 스트림이 클라이언트에 의해 초기화되었다면 이 식별자는 반드시 홀수여야 하며 서버라면 짝수를 갖는 식으로 요청 스트림인지 응답 스트림인지 구분을 둔다.\n새로 만들어지는 스트림의 식별자는 이전에 만들어졌거나 예약된 스트림들의 식별자보다 커야 한다. 한번 사용한 스트림 식별자는 다시 사용할 수 없다.\n하나의 커넥션에서 오래 스트림을 사용하다보면 스트림에 할당될 수 있는 식별자가 고갈되기도 하는데, 그런 경우 커넥션을 다시 맺는 식으로 처리한다.","tcp-자체의-holb-head-of-line-blocking#\u003cstrong\u003eTCP 자체의 HOLB (Head Of Line Blocking)\u003c/strong\u003e":"분명 HTTP 2에서 HTTP 1.1의 파이프라이닝 HOLB 문제를 멀티플렉싱(Multiplexing)을 통해 해결했다고 하였다.\n하지만 기본적으로 TCP는 패킷이 유실되거나 오류가 있을때 재전송하는데, 이 재전송 과정에서 패킷의 지연이 발생하면 결국 HOLB 문제가 발생된다. TCP/IP 4 계층을 보면, 애플리케이션 계층(L4)에서 HTTP HOLB를 해결하였다 하더라도, 전송 계층(L3)에서의 TCP HOLB 를 해결한건 아니기 때문이다.","tcp의-holb#\u003cstrong\u003eTCP의 HOLB \u003cstrong\u003e(Head Of Line Blocking)\u003c/strong\u003e\u003c/strong\u003e":"이처럼 HTTP 레이어의 HOL Blocking 은 해결됬지만, 문제는 TCP 레이어의 HOL Blocking 문제가 여전히 잔존해 있었던 것이다.\nHTTP/2를 사용하는 일반적인 브라우저는 TCP 연결 한개로 수십, 수백 개의 스트림 데이터를 병렬 전송을 한다. 그런데 만일 두 엔드포인트 사이 네트워크 어딘가에서 하나의 패킷이 빠지거나 없어진다면, 없어진 패킷을 다시 전송하고 목적지를 찾는 동안 전체 TCP 연결이 중단되게 된다. 즉, HTTP/2에서 스트림에서 여러가지 프레임들이 뒤 섞여 이동되게 되는데, 만일 어느 하나의 프레임에 문제가 ���기면 상관없는 그 뒤의 프레임까지 영향이 가게 된다. 따라서 결국은 HTTP의 HOLB처럼 스트림 내 패킷들은 전체가 지연이 되게 된다.\n거기다가 HTTP/2는 1개의 TCP 커넥션으로 전부를 처리하고 있기 때문에 패킷 손실률이 증가하면 여러 개의 TCP를 사용하는 HTTP/1.1보다 성능 저하가 커질 수 있다.","udp의-보안적인-문제#\u003cstrong\u003eUDP의 보안적인 문제\u003c/strong\u003e":"DNS에서 TCP나 UDP를 53포트를 이용해 통신하게 되는데, 53 포트가 아닌 UDP 트래픽이 최근에는 도스 공격에 주로 사용되기 때문에 많은 서비스들에서 차단하거나 속도를 제한하고 있다.\n그래서 QUIC에서는 초기 패킷이 최소 1200바이트여야 한다는 조건과 서버가 클라이언트로부터 응답 패킷을 받지 않으면 요청 크기의 3배 이상은 절대 보내면 안 된다는 프로토콜의 제약사항으로 이를 해결하려고 노력중이다.\n기존��도 HTTP/2의 여러 보안 취약점이 발견되어 모든 업체가 이에 대한 보안 패치를 적용한 사례가 있듯이, 이처럼 새로운 기술이 나오면 보안 문제는 항상 대두되길 마련이다.\n물론 이러한 우려점들은 QUIC도 버전이 업데이트 됨에 따라 극복될 가능성이 있다.\nHTTP/3도 점점 발전해 나갈것이고, QUIC가 사장되고 또다른 프로토콜이 나온다고 할지라도, 이제는 더이상 HTTP는 TCP라는 이야기도 바뀌지 않을꺼라 생각된다.","기존-체계-호환성-문제#\u003cstrong\u003e기존 체계 호환성 문제\u003c/strong\u003e":"HTTP/1.1 이나 HTTP/2 기반의 프론트엔드단 최적화를 이미 적용한 기업의 경우 QUIC 도입에 부담스러울 수 있다.\n예를들어 브라우저의 병렬 다운로드를 통해 리소스를 빠르게 받아오는 도메인 분할(domain sharding) 기법을 이미 적용하여 최적화를 시킨 기업은 오히려 멀티플렉싱 기반의 HTTP/2 혹은 HTTP/3에서 성능이 반감될 수 있다.\n또한 브라우저의 콘텐츠 Prefetch 기능을 적용한 경우, 이를 Server Push 기능으로 변경해야 할지에 대한 기술적인 판단과 충분한 성능 비교 테스트가 필요하게 된다. ​","길다란-커넥션-유지로-인한-개인정보-누출-우려#\u003cstrong\u003e길다란 커넥션 유지로 인한 개인정보 누출 우려\u003c/strong\u003e":"HTTP 2.0은 기본적으로 성능을 위해 클라이언트와 서버 사이의 커넥션을 오래 유지하는 것을 염두에 두고 있다.\n하지만 이것은 개인 정보의 유출에 악용될 가능성이 있다. 이는 HTTP/1.1에서의 Keep-Alive도 가지고 있는 문제이기도 하다.","네트워크가-변경-되도-연결이-유지#\u003cstrong\u003e네트워크가 변경 되도 연결이 유지\u003c/strong\u003e":"TCP의 경우 클라이언트와 서버가 서로를 구분하기 위해서는 클라이언트 IP, 클라이언트 PORT, 서버 IP, 서버 PORT, 이렇게 네 가지가 필요하다. 그래서 클라이언트의 IP가 바뀌는 상황이 발생하면 연결이 끊어져 버린다.\n우리가 핸드폰을 들고 와이파이존에서 LTE 데이터를 사용하게 됐을 때, 동영상 끊김과 같이 일시적 지연이 일어나는 이유는 클라이언트 IP가 이때 바뀌기 때문이다. 그래서 다시 연결을 생성하기 위해 결국 핸드쉐이크 과정을 다시 거쳐야한다는 것이고, 이 과정에서 다시 지연시간이 발생하게 되는 것이다.","더욱-향상된-멀티플렉싱#\u003cstrong\u003e더욱 향상된 멀티플렉싱\u003c/strong\u003e":"HTTP/3도 당연히 HTTP/2와 같은 멀티플렉싱을 지원한다.\n그리고 독립 스트림 방식으로 기존의 멀티플렉싱을 더욱 강화시켰다고 보면 된다.","독립-스트림으로-holb-단축#\u003cstrong\u003e독립 스트림으로 HOLB 단축\u003c/strong\u003e":"그래서 TCP를 버려버리고 새로 QUIC 프로토콜로 구축해서 아예 스트림 자체를 독립적으로 여러개로 나누어서 처리하도록 하였다. 이를 독립 스트림이라고 한다.\nQUIC 연결을 통해 두 가지 다른 스트림을 설정했을 때, 이들을 독립적으로 다루므로 만약 특정 스트림에서 HOLB가 발생하더라도, 다른 스트림에는 영향을 미치지 않는다.","무거운-헤더-구조와-중복#\u003cstrong\u003e무거운 헤더 구조와 중복\u003c/strong\u003e":"http/1.1의 헤더에는 많은 메타정보들이 저장되어져 있다. 또한 해당 도메인에 설정된 cookie정보도 매 요청시 마다 헤더에 포함되어 전송되기 때문에 오히려 전송하려는 값보다 헤더 값이 더 큰 경우가 비일비재 하였다.\n그리고 지속 커넥션 속에서 주고 받는 연속된 요청 데이터가 중복된 헤더값를 가지고 있는 경우가 많아 쓸데없는 메모리 자원도 낭비하게 되는 꼴이 되었다.","보안을-더욱-강화#\u003cstrong\u003e보안을 더욱 강화\u003c/strong\u003e":"HTTP/3와 그 기반 기술인 QUIC은 TLS 암호화를 기본적으로 사용한다.\n물론 UDP와 TLS가 결합된 기술로는 DTLS라는 기술도 있지만 ‘TCP의 재구현’이 목표 중 하나인 QUIC와는 지향하는 바가 다르다.\n이처럼 기본적으로 QUIC 내에 TLS 이 포함되어있기 때문에 TCP와 달리 헤더 영역도 같이 암호화된다.\n기존에 암호화되지 않던 영역까지 암호화에 포함해 보안성을 더 강화하였다.","스트림-우선순위-통신-과정#\u003cstrong\u003e스트림 우선순위 통신 과정\u003c/strong\u003e":"클라이언트는 서버에게 스트림을 보낼때, 각 요청 자원에 가중치 우선순위를 지정하고 보낸다. 그렇게 요청 받은 서버는 우선순위가 높은 응답이 클라이언트에 우선적으로 전달될 수 있도록 대역폭을 설정한다. 응답 받은 각 프레임에는 이것이 어떤 스트림인지에 대한 고유한 식별자가 있어, 클라이언트는 여러개의 스트림을 interleaving을 통해 서로 끼워놓는 식으로 조립한다. 최신 브라우저들은 자원의 종류, 페이지가 로드된 위치 그리고 이전 페이지 방문에서 학습한 결과에 따라 자원 요청의 우선순위를 결정하기도 한다.","암호화로-네트워크-제어가-힘듬#\u003cstrong\u003e암호화로 네트워크 제어가 힘듬\u003c/strong\u003e":"QUIC는 기존에는 암호화하지 않던 헤더 필드도 암호화한다. 그래서 이런 헤더의 정보를 사용하는 ISP나 네트워크 중계회사들은 기존에 암호화하지 않던 헤더 필드 영역들을 읽을 수 없어 네트워크 혼잡을 관리하기 위한 네트워크를 최적화하기 힘들다. 예를 들어 패킷이 ACK인지 재전송인지 알 수 없다. RTT 추정 은 더 어렵다.\n이러한 이유로 기업들이 HTTP 3 도입을 주저하고 있다.","암호화로-리소스가-많이-듬#\u003cstrong\u003e암호화로 리소스가 많이 듬\u003c/strong\u003e":"QUIC은 패킷별로 암호화를 한다.\n이는 기존의 TLS-TCP에서 패킷을 묶어서 암호화하는 것보다 더 큰 리소스 소모를 불러올 수 있다는 단점이 있다.","어째서-tcp가-아닌-udp인가-#\u003cstrong\u003e어째서 TCP가 아닌 UDP인가 ���\u003c/strong\u003e":"","여전한-rtt-round-trip-time#\u003cstrong\u003e여전한 RTT (Round Trip Time)\u003c/strong\u003e":"아무리 혁신적으로 개선되었다 하더라도, HTTP 1.1 이나 HTTP 2는 여전히 TCP를 이용하기 때문에 Handshake의 RTT(Round Trip Time)로인한 지연 시간(Latency)이 발생한다. 결국 원초적으로 TCP로 통신하는게 문제인 것이다.","연결-시-레이턴시-감소#\u003cstrong\u003e연결 시 레이턴시 감소\u003c/strong\u003e":"기존 TLS+TCP에서는 TLS 연결을 위한 핸드쉐이크와 TCP를 위한 핸드쉐이크가 각각 발생했다.\n그래서 TCP는 연결을 생성하기 위해 기본적으로 1 RTT 가 필요하고, 여기에 TLS를 이용한 암호화 통신까지 한다면 총 3 RTT가 필요하게 된다.\nRTT (Round Trip Time)\nRTT(Round Trip Time)란, 요청(SYN)을 보낼 때부터 요청에 대한 응답(SYN+ACK)을 받을 때까지의 왕복 시간을 의미한다.\nQUIC에서는 이를 한단계로 줄였다.\nUDP 위에서 동작하는 QUIC는 통신을 시작할 때 3 Way Handshake 과정을 거치지 않아도 되기 때문에 첫 연결 설정에 1 RTT만 소요된다. 그 이유는 연결 설정에 필요한 정보와 함께 데이터도 보내버리기 때문이다.\nQUIC 내에 아예 TLS 인증서를 내포하고 있기 때문에, 최초의 연결 설정에서 필요한 인증 정보와 데이터를 함께 전송한다. 그래서 클라이언트가 서버에 어떤 신호를 한번 주고, 서버도 거기에 응답하기만 하면 바로 본 통신을 시작할 수 있다는 것이다\n최초 Connection 시\n위의 그림에서 볼 수 있듯이 TCP+TLS는 서로 자신의 세션 키를 주고 받아 암호화된 연결을 성립하는 과정을 거치고 나서야 세션 키와 함께 데이터를 교환하기 때문에 핸드쉐이크 과정이 여러번 발생하게 된다.\n하지만 QUIC은 서로의 세션 키를 교환하기도 전에 데이터를 교환할 수 있기 때문에 연결 설정이 더 빠르다. 다만, 최초의 요청을 보낼 때는 클라이언트는 서버의 세션 키를 모르는 상태이기 때문에, 목적지인 서버의 Connection ID를 사용하여 생성한 특별한 키인 초기화 키(Initial Key)를 사용하여 통신을 암호화 한다.\n그리고 한번 연결에 성공했다면 서버는 그 설정을 캐싱해놓고 있다가, 다음 연결 때 캐시를 불러와 바로 연결을 하기 때문에 추가적인 핸드 쉐이크 없이 0 RTT만으로 바로 통신을 시작할 수도 있다는 장점도 있다. 재연결 Connection 시","잔존하던-holb-현상을-해결#\u003cstrong\u003e\u003cstrong\u003e잔존하던 HOLB 현상을 해결\u003c/strong\u003e\u003c/strong\u003e":"","중개자-캡슐화-공격#\u003cstrong\u003e중개자 캡슐화 공격\u003c/strong\u003e":"위에서 배웠듯이 HTTP 2.0은 헤더 필드의 이름과 값을 바이너리로 인코딩한다. 이를 다르게 말하면 HTTP 2.0 이 헤더 필드로 어떤 문자열이든 사용할 수 있게 해준다는 뜻이다.\n그래서 이를 악용하면 HTTP 2.0 메시지를 중간의 Proxy 서버가 HTTP 1.1 메시지로 변환할 때 메시지를 불법 위조할수 있다는 위험성이 있다. 다행히 거꾸로 HTTP/1.1 메시지를 HTTP/2.0 메시지로 번역하는 과정에서는 이런 문제가 발생하지 않는다.","패킷손실감지에걸리는시간단축#\u003cstrong\u003e패킷 손실 감지에 걸리는 시간 단축\u003c/strong\u003e":"HOLB 해결에 이어 QUIC는 흐름 제어하는 시간까지 단축하였다.\nQUIC도 TCP와 마찬가지로 전송하는 패킷에 대한 흐름 제어를 해야한다. QUIC는 기본적으로 TCP와 유사한 방법으로 패킷 손실을 탐지하지만 여기에 몇 가지 알고리즘 개선 사항을 추가하였다.\n예를들어 HTTP 2.0에서는 아래 그림과 같이 하나의 스트림에 A, B, C 패킷 프레임들이 비순서대로 전달될때, 만일 세번째 프레임에서 패킷 손실이 일어나면, 패킷 B만 중지되어야 하지만 위에서 배운바와 같이 전혀 연관없는 패킷 A와 C도 모두 막혀 대기를 해야된다.\n이러한 문제를 해결하기 위해 QUIC는 헤더에 패킷의 전송 순서를 나타내는 별도의 패킷 번호 공간을 부여했다.\n이를 이용해 QUIC는 패킷 번호를 파악해 개별 파일을 구분하여 중간에 패킷 로스가 발생해도 해당 파일의 스트림만 정지가 되도록 할 수 있다.\n하나의 스트림에서 문제가 발생한다고 해도 다른 스트림은 지킬 수 있게 되어 이런 문제에서 자유로워 졌다."},"title":"network 2차 과제"},"/06.university/network/university-network-quiz/":{"data":{"":"5번은 iterated query, recursive query 를 사용","중간고사#중간고사":"ack, nak : 비트 에러 대비용 seq : 순서 확인용 timeout : 패킷 손실 대비용\ntcp 에서 timeout 이 발생하면 timeout 이 발생한 패킷만 재전송한다( 잘 도착한 패킷은 버퍼링하기 때문에 필요없음 ) GBN, SR 의 원형은 받은 패킷번호를 ack vs TCP 는 받고난후 다음에 받을 패킷번호를 ack TCP RENO 32 - 14 = 18\n18 -\u003e 2^18\nNAT\n1. TDMA RAandom access csma/cd binary … 48"},"title":"university network quiz"},"/06.university/network/university-network/":{"data":{"":"","3계층#3계층":"FCFS Priority RR(round robin) weighted fair network neutality ( 망 중립성 )\n각 ISP 각 자원을 어떻게 분배할 것인가?\nprotecting free speech encouraging innovation, compatition link s","chapter4#chapter4":"보장된 전달 지연 제한 이내의 보장된 전달 순서화 패킷 전달 최소 대역폭 보장 보안 서비스","tcp#TCP":"","전송-4계층#전송 4계층":""},"title":"university network"},"/06.university/os/university-operating-system-quiz/":{"data":{"":"pcb(process control block) 에 포함된 정보 process state process number program counter and registers memory limits list of open files","10주차#10주차":"dining philosopher problem 에서 Deadlock 이 발생 -\u003e 이것의 해결방법 항상 적어도 한명의 철학자가 배가 고프지 않으면 된다 =\u003e Circular Wait 옆사람이 쥐고 있는 젓가락을 뺏어올 수 있으면 된다 =\u003e no preemtion 젓가락 두개를 동시에 가져올 수 없으면 젓가락을 가져가지 않으면 된다 =\u003e hold and wait deadlock 해결책 prevention 은 deadlock 이 발생할 수 있는 원인을 애초에 없애 버리는 기술이다 o avoid 기술은 deadlock 이 이미 발생했을 때 피해를 최소화 하는 방법이다 x =\u003e detection Detection 기술은 한 프로세스에게 리소스를 허용하면 deadlock 이 발생하는지 미리 감지하는 기술이다 x =\u003e avoid 다른문서 출력중인데 출력명령을 내리기위해 대기할 필요 없음 스풀링 4가지 조건은 필요조건( 충분조건 x , 필요충분조건 x )","12-주차#12 주차":"logical address space 맞는 설명 cpu 가 사용하는 주소 컴퓨터에 장착되어 있는 실제 메모리 크기 보다 클 수 있다 =\u003e virtual memory 실제와는 다른 추상적인 주소이다 MMU 는 레지스터에 저장된 base 주소를 더해서 메모리 상의 실제 주소를 찾아낸다 fixed partitioning 방법 에서는 프로세스 당 정해진 크기의 메모리가 할당되므로 프로세스가 사용하지 않는 공간이 생길 수 있는데 이 공간을 internal(내부) fragmentation(단편화) 이라고 부른다 반면 dynamic patritioning 방법에서는 프로세스에게 할당되는 공간 사이사아에 남는 공간이 생기는데 이른 external(외부) fragmentation(단편화) 라고 부른다 dynamic partitioning의 메모리 할당 전략에 대해서 맞는 것 First-fit: 요청 크기를 만족하는 첫 번째 가용 공간을 할당합니다 (위에서부터 탐색 가정). Best-fit: 요청 크기를 만족하면서 가장 크기가 비슷한 (즉, 남는 공간이 가장 적은) 가용 공간을 할당합니다. Worst-fit: 요청 크기를 만족하면서 가장 크기가 큰 가용 공간을 할당합니다. paging 기법 맞는 것 logical address 와 physical address space 를 분리하여 메모리를 유연하게 관리한다 cpu 가 바라보는 가용 용량과 실제 가용한 메모리 공간이 무관햊니다 page table 을 효과적으로 저장하고 읽어오기 우해서는 하드웨어의 도움이 필요하다 TLB(transiation lookaside buffer) 에 대해 맞는 것을 고르시오 캐시의 종류이야 하드웨어로 구현되어 있음 associative memory","6주차#6주차":"CPU를 연속적으로 사용하는 시간을 CPU burst 라고 한다 스케줄링 알고리즘의 목적으로 바람직한것 cpu 사용율을 최대화 throughput 을 최대화 average wating time 최대화 스케줄링에 대해 맞는것 preemtive 는 강제 중단 가능 non-preemtive 는 강제 중단 불가능 최근 운영체제는 preemtive 를 주로 사용 non-preemtive 알고리즘 SJF FCFS non-preemtive 에서 가장 average wating time 이 가장 작은 것은 shortest job first exponential moving average 과거의 데이터가 현재의 값에 영향을 미치고 최근 데이터가 더 영향이 더 큰 경우에 사용한다 값의 변화의 추이를 예측하는 데 사용된다 preemtive 스케줄링 SRTF Priorty Round Robin priorty 스케줄링의 단점 =\u003e starvation, 기아","7주차#7주차":"멀티레벨 queue 스케줄링에서는 각 큐가 일정비율로 CPU 를 할당받는다 =\u003e True process aging 을 구현할 수 있는 스케줄링 방법 =\u003e multilevel feedback queue 스케줄링 윈도우는 preemptive scheduling 을 사용 동시성 문제에 대해 맞는것 두개이상의 프로세스가 같은 리소스를 동시에 접근하려 할 때 발생 CPU 코어가 하나인 경우에도 발생한다 race condition 때문에 발생하기도 한다 critical section problem 으로 이해 할 수 있다 동시성 문제는 프로세스가 같은 변수를 동시에 읽으려고 할 때도 발생한다 =\u003e False critical section 은 하나의 프로세스만 들어갈 수 있다는 조건은 mutual exclution critical section에 아무도 없는데 계속 대기하는 상황은 Progress critical section 문제를 해결하고자 할때 Mutual exclution 을 만족하지 못하는 이유 locked = 0 or 1 lock 방식 알고리즘의 경우 여러 프로세스가 동시에 critical section에 들어 갈 수 있기 때문","9주차#9주차":"lock 방식은 mutual exclusion, bounded Waiting 만족하지 못한다 peterson solution의 한계는 critical section problem 이 이미 해결되었다고 가정한 후에 풀었다 critical section problem 를 해결하기 위해 interrupt 를 비활성화 하는 방법의 한계는 cpu 가 여러개인 경우 적용할 수 없고 결국 시스템의 성능이 저하된다 semaphore 접근을 위해 들어갈때 wait, 나갈 때 signal 을 부른다 semaphore 가 critical section 에 들어가기 위해 지속적으로 semaphore 의 현재값을 체크 할 수 있다 이것을 busy-wating(spin lock) 이라고 한다 semaphore 의 값이 -2 일 때 대기자 리스트에 2개의 프로세스가 대기중이다","중간고사#중간고사":"폰 노이만 구조가 이전과 다른점 : 코드영역(program)이 하드웨어가 아닌 메모리로 올라간다(소프트웨어 개념의 탄생)\n캐쉬를 통해 성능 향상이 가능한 이유 : priciple of locality : 비슷한 시간에 지역적으로 접근한다"},"title":"university operating system quiz"},"/06.university/os/university-operating-system/":{"data":{"":"","-mmap-함수-원형#🔧 \u003ccode\u003emmap()\u003c/code\u003e 함수 원형":"","-reader-프로세스--스레드-코드-수정-후#✅ Reader 프로세스 / 스레드 코드 (수정 후)":"// READER PROCESS while (TRUE) { wait(\u0026mutex); // mutex 잠금 (readcount 보호) readcount++; // reader 수 증가 if (readcount == 1) { wait(\u0026wrt); // 처음 읽는 reader면 writer 차단 } signal(\u0026mutex); // mutex 해제 // === 실제 데이터 읽기 영역 === printf(\"Reader is reading data\\n\"); // 여기서 데이터 읽기 수행 // ========================== wait(\u0026mutex); // 다시 mutex 잠금 readcount--; // reader 수 감소 if (readcount == 0) { signal(\u0026wrt); // 마지막 reader라면 writer에게 허가 } signal(\u0026mutex); // mutex 해제 }","-writer-프로세스--스레드-코드#✍️ Writer 프로세스 / 스레드 코드":"// WRITER PROCESS while (TRUE) { wait(\u0026wrt); // writer 잠금 확보 (다른 writer나 reader 모두 없어야 함) // === 실제 데이터 쓰기 영역 === printf(\"Writer is writing data\\n\"); // 여기서 데이터 쓰기 수행 // ========================== signal(\u0026wrt); // writer 작업 완료 후 잠금 해제 }","-각-인자-설명-및-가능한-값들#✅ 각 인자 설명 및 가능한 값들":"","-교착-상태-예방-deadlock-prevention#🛑 교착 상태 예방 (Deadlock Prevention)":"","-교착-상태-예방의-핵심-아이디어#✅ 교착 상태 예방의 핵심 아이디어:":"교착 상태는 네 가지 필수 조건이 모두 성립할 때 발생합니다. 따라서 이 중 하나라도 성립되지 않게 만들면 교착 상태를 예방할 수 있습니다.","-교착-상태-처리-방법-dealing-with-deadlock#💡 교착 상태 처리 방법 (Dealing with Deadlock)":"교착 상태를 다루는 일반적인 접근 방법에는 세 가지가 있습니다:\n교착 상태 예방 (Prevent deadlock) 시스템 설계 단계에서 교착 상태가 발생하지 않도록 조건을 강제함 교착 상태 회피 (Avoid deadlock) 런타임 동안 리소스 할당 상황을 분석하여 교착 상태가 생기지 않도록 주의해서 할당 교착 상태 탐지 및 복구 (Detect deadlock and recover) 교착 상태가 발생했음을 감지하고, 이를 해결하는 방식","-교착-상태의-4가지-필수-조건#🔁 교착 상태의 4가지 필수 조건:":"상호 배제 (Mutual Exclusion): 한 리소스는 동시에 한 프로세스만 사용 가능 보유 대기 (Hold and Wait): 이미 리소스를 가진 프로세스가 다른 리소스를 기다림 비선점 (No Preemption): 리소스는 프로세스가 스스로 반납하기 전에는 강제로 빼앗을 수 없음 순환 대기 (Circular Wait): A→B→C→…→A처럼 순환적으로 리소스를 기다리는 관계 존재","-목적#📌 목적:":"","-문제-정의-요약#✅ 문제 정의 요약":"여러 reader는 동시에 데이터를 읽을 수 있음. writer는 오직 하나만 접근 가능 먼저온 순서대로 reader 또는 writer 을 허용","-사용되는-세마포어#🧱 사용되는 세마포어":"sem_t mutex; // readcount 변수 보호용 (뮤텍스) sem_t wrt; // writer와 첫 번째 reader 간 경쟁 제어용 int readcount; // 현재 읽고 있는 reader 수","-슬라이드-11--12-피터슨의-해결책#### 슬라이드 11 \u0026amp; 12: 피터슨의 해결책":"","-슬라이드-13-교훈-및-문제점#### 슬라이드 13: 교훈 및 문제점":"","-슬라이드-14-해결책---인터럽트-비활성화#### 슬라이드 14: 해결책 - 인터럽트 비활성화":"","-슬라이드-15-16-17-해결책---원자적-명령어-testandset#### 슬라이드 15, 16, 17: 해결책 - 원자적 명령어 (TestAndSet)":"","-슬라이드-2-임계-구역-문제#### 슬라이드 2: 임계 구역 문제":"","-슬라이드-3-임계-구역의-일반적인-구조#### 슬라이드 3: 임계 구역의 일반적인 구조":"","-슬라이드-4-임계-구역-문제의-요구사항#### 슬라이드 4: 임계 구역 문제의 요구사항":"","-슬라이드-5--6-첫-번째-시도---lock-변수#### 슬라이드 5 \u0026amp; 6: 첫 번째 시도 - Lock 변수":"","-슬라이드-7--8-두-번째-시도---차례-지키기#### 슬라이드 7 \u0026amp; 8: 두 번째 시도 - 차례 지키기":"","-슬라이드-9--10-세-번째-시도---의도-확인#### 슬라이드 9 \u0026amp; 10: 세 번째 시도 - 의도 확인":"","-예시-코드-정리#🧪 예시 코드 정리":"","-예제-1-익명-공유-메모리-생성-프로세스-간-공유-가능#✅ 예제 1: 익명 공유 메모리 생성 (프로세스 간 공유 가능)":"","-예제-2-파일-전체-매핑-읽기-전용#✅ 예제 2: 파일 전체 매핑 (읽기 전용)":"","-정리표#📋 정리표":"","-주의사항#⚠️ 주의사항":"","1-1#\u003cstrong\u003e1-1. “Can occur every time the block is updated”\u003c/strong\u003e":"","1-2#\u003cstrong\u003e1-2. “Can occur when the block is replaced”\u003c/strong\u003e":"","1-2-1#\u003cstrong\u003e1-2-1. “Minimizes write operations”\u003c/strong\u003e":"","1-2-2#\u003cstrong\u003e1-2-2. “Leaves main memory in an obsolete state”\u003c/strong\u003e":"","1-block#(1) \u003cstrong\u003eBlock\u003c/strong\u003e":"","1-cache-size-캐시-크기#\u003cstrong\u003e1. Cache Size (캐시 크기)\u003c/strong\u003e":"","1-chooses-which-block-to-replace-when-a-new-block-is-to-be-loaded-into-the-cache#\u003cstrong\u003e(1) Chooses which block to replace when a new block is to be loaded into the cache\u003c/strong\u003e":"","1-complex-kernel#\u003cstrong\u003e(1) Complex kernel\u003c/strong\u003e":"","1-easier-to-extend-a-microkernel#\u003cstrong\u003e(1) Easier to extend a microkernel\u003c/strong\u003e":"","1-fast#\u003cstrong\u003e(1) Fast\u003c/strong\u003e":"","1-invisible-to-the-processors-programmer-os#\u003cstrong\u003e1. Invisible to the processors, programmer, OS\u003c/strong\u003e":"","1-line-number#(1) \u003cstrong\u003eLine Number\u003c/strong\u003e":"","1-lock-사용-첫-번째-시도--키를-가져가는-방식#\u003cstrong\u003e1. Lock 사용 (첫 번째 시도)\u003c/strong\u003e =\u0026gt; 키를 가져가는 방식":"use lock","1-mapping-function-매핑-함수#\u003cstrong\u003e1. Mapping Function (매핑 함수)\u003c/strong\u003e":"","1-memory-references-cluster-in-time-and-space#1. \u003cstrong\u003eMemory References Cluster in Time and Space\u003c/strong\u003e":"","1-microkernel-system-structure-마이크로커널-시스템-구조#\u003cstrong\u003e1. Microkernel System Structure (마이크로커널 시스템 구조)\u003c/strong\u003e":"","1-modules-모듈#\u003cstrong\u003e1. Modules (모듈)\u003c/strong\u003e":"","1-monolithic-system-structure-모놀리식-시스템-구조#\u003cstrong\u003e1. Monolithic System Structure (모놀리식 시스템 구조)\u003c/strong\u003e":"","1-most-modern-operating-systems-implement-kernel-modules#\u003cstrong\u003e(1) Most modern operating systems implement kernel modules\u003c/strong\u003e":"","1-moves-as-much-from-the-kernel-into#\u003cstrong\u003e(1) Moves as much from the kernel into “user” space\u003c/strong\u003e":"","1-performance-overhead-of-user-space-to-kernel-space-communication#\u003cstrong\u003e(1) Performance overhead of user space to kernel space communication\u003c/strong\u003e":"","1-put-every-os-functions-into-the-single-block-of-kernel#\u003cstrong\u003e(1) Put every OS functions into the single block of kernel\u003c/strong\u003e":"","1-replacement-algorithm-교체-알고리즘#\u003cstrong\u003e1. Replacement Algorithm (교체 알고리즘)\u003c/strong\u003e":"","1-similar-to-layers#\u003cstrong\u003e(1) Similar to layers\u003c/strong\u003e":"","1-void-addr#1. \u003ccode\u003evoid *addr\u003c/code\u003e":"","1-when-one-block-is-read-in-another-may-have-to-be-replaced#\u003cstrong\u003e(1) When one block is read in, another may have to be replaced\u003c/strong\u003e":"","1-write-policy-쓰기-정책#\u003cstrong\u003e1. Write Policy (쓰기 정책)\u003c/strong\u003e":"","1-다중-메모리-레벨#(1) 다중 메모리 레벨":"","1-메모리-계층-구조#(1) 메모리 계층 구조":"","1-메모리-모델과-원자성atomicity#\u003cstrong\u003e1. 메모리 모델과 원자성(Atomicity)\u003c/strong\u003e":"Peterson’s Solution은 공유 변수(flag 배열과 turn)에 대한 연산이 **원자적(Atomic)**으로 수행된다는 가정하에 동작합니다. 즉:\n각 프로세스가 flag[me] = true, turn = !me, 또는 while (flag[!me] \u0026\u0026 turn == !me) 같은 연산을 실행할 때, 중간에 다른 프로세스가 끼어들지 않아야 합니다. 만약 메모리 접근이나 변수 갱신이 비원자적으로 이루어진다면, 경쟁 상태(Race Condition)가 발생하여 상호 배제나 진행 조건이 깨질 수 있습니다.","1-상호-배제-조건-무효화-attacking-the-mutual-exclusion-condition#1️⃣ 상호 배제 조건 무효화 (Attacking the Mutual Exclusion Condition)":"해결 방안: 어떤 리소스는 여러 프로세스가 동시에 접근 가능하도록 설계\n예: 프린터 스풀링(Printer Spooling) 실제 프린터는 프린터 데몬(Daemon)만 접근 사용자는 파일을 스풀 영역에 저장하고 종료 → 동시 접근 방지 단점:\n모든 장치가 스풀링 가능한 것은 아님 (예: 키보드, 마우스 등) 리소스를 불필요하게 많이 점유하는 경우도 있음 원칙:\n리소스를 반드시 필요할 때만 할당 최소한의 프로세스만 해당 리소스를 점유하도록 제한","1-상호-배제mutual-exclusion---서로-배타적으로-실행해야-한다#1. \u003cstrong\u003e상호 배제(Mutual Exclusion)\u003c/strong\u003e =\u0026gt; 서로 배타적으로 실행해야 한다":"","1-시간적-지역성-temporal-locality#(1) 시간적 지역성 (Temporal Locality)":"","1-캐시cache의-구조#\u003cstrong\u003e1. 캐시(Cache)의 구조\u003c/strong\u003e":"","1단계-참조의-유효성-검사-check-validity#\u003cstrong\u003e1단계: 참조의 유효성 검사 (Check Validity)\u003c/strong\u003e":"페이지 폴트가 발생했다고 해서 무조건 페이지를 메모리로 가져오는 것은 아닙니다. 운영 체제는 먼저 이 메모리 접근 시도가 합법적인지를 판단해야 합니다. 유효-무효 비트가 ‘무효’인 이유는 두 가지일 수 있기 때문입니다.\n합법적이지만 메모리에 없는 경우 (Just not in memory): 프로세스가 자신의 논리 주소 공간 내에 있는 주소(예: 코드 영역, 데이터 영역, 스택 영역 등)에 접근했지만, 해당 페이지가 아직 디스크에서 물리 메모리로 로드되지 않은 경우입니다. 이것이 일반적인 요구 페이징 시나리오입니다. 불법적인 참조인 경우 (Invalid reference): 프로세스가 자신에게 할당된 논리 주소 공간의 범위를 벗어나는 주소에 접근하려고 시도한 경우입니다. 예를 들어, 4MB의 주소 공간을 할당받은 프로세스가 5MB 위치의 주소를 참조하려는 경우입니다. 이는 명백한 프로그래밍 오류이며, 메모리 보호(memory protection) 위반입니다. 운영 체제는 프로세스 제어 블록(Process Control Block, PCB) 등에 저장된 해당 프로세스의 메모리 할당 정보(예: 코드와 데이터 세그먼트의 시작 주소와 크기)를 참조하여, 폴트가 발생한 주소가 합법적인 범위 내에 있는지 검사합니다.\n검사 결과가 ‘불법’이면: 운영 체제는 더 이상 진행하지 않고 해당 프로세스를 강제 종료(abort)시킵니다. 이는 “세그멘테이션 폴트(Segmentation Fault)“와 같은 오류 메시지로 사용자에게 알려집니다. 검사 결과가 ‘합법’이면: 운영 체제는 다음 단계로 진행하여 페이지를 메모리로 가져올 준비를 합니다.","2-an-effective-strategy-is-to-replace-a-block-that-has-been-in-the-cache-the-longest-with-no-references-to-it#\u003cstrong\u003e(2) An effective strategy is to replace a block that has been in the cache the longest with no references to it\u003c/strong\u003e":"","2-benefits-장점#\u003cstrong\u003e2. Benefits (장점)\u003c/strong\u003e":"","2-benefits-장점-1#\u003cstrong\u003e2. Benefits (장점)\u003c/strong\u003e":"","2-block-size-블록-크기#\u003cstrong\u003e2. Block Size (블록 크기)\u003c/strong\u003e":"","2-communication-takes-place-between-user-modules-using-message-passing#\u003cstrong\u003e(2) Communication takes place between user modules using message passing\u003c/strong\u003e":"","2-data-is-organized-so-that-the-percentage-of-accesses-to-each-successively-lower-level-is-substantially-less-than-that-of-the-level-above#2. \u003cstrong\u003eData is Organized So That the Percentage of Accesses to Each Successively Lower Level is Substantially Less Than That of the Level Above\u003c/strong\u003e":"","2-easier-to-port-the-operating-system-to-new-architectures#\u003cstrong\u003e(2) Easier to port the operating system to new architectures\u003c/strong\u003e":"","2-inflexible#\u003cstrong\u003e(2) Inflexible\u003c/strong\u003e":"","2-interacts-with-other-memory-management-hardware#\u003cstrong\u003e2. Interacts with other memory management hardware\u003c/strong\u003e":"","2-least-recently-used-lru-algorithm#\u003cstrong\u003e2. Least Recently Used (LRU) Algorithm\u003c/strong\u003e":"","2-memory-address#(2) \u003cstrong\u003eMemory Address\u003c/strong\u003e":"","2-more-flexible#\u003cstrong\u003e(2) More flexible\u003c/strong\u003e":"","2-overall-similar-to-layers-but-with-more-flexible#\u003cstrong\u003e2. Overall, similar to layers but with more flexible\u003c/strong\u003e":"","2-parts-directly-interact#\u003cstrong\u003e(2) Parts directly interact\u003c/strong\u003e":"","2-size_t-length-또는-siz#2. \u003ccode\u003esize_t length\u003c/code\u003e (또는 siz)":"","2-tag#(2) \u003cstrong\u003eTag\u003c/strong\u003e":"","2-the-more-flexible-the-mapping-function-the-more-complex-is-the-circuitry-required-to-search-the-cache#\u003cstrong\u003e(2) The more flexible the mapping function, the more complex is the circuitry required to search the cache\u003c/strong\u003e":"","2-uses-object-oriented-approach#\u003cstrong\u003e(2) Uses object-oriented approach\u003c/strong\u003e":"","2-공간적-지역성-spatial-locality#(2) 공간적 지역성 (Spatial Locality)":"","2-데이터-이동#(2) 데이터 이동":"","2-두-가지-제약-조건#\u003cstrong\u003e2. 두 가지 제약 조건\u003c/strong\u003e":"","2-메인-메모리main-memory의-구조#\u003cstrong\u003e2. 메인 메모리(Main Memory)의 구조\u003c/strong\u003e":"","2-보유-대기-조건-무효화-attacking-the-hold-and-wait-condition#2️⃣ 보유 대기 조건 무효화 (Attacking the Hold-and-Wait Condition)":"해결 방안:\n프로세스가 실행 시작 시 필요한 모든 리소스를 미리 요청 실행 중에는 추가 리소스를 요청하지 못함 장점:\n프로세스가 실행 도중 리소스 대기를 하지 않아 교착 상태 발생 불가 단점:\n프로세스가 실행 전에 모든 리소스를 정확히 알기 어려움 리소스를 오랫동안 점유하면서 다른 프로세스가 대기하게 됨 (자원 낭비) 변형된 전략:\n새로운 리소스를 요청하기 전에 현재 가지고 있는 모든 리소스를 반납 그 후 필요한 모든 리소스를 다시 요청","2-접근-비율access-rate#(2) 접근 비율(Access Rate)":"","2-진행progress---아무도-안쓰면-쓰게-해야-한다#2. \u003cstrong\u003e진행(Progress)\u003c/strong\u003e =\u0026gt; 아무도 안쓰면 쓰게 해야 한다":"","2-턴turn-기반-접근법-두-번째-시도--끝나면-상대에게-양보#\u003cstrong\u003e2. 턴(Turn) 기반 접근법 (두 번째 시도)\u003c/strong\u003e =\u0026gt; 끝나면 상대에게 양보":"take turn","2-프로세스의-비선점성non-preemption#\u003cstrong\u003e2. 프로세스의 비선점성(Non-preemption)\u003c/strong\u003e":"Peterson’s Solution은 두 프로세스가 모두 임계구역 진입을 시도할 때, 프로세스가 중단되지 않고 자신의 코드를 완료할 수 있다는 가정하에 동작합니다. 즉:\n프로세스가 스케줄링 중에 강제로 선점(Preempted)되지 않아야 합니다. 만약 한 프로세스가 flag[me] = true 이후 turn = !me를 실행하기 전에 선점되면, 다른 프로세스가 잘못된 정보를 읽고 임계구역에 동시에 진입할 수 있습니다.","2단계-빈-프레임-확보-get-empty-frame#\u003cstrong\u003e2단계: 빈 프레임 확보 (Get Empty Frame)\u003c/strong\u003e":"이제 합법적인 페이지를 디스크에서 읽어와 담아둘 물리 메모리 공간, 즉 **빈 프레임(empty frame)**을 찾아야 합니다. 운영 체제는 현재 사용 가능한 빈 프레임들의 목록(free-frame list)을 관리하고 있습니다.\n만약 이 목록에 빈 프레임이 있다면, 간단히 하나를 할당받아 사용하면 됩니다. 만약 빈 프레임이 없다면? 이것이 바로 **페이지 교체(Page Replacement)**가 필요한 상황입니다. 운영 체제는 현재 메모리에 있는 페이지들 중에서 ‘희생될 페이지(victim page)‘를 하나 선택해야 합니다. 어떤 페이지를 희생시킬지 결정하는 정책을 페이지 교체 알고리즘(예: LRU, FIFO 등)이라고 하며, 이는 시스템 성능에 매우 큰 영향을 미칩니다. 희생될 페이지가 결정되면, 그 페이지가 차지하던 프레임을 비우고 새로운 페이지를 위한 공간으로 사용합니다.","3-block#(3) \u003cstrong\u003eBlock\u003c/strong\u003e":"","3-can-be-applied-across-more-than-two-levels-of-memory#3. \u003cstrong\u003eCan Be Applied Across More Than Two Levels of Memory\u003c/strong\u003e":"","3-detriments-단점#\u003cstrong\u003e3. Detriments (단점)\u003c/strong\u003e":"","3-detriments-단점-1#\u003cstrong\u003e3. Detriments (단점)\u003c/strong\u003e":"","3-each-core-component-is-separate#\u003cstrong\u003e(3) Each core component is separate\u003c/strong\u003e":"","3-hardware-mechanisms-are-needed-to-identify-the-least-recently-used-block#\u003cstrong\u003e(3) Hardware mechanisms are needed to identify the least recently used block\u003c/strong\u003e":"","3-int-prot---protection-접근-권한#3. \u003ccode\u003eint prot\u003c/code\u003e - Protection (접근 권한)":"","3-mapping-function-매핑-함수#\u003cstrong\u003e3. Mapping Function (매핑 함수)\u003c/strong\u003e":"","3-more-reliable-less-code-is-running-in-kernel-mode#\u003cstrong\u003e(3) More reliable (less code is running in kernel mode)\u003c/strong\u003e":"","3-reasons-for-its-existence#\u003cstrong\u003e3. Reasons for its existence:\u003c/strong\u003e":"","3-word-length#(3) \u003cstrong\u003eWord Length\u003c/strong\u003e":"","3-단일-프로세서-환경-또는-강력한-캐시-일관성#\u003cstrong\u003e3. 단일 프로세서 환경 또는 강력한 캐시 일관성\u003c/strong\u003e":"Peterson’s Solution은 단일 프로세서 환경이나 **강력한 캐시 일관성(Cache Coherence)**이 보장되는 다중 프로세서 환경에서만 안전하게 동작합니다. 즉:\n모든 프로세서가 동일한 메모리 값을 동일한 순서로 관찰해야 합니다. 만약 각 프로세서가 독립적인 캐시를 사용하고 동기화되지 않은 상태로 데이터를 읽거나 쓴다면, flag와 turn 값이 불일치하여 오류가 발생할 수 있습니다.","3-비선점-조건-무효화-attacking-the-no-preemption-condition#3️⃣ 비선점 조건 무효화 (Attacking the No Preemption Condition)":"해결 방안:\n리소스를 강제로 빼앗는 것 (선점) 문제점:\n일부 리소스는 중간에 선점하면 문제가 발생 예: 프린터 작업 중간에 리소스를 뺏으면 문서 출력이 불완전하게 됨 예: 데이터베이스 트랜잭션 도중에 중단되면 데이터 불일치 발생 결론:\n대부분의 시스템에서는 현실적이지 않은 방법","3-성능-최적화#(3) 성능 최적화":"","3-유한-대기bounded-waiting---대기시간의-제한ex--30ms-이상-기다리면-보장#3. \u003cstrong\u003e유한 대기(Bounded Waiting)\u003c/strong\u003e =\u0026gt; 대기시간의 제한(ex =\u0026gt; 30ms 이상 기다리면 보장)":"Computer Organization 폰 노이만 구조 폰 노이만 구조가 이전과 다른점 : 코드영역(program)이 하드웨어가 아닌 메모리로 올라간다(소프트웨어 개념의 탄생)\n메모리 계층 구조 위 내용은 컴퓨터 시스템에서 **메모리 계층 구조(Memory Hierarchy)**와 관련된 개념을 설명하고 있습니다. 특히, 프로세서가 메모리를 참조할 때 나타나는 **시간적/공간적 지역성(Temporal and Spatial Locality)**과 이를 기반으로 한 메모리 접근 패턴의 효율성을 다룹니다. 아래에서 각 항목을 상세히 설명하겠습니다.\n1. Memory References Cluster in Time and Space 이 문장은 메모리 참조가 **시간적 지역성(Temporal Locality)**과 **공간적 지역성(Spatial Locality)**이라는 두 가지 특성을 보인다는 것을 의미합니다. (1) 시간적 지역성 (Temporal Locality) 정의: 최근에 참조된 데이터가 다시 참조될 가능성이 높음. 예시: 프로그램이 특정 변수를 반복적으로 사용하는 경우, 해당 변수는 캐시 또는 레지스터에 남아 있는 것이 유리함. 응용: 캐시 메모리를 통해 자주 사용되는 데이터를 유지하여 성능을 향상시킴. (2) 공간적 지역성 (Spatial Locality) 정의: 어떤 메모리 주소가 참조되면 그 근처의 주소들도 곧 참조될 가능성이 높음. 예시: 배열이나 연속된 데이터 구조를 처리할 때, 프로세서는 연속된 메모리 위치를 순차적으로 접근함. 응용: 캐시 라인(Cache Line)을 통해 한 번에 여러 데이터를 미리 가져오는 방식으로 활용됨. 2. Data is Organized So That the Percentage of Accesses to Each Successively Lower Level is Substantially Less Than That of the Level Above 이 문장은 메모리 계층 구조의 기본 원칙을 설명합니다. 메모리 계층 구조는 다음과 같은 특징을 가집니다: (1) 메모리 계층 구조 컴퓨터 시스템은 다양한 종류의 메모리를 사용하며, 각 메모리는 속도, 크기, 비용의 관점에서 차이가 있음. 일반적으로 메모리 계층은 다음과 같이 구성됩니다: 레지스터(Register): 가장 빠르지만 크기가 작음. 캐시(Cache): L1, L2, L3 캐시로 나뉘며, 속도와 크기가 점진적으로 증가. RAM(Main Memory): 큰 용량을 제공하지만 상대적으로 느림. 디스크(Storage): 가장 느리지만 매우 큰 용량을 제공. (2) 접근 비율(Access Rate) 메모리 계층 구조에서는 더 낮은 수준의 메모리로 갈수록 접근 비율이 급격히 감소합니다. 예를 들어, 프로세서가 필요로 하는 데이터의 대부분은 L1 캐시에서 해결되며, L2 캐시로 넘어가는 비율은 그보다 적고, RAM으로 넘어가는 비율은 더욱 줄어듦. 이러한 접근 비율의 차이는 지역성 원칙 덕분에 가능해짐. (3) 효율성 메모리 계층 구조는 빠른 메모리를 적절히 활용하여 전체 시스템의 성능을 극대화합니다. 예를 들어, L1 캐시가 필요한 데이터를 제공할 확률이 90%이고, L2 캐시가 추가로 8%를 처리한다면, RAM에서 직접 데이터를 읽어야 하는 경우는 2%에 불과하게 됩니다. 3. Can Be Applied Across More Than Two Levels of Memory 메모리 계층 구조는 단순히 두 개의 메모리 레벨(예: 캐시와 RAM)에만 적용되는 것이 아니라, 여러 레벨에 걸쳐 적용될 수 있습니다. (1) 다중 메모리 레벨 현대 컴퓨터 시스템에서는 여러 레벨의 메모리가 존재하며, 각 레벨은 서로 다른 특성을 가짐: L1 캐시: 가장 빠르지만 작은 용량. L2 캐시: L1보다 느리지만 더 큰 용량. L3 캐시: L2보다 더 느리지만 더 큰 용량. RAM: 캐시보다 느리지만 매우 큰 용량. SSD/HDD: 가장 느리지만 영구 저장이 가능. (2) 데이터 이동 데이터는 필요한 경우에 따라 위계적으로 이동합니다. 예를 들어: 프로세서가 데이터를 요청하면 먼저 L1 캐시를 확인. L1 캐시에 없으면 L2 캐시를 확인. L2 캐시에도 없으면 L3 캐시, RAM, 디스크 순으로 검색. (3) 성능 최적화 각 메모리 레벨의 용량과 속도를 적절히 조합하여 전체 시스템의 성능을 최적화합니다. 예를 들어, 캐시 미스(Cache Miss)가 발생할 때마다 더 느린 메모리로 접근해야 하므로, 캐시 히트율(Cache Hit Rate)을 높이는 것이 중요합니다. 요약 및 결론 위 내용은 메모리 계층 구조와 지역성 원칙을 중심으로, 프로세서가 메모리를 참조할 때 나타나는 패턴과 이를 활용한 시스템 설계 원리를 설명합니다. 핵심 포인트는 다음과 같습니다:\n시간적/공간적 지역성은 메모리 참조 패턴의 기본 원칙이며, 이를 통해 캐시와 같은 고속 메모리를 효과적으로 활용할 수 있음. 메모리 계층 구조는 다양한 레벨의 메모리를 조합하여 속도와 용량의 균형을 맞춤. 접근 비율은 상위 메모리 레벨로 갈수록 높고, 하위 레벨로 갈수록 낮아짐. 이러한 원칙은 여러 레벨의 메모리에 걸쳐 적용되며, 전체 시스템의 성능을 최적화하는 데 기여함. 이러한 개념은 현대 컴퓨터 아키텍처에서 매우 중요한 역할을 하며, 캐시 설계, 메모리 관리, 성능 최적화 등 다양한 분야에서 활용됩니다.\ncache 1. Invisible to the processors, programmer, OS 번역: 프로세서, 프로그래머, 운영체제(OS)에 보이지 않음.\n설명: 이 문장은 특정 하드웨어나 메커니즘이 **투명(Transparent)**하다는 것을 의미합니다. “보이지 않는다\"는 것은 해당 메커니즘이 프로세서, 프로그래머, 또는 운영체제에 의해 직접적으로 인식되거나 제어되지 않는다는 뜻입니다. 예를 들어, **캐시(Cache)**는 프로세서와 메인 메모리 사이에서 데이터를 관리하는 하드웨어지만, 프로그래머나 운영체제가 이를 명시적으로 제어할 필요가 없습니다. 캐시는 자동으로 동작하며, 프로세서의 성능을 향상시키기 위해 배경에서 작동합니다. 2. Interacts with other memory management hardware 번역: 다른 메모리 관리 하드웨어와 상호작용함.\n설명: 이 문장은 해당 메커니즘이 독립적으로 동작하지 않고, 다른 메모리 관리 하드웨어와 협력하여 동작한다는 것을 강조합니다. 예를 들어: 캐시는 메인 메모리(RAM), 디스크, 또는 다른 계층적 메모리와 상호작용합니다. 캐시 미스(Cache Miss)가 발생하면, 다음 레벨의 메모리(예: L2 캐시 또는 RAM)에서 데이터를 가져옵니다. 이러한 상호작용은 메모리 계층 구조(Memory Hierarchy)의 핵심 원칙 중 하나입니다. 3. Reasons for its existence: 번역: 그 존재 이유:\n설명: 여기서 “그\"는 앞서 언급된 메커니즘(예: 캐시)을 의미합니다. 이 문장은 해당 메커니즘이 왜 필요한지에 대한 이유를 설명하기 위한 서론입니다. 아래에 나오는 세 가지 이유를 통해 이 메커니즘이 왜 중요한지를 구체적으로 설명합니다. 4. Processor must access memory at least once per instruction cycle 번역: 프로세서는 최소한 매 명령어 사이클마다 메모리에 접근해야 함.\n설명: 프로세서는 프로그램을 실행하기 위해 명령어(Instruction)를 읽고 실행해야 합니다. 명령어는 일반적으로 메모리(예: RAM)에 저장되어 있습니다. 따라서, 프로세서는 매 사이클마다 메모리에 접근하여 명령어를 가져와야 합니다. 문제는, 메모리 접근 속도가 프로세서의 처리 속도보다 훨씬 느릴 수 있다는 점입니다. 이를 해결하기 위해, 고속 메모리(예: 캐시)를 사용하여 메모리 접근 속도를 개선합니다. 5. Processor execution is limited by memory cycle time 번역: 프로세서의 실행은 메모리 사이클 시간에 의해 제한됨.\n설명: **메모리 사이클 시간(Memory Cycle Time)**은 메모리가 데이터를 읽거나 쓰는 데 걸리는 시간을 의미합니다. 메모리 사이클 시간이 길면, 프로세서가 데이터를 가져오거나 저장하는 데 시간이 많이 소요됩니다. 이로 인해 프로세서는 메모리 대기 시간(Memory Latency) 때문에 성능이 저하될 수 있습니다. 이를 해결하기 위해, 고속 메모리(예: 캐시)를 사용하여 메모리 접근 지연을 줄이고 프로세서 성능을 극대화합니다. 6. Exploit the principle of locality with a small, fast memory 번역: 작고 빠른 메모리를 통해 지역성 원칙을 활용함.\n설명: **지역성 원칙(Locality Principle)**은 프로세서가 메모리에 접근할 때 나타나는 패턴을 설명합니다: 시간적 지역성(Temporal Locality): 최근에 사용된 데이터는 다시 사용될 가능성이 높습니다. 공간적 지역성(Spatial Locality): 특정 메모리 위치 근처의 데이터도 곧 사용될 가능성이 높습니다. 이러한 지역성을 활용하기 위해, **작고 빠른 메모리(예: 캐시)**를 사용합니다. 캐시는 자주 사용되는 데이터를 임시로 저장하여, 프로세서가 메인 메모리에 직접 접근하지 않고도 데이터를 빠르게 가져올 수 있도록 합니다. 이는 메모리 접근 지연을 줄이고, 전체 시스템 성능을 향상시킵니다. 요약 및 결론 이 내용은 **캐시(Cache)**와 같은 메모리 관리 메커니즘의 중요성과 그 존재 이유를 설명합니다. 각 줄의 요점은 다음과 같습니다:\n투명성: 캐시는 프로세서, 프로그래머, 운영체제에 보이지 않으며, 자동으로 동작합니다. 상호작용: 캐시는 다른 메모리 관리 하드웨어(예: RAM, 디스크)와 상호작용하여 데이터를 관리합니다. 존재 이유: 프로세서는 매 명령어 사이클마다 메모리에 접근해야 합니다. 메모리 사이클 시간이 프로세서 성능을 제한합니다. 캐시는 지역성 원칙을 활용하여 메모리 접근 지연을 줄이고 성능을 향상시킵니다. $\\boxed{\\text{결론적으로, 이 내용은 캐시와 같은 메모리 관리 메커니즘이 왜 필요한지를 명확히 설명합니다.}}$\ncache vs main memory 캐시와 메인 메모리의 구조는 서로 다르며, 각각의 구성 요소는 데이터를 저장하고 관리하는 방식에서 차이를 보입니다. 아래에서 캐시와 메인 메모리의 구조를 비교하며 설명하겠습니다.\n1. 캐시(Cache)의 구조 캐시는 고속으로 동작하는 작은 메모리로, 메인 메모리에서 자주 사용되는 데이터를 임시로 저장합니다. 캐시의 구조는 다음과 같은 주요 요소로 구성됩니다:\n(1) Line Number 정의: 캐시 내부의 특정 위치를 식별하는 번호. 설명: 캐시는 여러 개의 **라인(Line)**으로 나뉘어 있으며, 각 라인은 메인 메모리의 데이터 블록을 저장할 수 있는 공간입니다. 예를 들어, 캐시가 64개의 라인을 가지고 있다면, 각 라인은 0부터 63까지의 고유 번호를 가집니다. 프로세서가 데이터를 요청할 때, 캐시는 이 번호를 사용하여 해당 데이터가 어느 라인에 있는지 확인합니다. (2) Tag 정의: 캐시 라인에 저장된 데이터가 메인 메모리의 어느 위치에 속하는지를 나타내는 정보. 설명: 캐시는 메인 메모리의 일부 데이터만 복사해 두기 때문에, 캐시 라인에 저장된 데이터가 메인 메모리의 어디에 해당하는지 알아야 합니다. 이를 위해 Tag 필드가 사용됩니다. Tag는 메인 메모리 주소의 상위 비트를 저장하여, 해당 데이터가 메인 메모리의 어느 블록인지 식별합니다. 예를 들어, 메인 메모리 주소가 0x1234이고, 캐시 라인에 저장된 Tag 값이 0x12라면, 이 데이터는 메인 메모리의 0x12xx 영역에 속함을 의미합니다. (3) Block 정의: 캐시 라인에 저장된 데이터 묶음. 설명: 캐시 라인에는 **블록(Block)**이라는 단위로 데이터가 저장됩니다. 블록은 메인 메모리에서 연속된 데이터(예: 여러 워드)를 포함하며, 일반적으로 4~64바이트 크기로 구성됩니다. 예를 들어, 블록 크기가 8워드(=32바이트)라면, 한 라인에는 8개의 워드가 저장됩니다. (4) Block Length (k Words) 정의: 블록에 포함된 워드의 개수. 설명: 블록 길이는 캐시 라인에 저장될 수 있는 데이터의 크기를 결정합니다. 예를 들어, 블록 길이가 k = 8이라면, 한 라인에는 8개의 워드가 저장됩니다. 블록 길이는 메모리 접근 효율성을 높이기 위해 설계되며, 공간적 지역성(Spatial Locality)을 활용합니다. 2. 메인 메모리(Main Memory)의 구조 메인 메모리는 시스템에서 가장 큰 용량을 가진 기본 메모리로, 프로그램과 데이터를 저장합니다. 메인 메모리의 구조는 다음과 같은 주요 요소로 구성됩니다:\n(1) Block 정의: 메인 메모리에서 연속된 데이터를 묶은 단위. 설명: 메인 메모리는 데이터를 블록(Block) 단위로 관리합니다. 블록은 캐시와 마찬가지로 연속된 데이터 묶음을 의미하며, 일반적으로 4~64바이트 크기로 구성됩니다. 예를 들어, 메인 메모리의 특정 위치에서 8워드(=32바이트)를 하나의 블록으로 정의할 수 있습니다. (2) Memory Address 정의: 메인 메모리의 특정 위치를 식별하는 주소. 설명: 메인 메모리의 모든 데이터는 고유한 주소를 가집니다. 주소는 일반적으로 바이트 단위로 지정되며, 예를 들어 0x1234와 같은 형식으로 표현됩니다. 프로세서가 데이터를 요청할 때, 메인 메모리 주소를 사용하여 해당 데이터를 찾습니다. (3) Word Length 정의: 메인 메모리에서 처리되는 기본 데이터 단위의 크기. 설명: 워드는 메인 메모리에서 읽거나 쓸 수 있는 최소 데이터 단위입니다. 워드 길이는 시스템 아키텍처에 따라 다릅니다. 예를 들어: 32비트 시스템에서는 워드 길이가 4바이트(32비트). 64비트 시스템에서는 워드 길이가 8바이트(64비트). 메인 메모리는 워드 단위로 데이터를 읽고 씁니다. 3. 캐시와 메인 메모리의 구조 차이 구분 캐시(Cache) 메인 메모리(Main Memory) 목적 메인 메모리보다 빠르게 데이터를 제공하기 위한 임시 저장소. 전체 프로그램과 데이터를 저장하기 위한 기본 메모리. 용량 매우 작음 (KB ~ MB 단위). 매우 큼 (GB 단위). 속도 매우 빠름 (나노초 단위). 상대적으로 느림 (캐시보다 약 10~100배 느림). 구성 요소 Line Number, Tag, Block, Block Length(k Words). Block, Memory Address, Word Length. 데이터 관리 단위 블록(Block) 단위로 데이터를 저장하며, Tag를 통해 메인 메모리 위치를 식별. 메모리 주소(Memory Address)를 기반으로 데이터를 관리. 지역성 활용 시간적/공간적 지역성을 활용하여 성능을 최적화. 지역성 원칙을 직접적으로 활용하지 않음. 요약 및 결론 캐시와 메인 메모리는 목적과 구조가 서로 다릅니다:\n캐시:\n고속으로 동작하며, 메인 메모리의 일부 데이터를 임시로 저장. Line Number, Tag, Block, Block Length로 구성. 지역성 원칙(Temporal \u0026 Spatial Locality)을 활용하여 성능을 최적화. 메인 메모리:\n대용량으로 동작하며, 전체 프로그램과 데이터를 저장. Block, Memory Address, Word Length로 구성. 캐시보다 느리지만, 모든 데이터를 저장할 수 있는 충분한 용량을 제공. $\\boxed{\\text{결론적으로, 캐시와 메인 메모리는 각각의 역할과 구조적 특징이 다르며, 이들의 협력으로 시스템 성능이 극대화됩니다.}}$\ncache design 캐시 설계는 컴퓨터 시스템의 성능에 큰 영향을 미치는 중요한 요소입니다. 캐시는 메인 메모리보다 빠르게 데이터를 제공하기 위해 사용되며, 이를 효율적으로 설계하기 위해서는 여러 가지 설계 요소를 고려해야 합니다. 아래에서 각 항목을 매우 상세히 설명하겠습니다.\n1. Cache Size (캐시 크기) 정의: 캐시 크기는 캐시가 저장할 수 있는 데이터의 총량을 의미합니다. 일반적으로 KB(킬로바이트) 또는 MB(메가바이트) 단위로 표현됩니다. 영향: 성능: 캐시 크기가 클수록 더 많은 데이터를 저장할 수 있으므로, 캐시 히트(Cache Hit) 확률이 증가합니다. 예: 32KB 캐시와 64KB 캐시를 비교했을 때, 64KB 캐시는 더 많은 데이터를 저장할 수 있어 성능이 개선될 가능성이 큽니다. 비용: 캐시 크기가 클수록 하드웨어 비용이 증가합니다. 고속 SRAM(Small Random Access Memory)을 사용하므로, 큰 캐시는 비용과 전력 소비를 증가시킵니다. 지연 시간(Latency): 캐시 크기가 너무 커지면, 탐색(Search) 시간이 증가할 수 있습니다. 설계 고려사항: 캐시 크기를 결정할 때는 비용, 성능, 전력 소비 간의 균형을 고려해야 합니다. 일반적인 캐시 크기: L1 캐시: 8KB ~ 64KB L2 캐시: 256KB ~ 8MB L3 캐시: 4MB ~ 32MB 이상 2. Block Size (블록 크기) 정의: 블록 크기는 캐시 라인(Line)에 저장되는 데이터의 양을 의미합니다. 일반적으로 워드(Word) 단위로 정의되며, 4~64바이트 범위에서 설정됩니다. 영향: 공간적 지역성(Spatial Locality): 블록 크기가 클수록 연속된 데이터를 한 번에 가져올 수 있으므로, 공간적 지역성을 효과적으로 활용할 수 있습니다. 예: 배열이나 연속된 데이터 구조를 처리할 때 유리함. 캐시 오버헤드: 블록 크기가 클수록 캐시 내부에 저장할 수 있는 라인(Line) 수가 줄어듭니다. 예: 32KB 캐시에서 블록 크기가 16바이트일 때와 64바이트일 때를 비교하면, 후자의 경우 더 적은 수의 라인이 존재하게 됩니다. 캐시 미스(Cache Miss): 블록 크기가 작으면 캐시 미스 발생 횟수가 증가할 수 있지만, 불필요한 데이터를 로드하지 않아 메모리 대역폭을 절약할 수 있습니다. 설계 고려사항: 블록 크기를 결정할 때는 공간적 지역성과 캐시 용량 사이의 균형을 고려해야 합니다. 일반적인 블록 크기: L1 캐시: 16~64바이트 L2/L3 캐시: 64~128바이트 3. Mapping Function (매핑 함수) 정의: 매핑 함수는 메인 메모리 주소가 캐시의 어느 라인(Line)에 저장될지를 결정하는 규칙입니다. 종류 및 특징: Direct Mapping (직접 매핑):\n메인 메모리의 특정 블록이 캐시의 특정 라인에만 매핑됩니다. 장점: 구현이 간단하고, 하드웨어 비용이 적음. 단점: 충돌(Collision)이 자주 발생하여 성능 저하 가능. 예: 두 개의 자주 사용되는 블록이 같은 캐시 라인을 공유하면, 계속해서 서로 교체되는 상황이 발생할 수 있음. Fully Associative Mapping (완전 연관 매핑):\n메인 메모리의 블록이 캐시의 어느 라인에든 저장될 수 있습니다. 장점: 충돌이 거의 없으며, 캐시 공간을 효율적으로 사용. 단점: 구현이 복잡하고, 탐색 시간(Search Time)이 길어질 수 있음. Set Associative Mapping (집합 연관 매핑):\n캐시를 여러 집합(Set)으로 나누고, 각 집합 내에서는 블록이 자유롭게 매핑됩니다. 예: 2-way Set Associative는 각 집합에 2개의 라인이 존재하며, 블록이 이 중 하나에 저장됨. 장점: Direct Mapping과 Fully Associative Mapping의 장점을 결합. 단점: 하드웨어 복잡도가 증가. 설계 고려사항: 매핑 방식은 충돌 최소화와 구현 복잡도 사이의 균형을 고려해야 합니다. 일반적으로 L1 캐시는 Direct Mapping, L2/L3 캐시는 Set Associative Mapping을 사용합니다. 4. Replacement Algorithm (교체 알고리즘) 정의: 캐시가 가득 찼을 때, 새로운 데이터를 저장하기 위해 기존 데이터를 어떤 순서로 교체할지를 결정하는 알고리즘입니다. 종류 및 특징: LRU (Least Recently Used):\n가장 오랫동안 사용되지 않은 데이터를 교체. 장점: 시간적 지역성을 잘 반영. 단점: 구현이 복잡하고, 하드웨어 비용이 증가. FIFO (First In First Out):\n가장 먼저 들어온 데이터를 교체. 장점: 구현이 간단. 단점: 최근에 사용된 데이터를 잘못 교체할 수 있음. Random Replacement:\n임의로 데이터를 선택하여 교체. 장점: 구현이 간단. 단점: 성능이 불규칙할 수 있음. 설계 고려사항: 교체 알고리즘은 성능과 구현 복잡도 사이의 균형을 고려해야 합니다. 일반적으로 LRU가 가장 많이 사용되지만, 하드웨어 비용을 절약하기 위해 FIFO나 Random Replacement도 사용될 수 있습니다. 5. Write Policy (쓰기 정책) 정의: 프로세서가 데이터를 쓰는 방법을 결정하는 정책입니다. 종류 및 특징: Write-Through:\n데이터를 캐시와 메인 메모리에 동시에 씁니다. 장점: 메인 메모리와 항상 일관성을 유지. 단점: 쓰기 작업이 많을 경우 성능 저하. Write-Back:\n데이터를 캐시에만 쓰고, 메인 메모리에는 나중에 업데이트. 장점: 쓰기 작업이 적어 성능 향상. 단점: 메인 메모리와 일관성 문제 발생 가능. 설계 고려사항: 쓰기 정책은 데이터 일관성과 성능 사이의 균형을 고려해야 합니다. 일반적으로 Write-Back이 더 많이 사용되지만, 실시간 시스템에서는 Write-Through가 선호될 수 있습니다. 6. Number of Cache Levels (캐시 레벨 수) 정의: 캐시 레벨 수는 계층적 메모리 구조에서 사용되는 캐시의 개수를 의미합니다. 일반적으로 L1, L2, L3 캐시로 구성됩니다. 영향: L1 캐시: 가장 빠르지만 용량이 작습니다. 프로세서와 직접 연결되어 있으며, 주로 명령어와 데이터를 분리하여 저장합니다(Instruc2on Cache와 Data Cache). L2 캐시: L1보다 느리지만 용량이 큽니다. L1 캐시 미스가 발생했을 때 데이터를 제공합니다. L3 캐시: L2보다 더 느리지만 용량이 큽니다. 여러 코어가 공유하며, 전체 시스템의 성능을 지원합니다. 설계 고려사항: 캐시 레벨 수는 성능과 비용 사이의 균형을 고려해야 합니다. 일반적으로 현대 CPU는 L1, L2, L3 캐시를 모두 사용합니다. 요약 및 결론 캐시 설계는 다음과 같은 요소들을 종합적으로 고려해야 합니다:\n캐시 크기: 성능과 비용의 균형을 맞춰야 함. 블록 크기: 공간적 지역성을 활용하면서 캐시 용량을 최적화. 매핑 함수: 충돌 최소화와 구현 복잡도 사이의 균형. 교체 알고리즘: 성능과 구현 복잡도 사이의 균형. 쓰기 정책: 데이터 일관성과 성능 사이의 균형. 캐시 레벨 수: 계층적 구조를 통해 성능과 비용의 균형을 맞춤. $\\boxed{\\text{결론적으로, 캐시 설계는 다양한 요소를 조합하여 시스템 성능을 최적화하는 복잡한 과정입니다.}}$\ncache mapping function 아래는 주어진 내용을 정확히 번역하고, 각 문장을 상세히 설명한 것입니다.\n번역 Mapping Function 블록이 어느 캐시 위치를 차지할지를 결정한다. 두 가지 제약 조건이 설계에 영향을 미침 한 블록을 읽어올 때, 다른 블록은 교체되어야 할 수도 있다. 매핑 함수가 더 유연할수록, 캐시를 탐색하는 데 필요한 회로가 더 복잡해진다. 상세한 설명 1. Mapping Function (매핑 함수) 정의: 매핑 함수는 메인 메모리의 특정 블록이 캐시의 어느 위치에 저장될지를 결정하는 규칙입니다. 예를 들어, 메인 메모리 주소 0x1234에 해당하는 데이터가 캐시의 어느 라인(Line)에 저장될지 매핑 함수가 결정합니다. 목적: 캐시는 메인 메모리보다 작기 때문에, 모든 메인 메모리 데이터를 동시에 저장할 수 없습니다. 따라서, 매핑 함수는 어떤 데이터가 캐시에 저장될지, 그리고 캐시 내에서 어디에 저장될지를 결정합니다. 중요성: 매핑 함수는 캐시의 성능과 효율성을 크게 좌우합니다. 잘못 설계된 매핑 함수는 충돌(Collision)을 증가시키고, 캐시 히트(Cache Hit) 확률을 낮출 수 있습니다. 2. 두 가지 제약 조건 (1) When one block is read in, another may have to be replaced 번역: 한 블록을 읽어올 때, 다른 블록은 교체되어야 할 수도 있다. 설명: 캐시는 용량이 제한적이므로, 새로운 데이터를 저장하려면 기존 데이터를 교체해야 하는 경우가 발생합니다. 이 과정은 **캐시 교체 정책(Replacement Policy)**에 따라 수행됩니다. 예: LRU(Least Recently Used), FIFO(First In First Out), Random Replacement 등. 문제점: 만약 자주 사용되는 데이터가 교체된다면, 성능 저하가 발생할 수 있습니다. 특히, 직접 매핑(Direct Mapping) 방식에서는 충돌(Collision)이 자주 발생하여 교체가 비효율적으로 이루어질 가능성이 큽니다. (2) The more flexible the mapping function, the more complex is the circuitry required to search the cache 번역: 매핑 함수가 더 유연할수록, 캐시를 탐색하는 데 필요한 회로가 더 복잡해진다. 설명: 매핑 함수의 유연성은 캐시의 성능을 향상시킬 수 있지만, 그만큼 하드웨어 구현이 복잡해집니다. 유연성(Flexibility): 직접 매핑(Direct Mapping): 가장 단순한 방식으로, 메인 메모리 블록이 캐시의 특정 라인에만 매핑됩니다. 장점: 구현이 간단하고, 탐색 시간이 짧음. 단점: 충돌이 자주 발생하여 성능 저하 가능. 완전 연관 매핑(Fully Associative Mapping): 메인 메모리 블록이 캐시의 어느 라인에든 저장될 수 있습니다. 장점: 충돌이 거의 없으며, 캐시 공간을 효율적으로 사용. 단점: 탐색(Search)이 복잡해져서 하드웨어 비용이 증가. 집합 연관 매핑(Set Associative Mapping): 캐시를 여러 집합(Set)으로 나누고, 각 집합 내에서는 블록이 자유롭게 매핑됩니다. 장점: Direct Mapping과 Fully Associative Mapping의 장점을 결합. 단점: 하드웨어 복잡도가 증가. 결론: 매핑 함수의 유연성을 높일수록, 캐시 탐색(Search)을 위한 비교 및 제어 회로가 더 복잡해집니다. 이를 위해 추가적인 하드웨어 리소스(예: 비교기, 제어 논리)가 필요하며, 이는 전력 소비와 비용을 증가시킵니다. 요약 및 결론 **매핑 함수(Mapping Function)**는 메인 메모리 블록이 캐시의 어느 위치에 저장될지를 결정하는 중요한 역할을 합니다.\n잘못 설계된 매핑 함수는 충돌을 증가시키고, 캐시 성능을 저하시킬 수 있습니다. 두 가지 제약 조건:\n교체 문제: 캐시가 가득 찼을 경우, 새로운 데이터를 저장하기 위해 기존 데이터를 교체해야 합니다. 이 과정은 캐시 교체 정책에 따라 수행됩니다. 복잡성 문제: 매핑 함수가 더 유연할수록, 캐시 탐색을 위한 하드웨어 회로가 더 복잡해집니다. 이는 비용과 전력 소비를 증가시키는 요인이 됩니다. 최적화:\n매핑 함수는 성능, 구현 복잡도, 비용 사이의 균형을 고려하여 설계해야 합니다. 일반적으로 현대 컴퓨터 시스템에서는 Set Associative Mapping 방식이 널리 사용되며, 이는 성능과 구현 복잡도 사이의 적절한 균형을 제공합니다. $\\boxed{\\text{결론적으로, 매핑 함수는 캐시 설계에서 매우 중요한 요소이며, 성능과 복잡성 사이의 균형을 맞추는 것이 핵심입니다.}}$\ncache mapping function replace algorithm 아래는 주어진 내용을 정확히 번역하고, 각 문장을 상세히 설명한 것입니다.\n번역 Replacement Algorithm (교체 알고리즘) 새로운 블록이 캐시에 로드될 때, 어느 블록을 교체할지를 선택합니다. Least Recently Used (LRU) 알고리즘: 효과적인 전략은 캐시에서 가장 오랫동안 참조되지 않은 블록을 교체하는 것입니다. 이를 위해 하드웨어 메커니즘이 필요하며, 이는 가장 최근에 사용되지 않은 블록을 식별하는 역할을 합니다. 상세한 설명 1. Replacement Algorithm (교체 알고리즘) 정의: 교체 알고리즘은 캐시가 가득 찼을 때, 새로운 데이터를 저장하기 위해 기존 데이터 중 어떤 블록을 교체할지를 결정하는 규칙입니다.\n캐시는 용량이 제한적이므로, 새로운 데이터를 저장하려면 기존 데이터를 제거해야 하는 경우가 발생합니다. 예: LRU(Least Recently Used), FIFO(First In First Out), Random Replacement 등. 목적:\n교체 알고리즘은 캐시 히트(Cache Hit) 확률을 최대화하면서 성능을 유지하기 위한 핵심 요소입니다. 잘못된 교체 알고리즘은 자주 사용되는 데이터를 잘못 교체하여 성능 저하를 초래할 수 있습니다. 2. Least Recently Used (LRU) Algorithm (1) Chooses which block to replace when a new block is to be loaded into the cache 번역: 새로운 블록이 캐시에 로드될 때, 어느 블록을 교체할지를 선택합니다. 설명: LRU 알고리즘은 “최근에 사용되지 않은 데이터\"를 교체 대상으로 선택합니다. 예를 들어, 캐시가 가득 찼을 때, 가장 오랫동안 참조되지 않은 블록을 제거하고 새로운 데이터를 저장합니다. 이 방식은 시간적 지역성(Temporal Locality)을 잘 반영하며, 자주 사용되는 데이터를 캐시에 유지할 가능성이 높습니다. (2) An effective strategy is to replace a block that has been in the cache the longest with no references to it 번역: 효과적인 전략은 캐시에서 가장 오랫동안 참조되지 않은 블록을 교체하는 것입니다. 설명: LRU 알고리즘의 핵심 아이디어는 시간적 지역성을 활용하는 것입니다. 최근에 사용된 데이터는 다시 사용될 가능성이 높습니다. 따라서, 오랫동안 참조되지 않은 데이터는 앞으로도 사용될 가능성이 낮다고 가정합니다. 예를 들어, 다음과 같은 시나리오를 고려해 보겠습니다: 캐시에 세 개의 블록(A, B, C)이 있고, A는 최근에 참조되었지만, B와 C는 오랫동안 참조되지 않았습니다. 이 경우, LRU 알고리즘은 B 또는 C를 교체 대상으로 선택합니다. (3) Hardware mechanisms are needed to identify the least recently used block 번역: 이를 위해 하드웨어 메커니즘이 필요하며, 이는 가장 최근에 사용되지 않은 블록을 식별하는 역할을 합니다. 설명: LRU 알고리즘을 구현하기 위해서는 하드웨어 지원이 필요합니다. 구현 방법: 카운터 기반 방식: 각 캐시 라인에 타임스탬프(시간 정보)를 할당하여, 마지막 참조 시간을 추적합니다. 예: 캐시 라인이 참조될 때마다 카운터 값을 업데이트하고, 가장 오래된 카운터 값을 가진 라인을 교체 대상으로 선택합니다. 스택 기반 방식: 스택(Stack) 자료구조를 사용하여, 가장 최근에 참조된 블록을 스택의 맨 위로 이동시키고, 가장 오래된 블록은 스택의 맨 아래에 위치하도록 관리합니다. 문제점: LRU 알고리즘은 매우 효과적이지만, 하드웨어 구현이 복잡하고 비용이 많이 듭니다. 특히, 캐시 크기가 클수록 탐색(Search)과 관리(Management)가 어려워집니다. 요약 및 결론 교체 알고리즘:\n새로운 데이터를 저장하기 위해 기존 데이터 중 어떤 블록을 교체할지를 결정하는 중요한 역할을 합니다. 잘못된 교체 알고리즘은 자주 사용되는 데이터를 잘못 교체하여 성능 저하를 초래할 수 있습니다. LRU 알고리즘:\n가장 오랫동안 참조되지 않은 블록을 교체 대상으로 선택합니다. 시간적 지역성을 잘 반영하며, 자주 사용되는 데이터를 캐시에 유지할 가능성이 높습니다. 하지만, 하드웨어 구현이 복잡하고 비용이 많이 드는 단점이 있습니다. 하드웨어 메커니즘:\nLRU 알고리즘을 구현하기 위해서는 하드웨어 지원(예: 카운터, 스택)이 필요합니다. 이를 통해 가장 최근에 사용되지 않은 블록을 식별하고, 효율적으로 교체할 수 있습니다. \\boxed{\\text{결론적으로, LRU 알고리즘은 캐시 성능을 극대화하는 데 효과적이지만, 구현 복잡도와 비용이 높다는 점을 고려해야 합니다.}}\ncache write policy 아래는 주어진 내용을 정확히 번역하고, 각 문장을 상세히 설명한 것입니다.\n번역 Write Policy (쓰기 정책) 블록이 업데이트될 때마다 발생할 수 있음. 블록이 교체될 때 발생할 수 있음. 쓰기 작업을 최소화함. 메인 메모리를 오래된 상태로 남겨둠. 상세한 설명 1. Write Policy (쓰기 정책) 정의: 쓰기 정책은 프로세서가 데이터를 수정(쓰기)할 때, 해당 데이터가 캐시와 메인 메모리에 어떻게 반영될지를 결정하는 규칙입니다. 캐시와 메인 메모리는 항상 일관성을 유지해야 하므로, 쓰기 정책은 매우 중요합니다. 대표적인 쓰기 정책으로는 Write-Through와 Write-Back이 있습니다. 1-1. “Can occur every time the block is updated” 번역: 블록이 업데이트될 때마다 발생할 수 있음. 설명: 이는 Write-Through 정책을 설명합니다. Write-Through: 프로세서가 데이터를 수정할 때마다, 해당 데이터를 캐시와 메인 메모리에 동시에 반영합니다. 장점: 메인 메모리와 캐시가 항상 일관성을 유지합니다. 데이터 손실 위험이 적습니다. 단점: 매번 메인 메모리에 쓰기를 수행하므로, 성능 저하가 발생할 수 있습니다. 특히, 쓰기 작업이 많은 경우 메인 메모리 액세스 시간이 병목 현상을 일으킬 수 있습니다. 1-2. “Can occur when the block is replaced” 번역: 블록이 교체될 때 발생할 수 있음. 설명: 이는 Write-Back 정책을 설명합니다. Write-Back: 프로세서가 데이터를 수정할 때, 해당 데이터는 캐시에만 저장됩니다. 메인 메모리에는 캐시 블록이 교체될 때만 데이터가 반영됩니다. 장점: 쓰기 작업이 메인 메모리에 직접 전달되지 않으므로, 성능이 향상됩니다. 특히, 쓰기 작업이 많은 경우 유리합니다. 단점: 메인 메모리와 캐시 간의 일관성 문제가 발생할 수 있습니다. 예를 들어, 시스템이 갑작스럽게 종료되면, 캐시에만 저장된 데이터가 손실될 수 있습니다. 1-2-1. “Minimizes write operations” 번역: 쓰기 작업을 최소화함. 설명: Write-Back 정책은 쓰기 작업을 최소화하는 데 초점을 맞춥니다. 캐시에만 데이터를 저장하고, 메인 메모리에는 블록 교체 시에만 데이터를 반영합니다. 따라서, 메인 메모리에 대한 쓰기 작업 횟수를 줄여 성능을 개선합니다. 반면, Write-Through 정책은 매번 메인 메모리에 쓰기를 수행하므로, 쓰기 작업이 많아질 가능성이 큽니다. 1-2-2. “Leaves main memory in an obsolete state” 번역: 메인 메모리를 오래된 상태로 남겨둠. 설명: Write-Back 정책에서는 메인 메모리가 캐시와 동기화되지 않은 상태로 남아 있을 수 있습니다. 예를 들어, 캐시에 수정된 데이터가 저장되어 있지만, 메인 메모리는 아직 이전 상태를 유지하고 있을 수 있습니다. 이를 **오래된 상태(Obsolete State)**라고 합니다. 이러한 문제는 다음과 같은 경우에 발생할 수 있습니다: 다른 프로세서나 장치가 메인 메모리에서 데이터를 읽으려 할 때, 잘못된 데이터를 참조할 가능성. 시스템 장애가 발생하면, 캐시에만 저장된 데이터가 손실될 가능성. 이를 해결하기 위해, Dirty Bit라는 메커니즘이 사용됩니다. Dirty Bit: 캐시 블록이 수정되었음을 표시하는 비트입니다. Dirty Bit가 설정된 블록은 메인 메모리로 데이터가 반영되어야 함을 나타냅니다. 요약 및 결론 쓰기 정책:\n쓰기 정책은 캐시와 메인 메모리 간의 데이터 일관성을 유지하는 중요한 역할을 합니다. 대표적인 정책으로는 Write-Through와 Write-Back이 있습니다. Write-Through:\n데이터를 매번 캐시와 메인 메모리에 동시에 반영합니다. 메인 메모리와 항상 일관성을 유지하지만, 성능 저하가 발생할 수 있습니다. Write-Back:\n데이터를 캐시에만 저장하고, 메인 메모리에는 블록 교체 시에만 반영합니다. 쓰기 작업을 최소화하여 성능을 향상시키지만, 메인 메모리가 오래된 상태로 남아 있을 수 있습니다. 메인 메모리의 오래된 상태:\nWrite-Back 정책에서는 메인 메모리가 캐시와 동기화되지 않은 상태로 남아 있을 수 있습니다. 이를 해결하기 위해 Dirty Bit와 같은 메커니즘이 사용됩니다. $\\boxed{\\text{결론적으로, 쓰기 정책은 데이터 일관성과 성능 사이의 균형을 맞추는 중요한 요소입니다.}}$\nOS microkernel System Structure 아래는 주어진 내용을 정확히 번역하고, 각 문장을 상세히 설명한 것입니다.\n번역 Microkernel System Structure (마이크로커널 시스템 구조) 커널에서 가능한 많은 기능을 “사용자 공간\"으로 이동시킴. 사용자 모듈 간의 통신은 메시지 전달(Message Passing)을 통해 이루어짐. 장점: 마이크로커널을 확장하기 쉽다. 새로운 아키텍처로 운영 체제를 포팅하기 쉽다. 더 신뢰할 수 있다 (커널 모드에서 실행되는 코드가 적음). 더 안전하다. 단점: 사용자 공간과 커널 공간 간 통신의 성능 오버헤드. 상세한 설명 1. Microkernel System Structure (마이크로커널 시스템 구조) (1) Moves as much from the kernel into “user” space 번역: 커널에서 가능한 많은 기능을 “사용자 공간\"으로 이동시킴. 설명: **마이크로커널(Microkernel)**은 최소한의 핵심 기능만 커널에 남기고, 나머지 기능은 사용자 공간(User Space)으로 이동시키는 설계 방식입니다. 커널은 기본적으로 다음과 같은 최소한의 기능만 수행합니다: 프로세스 간 통신(Inter-Process Communication, IPC) 낮은 수준의 메모리 관리 스케줄링(Scheduling) 하드웨어 추상화 파일 시스템, 장치 드라이버, 네트워크 스택 등은 사용자 공간에서 실행됩니다. 이는 Monolithic Kernel(모놀리식 커널)과 대비되며, 모놀리식 커널은 모든 서비스를 커널 공간에서 실행합니다. (2) Communication takes place between user modules using message passing 번역: 사용자 모듈 간의 통신은 메시지 전달(Message Passing)을 통해 이루어짐. 설명: 마이크로커널에서는 커널과 사용자 공간 간, 또는 사용자 공간 내부의 모듈 간 통신이 메시지 전달을 통해 이루어집니다. 메시지 전달(Message Passing): 데이터를 패킷 형태로 전송하여 다른 모듈과 통신하는 방식입니다. 예: 파일 시스템 요청이나 장치 드라이버와의 상호작용. 메시지 전달은 커널이 중개 역할을 하며, 이를 통해 각 모듈이 독립적으로 실행될 수 있습니다. 이 방식은 모듈 간의 결합도를 낮추고, 시스템의 유연성을 높이는 데 기여합니다. 2. Benefits (장점) (1) Easier to extend a microkernel 번역: 마이크로커널을 확장하기 쉽다. 설명: 마이크로커널은 최소한의 기능만 커널에 남기고, 나머지 기능은 사용자 공간에서 실행됩니다. 따라서, 새로운 서비스나 기능을 추가하려면 커널을 수정하지 않고 사용자 공간에서 새로운 모듈을 작성하면 됩니다. 예: 새로운 파일 시스템을 추가하거나, 새로운 장치 드라이버를 개발할 때 커널 재컴파일이 필요하지 않습니다. (2) Easier to port the operating system to new architectures 번역: 새로운 아키텍처로 운영 체제를 포팅하기 쉽다. 설명: 마이크로커널은 최소한의 하드웨어 의존적 코드만 커널에 포함합니다. 따라서, 새로운 하드웨어 아키텍처로 운영 체제를 이식(Porting)할 때, 커널 부분만 수정하면 됩니다. 사용자 공간의 모듈들은 하드웨어와 직접적인 연관이 없으므로, 재사용 가능합니다. (3) More reliable (less code is running in kernel mode) 번역: 더 신뢰할 수 있다 (커널 모드에서 실행되는 코드가 적음). 설명: 커널 모드에서 실행되는 코드는 시스템 전체에 영향을 미칠 수 있으므로, 버그가 발생할 경우 심각한 문제가 발생할 수 있습니다. 마이크로커널은 커널 모드에서 실행되는 코드를 최소화하므로, 잠재적인 버그가 발생할 확률이 줄어듭니다. 또한, 사용자 공간에서 실행되는 코드는 문제가 발생해도 시스템 전체가 다운되지 않으며, 복구가 용이합니다. (4) More secure 번역: 더 안전하다. 설명: 마이크로커널은 권한 분리를 강화합니다. 사용자 공간에서 실행되는 모듈들은 제한된 권한으로 동작하며, 커널에 접근할 수 없습니다. 따라서, 악성 코드가 시스템 전체에 영향을 미치는 위험을 줄일 수 있습니다. 3. Detriments (단점) (1) Performance overhead of user space to kernel space communication 번역: 사용자 공간과 커널 공간 간 통신의 성능 오버헤드. 설명: 마이크로커널에서는 사용자 공간과 커널 공간 간 통신이 메시지 전달을 통해 이루어집니다. 이 과정에서 다음과 같은 성능 오버헤드가 발생할 수 있습니다: 컨텍스트 전환(Context Switching): 사용자 모드와 커널 모드 간 전환이 필요함. 데이터 복사(Data Copying): 메시지를 전달하기 위해 데이터를 복사해야 함. 이러한 오버헤드는 특히 고성능이 요구되는 환경에서 문제가 될 수 있습니다. 반면, 모놀리식 커널은 모든 서비스가 커널 공간에서 실행되므로, 이러한 오버헤드가 적습니다. 요약 및 결론 마이크로커널 구조:\n커널에서 가능한 많은 기능을 사용자 공간으로 이동시켜, 최소한의 핵심 기능만 커널에 남깁니다. 사용자 모듈 간 통신은 메시지 전달을 통해 이루어집니다. 장점:\n확장성이 뛰어나며, 새로운 서비스를 쉽게 추가할 수 있습니다. 새로운 하드웨어 아키텍처로 이식하기 쉽습니다. 커널 모드에서 실행되는 코드가 적어 신뢰성과 보안성이 높습니다. 단점:\n사용자 공간과 커널 공간 간 통신의 성능 오버헤드가 발생합니다. 특히, 컨텍스트 전환과 데이터 복사로 인해 성능 저하가 발생할 수 있습니다. \\boxed{\\text{결론적으로, 마이크로커널 구조는 유연성과 보안성을 강화하지만, 성능 오버헤드라는 단점을 가지고 있습니다.}}\nMonolithic System Structure 아래는 주어진 내용을 정확히 번역하고, 각 문장을 상세히 설명한 것입니다.\n번역 Monolithic System Structure (모놀리식 시스템 구조) 모든 운영체제 기능을 단일 커널 블록에 포함시킴. 구성 요소들이 직접 상호작용함. 장점: 빠름. 단점: 복잡한 커널. 유연하지 않음. 상세한 설명 1. Monolithic System Structure (모놀리식 시스템 구조) (1) Put every OS functions into the single block of kernel 번역: 모든 운영체제 기능을 단일 커널 블록에 포함시킴. 설명: **모놀리식 커널(Monolithic Kernel)**은 운영체제의 모든 핵심 기능(예: 프로세스 관리, 메모리 관리, 파일 시스템, 장치 드라이버 등)을 하나의 큰 커널 내부에서 실행합니다. 이는 커널이 모든 서비스를 직접 처리한다는 것을 의미하며, 사용자 공간과 커널 공간의 명확한 분리가 없습니다. 예를 들어, Linux 커널은 모놀리식 구조를 따르며, 대부분의 기능이 커널 내부에서 동작합니다. (2) Parts directly interact 번역: 구성 요소들이 직접 상호작용함. 설명: 모놀리식 커널에서는 커널 내부의 다양한 구성 요소(예: 메모리 관리, 프로세스 스케줄링, 파일 시스템)가 서로 직접적으로 호출하거나 상호작용할 수 있습니다. 예: 파일 시스템 모듈이 메모리 관리 모듈을 직접 호출하여 데이터를 읽거나 쓸 수 있습니다. 이러한 직접적인 상호작용은 성능을 극대화하지만, 코드 간의 결합도(Coupling)가 높아져 유지보수가 어렵게 만듭니다. 2. Benefits (장점) (1) Fast 번역: 빠름. 설명: 모놀리식 커널은 모든 기능이 커널 내부에서 실행되므로, 사용자 공간과 커널 공간 간의 컨텍스트 전환(Context Switching)이나 메시지 전달(Message Passing)이 필요하지 않습니다. 따라서, 성능이 매우 빠릅니다. 예: 마이크로커널 구조에서는 사용자 공간과 커널 공간 간 통신으로 인해 오버헤드가 발생하지만, 모놀리식 커널에서는 이러한 오버헤드가 없습니다. 특히, 고성능이 요구되는 환경(예: 서버, 임베디드 시스템)에서 유리합니다. 3. Detriments (단점) (1) Complex kernel 번역: 복잡한 커널. 설명: 모놀리식 커널은 모든 기능이 하나의 커널 내부에서 실행되므로, 코드 규모가 매우 큽니다. 또한, 각 구성 요소 간의 직접적인 상호작용으로 인해 코드 간의 의존성이 높아지고, 유지보수가 어려워집니다. 예: 새로운 기능을 추가하거나 수정하려면 전체 커널을 재컴파일해야 할 수 있습니다. 이러한 복잡성은 버그(Bug) 발생 가능성을 높이며, 디버깅(Debugging)이 어려워질 수 있습니다. (2) Inflexible 번역: 유연하지 않음. 설명: 모놀리식 커널은 확장성(Extensibility)이 낮습니다. 새로운 하드웨어 아키텍처나 기능을 추가하려면 커널 코드를 수정하고 재컴파일해야 합니다. 또한, 특정 모듈(예: 파일 시스템, 장치 드라이버)을 독립적으로 개발하거나 테스트하기 어렵습니다. 반면, 마이크로커널 구조는 사용자 공간에서 모듈을 독립적으로 실행할 수 있으므로, 더 유연합니다. 요약 및 결론 모놀리식 커널 구조:\n모든 운영체제 기능을 단일 커널 내부에 포함시키고, 구성 요소들이 직접 상호작용합니다. 이는 성능을 극대화하지만, 복잡성과 유연성 부족이라는 단점을 가지고 있습니다. 장점:\n사용자 공간과 커널 공간 간 통신 오버헤드가 없으므로, 성능이 매우 빠릅니다. 단점:\n커널이 매우 복잡하고, 유지보수가 어렵습니다. 확장성이 낮아 새로운 기능이나 하드웨어 아키텍처를 추가하기 어렵습니다. \\boxed{\\text{결론적으로, 모놀리식 커널 구조는 성능이 뛰어나지만, 복잡성과 유연성 부족이라는 단점이 있습니다.}}\nmodule 아래는 주어진 내용을 정확히 번역하고, 각 문장을 상세히 설명한 것입니다.\n번역 Modules (모듈) 대부분의 현대 운영체제는 커널 모듈을 구현합니다. 객체 지향적 접근 방식을 사용합니다. 각 핵심 구성 요소는 분리되어 있습니다. 각 구성 요소는 알려진 인터페이스를 통해 다른 구성 요소와 통신합니다. 각 구성 요소는 필요할 때 커널 내에서 동적으로 로드됩니다. 전체적으로, 계층 구조와 유사하지만 더 유연합니다. 상세한 설명 1. Modules (모듈) (1) Most modern operating systems implement kernel modules 번역: 대부분의 현대 운영체제는 커널 모듈을 구현합니다. 설명: **커널 모듈(Kernel Module)**은 운영체제의 특정 기능을 독립적으로 구현한 소프트웨어 구성 요소입니다. 이는 운영체제의 핵심 기능을 확장하거나 수정하기 위해 사용됩니다. 예: Linux 커널은 다양한 모듈(예: 파일 시스템, 장치 드라이버 등)을 지원하며, 필요에 따라 동적으로 로드하거나 언로드할 수 있습니다. (2) Uses object-oriented approach 번역: 객체 지향적 접근 방식을 사용합니다. 설명: 커널 모듈은 객체 지향 프로그래밍(Object-Oriented Programming, OOP) 원칙을 따르며 설계됩니다. 각 모듈은 독립적인 객체처럼 동작하며, 명확한 경계와 역할을 가집니다. 객체 지향적 특징: 캡슐화(Encapsulation): 각 모듈은 자신의 데이터와 기능을 캡슐화하여 외부로부터 보호합니다. 재사용성(Reusability): 모듈은 다른 시스템에서도 재사용될 수 있습니다. 확장성(Extensibility): 새로운 기능을 추가하기 쉽습니다. (3) Each core component is separate 번역: 각 핵심 구성 요소는 분리되어 있습니다. 설명: 커널 모듈은 서로 독립적으로 설계되며, 각각의 모듈이 특정 기능을 담당합니다. 예: 파일 시스템 모듈, 네트워크 스택 모듈, 장치 드라이버 모듈 등이 각각 분리되어 있습니다. 이러한 분리는 코드 간의 결합도(Coupling)를 낮추고, 유지보수성을 높이는 데 기여합니다. (4) Each talks to the others over known interfaces 번역: 각 구성 요소는 알려진 인터페이스를 통해 다른 구성 요소와 통신합니다. 설명: 모듈 간의 상호작용은 표준화된 인터페이스를 통해 이루어집니다. 예: 파일 시스템 모듈이 메모리 관리 모듈과 통신할 때, 미리 정의된 API(Application Programming Interface)를 사용합니다. 이러한 방식은 모듈 간의 의존성을 줄이고, 독립적인 개발 및 테스트를 가능하게 합니다. (5) Each is loadable as needed within the kernel 번역: 각 구성 요소는 필요할 때 커널 내에서 동적으로 로드됩니다. 설명: 커널 모듈은 **동적 로딩(Dynamic Loading)**을 지원하므로, 필요할 때만 메모리에 로드됩니다. 예: USB 장치를 연결하면 관련된 드라이버 모듈이 동적으로 로드되고, 장치를 제거하면 모듈이 언로드됩니다. 이러한 동적 로딩은 리소스 사용을 최적화하고, 커널 크기를 줄이는 데 도움이 됩니다. 2. Overall, similar to layers but with more flexible (1) Similar to layers 번역: 계층 구조와 유사함. 설명: 커널 모듈은 **계층 구조(Layered Structure)**와 유사한 방식으로 작동합니다. 각 모듈은 특정 계층에서 실행되며, 하위 계층과 상호작용합니다. 예: 하드웨어 추상화 계층(Hardware Abstraction Layer, HAL)은 하위 계층(하드웨어)과 상호작용하고, 상위 계층(파일 시스템)에 서비스를 제공합니다. (2) More flexible 번역: 더 유연함. 설명: 커널 모듈은 계층 구조보다 더 유연합니다. 이유: 독립성: 각 모듈은 독립적으로 개발, 테스트, 로드, 언로드될 수 있습니다. 확장성: 새로운 모듈을 쉽게 추가하거나 기존 모듈을 수정할 수 있습니다. 동적 로딩: 모듈이 필요할 때만 로드되므로, 리소스를 효율적으로 사용할 수 있습니다. 예: 마이크로커널 구조와 유사한 유연성을 가지지만, 성능 오버헤드가 적습니다. 요약 및 결론 커널 모듈:\n커널 모듈은 운영체제의 특정 기능을 독립적으로 구현한 소프트웨어 구성 요소입니다. 객체 지향적 접근 방식을 사용하여 설계되며, 각 모듈은 분리되어 있고 표준화된 인터페이스를 통해 상호작용합니다. 유사점:\n커널 모듈은 계층 구조와 유사하게 작동하지만, 더 유연합니다. 장점:\n유연성: 독립적인 개발, 테스트, 로드, 언로드가 가능합니다. 확장성: 새로운 기능을 쉽게 추가하거나 수정할 수 있습니다. 효율성: 동적 로딩을 통해 리소스 사용을 최적화합니다. $\\boxed{\\text{결론적으로, 커널 모듈은 현대 운영체제에서 유연성과 확장성을 제공하는 중요한 구성 요소입니다.}}$\nPCB, TCB /** * 🔹 프로세스 상태 상수 * 프로세스(또는 스레드)가 가질 수 있는 상태를 나타냅니다. */ #define TASK_RUNNING 0 // 실행 중이거나 실행 가능한 상태 (큐에 등록됨) #define TASK_INTERRUPTIBLE 1 // 인터럽트 가능한 대기 상태 (시그널에 의해 깨어날 수 있음) #define TASK_UNINTERRUPTIBLE 2 // 인터럽트 불가능한 대기 상태 (예: 디스크 IO 대기) #define TASK_STOPPED 4 // 멈춤 상태 (SIGSTOP 등으로 멈춤) #define TASK_TRACED 8 // 디버거에 의해 추적 중인 상태 /** * 🔹 Forward Declaration * 아래 구조체들은 다른 헤더 파일에서 정의되며, 여기서는 포인터 사용을 위해 선언만 합니다. */ struct files_struct; // 열린 파일 디스크립터 정보 struct fs_struct; // 파일 시스템 관련 정보 (현재 디렉토리 등) struct signal_struct; // 시그널 핸들러 및 대기 시그널 목록 struct sched_entity; // CFS 스케줄러에 사용되는 스케줄링 엔티티 struct mm_struct; // 메모리 공간 정보 (코드, 스택, 힙 등 관리) struct vm_area_struct; // 가상 메모리 영역(VMA) 정보 struct cred; // 사용자/그룹 ID 및 권한 정보 (보안) /** * 🔹 struct thread_struct - 스레드 실행 컨텍스트 * CPU 레지스터 상태 및 실행 위치를 저장하는 구조체입니다. * 컨텍스트 스위칭(다른 스레드/프로세스로 전환) 시 사용됩니다. */ struct thread_struct { unsigned long sp; // 스택 포인터 (스택 전환용) unsigned long ip; // 명령 포인터 (프로그램 카운터) unsigned long fs, gs; // TLS(Thread Local Storage)에 사용되는 세그먼트 레지스터 unsigned long cr2, trap_no; // 페이지 폴트 발생 시 주소 및 예외 번호 unsigned long debugreg[8]; // 하드웨어 디버깅용 레지스터 (브레이크포인트 설정용) unsigned long kernel_gs_base; // 커널 모드에서 GS 레지스터 백업용 struct fpu fpu; // FPU 상태 (SSE / AVX 등 부동소수점 연산 처리) }; /** * 🔹 struct mm_struct - 메모리 관리 구조체 * 하나의 프로세스가 사용하는 전체 메모리 공간 정보를 저장합니다. * 코드 영역, 스택, 힙, mmap 등을 포함합니다. */ struct mm_struct { struct vm_area_struct *mmap; // 가상 메모리 영역(VMA) 연결 리스트 unsigned long start_code, end_code; // 코드 영역 시작 및 끝 주소 unsigned long start_stack; // 스택 시작 주소 unsigned long start_brk, brk; // 힙(heap)의 시작 주소 및 현재 크기 }; /** * 🔹 struct task_struct - 프로세스 또는 스레드의 전체 정보 * Linux 커널에서 하나의 실행 단위(스레드 또는 프로세스)를 나타내는 핵심 구조체입니다. * PCB(Process Control Block) + TCB(Thread Control Block)를 모두 포함합니다. */ struct task_struct { pid_t pid; // 고유한 스레드 ID (PID) pid_t tgid; // 스레드 그룹 ID — 같은 프로세스 내 모든 스레드가 공유 volatile long state; // 프로세스 상태: RUNNING, INTERRUPTIBLE, STOPPED, TRACED 등 struct list_head tasks; // 전체 프로세스 리스트에 연결된 노드 struct mm_struct *mm; // 메모리 관리 구조체 (코드/힙/스택 포함) struct files_struct *files; // 열린 파일 디스크립터 테이블 struct fs_struct *fs; // 파일 시스템 관련 정보 (현재 디렉토리 등) struct signal_struct *signal; // 시그널 처리 정보 및 대기 중인 시그널 목록 struct task_struct *real_parent; // 실제 부모 프로세스 (디버거가 아님) struct task_struct *parent; // 트레이싱 부모 (예: 디버거) struct list_head children; // 자식 프로세스 리스트 struct list_head sibling; // 형제 프로세스(같은 부모를 가진 다른 자식) 리스트 unsigned int flags; // 다양한 플래그 (PF_EXITING, PF_KTHREAD 등) int prio, static_prio, normal_prio; // 스케줄링 우선순위 정보 struct sched_entity se; // CFS 스케줄러용 스케줄링 엔티티 struct thread_struct thread; // CPU 레지스터 및 실행 컨텍스트 struct cred *cred; // 권한 정보 (UID, GID 등 보안 정보) u64 utime, stime; // 사용자 모드 시간, 커널 모드 시간 struct rcu_head rcu; // RCU 동기화용 구조체 (Read-Copy-Update) }; IPC shared Memory Message Passing Direct vs Indirect 프로세스들이 서로를 직접 지정하여 메시지를 전송하거나 수신 하는 방식입니다. 메시지는 메일박스 (Mailbox) 또는 포트(Port)를 통해 전달됩니다. , 프로세스 자신이 아니라 공유된 mailbox를 통해 통신 합니다. Blocking (Synchronous) vs Non-blocking (Asynchronous) 동기적 전송 vs 비동기적 전송 ㅇ IPC SHARE 아래는 mmap() 함수의 각 인자에 대한 상세한 설명과, 각각 사용할 수 있는 가능한 옵션, 그리고 예시입니다.\n🔧 mmap() 함수 원형 void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset); 📌 목적: mmap()은 파일이나 디바이스를 프로세스 주소 공간에 메모리 매핑하여 읽거나 쓸 수 있도록 해주는 시스템 콜입니다.\n파일을 메모리처럼 접근 가능하게 함 → 빠른 입출력 처리 가능 공유 메모리를 통해 여러 프로세스 간 통신(IPC) 가능 ✅ 각 인자 설명 및 가능한 값들 1. void *addr 요청하는 시작 주소 (NULL 권장) NULL: 커널이 적절한 위치에 할당 특정 주소 지정: 해당 주소 근처에 매핑 시도 (실제로 잘 사용되지 않음) 값 의미 NULL 커널이 자동으로 주소 선택 0x12345678 특정 주소에 매핑 시도 (권장되지 않음) 2. size_t length (또는 siz) 매핑할 데이터 크기 (바이트 단위) 보통 페이지 크기(4KB 등)의 배수로 설정해야 함 💡 예: 4096, 8192, 16384 등\n3. int prot - Protection (접근 권한) 메모리 영역에 대해 허용할 접근 권한 지정 플래그 의미 PROT_NONE 접근 금지 PROT_READ 읽기 허용 PROT_WRITE 쓰기 허용 PROT_EXEC 실행 허용 예시 조합 PROT_READ | PROT_WRITE // 읽기/쓰기 모두 가능 PROT_READ // 읽기 전용 PROT_EXEC // 실행 가능 코드 매핑 4. int flags - Mapping options 매핑 방식(공유 여부, 파일 기반/익명 등) 결정 플래그 의미 MAP_SHARED 수정사항이 다른 프로세스와 공유됨 MAP_PRIVATE Copy-on-write 방식으로 복사본 사용 MAP_ANONYMOUS 파일 없이 메모리만 생성 (file descriptor = -1) MAP_FIXED addr 강제 지정 (사용 권장 X) MAP_FILE 일반 파일 매핑 (기본값, 생략 가능) MAP_POPULATE 페이지 폴트를 피하기 위해 사전에 페이지 할당 MAP_HUGETLB, MAP_HUGE_2MB, MAP_HUGE_1GB huge page 사용 (성능 최적화) 자주 조합되는 패턴 // 파일 기반 공유 매핑 MAP_SHARED // 익명 공유 메모리 (IPC에 유용) MAP_SHARED | MAP_ANONYMOUS // 읽기 전용 파일 매핑 MAP_PRIVATE 5. int fd - File Descriptor 매핑할 파일의 디스크립터 (open()으로 열어야 함) MAP_ANONYMOUS를 사용하면 -1을 넣음 값 의미 -1 익명 메모리 (파일 없음) open(\"file.txt\", O_RDONLY) 실제 파일 매핑 6. off_t offset 파일 내에서 몇 번째 바이트부터 매핑할 것인지 반드시 페이지 경계(page-aligned)여야 함 (즉, 4096의 배수) 값 의미 0 파일 맨 처음부터 매핑 4096 4KB 이후부터 매핑 offset % getpagesize() != 0 오류 발생 🧪 예시 코드 정리 ✅ 예제 1: 익명 공유 메모리 생성 (프로세스 간 공유 가능) char *buffer = mmap(NULL, 4096, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_ANONYMOUS, -1, 0); ✅ 예제 2: 파일 전체 매핑 (읽기 전용) int fd = open(\"data.txt\", O_RDONLY); char *file_data = mmap(NULL, file_size, PROT_READ, MAP_PRIVATE, fd, 0); ⚠️ 주의사항 length는 페이지 크기의 배수여야 함 (보통 getpagesize() 리턴값인 4096) 성공 시 매핑된 주소 반환, 실패 시 (void *)-1 반환 반드시 munmap()으로 해제 필요 📋 정리표 인자 설명 가능한 값 예시 addr 매핑 시작 주소 NULL 또는 임의 주소 length 매핑할 크기 (byte) 4096, 8192 등 prot 접근 권한 PROT_READ, PROT_WRITE, PROT_EXEC, PROT_NONE flags 매핑 속성 MAP_SHARED, MAP_PRIVATE, MAP_ANONYMOUS, MAP_FIXED fd 파일 디스크립터 open() 결과 or -1 offset 파일 오프셋 0, 4096, … (페이지 경계) 필요하다면 실제 파일 매핑, huge page 사용 예제, 또는 에러 처리까지 포함해 드릴 수 있어요!\nCPU scheduling 번역 임계구역 문제(Critical-Section Problem)의 요구사항\n상호 배제(Mutual Exclusion) =\u003e 서로 배타적으로 실행해야 한다\n프로세스 Pi가 자신의 임계구역(Critical Section)에 있을 경우, 다른 모든 프로세스는 자신의 임계구역을 실행할 수 없다. 진행(Progress) =\u003e 아무도 안쓰면 쓰게 해야 한다\n현재 어떤 프로세스도 임계구역을 실행하고 있지 않고, 일부 프로세스들이 자신의 임계구역에 들어가기를 원할 때, 다음 프로세스 선택은 무기한으로 지연될 수 없다. 유한 대기(Bounded Waiting) =\u003e 대기시간의 제한(ex =\u003e 30ms 이상 기다리면 보장)\n한 프로세스가 자신의 임계구역에 들어가려고 요청한 후, 그 요청이 허용되기 전까지 다른 프로세스들이 임계구역에 들어가는 횟수에는 제한이 있어야 한다. 가정:\n각 프로세스는 0이 아닌 속도로 실행된다. n개의 프로세스 간의 상대적인 속도에 대한 가정은 없다. Requirements of Critical-Section Prob 중간고사 범위 설명 임계구역 문제는 다중 프로세스 환경에서 공유 자원(예: 변수, 파일 등)에 동시에 접근하는 것을 제어하기 위해 중요한 개념이다. 여러 프로세스가 동시에 임계구역에 진입하면 데이터 일관성(Data Consistency) 문제가 발생할 수 있기 때문에, 이를 방지하기 위한 세 가지 주요 요구사항이 있다.\n1. 상호 배제(Mutual Exclusion) =\u003e 서로 배타적으로 실행해야 한다 이 조건은 임계구역 문제의 핵심이다. 두 개 이상의 프로세스가 동시에 임계구역에 들어가는 것을 방지하여, 공유 자원에 대해 안전한 접근을 보장한다. 예를 들어, 두 프로세스가 동시에 같은 데이터를 수정하려고 하면 데이터가 손상될 수 있으므로, 이를 방지하기 위해 한 번에 하나의 프로세스만 임계구역에 진입하도록 해야 한다. 2. 진행(Progress) =\u003e 아무도 안쓰면 쓰게 해야 한다 이 조건은 시스템의 효율성을 보장하기 위한 것이다. 현재 임계구역을 사용 중인 프로세스가 없고, 임계구역에 진입하려는 프로세스가 있을 경우, 시스템은 적절히 다음 프로세스를 선택해야 한다. 만약 특정 프로세스가 계속해서 임계구역 진입을 차단한다면, 이는 “교착 상태(Deadlock)” 또는 “기아 상태(Starvation)“로 이어질 수 있다. 따라서 진행 조건은 이러한 문제를 방지하기 위해 필요하다. 3. 유한 대기(Bounded Waiting) =\u003e 대기시간의 제한(ex =\u003e 30ms 이상 기다리면 보장) 이 조건은 공정성을 보장하기 위한 것이다. 특정 프로세스가 임계구역에 진입하려고 요청한 후, 요청이 허용되기 전에 다른 프로세스들이 임계구역에 진입할 수 있는 횟수는 제한되어야 한다. 예를 들어, 어떤 프로세스가 무한히 기다리는 상황(기아 상태)이 발생하지 않도록 하기 위해, 각 프로세스는 일정 횟수 내에 임계구역에 진입할 기회를 가져야 한다.","3-의도intentions-확인-세-번째-시도--상대가-들어가고-싶으면-무조건-양보#\u003cstrong\u003e3. 의도(Intentions) 확인 (세 번째 시도)\u003c/strong\u003e =\u0026gt; 상대가 들어가고 싶으면 무조건! 양보":"check intentions","3-캐시와-메인-메모리의-구조-차이#\u003cstrong\u003e3. 캐시와 메인 메모리의 구조 차이\u003c/strong\u003e":"","3-효율성#(3) 효율성":"","3단계-페이지-스왑-인-swap-page-in#\u003cstrong\u003e3단계: 페이지 스왑 인 (Swap Page In)\u003c/strong\u003e":"빈 프레임이 확보되면, 운영 체제는 디스크 컨트롤러에게 I/O 요청을 보냅니다.\n폴트를 발생시킨 페이지가 디스크의 어느 위치에 저장되어 있는지 찾습니다. (이 정보는 보통 운영 체제가 관리하는 별도의 자료 구조에 있습니다.) 해당 위치의 데이터를 읽어서, 2단계에서 확보한 빈 프레임으로 **복사(load)**하라고 명령합니다. 이 디스크 I/O 작업은 CPU 속도에 비해 매우 느립니다. 수 밀리초(ms)가 걸릴 수 있습니다. 이 긴 시간 동안 CPU를 놀게 둘 수는 없으므로, 운영 체제는 페이지 폴트를 일으킨 프로세스의 상태를 ‘대기(waiting)’ 상태로 바꾸고, CPU를 다른 실행 가능한 프로세스에게 할당합니다(Context Switching). 이렇게 함으로써 시스템의 전반적인 효율성을 유지합니다.","4-block-length-k-words#(4) \u003cstrong\u003eBlock Length (k Words)\u003c/strong\u003e":"","4-each-talks-to-the-others-over-known-interfaces#\u003cstrong\u003e(4) Each talks to the others over known interfaces\u003c/strong\u003e":"","4-int-flags---mapping-options#4. \u003ccode\u003eint flags\u003c/code\u003e - Mapping options":"","4-more-secure#\u003cstrong\u003e(4) More secure\u003c/strong\u003e":"","4-peterson#\u003cstrong\u003e4. Peterson’s Solution (최종 해결책)\u003c/strong\u003e":"","4-processor-must-access-memory-at-least-once-per-instruction-cycle#\u003cstrong\u003e4. Processor must access memory at least once per instruction cycle\u003c/strong\u003e":"","4-replacement-algorithm-교체-알고리즘#\u003cstrong\u003e4. Replacement Algorithm (교체 알고리즘)\u003c/strong\u003e":"","4-순환-대기-조건-무효화-attacking-the-circular-wait-condition#4️⃣ 순환 대기 조건 무효화 (Attacking the Circular Wait Condition)":"해결 방안:\n모든 리소스에 고유한 번호 부여 프로세스는 번호가 증가하는 순서대로 리소스를 요청해야 함 예시:\nR1(1번), R2(2번), R3(3번) 프로세스가 R2를 사용 중이라면 다음에 요청할 수 있는 리소스는 R3 이상만 가능 R1은 요청 불가능 (번호가 작음) 장점:\n순환 대기 자체를 방지 비교적 실용적인 방법 단점:\n리소스 번호 체계를 잘 설계해야 함 특정 리소스를 반복적으로 사용해야 하는 경우 비효율적일 수 있음 조건 해결 방법 문제점 상호 배제 스풀링, 공유 자원 활용 모든 자원에 적용 불가 보유 대기 초기에 모든 자원 확보 or 반환 후 재요청 자원 낭비, 사전 예측 어려움 비선점 리소스 강제 선점 작업 중단으로 인한 데이터 손실 위험 순환 대기 리소스 순서 규칙 적용 유연성 저하, 번호 체계 복잡 네, 알겠습니다. 제공해주신 운영체제 강의 슬라이드를 바탕으로, 각 슬라이드별 원문, 번역, 그리고 6000자 이상의 매우 상세한 설명을 덧붙여드리겠습니다.","4-프레임으로-확장-시의-변화-개념적#\u003cstrong\u003e4 프레임으로 확장 시의 변화 (개념적)\u003c/strong\u003e":"만약 사용 가능한 프레임 수가 3개에서 4개로 늘어난다면 어떤 변화가 있을까요? 일반적으로 프레임 수가 증가하면 페이지 폴트 횟수는 감소하거나 최소한 동일하게 유지됩니다 (벨레이디의 모순이 없는 대부분의 알고리즘에서). 최적 알고리즘의 경우, 프레임이 더 많아지면 더 많은 페이지를 메모리에 유지할 수 있으므로, 교체가 필요한 상황 자체가 줄어들거나, 교체 시 더 나은(더 먼 미래에 사용될) 페이지를 남겨둘 수 있는 선택지가 늘어나 페이지 폴트가 감소할 가능성이 큽니다.\n예를 들어, 위의 3프레임 예시에서 4번째 프레임이 추가된다면, 초기 페이지 7, 0, 1, 2는 모두 폴트를 발생시키며 프레임에 순서대로 들어갈 것입니다. 그 이후의 교체 결정은 4개의 페이지 중에서 가장 먼 미래에 사용될 페이지를 선택하게 되므로, 3프레임일 때보다 더 적은 페이지 폴트를 기대할 수 있습니다. (예: 4프레임 시 7회 폴트)\n이러한 예시들은 최적 알고리즘이 어떻게 각 단계마다 “가장 이상적인” 결정을 내리는지를 보여줍니다. 비록 현실 세계의 제약으로 인해 직접 사용할 수는 없지만, 이 알고리즘의 원리를 이해하는 것은 다른 실용적인 페이지 교체 알고리즘들의 설계 철학과 성능 한계를 파악하는 데 중요한 기초가 됩니다. 슬라이드 8.15와 8.16은 보통 이러한 과정을 그림으로 표현하여 직관적인 이해를 돕습니다.","4-프로세스-속도와-실행-순서#\u003cstrong\u003e4. 프로세스 속도와 실행 순서\u003c/strong\u003e":"Peterson’s Solution은 프로세스 간의 상대적인 실행 속도에 대해 아무런 가정을 하지 않습니다. 그러나 각 프로세스가 반드시 무한히 실행되며 정지하지 않는다는 가정하에 동작합니다. 즉:\n프로세스가 무한 루프에 빠지거나 크래시(crash)하지 않아야 합니다. 만약 한 프로세스가 실행 중에 종료되면, 다른 프로세스가 영원히 대기할 수 있습니다.","4단계-테이블-재설정-reset-tables#\u003cstrong\u003e4단계: 테이블 재설정 (Reset Tables)\u003c/strong\u003e":"디스크 읽기 작업이 완료되었다는 인터럽트를 디스크 컨트롤러로부터 받으면, 운영 체제는 후속 작업을 마무리합니다.\n페이지 폴트를 일으켰던 프로세스의 페이지 테이블을 수정합니다. 해당 페이지의 항목으로 가서, 유효-무효 비트를 ‘i’에서 ‘v’로 변경합니다. 프레임 번호 필드에, 3단계에서 페이지를 로드한 물리 프레임의 번호를 기록합니다. 이제 이 프로세스는 다시 실행될 준비가 되었으므로, 프로세스의 상태를 ‘대기’에서 ‘준비(ready)’ 상태로 바꾸고, 준비 큐(ready queue)에 넣습니다.","5-each-is-loadable-as-needed-within-the-kernel#\u003cstrong\u003e(5) Each is loadable as needed within the kernel\u003c/strong\u003e":"","5-int-fd---file-descriptor#5. \u003ccode\u003eint fd\u003c/code\u003e - File Descriptor":"","5-processor-execution-is-limited-by-memory-cycle-time#\u003cstrong\u003e5. Processor execution is limited by memory cycle time\u003c/strong\u003e":"","5-write-policy-쓰기-정책#\u003cstrong\u003e5. Write Policy (쓰기 정책)\u003c/strong\u003e":"","5-프로세스-수-제한#\u003cstrong\u003e5. 프로세스 수 제한\u003c/strong\u003e":"Peterson’s Solution은 두 개의 프로세스만 지원하도록 설계되었습니다. 더 많은 프로세스를 지원하려면 알고리즘을 수정해야 합니다.","5단계-명령어-재시작-restart-instruction#\u003cstrong\u003e5단계: 명령어 재시작 (Restart Instruction)\u003c/strong\u003e":"이제 모든 준비가 끝났습니다. CPU 스케줄러에 의해 해당 프로세스가 다시 실행될 차례가 되면, 운영 체제는 이전에 페이지 폴트 때문에 중단되었던 바로 그 명령어를 처음부터 다시 시작시킵니다.\n이제 해당 명령어가 다시 실행되면, MMU는 똑같은 논리 주소에 대한 변환을 시도할 것입니다. 하지만 이번에는 페이지 테이블의 유효-무효 비트가 ‘v’로 설정되어 있고, 올바른 프레임 번호가 기록되어 있으므로, 주소 변환은 성공적으로 완료됩니다. 프로세스는 페이지 폴트가 있었는지조차 모른 채 자연스럽게 실행을 이어나가게 됩니다.\n이 5단계의 과정은 가상 메모리 시스템의 심장과도 같은 동적인 절차이며, 운영 체제가 어떻게 하드웨어와 협력하여 사용자에게 ‘무한한 메모리’라는 환상을 제공하는지를 명확하게 보여줍니다.","6-exploit-the-principle-of-locality-with-a-small-fast-memory#\u003cstrong\u003e6. Exploit the principle of locality with a small, fast memory\u003c/strong\u003e":"","6-number-of-cache-levels-캐시-레벨-수#\u003cstrong\u003e6. Number of Cache Levels (캐시 레벨 수)\u003c/strong\u003e":"","6-off_t-offset#6. \u003ccode\u003eoff_t offset\u003c/code\u003e":"","actual-deadlock#Actual Deadlock":"","address-binding-주소-바인딩#Address Binding (주소 바인딩)":"Inconvenient to have first user process physical address always at 0000 (첫 번째 사용자 프로세스의 물리 주소가 항상 0000번지인 것은 불편합니다) How can it not be? (어떻게 그렇지 않을 수 있는가?) Further, addresses represented in different ways at different stages of a program’s life (더 나아가, 주소는 프로그램 생명 주기의 여러 단계에서 다른 방식으로 표현됩니다) Source code addresses usually symbolic (소스 코드의 주소는 대개 심볼릭입니다) Compiled code addresses bind to relocatable addresses (컴파일된 코드의 주소는 재배치 가능 주소로 바인딩됩니다) → i.e. “14 bytes from beginning of this module” (예: “이 모듈 시작으로부터 14바이트 떨어진 곳”) Linker or loader will bind relocatable addresses to absolute addresses (링커 또는 로더가 재배치 가능 주소를 절대 주소로 바인딩합니다) → i.e. 74014 (예: 74014번지) Each binding maps one address space to another (각 바인딩은 하나의 주소 공간을 다른 주소 공간으로 매핑합니다) [설명]\n주소 바인딩은 프로그램 내의 주소(심볼릭 주소, 논리 주소 등)가 실제 물리 메모리 주소로 변환되고 연결되는 과정을 의미합니다. 이 바인딩이 어느 시점에 이루어지느냐에 따라 메모리 관리 방식의 유연성이 달라집니다.\n물리 주소 0000번지의 불편함: 만약 모든 사용자 프로세스가 물리 메모리의 0000번지부터 시작해야 한다면, 단 하나의 프로세스만 메모리에 적재될 수 있을 것입니다. 다중 프로그래밍 환경에서는 여러 프로세스가 동시에 메모리에 있어야 하므로, 각 프로세스는 서로 다른 시작 주소를 가져야 합니다. 이를 가능하게 하는 것이 주소 바인딩의 역할입니다. 프로그램 생명 주기에 따른 주소 표현: 소스 코드 (Symbolic addresses): 프로그래머가 코드를 작성할 때는 변수명, 함수명, 레이블 등 심볼릭 주소를 사용합니다 (예: count, calculateSum(), loop_start). 이는 사람이 이해하기 쉬운 형태입니다. 컴파일된 코드 (Relocatable addresses): 컴파일러는 소스 코드를 기계어로 번역하면서 심볼릭 주소를 재배치 가능 주소(상대 주소)로 변환합니다. 이는 특정 기준점(보통 모듈의 시작 지점)으로부터의 상대적인 위치를 나타냅니다 (예: “이 모듈의 시작으로부터 14바이트 떨어진 곳에 변수 count가 있다”). 이렇게 하면 이 모듈이 메모리의 어느 위치에 적재되든 내부적인 상대 주소는 변하지 않습니다. 링커 또는 로더 (Absolute addresses or Logical addresses): 링커(Linker): 여러 개의 컴파일된 모듈(오브젝트 파일)과 라이브러리들을 결합하여 하나의 실행 가능한 파일을 만듭니다. 이 과정에서 외부 참조된 심볼들의 주소를 결정하고, 재배치 가능 주소들을 하나의 통합된 주소 공간 내의 주소로 조정합니다. 이 주소는 아직 물리 주소가 아닐 수도 있고, 프로그램 전체의 논리 주소 공간 내의 주소일 수 있습니다. 로더(Loader): 실행 파일을 메모리에 적재하는 역할을 합니다. 이 때 재배치 가능 주소를 실제 물리 메모리의 절대 주소로 바인딩할 수도 있고(로드 타임 바인딩), 또는 프로그램이 실행될 때 동적으로 주소가 결정되도록 논리 주소 형태를 유지할 수도 있습니다(실행 시간 바인딩). (예: 74014번지) 바인딩의 의미: 각 단계의 바인딩은 한 종류의 주소 표현을 다른 종류의 주소 표현으로 매핑(mapping, 사상)하는 과정입니다. 예를 들어, 심볼 count를 “모듈 시작+14\"로, “모듈 시작+14\"를 다시 “74014번지\"로 매핑합니다.","address-translation-scheme-주소-변환-방식#Address Translation Scheme (주소 변환 방식)":"Address generated by CPU is divided into: (CPU에 의해 생성된 주소는 다음으로 나뉩니다:) Page number (p) (페이지 번호 (p)) → index into a page table = (page #, frame #) (페이지 테이블의 인덱스 = (페이지 번호, 프레임 번호)) Page offset (d) (페이지 오프셋 (d)) → offset within the page (frame) (페이지(프레임) 내의 오프셋) Given m bits logical address, page size 2n (m 비트 논리 주소이고, 페이지 크기가 2n일 때) → last n bit = offset = 0∼2n−1 (마지막 n 비트 = 오프셋 = 0∼2n−1) → first m-n bit = page number = 0∼2m−n−1 (처음 m-n 비트 = 페이지 번호 = 0∼2m−n−1) page table translates: page no → frame no (M-n bits) (페이지 테이블 변환: 페이지 번호 → 프레임 번호 (M-n 비트)) → M≥m (단, M은 물리 주소 비트 수, M이 m보다 크거나 같을 수 있음) [한글 번역 및 상세 설명]\n페이징에서의 주소 변환 메커니즘을 더 자세히 설명합니다.\nCPU 생성 주소의 구성 요소:\n페이지 번호 (p): 논리 주소에서 이 부분이 추출되어 페이지 테이블을 조회하는 데 사용됩니다. 페이지 테이블은 각 논리 페이지 번호에 해당하는 물리 프레임 번호를 저장하고 있습니다. (슬라이드에서는 (page #, frame #) 쌍으로 표현했는데, 정확히는 page #를 인덱스로 사용하여 frame #를 얻는다는 의미입니다.) 페이지 오프셋 (d): 해당 페이지(그리고 그 페이지가 적재된 프레임) 내에서의 정확한 바이트 위치를 나타냅니다. 이 값은 주소 변환 과정에서 변경되지 않습니다. 주소 비트 할당 (m비트 논리 주소, 페이지 크기 2n 바이트 가정):\n오프셋 (offset): 페이지 크기가 2n 바이트이므로, 페이지 내의 모든 바이트를 고유하게 식별하려면 n개의 비트가 필요합니다. 따라서 논리 주소의 하위 n비트가 오프셋으로 사용됩니다. 오프셋 값의 범위는 0부터 2n−1까지입니다. 페이지 번호 (page number): 논리 주소의 총 m비트 중 오프셋으로 사용된 n비트를 제외한 나머지 m-n비트가 페이지 번호로 사용됩니다. 이 페이지 번호는 0부터 2m−n−1까지의 값을 가질 수 있으며, 이는 해당 프로세스가 가질 수 있는 총 페이지의 수를 나타냅니다. 페이지 테이블의 변환 역할:\n페이지 테이블은 논리적인 **페이지 번호(p)**를 물리적인 **프레임 번호(f)**로 변환(매핑)하는 역할을 합니다. 만약 물리 주소의 전체 길이가 M비트이고, 오프셋 부분이 n비트라면, 프레임 번호를 나타내는 데 사용되는 비트 수는 M-n비트가 됩니다. 이 M-n비트로 2M−n개의 서로 다른 프레임을 구분할 수 있습니다. M≥m에 대한 노트: 슬라이드에는 M≥m이라고 되어 있지만, 이는 항상 참은 아닙니다. M: 물리 주소 공간의 비트 수 (예: 실제 RAM 크기에 따라 결정) m: 논리 주소 공간의 비트 수 (예: CPU 아키텍처에 따라 프로세스가 가질 수 있는 최대 가상 주소 공간 크기, 예: 32비트 CPU는 m=32) 물리 메모리(RAM)가 논리 주소 공간보다 작을 수도 있습니다 (예: 32비트 프로세스가 1GB RAM 시스템에서 실행). 반대로, 64비트 CPU의 논리 주소 공간은 현재 시스템들의 물리 RAM보다 훨씬 큽니다. 여기서 M-n은 프레임 번호를 표현하는 데 필요한 비트 수를 의미하고, 페이지 테이블에 저장되는 프레임 번호의 실제 크기를 나타냅니다. 다이어그램 요약:\n논리 주소: [페이지 번호 p (m-n 비트)] [오프셋 d (n 비트)] 페이지 테이블: p를 입력으로 받아 f(프레임 번호)를 출력. 물리 주소: [프레임 번호 f (M-n 비트)] [오프셋 d (n 비트)] 이 변환은 페이징 시스템의 핵심이며, MMU에 의해 하드웨어적으로 처리되어야 효율적인 실행이 가능합니다.","allocation-strategy-할당-전략#Allocation Strategy (할당 전략)":"How to satisfy a request of size n from a list of free holes? (크기 n의 요청을 가용 홀(hole) 리스트로부터 어떻게 만족시킬 것인가?)\nFirst-fit (최초 적합): Allocate the first hole that is big enough (충분히 큰 첫 번째 가용 홀을 할당) Best-fit (최적 적합): Allocate the smallest hole that is big enough; must search entire list, unless ordered by size (충분히 큰 가장 작은 가용 홀을 할당; 크기 순으로 정렬되어 있지 않다면 전체 리스트를 탐색해야 함) Produces the smallest leftover hole (가장 작은 남은 홀을 생성) Worst-fit (최악 적합): Allocate the largest hole; must also search entire list (가장 큰 가용 홀을 할당; 역시 전체 리스트를 탐색해야 함) Produces the largest leftover hole (가장 큰 남은 홀을 생성) First-fit and best-fit better than worst-fit in terms of speed and storage utilization (최초 적합과 최적 적합이 속도와 저장 공간 활용 측면에서 최악 적합보다 우수합니다)\n동적 분할에서 여러 개의 가용 블록(홀) 중 어느 것을 선택하여 프로세스에 할당할지를 결정하는 다양한 전략(알고리즘)입니다.\n최초 적합 (First-fit): 가용 메모리 블록 리스트를 처음부터 순서대로 탐색하여, 프로세스를 수용할 수 있는 충분한 크기의 첫 번째 블록을 할당합니다. 장점: 검색 시간이 빠를 수 있습니다 (운이 좋으면 리스트 앞부분에서 바로 찾음). 단점: 리스트 앞부분에 큰 가용 블록들이 집중되어 있을 경우, 작은 요청들이 이 큰 블록들을 잘게 쪼개어 나중에 큰 요청을 처리하지 못할 수 있습니다. 최적 적합 (Best-fit): 가용 메모리 블록 리스트 전체를 탐색하여, 프로세스를 수용할 수 있는 블록들 중에서 크기가 가장 작은 블록 (즉, 요청 크기와 가장 비슷한 크기의 블록)을 할당합니다. 장점: 요청 크기에 딱 맞는 블록을 할당하므로, 할당 후 남는 조각(leftover hole)의 크기를 최소화합니다. 이렇게 하면 아주 작은, 쓸모없는 조각들이 생기는 것을 방지하여 메모리 활용률을 높일 수 있다고 기대합니다. 단점: 항상 전체 리스트를 검색해야 하므로 검색 시간이 오래 걸릴 수 있습니다. 또한, 매우 작은 조각들이 많이 생겨서 오히려 단편화를 심화시킬 수도 있습니다. 최악 적합 (Worst-fit): 가용 메모리 블록 리스트 전체를 탐색하여, 프로세스를 수용할 수 있는 블록들 중에서 크기가 가장 큰 블록을 할당합니다. 장점: 큰 블록을 할당하고 남은 조각도 상대적으로 크기 때문에, 이 남은 조각이 다른 중간 크기의 프로세스를 수용할 가능성을 높이려는 의도입니다. 단점: 항상 전체 리스트를 검색해야 합니다. 큰 블록을 계속 사용하면 큰 가용 공간이 빨리 소진되어, 나중에 매우 큰 프로세스가 도착했을 때 할당하지 못할 수 있습니다. 결론:\n일반적으로 시뮬레이션 결과에 따르면, 최초 적합과 최적 적합이 최악 적합보다 평균적인 검색 시간이나 메모리 단편화 관리 측면에서 더 나은 성능을 보인다고 알려져 있습니다. 최초 적합은 구현이 간단하고 평균적으로 성능도 괜찮아서 많이 사용됩니다. 최적 적합은 더 많은 검색 시간을 소요하지만, 때로는 더 나은 메모리 활용을 보일 수도 있습니다.\n이 슬라이드는 가상의 메모리 상태를 보여주고, 새로운 프로세스 P8(크기가 명시되진 않음)이 도착했을 때 각 할당 전략이 어떤 가용 공간을 선택할지를 개념적으로 나타냅니다.\n현재 메모리에는 운영체제(OS)와 기존 프로세스들(process 6, 3, 5, 7)이 적재되어 있고, 그 사이사이에 여러 개의 가용 공간(hole)들이 존재합니다. First-fit: P8의 요청 크기를 만족하는 첫 번째 가용 공간을 할당합니다 (위에서부터 탐색 가정). Best-fit: P8의 요청 크기를 만족하면서 가장 크기가 비슷한 (즉, 남는 공간이 가장 적은) 가용 공간을 할당합니다. Worst-fit: P8의 요청 크기를 만족하면서 가장 크기가 큰 가용 공간을 할당합니다. 실제 어떤 공간이 선택될지는 P8의 크기와 각 가용 공간의 정확한 크기에 따라 달라집니다. 이 그림은 각 전략의 선택 기준이 다름을 보여줍니다.\n(Diagram Series Showing Process Allocation and Deallocation leading to External Fragmentation)\nOS process 1 process 2 process 3\nOS process 1 process 3 (process 2 deallocated)\nOS process 1 process 3 (hole where process 2 was)\nOS process 1 process 4 process 3 (process 4 allocated in the hole)\nprocess 4 process 5\nOS process 1 process 3 process 5 (process 4 deallocated)\nOS process 3 process 5 (process 1 deallocated)\nOS process 6 process 3 process 5 (process 6 allocated)\nOS process 6 process 3 process 5 process 7 (process 7 allocated)\nExternal Fragmentation! (외부 단편화!)\n[설명]\n이 슬라이드 시리즈는 동적 분할 방식에서 프로세스들이 메모리에 할당되고 해제되는 과정을 시간 순서대로 보여주면서, 결국 **외부 단편화(External Fragmentation)**가 발생하는 상황을 설명합니다.\n초기 상태: OS, P1, P2, P3가 순서대로 메모리에 적재되어 있습니다. P2 종료: P2가 사용하던 메모리 공간이 반납되어 가용 공간(hole)이 됩니다. (OS, P1, [hole1], P3) (hole1 표시) P4 할당: P4가 도착하여 hole1에 적재됩니다. (OS, P1, P4, P3) P5 할당: P5가 P3 다음에 적재됩니다. (OS, P1, P4, P3, P5) (그림에서는 P4, P5가 연달아 표시되어 있는데, 이는 P3 다음에 P5가 할당되고, 그 후 P4가 종료된 상황으로 해석하거나, 혹은 P4가 종료된 후 P5가 다른 곳에 할당된 상황으로 볼 수 있습니다. 슬라이드 순서상 P4 종료 후 P5가 다른 hole에 할당된 것으로 보는게 맞겠습니다. 하지만 그림 연결이 조금 불명확합니다. 중요한 것은 프로세스들이 할당되고 해제됨에 따라 hole들이 생긴다는 것입니다.) 정정 및 명확화: 슬라이드의 그림 흐름을 따라가면, OS, P1, P4, P3 (이전 상태에서 P2 자리에 P4 할당) 그림에서 “process 4 process 5\"라고만 되어 있어, P3 이후에 P5가 할당되었다고 가정하겠습니다. 즉, (OS, P1, P4, P3, P5). 다음 그림 “OS process 1 process 3 process 5\"는 P4가 종료된 상태를 나타냅니다. 즉, (OS, P1, [hole2], P3, P5). P1 종료: P1이 사용하던 공간이 반납되어 가용 공간이 됩니다. (OS, [hole3], [hole2], P3, P5) P6 할당: P6가 도착하여 가장 앞쪽 가용 공간인 hole3에 적재됩니다 (First-fit 가정). (OS, P6, [hole2], P3, P5) P7 할당: P7이 도착하여 P5 다음의 가용 공간에 적재됩니다. (OS, P6, [hole2], P3, P5, P7) 외부 단편화 발생:\n이제 메모리 상태는 (OS, P6, [hole2], P3, P5, P7)입니다. 여기서 [hole2]는 P4가 사용했던 공간으로, 여전히 가용 상태입니다. 만약 새로운 프로세스 P8이 도착했는데, P8의 크기가 [hole2]보다는 크지만, [hole2]와 메모리 끝 어딘가에 있을지 모르는 다른 작은 가용 공간들의 합보다는 작거나 같은 상황을 생각해봅시다. 즉, 전체 가용 메모리 공간의 합은 P8을 수용하기에 충분하지만, 이 가용 공간들이 연속적이지 않고 작은 조각들로 흩어져 있어서 P8을 할당할 수 없는 상태가 발생합니다. 이것이 바로 외부 단편화입니다. 메모리가 프로세스들의 외부에 잘게 조각나 있다는 의미입니다.","associative-memory-연관-메모리#Associative Memory (연관 메모리)":"Associative memory – parallel search (연관 메모리 – 병렬 검색)\nAddress translation (p, d) (주소 변환 (p, d))\nIf p is in associative register, get frame # out (만약 p가 연관 레지스터에 있으면, 프레임 번호를 가져옴) Otherwise get frame # from page table in memory (그렇지 않으면 메모리의 페이지 테이블에서 프레임 번호를 가져옴) [한글 번역 및 상세 설명]\nTLB의 핵심 구현 기술인 연관 메모리(Associative Memory)와 이를 이용한 주소 변환 과정을 설명합니다.\n연관 메모리 – 병렬 검색:\n연관 메모리는 일반적인 RAM(주소로 데이터 접근)과 달리, **내용(content)**을 기반으로 데이터를 검색합니다. 그래서 **CAM(Content Addressable Memory)**이라고도 불립니다. 병렬 검색(Parallel Search): 연관 메모리의 가장 큰 특징은 저장된 모든 항목에 대해 검색 키(여기서는 페이지 번호 p)를 동시에, 병렬적으로 비교한다는 것입니다. 이 덕분에 검색 속도가 매우 빠릅니다. 일반 메모리에서 특정 내용을 찾으려면 순차적으로 비교해야 하지만, 연관 메모리는 하드웨어적으로 모든 비교를 한 번에 수행합니다. TLB는 이러한 연관 메모리로 구성되어 (페이지 번호, 프레임 번호) 쌍들을 저장합니다. 주소 변환 (p, d) 과정:\nCPU가 논리 주소 (p, d)를 생성합니다. p는 페이지 번호, d는 오프셋입니다. 페이지 번호 p가 TLB(연관 레지스터들로 구성됨)에 검색 키로 제시됩니다. If p is in associative register, get frame # out (TLB 히트): TLB는 p와 일치하는 페이지 번호를 가진 항목이 있는지 모든 연관 레지스터를 병렬적으로 검사합니다. 일치하는 항목이 발견되면(TLB 히트), 해당 항목에 저장된 **프레임 번호(frame #)**를 즉시 출력합니다. 이 프레임 번호와 원래의 오프셋 d를 결합하여 물리 주소를 완성합니다. (매우 빠름) Otherwise get frame # from page table in memory (TLB 미스): p와 일치하는 항목이 TLB에 없으면(TLB 미스), 시스템은 주 메모리에 있는 페이지 테이블에 접근하여 해당 페이지 p에 대한 프레임 번호를 찾아야 합니다. (느림) 페이지 테이블에서 프레임 번호를 찾은 후, 이 (페이지 번호 p, 프레임 번호 f) 쌍은 다음번 빠른 조회를 위해 TLB에 새로 적재됩니다. (이때 TLB 교체 정책이 적용될 수 있습니다.) 다이어그램 설명:\n왼쪽에는 (Page #, Frame #) 쌍을 저장하는 연관 레지스터들(TLB의 각 항목)이 나열되어 있습니다. CPU로부터 논리 주소의 페이지 번호 p 부분이 입력됩니다. p는 TLB의 모든 ‘Page #’ 열의 값들과 동시에 비교됩니다. 만약 일치하는 p가 있다면 (화살표로 표시된 히트 상황), 해당 ‘Frame #’ 열의 값이 출력되어 물리 주소 형성에 사용됩니다. 연관 메모리를 사용함으로써 TLB는 페이지 테이블 참조의 대부분을 매우 빠르게 처리하여, 페이징으로 인한 두 번의 메모리 접근 문제를 효과적으로 완화시킵니다.","background#\u003cstrong\u003eBackground\u003c/strong\u003e":"","background-배경-지식#Background (배경 지식)":"Program must be brought (from disk) into memory and placed within a process for it to be run (프로그램이 실행되려면 (디스크에서) 메모리로 가져와 프로세스 내에 배치되어야 합니다) Main memory and registers are only storage CPU can access directly (주 기억장치(메인 메모리)와 레지스터만이 CPU가 직접 접근할 수 있는 저장 공간입니다) Memory unit only sees a stream of addresses + read requests, or address + data and write requests (메모리 장치는 주소 + 읽기 요청 스트림 또는 주소 + 데이터 및 쓰기 요청 스트림만을 봅니다) Register access in one CPU clock (or less) (레지스터 접근은 CPU 클럭 1회 (또는 그 이하) 소요) Main memory can take many cycles (주 기억장치 접근은 많은 사이클이 소요될 수 있습니다) Cache sits between main memory and CPU registers (캐시는 주 기억장치와 CPU 레지스터 사이에 위치합니다) Protection of memory required to ensure correct operation (올바른 작동을 보장하기 위해 메모리 보호가 필요합니다) [설명]\n메모리 관리를 이해하는 데 필요한 기본적인 컴퓨터 시스템 구조 및 동작 원리를 설명합니다.\n프로그램 실행 과정: 프로그램(실행 파일 형태)은 평소에는 보조 기억장치(예: 하드 디스크, SSD)에 저장되어 있습니다. 이를 실행하려면, 프로그램 코드가 주 기억장치(RAM)로 적재(load)되어야 합니다. 이 적재된 프로그램의 실행 단위를 프로세스라고 합니다. CPU의 직접 접근: CPU는 매우 빠르지만, 오직 레지스터와 주 기억장치(메인 메모리)에 있는 데이터와 명령어에만 직접 접근할 수 있습니다. 디스크에 있는 내용은 직접 실행하거나 처리할 수 없습니다. 메모리 장치의 역할: 메모리 컨트롤러를 포함한 메모리 유닛은 CPU로부터 주소와 함께 읽기/쓰기 요청을 받아 처리합니다. CPU가 “0x1000번지에서 데이터를 읽어와라” 또는 “0x2000번지에 이 데이터를 써라\"와 같은 형태로 요청합니다. 접근 속도 차이: 레지스터: CPU 내부에 있어 접근 속도가 가장 빠릅니다 (CPU 클럭과 동기화, 1클럭 이내). 주 기억장치 (RAM): 레지스터보다 훨씬 느립니다. CPU가 RAM에 접근하려면 수십~수백 CPU 클럭 사이클이 소요될 수 있습니다. 캐시 메모리: 이러한 속도 차이를 완화하기 위해 CPU와 주 기억장치 사이에 고속의 캐시 메모리를 둡니다. 자주 사용될 것으로 예상되는 데이터나 명령어를 미리 캐시에 가져다 놓으면, CPU는 대부분의 경우 느린 주 기억장치 대신 빠른 캐시에 접근하여 성능을 향상시킬 수 있습니다 (캐시 히트). 메모리 보호: 여러 프로세스가 동시에 메모리에 적재되어 실행되는 다중 프로그래밍 환경에서는, 한 프로세스가 다른 프로세스의 메모리 영역이나 운영체제의 메모리 영역을 침범하여 데이터를 손상시키거나 시스템 전체를 불안정하게 만드는 것을 방지해야 합니다. 이를 위해 메모리 보호 기법이 필수적입니다.","bankers-algorithm#Banker’s Algorithm":"","base-and-limit-registers-기준-레지스터와-한계-레지스터#Base and Limit Registers (기준 레지스터와 한계 레지스터)":"A pair of base and limit registers define the logical address space (한 쌍의 기준 레지스터와 한계 레지스터가 논리 주소 공간을 정의합니다) [설명]\n메모리 보호를 위한 간단하면서도 효과적인 하드웨어 기법 중 하나로 기준 레지스터와 한계 레지스터를 사용합니다.\n논리 주소 공간(Logical Address Space): 프로세스 입장에서 바라보는 메모리 주소의 범위입니다. 보통 0번지부터 시작하는 연속적인 주소 공간으로 인식합니다. 기준 레지스터 (Base Register): 어떤 프로세스가 메모리에 적재될 때, 그 프로세스가 적재된 물리 메모리의 시작 주소를 저장합니다. ‘재배치 레지스터(Relocation Register)‘라고도 불립니다. 한계 레지스터 (Limit Register): 해당 프로세스의 논리 주소 공간의 크기(즉, 프로그램의 길이)를 저장합니다. 프로세스가 접근할 수 있는 최대 논리 주소값을 나타냅니다. 프로세스가 어떤 논리 주소 L에 접근하려고 할 때, 하드웨어는 다음을 검사합니다:\n0 \u003c= L \u003c Limit Register 값\n만약 이 조건을 만족하지 않으면 (즉, 프로세스가 자신에게 할당된 영역을 벗어나려고 하면) 하드웨어 인터럽트(트랩)가 발생하여 운영체제에게 제어가 넘어가고, 운영체제는 해당 프로세스를 강제 종료시키는 등의 오류 처리를 합니다.\n만약 조건을 만족하면, 실제 물리 주소는 Base Register 값 + L로 변환됩니다. 이 모든 과정은 CPU가 메모리에 접근할 때마다 하드웨어적으로 빠르게 수행됩니다.\nHardware Address Protection with Base and Limit Registers (기준 및 한계 레지스터를 이용한 하드웨어 주소 보호)\n(Diagram: CPU -\u003e logical address -\u003e [check: address \u003e= base? and address \u003c base + limit?] -\u003e yes -\u003e physical address -\u003e memory; no -\u003e trap to OS)\nbase : 접근 가능한 최소 물리 주소\nlimit : 접근 가능한 논리 주소의 최대값.\nbase + limit (슬라이드 그림에는 base + limit으로 되어있지만, 더 정확히는 논리주소 \u003c limit 이고, 물리주소 = base + 논리주소. 따라서 CPU가 생성한 논리주소가 limit보다 작은지 확인하고, base와 더해 물리주소를 만듦. 그림은 물리주소 관점에서 base와 base+limit 사이인지 확인하는 것으로 표현)\n[설명]\n기준(base) 및 한계(limit) 레지스터를 사용한 메모리 보호 메커니즘을 도식화한 것입니다.\nCPU가 논리 주소 생성: CPU는 프로그램 코드에 따라 특정 메모리 위치에 접근하기 위한 논리 주소(logical address, 또는 가상 주소)를 생성합니다. 주소 검증: 생성된 논리 주소 addr_logical이 0보다 크거나 같고, 한계 레지스터(limit register)에 저장된 값보다 작은지 확인합니다 (0 \u003c= addr_logical \u003c limit_register_value). 만약 이 범위를 벗어나면 (no 경로), 이는 허가되지 않은 메모리 접근 시도이므로 트랩(trap)이 발생하여 운영체제로 제어권이 넘어갑니다. 운영체제는 “addressing error” (주소 지정 오류)로 처리하고 해당 프로세스를 종료시킬 수 있습니다. 물리 주소 변환: 논리 주소가 유효한 범위 내에 있다면 (yes 경로), 이 논리 주소는 기준 레지스터(base register, 또는 재배치 레지스터)에 저장된 값과 더해져 실제 물리 메모리 주소(addr_physical = base_register_value + addr_logical)로 변환됩니다. 메모리 접근: 변환된 물리 주소를 사용하여 실제 메모리에 접근합니다. 슬라이드 그림의 해석:\n슬라이드의 그림은 CPU가 생성한 주소(논리 주소)가 기준 레지스터(base) 값보다 크거나 같고, (기준 레지스터 값 + 한계 레지스터 값)보다 작은지를 검사하는 것처럼 보입니다.\nCPU generated address \u003e= base_register CPU generated address \u003c (base_register + limit_register) 이 방식에서는 CPU가 생성하는 주소 자체가 이미 재배치된 주소(즉, 논리 주소가 0부터 시작하는 것이 아니라, 특정 오프셋이 더해진 값)라고 가정하거나, 혹은 논리 주소에 base를 더한 후 그 결과가 base와 base+limit 사이에 있는지 보는 것과 같습니다. 더 일반적인 설명은 CPU가 0부터 시작하는 논리 주소를 생성하고, 이 논리 주소가 limit_register 값보다 작은지 확인한 후, base_register 값을 더해 물리 주소를 만드는 것입니다. 두 방식 모두 결과적으로 프로세스가 자신에게 할당된 [base, base+limit-1] 범위의 물리 메모리만 접근하도록 보장합니다.\n이 하드웨어 지원 덕분에 각 프로세스는 자신만의 독립된 주소 공간을 가지는 것처럼 느끼며, 다른 프로세스나 운영체제의 영역을 침범할 걱정 없이 프로그램을 실행할 수 있습니다. 또한, 프로세스가 메모리의 어느 위치에 적재되든 기준 레지스터 값만 적절히 설정해주면 되므로 프로그램 재배치가 용이해집니다.","binding-of-instructions-and-data-to-memory-명령어와-데이터의-메모리-주소-바인딩#Binding of Instructions and Data to Memory (명령어와 데이터의 메모리 주소 바인딩)":"Address binding of instructions and data to memory addresses can happen at three different stages (명령어와 데이터의 메모리 주소 바인딩은 세 가지 다른 시점에서 발생할 수 있습니다) Compile time: If memory location known a priori, absolute code can be generated; must recompile code if starting location changes (컴파일 시간: 메모리 위치를 미리 알 수 있다면, 절대 코드가 생성될 수 있음. 시작 위치가 변경되면 코드를 다시 컴파일해야 함) Load time: Must generate relocatable code if memory location is not known at compile time (적재 시간: 컴파일 시간에 메모리 위치를 알 수 없다면, 재배치 가능 코드를 생성해야 함) Execution time: Binding delayed until run time if the process can be moved during its execution from one memory segment to another (실행 시간: 프로세스가 실행 중에 한 메모리 세그먼트에서 다른 세그먼트로 이동될 수 있다면, 바인딩이 실행 시간까지 지연됨) Need hardware support for address maps (e.g., base and limit registers) (주소 맵을 위한 하드웨어 지원 필요 (예: 기준 및 한계 레지스터)) [설명]\n주소 바인딩이 일어나는 세 가지 주요 시점입니다.\n컴파일 시간 바인딩 (Compile time binding): 프로그램이 컴파일될 때, 프로그램이 적재될 메모리 위치를 미리 안다고 가정하고, 모든 주소를 실제 물리 주소(절대 주소)로 변환하여 코드를 생성합니다. 예: MS-DOS의 .COM 파일 형식. 항상 특정 주소(예: 0x0100)에 적재된다고 가정합니다. 장점: 실행이 빠릅니다 (주소 변환 과정이 필요 없음). 단점: 프로그램이 적재될 메모리 위치가 변경되면 (예: 다른 프로그램이 이미 그 위치를 사용 중이거나 OS 구조가 변경되면) 프로그램을 다시 컴파일해야 합니다. 매우 비유연적입니다. 적재 시간 바인딩 (Load time binding): 컴파일러는 재배치 가능 코드(relocatable code)를 생성합니다. 즉, 주소들이 특정 기준점으로부터의 상대적인 위치로 표현됩니다. 프로그램이 실제로 메모리에 적재될 때, 로더(loader)가 비어있는 메모리 위치를 찾고, 그 시작 주소를 기준으로 모든 상대 주소들을 실제 물리 주소로 변환합니다. 장점: 컴파일 시간 바인딩보다는 유연합니다. 컴파일을 다시 할 필요 없이, 로더가 적재 시점에 주소를 결정합니다. 단점: 일단 메모리에 적재되어 실행이 시작된 후에는 프로세스를 다른 메모리 위치로 옮기기 어렵습니다. 옮기려면 모든 주소를 다시 계산해야 합니다. 실행 시간 바인딩 (Execution time binding 또는 Run time binding): 주소 바인딩이 프로그램 실행 중에도 계속 지연됩니다. 즉, CPU가 특정 주소를 참조할 때마다 (명령어를 가져오거나 데이터를 읽고 쓸 때마다) 바인딩이 동적으로 이루어집니다. 프로세스는 실행 중에 메모리의 한 위치에서 다른 위치로 이동될 수 있습니다. 예를 들어, 압축(compaction)을 수행하거나 스와핑(swapping)으로 인해 프로세스가 디스크로 내려갔다가 다시 메모리의 다른 위치로 올라올 수 있습니다. 이를 위해서는 하드웨어적인 지원이 필수적입니다. 대표적으로 MMU(Memory Management Unit) 내의 기준 레지스터(base register)와 한계 레지스터(limit register) 또는 페이징/세그먼테이션 하드웨어가 이 역할을 합니다. CPU가 생성하는 주소는 논리 주소이고, 이것이 MMU를 통해 물리 주소로 실시간 변환됩니다. 장점: 가장 유연한 방식입니다. 메모리 공간을 효율적으로 관리할 수 있게 해줍니다 (예: 압축, 스와핑). 단점: 주소 변환을 위한 하드웨어 비용이 들고, 매 메모리 접근마다 주소 변환 과정이 추가되어 약간의 시간 오버헤드가 있을 수 있습니다 (보통 매우 빠름). 대부분의 현대 운영체제는 실행 시간 바인딩을 사용합니다.","buddy-system-버디-시스템#Buddy System (버디 시스템)":"For allocation of a process (프로세스 할당 시) Divide the free memory block into two blocks (가용 메모리 블록을 두 개의 블록으로 나눔) until it best fits to the block (블록에 가장 잘 맞을 때까지) For deallocation of a process (프로세스 해제 시) Merge the freed block with buddy block (해제된 블록을 버디 블록과 합병) buddy block → The other block when it was divided into two (버디 블록 → 두 개로 나뉘었을 때의 다른 쪽 블록) Has both internal/external fragmentations (내부/외부 단편화 모두 발생 가능) [설명]\n버디 시스템은 동적 할당의 한 형태로, 외부 단편화를 줄이면서도 가용 블록 관리를 비교적 쉽게 하려는 기법입니다.\n기본 아이디어: 메모리 블록 크기를 2의 거듭제곱 형태로 제한합니다 (예: 2k 바이트). 할당 과정: 프로세스가 크기 S의 메모리를 요청하면, 2k−1","cache#cache":"","cache-design#cache design":"","cache-mapping-function#cache mapping function":"","cache-mapping-function-replace-algorithm#cache mapping function replace algorithm":"","cache-vs-main-memory#cache vs main memory":"","cache-write-policy#cache write policy":"","cars-in-intersection-again#Cars in Intersection, again":"","computer-organization#Computer Organization":"","context-switch-time-including-swapping-스와핑을-포함한-문맥-교환-시간#Context Switch Time including Swapping (스와핑을 포함한 문맥 교환 시간)":"If next processes to be put on CPU is not in memory, need to swap out a process and swap in target process (CPU에 다음에 놓일 프로세스가 메모리에 없다면, 한 프로세스를 스왑 아웃하고 대상 프로세스를 스왑 인해야 합니다) Context switch time can then be very high (그러면 문맥 교환 시간이 매우 길어질 수 있습니다) 100MB process swapping to hard disk with transfer rate of 50MB/sec (50MB/초의 전송률을 가진 하드 디스크로 100MB 프로세스 스와핑) Plus disk latency of 8 ms (디스크 지연 시간 8ms 추가) Swap out time of 2008 ms (스왑 아웃 시간 2008ms) Plus swap in of same sized process (동일 크기 프로세스의 스왑 인 추가) Total context switch swapping component time of 4016ms (\u003e 4 seconds) (총 문맥 교환 스와핑 요소 시간 4016ms (\u003e 4초)) Can reduce if reduce size of memory swapped – by knowing how much memory really being used (실제로 사용되는 메모리 양을 앎으로써 스왑되는 메모리 크기를 줄이면 감소 가능) System calls to inform OS of memory use via request memory and release memory (메모리 요청 및 해제 시스템 호출을 통해 OS에 메모리 사용량을 알림) [설명]\n스와핑이 문맥 교환(context switch) 시간에 미치는 영향을 설명합니다. 문맥 교환은 CPU가 한 프로세스에서 다른 프로세스로 실행을 전환하는 과정입니다.\n스와핑과 문맥 교환: 만약 다음으로 실행될 프로세스가 현재 메모리에 없고 백킹 스토어에 있다면, 문맥 교환의 일부로 스와핑 작업이 필요하게 됩니다. 즉, 현재 메모리에 있는 어떤 프로세스를 디스크로 스왑 아웃하고 (공간 확보를 위해), 디스크에 있는 다음 실행 프로세스를 메모리로 스왑 인해야 합니다. 매우 높은 문맥 교환 비용: 스와핑은 디스크 I/O를 포함하므로 매우 느립니다. 따라서 스와핑이 필요한 문맥 교환은 그렇지 않은 경우보다 훨씬 더 많은 시간이 소요됩니다. 예시 계산: 프로세스 크기: 100MB 디스크 전송률: 50MB/초 디스크 지연 시간 (latency - 탐색 시간 + 회전 지연 시간 등): 8ms 스왑 아웃 시간: 전송 시간 = 100MB / 50MB/초 = 2초 = 2000ms 총 스왑 아웃 시간 = 전송 시간 + 지연 시간 = 2000ms + 8ms = 2008ms 스왑 인 시간: 동일 크기 프로세스를 스왑 인하는 데도 유사한 시간(2008ms)이 소요됩니다. 총 스와핑 관련 문맥 교환 시간: 스왑 아웃 시간 + 스왑 인 시간 = 2008ms + 2008ms = 4016ms, 즉 4초가 넘습니다. 이는 일반적인 CPU 작업에 비해 엄청나게 긴 시간입니다. CPU는 이 시간 동안 거의 아무 일도 못하고 기다리게 됩니다. 스왑 크기 줄이기: 스왑되는 데이터의 양을 줄이면 스왑 시간을 단축할 수 있습니다. 프로세스가 할당받은 전체 메모리 영역이 아니라, 그중에서도 실제로 사용하고 있는 부분만 스왑 대상으로 삼으면 됩니다. (예: 프로그램 코드 중에서도 자주 안 쓰이는 부분, 데이터 중에서도 현재 접근하지 않는 부분 등) 운영체제는 프로세스가 실제로 어느 정도의 메모리를 사용하는지 파악할 필요가 있습니다. 이를 위해 프로세스가 request_memory() (메모리 더 필요) 또는 release_memory() (이 메모리 더 이상 안 씀) 같은 시스템 호출을 통해 운영체제에 메모리 사용 현황을 알려줄 수 있습니다. (현대 가상 메모리 시스템에서는 페이지 단위로 사용 여부를 추적하여 더 정교하게 관리합니다.) 결론적으로, 프로세스 전체를 스왑하는 방식은 비용이 매우 크므로, 현대 시스템에서는 필요한 부분(페이지)만 스왑하는 페이징 기법을 주로 사용하며, 스와핑 발생 자체를 최소화하려고 노력합니다.","contiguous-allocation-cont-연속-할당-계속#Contiguous Allocation (Cont.) (연속 할당 (계속))":"Multiple-partition allocation (다중 파티션 할당) Degree of multiprogramming limited by number of partitions (다중 프로그래밍의 정도는 파티션 수에 의해 제한됨) Hole – block of available memory; holes of various size are scattered throughout memory (홀 – 사용 가능한 메모리 블록; 다양한 크기의 홀들이 메모리 전체에 흩어져 있음) When a process arrives, it is allocated memory from a hole large enough to accommodate it (프로세스가 도착하면, 그것을 수용할 만큼 충분히 큰 홀로부터 메모리를 할당받음) Process exiting frees its partition, adjacent free partitions combined (프로세스가 종료되면 그 파티션을 반환하고, 인접한 가용 파티션들은 합쳐짐) Operating system maintains information about: (운영체제는 다음에 대한 정보를 유지함:) a) allocated partitions (할당된 파티션들) b) free partitions (hole) (가용 파티션들 (홀)) (Diagram showing OS, process 5, process 8, process 2 initially. Then process 8 exits, leaving a hole. Then process 9 arrives and is allocated. Then process 5 exits. Then process 10 arrives and is allocated in the hole left by process 5 or another hole.) [설명]\n이 슬라이드는 연속 할당 방식 중에서도 주로 **동적 분할(Dynamic Partitioning)**에서의 다중 파티션 할당 상황을 설명하고 있습니다. (고정 분할도 다중 파티션이지만, 여기서 설명하는 ‘hole’의 생성과 관리, 인접 홀 병합 등은 동적 분할의 특징에 더 가깝습니다.)\n다중 파티션 할당: 메모리가 여러 개의 파티션으로 나뉘어 여러 프로세스를 동시에 적재하는 방식입니다. 다중 프로그래밍 정도 제한: (고정 분할의 경우) 파티션의 개수가 동시에 실행될 수 있는 프로세스의 최대 수를 결정합니다. 동적 분할의 경우에도 사용 가능한 메모리 총량과 외부 단편화 정도에 따라 제한됩니다. 홀 (Hole): 메모리 내에서 현재 사용되지 않고 비어 있는 가용 메모리 블록을 ‘홀’이라고 부릅니다. 동적 분할에서는 프로세스들이 할당되고 해제됨에 따라 다양한 크기의 홀들이 메모리 전체에 흩어져 나타납니다. 프로세스 도착 시 할당: 새로운 프로세스가 시스템에 도착하면, 운영체제는 현재 있는 홀들 중에서 해당 프로세스를 수용할 수 있을 만큼 충분히 큰 홀을 찾아 메모리를 할당합니다. (이때 First-fit, Best-fit, Worst-fit 등의 할당 전략이 사용됩니다.) 프로세스 종료 시 반환 및 병합: 프로세스가 실행을 마치고 종료되면, 그 프로세스가 사용하던 메모리 공간은 다시 가용 상태(홀)가 됩니다. 만약 새로 생긴 이 홀이 기존의 다른 홀(들)과 물리적으로 인접해 있다면, 이들은 하나의 더 큰 홀로 합병(merge 또는 coalesce)됩니다. 이는 작은 홀들이 너무 많이 생기는 것을 방지하여 외부 단편화를 줄이는 데 도움이 됩니다. 운영체제의 정보 관리: 운영체제는 메모리 관리를 위해 현재 어떤 부분들이 이미 할당된 파티션인지, 그리고 어떤 부분들이 가용 상태인 홀인지에 대한 정보를 리스트나 테이블 형태로 계속 추적하고 유지해야 합니다. (예: 각 블록의 시작 주소, 크기, 상태(할당/가용) 등) 다이어그램 설명:\n그림은 시간의 흐름에 따른 메모리 상태 변화를 보여줍니다.\n초기: OS, P5, P8, P2가 메모리에 적재되어 있습니다. P8 종료: P8이 있던 자리가 홀로 변합니다. (OS, P5, [hole1], P2) P9 도착 및 할당: P9이 hole1 또는 다른 적절한 홀에 할당됩니다 (그림에서는 P8 자리에 P9이 들어감). (OS, P5, P9, P2) P5 종료: P5가 있던 자리가 홀로 변합니다. ([hole2], P9, P2) (OS는 생략된 듯) P10 도착 및 할당: P10이 P5가 남긴 hole2 또는 다른 홀에 할당됩니다. (P10, P9, P2) 이러한 과정이 반복되면서 메모리에는 사용 중인 프로세스들과 다양한 크기의 홀들이 섞여 존재하게 되며, 외부 단편화가 발생할 가능성이 커집니다.","contiguous-allocation-연속-할당#Contiguous Allocation (연속 할당)":"Main memory usually into two partitions: (주 기억장치는 대개 두 개의 파티션으로 나뉨:) Resident operating system, usually held in low memory with interrupt vector (상주 운영체제, 보통 인터럽트 벡터와 함께 낮은 메모리 주소에 위치) User processes then held in high memory (사용자 프로세스들은 그 후 높은 메모리 주소에 위치) Each process contained in single contiguous section of memory (각 프로세스는 메모리의 단일 연속된 구역에 포함됨) Relocation registers used to protect user processes from each other, and from changing operating-system code and data (재배치 레지스터는 사용자 프로세스들을 서로로부터, 그리고 운영체제 코드 및 데이터 변경으로부터 보호하는 데 사용됨) Base register contains value of smallest physical address (기준 레지스터는 가장 작은 물리 주소값을 가짐) Limit register contains range of logical addresses – each logical address must be less than the limit register (한계 레지스터는 논리 주소의 범위를 가짐 – 각 논리 주소는 한계 레지스터보다 작아야 함) MMU maps logical address dynamically (MMU가 논리 주소를 동적으로 매핑함) Can then allow actions such as kernel code being transient and kernel changing size (그러면 커널 코드의 일부가 일시적이 되거나 커널 크기가 변경되는 등의 동작을 허용할 수 있음) [설명]\n연속 할당은 가장 단순한 메모리 할당 방식 중 하나로, 각 프로세스가 메모리의 한 군데에 연속적인 공간을 할당받는 것을 의미합니다. 고정 분할과 동적 분할 모두 이 범주에 속합니다.\n메모리 구조: 주 기억장치는 일반적으로 두 부분으로 나뉩니다. 운영체제 영역: 주로 낮은 주소 영역(low memory)을 차지하며, 시스템 부팅 및 운영에 필수적인 커널 코드, 데이터, 인터럽트 벡터 테이블 등이 위치합니다. 이 부분은 사용자 프로세스로부터 보호됩니다. 사용자 프로세스 영역: 운영체제 영역 다음의 높은 주소 영역(high memory)에 사용자 프로세스들이 적재됩니다. 단일 연속 구역: 각 사용자 프로세스는 메모리 내에서 물리적으로 연속된 하나의 덩어리(block)로 적재됩니다. 예를 들어, 100KB 크기의 프로세스는 100KB의 연속된 메모리 공간을 차지하며, 여러 조각으로 나뉘어 저장되지 않습니다. 보호 및 재배치를 위한 레지스터: 재배치 레지스터 (Relocation Register, 또는 기준 레지스터 Base Register): 프로세스가 적재된 물리 메모리의 시작 주소를 저장합니다. CPU가 생성하는 논리 주소에 이 값을 더하여 물리 주소를 얻습니다. 이를 통해 프로세스를 메모리의 어느 위치에든 적재(재배치)할 수 있게 됩니다. 한계 레지스터 (Limit Register): 프로세스의 논리 주소 공간의 크기(길이)를 저장합니다. CPU가 생성하는 논리 주소는 이 한계 레지스터 값보다 작아야 합니다. 이를 통해 프로세스가 자신에게 할당된 메모리 영역을 벗어나 다른 프로세스나 운영체제의 영역을 침범하는 것을 방지합니다. MMU의 역할: 이러한 재배치 및 한계 검사는 MMU(Memory Management Unit)라는 하드웨어에 의해 실행 시간에 동적으로 이루어집니다. 커널 유연성: 이러한 하드웨어 지원(MMU, 재배치/한계 레지스터)은 운영체제 커널 자체의 관리에도 유연성을 제공합니다. 예를 들어, 커널의 일부 모듈을 필요에 따라 메모리에 적재하거나 내릴 수 있게 하고(transient kernel code), 시스템 실행 중에 커널이 사용하는 메모리 크기를 동적으로 변경하는 것도 가능하게 합니다. 연속 할당은 구현이 비교적 간단하지만, 앞서 논의된 고정 분할의 내부 단편화 문제나 동적 분할의 외부 단편화 문제를 야기할 수 있습니다. 이러한 문제를 해결하기 위해 비연속 할당 방식인 페이징과 세그먼테이션이 등장하게 됩니다.","cpu-scheduling#CPU scheduling":"","data-structures-for-the-bankers-algorithm#Data Structures for the Banker’s Algorithm":"","deadlock#deadlock":"상호 배제 (Mutual Exclusion) 한 자원은 동시에 하나의 프로세스만 사용 가능 특정 파일을 여러 프로세스가 동시에 읽을 수 있는 경우는 해당하지 않는다 보유 및 대기 (Hold and Wait) 이미 자원을 가지고 있는 프로세스가 다른 자원을 기다림 2개 이상 자원이 필요한 프로세스 비선점 (No Preemption) 자원은 강제로 빼앗을 수 없고, 프로세스가 자발적으로 반납해야 함 외부에 의해 정지되지 않는 논리과정 순환 대기 (Circular Wait) 프로세스 집합 {P0, P1, …, Pn}에서, P0는 P1이 가진 자원을 기다리고, P1은 P2의 자원을 기다리며…, 마지막으로 Pn은 다시 P0의 자원을 기다리는 구조 순환","deadlock-1#deadlock":"","demand-paging#\u003cstrong\u003eDemand Paging\u003c/strong\u003e":"","description#description":"이 슬라이드는 교착 상태 처리 전략 중 하나인 **교착 상태 회피(Deadlock Avoidance)**의 기본 개념을 소개합니다. 교착 상태 예방(Prevention)이 교착 상태 발생 조건 자체를 원천적으로 제거하려는 정적인 접근 방식이라면, 교착 상태 회피는 보다 동적인 접근 방식을 취합니다. 🚦\n핵심 아이디어:\n교착 상태 회피는 시스템이 자원을 할당할 때마다 해당 할당이 미래에 교착 상태를 유발할 가능성이 있는지 여부를 실시간으로 판단하고, 안전하다고 판단될 때만 자원을 할당하는 전략입니다. 마치 복잡한 도로에서 운전할 때, 현재의 차선 변경이 미래의 충돌 사고로 이어질지를 미리 예측하고 안전한 경우에만 차선을 변경하는 것과 유사합니다.\n동적 결정 (A decision is made dynamically):\n프로세스가 자원을 요청하면, 운영체제는 그 요청을 즉시 승인하지 않습니다. 대신, “이 요청을 들어주었을 때, 시스템이 **불안전 상태(unsafe state)**로 진입하여 결국 교착 상태에 빠질 가능성은 없는가?“를 평가합니다. 이 평가는 시스템의 현재 상태(현재 자원 할당 상태, 가용 자원 등)와 앞으로 예상되는 프로세스들의 행동을 기반으로 이루어집니다.\n잠재적 교착 상태 예측 (potentially lead to a deadlock):\n회피 기법은 현재의 자원 할당이 당장은 문제가 없어 보여도, 이후 다른 프로세스들의 자원 요청이 연쇄적으로 발생했을 때 교착 상태로 이어질 수 있는 “잠재적 위험\"을 감지하려고 합니다. 즉, 현재의 결정이 미래에 미칠 영향을 고려하는 것입니다.\n미래 요청에 대한 정보 요구 (Requires knowledge of future process requests):\n이것이 교착 상태 회피 기법의 가장 큰 특징이자 전제 조건입니다. 시스템이 “안전한” 할당을 하기 위해서는 각 프로세스가 앞으로 최대 얼마만큼의 자원을 요청할 것인지(maximum claim), 또는 앞으로 어떤 순서로 자원을 요청할 것인지에 대한 사전 정보가 필요합니다. 이 정보가 없다면 미래의 위험을 예측할 수 없으므로 회피 기법을 적용하기 어렵습니다.\n예를 들어, 각 프로세스는 시작 시 자신이 실행 중에 최대로 사용할 각 자원 유형의 인스턴스 수를 운영체제에 미리 선언해야 합니다. 이 정보는 은행가 알고리즘(Banker’s Algorithm)과 같은 회피 알고리즘에서 중요한 입력값으로 사용됩니다. 교착 상태 예방(Prevention)과의 차이점:\n예방: 교착 상태의 네 가지 조건 중 하나를 원천적으로 부정하여 교착 상태가 발생할 수 없도록 하는 엄격한 규칙을 시스템 설계 시부터 적용합니다. (예: 모든 자원 순서대로 요청) 회피: 교착 상태의 조건 자체를 부정하지는 않지만, 자원 할당 시마다 현재 상태와 미래의 자원 요구량을 고려하여 교착 상태로 이어지지 않는 “안전한 경로\"로만 시스템을 운영합니다. 예방보다는 덜 제약적일 수 있지만, 미래 정보가 필요하고 동적 검사로 인한 오버헤드가 발생할 수 있습니다. 교착 상태 회피는 교착 상태 예방보다 자원 활용률을 높일 수 있는 잠재력을 가지고 있습니다. 왜냐하면 예방처럼 모든 상황에 대해 엄격한 제약을 가하는 대신, 실제 위험이 있을 때만 할당을 보류하기 때문입니다. 하지만 미래 자원 요구량에 대한 정확한 정보가 필요하고, 매번 자원 할당 시 안전성 검사를 수행해야 하는 부담이 있습니다. 이어지는 슬라이드에서는 이러한 회피 기법의 구체적인 두 가지 접근 방식을 설명할 것입니다.","description-1#description":"이 슬라이드는 교착 상태 회피(Deadlock Avoidance)를 구현하는 두 가지 주요 전략을 소개합니다. 두 전략 모두 시스템이 불안전 상태(unsafe state)로 진입하여 결국 교착 상태에 빠지는 것을 방지하려는 목적을 가지지만, 적용 시점과 대상에서 차이가 있습니다. 🧐\n1. 프로세스 개시 거부 (Process Initiation Denial):\n개념: 새로운 프로세스가 시스템에서 실행을 시작하려 할 때, 이 프로세스의 **최대 자원 요구량(maximum claim)**을 고려하여 시스템 진입 여부를 결정하는 방식입니다. 작동 원리: 프로세스가 시작되기 전에, 해당 프로세스가 최대로 필요로 할 자원의 양을 시스템에 알립니다. 운영체제는 현재 실행 중인 다른 프로세스들의 최대 자원 요구량과 새로 시작하려는 프로세스의 최대 자원 요구량을 합쳤을 때, 시스템이 감당할 수 있는 범위 내에 있는지, 그리고 이러한 요구들이 동시에 발생하더라도 시스템이 교착 상태에 빠지지 않고 모든 프로세스를 완료시킬 수 있는지를 판단합니다. 만약 새로운 프로세스를 시스템에 참여시키는 것이 잠재적으로 교착 상태를 유발할 위험이 있다고 판단되면 (즉, 안전한 실행 순서를 보장할 수 없다면), 해당 프로세스의 시작 자체를 거부하거나 보류합니다. 예시: 시스템에 총 10개의 테이프 드라이브가 있고, 현재 실행 중인 프로세스 A, B가 각각 최대 4개, 5개를 사용한다고 가정합시다. 새로운 프로세스 C가 최대 3개의 테이프 드라이브를 요구하며 시작하려 합니다. 만약 A, B, C가 동시에 최대 요구량을 요청하면 4+5+3=12개가 필요하므로 시스템 자원(10개)을 초과합니다. 이런 단순한 총량 비교 외에도, 이들의 요청을 안전하게 처리할 수 있는 순서가 있는지를 더 정교하게 판단하여 C의 시작 여부를 결정합니다. 특징: 프로세스 실행의 초기 단계에서 교착 상태 위험을 평가하고 제어합니다. 2. 자원 할당 거부 (Resource Allocation Denial):\n개념: 이미 실행 중인 프로세스가 **추가적인 자원(incremental resource)**을 요청할 때, 이 요청을 승인할 경우 시스템이 불안전 상태로 진입할지를 판단하여 할당 여부를 결정하는 방식입니다. 이것이 바로 유명한 **은행가 알고리즘(Banker’s Algorithm)**이 사용하는 전략입니다. 작동 원리: 프로세스는 실행 도중 필요한 자원을 운영체제에 요청합니다. 운영체제는 해당 요청을 즉시 들어주는 대신, “만약 이 요청을 승인하여 자원을 할당한다면, 시스템의 상태가 어떻게 변할 것인가?” 그리고 “변경된 상태가 여전히 안전 상태인가?“를 검사합니다. 안전 상태란, 시스템 내의 모든 프로세스들이 교착 상태 없이 각각의 작업을 완료할 수 있는 실행 순서(safe sequence)가 최소한 하나 이상 존재하는 상태를 의미합니다. 만약 요청된 자원을 할당했을 때 시스템이 불안전 상태(안전 순서가 존재하지 않는 상태)로 변하게 된다면, 운영체제는 해당 자원 요청을 거부하고 프로세스를 대기시킵니다. 요청을 승인해도 안전 상태가 유지된다면 자원을 할당합니다. 예시: 프로세스 P1이 현재 자원 X를 1개 사용 중이고, 추가로 1개를 더 요청했습니다. 시스템에는 가용 자원 X가 충분히 있지만, 만약 이 할당으로 인해 다른 프로세스 P2, P3 등이 앞으로 필요한 자원을 얻지 못하게 되어 교착 상태에 빠질 가능성이 생긴다면, P1의 요청은 일단 거부됩니다. 특징: 프로세스 실행 중에 발생하는 개별 자원 요청에 대해 동적으로 교착 상태 위험을 평가하고 제어합니다. 두 접근법의 관계:\n프로세스 개시 거부는 시스템에 참여하는 프로세스의 수와 그들의 최대 요구량을 조절하여 초기 단계에서 위험을 줄이는 반면, 자원 할당 거부는 이미 실행 중인 프로세스들의 실제 자원 사용 패턴에 따라 더 세밀하게 할당을 제어합니다. 실제 시스템에서는 이 두 가지 방법이 함께 사용될 수도 있고, 주로 자원 할당 거부 방식(은행가 알고리즘)이 교착 상태 회피의 대표적인 방법으로 논의됩니다.\n두 방법 모두 각 프로세스의 **미래 자원 요구량(보통 최대 요구량)**에 대한 사전 정보가 필요하다는 공통적인 제약 조건을 가지고 있습니다. 이 정보의 정확성이 회피 전략의 효과에 큰 영향을 미칩니다.","description-10#description":"이 슬라이드 또한 “Unsafe State In Resource-Allocation Graph\"라는 제목만을 포함하고 있어, 자원 할당 그래프에서 **불안전 상태(unsafe state)**가 어떻게 시각적으로 나타나는지 또는 어떤 조건을 만족할 때 불안전 상태로 간주되는지에 대한 구체적인 예시나 설명을 기대하게 합니다.\n**안전 상태(safe state)**와 **불안전 상태(unsafe state)**의 개념은 주로 **은행원 알고리즘(Banker’s Algorithm)**과 같은 교착 상태 회피 알고리즘에서 중요하게 다루어집니다. 시스템이 안전 상태에 있다는 것은 모든 프로세스에 대해, 프로세스가 요청한 자원을 모두 할당하여 프로세스가 종료될 수 있는 **안전 순서열(safe sequence)**이 존재한다는 것을 의미합니다. 반면, 불안전 상태는 그러한 안전 순서열을 찾을 수 없는 상태를 말합니다. 불안전 상태가 반드시 교착 상태를 의미하는 것은 아니지만, 교착 상태가 발생할 가능성이 있는 상태를 의미합니다. 즉, 불안전 상태는 교착 상태로 이어질 수 있는 잠재적인 위험을 내포하고 있습니다.\n자원 할당 그래프의 관점에서 불안전 상태를 이해하려면, 단순히 사이클의 존재 여부뿐만 아니라 자원의 가용성(availability)과 프로세스의 최대 요구량(maximum claim)을 함께 고려해야 합니다.\n불안전 상태의 특징 (자원 할당 그래프와 관련하여):\n사이클의 존재 가능성: 자원 할당 그래프에서 사이클이 존재하면 교착 상태가 발생할 수 있습니다. 특히, 모든 자원 유형에 하나의 인스턴스만 있는 경우, 사이클은 교착 상태를 의미합니다. 그러나 여러 인스턴스가 있는 경우, 사이클이 있더라도 시스템이 안전할 수 있습니다 (즉, 사이클이 교착 상태를 의미하지 않을 수도 있습니다). 안전 순서열의 부재: 시스템이 불안전 상태라는 것은 현재 가용한 자원만으로는 더 이상 어떤 프로세스도 자신의 작업을 완료할 수 있도록 충분한 자원을 할당할 수 있는 순서열을 찾을 수 없음을 의미합니다. 즉, 현재 상태에서 어떤 프로세스가 자원을 요청하더라도, 그 요청을 들어주면 시스템이 교착 상태에 빠질 위험이 커진다는 것입니다. 교착 상태의 잠재적 위험: 불안전 상태는 교착 상태가 발생할 수 있는 “경고 신호\"로 볼 수 있습니다. 시스템은 불안전 상태에 진입하는 것을 피하려고 노력하며, 이를 위해 자원 할당 요청이 들어올 때마다 시스템이 안전 상태를 유지할 수 있는지 여부를 확인합니다. 만약 요청을 승인하면 불안전 상태가 될 가능성이 있다면, 해당 요청을 보류시킵니다. 자원 할당 그래프에서 구체적인 불안전 상태의 예시를 보여준다면, 다음과 같은 상황을 묘사할 수 있습니다:\n프로세스들이 자원을 요청하고 있으나, 가용 자원이 부족하여 어떤 프로세스도 당장 작업을 완료할 수 없는 상황. 그래프에 사이클이 존재하며, 이 사이클에 포함된 프로세스들이 모두 서로가 쥐고 있는 자원을 기다리는 상황. 결론적으로, 이 슬라이드는 자원 할당 그래프를 통해 시스템의 안전성을 분석하는 맥락에서 “불안전 상태\"라는 핵심 개념을 소개하며, 이는 곧 교착 상태를 회피하기 위한 알고리즘의 필요성을 제기하는 중요한 전환점이 됩니다. 다음 슬라이드에서는 이러한 불안전 상태를 방지하기 위한 구체적인 알고리즘인 “Resource-Allocation Graph Algorithm\"이 소개될 것으로 예상됩니다.","description-11#description":"이 슬라이드는 **자원 할당 그래프 알고리즘(Resource-Allocation Graph Algorithm)**의 핵심 원칙을 설명합니다. 이 알고리즘은 교착 상태 회피(deadlock avoidance) 전략 중 하나로, 자원 요청이 들어올 때마다 시스템이 안전한 상태를 유지할 수 있는지 여부를 동적으로 검사합니다. 특히, 이 알고리즘은 자원 유형당 인스턴스가 하나만 있는 경우에 효과적으로 적용될 수 있습니다.\n알고리즘의 작동 방식은 다음과 같습니다:\n자원 요청 상황: 먼저, 특정 프로세스 Pi​가 자원 Rj​를 요청했다고 가정합니다. 이는 자원 할당 그래프에서 프로세스 Pi​에서 자원 Rj​로 향하는 요청 간선(Pi​→Rj​)이 존재함을 의미합니다.\n할당 시뮬레이션 및 사이클 검사: 시스템은 이 요청을 즉시 승인하는 대신, 만약 자원 Rj​가 Pi​에 할당된다면 어떤 일이 일어날지 “가상으로” 시뮬레이션해 봅니다. 이 시뮬레이션은 요청 간선(Pi​→Rj​)을 할당 간선(Rj​→Pi​)으로 변환하는 것으로 나타납니다. 즉, 프로세스 Pi​가 자원 Rj​를 얻게 되는 상황을 가정하는 것입니다.\n승인 조건: 이 가상 할당 후에 자원 할당 그래프에 새로운 사이클이 형성되지 않는다면, 해당 자원 요청은 안전하게 승인될 수 있습니다. 사이클이 형성되지 않는다는 것은 시스템이 여전히 안전 상태에 있거나, 적어도 교착 상태로 이어질 직접적인 경로가 없음을 의미합니다.\n요청 거부 또는 지연: 만약 가상 할당 후에 그래프에 사이클이 형성된다면, 해당 자원 요청은 승인되지 않거나 (즉시 거부되거나) 지연됩니다. 이는 요청을 승인할 경우 교착 상태가 발생할 가능성이 매우 높다는 것을 의미하기 때문입니다. 프로세스 Pi​는 자원 Rj​가 해제될 때까지 기다려야 하거나, 시스템 관리자가 개입하여 교착 상태를 해결해야 할 수도 있습니다.\n이 알고리즘의 중요성:\n교착 상태 회피: 이 알고리즘은 교착 상태가 발생하기 전에 잠재적인 위험을 감지하고 회피하는 데 중점을 둡니다. 이는 교착 상태가 일단 발생하면 이를 탐지하고 복구하는 것보다 훨씬 효율적인 방법입니다. 사이클 탐지: 그래프에서 사이클을 탐지하는 것은 깊이 우선 탐색(DFS)이나 너비 우선 탐색(BFS)과 같은 표준 그래프 알고리즘을 사용하여 효율적으로 수행할 수 있습니다. 제한 사항: 이 알고리즘은 주로 자원 유형당 단일 인스턴스만 존재하는 시스템에 적합합니다. 만약 자원 유형에 여러 인스턴스가 있다면, 단순히 사이클의 존재만으로는 교착 상태를 단정할 수 없으며, **은행원 알고리즘(Banker’s Algorithm)**과 같은 더 복잡한 접근 방식이 필요합니다. 이는 은행원 알고리즘이 시스템의 가용 자원, 최대 요구량, 할당된 자원 등을 종합적으로 고려하여 안전 순서열의 존재 여부를 판단하기 때문입니다. 결론적으로, 자원 할당 그래프 알고리즘은 간단하면서도 효과적인 교착 상태 회피 메커니즘을 제공하지만, 그 적용 범위는 자원 유형당 인스턴스 수에 따라 제한될 수 있습니다.","description-12#description":"이 슬라이드는 **잠재적 교착 상태(Potential Deadlock)**의 개념을 추상적인 예시를 통해 설명합니다. “quad A and B”, “quad B and C” 등의 표현은 어떤 자원 그룹 또는 영역을 의미하는 것으로 보입니다. 이 예시에서 각 문장은 특정 주체가 두 가지 이상의 자원(이 경우, “quad A”, “quad B”, “quad C”, “quad D\"로 명명된 사분면)을 동시에 필요로 한다는 것을 나타냅니다.\n이러한 상황은 다음과 같은 방식으로 잠재적 교착 상태를 유발할 수 있습니다:\n자원 요청의 상호 의존성: 각 주체(여기서는 “I\"로 표현된 어떤 주체들)는 두 개의 사분면을 필요로 합니다. 만약 이들이 요청하는 사분면 중 일부가 이미 다른 주체에 의해 점유되어 있다면, 자원을 얻기 위해 기다려야 합니다.\n“나는 A와 B 사분면이 필요하다” (주체 1) “나는 B와 C 사분면이 필요하다” (주체 2) “나는 C와 B 사분면이 필요하다” (주체 3 - 주체 2와 유사하지만 요청 순서나 주체가 다를 수 있음) “나는 D와 A 사분면이 필요하다” (주체 4) 순환 대기 조건 형성: 교착 상태가 발생하려면 네 가지 필요 조건(상호 배제, 점유 및 대기, 비선점, 순환 대기)이 충족되어야 합니다. 이 예시에서는 순환 대기(circular wait) 조건이 형성될 가능성이 높습니다.\n만약 주체 1이 A를 가지고 B를 기다리고, 주체 2가 B를 가지고 C를 기다리고, 주체 3이 C를 가지고 B를 기다리고 (또는 어떤 주체가 C를 가지고 D를 기다리고), 주체 4가 D를 가지고 A를 기다리는 상황이 발생한다면, 주체 1 (A 보유, B 대기) -\u003e 주체 2 (B 보유, C 대기) -\u003e 주체 3 (C 보유, D 대기) -\u003e 주체 4 (D 보유, A 대기) -\u003e 주체 1\n이러한 순환적인 대기 상황은 아무도 자원을 해제하지 않고 서로가 필요한 자원을 기다리는 교착 상태로 이어질 수 있습니다.\n자원의 제한성: 여기서 “quad\"는 제한된 수의 인스턴스를 가진 자원을 의미할 가능성이 높습니다. 예를 들어, 각 사분면이 단 하나의 주체만 사용할 수 있는 자원이라면 상호 배제 조건이 충족됩니다.\n이 슬라이드는 실제 시스템의 복잡한 자원 할당 시나리오를 단순화하여 보여주며, 여러 프로세스(여기서는 “I\"로 칭해진 주체들)가 서로 다른 자원을 동시에 요청할 때 어떻게 잠재적인 교착 상태가 발생할 수 있는지 직관적으로 이해하도록 돕습니다. 즉, 현재 당장 교착 상태가 발생한 것은 아니지만, 잘못된 자원 할당 순서나 불운한 타이밍으로 인해 쉽게 교착 상태에 빠질 수 있는 위험한 상태를 의미합니다. 다음 슬라이드에서는 이러한 잠재적 교착 상태가 실제로 어떻게 “Actual Deadlock\"으로 발전하는지를 보여줄 수 있습니다.","description-13#description":"이 슬라이드는 “Resource Allocation Diagram\"이라는 제목만을 포함하고 있어, 앞서 “Potential Deadlock” 슬라이드에서 제시된 추상적인 시나리오(“I need quad A and B” 등)를 구체적인 자원 할당 그래프(Resource Allocation Graph) 또는 이와 유사한 다이어그램으로 시각화한 내용을 담고 있을 것으로 예상됩니다. 이 다이어그램은 프로세스와 자원 간의 관계를 그래픽으로 표현하여 교착 상태의 발생 가능성을 분석하는 데 사용됩니다.\n일반적인 자원 할당 다이어그램에는 다음과 같은 요소들이 포함될 수 있습니다:\n프로세스 (Processes): 시스템에서 실행 중인 작업을 나타내며, 보통 원형 노드로 표현됩니다. 자원 유형 (Resource Types): 시스템에서 사용 가능한 자원의 종류를 나타내며, 보통 사각형 노드로 표현됩니다. 자원 인스턴스 (Resource Instances): 각 자원 유형 내에 있는 개별 자원 단위를 나타내며, 자원 유형 노드 내의 점 또는 작은 원으로 표시됩니다. 요청 간선 (Request Edges): 프로세스에서 자원 유형으로 향하는 화살표(예: Pi​→Rj​). 프로세스 Pi​가 자원 Rj​의 인스턴스를 요청하고 있음을 나타냅니다. 할당 간선 (Assignment Edges): 자원 인스턴스에서 프로세스로 향하는 화살표(예: Rj​⋅→Pi​). 자원 Rj​의 인스턴스가 프로세스 Pi​에 할당되어 있음을 나타냅니다. 앞선 “Potential Deadlock” 슬라이드에서 언급된 “quad A”, “quad B”, “quad C”, “quad D\"는 자원 유형이 될 수 있고, 각 “I\"는 프로세스가 될 수 있습니다. 이 다이어그램에서는 각 프로세스가 어떤 “quad” 자원을 현재 보유하고 있고 어떤 “quad” 자원을 기다리고 있는지 명확하게 보여줄 것입니다.\n예상되는 시각적 표현의 특징:\n여러 프로세스 노드와 여러 자원 유형 노드가 존재할 것입니다. 프로세스에서 자원으로 향하는 요청 간선(예: P1​→Quad B)과 자원 인스턴스에서 프로세스로 향하는 할당 간선(예: Quad A→P1​)이 나타날 것입니다. 아마도 이전 슬라이드에서 언급된 “I need quad A and B\"와 같은 문장이 실제 다이어그램에서는 P1​이 Quad A를 보유하고 P1​→Quad B 요청 간선을 가지는 형태로 표현될 수 있습니다. 잠재적 교착 상태를 보여주기 위해, 다이어그램 내에 **사이클(cycle)**이 형성되어 있을 가능성이 높습니다. 이 사이클은 프로세스들이 서로가 보유하고 있는 자원을 기다리는 순환 대기(circular wait) 상태를 시각적으로 나타낼 것입니다. 그러나 이 사이클이 반드시 실제 교착 상태를 의미하지는 않습니다. 잠재적이라는 것은 아직은 교착 상태가 아니지만, 조금만 더 자원 할당이 잘못되면 바로 교착 상태로 이어질 수 있다는 경고를 의미합니다. 이 슬라이드는 추상적인 개념을 구체적인 예시로 연결하여 교착 상태의 원인과 메커니즘을 더 쉽게 이해하도록 돕는 역할을 합니다.","description-14#description":"이 슬라이드 또한 “Resource Allocation Diagram\"이라는 제목만을 가지고 있지만, 앞선 동일한 제목의 슬라이드 다음에 위치한다는 점에서, 아마도 첫 번째 다이어그램에서 보여준 잠재적 교착 상태(Potential Deadlock)가 실제 교착 상태(Actual Deadlock)로 진행되는 과정 또는 다른 교착 상태 시나리오를 시각적으로 보여주는 내용을 담고 있을 것으로 예상됩니다.\n첫 번째 “Resource Allocation Diagram\"이 잠재적인 위험을 내포한 상태를 보여주었다면, 이 두 번째 다이어그램은 그 위험이 현실화된 모습을 묘사할 수 있습니다. 즉, **실제 교착 상태(Actual Deadlock)**는 시스템의 모든 교착 상태 필요 조건(상호 배제, 점유 및 대기, 비선점, 순환 대기)이 충족되어, 더 이상 어떤 프로세스도 진행할 수 없는 상태를 의미합니다.\n이 다이어그램에서 예상되는 시각적 특징:\n명확한 사이클 형성: 실제 교착 상태를 나타내기 위해 자원 할당 그래프에 명확하고 고립된 **사이클(cycle)**이 형성되어 있을 것입니다. 이 사이클은 관련된 프로세스들과 자원들 간의 순환 대기 관계를 직접적으로 보여줄 것입니다. 각 프로세스가 자원을 점유하고 있으면서 동시에 다른 프로세스가 점유하고 있는 자원을 요청하는, 끊을 수 없는 의존성 고리가 시각적으로 표현될 것입니다.\n모든 관련 자원의 점유: 사이클 내의 모든 자원이 어떤 프로세스에 의해 점유되어 있고, 해당 자원을 요청하는 프로세스들이 모두 대기 상태에 있음을 보여줄 것입니다. 즉, 자원 인스턴스에서 프로세스로 향하는 할당 간선과 프로세스에서 자원 유형으로 향하는 요청 간선이 서로를 막고 있는 형태가 됩니다.\n진행 불가능: 다이어그램을 통해 어떤 프로세스도 더 이상 자원을 얻거나 작업을 완료할 수 없는 멈춘 상태임을 암시할 수 있습니다. 예를 들어, 가용한 자원이 전혀 없거나, 가용한 자원이 있더라도 사이클에 묶인 프로세스들에게는 의미 없는 상황을 나타낼 수 있습니다.\n“Cars in Intersection, again\"과의 연관성: 바로 다음 슬라이드에서 “Cars in Intersection, again\"이라는 제목이 나오는 것을 보면, 이 다이어그램은 교차로에서 차량들이 서로의 경로를 막아 움직이지 못하는 상황과 매우 유사하게 시각화될 수 있습니다. 각 차량은 프로세스, 교차로의 특정 구역이나 방향은 자원으로 비유될 수 있습니다.\n결론적으로, 이 두 번째 “Resource Allocation Diagram\"은 교착 상태의 비극적인 결과, 즉 시스템의 일부 또는 전체가 멈춰버리는 상황을 시각적으로 명확하게 보여줌으로써, 교착 상태 회피 및 탐지 알고리즘의 중요성을 다시 한번 강조하는 역할을 할 것입니다.","description-15#description":"이 슬라이드는 **실제 교착 상태(Actual Deadlock)**가 발생했을 때의 상황을 명확하고 직관적인 메시지로 보여줍니다. 각 문장은 어떤 주체(이전 슬라이드의 “I” 또는 “Cars in Intersection\"의 차량)가 특정 자원(여기서는 “B”, “C”, “D”, “A”)이 해제될 때까지 무기한 대기하고 있음을 나타냅니다.\n이 메시지들이 의미하는 바:\n순환 대기(Circular Wait)의 완성: 이 네 줄의 메시지는 전형적인 순환 대기 상황을 완벽하게 묘사합니다.\n어떤 주체는 B가 해제되기를 기다립니다. (예: P1​이 RB​를 기다림) 다른 주체는 C가 해제되기를 기다립니다. (예: P2​가 RC​를 기다림) 또 다른 주체는 D가 해제되기를 기다립니다. (예: P3​이 RD​를 기다림) 마지막 주체는 A가 해제되기를 기다립니다. (예: P4​가 RA​를 기다림) 여기서 핵심은, 만약 B를 쥐고 있는 주체가 A를 기다리고, C를 쥐고 있는 주체가 B를 기다리고, D를 쥐고 있는 주체가 C를 기다리고, A를 쥐고 있는 주체가 D를 기다리는 상황이라면, 이들은 서로가 필요한 자원을 쥐고 있기 때문에 아무도 자원을 해제할 수 없게 됩니다.\n주체 1 (A를 가지고 B 대기) -\u003e 주체 2 (B를 가지고 C 대기) -\u003e 주체 3 (C를 가지고 D 대기) -\u003e 주체 4 (D를 가지고 A 대기) -\u003e 주체 1\n이러한 고리는 끊어질 수 없으며, 모든 주체는 영원히 “HALT” 상태에 머무르게 됩니다.\n교착 상태의 4가지 조건 충족: 이 상황은 교착 상태의 네 가지 필수 조건이 모두 충족되었음을 의미합니다:\n상호 배제 (Mutual Exclusion): 각 자원(A, B, C, D)은 한 번에 한 주체만 사용할 수 있습니다. 점유 및 대기 (Hold and Wait): 각 주체는 이미 자원(예: P1​은 A를)을 점유하고 있으면서 다른 자원(예: P1​은 B를)을 기다리고 있습니다. 비선점 (No Preemption): 이미 할당된 자원은 해당 주체가 자발적으로 해제하기 전까지는 강제로 뺏을 수 없습니다. 순환 대기 (Circular Wait): 대기하고 있는 주체들의 집합이 순환 고리를 형성합니다. 시스템의 멈춤: 이 메시지들은 해당 자원들을 기다리는 프로세스들이 더 이상 진행할 수 없음을 명확히 보여줍니다. 이는 시스템의 효율성을 저하시키고, 경우에 따라서는 시스템 전체를 마비시킬 수도 있습니다.\n이 슬라이드는 교착 상태의 가장 중요한 특징인 “순환 대기\"를 간단하면서도 강력하게 표현하며, 이는 교착 상태가 시스템에 미치는 치명적인 영향을 강조합니다. 바로 다음 슬라이드에서 “Cars in Intersection, again\"이라는 제목이 나오는 것을 보면, 이 “HALT” 메시지들이 실제 교차로에서 차량들이 꼼짝없이 멈춰 있는 상황에 직접적으로 비유될 것임을 예상할 수 있습니다. 이러한 직관적인 비유는 복잡한 교착 상태 개념을 쉽게 이해하도록 돕습니다.","description-16#description":"이 슬라이드는 **“Cars in Intersection, again”**이라는 제목만을 포함하고 있습니다. 이 제목은 이전에 언급된 “Potential Deadlock\"과 “Actual Deadlock” 슬라이드에서 추상적으로 설명된 개념을 현실 세계의 구체적인 비유로 재강조하거나 확장하려는 의도를 나타냅니다. “다시\"라는 표현은 이 비유가 이전에 (혹은 다른 문맥에서) 한 번 이상 사용되었음을 암시하며, 교착 상태를 설명하는 데 매우 흔하고 효과적인 예시임을 시사합니다.\n교차로의 자동차 비유가 교착 상태를 설명하는 방식:\n자원 (Resources): 교차로의 특정 영역(예: 각 차량이 진입해야 할 교차로 내의 공간), 또는 교차로를 안전하게 통과하기 위한 ‘길’ 자체가 자원으로 비유될 수 있습니다. 각각의 자원은 한 번에 하나의 차량(프로세스)만 점유할 수 있습니다 (상호 배제).\n프로세스 (Processes): 교차로를 통과하려는 각 자동차가 프로세스에 해당합니다. 각 자동차는 목적지에 도달하기 위해 여러 자원(교차로의 여러 부분)을 순차적으로 또는 동시에 필요로 합니다.\n점유 및 대기 (Hold and Wait): 각 자동차는 이미 교차로의 일부(자원)를 점유하고 있으면서(예: 교차로 진입 후 멈춰 섬) 동시에 다른 자동차가 점유하고 있는 교차로의 다른 부분(다른 자원)이 비워지기를 기다립니다.\n비선점 (No Preemption): 일단 교차로에 진입한 자동차는 다른 자동차에 의해 강제로 밀려나거나 움직여질 수 없습니다. 오직 운전자(프로세스)가 자발적으로 차를 움직여야만 자원이 해제됩니다.\n순환 대기 (Circular Wait): 가장 중요한 교착 상태의 조건입니다. 여러 자동차가 교차로 한가운데에서 서로의 길을 막고, 각 자동차가 다른 자동차가 비워주기를 기다리는 상황이 발생할 수 있습니다. 예를 들어:\n차 A는 차 B가 움직이기를 기다리고, 차 B는 차 C가 움직이기를 기다리고, 차 C는 차 D가 움직이기를 기다리고, 차 D는 차 A가 움직이기를 기다리는 경우. 이러한 순환적인 대기 상태는 아무도 움직일 수 없게 만들고, 모든 차량이 교차로에서 꼼짝없이 멈춰 서게 됩니다. 이것이 바로 “Actual Deadlock” 슬라이드에서 “HALT until X is free\"라고 했던 상황과 정확히 일치합니다. 이 비유는 교착 상태의 복잡한 기술적 개념을 일상생활의 친숙한 시나리오로 풀어내어, 비전공자도 쉽게 교착 상태가 왜 발생하며 어떤 결과를 초래하는지 이해할 수 있도록 돕습니다. 특히, “다시\"라는 표현은 이 비유가 교착 상태의 개념을 설명하는 데 있어 매우 강력하고 효과적인 도구임을 강조합니다. 이 슬라이드 다음에 교차로에서 실제로 교착 상태에 빠진 차량들의 그림이나 애니메이션이 나올 가능성이 높습니다.","description-17#description":"**은행원 알고리즘(Banker’s Algorithm)**은 교착 상태 회피(deadlock avoidance)를 위한 대표적인 알고리즘입니다. 이 알고리즘은 시스템이 항상 안전 상태(safe state)를 유지하도록 보장하면서 자원을 할당합니다. 이 슬라이드는 은행원 알고리즘의 네 가지 핵심 특징과 전제 조건을 설명합니다.\n다중 인스턴스 (Multiple instances): 이 알고리즘의 가장 큰 특징 중 하나는 각 자원 유형에 **여러 개의 인스턴스(instance)**가 존재할 수 있는 환경에서 작동한다는 점입니다. 예를 들어, 시스템에 여러 대의 프린터(R1)나 여러 블록의 메모리(R2)가 있을 수 있습니다. 이는 앞서 설명된 자원 할당 그래프 알고리즘(Resource-Allocation Graph Algorithm)이 주로 단일 인스턴스 자원에 적합했던 것과 대조됩니다. 다중 인스턴스 환경에서는 단순히 사이클의 존재만으로 교착 상태를 단정할 수 없기 때문에, 더 정교한 안전성 검사 메커니즘이 필요하며, 은행원 알고리즘이 이를 제공합니다.\n사전 최대 클레임 (Each process must a priori claim maximum use): 모든 프로세스는 실행을 시작하기 전에 자신이 작업 완료를 위해 필요로 할 수 있는 각 자원 유형의 최대 개수를 미리 시스템에 선언해야 합니다. 이는 “a priori claim” 즉, ‘사전 클레임’의 원칙입니다. 예를 들어, 프로세스 P1​은 “저는 최대 3개의 프린터와 2GB의 메모리가 필요할 수 있습니다\"라고 미리 알려야 합니다. 이 정보는 은행원 알고리즘이 자원 할당 요청을 평가하고 시스템의 안전성을 판단하는 데 필수적인 기반이 됩니다.\n자원 요청 시 대기 가능성 (When a process requests a resource it may have to wait): 프로세스가 자원을 요청했을 때, 해당 자원이 현재 가용하더라도 시스템이 해당 요청을 즉시 승인하지 않고 프로세스를 **대기(wait)**시킬 수 있습니다. 이는 시스템의 현재 상태에서 자원 할당을 시뮬레이션했을 때, 만약 그 요청을 승인하면 시스템이 불안전 상태(unsafe state)로 진입할 수 있다고 판단될 경우 발생합니다. 즉, 교착 상태를 회피하기 위해 일시적인 대기가 필요할 수 있다는 의미입니다. 이 점이 은행원 알고리즘이 “교착 상태 회피” 알고리즘으로 분류되는 이유입니다.\n유한 시간 내 자원 반환 (When a process gets all its resources it must return them in a finite amount of time): 프로세스가 필요한 모든 자원을 성공적으로 할당받아 작업을 완료했다면, 그 프로세스는 유한한 시간 내에 자신이 점유하고 있던 모든 자원을 시스템에 반환해야 합니다. 이 조건은 프로세스가 자원을 무기한으로 점유하지 않도록 보장하여, 다른 프로세스들이 해당 자원을 사용할 수 있게 함으로써 시스템의 자원 활용도를 높이고 교착 상태 발생 가능성을 줄이는 데 기여합니다. 이는 교착 상태의 비선점(No Preemption) 조건과는 관련이 없고, 프로세스의 정상적인 종료 및 자원 해제에 대한 요구사항입니다.\n은행원 알고리즘은 이러한 전제 조건들을 바탕으로 자원 할당 요청이 있을 때마다 **안전성 알고리즘(Safety Algorithm)**을 실행하여 시스템이 안전한 상태를 유지할 수 있는지 검사합니다. 만약 안전한 상태를 유지할 수 있다면 요청을 승인하고, 그렇지 않다면 요청을 지연시키는 방식으로 교착 상태를 회피합니다.","description-18#description":"이 슬라이드는 **은행원 알고리즘(Banker’s Algorithm)**이 시스템의 자원 할당 상태를 관리하고 안전성을 판단하기 위해 사용하는 핵심 데이터 구조들을 설명합니다. 여기서 n은 시스템 내의 총 프로세스 수(예: P0​,P1​,…,Pn−1​)를, m은 총 자원 유형 수(예: R0​,R1​,…,Rm−1​)를 나타냅니다.\n각 데이터 구조의 상세 내용은 다음과 같습니다:\nAvailable (가용 자원 벡터):\n정의: 시스템에 현재 사용 가능한 각 자원 유형의 인스턴스 수를 나타내는 벡터입니다. 길이: 자원 유형의 수와 동일한 m의 길이를 가집니다. 의미: Available[j] = k는 자원 유형 Rj​의 인스턴스 k개가 현재 어떤 프로세스에도 할당되지 않고 자유롭게 사용 가능하다는 것을 의미합니다. 예를 들어, Available[0] = 3이라면, 시스템에 프린터 3대가 현재 가용하다는 뜻입니다. 이 벡터는 자원 할당 및 해제에 따라 실시간으로 업데이트됩니다. Max (최대 요구량 행렬):\n정의: 각 프로세스가 각 자원 유형에 대해 최대로 요청할 수 있는 인스턴스 수를 정의하는 행렬입니다. 크기: n×m 크기를 가집니다. (n은 프로세스 수, m은 자원 유형 수) 의미: Max[i,j] = k는 프로세스 Pi​가 자신의 작업을 완료하기 위해 자원 유형 Rj​의 인스턴스를 최대 k개까지 필요로 할 수 있다고 사전에 선언했음을 의미합니다. 이 값은 프로세스가 시작될 때 결정되며, 이후에는 변경되지 않습니다. 이는 은행원 알고리즘의 핵심 전제 조건인 “사전 최대 클레임\"을 반영합니다. Allocation (할당량 행렬):\n정의: 각 프로세스에 현재 할당되어 있는 각 자원 유형의 인스턴스 수를 나타내는 행렬입니다. 크기: n×m 크기를 가집니다. 의미: Allocation[i,j] = k는 프로세스 Pi​가 현재 자원 유형 Rj​의 인스턴스 k개를 사용하고 있음을 의미합니다. 이 행렬은 자원이 할당되거나 해제될 때마다 업데이트됩니다. Need (남은 필요량 행렬):\n정의: 각 프로세스가 자신의 작업을 완료하기 위해 각 자원 유형에 대해 추가로 필요한 인스턴스 수를 나타내는 행렬입니다. 크기: n×m 크기를 가집니다. 계산: Need[i,j] = Max[i,j] – Allocation[i,j]로 계산됩니다. 즉, 프로세스 Pi​가 Rj​ 자원에 대해 최대로 필요하다고 클레임했던 양(Max[i,j])에서 현재 할당받은 양(Allocation[i,j])을 뺀 값이 앞으로 더 필요할 수 있는 자원의 양(Need[i,j])이 됩니다. 의미: Need[i,j] = k는 프로세스 Pi​가 작업을 마치기 위해 자원 Rj​를 k개 더 필요로 한다는 의미입니다. 이 행렬은 안전성 알고리즘에서 프로세스가 자원 요청을 완료할 수 있는지 여부를 판단하는 데 결정적으로 사용됩니다. 이 네 가지 데이터 구조는 은행원 알고리즘이 시스템의 자원 상태를 완벽하게 파악하고, 들어오는 자원 요청에 대해 안전성을 검증하는 데 필요한 모든 정보를 제공합니다. 다음 슬라이드에서 설명될 **안전성 알고리즘(Safety Algorithm)**은 이러한 데이터 구조를 활용하여 시스템이 안전 상태에 있는지 여부를 판단하게 됩니다.","description-19#description":"**안전성 알고리즘(Safety Algorithm)**은 은행원 알고리즘의 핵심 부분으로, 현재 시스템의 자원 할당 상태가 **안전 상태(safe state)**인지 여부를 판단하는 데 사용됩니다. 안전 상태는 모든 프로세스를 교착 상태 없이 완료시킬 수 있는 **안전 순서열(safe sequence)**이 존재하는 상태를 의미합니다. 이 알고리즘은 가상의 자원 할당 및 반환 과정을 시뮬레이션하여 안전 순서열의 존재 여부를 확인합니다.\n알고리즘의 단계별 설명은 다음과 같습니다:\n초기화:\nWork 벡터는 현재 시스템에서 사용 가능한 자원의 양을 추적합니다. 처음에는 Available 벡터(현재 시스템의 실제 가용 자원)의 값으로 초기화됩니다. 이는 “지금 당장 시스템에 있는 자원이 이만큼 있다\"는 의미입니다. Finish 벡터는 각 프로세스가 완료될 수 있는지 여부를 추적하는 불리언(boolean) 배열입니다. 모든 프로세스는 처음에 false로 설정됩니다. 이는 “아직 어떤 프로세스도 완료시킬 수 있다고 확신하지 못한다\"는 의미입니다. n은 프로세스 수, m은 자원 유형 수입니다. 안전 순서열 탐색:\n이 단계는 아직 완료되지 않은 프로세스($Finish[i] = false$) 중에서 현재 Work 벡터(가용 자원)만으로도 자신의 **남은 필요량(Need$_i$)**을 모두 충족시킬 수 있는 프로세스 Pi​를 찾습니다. Need$_i \\le$ Work라는 조건은 벡터 비교를 의미합니다. 즉, Pi​가 필요로 하는 각 자원 유형의 양이 현재 Work에 있는 해당 자원 유형의 양보다 작거나 같아야 합니다. 이러한 프로세스 Pi​를 찾는다는 것은, Pi​에게 자원을 할당하여 Pi​가 작업을 완료할 수 있도록 하는 것이 가능하다고 가정하는 것입니다. 만약 이러한 프로세스를 더 이상 찾을 수 없다면, 현재 Work로 완료시킬 수 있는 프로세스가 없다는 뜻이므로 4단계로 넘어갑니다. 가상 자원 반환:\n2단계에서 조건을 만족하는 프로세스 Pi​를 찾았다면, 이 프로세스 Pi​가 자신의 작업을 완료했다고 가정하고, Pi​가 현재 점유하고 있던 모든 자원(Allocation$_i$)을 시스템에 반환했다고 시뮬레이션합니다. Work = Work + Allocation$_i$는 Pi​가 반환한 자원을 Work 벡터에 더하여, 이제 시스템에 더 많은 자원이 가용하게 되었음을 나타냅니다. Finish[i] = true로 설정하여 Pi​가 완료되었음을 표시합니다. 이제 Work 벡터가 업데이트되었으므로, 2단계로 돌아가서 업데이트된 Work를 가지고 다른 프로세스들을 완료시킬 수 있는지 다시 시도합니다. 안전 상태 판단:\n모든 프로세스 i에 대해 Finish[i]가 true로 설정되었다면, 이는 시스템에 있는 모든 프로세스가 (어떤 특정 순서열에 따라) 자신의 작업을 완료하고 자원을 해제할 수 있음을 의미합니다. 즉, 안전 순서열이 존재하며, 시스템은 안전 상태에 있습니다. 만약 모든 프로세스를 완료시키지 못하고 2단계에서 더 이상 조건을 만족하는 프로세스를 찾을 수 없어서 4단계로 넘어왔는데, 여전히 Finish[i]가 false인 프로세스가 남아있다면, 시스템은 **불안전 상태(unsafe state)**에 있는 것입니다. 이 알고리즘은 시스템의 자원 할당 결정 시 매번 수행되어, 잠재적인 교착 상태를 미리 감지하고 회피하는 데 중요한 역할을 합니다.","description-2#description":"이 슬라이드는 교착 상태 회피의 두 가지 접근법 중 하나인 **프로세스 개시 거부(Process Initiation Denial)**에 대해 더 자세히 설명합니다. 이 전략은 시스템에 새로운 프로세스를 받아들일지 여부를 결정하는 시점에서 교착 상태 가능성을 평가합니다. ⛔🆕\n핵심 원리:\n“A process is only started if the maximum claim of all current processes plus those of the new process can be met.”\n새로운 프로세스를 시스템에 진입시키기 전에, 이 프로세스가 앞으로 최대로 요구할 자원의 양(maximum claim)을 고려합니다. 시스템은 현재 이미 실행 중인 모든 프로세스들이 각자 선언한 최대 요구량을 모두 사용하고, 동시에 새로운 프로세스도 자신의 최대 요구량을 사용한다고 가정했을 때, 시스템 전체의 자원으로 이 모든 요구를 충족시킬 수 있는지, 그리고 더 나아가 이러한 상황에서도 안전한 실행 순서(safe sequence)가 존재할 수 있는지를 확인합니다. 만약 이 모든 최대 요구량을 동시에 만족시킬 수 없거나, 시스템이 불안전 상태로 진입할 위험이 있다면 새로운 프로세스의 시작을 허용하지 않습니다.\n예시:\n시스템 자원: RAM 100MB 현재 실행 중인 프로세스: P1: 최대 30MB RAM 요구 P2: 최대 40MB RAM 요구 새로 시작하려는 프로세스: P3: 최대 50MB RAM 요구 단순 총량 계산: 30MB(P1)+40MB(P2)+50MB(P3)=120MB.\n이는 시스템 가용 RAM 100MB를 초과합니다. 따라서 이 단순한 논리에 따르면 P3의 시작은 거부될 수 있습니다. 실제 프로세스 개시 거부 알고리즘은 단순히 총량만 비교하는 것보다 더 정교하게 안전 상태 여부를 판단하지만, 기본적인 아이디어는 이와 같습니다. 즉, 모든 프로세스가 “최악의 경우\"처럼 동시에 최대 자원을 요구하는 상황을 가정하고 시스템의 수용 능력을 따지는 것입니다.\n문제점 및 비최적성 (Not optimal):\n이 전략은 교착 상태를 예방하는 데는 도움이 될 수 있지만, 몇 가지 중요한 이유로 최적이라고 보기 어렵습니다.\n“Assumes the worst: that all processes will make their maximum claims together.” (최악의 경우를 가정함: 모든 프로세스가 동시에 최대 요구량을 요청할 것이라고 가정):\n지나치게 보수적: 실제로 대부분의 프로세스는 실행 시간의 극히 일부 동안만 최대 자원을 사용하거나, 동시에 모든 프로세스가 최대 자원을 요구하는 경우는 매우 드뭅니다. 많은 프로세스는 실행 기간 동안 평균적으로 최대 요구량보다 훨씬 적은 양의 자원을 사용합니다. 자원 활용률 저하: 이처럼 최악의 상황을 가정하기 때문에, 실제로는 시스템에 충분한 여유 자원이 있음에도 불구하고 새로운 프로세스의 시작이 불필요하게 거부될 수 있습니다. 이는 시스템 자원의 활용률을 낮추고, 동시에 실행될 수 있는 프로세스의 수(다중 프로그래밍 정도, degree of multiprogramming)를 감소시켜 시스템 전체의 처리율(throughput)을 저하시킬 수 있습니다. 프로세스 대기 시간 증가: 새로운 프로세스가 시스템에 진입하기 위해 더 오래 기다려야 할 수 있습니다. 미래 자원 요구량 예측의 어려움:\n모든 프로세스가 시작 전에 자신의 정확한 최대 자원 요구량을 선언해야 한다는 전제 자체가 현실적으로 어려울 수 있습니다. 많은 프로그램은 실행 중 입력이나 상황에 따라 필요한 자원이 동적으로 변하기 때문입니다. 결론:\n프로세스 개시 거부는 교착 상태 회피를 위한 하나의 방법으로, 시스템에 진입하는 프로세스의 수를 제어함으로써 잠재적인 위험을 초기에 차단하려는 시도입니다. 그러나 모든 프로세스가 동시에 최대 자원을 요구한다는 비현실적인 가정을 기반으로 하기 때문에, 시스템 자원의 비효율적인 사용을 초래할 가능성이 큽니다. 이 때문에 이 방법 단독으로 사용되기보다는, 좀 더 유연하고 동적인 자원 할당 전략(예: 자원 할당 거부 - 은행가 알고리즘)과 함께 고려되거나, 매우 특수한 환경에서 제한적으로 사용될 수 있습니다. 교착 상태 회피의 주된 관심사는 보통 다음에 나올 자원 할당 거부 방식에 더 집중됩니다.","description-20#description":"**자원 요청 알고리즘(Resource-Request Algorithm)**은 프로세스 Pi​가 자원 Rj​의 인스턴스를 요청했을 때, 은행원 알고리즘이 이 요청을 어떻게 처리할지 결정하는 절차를 정의합니다. 이 알고리즘의 목표는 교착 상태를 회피하면서 자원 요청을 최대한 효율적으로 처리하는 것입니다.\n알고리즘의 단계별 설명은 다음과 같습니다:\n최대 클레임 초과 검사:\n프로세스 Pi​가 요청한 자원 양(Request$_i$)이 이전에 선언했던 **최대 필요량(Need$_i$)**을 초과하는지 확인합니다. Request$_i \\le$ Need$_i$는 Pi​가 현재 요청한 자원의 각 유형별 개수가 Pi​가 자신의 작업을 완료하기 위해 추가로 필요하다고 명시한 양을 넘어서는 안 된다는 것을 의미합니다. 만약 Request$_i \u003e$ Need$_i$라면, 이는 프로세스가 원래 약속했던 최대 요구량을 넘어선 부당한 요청이므로, 시스템은 이를 오류로 처리하고 요청을 거부합니다. 가용 자원 부족 검사:\n현재 시스템에 가용한 자원(Available)이 프로세스 Pi​의 요청량(Request$_i$)을 충족시킬 수 있는지 확인합니다. Request$_i \\le$ Available는 현재 시스템에 요청된 모든 자원 유형에 대해 충분한 인스턴스가 사용 가능한지를 확인합니다. 만약 Request$_i \u003e$ Available라면, 현재 가용한 자원이 부족하므로 Pi​는 해당 자원이 해제될 때까지 대기해야 합니다. 이 경우, 요청은 즉시 거부되는 것이 아니라 보류 상태가 됩니다. 가상 할당 및 안전성 검사:\n앞선 두 단계를 통과하면, 시스템은 요청된 자원을 Pi​에 실제로 할당하기 전에, 만약 할당했을 경우 시스템이 안전 상태를 유지할 수 있는지 시뮬레이션합니다. 상태 임시 수정: 시스템은 다음과 같이 데이터 구조를 임시로 업데이트하여 자원 할당이 이루어진 것처럼 가정합니다: Available = Available – Request$_i$;: 요청된 자원만큼 가용 자원이 줄어듭니다. Allocation$_i$ = Allocation$_i$ + Request$_i$;: Pi​에게 할당된 자원량이 늘어납니다. Need$_i$ = Need$_i$ – Request$_i$;: Pi​가 앞으로 더 필요로 할 자원량이 줄어듭니다. 안전성 알고리즘 실행: 이 임시로 수정된 상태에서 **안전성 알고리즘(Safety Algorithm)**을 실행하여 시스템이 여전히 안전 상태인지 판단합니다. 결정: If safe: 안전성 알고리즘의 결과 시스템이 안전 상태로 유지된다면, 요청된 자원이 Pi​에 실제로 할당됩니다. 임시 수정된 상태가 실제 시스템 상태가 됩니다. If unsafe: 안전성 알고리즘의 결과 시스템이 불안전 상태로 진입하게 된다면, 해당 요청은 거부되고 Pi​는 대기해야 합니다. 시스템의 자원 할당 상태는 이전 상태로 복원됩니다. 즉, 시뮬레이션했던 모든 변경 사항이 되돌려집니다. 이 알고리즘은 교착 상태를 능동적으로 회피하는 핵심 메커니즘입니다. 자원 요청이 들어올 때마다 엄격한 검사를 통해 시스템의 안전성을 보장하고, 잠재적인 위험을 감지하여 자원 할당 결정을 내립니다. 이는 시스템의 복잡성과 오버헤드를 증가시키지만, 교착 상태로 인한 심각한 문제를 방지하는 데 필수적입니다.","description-21#description":"이 슬라이드는 **은행원 알고리즘(Banker’s Algorithm)**의 실제 적용을 보여주기 위한 구체적인 예시를 제시합니다. 시스템의 초기 상태, 즉 시간 T0​에서의 자원 할당 스냅샷을 보여주며, 이를 통해 다음 단계에서 안전성 검사를 수행할 수 있는 기반 데이터를 제공합니다.\n예시의 구성 요소:\n프로세스 수 (n): 시스템에는 총 5개의 프로세스, 즉 P0​,P1​,P2​,P3​,P4​가 존재합니다.\n자원 유형 수 (m) 및 총 인스턴스 수: 시스템에는 3가지 유형의 자원, 즉 A, B, C가 존재하며, 각 유형별 총 인스턴스 수는 다음과 같습니다:\n자원 A: 총 10개 인스턴스 자원 B: 총 5개 인스턴스 자원 C: 총 7개 인스턴스 이 총 인스턴스 수는 이후 Available 벡터와 Allocation 행렬의 합산을 검증하는 데 사용될 수 있습니다. 시간 T0​에서의 스냅샷: 시스템의 현재 자원 할당 상태를 보여주는 세 가지 주요 데이터 구조의 초기 값입니다.\nAllocation (할당량 행렬): 각 프로세스가 현재 각 자원 유형으로부터 얼마나 많은 인스턴스를 할당받고 있는지를 나타냅니다.\nP0: A 0개, B 1개, C 0개 할당 P1: A 2개, B 0개, C 0개 할당 P2: A 3개, B 0개, C 2개 할당 P3: A 2개, B 1개, C 1개 할당 P4: A 0개, B 0개, C 2개 할당 총 할당된 자원: (A: 0+2+3+2+0=7), (B: 1+0+0+1+0=2), (C: 0+0+2+1+2=5) Max (최대 요구량 행렬): 각 프로세스가 작업을 완료하기 위해 각 자원 유형으로부터 최대로 필요하다고 사전에 클레임한 인스턴스 수를 나타냅니다.\nP0: A 7개, B 5개, C 3개까지 필요할 수 있음 P1: A 3개, B 2개, C 2개까지 필요할 수 있음 P2: A 9개, B 0개, C 2개까지 필요할 수 있음 P3: A 2개, B 2개, C 2개까지 필요할 수 있음 P4: A 4개, B 3개, C 3개까지 필요할 수 있음 Available (가용 자원 벡터): 현재 시스템에 남아 있는 각 자원 유형의 가용 인스턴스 수입니다.\nA: 3개, B: 3개, C: 2개 이 값은 (Total Instances - Sum of allocated instances for each type)으로 검증될 수 있습니다. A: 10−7=3 (일치) B: 5−2=3 (일치) C: 7−5=2 (일치) 따라서 주어진 Available 값은 현재 할당 상태와 총 자원 인스턴스 수에 부합합니다. 이 초기 스냅샷은 다음 슬라이드에서 **Need (남은 필요량 행렬)**을 계산하고, 이어서 **안전성 알고리즘(Safety Algorithm)**을 실행하여 시스템의 현재 상태가 안전한지 아닌지를 판단하는 데 사용될 것입니다. 이 예시는 은행원 알고리즘의 작동 방식을 단계별로 이해하는 데 매우 중요한 출발점입니다.","description-22#description":"이 슬라이드는 은행원 알고리즘 예시의 연속으로, 이전 슬라이드에서 주어진 Max와 Allocation 행렬을 바탕으로 Need 행렬을 계산하고, 계산된 Need 행렬과 Available 벡터를 사용하여 **안전성 알고리즘(Safety Algorithm)**을 실행한 결과를 보여줍니다.\nNeed (남은 필요량) 행렬 계산:\nNeed[i,j] = Max[i,j] – Allocation[i,j] 공식에 따라 각 프로세스의 Need 값을 계산합니다. P0: Max[0]=(7,5,3), Allocation[0]=(0,1,0) ⟹ Need[0]=(7-0, 5-1, 3-0) = (7,4,3) P1: Max[1]=(3,2,2), Allocation[1]=(2,0,0) ⟹ Need[1]=(3-2, 2-0, 2-0) = (1,2,2) P2: Max[2]=(9,0,2), Allocation[2]=(3,0,2) ⟹ Need[2]=(9-3, 0-0, 2-2) = (6,0,0) P3: Max[3]=(2,2,2), Allocation[3]=(2,1,1) ⟹ Need[3]=(2-2, 2-1, 2-1) = (0,1,1) P4: Max[4]=(4,3,3), Allocation[4]=(0,0,2) ⟹ Need[4]=(4-0, 3-0, 3-2) = (4,3,1) 계산된 Need 행렬은 슬라이드에 제시된 내용과 정확히 일치합니다. 안전성 알고리즘 실행 및 안전 순서열 찾기:\n이제 Available = (3,3,2)와 계산된 Need 행렬, 그리고 Allocation 행렬을 사용하여 안전성 알고리즘을 실행합니다.\n초기 상태: Work = (3,3,2), Finish = [F,F,F,F,F]\n1단계: P1을 찾습니다.\nNeed[1] = (1,2,2) 입니다. Need[1] \u003c= Work? (1,2,2) \u003c= (3,3,2) ⟹ True (모든 요소가 작거나 같음) P1을 실행시킬 수 있습니다. Work = Work + Allocation[1] = (3,3,2) + (2,0,0) = (5,3,2) Finish[1] = True 안전 순서열: \u003c P1 \u003e 2단계: 다음 프로세스를 찾습니다. P3을 찾습니다.\nNeed[3] = (0,1,1) 입니다. Need[3] \u003c= Work? (0,1,1) \u003c= (5,3,2) ⟹ True P3을 실행시킬 수 있습니다. Work = Work + Allocation[3] = (5,3,2) + (2,1,1) = (7,4,3) Finish[3] = True 안전 순서열: \u003c P1, P3 \u003e 3단계: 다음 프로세스를 찾습니다. P4를 찾습니다.\nNeed[4] = (4,3,1) 입니다. Need[4] \u003c= Work? (4,3,1) \u003c= (7,4,3) ⟹ True P4를 실행시킬 수 있습니다. Work = Work + Allocation[4] = (7,4,3) + (0,0,2) = (7,4,5) Finish[4] = True 안전 순서열: \u003c P1, P3, P4 \u003e 4단계: 다음 프로세스를 찾습니다. P2를 찾습니다.\nNeed[2] = (6,0,0) 입니다. Need[2] \u003c= Work? (6,0,0) \u003c= (7,4,5) ⟹ True P2를 실행시킬 수 있습니다. Work = Work + Allocation[2] = (7,4,5) + (3,0,2) = (10,4,7) Finish[2] = True 안전 순서열: \u003c P1, P3, P4, P2 \u003e 5단계: 마지막 프로세스를 찾습니다. P0를 찾습니다.\nNeed[0] = (7,4,3) 입니다. Need[0] \u003c= Work? (7,4,3) \u003c= (10,4,7) ⟹ True P0를 실행시킬 수 있습니다. Work = Work + Allocation[0] = (10,4,7) + (0,1,0) = (10,5,7) Finish[0] = True 안전 순서열: \u003c P1, P3, P4, P2, P0 \u003e 최종 결과: 모든 Finish 값이 True가 되었으므로, 시스템은 안전 상태에 있으며, 찾은 \u003c P1, P3, P4, P2, P0 \u003e는 유효한 안전 순서열입니다.\n이 슬라이드는 은행원 알고리즘이 시스템의 현재 상태가 안전한지 여부를 어떻게 결정하는지 명확하게 보여주는 핵심 예시입니다. 안전 순서열을 찾음으로써 시스템이 교착 상태에 빠지지 않고 모든 프로세스를 완료시킬 수 있음을 증명합니다.","description-23#description":"이 슬라이드는 은행원 알고리즘의 **자원 요청 알고리즘(Resource-Request Algorithm)**이 실제 어떻게 작동하는지 보여주는 예시입니다. 특히, 프로세스 P1​이 자원 (1,0,2)를 요청했을 때의 과정을 상세히 설명하고 있습니다.\nP1​의 요청 분석:\n프로세스 P1​이 자원 유형 A 1개, B 0개, C 2개, 즉 Request[1] = (1,0,2)를 요청했습니다. 1단계: Request vs Need 검사: 이전 슬라이드에서 Need[1]은 (1,2,2)였습니다. Request[1] = (1,0,2)이고 Need[1] = (1,2,2)이므로, (1,0,2) \\le (1,2,2) 입니다. 이 조건은 참입니다. (요청량이 최대 필요량을 초과하지 않음) 2단계: Request vs Available 검사: 초기 Available은 (3,3,2)였습니다. Request[1] = (1,0,2)이고 Available = (3,3,2)이므로, (1,0,2) \\le (3,3,2) 입니다. 이 조건은 참입니다. (요청을 처리할 가용 자원이 충분함) 가상 할당 및 상태 업데이트:\n두 가지 검사를 통과했으므로, 이제 시스템은 자원을 P1​에 할당했다고 가정하고 상태를 업데이트합니다.\n기존 상태:\nAvailable = (3,3,2) Allocation[1] = (2,0,0) Need[1] = (1,2,2) 임시 수정:\nAvailable = Available – Request[1] = (3,3,2) – (1,0,2) = (2,3,0) Allocation[1] = Allocation[1] + Request[1] = (2,0,0) + (1,0,2) = (3,0,2) Need[1] = Need[1] – Request[1] = (1,2,2) – (1,0,2) = (0,2,0) 슬라이드에 제시된 임시 할당 후의 Available, Allocation[1], Need[1] 값이 위 계산 결과와 일치합니다. 다른 프로세스들의 Allocation과 Need는 P1​의 요청에 의해 변경되지 않으므로, 이전 상태 그대로 유지됩니다.\n안전성 알고리즘 실행:\n이 임시로 수정된 상태에서 (새로운 Available 값 (2,3,0)을 가지고) 안전성 알고리즘을 다시 실행합니다.\n슬라이드는 \u003c P1, P3, P4, P0, P2 \u003e라는 안전 순서열을 찾았다고 명시합니다. 이는 이 임시 상태가 여전히 안전함을 의미합니다.\n안전 순서열 검증 (간략히):\nWork = (2,3,0) P1 (Need[1]=(0,2,0) \\le Work=(2,3,0)): Work = Work + Allocation[1] = (2,3,0) + (3,0,2) = (5,3,2) P3 (Need[3]=(0,1,1) \\le Work=(5,3,2)): Work = Work + Allocation[3] = (5,3,2) + (2,1,1) = (7,4,3) P4 (Need[4]=(4,3,1) \\le Work=(7,4,3)): Work = Work + Allocation[4] = (7,4,3) + (0,0,2) = (7,4,5) P0 (Need[0]=(7,4,3) \\le Work=(7,4,5)): Work = Work + Allocation[0] = (7,4,5) + (0,1,0) = (7,5,5) P2 (Need[2]=(6,0,0) \\le Work=(7,5,5)): Work = Work + Allocation[2] = (7,5,5) + (3,0,2) = (10,5,7) 모든 프로세스가 완료될 수 있으므로, 시스템은 안전 상태입니다. 결론:\nP1​의 요청 (1,0,2)는 시스템을 안전 상태에 유지하므로 승인됩니다. 임시 변경된 상태가 실제 시스템의 새로운 자원 할당 상태가 됩니다. 추가 질문:\n슬라이드는 두 가지 추가 질문을 던집니다. 이는 독자가 은행원 알고리즘을 추가로 연습하고 이해도를 높이도록 유도합니다. 이 질문들에 대한 답을 찾으려면 위와 동일한 자원 요청 알고리즘 단계를 각 요청에 대해 적용해야 합니다.\nP4​의 요청 (3,3,0) 승인 여부:\nNeed[4] = (4,3,1). Request[4] = (3,3,0). (3,3,0) \\le (4,3,1) (참). P1​ 요청 승인 후 Available = (2,3,0)입니다. Request[4] = (3,3,0). (3,3,0) \\le (2,3,0) (거짓, A 자원이 부족). 결론: P4​의 요청 (3,3,0)은 현재 Available 자원 부족으로 거부됩니다 (또는 대기해야 합니다). P0​의 요청 (0,2,0) 승인 여부:\nNeed[0] = (7,4,3). Request[0] = (0,2,0). (0,2,0) \\le (7,4,3) (참). P1​ 요청 승인 후 Available = (2,3,0)입니다. Request[0] = (0,2,0). (0,2,0) \\le (2,3,0) (참). 가상 할당: Available = (2,3,0) - (0,2,0) = (2,1,0) Allocation[0] = (0,1,0) + (0,2,0) = (0,3,0) Need[0] = (7,4,3) - (0,2,0) = (7,2,3) 안전성 알고리즘 실행 (새로운 Available = (2,1,0) 사용): Work = (2,1,0) P1 (Need[1]=(0,2,0)): (0,2,0) \\not\\le (2,1,0) (B 자원 부족). P3 (Need[3]=(0,1,1)): (0,1,1) \\le (2,1,0) (참). Work = (2,1,0) + Allocation[3]=(2,1,1) = (4,2,1) 이제 Work = (4,2,1)로 다른 프로세스를 시도. P1 (Need[1]=(0,2,0) \\le Work=(4,2,1)): Work = (4,2,1) + Allocation[1]=(3,0,2) = (7,2,3) P4 (Need[4]=(4,3,1)): (4,3,1) \\not\\le (7,2,3) (B 자원 부족). … 계속 시도해도 모든 프로세스를 완료시킬 수 있는 안전 순서열을 찾기 어렵습니다. 특히 P0와 P2의 Need 값이 커서 현재 Work로는 충족시키기 어렵습니다. 따라서, P0의 요청 (0,2,0)은 시스템을 불안전 상태로 만들 가능성이 높으므로 거부될 것입니다. 이 예시는 은행원 알고리즘이 어떻게 자원 요청을 동적으로 평가하고, 시스템의 안전성을 유지하면서 자원 할당을 결정하는지 잘 보여줍니다.","description-3#description":"이 슬라이드는 교착 상태 회피의 두 가지 접근법 중 더 중요하고 널리 알려진 자원 할당 거부(Resource Allocation Denial) 전략을 소개하며, 이 전략의 대표적인 예시로 **은행가 알고리즘(Banker’s Algorithm)**을 언급합니다. 🏦\n자원 할당 거부의 핵심:\n이미 실행 중인 프로세스가 추가적인 자원을 요청했을 때, 이 요청을 “즉시 승인해도 시스템이 여전히 안전한가?” 를 판단하여 할당 여부를 결정하는 방식입니다. 만약 할당으로 인해 시스템이 불안전 상태(unsafe state), 즉 교착 상태로 이어질 가능성이 있는 상태로 변하게 된다면, 해당 자원 요청은 일단 거부되고 프로세스는 대기합니다.\n1. 은행가 알고리즘 (Banker’s Algorithm):\n“Referred to as the Banker’s algorithm - A strategy of resource allocation denial” 은행가 알고리즘은 다익스트라(Dijkstra)에 의해 제안된 교착 상태 회피 알고리즘입니다. 이름에서 알 수 있듯이, 은행이 고객에게 대출을 해줄 때 고객의 상환 능력과 은행의 자금 상태를 고려하여 대출 심사를 하는 과정과 유사합니다. 작동 원리: 각 프로세스는 시작 시 자신이 필요로 할 **최대 자원량(maximum claim)**을 선언합니다. 프로세스가 자원을 요청하면, 시스템은 먼저 요청량이 프로세스가 선언한 최대 요구량 이내인지, 그리고 현재 가용 자원 범위 내인지를 확인합니다. 만약 이 조건들을 만족하면, 시스템은 가상으로 자원을 할당해 봅니다. 그 후, 이 가상 할당된 상태가 **안전 상태(safe state)**인지를 검사합니다. 안전 상태란, 시스템 내의 모든 프로세스들이 교착 없이 자신의 작업을 완료하고 종료될 수 있는 **실행 순서(safe sequence)**가 존재하는 상태를 의미합니다. 만약 가상 할당 후에도 시스템이 안전 상태를 유지한다면 실제 자원 할당이 이루어지고, 그렇지 않다면 (불안전 상태로 진입한다면) 자원 할당은 거부되고 프로세스는 대기합니다. 2. 시스템 및 상태 정의:\n“Consider a system with fixed number of resources” (고정된 수의 자원을 가진 시스템을 고려):\n은행가 알고리즘과 같은 회피 기법은 일반적으로 시스템 내 각 자원 유형의 총량이 변하지 않는, 즉 고정된 수의 자원 인스턴스를 가정하고 작동합니다.\n“State of the system is the current allocation of resources to process” (시스템의 상태는 현재 프로세스에 대한 자원 할당 상태임):\n시스템의 현재 상태는 다음 정보들로 정의됩니다.\n각 프로세스에게 현재 할당된 자원의 양 각 프로세스가 앞으로 추가로 요청할 수 있는 (최대 요구량 - 현재 할당량) 자원의 양 현재 시스템에서 사용 가능한 (가용) 자원의 양 “Safe state is where there is at least one sequence that does not result in deadlock” (안전 상태는 교착 상태를 초래하지 않는 순서가 하나 이상 존재하는 상태임):\n시스템이 안전 상태에 있다는 것은, 현재 자원 할당 상태에서 시작하여, 어떤 순서로 프로세스들을 실행시키면 각 프로세스가 필요한 자원을 모두 할당받아 작업을 완료하고 자원을 반납하여, 결국 모든 프로세스가 교착 없이 종료될 수 있는 **“안전 순서(safe sequence)”**가 최소한 하나 이상 존재함을 의미합니다. 예를 들어, 프로세스 순서 가 안전 순서라면, P1​이 현재 가용 자원으로 작업을 마칠 수 있고, P1​이 끝나고 자원을 반납하면 그 자원을 이용하여 P2​가 작업을 마칠 수 있으며, 또 P2​가 끝나고 자원을 반납하면 그 자원으로 P3​가 작업을 마칠 수 있다는 의미입니다. “Unsafe state is a state that is not safe” (불안전 상태는 안전하지 않은 상태임):\n불안전 상태는 위에서 정의한 안전 순서가 존재하지 않는 상태입니다. 주의할 점: 불안전 상태가 반드시 교착 상태를 의미하는 것은 아닙니다. 불안전 상태는 교착 상태로 이어질 가능성이 있는 상태를 의미합니다. 프로세스들이 실제로 최대 요구량까지 자원을 요청하지 않거나, 특정 순서로 자원을 요청하면 교착을 피할 수도 있습니다. 하지만 회피 알고리즘은 이러한 “가능성\"을 회피하기 위해 불안전 상태로의 진입 자체를 막습니다. 결론:\n자원 할당 거부 전략, 특히 은행가 알고리즘은 교착 상태 회피를 위한 정교한 방법론을 제공합니다. 이는 시스템이 항상 안전 상태를 유지하도록 보장함으로써 교착 상태를 방지합니다. 그러나 이를 위해서는 각 프로세스의 최대 자원 요구량에 대한 사전 정보가 필요하고, 자원 요청 시마다 안전성 검사를 수행하는 데 따른 계산 오버헤드가 발생할 수 있다는 점을 고려해야 합니다. 다음 슬라이드에서는 이 “안전 상태\"에 대해 더 자세히 정의할 것입니다.","description-4#description":"이 슬라이드는 교착 상태 회피(Deadlock Avoidance)의 핵심 개념인 **안전 상태(Safe State)**에 대해 보다 상세하고 공식적인 정의를 제공합니다. 🛡️✅ 시스템이 안전 상태를 유지하도록 하는 것이 교착 상태 회피 알고리즘의 주된 목표입니다.\n안전 상태의 정의:\n자원 요청 시 판단 기준:\n“When a process requests an available resource, system must decide if immediate allocation leaves the system in a safe state” 프로세스가 자원을 요청하고 해당 자원이 현재 시스템에 가용(available)할지라도, 운영체제는 이 요청을 즉시 승인하는 것이 시스템을 여전히 안전 상태로 유지하는지를 먼저 판단해야 합니다. 만약 할당 후 시스템이 불안전 상태(unsafe state)로 빠질 위험이 있다면, 요청은 보류됩니다. 안전 순서(Safe Sequence)의 존재:\n“System is in safe state if there exists a sequence of ALL the processes in the systems such that for each Pi​, the resources that Pi​ can still request can be satisfied by currently available resources + resources held by all the Pj​, with j","description-5#description":"이 슬라이드는 안전 상태(Safe State), 불안전 상태(Unsafe State), 그리고 교착 상태(Deadlock) 간의 관계 및 교착 상태 회피(Avoidance) 전략의 목표를 명확하게 요약합니다. 📜\n1. 시스템이 안전 상태에 있다면 ⇒ 교착 상태 없음 (If a system is in safe state ⇒ no deadlocks):\n의미: 이것은 매우 강력한 보장입니다. 시스템이 현재 안전 상태에 있다면, 즉 모든 프로세스를 교착 없이 완료시킬 수 있는 최소한 하나의 실행 순서(safe sequence)가 존재한다면, 현재 시점에서 시스템에는 교착 상태가 절대 존재하지 않으며, 또한 현재 상태에서 앞으로 교착 상태가 발생하지 않고 모든 프로세스가 결국 종료될 수 있음을 보장합니다 (프로세스들이 선언한 최대 요구량 내에서 자원을 요청하고, 시스템이 회피 알고리즘을 따른다는 가정 하에). 이유: 안전 순서의 정의 자체가 각 프로세스가 필요한 자원을 (비록 기다릴 수는 있지만) 결국에는 얻어서 작업을 완료하고 자원을 반납할 수 있음을 의미하기 때문입니다. 이 연쇄적인 완료 과정은 교착 상태의 특징인 순환 대기를 방지합니다. 2. 시스템이 불안전 상태에 있다면 ⇒ 교착 상태의 가능성 있음 (If a system is in unsafe state ⇒ possibility of deadlock):\n의미: 시스템이 불안전 상태에 있다는 것은 안전 순서가 존재하지 않음을 의미합니다. 중요한 점은, 불안전 상태가 반드시 교착 상태를 의미하는 것은 아니라는 것입니다. 불안전 상태는 단지 교착 상태로 이어질 “가능성” 또는 “위험” 이 있는 상태를 나타냅니다. 이유: 불안전 상태에서는 운영체제가 프로세스들의 자원 요청을 조심스럽게 관리하지 않으면 교착 상태가 발생할 수 있습니다. 하지만, 불안전 상태에 있더라도 프로세스들이 실제로 자신들이 선언한 최대 자원량까지 요청하지 않거나, 또는 우연히 교착을 피하는 순서로 자원을 요청하고 해제하면 교착 상태가 발생하지 않을 수도 있습니다. 예를 들어, 한 프로세스가 최대치보다 적은 자원만 사용하고 일찍 종료하여 다른 프로세스에게 자원을 넘겨줄 수도 있습니다. 예시: 은행에 돈이 거의 바닥났지만(불안전 상태), 대출자들이 동시에 돈을 인출하러 오지 않거나 일부만 인출하면 은행이 파산하지 않을 수 있는 것과 유사합니다. 하지만 모든 대출자가 동시에 최대 금액을 인출하려 한다면 파산(교착)할 수 있습니다. 3. 회피(Avoidance) ⇒ 시스템이 절대로 불안전 상태로 진입하지 않도록 보장함 (Avoidance ⇒ ensure that a system will never enter an unsafe state.):\n목표: 교착 상태 회피 알고리즘(예: 은행가 알고리즘)의 핵심 목표는, 시스템이 애초에 불안전 상태로 진입하는 것을 막는 것입니다. 작동 방식: 프로세스가 자원을 요청할 때마다, 회피 알고리즘은 만약 이 요청을 승인했을 경우 시스템이 불안전 상태로 변하게 될지를 미리 검사합니다. 만약 불안전 상태로의 전이가 예상되면, 해당 자원 요청은 거부되고 프로세스는 대기합니다. 오직 요청을 승인해도 시스템이 계속 안전 상태를 유지할 경우에만 자원이 할당됩니다. 결과: 이 전략을 통해 시스템은 항상 안전 상태에 머무르게 되며, 따라서 (위의 1번 사실에 의해) 교착 상태는 발생하지 않게 됩니다. 요약:\n안전 상태: 교착 없음 (보장됨) 불안전 상태: 교착 가능성 있음 (반드시 교착은 아님) 교착 상태 회피의 역할: 시스템을 항상 안전 상태 영역 내에 있도록 유지하여, 불안전 상태로의 진입 자체를 차단함으로써 교착 상태를 예방적으로 피하는 것입니다. 이러한 기본 사실들은 교착 상태 회피 기법의 이론적 근거를 제공하며, 왜 회피 알고리즘이 안전 상태를 유지하려고 하는지를 설명해줍니다. 다음 슬라이드에서는 이러한 상태들 간의 관계를 시각적으로 표현할 가능성이 있습니다.","description-6#description":"이 슬라이드의 제목 “Safe, Unsafe, Deadlock State\"는 시스템이 처할 수 있는 세 가지 중요한 상태와 그들 사이의 관계를 시각적으로 설명하려는 의도로 보입니다. 실제 이미지는 제공되지 않았지만, 일반적으로 이러한 상태들은 다음과 같은 포함 관계로 표현됩니다. 벤 다이어그램 형태를 생각할 수 있습니다. ⭕\n상태 간의 개념적 관계:\n전체 상태 공간 (All Possible System States):\n시스템이 취할 수 있는 모든 자원 할당 상태들의 집합입니다.\n안전 상태 (Safe States):\n전체 상태 공간 내의 한 부분집합입니다. 이 상태에서는 교착 상태가 발생하지 않음을 보장하는 실행 순서(safe sequence)가 존재합니다. 교착 상태 회피 알고리즘은 시스템이 항상 이 안전 상태 영역 내에 머무르도록 하는 것을 목표로 합니다. [안전 상태 영역] 불안전 상태 (Unsafe States):\n안전 상태가 아닌 모든 상태를 의미합니다. 즉, 안전 순서가 존재하지 않는 상태들입니다. [불안전 상태 영역 = 전체 상태 영역 - 안전 상태 영역] 중요: 불안전 상태가 곧 교착 상태를 의미하지는 않습니다. 불안전 상태는 교착 상태로 이어질 “가능성\"이 있는 상태입니다. 교착 상태 (Deadlock States):\n불안전 상태 영역 내의 일부분입니다. 실제로 하나 이상의 프로세스가 더 이상 진행할 수 없는 순환 대기에 빠진 상태입니다. [교착 상태 영역 ⊂ 불안전 상태 영역] 시각적 표현 (가상 다이어그램 설명):\n일반적으로 다음과 같은 형태로 표현될 수 있습니다:\n코드 스니펫\ngraph TD subgraph 전체 시스템 상태 공간 direction LR subgraph 안전 상태 (Safe States) A[ ] end subgraph 불안전 상태 (Unsafe States) direction LR B_non_deadlock[불안전하지만 교착은 아님] subgraph 교착 상태 (Deadlock States) C[ ] end end end style A fill:#9f9,stroke:#333,stroke-width:2px style C fill:#f99,stroke:#333,stroke-width:2px style B_non_deadlock fill:#ff9,stroke:#333,stroke-width:2px %% 설명: %% 녹색 영역(A): 안전 상태. 시스템이 여기에 머무르면 교착 없음. %% 노란색 영역(B_non_deadlock) + 빨간색 영역(C): 불안전 상태. %% 빨간색 영역(C): 실제 교착 상태. 불안전 상태의 일부임. %% 교착 상태 회피 알고리즘은 시스템이 녹색 영역을 벗어나 노란색/빨간색 영역으로 진입하는 것을 방지함. 다이어그램 해석:\n안전 상태에서 불안전 상태로의 전이: 교착 상태 회피 알고리즘은 자원 할당 요청을 승인했을 때 시스템이 안전 상태에서 불안전 상태로 넘어가는 것을 감지하고, 이러한 전이를 막습니다. 즉, 시스템의 운영 지점을 항상 안전 상태 영역 내에 유지하려고 합니다. 불안전 상태에서 교착 상태로의 전이: 시스템이 일단 불안전 상태로 진입했다고 해서 반드시 교착 상태가 되는 것은 아닙니다. 프로세스들이 자원을 요청하는 패턴에 따라 교착 상태로 빠질 수도 있고, 운 좋게 빠져나올 수도 있습니다. 하지만 회피 알고리즘은 이러한 “운\"에 맡기지 않고 불안전 상태 자체를 피합니다. 교착 상태는 불안전 상태의 부분집합: 모든 교착 상태는 불안전 상태입니다 (교착 상태에서는 안전 순서가 존재할 수 없으므로). 그러나 모든 불안전 상태가 교착 상태인 것은 아닙니다. 교착 상태 회피의 역할:\n교착 상태 회피(Avoidance) 전략은 자원 할당 결정 시, 해당 결정이 시스템을 안전 상태 영역에서 불안전 상태 영역으로 이동시키는지 여부를 확인합니다. 만약 그렇다면, 그 할당을 거부하여 시스템을 계속 안전 상태에 머무르게 합니다. 이렇게 함으로써, 시스템이 교착 상태(불안전 상태 영역 내의 특정 부분)에 도달하는 것을 원천적으로 방지합니다.\n이러한 상태 간의 관계를 이해하는 것은 교착 상태 회피 알고리즘이 왜 그렇게 설계되었고 어떻게 작동하는지를 파악하는 데 매우 중요합니다. 시스템은 “위험한” 불안전 상태로의 진입을 피함으로써 “실제 재앙\"인 교착 상태를 막는 것입니다.","description-7#description":"이 슬라이드는 교착 상태 회피(Deadlock Avoidance)를 위해 사용되는 구체적인 알고리즘들을 시스템의 자원 특성에 따라 구분하여 제시합니다. 특히 자원 유형별 인스턴스 수에 따라 다른 접근법이 사용됨을 강조합니다. 🛠️\n1. 자원 유형당 단일 인스턴스인 경우 (Single instance of a resource type):\n알고리즘: 자원 할당 그래프 (Resource-Allocation Graph) 사용 이전에 교착 상태 탐지(Detection)에서 자원 할당 그래프를 사용하여 사이클을 찾는 방법을 논의한 바 있습니다. 교착 상태 회피에서도 유사한 원리를 사용하지만, 목적이 다릅니다. 작동 방식 (회피에서의 활용): 프로세스가 자원을 요청하면, 시스템은 이 요청을 승인한다고 가정하고 자원 할당 그래프에 해당 요청 간선(Pi​→Rj​)을 추가해 봅니다. 또한, 프로세스가 앞으로 요청할 수 있는 모든 가능한 자원들을 나타내는 **요구 간선(claim edge)**이라는 개념을 도입할 수 있습니다. 요구 간선은 점선으로 표시되며, 프로세스가 미래에 해당 자원을 요청할 _수도 있음_을 나타냅니다. (요청 간선은 실제 요청, 할당 간선은 실제 할당) 요청을 승인하여 요청 간선이 할당 간선(Rj​→Pi​)으로 바뀌었을 때, 만약 이 그래프에서 사이클(cycle)이 형성될 가능성이 있다면 해당 요청은 교착 상태를 유발할 수 있는 것으로 간주되어 거부됩니다. 단일 인스턴스 환경에서는 사이클이 곧 교착 상태를 의미하기 때문입니다. 정확히는, 요청을 승인했을 때 생기는 할당 간선과 기존의 요구 간선들을 고려하여 사이클이 발생하는지를 검사합니다. 만약 사이클이 발생하면, 해당 요청은 시스템을 불안전 상태로 만들 수 있으므로 거부됩니다. 장점: 개념적으로 비교적 간단합니다. 단점: 자원 유형별 인스턴스가 하나뿐인 제한된 환경에서만 효과적입니다. 2. 자원 유형당 다중 인스턴스인 경우 (Multiple instances of a resource type):\n알고리즘: 은행가 알고리즘 (Banker’s Algorithm) 사용\n자원 유형별로 여러 개의 동일한 인스턴스가 존재하는 경우, 자원 할당 그래프에서의 단순한 사이클 탐지만으로는 교착 상태를 정확히 판단하기 어렵습니다 (사이클이 있어도 교착 상태가 아닐 수 있음). 따라서 더 정교한 알고리즘인 은행가 알고리즘이 사용됩니다. 은행가 알고리즘의 핵심 요소: 최대 요구량 (Max): 각 프로세스가 각 자원 유형에 대해 최대로 필요로 하는 인스턴스 수. 현재 할당량 (Allocation): 현재 각 프로세스에게 할당된 각 자원 유형의 인스턴스 수. 필요량 (Need): 각 프로세스가 작업을 완료하기 위해 앞으로 더 필요한 각 자원 유형의 인스턴스 수 (Need = Max - Allocation). 가용량 (Available): 현재 시스템에서 즉시 사용 가능한 각 자원 유형의 인스턴스 수. 작동 방식 (안전성 검사 - Safety Algorithm): 프로세스가 자원을 요청하면, 일단 요청량이 Need 벡터 이내인지, 그리고 Available 벡터 이내인지를 확인합니다. 만약 그렇다면, 가상으로 자원을 할당해 봅니다 (Available 감소, Allocation 증가, Need 감소). 이 새로운 상태에서 안전성 알고리즘을 실행하여 시스템이 여전히 안전 상태인지 확인합니다. 안전성 알고리즘은 현재 가용 자원과 각 프로세스의 Need를 비교하여, 모든 프로세스를 완료시킬 수 있는 **안전 순서(safe sequence)**를 찾으려고 시도합니다. (방법 요약) 현재 가용 자원으로 Need를 만족시킬 수 있는 프로세스 Pi​를 찾습니다. 있다면, Pi​가 작업을 마치고 자신이 가진 모든 자원을 반납한다고 가정하고 가용 자원을 업데이트합니다. 이 과정을 반복하여 모든 프로세스가 포함되는 순서를 찾으면 안전 상태입니다. 안전 순서가 발견되면 실제 자원 할당이 이루어지고, 발견되지 않으면 (불안전 상태) 가상 할당을 취소하고 프로세스는 대기합니다. “resource type 당 2개의 인스턴스가 있을때 뱅커스 알로리즘을 사용한다” (원문 반복):\n이 문장이 두 번 반복된 것은 “자원 유형당 다중 인스턴스\"의 예시로서 최소 2개 이상의 인스턴스가 있을 때부터 은행가 알고리즘이 적용될 수 있음을 강조하는 것으로 보입니다. 즉, 인스턴스가 하나일 때는 자원 할당 그래프를 통한 사이클 검출 방식이 더 적합하고, 인스턴스가 2개 이상인 다중 인스턴스 환경에서는 은행가 알고리즘과 같은 보다 일반적인 방법이 필요하다는 의미입니다. 물론 은행가 알고리즘은 이론적으로 단일 인스턴스 환경에도 적용할 수 있지만, 다중 인스턴스 환경에서 그 필요성과 효과가 더욱 부각됩니다. 결론:\n교착 상태 회피 알고리즘은 시스템 내 자원의 특성(특히 인스턴스 수)에 따라 선택됩니다.\n단일 인스턴스/자원 유형: 자원 할당 그래프 기반 사이클 검사 (미래의 잠재적 사이클 형성 방지) 다중 인스턴스/자원 유형: 은행가 알고리즘 (안전 순서 존재 여부 검사를 통해 안전 상태 유지) 은행가 알고리즘은 더 일반적이고 강력하지만, 각 프로세스의 최대 자원 요구량 정보가 필요하고 매 자원 요청 시 안전성 검사로 인한 오버헤드가 발생한다는 점을 항상 염두에 두어야 합니다.","description-8#description":"자원 할당 그래프(Resource-Allocation Graph)는 운영체제에서 프로세스와 자원 간의 관계를 시각적으로 표현하여 교착 상태(deadlock)를 탐지하고 방지하는 데 사용되는 도구입니다. 이 슬라이드에서는 자원 할당 그래프의 주요 구성 요소인 **간선(edge)**의 종류와 그 변환 규칙을 설명합니다.\n첫째, **클레임 간선(Pi​→Rj​)**은 프로세스 Pi​가 미래에 자원 Rj​를 요청할 _수 있음_을 나타냅니다. 이 간선은 점선으로 표현되며, 프로세스가 작업을 시작하기 전에 자신이 필요로 할 수 있는 모든 자원을 미리 선언(claim)해야 한다는 “사전 클레임(a priori claim)” 원칙을 반영합니다. 예를 들어, 어떤 프로그램이 실행되기 전에 “저는 프린터와 스캐너가 필요할 수 있습니다\"라고 미리 알리는 것과 같습니다. 이는 시스템이 자원 할당 결정을 내릴 때 미래의 자원 요구 사항을 고려할 수 있도록 돕습니다.\n둘째, 프로세스 Pi​가 실제로 자원 Rj​를 요청할 때, 점선으로 표시되었던 클레임 간선은 **요청 간선(request edge)**으로 변환됩니다. 요청 간선은 실선으로 표현될 수 있으며, 현재 프로세스가 해당 자원을 적극적으로 기다리고 있음을 나타냅니다. 예를 들어, “프린터를 요청합니다!“라고 외치는 것과 같은 상황입니다.\n셋째, 요청된 자원 Rj​가 프로세스 Pi​에 성공적으로 할당되면 요청 간선은 **할당 간선(assignment edge)**으로 다시 변환됩니다. 할당 간선은 자원 인스턴스에서 프로세스 Pi​로 향하는 화살표로 표현되며, 프로세스가 해당 자원을 현재 소유하고 있음을 의미합니다. “프린터가 저에게 할당되었습니다!“라는 상황입니다.\n넷째, 프로세스 Pi​가 자원 Rj​의 사용을 마친 후 이를 해제(release)하면, 할당 간선은 다시 **클레임 간선(claim edge)**으로 되돌아갑니다. 이는 프로세스가 자원을 더 이상 소유하고 있지 않지만, 미래에 다시 요청할 가능성이 있음을 나타냅니다. “프린터 사용을 마쳤습니다. 나중에 다시 사용할 수도 있어요.“와 같은 의미입니다.\n마지막으로 “Resources must be claimed a priori in the system\"이라는 문구는 이 자원 할당 그래프 스키마의 중요한 전제 조건을 강조합니다. 모든 프로세스는 실행을 시작하기 전에 자신이 필요로 할 수 있는 최대 자원 요구량을 미리 시스템에 알려야 합니다. 이는 시스템이 잠재적인 교착 상태를 미리 예측하고 방지하기 위한 정보를 얻는 데 필수적입니다. 이 사전 클레임 정보는 주로 **은행원 알고리즘(Banker’s Algorithm)**과 같은 교착 상태 회피(deadlock avoidance) 알고리즘에서 활용되어, 자원 할당 요청이 들어왔을 때 시스템이 안전한 상태를 유지할 수 있는지 판단하는 데 사용됩니다. 이 모든 간선 변환 과정은 시스템이 프로세스와 자원 간의 복잡한 상호작용을 추적하고, 잠재적인 교착 상태를 식별하며, 이를 방지하기 위한 전략을 적용하는 데 중요한 기반을 제공합니다.","description-9#description":"이 슬라이드는 단순히 **“Resource-Allocation Graph”**라는 제목만을 포함하고 있으며, 실제 그래프의 시각적인 예시를 기대하게 만듭니다. 앞선 슬라이드에서 설명된 클레임 간선, 요청 간선, 할당 간선의 개념들이 실제 그래프 상에서 어떻게 표현되는지를 보여주는 그림이 뒤따라야 합니다.\n일반적인 자원 할당 그래프는 다음과 같은 요소들을 포함합니다:\n프로세스 노드 (Process Nodes): 원 또는 타원으로 표시되며, P1​,P2​,…와 같이 프로세스를 나타냅니다. 자원 유형 노드 (Resource Type Nodes): 사각형으로 표시되며, R1​,R2​,…와 같이 특정 유형의 자원(예: 프린터, 스캐너, CPU, 메모리 블록 등)을 나타냅니다. 자원 인스턴스 (Resource Instances): 자원 유형 노드 내부에 점 또는 작은 원으로 표시되며, 해당 자원 유형에 속하는 개별 자원 단위를 나타냅니다. 예를 들어, 3개의 프린터가 있다면 R1​ 노드 안에 3개의 점이 있을 수 있습니다. **간선(Edges)**의 종류와 의미는 다음과 같습니다:\n요청 간선 (Request Edge): 프로세스 노드에서 자원 유형 노드로 향하는 화살표(Pi​→Rj​). 프로세스 Pi​가 자원 Rj​의 인스턴스 하나를 요청하고 있음을 나타냅니다. 이 간선은 프로세스가 자원을 얻기 위해 기다리고 있음을 의미합니다. 할당 간선 (Assignment Edge): 자원 유형 노드 내의 특정 자원 인스턴스에서 프로세스 노드로 향하는 화살표(Rj​⋅→Pi​). 자원 Rj​의 한 인스턴스가 프로세스 Pi​에 할당되어 있음을 나타냅니다. 이는 프로세스 Pi​가 현재 해당 자원을 사용 중임을 의미합니다. 클레임 간선 (Claim Edge): 프로세스 노드에서 자원 유형 노드로 향하는 점선 화살표(Pi​⇢Rj​). 프로세스 Pi​가 미래에 자원 Rj​를 요청할 수 있음을 나타냅니다. 이는 자원 할당 그래프 알고리즘에서 교착 상태를 회피하기 위한 사전 정보로 사용됩니다. 이 간선은 프로세스가 실행되기 전에 자신이 필요로 할 수 있는 최대 자원을 미리 선언하는 개념과 관련이 있습니다. 자원 할당 그래프는 이러한 노드와 간선들의 관계를 통해 시스템의 현재 자원 할당 상태와 잠재적인 요청 상태를 보여줍니다. 그래프에서 **사이클(cycle)**이 발견될 경우, 이는 **교착 상태(deadlock)**의 가능성(potential deadlock) 또는 실제 교착 상태(actual deadlock)를 나타낼 수 있습니다. 사이클이 존재한다고 해서 항상 교착 상태인 것은 아니지만, 교착 상태가 발생하기 위한 필요 조건 중 하나입니다. 특히, 자원 유형 노드에 여러 인스턴스가 있는 경우에는 사이클이 있더라도 교착 상태가 아닐 수 있습니다. 하지만 모든 자원 유형에 인스턴스가 하나뿐인 경우, 사이클은 곧 교착 상태를 의미합니다. 다음 슬라이드들에서 이러한 개념들이 더 구체적인 예시와 함께 설명될 것입니다.","detailed-explanation#\u003cstrong\u003eDetailed Explanation\u003c/strong\u003e":"이 슬라이드는 컴퓨터 과학, 특히 운영 체제 분야의 핵심 개념인 **가상 메모리(Virtual Memory)**의 기본적인 배경과 원리를 소개하고 있습니다. 가상 메모리는 현대 컴퓨팅 환경에서 메모리를 효율적으로 관리하고 다중 프로그래밍을 가능하게 하는 필수적인 기술입니다.","detailed-explanation-1#\u003cstrong\u003eDetailed Explanation\u003c/strong\u003e":"이 슬라이드의 다이어그램은 가상 메모리의 핵심 원리인 **‘논리 주소 공간이 물리 주소 공간보다 클 수 있다’**는 개념을 시각적으로 압축하여 보여줍니다. 이 그림은 가상 메모리 시스템의 전체적인 구조와 동작 방식을 이해하는 데 매우 중요합니다.","detailed-explanation-10#\u003cstrong\u003eDetailed Explanation\u003c/strong\u003e":"이 슬라이드는 다양한 **페이지 교체 알고리즘(Page Replacement Algorithms)**을 소개하며, 이들 알고리즘이 추구하는 근본적인 목표를 명시하고 있습니다. 페이지 교체 알고리즘은 가상 메모리 시스템의 성능에 지대한 영향을 미치는 운영 체제의 핵심 구성 요소입니다.","detailed-explanation-11#\u003cstrong\u003eDetailed Explanation\u003c/strong\u003e":"이 슬라이드는 최적 페이지 교체 알고리즘(Optimal Page Replacement Algorithm), 종종 OPT 또는 MIN 알고리즘이라고도 불리는 기법에 대해 설명합니다. 이 알고리즘은 이름에서 알 수 있듯이 이론적으로 가장 이상적인 페이지 교체 성능을 제공합니다.","detailed-explanation-12#\u003cstrong\u003eDetailed Explanation\u003c/strong\u003e":"이 슬라이드들은 최적 페이지 교체(Optimal Page Replacement) 알고리즘이 실제로 어떻게 동작하는지를 보여주는 예시 또는 다이어그램을 위한 자리입니다. 특정 다이어그램이 주어지지 않았으므로, 가장 널리 사용되는 방식인 **참조 문자열(reference string)**과 **고정된 수의 프레임(frame)**을 사용하여 최적 알고리즘의 단계별 실행 과정을 시뮬레이션하고, 그 결과를 통해 알고리즘의 특징을 상세히 설명하겠습니다.","detailed-explanation-13#\u003cstrong\u003eDetailed Explanation\u003c/strong\u003e":"이 슬라이드는 페이지 교체 알고리즘 중 가장 간단하고 직관적인 방법 중 하나인 FIFO(First-In, First-Out) 알고리즘에 대해 설명합니다. FIFO는 우리말로 선입선출 알고리즘이라고 하며, 그 이름에서 알 수 있듯이 메모리에 가장 먼저 들어온 페이지를 가장 먼저 내보내는 방식을 사용합니다.","detailed-explanation-14#\u003cstrong\u003eDetailed Explanation\u003c/strong\u003e":"이 슬라이드들은 FIFO(First-In, First-Out) 페이지 교체 알고리즘이 실제로 어떻게 동작하는지를 보여주는 예시 또는 다이어그램을 위한 자리입니다. 최적 알고리즘 예시에서 사용했던 것과 동일한 **참조 문자열(reference string)**과 프레임 수를 사용하여 FIFO 알고리즘의 단계별 실행 과정을 시뮬레이션하고, 그 결과를 통해 알고리즘의 특징과 최적 알고리즘과의 성능 차이를 비교 분석하겠습니다.","detailed-explanation-2#\u003cstrong\u003eDetailed Explanation\u003c/strong\u003e":"이 슬라이드는 가상 메모리를 구현하는 가장 대표적인 방법인 **요구 페이징(Demand Paging)**의 개념과 그로 인해 얻을 수 있는 핵심적인 이점들을 설명합니다. 요구 페이징은 ‘게으른 스와퍼(Lazy Swapper)‘라고도 불리며, 효율적인 메모리 관리를 위한 핵심 전략입니다.","detailed-explanation-3#\u003cstrong\u003eDetailed Explanation\u003c/strong\u003e":"이 슬라이드는 요구 페이징을 하드웨어 수준에서 실제로 구현하기 위한 핵심 메커니즘인 **유효-무효 비트(Valid-Invalid Bit)**에 대해 설명합니다. 이 작은 1비트짜리 플래그는 가상 메모리 시스템이 제대로 동작하는 데 있어 결정적인 역할을 합니다.","detailed-explanation-4#\u003cstrong\u003eDetailed Explanation\u003c/strong\u003e":"이 슬라이드의 다이어그램은 앞선 슬라이드에서 설명한 이론적인 개념들, 즉 논리/물리 주소 공간의 분리, 페이지 테이블, 그리고 유효-무효 비트가 실제 시스템에서 어떻게 통합되어 동작하는지를 구체적인 예시를 통해 시각적으로 보여줍니다. 이 그림은 가상 메모리 시스템의 ‘스냅샷’과 같으며, 특정 시점의 메모리 상태를 명확하게 이해하는 데 큰 도움을 줍니다.","detailed-explanation-5#\u003cstrong\u003eDetailed Explanation\u003c/strong\u003e":"이 슬라이드는 **페이지 폴트(Page Fault)**가 발생했을 때, 운영 체제가 이를 처리하는 구체적인 절차를 단계별로 상세하게 설명합니다. 페이지 폴트는 오류가 아니라, 요구 페이징 시스템이 동작하기 위한 정상적이고 필수적인 과정입니다. 이는 하드웨어(MMU)가 해결할 수 없는 문제를 소프트웨어(운영 체제)에게 위임하는 정교한 협력 메커니즘입니다.","detailed-explanation-6#\u003cstrong\u003eDetailed Explanation\u003c/strong\u003e":"이 슬라이드의 다이어그램은 바로 앞 슬라이드에서 텍스트로 설명했던 페이지 폴트 처리 과정을 한 장의 그림으로 요약하여 시각화한 것입니다. 각 번호가 붙은 단계는 운영 체제와 하드웨어가 협력하여 메모리에 없는 페이지를 가져오는 일련의 동작을 명확하게 보여줍니다. 이 다이어그램을 단계별로 따라가면 페이지 폴트 처리의 전체 흐름을 직관적으로 이해할 수 있습니다.","detailed-explanation-7#\u003cstrong\u003eDetailed Explanation\u003c/strong\u003e":"이 슬라이드는 요구 페이징 시스템 운영 중에 발생하는 매우 현실적이고 중요한 문제 상황을 제기하고, 그 해결책인 **페이지 교체(Page Replacement)**의 개념을 소개합니다. 이 문제는 시스템의 성능에 직접적인 영향을 미치기 때문에 매우 신중하게 다루어져야 합니다.","detailed-explanation-8#\u003cstrong\u003eDetailed Explanation\u003c/strong\u003e":"이 슬라이드의 다이어그램은 앞선 슬라이드에서 설명한 **페이지 교체(Page Replacement)**의 전체 과정을 시각적으로 명확하게 보여주는 순서도입니다. 이 그림은 페이지 폴트가 발생했지만 물리 메모리에 빈 프레임이 없을 때, 운영 체제가 어떻게 이 위기를 기회로 바꾸어 시스템을 계속 작동시키는지를 단계별로 나타냅니다.","detailed-explanation-9#\u003cstrong\u003eDetailed Explanation\u003c/strong\u003e":"이 슬라이드는 운영 체제의 메모리 관리에서 매우 중요한 주제인 **페이지 교체(Page Replacement)**를 소개하는 제목 슬라이드입니다. 이전 슬라이드들에서 가상 메모리의 개념, 요구 페이징, 페이지 폴트 처리 과정 등을 살펴보았습니다. 페이지 교체는 이러한 과정 중, 특히 페이지 폴트가 발생했으나 물리 메모리에 새로운 페이지를 적재할 빈 프레임(free frame)이 없는 경우에 반드시 필요한 핵심적인 후속 조치입니다.","dynamic-linking-동적-연결#Dynamic Linking (동적 연결)":"Static linking – system libraries and program code combined by the loader into the binary program image (정적 연결 – 시스템 라이브러리와 프로그램 코드가 로더에 의해 바이너리 프로그램 이미지로 결합됨) Dynamic linking –linking postponed until execution time (동적 연결 – 연결이 실행 시간까지 연기됨) Small piece of code, stub, used to locate the appropriate memory-resident library routine (스텁이라는 작은 코드 조각이 메모리에 상주하는 적절한 라이브러리 루틴을 찾는 데 사용됨) Stub replaces itself with the address of the routine, and executes the routine (스텁은 자신을 루틴의 주소로 대체하고, 해당 루틴을 실행함) Operating system checks if routine is in processes’ memory address (운영체제는 루틴이 프로세스의 메모리 주소 공간에 있는지 확인합니다) If not in address space, add to address space (주소 공간에 없다면, 주소 공간에 추가함) Dynamic linking is particularly useful for libraries (동적 연결은 특히 라이브러리에 유용합니다) System also known as shared libraries (이 시스템은 공유 라이브러리라고도 알려져 있음) [설명]\n동적 연결은 라이브러리 함수들과 같은 외부 코드와의 연결(linking)을 프로그램 실행 시간까지 미루는 기법입니다.\n정적 연결 (Static Linking): 전통적인 방식에서는 프로그램이 컴파일되고 링크될 때, 프로그램 코드뿐만 아니라 프로그램이 사용하는 모든 라이브러리 루틴(예: printf 함수)의 코드까지 실행 파일 안에 포함시킵니다. 단점: 실행 파일의 크기가 커집니다. 여러 프로그램이 동일한 라이브러리 루틴을 사용하더라도, 각 프로그램의 실행 파일마다 해당 루틴의 복사본이 포함되므로 디스크 공간이 낭비됩니다. 또한 메모리에 여러 복사본이 동시에 올라올 수 있어 메모리도 낭비됩니다. 라이브러리가 업데이트되면, 해당 라이브러리를 사용하는 모든 프로그램을 다시 링크하고 재배포해야 합니다. 동적 연결 (Dynamic Linking): 라이브러리 루틴과의 실제 연결은 프로그램이 실행될 때(또는 해당 루틴이 처음 호출될 때) 이루어집니다. 스텁 (Stub): 프로그램 코드 내에는 실제 라이브러리 루틴 대신, 해당 루틴을 찾는 방법을 아는 작은 코드 조각인 ‘스텁’이 포함됩니다. 동작 과정: 프로그램이 동적으로 연결된 라이브러리 루틴을 처음 호출하면, 스텁이 실행됩니다. 스텁은 운영체제에게 해당 라이브러리 루틴이 이미 메모리에 있는지 확인하도록 요청합니다. 만약 라이브러리 루틴이 메모리에 있다면 (다른 프로세스가 이미 로드했을 수 있음), 스텁은 그 루틴의 메모리 주소를 얻어와서, 다음부터는 스텁을 거치지 않고 바로 그 주소로 점프하도록 자신의 코드를 수정하거나 포인터를 설정합니다. 그리고 해당 루틴을 실행합니다. 만약 라이브러리 루틴이 메모리에 없다면, 운영체제는 디스크에서 해당 라이브러리를 찾아 메모리에 적재하고, 그 주소를 스텁에게 알려줍니다. 이후 과정은 3번과 동일합니다. 장점 (특히 라이브러리에 유용): 메모리 절약: 라이브러리 코드가 메모리에 한 번만 적재되고, 이를 필요로 하는 모든 프로세스들이 이 한 벌의 코드를 공유합니다. 이를 **공유 라이브러리(Shared Libraries)**라고 합니다 (예: Windows의 DLL, Linux의 .so 파일). 디스크 공간 절약: 실행 파일 자체에는 라이브러리 코드가 포함되지 않으므로 파일 크기가 작아집니다. 쉬운 업데이트: 라이브러리가 업데이트되면, 해당 라이브러리 파일만 교체하면 됩니다. 이 라이브러리를 사용하는 프로그램들은 다시 컴파일하거나 링크할 필요 없이 새로운 버전의 라이브러리를 자동으로 사용하게 됩니다 (인터페이스가 호환되는 한). 운영체제의 역할: 동적 연결에서는 운영체제가 라이브러리 관리, 메모리 적재, 주소 매핑 등에 관여하여 프로세스들이 공유 라이브러리를 안전하고 효율적으로 사용할 수 있도록 지원합니다. 동적 적재와 동적 연결은 종종 함께 사용되어 시스템 자원의 효율성을 극대화합니다.","dynamic-loading-동적-적재#Dynamic Loading (동적 적재)":"Routine is not loaded until it is called (루틴이 호출될 때까지 적재되지 않습니다) Better memory-space utilization; unused routine is never loaded (더 나은 메모리 공간 활용; 사용되지 않는 루틴은 절대로 적재되지 않음) All routines kept on disk in relocatable load format (모든 루틴은 재배치 가능 적재 포맷으로 디스크에 유지됨) Useful when large amounts of code are needed to handle infrequently occurring cases (드물게 발생하는 경우를 처리하기 위해 많은 양의 코드가 필요할 때 유용함) No special support from the operating system is required (운영체제의 특별한 지원이 필요하지 않음) Implemented through program design (프로그램 설계를 통해 구현됨) OS can help by providing libraries to implement dynamic loading (OS는 동적 적재를 구현하기 위한 라이브러리를 제공하여 도움을 줄 수 있음) [설명]\n동적 적재는 메모리 효율성을 높이기 위한 기법으로, 프로그램의 모든 부분을 실행 시작 시점에 메모리에 올리는 대신, 특정 루틴(함수 또는 코드 모듈)이 실제로 호출되는 시점에 메모리에 적재하는 방식입니다.\n지연된 적재: 프로그램이 시작될 때는 핵심적인 부분만 메모리에 적재하고, 나머지 루틴들은 디스크에 재배치 가능한 형태로 대기합니다. 어떤 루틴이 호출되면, 그제서야 해당 루틴을 디스크에서 메모리로 가져와 연결하고 실행합니다. 메모리 효율성 향상: 프로그램 내에는 많은 기능들이 있지만, 실제 실행 시에는 그중 일부만 사용되는 경우가 많습니다 (예: 복잡한 소프트웨어의 특정 고급 기능, 오류 처리 루틴 등). 동적 적재를 사용하면, 한 번도 호출되지 않는 루틴은 메모리를 전혀 차지하지 않으므로 메모리 공간을 절약할 수 있습니다. 특히 전체 프로그램 크기가 매우 클 때 유용합니다. 적재 형태: 디스크에 있는 루틴들은 재배치 가능한 형태로 저장되어 있어, 메모리의 어느 위치에 적재되더라도 주소 문제가 발생하지 않도록 준비되어 있습니다. 유용성: 프로그램의 크기는 크지만 특정 기능(예: 도움말 기능, 특정 오류 복구 루틴, 드문 사용자 옵션 처리)이 자주 사용되지 않을 때 효과적입니다. 이렇게 하면 프로그램 시작 시간도 빨라질 수 있습니다. 구현: 원칙적으로 동적 적재는 프로그래머가 직접 프로그램 로직 내에서 구현할 수 있습니다. 예를 들어, 루틴 호출 시 해당 루틴이 메모리에 있는지 확인하고, 없으면 로드하는 코드를 작성할 수 있습니다. 운영체제는 이러한 동적 적재 기능을 쉽게 구현할 수 있도록 시스템 라이브러리(예: dlopen(), dlsym() 같은 함수를 제공하는 라이브러리)를 제공하여 프로그래머를 도울 수 있습니다. 동적 적재는 특히 메모리가 제한적인 환경이나 매우 큰 애플리케이션에서 유용하며, 프로그램의 시작 속도를 개선하고 전반적인 시스템 성능을 향상시키는 데 기여할 수 있습니다.","dynamic-partitioning-example-동적-분할-예제#Dynamic Partitioning Example (동적 분할 예제)":"External Fragmentation (외부 단편화) Memory external to all processes is fragmented (모든 프로세스의 외부에 있는 메모리가 단편화됨) Compaction (압축 또는 집약) OS moves processes so that they are contiguous (운영체제가 프로세스들을 이동시켜 연속적으로 만듦) Time consuming and wastes CPU time (시간이 많이 소모되고 CPU 시간을 낭비함) [설명]\n외부 단편화 재정의: 사용 중인 프로세스들 사이에 끼어 있는 작은 가용 메모리 공간들로 인해, 총 가용 메모리 양은 충분함에도 불구하고 특정 크기의 프로세스를 할당할 수 없는 현상입니다. 압축 (Compaction): 외부 단편화 문제를 해결하기 위한 방법 중 하나입니다. 운영체제가 메모리에 흩어져 있는 여러 프로세스들을 한쪽으로 이동시켜 연속된 공간을 만들고, 흩어져 있던 가용 공간들을 하나의 큰 가용 블록으로 합칩니다. 예: (P1, hole1, P2, hole2, P3) -\u003e (P1, P2, P3, hole_combined) 문제점: 시간 소모: 메모리 내용을 복사하고 이동시키는 작업은 매우 많은 시간이 소요됩니다. 이 동안 시스템은 다른 작업을 거의 수행할 수 없습니다. CPU 시간 낭비: 압축 작업 자체가 CPU 자원을 사용합니다. 어떤 프로세스를 옮길 것인가?: 모든 프로세스를 옮겨야 합니다. 언제 압축을 수행할 것인가?: 너무 자주 하면 성능 저하, 너무 안 하면 단편화 심화. 실행 중인 프로세스 이동의 어려움: 프로세스가 실행 중에 메모리 주소가 바뀌면 프로그램 내의 주소 참조가 모두 엉망이 됩니다. 따라서 압축은 프로세스의 주소 바인딩이 실행 시간 바인딩(execution time binding)일 때, 즉 MMU와 같은 하드웨어 지원으로 논리 주소와 물리 주소가 동적으로 변환될 때만 가능합니다. (이후 슬라이드에서 주소 바인딩 설명됨)","dynamic-partitioning-동적-분할#Dynamic Partitioning (동적 분할)":"Partitions are of variable length and number (파티션의 길이와 수가 가변적입니다) Process is allocated as much as required (프로세스는 필요한 만큼의 메모리를 할당받습니다) OS decides which free block to allocate (운영체제가 어느 가용 블록을 할당할지 결정합니다) 동적 분할 방식은 고정 분할의 단점을 해결하기 위해 등장했습니다.\n가변 길이 및 수의 파티션: 동적 분할에서는 미리 파티션을 나누어 놓지 않습니다. 메모리는 초기에 하나의 큰 가용 블록(free block 또는 hole)으로 간주됩니다. 프로세스가 도착하면, 운영체제는 이 가용 블록 중에서 해당 프로세스를 수용할 수 있는 공간을 찾아 정확히 필요한 만큼의 크기로 파티션을 만들어 할당합니다. 따라서 파티션의 크기와 개수는 실행 중인 프로세스들의 요구에 따라 동적으로 변합니다. 필요한 만큼 할당: 프로세스가 70KB를 필요로 하면 정확히 70KB를 할당합니다. 이로 인해 고정 분할에서 발생했던 내부 단편화 문제는 발생하지 않습니다. (이론적으로는 그렇지만, 실제로는 할당 단위 등의 이유로 아주 작은 내부 단편화가 발생할 수도 있으나, 고정 분할에 비하면 무시할 만한 수준입니다.) OS의 할당 결정: 여러 개의 가용 블록이 존재할 수 있습니다 (프로세스가 종료되어 메모리를 반납하면 해당 공간이 가용 블록이 됨). 새로운 프로세스에 어떤 가용 블록을 할당할지 결정하는 정책(알고리즘)이 필요합니다.","dynamic-relocation-using-a-relocation-register-재배치-레지스터를-사용한-동적-재배치#Dynamic relocation using a relocation register (재배치 레지스터를 사용한 동적 재배치)":"(Diagram showing: CPU -\u003e logical address -\u003e MMU [Relocation register +] -\u003e physical address -\u003e Memory)\n[설명]\n이 다이어그램은 재배치 레지스터(MMU의 일부)를 사용한 가장 기본적인 동적 주소 변환 과정을 보여줍니다.\nCPU: 논리 주소(logical address)를 생성합니다. 이 주소는 보통 0부터 시작하는 상대적인 주소입니다. (예: 100) MMU (Memory Management Unit): CPU로부터 논리 주소를 받습니다. MMU 내의 재배치 레지스터(relocation register)에는 해당 프로세스가 적재된 물리 메모리의 시작 주소가 저장되어 있습니다. (예: 재배치 레지스터 값 = 14000) 논리 주소에 재배치 레지스터 값을 더합니다. (예: 100 + 14000 = 14100) (그림에는 생략되었지만, 이 과정에서 한계 레지스터를 이용한 유효 범위 검사도 함께 이루어집니다.) Physical Address (물리 주소): 변환된 결과가 물리 주소입니다. (예: 14100) Memory (메모리): 이 물리 주소를 사용하여 실제 메모리 위치에 접근합니다. 이러한 동적 재배치 덕분에, 같은 프로그램이라도 메모리의 다른 위치에 적재될 때마다 재배치 레지스터 값만 변경해주면 되므로, 코드를 수정할 필요 없이 유연하게 메모리를 사용할 수 있습니다.","dynamic-storage-allocation-problem-동적-저장-공간-할당-문제#Dynamic Storage-Allocation Problem (동적 저장 공간 할당 문제)":"How to satisfy a request of size n from a list of free holes? (크기 n의 요청을 가용 홀 리스트로부터 어떻게 만족시킬 것인가?)\nFirst-fit: Allocate the first hole that is big enough (충분히 큰 첫 번째 가용 홀을 할당) Best-fit: Allocate the smallest hole that is big enough; must search entire list, unless ordered by size (충분히 큰 가장 작은 가용 홀을 할당; 크기 순으로 정렬되어 있지 않다면 전체 리스트를 탐색해야 함) Produces the smallest leftover hole (가장 작은 남은 홀을 생성) Worst-fit: Allocate the largest hole; must also search entire list (가장 큰 가용 홀을 할당; 역시 전체 리스트를 탐색해야 함) Produces the largest leftover hole (가장 큰 남은 홀을 생성) First-fit and best-fit better than worst-fit in terms of speed and storage utilization (최초 적합과 최적 적합이 속도와 저장 공간 활용 측면에서 최악 적합보다 우수합니다)\n[설명]\n이 슬라이드는 슬라이드 8.12에서 설명했던 동적 분할에서의 할당 전략(First-fit, Best-fit, Worst-fit)을 다시 한번 반복하고 있습니다. 이는 동적 저장 공간 할당 문제의 핵심적인 부분이기 때문입니다.\n문제 정의: 현재 메모리에는 여러 개의 가용 공간(홀)들이 흩어져 있습니다. 새로운 프로세스가 크기 n의 메모리를 요청할 때, 이 가용 홀들 중 어느 것을 선택하여 할당할 것인가 하는 문제입니다. First-fit (최초 적합): 홀 리스트를 순서대로 검색하여 n보다 크거나 같은 첫 번째 홀을 선택합니다. 장점: 검색 시간이 비교적 빠를 수 있습니다 (평균적으로 리스트의 절반만 검색). 구현이 간단합니다. 단점: 큰 홀들이 앞부분에 있을 경우 작은 요청에 의해 잘게 나뉘어, 나중에 큰 요청을 처리하지 못할 수 있습니다. Best-fit (최적 적합): 홀 리스트 전체를 검색하여 n보다 크거나 같으면서 그 크기 차이가 가장 작은 홀(즉, hole_size - n이 최소가 되는 홀)을 선택합니다. 장점: 요청 크기에 가장 근접한 홀을 사용하므로, 할당 후 남는 조각(leftover hole)의 크기가 최소화됩니다. 이는 매우 작은, 쓸모없는 홀들이 생기는 것을 줄여 메모리 활용률을 높일 수 있다는 기대를 줍니다. 단점: 항상 전체 홀 리스트를 검색해야 하므로 검색 시간이 오래 걸립니다 (리스트가 크기순으로 정렬되어 있다면 개선 가능). 또한, 매우 작은 홀들이 많이 생성되어 오히려 단편화를 악화시킬 수도 있습니다. Worst-fit (최악 적합): 홀 리스트 전체를 검색하여 n보다 크거나 같은 홀 중에서 가장 큰 홀을 선택합니다. 장점 (이론적): 큰 홀을 사용하고 남은 조각도 상대적으로 크기 때문에, 그 남은 조각이 다른 중간 크기의 프로세스를 수용할 가능성을 높이려는 의도입니다. 단점: 항상 전체 홀 리스트를 검색해야 합니다. 큰 가용 공간이 빨리 소모되어, 정작 매우 큰 프로세스가 필요할 때 할당 가능한 큰 홀이 남아있지 않을 수 있습니다. 실험 결과, 일반적으로 성능이 좋지 않은 것으로 알려져 있습니다. 일반적인 평가:\n시뮬레이션 결과와 실제 구현 경험에 따르면, 최초 적합(First-fit)과 최적 적합(Best-fit)이 최악 적합(Worst-fit)보다 평균적인 검색 속도나 메모리 단편화 관리(storage utilization) 측면에서 더 나은 성능을 보입니다. 최초 적합은 구현의 단순성과 괜찮은 평균 성능 때문에 널리 사용됩니다. 최적 적합은 검색 비용이 더 들지만 때때로 메모리 활용도를 약간 더 높일 수 있습니다.","effective-access-time-유효-접근-시간#Effective Access Time (유효 접근 시간)":"Associative Lookup = e time unit (연관 메모리 조회 = e 시간 단위)\nCan be \u003c 10% of memory access time (메모리 접근 시간의 10% 미만일 수 있음) Hit ratio = α (히트율 = α)\nHit ratio – percentage of times that a page number is found in the associative registers; ratio related to number of associative registers (히트율 – 페이지 번호가 연관 레지스터(TLB)에서 발견되는 비율; 이 비율은 연관 레지스터의 수와 관련됨) Consider α = 80%, e = 20ns for TLB search, 100ns for memory access (α = 80%, TLB 검색에 e = 20ns, 메모리 접근에 100ns를 가정)\nEffective Access Time (EAT) (유효 접근 시간)\nEAT = (1 + e) α + (2 + e)(1 – α) (이 공식은 M=1로 정규화한 시간 단위로 보임)\n= 2 + e – α (위 공식을 M=1로 정규화하고 e도 비율로 가정했을 때의 단순화된 형태) Consider α = 80%, e = 20ns for TLB search, 100ns for memory access (α = 80%, TLB 검색에 e = 20ns, 메모리 접근에 100ns를 가정)\nEAT = 0.80 x 120 + 0.20 x 220 = 140ns Consider slower memory but better hit ratio -\u003e α = 98%, e = 20ns for TLB search, 140ns for memory access (더 느린 메모리지만 더 나은 히트율을 가정 → α = 98%, TLB 검색에 e = 20ns, 메모리 접근에 140ns)\nEAT = 0.98 x 160 + 0.02 x 300 = 162.8ns [한글 번역 및 상세 설명]\nTLB를 사용하는 페이징 시스템의 평균적인 메모리 접근 성능을 나타내는 **유효 접근 시간(Effective Access Time, EAT)**을 계산하는 방법을 설명합니다. ⏱️\n용어 정의:\nAssociative Lookup (연관 메모리 조회 시간) = e: TLB에서 페이지 번호를 검색하는 데 걸리는 시간입니다. 이 시간 e는 주 메모리 접근 시간 M에 비해 매우 작습니다 (예: M의 10% 미만). Hit ratio (히트율) = α (알파): CPU가 생성한 논리 주소의 페이지 번호가 TLB에서 발견될 확률(비율)입니다. 예를 들어 α = 0.80은 80%의 경우 TLB에서 원하는 정보를 찾는다는 의미입니다. 히트율은 TLB의 크기, 프로그램의 메모리 접근 패턴(지역성), 교체 정책 등에 의해 영향을 받습니다. (TLB 미스율은 1-α가 됩니다.) 유효 접근 시간 (EAT) 계산 원리:\nEAT는 TLB 히트 시의 접근 시간과 TLB 미스 시의 접근 시간을 각각의 발생 확률(히트율, 미스율)로 가중 평균하여 계산합니다.\nTLB 히트 시 접근 시간 = e + M (TLB 조회 시간 + 실제 데이터 메모리 접근 시간) TLB 미스 시 접근 시간 = e + M + M = e + 2M (TLB 조회 시간 + 페이지 테이블 메모리 접근 시간 + 실제 데이터 메모리 접근 시간) 따라서, EAT = α * (e + M) + (1 - α) * (e + 2M) 슬라이드의 EAT 공식에 대한 부연 설명:\n슬라이드에 제시된 EAT = (1 + e) α + (2 + e)(1 – α) 와 EAT = 2 + e – α 공식은, 주 메모리 접근 시간 M을 1 시간 단위로 정규화하고, e를 M에 대한 상대적인 비율로 표현했을 때 유도될 수 있는 형태입니다. 만약 M=1이고, e가 e_ratio = e_actual / M 이라면, EATratio​=α(eratio​+1)+(1−α)(eratio​+2) =αeratio​+α+eratio​+2−αeratio​−2α =eratio​+2−α 이것이 슬라이드의 2 + e – α 형태와 일치합니다. (여기서 e는 eratio​를 의미) 그러나 슬라이드의 예제 계산에서는 e와 M에 실제 시간 단위(ns)를 사용하고 있으므로, EAT = α * (e + M) + (1 - α) * (e + 2M) 공식을 직접 사용하는 것이 더 명확합니다. 슬라이드의 계산 과정은 이 정확한 공식을 따르고 있습니다. 예제 계산 1:\n가정: 히트율 α = 80% (0.80), TLB 검색 시간 e = 20ns, 주 메모리 접근 시간 M = 100ns. TLB 히트 시 접근 시간 = 20ns+100ns=120ns. TLB 미스 시 접근 시간 = 20ns+100ns+100ns=220ns. EAT = 0.80×(120ns)+(1−0.80)×(220ns) =0.80×120ns+0.20×220ns =96ns+44ns=140ns. TLB가 없을 때의 접근 시간(200ns)에 비해 상당히 개선되었음을 알 수 있습니다. (140ns는 200ns 대비 30% 성능 향상) 예제 계산 2 (더 느린 메모리, 더 높은 히트율):\n가정: 히트율 α = 98% (0.98), TLB 검색 시간 e = 20ns, 주 메모리 접근 시간 M = 140ns. TLB 히트 시 접근 시간 = 20ns+140ns=160ns. TLB 미스 시 접근 시간 = 20ns+140ns+140ns=300ns. EAT = 0.98×(160ns)+(1−0.98)×(300ns) =0.98×160ns+0.02×300ns =156.8ns+6ns=162.8ns. 이 예는 히트율이 매우 높더라도(α=0.98), 주 메모리 자체가 느리면(M=140ns) EAT가 이전 예(M=100ns, α=0.80일 때 140ns)보다 나빠질 수 있음을 보여줍니다. 또한, 히트율이 EAT에 미치는 영향이 매우 크다는 것을 알 수 있습니다. 미스율이 단 2%임에도 불구하고, 미스 시의 페널티(300ns)가 크기 때문에 EAT에 영향을 줍니다. 결론: TLB는 페이징 시스템의 성능에 필수적이며, EAT는 TLB 히트율(α), TLB 접근 시간(e), 주 메모리 접근 시간(M)에 의해 결정됩니다. 높은 히트율을 유지하는 것이 EAT를 낮추는 데 가장 중요합니다.","equal-size-partitions-동일-크기-분할#Equal-size partitions (동일 크기 분할)":"Any process whose size is less than or equal to the partition size can be loaded into an available partition (파티션 크기보다 작거나 같은 크기의 모든 프로세스는 가용한 파티션에 적재될 수 있습니다)\n고정 분할 방식 중 ‘동일 크기 분할’에 대해 설명합니다.\n동일 크기 분할: 시스템이 시작될 때 전체 메모리를 동일한 크기를 가진 여러 개의 파티션으로 미리 나누어 놓습니다. 예를 들어 1000KB 메모리를 100KB 크기의 파티션 10개로 나눌 수 있습니다. 프로세스 적재 조건: 실행하려는 프로세스의 크기가 이 미리 정해진 파티션의 크기보다 작거나 같아야 합니다. 만약 프로세스 크기가 50KB라면 100KB 파티션에 들어갈 수 있지만, 프로세스 크기가 150KB라면 100KB 파티션에는 들어갈 수 없습니다. 가용 파티션: 비어있는 파티션 중 아무 곳에나 프로세스를 적재할 수 있습니다. 이 슬라이드는 동일 크기 고정 분할 방식에서 메모리가 할당된 모습을 시각적으로 보여줍니다.\n메모리가 여러 개의 동일한 크기의 칸(파티션)으로 나누어져 있고, 각 파티션에 프로세스 P1, P2, P3가 적재되어 있는 상황을 가정할 수 있습니다. 각 프로세스(P1, P2, P3)는 각각의 파티션 크기보다 작거나 같기 때문에 해당 파티션에 적재될 수 있었습니다.","example-cont#Example (Cont.)":"","example-of-bankers-algorithm#Example of Banker’s Algorithm":"","example-of-buddy-system-버디-시스템-예제#Example of Buddy System (버디 시스템 예제)":"(Diagram illustrating splitting and merging of blocks of sizes like 1M, 512K, 256K, 128K, 64K)\n[설명]\n이 슬라이드는 버디 시스템의 동작을 시각적으로 보여주는 예제입니다.\n초기 상태: 예를 들어 1MB의 전체 메모리 블록이 있다고 가정합니다. 할당 예시: 프로세스 A (100KB) 요청: 1MB -\u003e 512KB + 512KB. 512KB -\u003e 256KB + 256KB. 256KB -\u003e 128KB + 128KB. A에 128KB 할당. 프로세스 B (200KB) 요청: 남은 128KB 옆의 256KB를 가져와 할당 (만약 256KB가 없다면 다른 512KB를 다시 분할). 프로세스 C (70KB) 요청: 남은 128KB에서 분할. 128KB -\u003e 64KB + 64KB. C에 64KB 할당 (내부 단편화 발생). 또는 70KB는 128KB 블록에 할당될 수 있습니다. 해제 및 합병 예시: 프로세스 A (128KB) 해제: A가 사용하던 128KB 블록의 버디(다른 128KB)가 가용 상태인지 확인. 가용 상태라면 합병하여 256KB 블록 생성. 이 256KB 블록의 버디(다른 256KB)도 가용 상태라면 다시 합병하여 512KB 생성. 이런 식으로 가능한 최대 크기로 합병을 시도합니다. 그림은 이러한 분할과 합병 과정을 단계별로 보여주며, 특정 크기의 블록들이 어떻게 생성되고 사라지는지를 나타냅니다.","example-p1-request-102#Example: P1 Request (1,0,2)":"","fifo-알고리즘의-교체-전략-도착-순서-기반#\u003cstrong\u003eFIFO 알고리즘의 교체 전략: 도착 순서 기반\u003c/strong\u003e":"FIFO 알고리즘의 핵심 전략은 매우 단순합니다. 페이지 폴트가 발생하여 희생 페이지를 선택해야 할 때, “현재 물리 메모리에 있는 페이지들 중에서 가장 먼저 메모리에 적재되었던 페이지, 즉 가장 오랫동안 메모리에 머물렀던 페이지를 선택하여 교체한다.”\n이는 마치 우리가 줄을 서서 서비스를 기다리는 것과 같습니다. 가장 먼저 줄을 선 사람(가장 먼저 메모리에 들어온 페이지)이 가장 먼저 서비스(교체 대상)를 받는 것입니다. 이 알고리즘은 페이지가 얼마나 자주 사용되었는지, 또는 얼마나 최근에 사용되었는지와 같은 페이지의 사용 패턴은 전혀 고려하지 않습니다. 오직 **메모리 도착 시간(arrival time)**만이 유일한 교체 기준이 됩니다.","fifo-알고리즘의-단점-및-한계#\u003cstrong\u003eFIFO 알고리즘의 단점 및 한계\u003c/strong\u003e":"단순함에도 불구하고, FIFO 알고리즘은 심각한 성능 문제를 야기할 수 있는 몇 가지 중요한 단점을 가지고 있습니다.\n페이지 사용 패턴 무시: FIFO는 페이지가 얼마나 중요하게, 또는 얼마나 자주 사용되는지를 전혀 고려하지 않습니다. 예를 들어, 프로그램의 핵심적인 기능을 수행하는 코드 페이지가 초기에 메모리에 적재되어 오랫동안 활발하게 사용되고 있었다고 가정해 봅시다. FIFO 알고리즘에서는 이 페이지가 단지 ‘오래되었다’는 이유만으로 교체될 수 있습니다. 만약 이 페이지가 교체된 직후 다시 필요해진다면, 즉시 또 다른 페이지 폴트가 발생하여 성능 저하를 초래합니다.\n최적 성능과의 괴리: 일반적으로 FIFO 알고리즘의 페이지 폴트율은 최적 알고리즘이나 LRU 알고리즘에 비해 높게 나타납니다. 이는 페이지의 과거 사용 이력이나 미래 사용 가능성을 고려하지 않는 단순한 교체 전략 때문입니다.\n벨레이디의 모순 (Belady’s Anomaly): FIFO 알고리즘에서 나타날 수 있는 매우 특이하고 비직관적인 현상입니다. 대부분의 페이지 교체 알고리즘에서는 사용 가능한 물리 메모리 프레임의 수를 늘리면 페이지 폴트 횟수가 감소하거나 최소한 동일하게 유지되는 것이 일반적입니다. 하지만 FIFO 알고리즘에서는 프레임 수를 늘렸음에도 불구하고 오히려 페이지 폴트 횟수가 증가하는 경우가 발생할 수 있습니다. 이는 상식에 반하는 현상으로, FIFO 알고리즘의 비효율성을 단적으로 보여주는 예시입니다. (이 현상은 이후 슬라이드의 예시를 통해 더 자세히 설명될 수 있습니다.)\n벨레이디의 모순 예시: 간단히 말해, 특정 참조 문자열에 대해 3개의 프레임으로 실행했을 때보다 4개의 프레임으로 실행했을 때 더 많은 페이지 폴트가 발생하는 상황입니다. 이는 프레임이 늘어남에 따라 페이지들이 메모리에 머무는 순서와 기간이 달라지고, 이로 인해 FIFO의 “가장 오래된 페이지\"라는 선택 기준이 오히려 불리한 교체를 유도하기 때문입니다.","fifo-알고리즘의-사용-사례#\u003cstrong\u003eFIFO 알고리즘의 사용 사례\u003c/strong\u003e":"이러한 단점들 때문에, 순수한 FIFO 알고리즘은 현대의 고성능 운영 체제에서 주된 페이지 교체 전략으로 널리 사용되지는 않습니다. 하지만 그 단순성 덕분에 특정 임베디드 시스템이나 매우 간단한 메모리 관리 기법이 요구되는 환경, 또는 다른 복잡한 알고리즘의 일부 구성 요소(예: 2차 기회 알고리즘의 기본 큐 관리)로 활용될 여지는 있습니다.\n결론적으로, FIFO 페이지 교체 알고리즘은 구현의 용이성과 낮은 오버헤드라는 명확한 장점을 가지고 있지만, 페이지의 실제 사용 패턴을 고려하지 않아 성능이 떨어질 수 있으며, 특히 벨레이디의 모순과 같은 예측하기 어려운 행동을 보일 수 있는 한계를 지니고 있습니다. 이는 페이지 교체 알고리즘을 선택할 때 단순성 외에 다른 요소들(예: 효율성, 예측 가능성)도 중요하게 고려해야 함을 시사합니다.","fifo-알고리즘의-장점#\u003cstrong\u003eFIFO 알고리즘의 장점\u003c/strong\u003e":"단순성 및 낮은 오버헤드: 앞서 언급했듯이, FIFO 알고리즘은 이해하기 쉽고 구현하기가 매우 간단합니다. 페이지 교체 결정을 내리는 데 필요한 계산이 거의 없으므로, 알고리즘 자체의 실행 시간(오버헤드)이 매우 작습니다. 이는 시스템 자원이 제한적인 환경이나 빠른 결정이 요구되는 상황에서 유리할 수 있습니다.","fifo-페이지-교체-알고리즘-실행-과정-3-프레임#\u003cstrong\u003eFIFO 페이지 교체 알고리즘 실행 과정 (3 프레임)\u003c/strong\u003e":"각 단계에서 참조되는 페이지, 현재 프레임 상태 (메모리 도착 순으로 표시), FIFO 큐의 상태, 페이지 폴트 발생 여부(H: Hit, F: Fault)를 살펴보겠습니다.\n참조 페이지 프레임 1 (가장 오래됨) 프레임 2 프레임 3 (가장 최신) FIFO 큐 (Head -\u003e Tail) 결과 (PF 수) 7 7 7 F (1) 0 7 0 7, 0 F (2) 1 7 0 1 7, 0, 1 F (3) 2 0 1 2 0, 1, 2 F (4) 0 0 1 2 0, 1, 2 H 3 1 2 3 1, 2, 3 F (5) 0 2 3 0 2, 3, 0 F (6) 4 3 0 4 3, 0, 4 F (7) 2 0 4 2 0, 4, 2 F (8) 3 4 2 3 4, 2, 3 F (9) 0 2 3 0 2, 3, 0 F (10) 3 2 3 0 2, 3, 0 H 2 2 3 0 2, 3, 0 H 1 3 0 1 3, 0, 1 F (11) 2 0 1 2 0, 1, 2 F (12) 0 0 1 2 0, 1, 2 H 1 0 1 2 0, 1, 2 H 7 1 2 7 1, 2, 7 F (13) 0 2 7 0 2, 7, 0 F (14) 1 7 0 1 7, 0, 1 F (15) 최종 페이지 폴트 수 (FIFO, 3 프레임): 15회","fixed-partitioning-고정-분할#Fixed Partitioning (고정 분할)":"","fragmentation-cont-단편화-계속#Fragmentation (Cont.) (단편화 (계속))":"Reduce external fragmentation by compaction (압축을 통해 외부 단편화를 줄임) Shuffle memory contents to place all free memory together in one large block (모든 가용 메모리를 하나의 큰 블록으로 모으기 위해 메모리 내용을 재배치함) Compaction is possible only if relocation is dynamic, and is done at execution time (압축은 재배치가 동적이고 실행 시간에 수행될 경우에만 가능함) I/O problem (입출력 문제) → Latch job in memory while it is involved in I/O (입출력에 관여하는 동안 작업을 메모리에 고정시킴) → Do I/O only into OS buffers (입출력을 OS 버퍼로만 수행함) Now consider that backing store has same fragmentation problems (이제 백킹 스토어도 동일한 단편화 문제를 가짐을 고려하십시오) [설명]\n외부 단편화 문제에 대한 해결책 중 하나인 압축(Compaction)과 그와 관련된 문제점, 그리고 백킹 스토어의 단편화 문제를 언급합니다.\n압축 (Compaction)을 통한 외부 단편화 감소: 방법: 메모리 압축은 운영체제가 현재 메모리에 흩어져 있는 모든 사용 중인 프로세스들을 한쪽으로 이동시켜 연속적으로 배치하고, 그 결과로 흩어져 있던 작은 가용 공간(홀)들을 하나의 큰 연속된 가용 공간으로 통합하는 작업입니다. 예: [P1] [hole1] [P2] [hole2] [P3] 상태를 [P1] [P2] [P3] [merged_hole] 상태로 만듭니다. 조건: 압축을 하려면 프로세스의 메모리 주소가 실행 중에 변경될 수 있어야 합니다. 이는 주소 바인딩이 **실행 시간(execution time)**에 동적으로 이루어질 때만 가능합니다. 즉, MMU와 같은 하드웨어 지원으로 논리 주소와 물리 주소가 분리되어 관리되어야 합니다. 컴파일 시간이나 적재 시간 바인딩에서는 압축이 불가능하거나 매우 어렵습니다. 압축의 입출력 문제 (I/O Problem): 프로세스가 메모리 내의 특정 버퍼를 사용하여 디스크 등과 입출력(I/O) 작업을 수행 중일 때, 그 프로세스를 이동시키면 문제가 발생합니다. 입출력 장치(예: DMA 컨트롤러)는 이전의 물리 주소로 계속 데이터를 전송하거나 읽으려고 할 것이기 때문입니다. 해결 방안: 입출력 중인 작업 메모리 고정 (Latch job in memory): 특정 프로세스가 입출력 작업을 완료할 때까지는 해당 프로세스를 메모리에서 이동시키지 않고 고정(pinning)합니다. 이 프로세스는 압축 대상에서 제외됩니다. OS 버퍼를 통한 입출력: 모든 입출력 연산은 사용자 프로세스 공간이 아닌, 운영체제가 관리하는 고정된 버퍼(OS buffers)를 통해서만 이루어지도록 합니다. 데이터는 먼저 OS 버퍼로 전송된 후, 사용자 프로세스 공간으로 복사되거나 그 반대로 이루어집니다. 이렇게 하면 사용자 프로세스가 이동하더라도 OS 버퍼의 주소는 변하지 않으므로 입출력에 문제가 없습니다. 다만, 데이터 복사로 인한 오버헤드가 추가됩니다. 백킹 스토어의 단편화 (Fragmentation on Backing Store): 스와핑이나 페이징에 사용되는 백킹 스토어(주로 디스크)도 메모리와 유사하게 단편화 문제를 겪을 수 있습니다. 프로세스나 페이지들이 디스크에 저장되었다가 삭제되는 과정이 반복되면, 디스크 상에도 사용 중인 공간과 빈 공간(hole)들이 흩어져 존재하게 됩니다. 이로 인해 큰 프로세스 이미지나 연속된 페이지들을 저장할 공간을 찾기 어려워지거나, 파일 시스템의 성능이 저하될 수 있습니다. 디스크 조각 모음(defragmentation)과 같은 유틸리티가 이러한 백킹 스토어의 단편화를 줄이는 데 사용될 수 있습니다. 압축은 외부 단편화를 해결하는 효과적인 방법일 수 있지만, 상당한 시스템 오버헤드(시간 소모, CPU 사용)를 유발하므로 자주 수행하기는 어렵습니다. 따라서 압축의 필요성을 줄이는 다른 메모리 관리 기법(페이징 등)이 더 선호됩니다.","fragmentation-in-paging-페이징에서의-단편화#Fragmentation in Paging (페이징에서의 단편화)":"Internal fragmentation (내부 단편화) Page size = 2,048 bytes (페이지 크기 = 2,048 바이트) Process size = 72,766 bytes (프로세스 크기 = 72,766 바이트) 35 pages + 1,086 bytes (35 페이지 + 1,086 바이트) Internal fragmentation = 2,048 - 1,086 = 962 bytes (내부 단편화 = 2,048 - 1,086 = 962 바이트) Frame size \u0026 fragmentation (프레임 크기와 단편화) Internal fragmentation = 1byte ~ (frame size – 1) (내부 단편화 = 1바이트 ~ (프레임 크기 – 1)) Average fragmentation = 1 / 2 frame size (평균 단편화 = 프레임 크기의 1/2) Small frame size better? (작은 프레임 크기가 더 좋은가?) Small frame size → Small internal fragmentation (작은 프레임 크기 → 작은 내부 단편화) → Large page table (→ 큰 페이지 테이블) Large frame size → Small page table (큰 프레임 크기 → 작은 페이지 테이블) → More internal fragmentation (→ 더 많은 내부 단편화) [한글 번역 및 상세 설명]\n페이징 시스템은 외부 단편화 문제를 해결하지만, 내부 단편화(Internal Fragmentation) 문제는 여전히 안고 있습니다.\n내부 단편화 발생 원리:\n프로세스는 다양한 크기를 가질 수 있지만, 페이징 시스템에서는 메모리가 고정된 크기의 페이지(프레임) 단위로 할당됩니다. 만약 프로세스의 전체 크기가 페이지 크기의 정확한 배수가 아니라면, 프로세스의 마지막 페이지는 해당 페이지를 다 채우지 못하고 일부 공간만 사용하게 됩니다. 이때, 마지막 페이지에서 사용되지 않고 남는 공간이 바로 내부 단편화입니다. 이 공간은 해당 프로세스에 할당은 되었지만, 실제로는 사용되지 않아 낭비되는 부분입니다. 예시:\n페이지(프레임) 크기 = 2,048 바이트 (2KB) 프로세스 크기 = 72,766 바이트 필요한 페이지 수 계산: 프로세스가 완전히 채울 수 있는 페이지 수 = 72,766÷2,048=35 (몫) 하고 1,086 바이트가 남습니다 (나머지). 즉, 이 프로세스는 35개의 페이지를 꽉 채우고, 추가로 1,086 바이트의 데이터를 더 저장해야 합니다. 이 남은 1,086 바이트를 저장하기 위해 어쩔 수 없이 한 개의 페이지(36번째 페이지)가 더 할당됩니다. 내부 단편화 계산: 36번째 페이지의 크기는 2,048 바이트이지만, 이 중 1,086 바이트만 사용됩니다. 따라서 사용되지 않고 낭비되는 공간 (내부 단편화) = 2,048 바이트−1,086 바이트=962 바이트. 이 프로세스 하나에서만 962바이트의 메모리가 내부 단편화로 인해 낭비되는 것입니다. 프레임(페이지) 크기와 단편화의 관계:\n내부 단편화의 범위: 어떤 프로세스에 대해 발생하는 내부 단편화의 크기는 최소 0바이트 (프로세스 크기가 페이지 크기의 정확한 배수일 경우)부터 최대 (프레임 크기 - 1) 바이트까지 가능합니다. (슬라이드의 1byte ~ (frame size – 1) 표현은, 프로세스가 최소 1바이트의 데이터를 마지막 페이지에 가져야 단편화가 frame_size - 1이 된다는 의미로, 0인 경우를 제외하고 본다면 타당합니다.) 평균 내부 단편화: 다양한 크기의 많은 프로세스들이 시스템에서 실행된다고 가정할 때, 평균적으로 각 프로세스당 약 **프레임(페이지) 크기의 절반 (1/2)**만큼의 내부 단편화가 발생한다고 알려져 있습니다. 이는 통계적인 추정치입니다. 적절한 프레임(페이지) 크기 결정의 딜레마 (Small frame size better?):\n작은 프레임(페이지) 크기를 사용할 경우: 👍 장점: 내부 단편화의 크기가 줄어듭니다. 프로세스 크기가 페이지 크기의 배수에서 조금 벗어나더라도 낭비되는 공간이 작아집니다. 👎 단점: 페이지 테이블의 크기가 매우 커집니다. 예를 들어, 같은 크기의 프로세스라도 페이지 크기가 절반이 되면 필요한 페이지 수는 두 배가 되고, 따라서 페이지 테이블의 항목 수도 두 배가 됩니다. 큰 페이지 테이블은 그 자체로 메모리를 많이 차지하고, 페이지 테이블 검색(특히 TLB miss 시)에 더 많은 시간이 소요될 수 있습니다. 또한 디스크 I/O 시 더 많은 페이지 전송이 필요할 수 있습니다. 큰 프레임(페이지) 크기를 사용할 경우: 👍 장점: 페이지 테이블의 크기가 작아집니다. 관리해야 할 페이지 수가 줄어들기 때문입니다. 이는 페이지 테이블로 인한 메모리 오버헤드와 검색 시간을 줄일 수 있습니다. 디스크 I/O 효율도 높아질 수 있습니다 (한 번에 많은 데이터를 전송). 👎 단점: 내부 단편화가 커질 가능성이 높습니다. 프로세스의 마지막 부분이 큰 프레임의 작은 일부만 사용할 경우 낭비되는 공간이 많아집니다. 결국, 페이지(프레임) 크기는 시스템 설계 시 내부 단편화, 페이지 테이블 크기, 디스크 I/O 효율성, TLB 성능 등 다양한 요소를 고려하여 신중하게 결정해야 하는 트레이드오프(trade-off) 관계에 있습니다. 현대 시스템은 이러한 단점을 보완하기 위해 여러 크기의 페이지(예: 4KB 표준 페이지 + 2MB/1GB Huge Page)를 함께 지원하기도 합니다.","fragmentation-단편화#Fragmentation (단편화)":"External Fragmentation – total free memory is enough for new process, but it is not contiguous (외부 단편화 – 새 프로세스를 수용하기에 총 가용 메모리는 충분하지만, 연속적이지 않음) Internal Fragmentation – allocated memory to a process but never used (내부 단편화 – 프로세스에 할당되었지만 사용되지 않는 메모리) Fixed partitioning has only internal frag. (고정 분할은 내부 단편화만 가짐) Dynamic partitioning has only external frag. (동적 분할은 외부 단편화만 가짐) First fit has 50-percent rule (최초 적합은 50% 규칙을 가짐) \u003c- 외부 단편화에서만 given N blocks allocated, 0.5 N blocks lost to external fragmentation (N개의 블록이 할당되었을 때, 0.5N 개의 블록이 외부 단편화로 손실됨) Memory utilization = 2/3 (메모리 사용률 = 2/3) 단편화의 두 종류를 다시 한번 명확히 정의하고, 각 분할 방식과의 관계, 그리고 외부 단편화에 대한 통계적 규칙을 설명합니다.\n외부 단편화 vs. 내부 단편화 비교: 외부 단편화: 가용 공간이 여러 조각으로 나뉘어, 합치면 충분하지만 개별적으로는 부족한 상태. (동적 분할에서 주로 발생) 내부 단편화: 할당된 파티션/블록 내부에 사용되지 않고 남는 공간. (고정 분할에서 주로 발생) 고정 분할과 내부 단편화: 미리 정해진 크기의 파티션에 프로세스를 할당하므로, 프로세스 크기가 파티션 크기보다 작으면 남는 공간이 내부 단편화가 됩니다. 외부 단편화는 개념적으로 발생하지 않습니다 (파티션 사이는 항상 다른 파티션이거나, 시스템이 사용 못하는 경계일 뿐 ‘가용 공간’으로 보지 않음). 동적 분할과 외부 단편화: 프로세스 요청 크기만큼 정확히 할당하므로 내부 단편화는 거의 없습니다. 그러나 프로세스들이 할당되고 해제되면서 그 사이에 작은 가용 공간(hole)들이 생겨 외부 단편화가 발생합니다. 최초 적합의 50% 규칙 (50-percent rule): Knuth에 의해 제안된 경험적 규칙으로, 최초 적합 알고리즘을 사용하여 오랜 시간 동안 메모리 할당과 해제가 반복되면, 평균적으로 할당된 블록 수(N)의 약 절반(0.5N)에 해당하는 수의 가용 블록(hole)이 단편화로 인해 발생한다는 것입니다. 이로 인해 메모리 사용률이 약 2/3 (약 66.7%) 정도가 될 수 있다는 분석 결과입니다. 즉, 메모리의 약 1/3은 외부 단편화로 인해 사용되지 못하고 낭비될 수 있다는 의미입니다. 이는 통계적인 결과이며 항상 정확히 들어맞는 것은 아닙니다.","fragmentation-단편화-1#Fragmentation (단편화)":"External Fragmentation – total memory space exists to satisfy a request, but it is not contiguous (외부 단편화 – 요청을 만족시키기에 충분한 총 메모리 공간이 존재하지만, 연속적이지 않음) Internal Fragmentation – allocated memory may be slightly larger than requested memory; this size difference is memory internal to a partition, but not being used (내부 단편화 – 할당된 메모리가 요청된 메모리보다 약간 클 수 있음; 이 크기 차이는 파티션 내부의 메모리이지만 사용되지 않음) First fit analysis reveals that given N blocks allocated, 0.5 N blocks lost to fragmentation (최초 적합 분석에 따르면, N개의 블록이 할당되었을 때 0.5N 개의 블록이 단편화로 손실됨) 1/3 may be unusable -\u003e 50-percent rule (1/3이 사용 불가능할 수 있음 → 50% 규칙) [설명]\n이 슬라이드는 슬라이드 8.16의 내용을 다시 한번 강조하며, 단편화의 종류와 그 영향을 설명합니다.\n외부 단편화 (External Fragmentation): 발생 원인: 동적 할당 방식에서 프로세스들이 메모리에 할당되고 해제되는 과정이 반복되면서, 사용 중인 메모리 블록들 사이에 작은 크기의 가용 공간(홀)들이 흩어져 생기는 현상입니다. 문제점: 이 작은 홀들의 크기를 모두 합하면 새로운 프로세스를 수용하기에 충분한 공간이 될 수 있지만, 각각의 홀은 너무 작아서 실제로 할당할 수 없는 상태입니다. 즉, 메모리가 ‘외부적으로’ 잘게 조각나 있는 것입니다. 내부 단편화 (Internal Fragmentation): 발생 원인: 고정 분할 방식이나, 할당 단위가 정해져 있는 경우 (예: 페이징, 버디 시스템) 발생합니다. 프로세스에 할당된 메모리 블록(파티션 또는 페이지)의 크기가 실제 프로세스가 필요로 하는 크기보다 약간 클 때, 그 차이만큼의 공간이 해당 블록 ‘내부에서’ 사용되지 않고 낭비되는 현상입니다. 예: 100KB 크기의 고정 파티션에 80KB 프로세스를 할당하면 20KB의 내부 단편화 발생. 4KB 페이지에 1KB의 데이터만 저장하면 3KB의 내부 단편화 발생. 최초 적합(First-fit)과 50% 규칙 (50-percent Rule): 이론적, 실험적 분석에 따르면, 최초 적합 할당 전략을 오랜 시간 사용했을 때, 평균적으로 할당된 블록 N개당 약 0.5N개의 추가적인 가용 블록(단편화된 홀)이 발생한다는 경험적 규칙입니다. 이는 곧 전체 메모리 중 약 1/3 정도가 외부 단편화로 인해 사용 불가능한 상태가 될 수 있음을 의미합니다 (메모리 사용률이 약 2/3). 이는 매우 일반화된 규칙이며, 실제 상황에서는 작업 부하(workload)의 특성에 따라 달라질 수 있습니다. 단편화는 메모리 관리 시스템의 효율성을 저해하는 주요 요인이므로, 이를 줄이거나 해결하기 위한 다양한 기법(압축, 페이징, 세그먼테이션 등)이 연구되고 사용됩니다.","free-frames-가용-프레임#Free Frames (가용 프레임)":"Before allocation (할당 전) After allocation (할당 후) (Diagram showing a list of free frames, and then a process’s pages (page 0, 1, 2, 3) being allocated to some of these frames, and the page table being updated. The free frame list also gets updated.)\n[한글 번역 및 상세 설명]\n이 슬라이드의 다이어그램은 페이징 시스템에서 프로세스에 메모리가 할당되기 전과 후의 가용 프레임(free frame) 상태 변화를 시각적으로 보여줍니다.\n가용 프레임 (Free Frames): 물리 메모리는 일정한 크기의 프레임들로 나누어지며, 이 중 어떤 프로세스에게도 아직 할당되지 않은, 즉 비어있는 프레임들을 ‘가용 프레임’이라고 합니다. 운영체제는 이러한 가용 프레임들의 목록을 관리합니다 (이를 **가용 프레임 리스트(free-frame list)**라고 부릅니다).\nBefore allocation (할당 전):\n다이어그램의 왼쪽 부분은 새로운 프로세스(예: new_process)가 메모리를 할당받기 전의 상태를 나타냅니다. 물리 메모리에는 여러 개의 프레임들이 있으며, 이 중 일부는 이미 다른 프로세스나 운영체제에 의해 사용 중일 수 있고, 나머지 프레임들은 가용 상태입니다. 가용 프레임 리스트에는 현재 사용 가능한 프레임들의 번호가 들어있습니다. (예: 14, 13, 18, 20, 15번 프레임 등이 가용 상태) After allocation (할당 후):\n다이어그램의 오른쪽 부분은 new_process에게 메모리가 할당된 후의 상태를 보여줍니다. new_process는 여러 개의 페이지(예: page 0, page 1, page 2, page 3)로 구성되어 있습니다. 운영체제는 가용 프레임 리스트에서 new_process의 페이지 수만큼 프레임을 가져와 각 페이지에 할당합니다. 예를 들어: page 0은 가용 프레임 중 하나(예: 14번 프레임)에 할당됩니다. page 1은 그 다음 가용 프레임(예: 13번 프레임)에 할당됩니다. 이런 식으로 page 2는 18번, page 3은 20번 프레임에 할당될 수 있습니다. 페이지 테이블 업데이트: new_process의 페이지 테이블에는 이러한 매핑 정보가 기록됩니다. 즉, page_table[0] = 14, page_table[1] = 13, page_table[2] = 18, page_table[3] = 20 과 같이 설정됩니다. 가용 프레임 리스트 업데이트: 할당된 프레임들(14, 13, 18, 20)은 더 이상 가용 상태가 아니므로 가용 프레임 리스트에서 제거됩니다. 따라서 가용 프레임 리스트는 (예: 15번 프레임부터 시작하는 리스트)로 업데이트됩니다. 이 과정은 페이징 시스템이 어떻게 외부 단편화 없이 필요한 만큼의 프레임을 (비록 물리적으로 흩어져 있을지라도) 프로세스에게 할당하는지를 보여줍니다. 운영체제는 항상 가용 프레임 목록을 정확하게 유지하여 효율적인 메모리 할당 및 회수를 보장해야 합니다.","hardware-support-for-relocation-and-limit-registers-재배치-및-한계-레지스터를-위한-하드웨어-지원#Hardware Support for Relocation and Limit Registers (재배치 및 한계 레지스터를 위한 하드웨어 지원)":"(Diagram very similar to 8.22: CPU -\u003e logical address -\u003e [check: logical address \u003c limit register?] -\u003e yes -\u003e [physical address = logical address + relocation register] -\u003e memory; no -\u003e trap to OS)\n[설명]\n이 그림은 재배치(Relocation) 레지스터와 한계(Limit) 레지스터를 사용한 하드웨어 기반 주소 변환 및 보호 메커니즘을 다시 한번 보여줍니다. 슬라이드 8.22의 그림과 거의 동일한 개념입니다.\nCPU가 논리 주소(Logical Address) 생성: 프로세스 내에서 사용되는 주소로, 보통 0부터 시작합니다. 한계 검사 (Limit Check): 생성된 논리 주소가 한계 레지스터(Limit Register)에 저장된 값보다 작은지 비교합니다 (Logical Address \u003c Limit Register Value). 한계 레지스터는 해당 프로세스의 크기를 나타내므로, 이 검사는 논리 주소가 프로세스에게 할당된 주소 범위를 벗어나는지 확인하는 것입니다. 만약 논리 주소가 한계 레지스터 값보다 크거나 같다면 (No 경로), 이는 유효하지 않은 접근이므로 트랩(trap)이 발생하여 운영체제에게 제어권이 넘어갑니다. (예: “segmentation fault” 또는 “access violation” 오류) 물리 주소 계산 (Physical Address Calculation): 논리 주소가 유효 범위 내에 있다면 (Yes 경로), 이 논리 주소에 재배치 레지스터(Relocation Register, 또는 Base Register)의 값을 더하여 물리 주소(Physical Address)를 계산합니다. Physical Address = Logical Address + Relocation Register Value 재배치 레지스터에는 해당 프로세스가 물리 메모리에 적재된 시작 주소가 들어있습니다. 메모리 접근: 계산된 물리 주소를 사용하여 실제 메모리에 접근합니다. 이러한 하드웨어 메커니즘은 모든 메모리 접근 시 자동으로 수행되며, 각 프로세스가 자신만의 격리된 메모리 공간을 안전하게 사용하도록 보장하고, 프로그램의 재배치를 용이하게 합니다. 이는 실행 시간 주소 바인딩의 핵심 요소입니다.","implementation-of-page-table-페이지-테이블-구현#Implementation of Page Table (페이지 테이블 구현)":"Page table is kept in main memory (페이지 테이블은 주 메모리에 유지됨) Page-table base register (PTBR) points to the page table (페이지 테이블 기준 레지스터(PTBR)는 페이지 테이블을 가리킴) Page-table length register (PTLR) indicates size of the page table (페이지 테이블 길이 레지스터(PTLR)는 페이지 테이블의 크기를 나타냄) In this scheme every data/instruction access requires two memory accesses (이 방식에서는 모든 데이터/명령어 접근이 두 번의 메모리 접근을 필요로 함) One for the page table and one for the data / instruction (하나는 페이지 테이블을 위해, 다른 하나는 데이터/명령어를 위해) The two memory access problem can be solved by the use of a special fast-lookup hardware cache called associative memory or translation look-aside buffers (TLBs) (두 번의 메모리 접근 문제는 연관 메모리 또는 TLB(Translation Look-aside Buffer)라고 불리는 특별한 고속 검색 하드웨어 캐시를 사용하여 해결될 수 있음) Some TLBs store address-space identifiers (ASIDs) in each TLB entry – uniquely identifies each process to provide address-space protection for that process (일부 TLB는 각 TLB 항목에 주소 공간 식별자(ASID)를 저장함 – 각 프로세스를 고유하게 식별하여 해당 프로세스에 대한 주소 공간 보호를 제공함) Otherwise need to flush at every context switch (그렇지 않으면 모든 문맥 교환 시에 플러시(비우기)해야 함) TLBs typically small (64 to 1,024 entries) (TLB는 일반적으로 작음 (64개에서 1,024개 항목)) [한글 번역 및 상세 설명]\n페이지 테이블을 실제로 시스템에서 어떻게 구현하고 관리하는지에 대한 중요한 사항들을 설명합니다. 📜\n페이지 테이블의 주 메모리 저장:\n각 프로세스는 자신만의 페이지 테이블을 가집니다. 이 페이지 테이블은 프로세스의 논리 주소 공간이 클수록 커질 수 있습니다 (예: 32비트 주소 공간, 4KB 페이지 크기 → 220개의 항목, 각 항목 4바이트 시 4MB). 이렇게 큰 자료구조를 CPU 내의 한정된 레지스터에 모두 저장하는 것은 불가능하므로, 페이지 테이블은 **주 메모리(main memory, RAM)**에 저장됩니다. 페이지 테이블 접근을 위한 레지스터:\nPTBR (Page-Table Base Register, 페이지 테이블 기준 레지스터): CPU 내의 특별한 레지스터로, 현재 실행 중인 프로세스의 페이지 테이블이 주 메모리에서 시작하는 물리 주소를 가지고 있습니다. CPU가 논리 주소를 물리 주소로 변환해야 할 때, 이 PTBR을 참조하여 메모리에서 해당 프로세스의 페이지 테이블을 찾습니다. PTLR (Page-Table Length Register, 페이지 테이블 길이 레지스터): 이 레지스터는 페이지 테이블의 크기(즉, 페이지 테이블이 가진 항목의 수 또는 유효한 페이지 번호의 최대치)를 저장합니다. 이는 프로세스가 자신의 논리 주소 공간 범위를 벗어나는 페이지 번호(예: 페이지 테이블의 크기를 넘어서는 인덱스)로 메모리에 접근하려는 시도를 막아 메모리 보호 기능을 수행합니다. CPU가 생성한 페이지 번호 p가 PTLR 값보다 크거나 같으면 주소 오류 트랩이 발생합니다. 두 번의 메모리 접근 문제 (Two Memory Access Problem): 💔\n페이지 테이블이 주 메모리에 있기 때문에, CPU가 하나의 데이터나 명령어를 메모리에서 가져오려고 할 때마다 최소 두 번의 메모리 접근이 필요하게 됩니다. 첫 번째 접근: 페이지 테이블 자체에 접근하여, 논리 페이지 번호에 해당하는 페이지 테이블 항목(PTE)을 읽어와 물리 프레임 번호를 알아냅니다. 두 번째 접근: 이렇게 얻은 물리 프레임 번호와 오프셋을 결합한 최종 물리 주소를 사용하여, 실제 원하는 데이터나 명령어를 메모리에서 읽어옵니다. 메모리 접근은 CPU 내부 연산에 비해 매우 느린 작업이므로, 매번 두 번씩 접근하는 것은 시스템 성능에 심각한 저하를 초래합니다. TLB (Translation Look-aside Buffer)를 이용한 해결책: 🚀\n이 두 번의 메모리 접근 문제를 해결(완화)하기 위해 대부분의 현대 CPU는 TLB라는 특별한 하드웨어 캐시를 사용합니다. TLB는 **연관 메모리(associative memory)**로 구현되며, 최근에 사용된 (페이지 번호, 프레임 번호) 매핑 정보를 매우 빠르게 검색할 수 있도록 설계된 작은 고속 캐시입니다. CPU가 논리 주소를 생성하면, 먼저 TLB에서 해당 페이지 번호에 대한 매핑 정보가 있는지 병렬적으로(associatively) 검색합니다 (TLB 조회). TLB 히트(Hit): 만약 TLB에 해당 정보가 있으면(캐시 히트), 프레임 번호를 즉시 얻어 물리 주소를 형성하고 메모리에 접근합니다. 이 경우, 페이지 테이블을 위한 주 메모리 접근이 생략되므로 한 번의 메모리 접근만 필요하게 됩니다(실제 데이터/명령어 접근). TLB 미스(Miss): 만약 TLB에 정보가 없으면(캐시 미스), 어쩔 수 없이 PTBR을 사용하여 주 메모리의 페이지 테이블에 접근하여 프레임 번호를 가져옵니다 (두 번의 메모리 접근 발생). 그리고 이렇게 얻은 (페이지 번호, 프레임 번호) 매핑 정보는 다음 사용을 위해 TLB에 새로 저장됩니다 (이때 TLB가 꽉 차 있다면 기존 항목 중 하나를 교체해야 함 - LRU 등의 교체 정책 사용). ASID (Address-Space Identifiers, 주소 공간 식별자):\nTLB는 여러 프로세스가 공유하는 하드웨어 자원입니다. 문맥 교환이 일어나 다른 프로세스가 실행되면, 이전 프로세스의 TLB 항목들이 새 프로세스에게는 유효하지 않을 수 있습니다 (같은 논리 페이지 번호라도 다른 물리 프레임을 가리킬 수 있기 때문). 이 문제를 해결하기 위해 일부 TLB는 각 항목에 ASID를 저장합니다. ASID는 각 프로세스를 고유하게 식별하는 번호입니다. TLB 조회 시 페이지 번호뿐만 아니라 현재 실행 중인 프로세스의 ASID도 함께 사용하여, 정확히 해당 프로세스의 매핑 정보만 찾도록 합니다. ASID를 사용하면, 문맥 교환 시 TLB 전체를 비울(flush) 필요가 없어집니다. 각 항목이 어떤 프로세스에 속하는지 구분할 수 있기 때문입니다. ASID가 없다면, 문맥 교환마다 TLB를 플러시해야 하므로 TLB 효율이 떨어집니다 (새 프로세스는 처음부터 TLB 미스를 많이 겪게 됨). TLB 크기:\nTLB는 고속의 연관 메모리로 만들어지기 때문에 가격이 비싸고 전력 소모도 있습니다. 따라서 그 크기는 제한적입니다. 일반적으로 64개에서 1,024개 정도의 항목을 가집니다. (현대 CPU는 더 많은 항목을 가질 수도 있고, 계층적 TLB 구조를 사용하기도 합니다.) 크기는 작지만, 프로그램 실행의 지역성(locality of reference - 한 번 참조된 메모리 영역은 곧 다시 참조될 가능성이 높고, 그 주변 영역도 참조될 가능성이 높다는 성질) 때문에 TLB 히트율(hit ratio)은 매우 높게(예: 98% 이상) 유지될 수 있어 성능 향상에 크게 기여합니다.","ipc#IPC":"","ipc-share#IPC SHARE":"","korea#korea":"교착 상태 회피 현재의 자원 할당 요청을 승인할 경우 잠재적으로 교착 상태로 이어질 수 있는지를 동적으로 결정함 프로세스의 미래 요청에 대한 정보가 필요함","korea-1#korea":"교착 상태 회피의 두 가지 접근법 프로세스 개시 거부 (Process Initiation Denial) 프로세스의 요구가 교착 상태로 이어질 수 있다면 해당 프로세스를 시작하지 않음 자원 할당 거부 (Resource Allocation Denial) 증분적 자원 요청에 대한 할당이 교착 상태로 이어질 수 있다면 해당 요청을 승인하지 않음","korea-10#korea":"자원-할당 그래프에서의 불안전 상태","korea-11#korea":"프로세스 Pi​가 자원 Rj​를 요청한다고 가정합니다. 요청은 **요청 간선(request edge)**을 **할당 간선(assignment edge)**으로 변환했을 때, 자원 할당 그래프에서 **사이클(cycle)**이 형성되지 않는 경우에만 승인될 수 있습니다.","korea-12#korea":"잠재적 교착 상태\n나는 A와 B 사분면이 필요하다\n나는 B와 C 사분면이 필요하다\n나는 C와 B 사분면이 필요하다\n나는 D와 A 사분면이 필요하다","korea-13#korea":"자원 할당 다이어그램","korea-14#korea":"자원 할당 다이어그램","korea-15#korea":"실제 교착 상태\nB가 해제될 때까지 멈춤\nC가 해제될 때까지 멈춤\nD가 해제될 때까지 멈춤\nA가 해제될 때까지 멈춤","korea-16#korea":"다시, 교차로의 자동차들","korea-17#korea":"다중 인스턴스 (Multiple instances): 이 알고리즘은 자원 유형당 여러 인스턴스가 존재하는 환경에서 작동합니다. 사전 최대 클레임 (a priori claim maximum use): 각 프로세스는 실행 전에 자신이 필요로 할 수 있는 최대 자원 요구량을 미리 선언해야 합니다. 자원 요청 시 대기 가능성: 프로세스가 자원을 요청할 때, 자원이 당장 사용 가능하더라도 대기해야 할 수 있습니다. 유한 시간 내 자원 반환: 프로세스가 모든 자원을 할당받아 작업을 완료하면, 유한한 시간 내에 할당받은 모든 자원을 반환해야 합니다.","korea-18#korea":"Available (가용 자원 벡터): 길이 m의 벡터. Available[j] = k는 자원 유형 Rj​의 인스턴스가 k개 현재 사용 가능하다는 것을 의미합니다. Max (최대 요구량 행렬): n×m 크기의 행렬. Max[i,j] = k는 프로세스 Pi​가 자원 유형 Rj​의 인스턴스를 최대 k개까지 요청할 수 있음을 의미합니다. Allocation (할당량 행렬): n×m 크기의 행렬. Allocation[i,j] = k는 프로세스 Pi​가 현재 자원 유형 Rj​의 인스턴스를 k개 할당받았음을 의미합니다. Need (남은 필요량 행렬): n×m 크기의 행렬. Need[i,j] = k는 프로세스 Pi​가 작업을 완료하기 위해 자원 유형 Rj​의 인스턴스가 k개 더 필요함을 의미합니다. Need[i,j] = Max[i,j] – Allocation[i,j]로 계산됩니다.","korea-19#korea":"길이 m의 Work 벡터와 길이 n의 Finish 벡터를 선언합니다. Work를 현재 가용한 자원 상태인 Available로 초기화합니다. 모든 프로세스 i (0,1,…,n−1)에 대해 Finish[i]를 false로 초기화합니다. 다음 두 가지 조건을 모두 만족하는 프로세스 i를 찾습니다: (a) Finish[i]가 false (즉, 아직 완료되지 않은 프로세스) (b) Need$_i \\le$ Work (즉, 프로세스 Pi​가 추가로 필요로 하는 자원량이 현재 가용한 Work 벡터의 자원량보다 작거나 같음) 이러한 i가 존재하지 않으면 4단계로 이동합니다. 프로세스 Pi​가 완료되었다고 가정하고, Pi​가 할당받았던 자원(Allocation$_i$)을 Work에 반환합니다. Work = Work + Allocation$_i$ Finish[i] = true 2단계로 돌아갑니다. 모든 프로세스 i에 대해 Finish[i]가 true이면 (즉, 모든 프로세스를 완료시킬 수 있는 안전 순서열을 찾았다면), 시스템은 **안전 상태(safe state)**에 있습니다.","korea-2#korea":"프로세스 개시 거부 현재 실행 중인 모든 프로세스들의 최대 요구량에 새로운 프로세스의 최대 요구량을 더한 값이 충족될 수 있을 경우에만 프로세스를 시작함. 최적이 아님: 최악의 경우를 가정함: 모든 프로세스가 동시에 최대 요구량을 요청할 것이라고 가정.","korea-20#korea":"Request는 프로세스 Pi​의 요청 벡터입니다. 만약 Request$_i$[j] = k라면, 프로세스 Pi​가 자원 유형 Rj​의 인스턴스를 k개 요청한다는 것을 의미합니다.\n만약 Request$_i \\le$ Need$_i$이면 2단계로 이동합니다. 그렇지 않으면, 프로세스가 자신의 최대 클레임을 초과했으므로 오류 조건을 발생시킵니다. 만약 Request$_i \\le$ Available이면 3단계로 이동합니다. 그렇지 않으면, 자원이 가용하지 않으므로 Pi​는 대기해야 합니다. 요청된 자원을 Pi​에 할당하는 것을 가정하고 상태를 다음과 같이 수정합니다: Available = Available – Request$_i$; Allocation$_i$ = Allocation$_i$ + Request$_i$; Need$_i$ = Need$_i$ – Request$_i$; 만약 안전성 알고리즘(Safety Algorithm)을 실행한 결과 시스템이 safe 상태이면: 자원이 Pi​에 실제로 할당됩니다. 만약 안전성 알고리즘을 실행한 결과 시스템이 unsafe 상태이면: Pi​는 대기해야 하며, 이전 자원 할당 상태가 복원됩니다.","korea-21#korea":"5개의 프로세스: P0​부터 P4​까지. 3가지 자원 유형: A: 10개 인스턴스 B: 5개 인스턴스 C: 7개 인스턴스 시간 T0​에서의 스냅샷: Allocation Max Available A B C A B C A B C P0 0 1 0 7 5 3 3 3 2 P1 2 0 0 3 2 2 P2 3 0 2 9 0 2 P3 2 1 1 2 2 2 P4 0 0 2 4 3 3","korea-22#korea":"Need (남은 필요량) 행렬의 내용은 Max – Allocation으로 정의됩니다. Need A B C P0 7 4 3 P1 1 2 2 P2 6 0 0 P3 0 1 1 P4 4 3 1 시스템은 \u003c P1, P3, P4, P2, P0 \u003e 순서열이 안전성 조건을 만족하므로 **안전 상태(safe state)**에 있습니다.","korea-23#korea":"요청 검사: 요청량(Request = (1,0,2))이 현재 가용 자원(Available = (3,3,2))보다 작거나 같은지 확인합니다. ((1,0,2) \\le (3,3,2) ⟹ 참) 임시 할당 후 상태: Allocation Need Available A B C A B C A B C P0 0 1 0 7 4 3 2 3 0 P1 3 0 2 0 2 0 P2 3 0 2 6 0 0 P3 2 1 1 0 1 1 P4 0 0 2 4 3 1 안전성 알고리즘 실행: 안전성 알고리즘을 실행한 결과, 순서열 \u003c P1, P3, P4, P0, P2 \u003e가 안전성 조건을 만족합니다. 추가 질문: P4​의 요청 (3,3,0)은 승인될 수 있는가? P0​의 요청 (0,2,0)은 승인될 수 있는가?","korea-3#korea":"자원 할당 거부 은행가 알고리즘(Banker’s algorithm)으로 불림 자원 할당 거부 전략의 일종 고정된 수의 자원을 가진 시스템을 고려 시스템의 상태는 현재 프로세스에 대한 자원 할당 상태임 안전 상태(Safe state)는 교착 상태를 초래하지 않는 순서가 하나 이상 존재하는 상태임 불안전 상태(Unsafe state)는 안전하지 않은 상태임","korea-4#korea":"안전 상태 프로세스가 가용 자원을 요청할 때, 시스템은 즉각적인 할당이 시스템을 안전 상태로 남겨두는지 결정해야 함 시스템 내 모든 프로세스에 대한 순서(sequence) 이 존재하여, 각 Pi에 대해 Pi가 여전히 요청할 수 있는 자원들이 현재 가용한 자원과 모든 Pj (j \u003c i)에 의해 보유된 자원들의 합으로 충족될 수 있다면 시스템은 안전 상태임 즉: Pi의 자원 요구가 즉시 가능하지 않다면, Pi는 모든 Pj가 완료될 때까지 기다릴 수 있음 Pj가 완료되면, Pi는 필요한 자원을 얻고, 실행하고, 할당된 자원을 반납하고, 종료할 수 있음 Pi가 종료되면, Pi+1이 필요한 자원을 얻을 수 있고, 이런 식으로 계속됨","korea-5#korea":"기본 사실들 시스템이 안전 상태(safe state)에 있다면 Þ 교착 상태 없음 시스템이 불안전 상태(unsafe state)에 있다면 Þ 교착 상태의 가능성 있음 회피(Avoidance) Þ 시스템이 절대로 불안전 상태로 진입하지 않도록 보장함.","korea-6#korea":"안전, 불안전, 교착 상태 (이 슬라이드는 일반적으로 세 가지 상태 간의 관계를 보여주는 다이어그램이나 그림을 포함하지만, 텍스트만 제공되었습니다. 설명을 위해 일반적인 개념도를 가정하여 설명합니다.)","korea-7#korea":"회피 알고리즘 자원 유형당 단일 인스턴스인 경우 자원 할당 그래프를 사용함 자원 유형당 다중 인스턴스인 경우 은행가 알고리즘을 사용함 자원 유형 당 2개의 인스턴스가 있을 때 은행가 알고리즘을 사용한다 (원문 반복) 자원 유형 당 2개의 인스턴스가 있을 때 은행가 알고리즘을 사용한다 (원문 반복)","korea-8#korea":"클레임 간선 (Claim edge) Pi​→Rj: 프로세스 Pi​가 자원 Rj​를 요청할 수 있음을 나타내며, 점선으로 표현됩니다. 클레임 간선의 변환: 프로세스가 자원을 요청하면 클레임 간선은 **요청 간선 (request edge)**으로 변환됩니다. 요청 간선의 변환: 자원이 프로세스에 할당되면 요청 간선은 **할당 간선 (assignment edge)**으로 변환됩니다. 할당 간선의 재변환: 프로세스가 자원을 해제하면 할당 간선은 다시 클레임 간선으로 변환됩니다. 자원의 사전 클레임: 시스템에서 자원은 사전에 클레임되어야 합니다.","korea-9#korea":"자원-할당 그래프","korean-translation#\u003cstrong\u003eKorean Translation\u003c/strong\u003e":"배경\n가상 메모리 – 사용자 논리 메모리와 물리 메모리의 분리 실행을 위해 프로그램의 일부만 메모리에 있으면 됨 따라서 논리 주소 공간이 물리 주소 공간보다 훨씬 클 수 있음 가상 메모리는 다음을 통해 구현될 수 있음: 요구 페이징 요구 세그먼테이션","korean-translation-1#\u003cstrong\u003eKorean Translation\u003c/strong\u003e":"물리 메모리보다 큰 가상 메모리\n(거대한 논리 메모리 공간이 더 작은 물리 메모리에 매핑되고, 나머지는 디스크에 저장되는 것을 보여주는 다이어그램)","korean-translation-10#\u003cstrong\u003eKorean Translation\u003c/strong\u003e":"페이지 교체 알고리즘\n페이지 교체 알고리즘 첫 접근과 재접근 모두에서 가장 낮은 페이지 폴트율을 원함 최적 (Optimal) 선입선출 (FIFO) 최근 최소 사용 (LRU)","korean-translation-11#\u003cstrong\u003eKorean Translation\u003c/strong\u003e":"최적 알고리즘\n가장 오랜 기간 동안 사용되지 않을 페이지를 교체 이것을 어떻게 알 수 있는가? 미래를 읽을 수 없음 여러분의 알고리즘이 얼마나 잘 수행되는지 측정하는 데 사용됨","korean-translation-12#\u003cstrong\u003eKorean Translation\u003c/strong\u003e":"최적 페이지 교체\n(이 슬라이드들은 일반적으로 최적 알고리즘이 동작하는 예시나 다이어그램을 포함합니다. 제시된 프롬프트에는 제목 외에 특정 다이어그램 내용이 없으므로, 일반적인 참조 문자열 예시를 가정하고 알고리즘 실행 과정을 설명하겠습니다.)","korean-translation-13#\u003cstrong\u003eKorean Translation\u003c/strong\u003e":"FIFO 알고리즘\n가장 오래된 페이지를 교체 이것을 어떻게 알 수 있는가? FIFO 큐","korean-translation-14#\u003cstrong\u003eKorean Translation\u003c/strong\u003e":"FIFO 페이지 교체\n(이 슬라이드들은 일반적으로 FIFO 알고리즘이 동작하는 예시나 다이어그램을 포함합니다. 최적 알고리즘 슬라이드와 마찬가지로, 성능 비교를 위해 동일한 참조 문자열을 가정하여 설명하겠습니다.)","korean-translation-2#\u003cstrong\u003eKorean Translation\u003c/strong\u003e":"요구 페이징\n필요할 때만 페이지를 메모리로 가져옴 더 적은 I/O 필요, 불필요한 I/O 없음 더 적은 메모리 필요 더 빠른 응답 시간 =\u003e ‘순수 페이징(Pure Paging)’ 또는 ‘선행 페이징(Anticipatory Paging)’ 보다는 빠름 더 많은 사용자 수용 가능","korean-translation-3#\u003cstrong\u003eKorean Translation\u003c/strong\u003e":"유효-무효 비트\n각 페이지 테이블 항목에는 유효-무효 비트가 연관되어 있음 (v =\u003e 메모리 내에 있음 – 메모리 상주, i =\u003e 메모리 내에 없음) 페이지 테이블 스냅샷 예시: (프레임 번호와 유효-무효 비트를 포함하는 페이지 테이블 항목 다이어그램) 주소 변환 중에 페이지 테이블 항목의 유효-무효 비트가 i이면 =\u003e 페이지 폴트 발생","korean-translation-4#\u003cstrong\u003eKorean Translation\u003c/strong\u003e":"일부 페이지가 주 메모리에 없을 때의 페이지 테이블\n(논리 메모리, 페이지 테이블, 물리 메모리를 보여주는 다이어그램. 일부 페이지 테이블 항목은 물리 메모리의 프레임을 가리키고, 다른 항목들은 무효(invalid)로 표시되어 디스크로부터 아직 로드되지 않은 페이지에 해당함을 보여줌.)","korean-translation-5#\u003cstrong\u003eKorean Translation\u003c/strong\u003e":"페이지 폴트\n페이지에 대한 참조가 있을 경우, 해당 페이지에 대한 첫 번째 참조는 운영 체제에 트랩을 발생시킴: 페이지 폴트\n운영 체제는 다른 테이블을 참조하여 결정: 유효하지 않은 참조 =\u003e 중단 단지 메모리에 없을 뿐 빈 프레임을 얻음 스케줄된 디스크 작업을 통해 페이지를 프레임으로 스왑 인 페이지가 이제 메모리에 있음을 나타내도록 테이블을 재설정. 유효 비트를 v로 설정 페이지 폴트를 유발한 명령을 다시 시작","korean-translation-6#\u003cstrong\u003eKorean Translation\u003c/strong\u003e":"페이지 폴트 처리 단계\n(최초 메모리 참조부터 명령어 재시작까지, 페이지 폴트를 처리하는 6가지 단계를 보여주는 상세한 다이어그램)","korean-translation-7#\u003cstrong\u003eKorean Translation\u003c/strong\u003e":"만약 빈 프레임이 없다면 어떻게 되는가?\n페이지 교체 메모리에 있지만 실제로는 사용되지 않는 페이지를 찾아 페이지 아웃시킴 성능 – 최소한의 페이지 폴트를 유발하는 알고리즘을 원함","korean-translation-8#\u003cstrong\u003eKorean Translation\u003c/strong\u003e":"페이지 교체의 필요성\n(페이지 교체 과정을 보여주는 다이어그램: 희생 페이지가 디스크로 페이지 아웃되고, 원하는 새로운 페이지가 비워진 프레임으로 페이지 인됨.)","korean-translation-9#\u003cstrong\u003eKorean Translation\u003c/strong\u003e":"페이지 교체","logical-vs-physical-address-space-논리적-주소-공간-대-물리적-주소-공간#Logical vs. Physical Address Space (논리적 주소 공간 대 물리적 주소 공간)":"The concept of a logical address space that is bound to a separate physical address space is central to proper memory management (별도의 물리적 주소 공간에 바인딩되는 논리적 주소 공간의 개념은 적절한 메모리 관리의 핵심입니다) Logical address – generated by the CPU; also referred to as virtual address (논리 주소 – CPU에 의해 생성됨; 가상 주소라고도 함) Physical address – address seen by the memory unit (물리 주소 – 메모리 장치에 의해 보여지는 주소) Logical and physical addresses are the same in compile-time and load-time address-binding schemes; logical (virtual) and physical addresses differ in execution-time address-binding scheme (논리 주소와 물리 주소는 컴파일 시간 및 적재 시간 주소 바인딩 방식에서는 동일함; 논리(가상) 주소와 물리 주소는 실행 시간 주소 바인딩 방식에서 다름) Logical address space is the set of all logical addresses generated by a program (논리 주소 공간은 프로그램에 의해 생성된 모든 논리 주소의 집합입니다) Physical address space is the set of all physical addresses generated by a program (물리 주소 공간은 프로그램에 의해 생성된 모든 물리 주소의 집합입니다) [설명]\n논리 주소와 물리 주소의 개념은 현대 메모리 관리의 근간을 이룹니다.\n핵심 개념: 프로세스는 자신만의 독립적인 논리 주소 공간을 가지고, 이 논리 주소 공간이 실제 물리 메모리의 특정 위치(물리 주소 공간)에 매핑(바인딩)됩니다. 논리 주소 (Logical Address): CPU가 생성하는 주소입니다. 프로세스 입장에서 바라보는 주소이며, 보통 0번지부터 시작하는 연속적인 공간으로 인식됩니다. **가상 주소 (Virtual Address)**와 거의 동의어로 사용됩니다. (엄밀히는 페이징이나 세그먼테이션 같은 가상 메모리 기법에서 사용되는 논리 주소를 가상 주소라고 부르는 경향이 있습니다.) 물리 주소 (Physical Address): 실제 메모리 하드웨어(RAM) 상의 주소입니다. 메모리 관리 장치(MMU)를 거쳐 최종적으로 메모리 버스에 실리는 주소입니다. 주소 바인딩 시점에 따른 관계: 컴파일 시간 및 적재 시간 바인딩: 프로그램이 생성하는 주소가 곧 물리 주소입니다. 즉, 논리 주소 = 물리 주소. 이 경우, 프로그램은 자신이 메모리의 어느 위치에 있는지 알아야 하거나, 한번 정해진 위치에서 이동할 수 없습니다. 실행 시간 바인딩: CPU가 생성하는 논리 주소와 메모리가 보는 물리 주소가 다릅니다. MMU가 이 둘 사이의 변환을 담당합니다. 이를 통해 프로세스는 물리 메모리의 어느 위치에든 적재될 수 있고, 심지어 실행 중에 이동될 수도 있습니다. 주소 공간: 논리 주소 공간 (Logical Address Space): 한 프로그램이 만들어낼 수 있는 모든 논리 주소들의 집합입니다. 예를 들어, 32비트 시스템에서 각 프로세스는 232 바이트 (4GB) 크기의 논리 주소 공간을 가질 수 있습니다 (이론적으로). 물리 주소 공간 (Physical Address Space): 시스템에 장착된 실제 물리 메모리의 주소 범위에 해당하는 모든 물리 주소들의 집합입니다. 예를 들어, 1GB RAM이 장착된 시스템의 물리 주소 공간 크기는 1GB입니다. 실행 시간 바인딩을 통해 논리 주소 공간과 물리 주소 공간을 분리함으로써, 프로그래머는 실제 물리 메모리 크기나 다른 프로세스의 존재에 대해 크게 신경 쓰지 않고 프로그램을 작성할 수 있게 되며, 운영체제는 메모리를 보다 유연하고 효율적으로 관리할 수 있습니다.","mapping-function#\u003cstrong\u003eMapping Function\u003c/strong\u003e":"","memory-access-with-paging-페이징에서의-메모리-접근#Memory Access with Paging (페이징에서의 메모리 접근)":"With paging, every data/instruction access requires (페이징 사용 시, 모든 데이터/명령어 접근은 다음을 필요로 함) 2 memory accesses (2번의 메모리 접근) One for the page table and one for the data / instruction (하나는 페이지 테이블을 위해, 다른 하나는 데이터/명령어를 위해) [한글 번역 및 상세 설명]\n페이징 시스템에서 TLB가 없을 경우 발생하는 “두 번의 메모리 접근” 문제를 시각적으로 명확하게 보여주는 슬라이드입니다. 💔➡️💔\n문제점 반복 강조:\n페이징을 사용할 때, 페이지 테이블이 주 메모리에 있기 때문에, CPU가 어떤 데이터나 명령어를 실제 메모리에서 가져오기까지 총 두 번의 주 메모리 접근이 필요하다는 점을 다시 한번 강조합니다. 다이어그램 설명:\nCPU가 논리 주소 생성: CPU가 특정 논리 주소(Page X 내의 어떤 오프셋)를 참조하려고 합니다. 접근 1: 페이지 테이블 조회 (get address - 정확히는 get frame number): CPU는 먼저 이 논리 주소의 페이지 번호 부분(X)을 사용하여, 현재 프로세스의 페이지 테이블에서 해당 페이지 X에 대한 항목(PTE)을 찾아야 합니다. PTBR 레지스터가 가리키는 주 메모리 위치에서 페이지 테이블이 시작되므로, 이 위치로부터 페이지 X의 PTE를 읽어옵니다. 이것이 첫 번째 메모리 접근입니다. 이 접근을 통해 페이지 X가 저장된 물리 프레임 번호를 얻습니다. 접근 2: 실제 데이터/명령어 조회 (get data/instruction): 첫 번째 접근에서 얻은 프레임 번호와 원래 논리 주소의 오프셋 부분을 결합하여 최종 물리 주소를 계산합니다. 이 계산된 물리 주소를 사용하여 주 메모리에 다시 한번 접근하여, 실제 원하는 데이터나 명령어를 가져옵니다. 이것이 두 번째 메모리 접근입니다. 성능 저하:\n메모리 접근은 상대적으로 느린 작업입니다. 만약 메모리 접근에 100 나노초(ns)가 걸린다고 가정하면, TLB가 없는 순수 페이징 시스템에서는 단일 논리 주소 참조에 200ns가 소요됩니다 (페이지 테이블 접근 100ns + 실제 데이터 접근 100ns). 이는 메모리 접근 속도를 실질적으로 절반으로 떨어뜨리는 것과 같아서 시스템 전체 성능에 큰 부담을 줍니다. 이러한 심각한 성능 문제를 해결하기 위해 다음 슬라이드에서 설명할 TLB(Translation Look-aside Buffer)가 필수적으로 사용됩니다.","memory-access-with-paging-페이징에서의-메모리-접근-1#Memory Access with Paging (페이징에서의 메모리 접근)":"Solution: translation look-aside buffer (해결책: TLB - 주소 변환 색인 버퍼) a special fast-lookup hardware cache (특별한 고속 검색 하드웨어 캐시) associative memory (연관 메모리) address-space identifiers (ASIDs) (주소 공간 식별자) distinguish between entries of different processes (다른 프로세스들의 항목들을 구별함) Otherwise need to flush at every context switch (그렇지 않으면 모든 문맥 교환 시에 플러시해야 함) TLBs typically small (64 to 1,024 entries) (TLB는 일반적으로 작음 (64에서 1,024 항목)) Operation (동작 방식) Works like a cache (캐시처럼 동작함) Replacement policies must be considered (교체 정책이 고려되어야 함) Some entries can be wired down for permanent fast access (일부 항목은 영구적인 빠른 접근을 위해 고정될(wired down) 수 있음) [한글 번역 및 상세 설명]\n두 번의 메모리 접근 문제를 해결하기 위한 핵심 요소인 TLB(Translation Look-aside Buffer)에 대해 더 자세히 설명합니다. 💡\nTLB 정의 및 특징:\n특별한 고속 검색 하드웨어 캐시: TLB는 MMU(Memory Management Unit) 내에 위치하거나 CPU 코어에 매우 가까이 위치하는 작고 매우 빠른 하드웨어 캐시입니다. 주 목적은 최근에 사용된 (논리 페이지 번호, 물리 프레임 번호) 매핑 정보를 저장하여, 페이지 테이블을 위한 느린 주 메모리 접근을 피하는 것입니다. 연관 메모리 (Associative Memory): TLB는 종종 연관 메모리(또는 내용 주소 지정 가능 메모리, CAM - Content Addressable Memory)로 구현됩니다. 연관 메모리는 일반 메모리처럼 주소를 주면 내용을 찾는 것이 아니라, 내용(여기서는 페이지 번호)을 주면 그 내용과 일치하는 모든 항목을 병렬적으로 동시에 검색하여 해당 항목(여기서는 프레임 번호)을 매우 빠르게 찾아낼 수 있습니다. ASIDs (Address-Space Identifiers, 주소 공간 식별자):\n다중 프로그래밍 환경에서는 여러 프로세스가 동시에 시스템에 존재하며, CPU는 이들 사이를 빠르게 전환(문맥 교환)합니다. 각 프로세스는 자신만의 페이지 테이블을 가지고 있으므로, 논리 페이지 번호 10이 프로세스 A에서는 프레임 100을 의미하고, 프로세스 B에서는 프레임 200을 의미할 수 있습니다. TLB에 단순히 (페이지 번호, 프레임 번호) 쌍만 저장하면, 문맥 교환 시 이전 프로세스의 TLB 항목이 새 프로세스에게 잘못된 정보를 줄 수 있습니다. 이를 방지하기 위해 ASID가 사용됩니다. ASID는 각 프로세스에 할당되는 고유한 식별자입니다. TLB 항목에는 (ASID, 페이지 번호, 프레임 번호, 기타 정보) 형태로 저장됩니다. TLB를 검색할 때는 현재 실행 중인 프로세스의 ASID와 찾고자 하는 페이지 번호를 함께 사용하여, 정확히 현재 프로세스에 해당하는 항목만 찾습니다. ASID의 장점: 문맥 교환이 발생해도 TLB 전체를 비울(flush) 필요가 없습니다. ASID를 통해 서로 다른 프로세스의 TLB 항목들이 공존할 수 있기 때문입니다. ASID가 없다면, 문맥 교환 시마다 TLB를 비워야 하므로, 새 프로세스가 실행될 때마다 TLB 미스가 자주 발생하여 성능이 저하됩니다. TLB 크기:\n연관 메모리는 일반 SRAM보다 복잡하고 비싸기 때문에 TLB의 크기는 제한적입니다. 일반적으로 수십에서 수천 개(예: 64~1024개, 현대 CPU는 더 많을 수 있음)의 항목을 가집니다. L1 TLB, L2 TLB 등 계층적인 구조를 갖기도 합니다. TLB 동작 방식:\n캐시처럼 동작: 일반적인 데이터 캐시나 명령어 캐시와 유사하게 동작합니다. TLB 히트(Hit): CPU가 논리 주소를 생성하면, 먼저 TLB에서 해당 페이지 번호(+ASID)를 찾습니다. 정보가 있으면(히트), 프레임 번호를 즉시 얻어 주소 변환을 완료합니다. (매우 빠름) TLB 미스(Miss): 정보가 없으면(미스), 주 메모리의 페이지 테이블에 접근하여 프레임 번호를 가져와야 합니다. (느림) 그리고 이 새로운 매핑 정보는 TLB에 저장됩니다. 교체 정책 (Replacement Policies): TLB 미스가 발생하여 새로운 항목을 TLB에 넣어야 하는데 TLB가 꽉 차 있다면, 기존 항목 중 하나를 제거(evict)해야 합니다. 이때 어떤 항목을 제거할지를 결정하는 정책이 필요합니다. 일반적인 캐시 교체 알고리즘인 LRU(Least Recently Used), FIFO(First-In First-Out), 또는 랜덤 방식 등이 사용될 수 있습니다. 고정 항목 (Wired Down Entries): 일부 TLB 항목은 교체 대상에서 제외되어 영구적으로 TLB에 상주하도록 “고정(wire down)“될 수 있습니다. 이는 운영체제 커널의 매우 중요한 페이지나, 성능에 민감한 애플리케이션의 핵심 페이지 등에 사용되어 항상 빠른 접근을 보장하기 위함입니다. TLB는 페이징 시스템의 성능을 실용적인 수준으로 끌어올리는 데 결정적인 역할을 합니다. 높은 TLB 히트율을 유지하는 것이 페이징 시스템 성능의 핵심입니다.","memory-management#Memory Management":"메모리 관리 (Memory Management)\n메모리 관리는 운영체제의 핵심 기능 중 하나로, 한정된 물리적 메모리(RAM)를 여러 프로세스들이 효율적이고 안전하게 공유할 수 있도록 관리하는 기법입니다. 각 프로세스가 필요로 하는 메모리 공간을 할당하고, 사용이 끝나면 회수하며, 다른 프로세스의 공간을 침범하지 않도록 보호하는 역할을 수행합니다.","memory-management-unit-mmu-메모리-관리-장치#Memory-Management Unit (MMU) (메모리 관리 장치)":"Hardware device that at run time maps virtual to physical address (실행 시간에 가상 주소를 물리 주소로 매핑하는 하드웨어 장치) Many methods possible, covered in the rest of this chapter (다양한 방법이 가능하며, 이 장의 나머지 부분에서 다룸) To start, consider simple scheme where the value in the relocation register is added to every address generated by a user process at the time it is sent to memory (우선, 사용자 프로세스에 의해 생성된 모든 주소가 메모리로 보내질 때 재배치 레지스터의 값이 더해지는 간단한 방식을 고려해 봅시다) Base register now called relocation register (기준 레지스터가 이제 재배치 레지스터로 불림) MS-DOS on Intel 80x86 used 4 relocation registers (인텔 80x86 기반 MS-DOS는 4개의 재배치 레지스터를 사용했음) The user program deals with logical addresses; it never sees the real physical addresses (사용자 프로그램은 논리 주소를 다루며, 실제 물리 주소를 절대로 보지 못합니다) Execution-time binding occurs when reference is made to location in memory (실행 시간 바인딩은 메모리 위치에 대한 참조가 이루어질 때 발생합니다) Logical address bound to physical addresses (논리 주소가 물리 주소에 바인딩됨) [설명]\nMMU는 실행 시간 주소 바인딩을 가능하게 하는 핵심 하드웨어입니다.\nMMU의 역할: CPU와 메모리 사이에 위치하며, CPU가 생성한 논리(가상) 주소를 물리 주소로 변환하는 역할을 수행합니다. 이 변환은 프로그램 실행 중에, 즉 런타임에 이루어집니다. 다양한 변환 방식: MMU는 단순한 재배치 레지스터 방식부터 페이징 테이블, 세그먼트 테이블을 사용하는 복잡한 방식까지 다양한 주소 변환 메커니즘을 지원할 수 있습니다. 이 장의 뒷부분에서 페이징과 세그먼테이션을 다룰 때 더 자세히 나옵니다. 간단한 MMU 방식 (재배치 레지스터 사용): 가장 기본적인 MMU 기능은 재배치 레지스터(Relocation Register, 이전의 Base Register와 유사한 개념)를 사용하는 것입니다. CPU가 생성한 모든 논리 주소에 재배치 레지스터의 값을 더하여 물리 주소를 얻습니다. Physical Address = Logical Address + Relocation_Register_Value 이때 한계 레지스터(Limit Register)도 함께 사용하여 메모리 보호 기능을 제공합니다. 즉, Logical Address \u003c Limit_Register_Value 인지 검사합니다. 예시: MS-DOS는 인텔 80x86 CPU의 세그먼트 레지스터(CS, DS, SS, ES - 일종의 재배치 레지스터)를 사용하여 메모리를 관리했습니다. 각 세그먼트 레지스터는 64KB 세그먼트의 시작 주소를 가리켰습니다. 사용자 프로그램과 논리 주소: 사용자 프로그램은 항상 논리 주소만을 사용합니다. 프로그래머나 컴파일러는 프로그램이 실제 물리 메모리의 어느 위치에 적재될지 알 필요가 없습니다. 프로그램은 자신이 0번지부터 시작하는 연속적인 메모리 공간을 사용하는 것처럼 동작합니다. 실행 시간 바인딩의 실제: CPU가 메모리를 참조하는 명령어(예: LOAD, STORE)를 실행할 때마다, 해당 명령어에 포함된 논리 주소가 MMU에 의해 물리 주소로 즉시 변환됩니다. 이것이 바로 실행 시간 바인딩이 실제로 일어나는 순간입니다. MMU 덕분에 운영체제는 프로세스를 메모리의 어느 위치에든 적재할 수 있고, 필요에 따라 이동시킬 수도 있으며, 각 프로세스에게 격리된 주소 공간을 제공하여 시스템의 안정성과 효율성을 높일 수 있습니다.","memory-protection-메모리-보호#Memory Protection (메모리 보호)":"Memory protection implemented by associating protection bit with each frame to indicate if read-only or read-write access is allowed (메모리 보호는 각 프레임에 보호 비트를 연관시켜 읽기 전용 또는 읽기/쓰기 접근이 허용되는지를 나타냄으로써 구현됨) Can also add more bits to indicate page execute-only, and so on (페이지 실행 전용 등을 나타내기 위해 더 많은 비트를 추가할 수도 있음) Valid-invalid bit attached to each entry in the page table: (페이지 테이블의 각 항목에 유효-무효 비트가 첨부됨:) “valid” indicates that the associated page is in the process’ logical address space, and is thus a legal page (“유효\"는 연관된 페이지가 프로세스의 논리 주소 공간 내에 있으며, 따라서 합법적인 페이지임을 나타냄) “invalid” indicates that the page is not in the process’ logical address space (“무효\"는 해당 페이지가 프로세스의 논리 주소 공간 내에 없음을 나타냄) Or use PTLR (또는 PTLR을 사용함) Any violations result in a trap to the kernel (어떤 위반이라도 커널로의 트랩을 발생시킴) [한글 번역 및 상세 설명]\n페이징 시스템에서 메모리 보호는 매우 중요한 기능입니다. 각 프로세스가 자신에게 할당된 메모리 영역에만 접근하고, 허용된 방식으로만 접근하도록 보장해야 합니다. 🛡️\n프레임(또는 페이지 테이블 항목) 단위의 보호 비트:\n메모리 보호는 주로 **페이지 테이블의 각 항목(PTE, Page Table Entry)**에 여러 종류의 **보호 비트(protection bits)**를 추가하여 구현됩니다. (슬라이드에서는 “각 프레임에\"라고 했지만, 실제로는 PTE에 저장되어 해당 프레임에 적용됩니다.) 읽기/쓰기 권한 (Read-Only or Read-Write): 가장 기본적인 보호 비트는 해당 페이지(프레임)에 대한 접근 권한을 나타냅니다. 읽기 전용 (Read-Only, RO): 이 비트가 설정된 페이지는 내용을 읽을 수만 있고, 쓰려고 시도하면 하드웨어 트랩(예: 보호 오류, segmentation fault)이 발생합니다. 프로그램의 코드 부분(텍스트 세그먼트)은 보통 읽기 전용으로 설정됩니다. 읽기/쓰기 (Read-Write, RW): 이 페이지는 내용을 읽고 쓰는 것이 모두 허용됩니다. 데이터 세그먼트나 스택 세그먼트의 페이지들은 보통 읽기/쓰기 권한을 가집니다. 추가적인 보호 비트: 실행 전용 (Execute-Only, XO) 또는 실행 금지 (No-Execute, NX / Execute-Disable, XD): 페이지의 내용을 CPU 명령어로 실행할 수 있는지 여부를 제어합니다. 코드 페이지는 실행 가능해야 하지만, 데이터 페이지나 스택 페이지는 악의적인 코드 실행(예: 버퍼 오버플로우 공격)을 막기 위해 실행 금지(NX 또는 XD 비트 설정)로 설정하는 것이 보안상 중요합니다. 기타 커널 모드/사용자 모드 접근 권한 비트 등 더 세분화된 보호 기능이 있을 수 있습니다. 유효-무효 비트 (Valid-Invalid Bit):\n페이지 테이블의 각 항목(PTE)에는 유효(valid) 비트 또는 무효(invalid) 비트 (보통 하나의 비트로 표현되어 0이면 무효, 1이면 유효)가 포함됩니다. “valid” (유효): 이 비트가 설정되어 있으면, 해당 논리 페이지는 현재 프로세스의 합법적인 논리 주소 공간에 속하며, 또한 실제로 물리 메모리(프레임)에 적재되어 사용 가능한 상태임을 의미합니다. 페이지 테이블 항목에 있는 프레임 번호가 유효하다는 뜻입니다. “invalid” (무효): 해당 논리 페이지가 프로세스의 합법적인 주소 공간에 아예 속하지 않음을 의미할 수 있습니다. 예를 들어, 프로세스가 4개의 페이지만 사용하는데 페이지 번호 5에 접근하려 할 때, 페이지 5에 대한 PTE의 유효 비트는 ‘invalid’로 설정되어 있을 것입니다. 또는, 해당 페이지가 합법적인 주소 공간에는 속하지만 현재 물리 메모리에 없고 디스크(백킹 스토어)에 내려가 있는 상태(swapped out 또는 paged out)임을 의미할 수도 있습니다. 이 경우, 접근 시 **페이지 폴트(page fault)**라는 트랩이 발생하고, 운영체제는 해당 페이지를 디스크에서 메모리로 가져오는 작업을 수행합니다. PTLR (Page-Table Length Register)과의 관계: PTLR은 프로세스가 가질 수 있는 페이지 번호의 최대 범위를 제한합니다. 만약 CPU가 생성한 페이지 번호 p가 PTLR 값보다 크거나 같다면, 이는 명백히 잘못된 접근이므로 PTLR에 의해 1차적으로 걸러집니다. p가 PTLR 범위 내에 있더라도, 해당 p에 대한 PTE의 유효 비트가 ‘invalid’로 설정되어 있다면, 그 페이지는 접근할 수 없습니다. 즉, PTLR은 페이지 테이블 전체의 크기를 제한하고, 유효-무효 비트는 각 개별 페이지의 유효성을 나타냅니다. 위반 시 커널 트랩:\n프로세스가 허용되지 않은 방식(예: 읽기 전용 페이지에 쓰기 시도)으로 메모리에 접근하거나, 유효하지 않은 페이지(예: PTLR 범위 초과 또는 유효 비트가 ‘invalid’인 페이지)에 접근하려고 하면, 하드웨어(MMU)는 이를 감지하고 즉시 **트랩(trap)**을 발생시켜 운영체제 커널에게 제어권을 넘깁니다. 커널은 이 트랩의 원인을 분석하여, 만약 단순한 페이지 폴트(페이지가 디스크에 있는 경우)라면 해당 페이지를 메모리로 가져오는 등의 처리를 하고 프로세스를 재개시키지만, 진짜 메모리 보호 위반(예: 권한 없는 접근, 존재하지 않는 주소 접근)이라면 “Segmentation Fault”, “Access Violation”, “General Protection Fault” 등의 오류를 발생시키고 해당 프로세스를 강제 종료시킵니다. 이러한 메모리 보호 메커니즘은 각 프로세스가 자신만의 격리된 환경에서 안전하게 실행될 수 있도록 보장하며, 시스템 전체의 안정성과 보안을 유지하는 데 핵심적인 역할을 합니다.","microkernel-system-structure#microkernel System Structure":"","microkernel-system-structure-마이크로커널-시스템-구조#\u003cstrong\u003eMicrokernel System Structure (마이크로커널 시스템 구조)\u003c/strong\u003e":"","module#module":"","modules-모듈#\u003cstrong\u003eModules (모듈)\u003c/strong\u003e":"","monolithic-system-structure#Monolithic System Structure":"","monolithic-system-structure-모놀리식-시스템-구조#\u003cstrong\u003eMonolithic System Structure (모놀리식 시스템 구조)\u003c/strong\u003e":"","multistep-processing-of-a-user-program-사용자-프로그램의-다단계-처리-과정#Multistep Processing of a User Program (사용자 프로그램의 다단계 처리 과정)":"(Diagram showing: Source program -\u003e Compiler -\u003e Object module -\u003e Linker -\u003e Load module -\u003e Loader -\u003e In-memory process with dynamic linking/loading) [설명]\n사용자 프로그램이 작성되어 실행되기까지 거치는 여러 단계를 보여주는 다이어그램입니다. 각 단계에서 주소와 관련된 변환 및 바인딩 작업이 이루어집니다.\nSource Program (소스 프로그램): 프로그래머가 작성한 고급 언어 또는 어셈블리어 코드. 심볼릭 주소(변수명, 함수명 등)를 사용합니다. Compiler (컴파일러) 또는 Assembler (어셈블러): 소스 프로그램을 기계가 이해할 수 있는 오브젝트 모듈(object module)로 번역합니다. 심볼릭 주소를 재배치 가능 주소(상대 주소)로 변환합니다. 외부 참조(다른 모듈에 정의된 함수나 변수)에 대한 정보를 포함합니다. Object Module (오브젝트 모듈): 컴파일된 결과물. 재배치 정보, 심볼 테이블 등을 포함합니다. Linker (링커): 여러 개의 오브젝트 모듈과 필요한 라이브러리 모듈들을 결합하여 하나의 실행 가능한 로드 모듈(load module) 또는 실행 파일(executable file)을 만듭니다. 모듈 간의 외부 참조를 해결하여 주소를 연결합니다. 주소들을 하나의 통합된 (논리적) 주소 공간 내의 주소로 조정합니다. Load Module (로드 모듈) / Executable File (실행 파일): 디스크에 저장된, 실행 준비가 된 프로그램입니다. Loader (로더): 사용자가 프로그램을 실행시키면, 로더가 로드 모듈을 메모리에 적재합니다. 적재 시간 바인딩을 사용한다면, 이 때 재배치 가능 주소를 물리 주소로 변환합니다. 실행 시간 바인딩을 사용한다면, 논리 주소 형태를 유지한 채로 적재하고, MMU가 실행 중에 주소 변환을 담당합니다. In-memory process (메모리 내의 프로세스): 메모리에 적재되어 실행 중인 프로그램. Dynamic Linking (동적 연결): 라이브러리 루틴과의 연결이 실행 시점까지 지연되는 경우. 필요할 때 해당 라이브러리가 메모리에 로드되고 연결됩니다. (다음 슬라이드에서 설명) Dynamic Loading (동적 적재): 프로그램의 특정 루틴이 호출될 때까지 디스크에 남아 있다가, 호출되는 순간에 메모리에 적재되는 경우. (다음 슬라이드에서 설명) 이 과정을 통해 프로그램의 추상적인 주소 표현이 점차 구체적인 물리 메모리 주소로 연결됩니다.","need-for-page-replacement#\u003cstrong\u003eNeed For Page Replacement\u003c/strong\u003e":"","optimal-algorithm#Optimal Algorithm":"","optimal-page-replacement#\u003cstrong\u003eOptimal Page Replacement\u003c/strong\u003e":"","original-text#original text":"Deadlock Avoidance A decision is made dynamically whether the current resource allocation request will, if granted, potentially lead to a deadlock Requires knowledge of future process requests","original-text-1#original text":"Two Approaches to Deadlock Avoidance Process Initiation Denial Do not start a process if its demands might lead to deadlock Resource Allocation Denial Do not grant an incremental resource request to a process if this allocation might lead to deadlock","original-text-10#original text":"Unsafe State In Resource-Allocation Graph","original-text-11#original text":"Suppose that process Pi​ requests a resource Rj​ The request can be granted only if converting the request edge to an assignment edge does not result in the formation of a cycle in the resource allocation graph","original-text-12#original text":"Potential Deadlock\nI need quad A and B\nI need quad B and C\nI need quad C and B\nI need quad D and A","original-text-13#original text":"Resource Allocation Diagram","original-text-14#original text":"Resource Allocation Diagram","original-text-15#original text":"Actual Deadlock\nHALT until B is free\nHALT until C is free\nHALT until D is free\nHALT until A is free","original-text-16#original text":"Cars in Intersection, again","original-text-17#original text":"Multiple instances Each process must a priori claim maximum use When a process requests a resource it may have to wait When a process gets all its resources it must return them in a finite amount of time","original-text-18#original text":"Available: Vector of length m. If available [j]=k, there are k instances of resource type Rj​ available Max: n×m matrix. If Max [i,j]=k, then process Pi​ may request at most k instances of resource type Rj​ Allocation: n×m matrix. If Allocation$[i,j] = k$ then Pi​ is currently allocated k instances of Rj​ Need: n×m matrix. If Need$[i,j] = k$, then Pi​ may need k more instances of Rj​ to complete its task Need [i,j]=Max[i,j]–Allocation[i,j]","original-text-19#original text":"Let Work and Finish be vectors of length m and n, respectively. Initialize: Work = Available Finish [i] = false for i=0,1,…,n−1 Find an i such that both: (a) Finish [i] = false (b) Need$_i \\le$ Work If no such i exists, go to step 4 Work = Work + Allocation$_i$ Finish$[i]$ = true go to step 2 If Finish [i] == true for all i, then the system is in a safe state","original-text-2#original text":"Process Initiation Denial A process is only started if the maximum claim of all current processes plus those of the new process can be met. Not optimal: Assumes the worst: that all processes will make their maximum claims together.","original-text-20#original text":"Request = request vector for process Pi​. If Request$_i [j] = k$ then process Pi​ wants k instances of resource type Rj​\nIf Request$_i \\le$ Need$_i$ go to step 2. Otherwise, raise error condition, since process has exceeded its maximum claim If Request$_i \\le$ Available, go to step 3. Otherwise Pi​ must wait, since resources are not available Pretend to allocate requested resources to Pi​ by modifying the state as follows: Available = Available – Request$_i$; Allocation$_i$ = Allocation$_i$ + Request$_i$; Need$_i$ = Need$_i$ – Request$_i$; If safe ⟹ the resources are allocated to Pi​ If unsafe ⟹Pi​ must wait, and the old resource-allocation state is restored","original-text-21#original text":"5 processes P0​ through P4​; 3 resource types: A (10 instances), B (5 instances), and C (7 instances) Snapshot at time T0: Allocation Max Available A B C A B C A B C P0 0 1 0 7 5 3 3 3 2 P1 2 0 0 3 2 2 P2 3 0 2 9 0 2 P3 2 1 1 2 2 2 P4 0 0 2 4 3 3","original-text-22#original text":"The content of the matrix Need is defined to be Max – Allocation Need A B C P0 7 4 3 P1 1 2 2 P2 6 0 0 P3 0 1 1 P4 4 3 1 The system is in a safe state since the sequence \u003c P1, P3, P4, P2, P0\u003e satisfies safety criteria","original-text-23#original text":"Check that Request ≤ Available (that is, (1,0,2)≤(3,3,2) ⟹ true Allocation Need Available A B C A B C A B C P0 0 1 0 7 4 3 2 3 0 P1 3 0 2 0 2 0 P2 3 0 2 6 0 0 P3 2 1 1 0 1 1 P4 0 0 2 4 3 1 Executing safety algorithm shows that sequence \u003c P1, P3, P4, P0, P2\u003e satisfies safety requirement Can request for (3,3,0) by P4 be granted? Can request for (0,2,0) by P0 be granted?","original-text-24#\u003cstrong\u003eOriginal Text\u003c/strong\u003e":"Background\nVirtual memory – separation of user logical memory from physical memory Only part of the program needs to be in memory for execution Logical address space can therefore be much larger than physical address space Virtual memory can be implemented via: Demand paging Demand segmentation","original-text-25#\u003cstrong\u003eOriginal Text\u003c/strong\u003e":"Virtual Memory That is Larger Than Physical Memory\n(Diagram illustrating a large logical memory space mapped to a smaller physical memory, with overflow stored on disk)","original-text-26#\u003cstrong\u003eOriginal Text\u003c/strong\u003e":"Demand Paging\nBring a page into memory only when it is needed Less I/O needed, no unnecessary I/O Less memory needed Faster response More users","original-text-27#\u003cstrong\u003eOriginal Text\u003c/strong\u003e":"Valid-Invalid Bit\nWith each page table entry a valid–invalid bit is associated (v =\u003e in-memory – memory resident, i =\u003e not-in-memory) Example of a page table snapshot: (Diagram showing a page table with entries containing a frame number and a valid-invalid bit) During address translation, if valid–invalid bit in page table entry is i =\u003e page fault","original-text-28#\u003cstrong\u003eOriginal Text\u003c/strong\u003e":"Page Table When Some Pages Are Not in Main Memory\n(Diagram showing logical memory, the page table, and physical memory. Some page table entries point to frames in physical memory, while others are marked invalid, corresponding to pages not loaded from the disk.)","original-text-29#\u003cstrong\u003eOriginal Text\u003c/strong\u003e":"Page Fault\nIf there is a reference to a page, first reference to that page will trap to operating system: page fault\nOperating system looks at another table to decide: Invalid reference =\u003e abort Just not in memory Get empty frame Swap page into frame via scheduled disk operation Reset tables to indicate page now in memory. Set validation bit = v Restart the instruction that caused the page fault","original-text-3#original text":"Resource Allocation Denial Referred to as the Banker’s algorithm A strategy of resource allocation denial Consider a system with fixed number of resources State of the system is the current allocation of resources to process Safe state is where there is at least one sequence that does not result in deadlock Unsafe state is a state that is not safe","original-text-30#\u003cstrong\u003eOriginal Text\u003c/strong\u003e":"Steps in Handling a Page Fault\n(A detailed diagram illustrating the 6 steps of handling a page fault, from the initial memory reference to restarting the instruction.)","original-text-31#\u003cstrong\u003eOriginal Text\u003c/strong\u003e":"What Happens if There is no Free Frame?\nPage replacement Find some page in memory, but not really in use, page it out Performance – want an algorithm which will result in minimum number of page faults","original-text-32#\u003cstrong\u003eOriginal Text\u003c/strong\u003e":"Need For Page Replacement\n(A diagram illustrating the process of page replacement: a victim page is paged out to disk, and the desired new page is paged into the now-free frame.)","original-text-33#\u003cstrong\u003eOriginal Text\u003c/strong\u003e":"Page Replacement","original-text-34#\u003cstrong\u003eOriginal Text\u003c/strong\u003e":"Page Replacement Algorithms\nPage-replacement algorithm Want lowest page-fault rate on both first access and re-access Optimal FIFO (First In First Out) Least Recently Used (LRU)","original-text-35#\u003cstrong\u003eOriginal Text\u003c/strong\u003e":"Optimal Algorithm\nReplace page that will not be used for longest period of time How do you know this? Can’t read the future Used for measuring how well your algorithm performs","original-text-36#\u003cstrong\u003eOriginal Text\u003c/strong\u003e":"Optimal Page Replacement\n(These slides typically depict a diagram or an example of the Optimal algorithm in action. Since no specific diagram content is provided in the prompt other than the title, the explanation will assume a common example reference string and walk through the algorithm’s execution.)","original-text-37#\u003cstrong\u003eOriginal Text\u003c/strong\u003e":"FIFO Algorithm\nReplace page that is oldest How do you know this? FIFO queue","original-text-38#\u003cstrong\u003eOriginal Text\u003c/strong\u003e":"FIFO Page Replacement\n(These slides typically depict a diagram or an example of the FIFO algorithm in action. Similar to the Optimal algorithm slides, the explanation will assume the same reference string to compare performance.)","original-text-4#original text":"Safe State When a process requests an available resource, system must decide if immediate allocation leaves the system in a safe state System is in safe state if there exists a sequence of ALL the processes in the systems such that for each Pi, the resources that Pi can still request can be satisfied by currently available resources + resources held by all the Pj, with j \u003c i That is: If Pi resource needs are not immediately available, then Pi can wait until all Pj have finished When Pj is finished, Pi can obtain needed resources, execute, return allocated resources, and terminate When Pi terminates, Pi+1 can obtain its needed resources, and so on","original-text-5#original text":"Basic Facts If a system is in safe state Þ no deadlocks If a system is in unsafe state Þ possibility of deadlock Avoidance Þ ensure that a system will never enter an unsafe state.","original-text-6#original text":"Safe, Unsafe, Deadlock State (이 슬라이드는 일반적으로 세 가지 상태 간의 관계를 보여주는 다이어그램이나 그림을 포함하지만, 텍스트만 제공되었습니다. 설명을 위해 일반적인 개념도를 가정하여 설명합니다.)","original-text-7#original text":"Avoidance algorithms Single instance of a resource type Use a resource-allocation graph Multiple instances of a resource type Use the banker’s algorithm resource type 당 2개의 인스턴스가 있을때 뱅커스 알로리즘을 사용한다 resource type 당 2개의 인스턴스가 있을때 뱅커스 알로리즘을 사용한다","original-text-8#original text":"Claim edge Pi​→Rj​ indicated that process Pi​ may request resource Rj​; represented by a dashed line Claim edge converts to request edge when a process requests a resource Request edge converted to an assignment edge when the resource is allocated to the process When a resource is released by a process, assignment edge reconverts to a claim edge Resources must be claimed a priori in the system","original-text-9#original text":"Resource-Allocation Graph","os#OS":"","page-replacement#Page Replacement":"","page-replacement-algorithms#\u003cstrong\u003ePage Replacement Algorithms\u003c/strong\u003e":"","page-table-when-some-pages-are-not-in-main-memory#\u003cstrong\u003ePage Table When Some Pages Are Not in Main Memory\u003c/strong\u003e":"","paging-example-페이징-예제#Paging Example (페이징 예제)":"(Diagram with Logical memory (pages 0-3, data a-p), Page table (mapping pages to frames), and Physical memory (frames 0-7, showing where data a-p is stored based on page table, and some frames are free).)\n이 슬라이드는 앞서 설정된 값(m=4, n=2, 32바이트 물리 메모리)을 바탕으로 페이징 시스템의 구체적인 메모리 할당 상태를 보여줍니다. 🗺️\n논리 주소 및 프로세스 공간:\n4-bit logical address (m=4): 논리 주소는 4비트로 표현됩니다. 16-byte process space: 24=16 바이트의 논리 주소 공간을 가집니다. 2-bit page no (m-n=2), 0~3: 논리 주소의 상위 2비트는 페이지 번호(p)를 나타내며, 값의 범위는 00(0)부터 11(3)까지 총 4개의 페이지입니다. 2-bit offset (n=2), 4-byte pages: 논리 주소의 하위 2비트는 오프셋(d)을 나타내며, 페이지(프레임) 크기는 22=4 바이트입니다. 물리 주소 및 메모리:\n5-bit physical address: 물리 주소는 5비트로 표현됩니다. 32-byte memory: 25=32 바이트의 물리 메모리 공간을 가집니다. 물리 메모리는 4바이트 크기의 프레임 8개(32바이트 / 4바이트/프레임 = 8 프레임)로 나누어집니다. 프레임 번호는 3비트(000부터 111까지)로 표현됩니다. 다이어그램 해석:\nLogical Memory (논리 메모리): 프로세스가 “보는” 메모리 모습입니다. 0번지부터 15번지(0000부터 1111까지)까지 16바이트의 연속된 공간으로 보입니다. 이 공간은 4개의 페이지(Page 0, Page 1, Page 2, Page 3)로 나뉘어 있고, 각 페이지는 4바이트의 데이터(임의로 a부터 p까지 문자로 표현)를 담고 있습니다. Page 0 (논리 주소 0000~0011): 데이터 a, b, c, d Page 1 (논리 주소 0100~0111): 데이터 e, f, g, h Page 2 (논리 주소 1000~1011): 데이터 i, j, k, l Page 3 (논리 주소 1100~1111): 데이터 m, n, o, p Page Table (페이지 테이블): 이 프로세스의 각 논리 페이지가 어느 물리 프레임에 저장되어 있는지를 보여주는 매핑 테이블입니다. (페이지 번호 | 프레임 번호) 형태로 표시되어 있습니다. 페이지 0 (00)은 프레임 5 (101)에 매핑됩니다. 페이지 1 (01)은 프레임 6 (110)에 매핑됩니다. 페이지 2 (10)은 프레임 1 (001)에 매핑됩니다. 페이지 3 (11)은 프레임 2 (010)에 매핑됩니다. Physical Memory (물리 메모리): 실제 RAM의 모습입니다. 8개의 프레임(frame-0부터 frame-7까지)으로 구성되어 있습니다. 각 프레임의 시작 물리 주소도 표시되어 있습니다 (예: frame-1은 00100부터 시작). 페이지 테이블의 매핑 정보에 따라 각 페이지의 데이터가 실제 물리 프레임에 저장된 모습을 보여줍니다. 프레임 0 (00000): 비어 있음 (free) 프레임 1 (00100): 페이지 2의 데이터 (i, j, k, l) 저장 프레임 2 (01000): 페이지 3의 데이터 (m, n, o, p) 저장 프레임 3 (01100): 비어 있음 (free) 프레임 4 (10000): 비어 있음 (free) 프레임 5 (10100): 페이지 0의 데이터 (a, b, c, d) 저장 프레임 6 (11000): 페이지 1의 데이터 (e, f, g, h) 저장 프레임 7 (11100): 비어 있음 (free) 중요한 것은 페이지 0, 1, 2, 3이 물리 메모리에서 (프레임 5, 6, 1, 2 순서로) 비연속적으로 흩어져 저장되어 있다는 점입니다. 이 예제를 통해 프로세스의 논리적인 연속성이 페이지 테이블을 통해 물리적인 비연속성으로 어떻게 변환되는지 명확히 알 수 있습니다.","paging-hardware-페이징-하드웨어#Paging Hardware (페이징 하드웨어)":"(Diagram showing CPU generating a logical address (p, d). ‘p’ is used as an index into a Page table. The Page table base register (PTBR) points to the start of the page table in physical memory. The entry at PTBR + p gives the frame number ‘f’. ‘f’ is concatenated with ’d’ to form the physical address, which then accesses physical memory.)\nCPU [ p | d ] -\u003e Page table [ PTBR + p gives f ] -\u003e Physical memory [ f | d ]\nLogical Address -\u003e Physical Address\nPage table base register (PTBR) / Page table length register (PTLR)\n[한글 번역 및 상세 설명]\n이 슬라이드의 다이어그램은 페이징에서 주소 변환을 지원하는 데 필요한 하드웨어 요소, 특히 페이지 테이블이 메모리에 저장되는 방식과 접근 과정을 보여줍니다.\nCPU의 논리 주소 생성: CPU는 논리 주소를 생성하며, 이는 페이지 번호(p)와 오프셋(d)으로 나뉩니다.\n페이지 테이블 위치:\n각 프로세스는 자신만의 페이지 테이블을 가지고 있으며, 이 페이지 테이블은 물리 메모리에 저장됩니다. 운영체제는 현재 실행 중인 프로세스의 페이지 테이블이 물리 메모리의 어디에 시작하는지를 알아야 합니다. 이 시작 주소는 특별한 CPU 레지스터인 **페이지 테이블 기준 레지스터(Page Table Base Register, PTBR)**에 저장됩니다. (때로는 Page Table Pointer 라고도 불립니다.) **페이지 테이블 길이 레지스터(Page Table Length Register, PTLR)**도 사용될 수 있습니다. 이는 페이지 테이블의 크기(즉, 유효한 페이지 번호의 범위)를 나타내어, 프로세스가 자신의 페이지 테이블 범위를 벗어나는 잘못된 페이지 번호로 접근하는 것을 방지합니다 (메모리 보호). p \u003e= PTLR 이면 오류입니다. 페이지 테이블 항목(PTE) 접근:\nCPU가 생성한 논리 주소의 페이지 번호(p)와 PTBR 값을 사용하여, 해당 페이지에 대한 정보(페이지 테이블 항목, Page Table Entry, PTE)가 저장된 물리 메모리 주소를 계산합니다. 만약 각 PTE의 크기가 entry_size 바이트라면, 원하는 PTE의 주소는 PTBR + (p * entry_size)가 됩니다. (다이어그램에서는 단순하게 PTBR + p로 표현했는데, 이는 p가 PTE의 오프셋 인덱스로 사용되고, PTBR이 이미 올바른 시작점을 가리킨다고 가정한 것입니다. 실제로는 PTE 크기를 고려해야 합니다.) 이 주소에서 PTE를 읽어옵니다. PTE에는 해당 페이지가 적재된 **프레임 번호(f)**가 들어있습니다. 물리 주소 형성 및 접근:\n읽어온 프레임 번호(f)와 원래의 오프셋(d)을 결합하여 최종 물리 주소를 만듭니다. ([f | d]) 이 물리 주소를 사용하여 실제 데이터나 명령어가 있는 물리 메모리 위치에 접근합니다. 중요한 점:\n페이지 테이블의 메모리 상주: 페이지 테이블 자체가 주 메모리에 있다는 것은, 모든 논리 주소 참조가 잠재적으로 두 번의 메모리 접근을 필요로 한다는 것을 의미합니다. 첫 번째 접근: 페이지 테이블에서 프레임 번호를 가져오기 위한 접근. 두 번째 접근: 실제 데이터나 명령어를 가져오기 위한 접근. 성능 문제: 두 번의 메모리 접근은 시스템 성능을 크게 저하시킬 수 있습니다. 이를 해결하기 위해 대부분의 시스템은 TLB(Translation Lookaside Buffer) 또는 주소 변환 버퍼라고 불리는 고속의 하드웨어 캐시를 사용합니다. TLB에는 최근에 사용된 (페이지 번호, 프레임 번호) 매핑 정보가 저장되어 있어, 페이지 테이블을 매번 메모리에서 읽어오는 대신 TLB에서 빠르게 찾을 수 있도록 합니다. (TLB는 이 슬라이드 세트에는 명시적으로 나오지 않았지만, 페이징 하드웨어의 매우 중요한 부분입니다.) PTBR과 PTLR(또는 이와 유사한 메커니즘)은 문맥 교환(context switch) 시 운영체제에 의해 현재 실행될 프로세스의 값으로 변경되어야 합니다. 그래야 각 프로세스가 자신만의 페이지 테이블을 올바르게 참조할 수 있습니다.","paging-logical-addresses-페이징-논리-주소#Paging: Logical Addresses (페이징: 논리 주소)":"• 16-bit address, page size 1K=210, first 6 bit=page #, last 10bit = offset\n(16비트 주소, 페이지 크기 1KB=210, 처음 6비트=페이지 번호, 마지막 10비트=오프셋)\n[한글 번역 및 상세 설명]\n페이징 시스템에서 CPU가 생성하는 논리 주소는 두 부분으로 나뉘어 해석됩니다: **페이지 번호(page number, p)**와 페이지 오프셋(page offset, d).\n예시 설명:\n16-bit logical address (16비트 논리 주소): CPU가 생성할 수 있는 전체 논리 주소의 길이가 16비트라는 의미입니다. 이는 216=65,536 바이트 (64KB)의 논리 주소 공간을 나타냅니다. Page size 1K = 210 bytes (페이지 크기 1KB): 하나의 페이지(그리고 프레임)의 크기가 1KB, 즉 1024바이트라는 의미입니다. 1KB=210 바이트이므로, 페이지 내의 특정 바이트를 가리키기 위해서는 10비트가 필요합니다. 이것이 오프셋의 비트 수가 됩니다. Last 10 bits = offset (마지막 10비트는 오프셋): 논리 주소의 하위 10비트는 페이지 내에서의 상대적인 위치(변위)를 나타내는 오프셋(d)으로 사용됩니다. 오프셋 값의 범위는 0부터 210−1 (즉, 0부터 1023)까지입니다. First 6 bits = page # (처음 6비트는 페이지 번호): 전체 논리 주소 16비트 중 오프셋으로 사용된 10비트를 제외한 나머지 상위 비트들이 페이지 번호(p)로 사용됩니다. 즉, 16−10=6 비트가 페이지 번호가 됩니다. 이 6비트로는 26=64개의 서로 다른 페이지(페이지 0부터 페이지 63까지)를 구분할 수 있습니다. 일반화:\n만약 논리 주소의 전체 길이가 m비트이고, 페이지 크기가 2n 바이트라면, 하위 n비트는 페이지 오프셋(d)이 됩니다. 상위 m-n비트는 페이지 번호(p)가 됩니다. 이러한 논리 주소의 구조는 하드웨어(MMU)에 의해 해석되어 물리 주소로 변환됩니다. 페이지 번호(p)는 페이지 테이블의 인덱스로 사용되어 해당 페이지가 저장된 프레임 번호(f)를 찾는 데 사용되고, 오프셋(d)은 그 프레임 내에서의 상대 위치를 나타내므로 물리 주소 계산 시 그대로 사용됩니다.","paging-logical-to-physical-address-페이징-논리-주소에서-물리-주소로#Paging: Logical to Physical Address (페이징: 논리 주소에서 물리 주소로)":"(Diagram showing logical address (page p, offset d) being translated. ‘p’ goes into page table, which outputs frame ‘f’. ‘f’ is combined with ’d’ to form physical address (frame f, offset d) which accesses physical memory.)\npage table (페이지 테이블)\nlogical address (논리 주소) [ p | d ]\nphysical address (물리 주소) [ f | d ]\nphysical memory (물리 메모리)\nframe number (프레임 번호)\n[한글 번역 및 상세 설명]\n이 다이어그램은 페이징 시스템에서 논리 주소가 물리 주소로 변환되는 핵심 과정을 보여줍니다. ⚙️\nCPU가 논리 주소 생성: CPU는 실행할 명령어에 따라 논리 주소를 생성합니다. 이 논리 주소는 내부적으로 두 부분으로 구성됩니다.\n페이지 번호 (p, page number): 논리 주소의 상위 비트들로, 어떤 페이지를 참조하는지를 나타냅니다. 오프셋 (d, offset): 논리 주소의 하위 비트들로, 해당 페이지 내에서 얼마나 떨어져 있는 위치(바이트 단위)를 참조하는지를 나타냅니다. 페이지 테이블 참조:\n논리 주소에서 추출된 **페이지 번호(p)**는 **페이지 테이블(page table)**의 인덱스로 사용됩니다. 페이지 테이블의 각 항목(entry)에는 해당 논리 페이지가 실제로 저장되어 있는 물리 메모리의 **프레임 번호(f, frame number)**가 들어있습니다. (그리고 유효 비트, 보호 비트 등의 추가 정보도 포함될 수 있습니다.) 즉, 프레임 번호 (f) = 페이지 테이블 [페이지 번호 (p)] 와 같은 연산이 수행됩니다. 물리 주소 형성:\n페이지 테이블로부터 얻은 **프레임 번호(f)**와 원래 논리 주소에 있던 **오프셋(d)**을 결합하여 최종적인 물리 주소를 만듭니다. 물리 주소의 구조는 [프레임 번호 (f) | 오프셋 (d)]가 됩니다. 오프셋(d)은 변환 과정에서 변경되지 않고 그대로 사용됩니다. 이는 오프셋이 페이지(또는 프레임) 내에서의 상대적인 위치를 의미하기 때문입니다. 페이지가 어떤 프레임에 적재되든 그 페이지 내부의 구조는 동일합니다. 물리 메모리 접근: 이렇게 형성된 물리 주소를 사용하여 실제 물리 메모리에 접근하여 원하는 데이터나 명령어를 가져오거나 저장합니다.\n이 모든 주소 변환 과정은 하드웨어인 **MMU(Memory Management Unit)**에 의해 매우 빠르게 수행됩니다. 이 과정 덕분에 프로그래머나 컴파일러는 실제 물리 메모리 구조를 신경 쓸 필요 없이 논리 주소 공간만을 대상으로 작업할 수 있습니다.","paging-with-tlb-hit-tlb-히트-시-페이징#Paging With TLB-hit (TLB 히트 시 페이징)":"(Diagram focusing on TLB hit path: CPU -\u003e Logical Address (p,d) -\u003e TLB (hit) -\u003e Frame f -\u003e Physical Address (f,d) -\u003e Memory)\n1 cache access (1번의 캐시 접근)\n1 memory access (1번의 메모리 접근)\nAccess time = e + M (접근 시간 = e + M)\n[한글 번역 및 상세 설명]\n이 슬라이드는 TLB 히트(TLB Hit)가 발생했을 때의 메모리 접근 과정을 집중적으로 보여줍니다. 이것이 페이징 시스템에서 가장 바람직하고 빠른 경로입니다.\n과정 요약 (TLB 히트 시):\nCPU가 논리 주소 (p,d) 생성. TLB 조회: 페이지 번호 p를 사용하여 TLB를 검색합니다. (시간 e 소요) 히트!: p에 대한 (페이지 번호, 프레임 번호) 매핑 정보가 TLB에 존재합니다. TLB로부터 프레임 번호 f를 즉시 얻습니다. 물리 주소 형성: (f,d)로 물리 주소를 만듭니다. 데이터 접근: 형성된 물리 주소로 주 메모리에 접근하여 원하는 데이터나 명령어를 가져옵니다. (시간 M 소요) 소요 시간 및 접근 횟수:\n1 cache access (1번의 캐시 접근): TLB를 조회하는 데 한 번의 캐시(TLB) 접근이 필요합니다. 1 memory access (1번의 메모리 접근): 실제 데이터나 명령어를 주 메모리에서 가져오는 데 한 번의 메모리 접근이 필요합니다. (페이지 테이블을 위한 추가적인 메모리 접근은 발생하지 않습니다.) Access time (총 접근 시간) = e (TLB 접근 시간) + M (메모리 접근 시간) TLB 히트 시에는 페이지 테이블을 직접 참조할 필요가 없으므로, “두 번의 메모리 접근” 문제가 발생하지 않고, 마치 TLB가 없는 시스템에서 직접 메모리에 한 번 접근하는 것과 유사한 속도(e는 M에 비해 매우 작으므로 e+M ≈ M)를 낼 수 있게 됩니다. 따라서 TLB 히트율을 높이는 것이 페이징 시스템의 성능에 매우 중요합니다.","paging-with-tlb-miss-tlb-미스-시-페이징#Paging With TLB-miss (TLB 미스 시 페이징)":"(Diagram focusing on TLB miss path: CPU -\u003e Logical Address (p,d) -\u003e TLB (miss) -\u003e Page Table (in memory, access 1) -\u003e Frame f -\u003e Physical Address (f,d) -\u003e Memory (access 2 for data). The (p,f) pair is then written to TLB.)\n1 cache access (1번의 캐시 접근 - 미스)\n2 memory accesses (2번의 메모리 접근 - 페이지 테이블 + 실제 데이터)\nAccess time = e + 2M (접근 시간 = e + 2M)\n[한글 번역 및 상세 설명]\n이 슬라이드는 TLB 미스(TLB Miss)가 발생했을 때의 메모리 접근 과정을 보여줍니다. 이는 TLB 히트 시보다 더 많은 시간이 소요되는 경로입니다.\n과정 요약 (TLB 미스 시):\nCPU가 논리 주소 (p,d) 생성. TLB 조회: 페이지 번호 p를 사용하여 TLB를 검색합니다. (시간 e 소요) 미스!: p에 대한 매핑 정보가 TLB에 존재하지 않습니다. 페이지 테이블 조회 (첫 번째 메모리 접근): 주 메모리에 있는 페이지 테이블에 접근하여, 페이지 번호 p에 해당하는 페이지 테이블 항목(PTE)을 읽어옵니다. 이 과정에서 프레임 번호 f를 얻습니다. (시간 M 소요) 물리 주소 형성: (f,d)로 물리 주소를 만듭니다. 데이터 접근 (두 번째 메모리 접근): 형성된 물리 주소로 주 메모리에 접근하여 원하는 데이터나 명령어를 가져옵니다. (시간 M 소요) TLB 업데이트: 페이지 테이블에서 가져온 새로운 매핑 정보 (p와 그에 해당하는 f)를 다음번 빠른 조회를 위해 TLB에 저장합니다. 만약 TLB가 가득 찼다면, 기존 항목 중 하나가 교체 정책에 따라 제거되고 새 항목이 들어갑니다. 소요 시간 및 접근 횟수:\n1 cache access (1번의 캐시 접근): TLB를 조회했으나 실패(미스)한 접근입니다. 2 memory accesses (2번의 메모리 접근): 페이지 테이블에서 프레임 번호를 가져오기 위한 접근. 실제 데이터나 명령어를 주 메모리에서 가져오기 위한 접근. Access time (총 접근 시간) = e (TLB 접근 시간) + M (페이지 테이블 접근 시간) + M (실제 데이터 접근 시간) = e + 2M TLB 미스가 발생하면, TLB가 없을 때와 마찬가지로 두 번의 주 메모리 접근이 필요하게 되어 성능 저하가 발생합니다. 그러나 프로그램 실행의 지역성(locality) 덕분에 한 번 TLB에 적재된 정보는 짧은 시간 내에 다시 사용될 확률이 높아, 전체적으로는 TLB 히트가 미스보다 훨씬 자주 발생합니다. 이로 인해 평균적인 메모리 접근 시간은 크게 향상됩니다.","paging-with-tlb-tlb를-사용한-페이징#Paging With TLB (TLB를 사용한 페이징)":"[한글 번역 및 상세 설명]\nTLB를 포함한 전체 페이징 주소 변환 과정을 보여주는 종합적인 다이어그램입니다. 🌟\nCPU가 논리 주소 (p, d) 생성: CPU는 페이지 번호 p와 오프셋 d로 구성된 논리 주소를 생성합니다.\nTLB 조회 (Cache Access - 시간 e 소요):\nMMU는 먼저 페이지 번호 p를 사용하여 TLB를 검색합니다. 이 TLB 접근에는 e만큼의 시간이 걸립니다. (e는 주 메모리 접근 시간 M보다 훨씬 작습니다.) TLB 히트 (TLB Hit) 시:\n만약 TLB에서 p와 일치하는 항목이 발견되면 (TLB 히트), 해당 항목으로부터 프레임 번호 f를 즉시 얻습니다. 물리 주소 (f, d)가 형성됩니다. 이 물리 주소를 사용하여 주 메모리에 접근하여 실제 데이터나 명령어를 가져옵니다. 이 메모리 접근에는 M만큼의 시간이 걸립니다. 총 소요 시간 (TLB 히트 시) = e + M TLB 미스 (TLB Miss) 시:\n만약 TLB에서 p와 일치하는 항목이 없으면 (TLB 미스), 다음 단계로 진행합니다. 페이지 테이블 조회 (Memory Access - 시간 M 소요): 시스템은 주 메모리에 있는 페이지 테이블에 접근하여 페이지 p에 대한 페이지 테이블 항목(PTE)을 찾아야 합니다. 이 접근에 M만큼의 시간이 걸립니다. PTE로부터 프레임 번호 f를 얻습니다. 물리 주소 형성 및 실제 데이터 접근 (Memory Access - 시간 M 소요): 얻은 프레임 번호 f와 오프셋 d를 결합하여 물리 주소 (f, d)를 형성합니다. 이 물리 주소를 사용하여 주 메모리에 접근하여 실제 데이터나 명령어를 가져옵니다. 이 접근에도 M만큼의 시간이 걸립니다. TLB 업데이트: 페이지 테이블에서 가져온 새로운 (p, f) 매핑 정보는 다음번 조회를 위해 TLB에 저장됩니다. (만약 TLB가 꽉 찼다면, 기존 항목 중 하나가 교체 정책에 따라 제거됩니다.) 총 소요 시간 (TLB 미스 시) = e (TLB 조회) + M (페이지 테이블 접근) + M (실제 데이터 접근) = e + 2M 시간 변수: M: 주 메모리 접근 시간 (상대적으로 느림) e: TLB (캐시) 접근 시간 (매우 빠름, e \u003c\u003c M) 이 다이어그램은 TLB가 어떻게 “빠른 경로(fast path)” (TLB 히트 시)와 “느린 경로(slow path)” (TLB 미스 시)를 제공하여 평균적인 메모리 접근 시간을 크게 단축시키는지를 잘 보여줍니다. TLB 히트율이 높을수록 시스템 성능은 향상됩니다.","paging-페이징#Paging (페이징)":"Partition physical memory into equal size frames (물리 메모리를 동일한 크기의 프레임으로 분할)\n[한글 번역 및 상세 설명]\n페이징 시스템에서 물리 메모리(RAM)는 **프레임(frame)**이라고 불리는 여러 개의 고정된 크기의 블록으로 나뉩니다.\n물리 메모리 분할: 시스템에 설치된 전체 물리 메모리가 대상입니다. 예를 들어 1GB의 RAM이 있다면, 이 1GB 전체가 프레임들로 나누어집니다. 동일 크기: 모든 프레임의 크기는 같습니다. 이 크기는 페이지의 크기와 정확히 일치하며, 보통 2의 거듭제곱(예: 512바이트, 1KB, 4KB, 2MB 등)으로 정해집니다. 4KB가 현대 시스템에서 흔히 사용되는 크기입니다. 프레임의 역할: 프레임은 프로세스의 페이지가 실제로 저장되는 물리적인 공간 단위입니다. 운영체제는 어떤 프레임이 사용 중이고 어떤 프레임이 비어있는지(가용 프레임 리스트)를 관리합니다. Partition physical memory into equal size frames (물리 메모리를 동일한 크기의 프레임으로 분할) Divide logical memory into same-size pages (논리 메모리를 동일한 크기의 페이지로 분할) [한글 번역 및 상세 설명]\n물리 메모리가 프레임으로 나뉘는 것처럼, 각 프로세스의 논리 주소 공간(logical memory) 역시 **페이지(page)**라고 하는 블록으로 나뉩니다.\n논리 메모리 분할: 프로세스가 실행될 때 가지는 가상적인 주소 공간입니다. 예를 들어 32비트 시스템에서 각 프로세스는 최대 4GB의 논리 주소 공간을 가질 수 있습니다. 이 논리 주소 공간이 페이지들로 나누어집니다. 동일 크기: 페이지의 크기는 프레임의 크기와 정확히 같습니다. 이는 페이지와 프레임 간의 1:1 매핑을 단순화합니다. 만약 프레임 크기가 4KB라면, 페이지 크기도 4KB입니다. 페이지의 역할: 페이지는 프로세스가 사용하는 논리적인 메모리 단위입니다. CPU가 생성하는 주소(논리 주소)는 특정 페이지의 특정 위치를 가리키게 됩니다. Partition physical memory into equal size frames (물리 메모리를 동일한 크기의 프레임으로 분할) Divide logical memory into same-size pages (논리 메모리를 동일한 크기의 페이지로 분할) Each page can go to any free frame (각 페이지는 어떤 가용 프레임으로든 갈 수 있음) [한글 번역 및 상세 설명]\n이것이 페이징의 핵심적인 유연성을 보여주는 부분입니다.\n비연속적 할당: 한 프로세스를 구성하는 여러 페이지들은 물리 메모리 상에서 연속적으로 위치할 필요가 없습니다. 예를 들어, 프로세스 A의 페이지 0은 프레임 10에, 페이지 1은 프레임 3에, 페이지 2는 프레임 25에 저장될 수 있습니다. 가용 프레임 활용: 운영체제는 비어있는 프레임(free frame)의 목록을 유지하고 있다가, 새로운 페이지를 메모리에 적재해야 할 때 이 목록에서 임의의 가용 프레임을 선택하여 할당합니다. 외부 단편화 해결: 이 방식 덕분에, 물리 메모리에 흩어져 있는 작은 빈 공간(프레임 단위)들도 효과적으로 사용할 수 있게 되어 외부 단편화 문제가 발생하지 않습니다. Partition physical memory into equal size frames (물리 메모리를 동일한 크기의 프레임으로 분할) Divide logical memory into same-size pages (논리 메모리를 동일한 크기의 페이지로 분할) Each page can go to any free frame (각 페이지는 어떤 가용 프레임으로든 갈 수 있음) OS knows the mapping (운영체제는 매핑을 알고 있음) page table (페이지 테이블) [한글 번역 및 상세 설명]\n프로세스의 페이지들이 물리 메모리의 프레임들에 흩어져 저장될 수 있기 때문에, 운영체제는 각 논리 페이지가 어느 물리 프레임에 저장되어 있는지를 정확히 추적해야 합니다.\n매핑 정보: 논리적인 페이지 번호(page number)와 이 페이지가 실제 저장된 물리적인 프레임 번호(frame number) 간의 대응 관계를 매핑(mapping)이라고 합니다. 페이지 테이블 (Page Table): 이 매핑 정보를 저장하는 자료구조가 바로 페이지 테이블입니다. 각 프로세스는 자신만의 페이지 테이블을 가집니다. 페이지 테이블은 일반적으로 배열 형태로 구현되며, 배열의 인덱스는 페이지 번호에 해당하고, 해당 인덱스에 저장된 값은 그 페이지가 적재된 프레임 번호입니다. 예를 들어, 페이지 테이블[i] = j 라면, i번 페이지는 j번 프레임에 있다는 의미입니다. 페이지 테이블에는 프레임 번호 외에도 페이지의 유효/무효 비트(valid/invalid bit), 접근 권한 비트(read/write/execute), 수정 여부 비트(dirty bit) 등 다양한 부가 정보가 포함될 수 있습니다. CPU가 논리 주소를 참조할 때, 이 페이지 테이블을 사용하여 해당 논리 주소가 속한 페이지가 어느 프레임에 있는지 알아내고, 이를 통해 최종 물리 주소를 계산합니다.\nPhysical address space of a process can be noncontiguous; process is allocated physical memory whenever the latter is available (프로세스의 물리 주소 공간은 비연속적일 수 있음; 프로세스는 물리 메모리가 가용할 때마다 할당받음) Divide physical memory into fixed-sized blocks called frames (물리 메모리를 프레임이라고 불리는 고정 크기 블록으로 분할) Size is power of 2, between 512 bytes and 16 Mbytes (크기는 2의 거듭제곱이며, 512 바이트에서 16 메가바이트 사이임) Divide logical memory into blocks of same size called pages (논리 메모리를 페이지라고 불리는 동일 크기의 블록으로 분할) Keep track of all free frames (모든 가용 프레임을 추적함) To run a program of size N pages, need to find N free frames and load program (크기가 N 페이지인 프로그램을 실행하려면, N개의 가용 프레임을 찾아 프로그램을 적재해야 함) Set up a page table to translate logical to physical addresses (논리 주소를 물리 주소로 변환하기 위해 페이지 테이블을 설정함) Backing store likewise split into pages (백킹 스토어(보조 기억 장치)도 마찬가지로 페이지 단위로 분할됨) Still have Internal fragmentation (여전히 내부 단편화는 존재함) [한글 번역 및 상세 설명]\n이 슬라이드는 페이징의 주요 특징과 동작 방식을 요약합니다.\n프로세스의 비연속적 물리 주소 공간: 페이징을 사용하면 프로세스가 사용하는 물리 메모리 영역이 한 곳에 모여 있을 필요가 없습니다. 페이지 단위로 흩어져 있는 여러 프레임에 분산되어 저장될 수 있습니다. 이는 메모리가 가용할 때마다(즉, 빈 프레임이 발견될 때마다) 그 프레임에 페이지를 할당할 수 있기 때문입니다. 프레임 (Frames): 물리 메모리는 프레임이라는 고정된 크기의 블록으로 나뉩니다. 크기: 프레임(및 페이지) 크기는 일반적으로 하드웨어적인 이유(주소 계산의 용이성)로 2의 거듭제곱으로 정해집니다. 예를 들어 29=512 바이트, 210=1KB, 212=4KB, 220=1MB, 최대 224=16MB (또는 그 이상)까지 다양할 수 있습니다. 현대 시스템에서는 4KB나 2MB(Huge Page)가 주로 사용됩니다. 페이지 (Pages): 각 프로세스의 논리 주소 공간도 프레임과 동일한 크기의 페이지라는 블록으로 나뉩니다. 가용 프레임 관리: 운영체제는 현재 사용 중이지 않은, 즉 비어있는 모든 프레임의 목록(free-frame list)을 유지하고 관리해야 합니다. 프로세스가 새로운 페이지를 필요로 할 때 이 목록에서 프레임을 할당해줍니다. 프로그램 실행 과정: 크기가 N개의 페이지로 구성된 프로그램을 실행하려면, 운영체제는 먼저 N개의 가용 프레임을 찾아야 합니다. 이 N개의 프레임은 물리 메모리 어디에 있든 상관없습니다 (연속될 필요 없음). 그런 다음 프로그램의 각 페이지를 이 프레임들에 적재(load)합니다. 페이지 테이블 설정: 프로그램 페이지들이 프레임에 적재된 후, 운영체제는 해당 프로세스를 위한 페이지 테이블을 설정합니다. 이 페이지 테이블에는 각 논리 페이지 번호가 어느 물리 프레임 번호에 매핑되는지에 대한 정보가 기록됩니다. 이 테이블은 CPU가 논리 주소를 물리 주소로 변환하는 데 사용됩니다. 백킹 스토어의 페이지화: 페이징은 가상 메모리 시스템과 긴밀하게 연관됩니다. 가상 메모리에서는 현재 사용되지 않는 페이지들을 디스크의 특정 영역인 **백킹 스토어(backing store 또는 swap space)**로 내보낼 수 있습니다(페이지 아웃). 이 백킹 스토어 역시 메모리와 마찬가지로 페이지 크기의 단위로 관리되어, 메모리 페이지를 그대로 디스크에 저장하거나 읽어올 수 있도록 합니다. 내부 단편화 (Internal Fragmentation) 문제 잔존: 😥 페이징은 외부 단편화는 해결하지만, 내부 단편화는 여전히 발생할 수 있습니다. 프로세스의 크기가 페이지 크기의 정확한 배수가 아닐 경우, 마지막 페이지는 완전히 채워지지 않고 일부 공간이 남게 됩니다. 이 남는 공간이 바로 내부 단편화입니다. 예를 들어 페이지 크기가 4KB인데 프로세스의 마지막 부분이 1KB라면, 해당 페이지에는 3KB의 사용되지 않는 공간(내부 단편화)이 발생합니다. 평균적으로 프로세스당 마지막 페이지에서 (페이지 크기 / 2) 만큼의 내부 단편화가 발생할 수 있다고 봅니다.","pcb-tcb#PCB, TCB":"","petersons-solution-의-성립을-위한-필요-가정-skip#Peterson\u0026rsquo;s Solution 의 성립을 위한 필요 가정 [SKIP]":"Peterson’s Solution은 상호 배제(Mutual Exclusion), 진행(Progress), **유한 대기(Bounded Waiting)**라는 세 가지 요구사항을 충족하는 알고리즘이지만, 이는 몇 가지 중요한 가정이 성립할 때만 가능합니다. 이러한 가정이 깨지면 Peterson’s Solution도 요구사항을 충족하지 못할 수 있습니다.\n아래에서 Peterson’s Solution이 요구사항을 충족하기 위한 특정 조건들을 설명하겠습니다.","potential-deadlock#Potential Deadlock":"","problems-문제점#Problems (문제점)":"Large process can’t fit (큰 프로세스는 적재될 수 없습니다) Small process wastes memory (작은 프로세스는 메모리를 낭비합니다)→ Internal fragmentation (내부 단편화) 동일 크기 고정 분할 방식의 문제점을 설명합니다.\n큰 프로세스 적재 불가: 만약 시스템의 파티션 크기가 모두 100KB로 고정되어 있는데, 120KB 크기의 프로세스 P4가 실행을 요청하면, 이 프로세스는 어떤 파티션에도 들어갈 수 없어 실행될 수 없습니다. (그림에서 P4 옆의 X 표시) 작은 프로세스로 인한 메모리 낭비 (내부 단편화): 만약 파티션 크기가 100KB인데, 30KB 크기의 프로세스가 이 파티션에 적재된다면, 나머지 70KB(100KB - 30KB)는 해당 프로세스에 의해 사용되지 않지만, 이미 이 파티션은 할당된 것으로 간주되어 다른 프로세스가 사용할 수 없습니다. 이렇게 할당된 파티션 내부에 사용되지 않고 낭비되는 공간을 **내부 단편화(Internal Fragmentation)**라고 합니다. (그림에서 마지막 두 파티션의 X 표시) 예를 들어 P1이 80KB, P2가 90KB, P3가 70KB이고 파티션 크기가 100KB라면, P1에서는 20KB, P2에서는 10KB, P3에서는 30KB의 내부 단편화가 발생합니다.","process-synchronization#Process Synchronization":"","quiz-퀴즈#Quiz (퀴즈)":"Consider a simple paging system with the following parameters: $2^{32}$ bytes of physical memory; page size of $2^{10}$ bytes; $2^{16}$ pages of logical address space.\n(다음 매개변수를 가진 간단한 페이징 시스템을 고려하십시오: 물리 메모리 $2^{32}$ 바이트; 페이지 크기 $2^{10}$ 바이트; 논리 주소 공간 $2^{16}$ 페이지.)\nHow many bits are in a logical address? (논리 주소는 몇 비트입니까?) How many bytes in a frame? (프레임의 바이트 수는 얼마입니까?) How many bits in the physical address specify the frame? (물리 주소에서 프레임을 지정하는 비트 수는 몇 개입니까?) How many entries in the page table? (페이지 테이블의 항목 수는 몇 개입니까?) [한글 번역 및 상세 설명 및 풀이]\n페이징 시스템의 매개변수를 이해하고 계산하는 퀴즈입니다. 🤓\n주어진 매개변수 분석:\n물리 메모리 크기 = $2^{32}$ 바이트 (이는 4GB에 해당합니다.) 페이지 크기 = $2^{10}$ 바이트 (이는 1KB 또는 1024 바이트에 해당합니다.) 논리 주소 공간의 페이지 수 = $2^{16}$ 페이지 (이는 65,536개의 페이지를 의미합니다.) 풀이:\nHow many bits are in a logical address? (논리 주소는 몇 비트입니까?)\n논리 주소는 페이지 번호(p) 부분과 오프셋(d) 부분으로 구성됩니다.\n오프셋(d) 비트 수: 페이지 크기가 210 바이트이므로, 페이지 내의 특정 바이트를 가리키기 위한 오프셋은 10비트가 필요합니다. (오프셋은 0부터 210−1까지의 값을 가짐) 즉, n = 10 비트. 페이지 번호(p) 비트 수: 논리 주소 공간에 216개의 페이지가 있다고 주어졌습니다. 216개의 서로 다른 페이지를 구분하기 위해서는 16비트가 필요합니다. (페이지 번호는 0부터 216−1까지의 값을 가짐) 즉, m-n = 16 비트. 총 논리 주소 비트 수 (m): 논리 주소 비트 수 = (페이지 번호 비트 수) + (오프셋 비트 수) m=(m−n)+n=16+10=26 비트. 답: 26 비트 How many bytes in a frame? (프레임의 바이트 수는 얼마입니까?)\n페이징 시스템에서 프레임의 크기는 항상 페이지의 크기와 동일합니다.\n주어진 페이지 크기 = $2^{10}$ 바이트. 답: $2^{10}$ 바이트 (또는 1024 바이트) How many bits in the physical address specify the frame? (물리 주소에서 프레임을 지정하는 비트 수는 몇 개입니까?)\n물리 주소도 프레임 번호(f) 부분과 오프셋(d) 부분으로 구성됩니다.\n물리 메모리의 총 프레임 수 계산: 물리 메모리 크기 = $2^{32}$ 바이트. 프레임 크기 = $2^{10}$ 바이트. 총 프레임 수 = (물리 메모리 크기) / (프레임 크기) = $2^{32}\\div2^{10}$=$2^{32 - 10}$=$2^{22}$ 개의 프레임. 프레임 번호(f) 비트 수: $2^{22}$개의 서로 다른 프레임을 구분하기 위해서는 22비트가 필요합니다. (프레임 번호는 0부터 $2^{22}$−1까지의 값을 가짐) 답: 22 비트 (참고: 전체 물리 주소 비트 수는 프레임 번호 비트(22) + 오프셋 비트(10) = 32비트이며, 이는 주어진 물리 메모리 크기 232 바이트와 일치합니다.) How many entries in the page table? (페이지 테이블의 항목 수는 몇 개입니까?)\n페이지 테이블은 프로세스의 각 논리 페이지에 대한 매핑 정보를 담고 있습니다. 따라서 페이지 테이블의 항목(entry) 수는 해당 프로세스가 가질 수 있는 총 논리 페이지의 수와 같습니다.\n주어진 논리 주소 공간의 페이지 수 = $2^{16}$ 페이지. 답: $2^{16}$ 개 (또는 65,536 개)","readers-writers-problem#\u003cstrong\u003eReaders-Writers Problem\u003c/strong\u003e":"좋아요! 주어진 코드는 Readers-Writers Problem 중에서 “first readers-writers problem”, 즉:\nReader 우선 (Readers-preference) 전략입니다.\n즉, 여러 reader가 동시에 읽을 수 있고, writer는 모든 reader가 끝날 때까지 기다려야 합니다.","replacement-algorithm-교체-알고리즘#\u003cstrong\u003eReplacement Algorithm (교체 알고리즘)\u003c/strong\u003e":"","requirements-of-critical-section-prob-중간고사-범위#Requirements of Critical-Section Prob 중간고사 범위":"","resource-allocation-diagram-두-번째#Resource Allocation Diagram (두 번째)":"","resource-allocation-diagram-첫-번째#Resource Allocation Diagram (첫 번째)":"","resource-allocation-graph-algorithm#Resource-Allocation Graph Algorithm":"","resource-allocation-graph-scheme#Resource-Allocation Graph Scheme":"","resource-allocation-graph-visual#Resource-Allocation Graph Visual":"","resource-request-algorithm-for-process-pi#Resource-Request Algorithm for Process Pi​":"","safety-algorithm#Safety Algorithm":"","schematic-view-of-swapping-스와핑의-개략도#Schematic View of Swapping (스와핑의 개략도)":"(Diagram showing: Operating System in Main memory, User Space in Main memory with Process P1. Backing store (disk) with Process P2. Arrows indicating P1 can be swapped out to disk, and P2 can be swapped in to main memory.)\n[설명]\n이 그림은 스와핑의 기본 개념을 간단하게 보여줍니다.\n주 기억장치 (Main memory): 운영체제(OS)가 상주하고 있고, 사용자 공간(User Space)에는 현재 실행 중이거나 실행 대기 중인 프로세스 P1이 적재되어 있습니다. 백킹 스토어 (Backing store, 보통 디스크): 다른 프로세스 P2의 메모리 이미지가 저장되어 있습니다. P2는 현재 메모리에 없지만 실행될 수 있는 상태이거나, 이전에 메모리에서 스왑 아웃된 상태일 수 있습니다. 스왑 아웃 (Swap out): 화살표는 주 기억장치에 있는 프로세스 P1이 백킹 스토어로 이동될 수 있음(스왑 아웃)을 나타냅니다. 이는 P1이 잠시 실행을 멈추거나, 더 높은 우선순위의 프로세스에게 메모리를 양보해야 할 때 발생할 수 있습니다. 스왑 인 (Swap in): 다른 화살표는 백킹 스토어에 있는 프로세스 P2가 주 기억장치로 이동될 수 있음(스왑 인)을 나타냅니다. 이는 P2가 실행될 차례가 되었거나, P1이 스왑 아웃되어 생긴 빈 공간을 활용하기 위함일 수 있습니다. 이러한 스왑 인/아웃 과정을 통해 제한된 주 기억장치를 여러 프로세스가 시간적으로 공유하여 사용할 수 있게 됩니다.","shared-pages-example-공유-페이지-예제#Shared Pages Example (공유 페이지 예제)":"Process P1 page table: ed1-\u003eF3, data1-\u003eF1, ed2-\u003eF4, ed3-\u003eF6 Process P2 page table: ed1-\u003eF3, data2-\u003eF7, ed2-\u003eF4, ed3-\u003eF6 Process P3 page table: ed1-\u003eF3, data3-\u003eF2, ed2-\u003eF4, ed3-\u003eF6 Physical Memory: F1(data1), F2(data3), F3(ed1), F4(ed2), F6(ed3), F7(data2) [한글 번역 및 상세 설명]\n이 다이어그램은 세 개의 프로세스(P1, P2, P3)가 공통된 코드 페이지들을 공유하고, 각자 고유한 데이터 페이지를 가지는 상황을 보여주는 훌륭한 예제입니다. 👨‍👨‍👧‍👦+💾\n시나리오:\n세 개의 프로세스 P1, P2, P3가 동일한 편집기 프로그램(예: vi 또는 emacs)을 사용하고 있다고 가정합니다. 이 편집기 프로그램의 코드는 여러 페이지(예: ed1, ed2, ed3)로 구성되어 있으며, 이 코드는 읽기 전용이고 재진입 가능하다고 가정합니다. 각 프로세스는 편집 작업을 위한 자신만의 데이터(예: P1은 data1, P2는 data2, P3는 data3)를 가지고 있습니다. 다이어그램 해석:\n각 프로세스의 페이지 테이블:\nProcess P1의 페이지 테이블: ed1 (편집기 코드 페이지 1) → 물리 프레임 3 (F3) data1 (P1의 개인 데이터 페이지) → 물리 프레임 1 (F1) ed2 (편집기 코드 페이지 2) → 물리 프레임 4 (F4) ed3 (편집기 코드 페이지 3) → 물리 프레임 6 (F6) Process P2의 페이지 테이블: ed1 (편집기 코드 페이지 1) → 물리 프레임 3 (F3) \u003c– 공유! data2 (P2의 개인 데이터 페이지) → 물리 프레임 7 (F7) ed2 (편집기 코드 페이지 2) → 물리 프레임 4 (F4) \u003c– 공유! ed3 (편집기 코드 페이지 3) → 물리 프레임 6 (F6) \u003c– 공유! Process P3의 페이지 테이블: ed1 (편집기 코드 페이지 1) → 물리 프레임 3 (F3) \u003c– 공유! data3 (P3의 개인 데이터 페이지) → 물리 프레임 2 (F2) ed2 (편집기 코드 페이지 2) → 물리 프레임 4 (F4) \u003c– 공유! ed3 (편집기 코드 페이지 3) → 물리 프레임 6 (F6) \u003c– 공유! 물리 메모리 (Physical Memory):\n프레임 1 (F1)에는 P1의 개인 데이터 data1이 저장됩니다. 프레임 2 (F2)에는 P3의 개인 데이터 data3이 저장됩니다. 프레임 3 (F3)에는 공유 코드 ed1이 단 한 벌만 저장됩니다. P1, P2, P3 모두 이 프레임 3을 참조합니다. 프레임 4 (F4)에는 공유 코드 ed2가 단 한 벌만 저장됩니다. P1, P2, P3 모두 이 프레임 4를 참조합니다. 프레임 6 (F6)에는 공유 코드 ed3가 단 한 벌만 저장됩니다. P1, P2, P3 모두 이 프레임 6을 참조합니다. 프레임 7 (F7)에는 P2의 개인 데이터 data2가 저장됩니다. (프레임 0, 5 등은 다른 용도로 사용되거나 비어있을 수 있습니다.) 핵심 포인트:\n코드 공유: 편집기 코드 페이지들(ed1, ed2, ed3)은 물리 메모리에 각각 단 하나의 복사본만 존재하며 (프레임 3, 4, 6에), 세 프로세스 모두 이 동일한 물리 프레임들을 가리키도록 페이지 테이블이 설정되어 있습니다. 이를 통해 상당한 메모리 공간을 절약합니다. 데이터 분리: 각 프로세스의 개인 데이터 페이지들(data1, data2, data3)은 서로 다른 물리 프레임(프레임 1, 7, 2)에 저장되어, 각 프로세스가 자신만의 데이터를 독립적으로 유지하고 수정할 수 있도록 합니다. 이 예는 페이징이 어떻게 코드 공유를 효율적으로 지원하여 메모리 사용률을 높이는 동시에, 각 프로세스의 데이터 독립성은 보장하는지를 명확하게 보여줍니다.","shared-pages-공유-페이지#Shared Pages (공유 페이지)":"Shared code (공유 코드) One copy of read-only (reentrant) code shared among processes (i.e., text editors, compilers, window systems) (읽기 전용 (재진입 가능) 코드의 한 복사본이 여러 프로세스간에 공유됨 (예: 텍스트 편집기, 컴파일러, 윈도우 시스템)) Similar to multiple threads sharing the same process space (여러 스레드가 동일한 프로세스 공간을 공유하는 것과 유사함) Also useful for interprocess communication if sharing of read-write pages is allowed (읽기/쓰기 페이지의 공유가 허용된다면 프로세스 간 통신에도 유용함) Private code and data (개인 코드 및 데이터) Each process keeps a separate copy of the code and data (각 프로세스는 코드와 데이터의 개별적인 복사본을 유지함) The pages for the private code and data can appear anywhere in the logical address space (개인 코드와 데이터를 위한 페이지들은 논리 주소 공간의 어느 곳에나 나타날 수 있음) [한글 번역 및 상세 설명]\n페이징 시스템의 중요한 장점 중 하나는 메모리를 효율적으로 공유할 수 있다는 것입니다. 🤝\n공유 코드 (Shared Code):\n개념: 여러 프로세스가 동일한 프로그램 코드를 실행할 때 (예: 여러 사용자가 동시에 같은 텍스트 편집기나 웹 브라우저를 실행하는 경우), 해당 프로그램의 코드 부분은 모든 프로세스에 의해 공유될 수 있습니다. 조건: 공유되는 코드는 반드시 **읽기 전용(read-only)**이어야 하며, 실행 중에 스스로를 수정하지 않는 재진입 가능(reentrant) 코드여야 합니다. 재진입 코드는 여러 프로세스(또는 스레드)가 동시에 실행해도 각자의 상태(예: 레지스터 값, 스택 데이터)에만 영향을 미치고 코드 자체는 변경되지 않아 안전하게 공유될 수 있습니다. 구현: 공유 코드의 페이지들은 물리 메모리에 단 한 벌만 적재됩니다. 그리고 이 코드를 사용하는 각 프로세스의 페이지 테이블은 해당 논리 페이지들을 이 동일한 물리 프레임들로 매핑합니다. 예시: 텍스트 편집기, 컴파일러, 라이브러리 루틴(예: 표준 C 라이브러리), 윈도우 시스템의 GUI 코드 등은 여러 프로세스에 의해 공유될 수 있는 대표적인 예입니다. 장점: 메모리를 크게 절약할 수 있습니다. 1MB 크기의 공유 코드를 10개의 프로세스가 사용한다면, 공유하지 않을 경우 10MB가 필요하지만 공유하면 1MB만으로 충분합니다. 스레드와의 유사성: 한 프로세스 내의 여러 스레드들이 부모 프로세스의 주소 공간(코드, 데이터, 힙 등)을 공유하는 것과 유사한 개념입니다. 다만, 공유 페이지는 서로 다른 프로세스들 간의 공유라는 점이 다릅니다. 프로세스 간 통신 (Interprocess Communication, IPC) 수단:\n만약 읽기/쓰기(read-write)가 가능한 페이지를 여러 프로세스가 공유하도록 허용한다면, 이는 매우 효율적인 프로세스 간 통신 수단이 될 수 있습니다 (이를 공유 메모리(shared memory) 기법이라고 합니다). 한 프로세스가 공유 메모리 페이지에 데이터를 쓰면, 다른 공유하는 프로세스들이 즉시 그 변경된 내용을 볼 수 있습니다. 단, 여러 프로세스가 동시에 공유 메모리에 접근하여 데이터를 수정할 수 있으므로, 데이터 일관성을 유지하기 위한 동기화 메커니즘(예: 세마포어, 뮤텍스)이 반드시 필요합니다. 개인 코드 및 데이터 (Private Code and Data):\n일반적으로 각 프로세스는 자신만의 개인적인 코드와 데이터를 가집니다. 개인 데이터: 각 프로세스의 데이터 세그먼트(전역 변수, 정적 변수), 스택 세그먼트(지역 변수, 함수 호출 정보), 힙 세그먼트(동적 할당 메모리) 등은 다른 프로세스와 공유되지 않고 해당 프로세스에게만 고유합니다. 이 페이지들은 각 프로세스마다 별도의 물리 프레임에 할당됩니다. 개인 코드: 코드가 재진입 가능하지 않거나, 프로세스별로 다르게 수정될 수 있는 경우에는 공유되지 않고 각 프로세스가 자신만의 복사본을 가질 수도 있습니다 (흔한 경우는 아님). 이러한 개인 페이지들은 해당 프로세스의 논리 주소 공간 내 어디에든 위치할 수 있으며, 페이지 테이블을 통해 고유한 물리 프레임으로 매핑됩니다. 페이징을 통한 공유는 시스템 자원, 특히 메모리를 매우 효율적으로 사용할 수 있게 해주며, 빠른 프로세스 간 통신 방법도 제공합니다.","slide-15-817#\u003cstrong\u003eSlide 15 (8.17)\u003c/strong\u003e":"","slide-16-818--slide-17-819#\u003cstrong\u003eSlide 16 (8.18) \u0026amp; Slide 17 (8.19)\u003c/strong\u003e":"","slide-6#\u003cstrong\u003eSlide 6\u003c/strong\u003e":"","solutions-해결책은#Solutions? (해결책은?)":"고정 분할 방식(동일 크기든 가변 크기든)의 일반적인 문제점을 다시 한번 요약하고 해결책을 묻고 있습니다.\n활성 프로세스 수 제한: 고정 분할 방식에서는 파티션의 수가 정해져 있기 때문에, 동시에 실행될 수 있는 프로세스의 최대 개수가 이 파티션 수로 제한됩니다. 예를 들어 파티션이 5개라면, 아무리 작은 프로세스들이라도 최대 5개까지만 동시에 메모리에 적재될 수 있습니다. 메모리 공간이 충분히 남아 있더라도 (예: 각 파티션의 내부 단편화로 인해) 더 이상 새로운 프로세스를 받아들일 수 없는 상황이 발생할 수 있습니다. 작은 프로세스들의 비효율적 공간 사용: 특히 동일 크기 고정 분할에서, 파티션 크기보다 훨씬 작은 프로세스들이 많이 실행되면, 각 파티션마다 큰 내부 단편화가 발생하여 전체적인 메모리 사용 효율이 크게 떨어집니다. 가변 크기 고정 분할도 이 문제를 완전히 해결하지는 못합니다. 해결책?: 이러한 고정 분할의 한계를 극복하기 위한 방법으로 다음에 나올 동적 분할, 페이징, 세그먼테이션 등의 기법들이 제시됩니다.","steps-in-handling-a-page-fault#\u003cstrong\u003eSteps in Handling a Page Fault\u003c/strong\u003e":"","swapping-스와핑#Swapping (스와핑)":"A process can be swapped temporarily out of memory to a backing store, and then brought back into memory for continued execution (프로세스는 일시적으로 메모리에서 백킹 스토어로 스왑 아웃되었다가, 계속 실행하기 위해 다시 메모리로 스왑 인될 수 있습니다) Total physical memory space of processes can exceed physical memory (프로세스들의 총 물리 메모리 공간 요구량이 실제 물리 메모리를 초과할 수 있게 함) Backing store – fast disk large enough to accommodate copies of all memory images for all users; must provide direct access to these memory images (백킹 스토어 – 모든 사용자의 모든 메모리 이미지 복사본을 수용할 만큼 충분히 큰 고속 디스크; 이러한 메모리 이미지에 대한 직접 접근을 제공해야 함) Roll out, roll in – swapping variant used for priority-based scheduling algorithms; lower-priority process is swapped out so higher-priority process can be loaded and executed (롤 아웃, 롤 인 – 우선순위 기반 스케줄링 알고리즘에 사용되는 스와핑 변형; 우선순위가 낮은 프로세스가 스왑 아웃되고 우선순위가 높은 프로세스가 적재되어 실행될 수 있도록 함) Major part of swap time is transfer time; total transfer time is directly proportional to the amount of memory swapped (스왑 시간의 주요 부분은 전송 시간임; 총 전송 시간은 스왑되는 메모리 양에 정비례함) System maintains a ready queue of ready-to-run processes which have memory images on disk (시스템은 디스크에 메모리 이미지를 가진, 실행 준비가 된 프로세스들의 준비 큐를 유지함) Does the swapped out process need to swap back in to same physical addresses? (스왑 아웃된 프로세스가 동일한 물리 주소로 다시 스왑 인되어야 하는가?) Depends on address binding method (주소 바인딩 방법에 따라 다름) Plus consider pending I/O to / from process memory space (또한 프로세스 메모리 공간으로/부터의 보류 중인 입출력을 고려해야 함) Modified versions of swapping are found on many systems (i.e., UNIX, Linux, and Windows) (수정된 버전의 스와핑이 많은 시스템(예: UNIX, Linux, Windows)에서 발견됨) Swapping normally disabled (스와핑은 일반적으로 비활성화되어 있음) Started if more than threshold amount of memory allocated (임계치 이상의 메모리가 할당되면 시작됨) Disabled again once memory demand reduced below threshold (메모리 요구량이 임계치 아래로 줄어들면 다시 비활성화됨) [설명]\n스와핑은 물리 메모리보다 더 많은 프로세스를 시스템에서 실행할 수 있도록 하는 고전적인 메모리 관리 기법입니다. 가상 메모리의 초기 형태로 볼 수 있습니다.\n기본 개념: 메모리가 부족할 경우, 현재 메모리에 있는 프로세스 중 일부(또는 전체)를 일시적으로 디스크의 특별한 공간인 **백킹 스토어(backing store)**로 내보내고(swap out), 필요할 때 다시 메모리로 가져와(swap in) 실행을 계속합니다. 이를 통해 물리 메모리의 크기보다 더 큰 총량의 프로세스들이 시스템에 존재할 수 있게 됩니다. 백킹 스토어: 스왑된 프로세스들의 메모리 이미지를 저장하는 공간으로, 충분히 크고 빨라야 합니다 (보통 하드 디스크나 SSD의 특정 파티션 또는 파일). 메모리 이미지에 빠르게 직접 접근(direct access)할 수 있어야 효율적입니다. 롤 아웃, 롤 인 (Roll out, roll in): 스와핑의 한 형태로, 주로 우선순위 기반 스케줄링에서 사용됩니다. 실행 준비가 된 더 높은 우선순위의 프로세스를 위해 현재 실행 중이거나 메모리에 있는 낮은 우선순위의 프로세스를 백킹 스토어로 내보내는(롤 아웃) 방식입니다. 스왑 시간: 스와핑은 디스크 입출력을 동반하므로 시간이 많이 걸립니다. 주된 시간은 메모리 내용을 디스크로 옮기거나 디스크에서 메모리로 옮기는 전송 시간(transfer time)이며, 이는 스왑되는 메모리 양에 비례합니다. 디스크 접근 시간(탐색 시간, 회전 지연 시간)도 추가됩니다. 준비 큐: 스왑 아웃된 프로세스들은 디스크에 메모리 이미지를 가진 채로 준비 큐(ready queue)에서 자신의 차례를 기다릴 수 있습니다. CPU를 할당받기 전에 메모리로 스왑 인되어야 합니다. 재적재 주소 문제: 스왑 아웃되었다가 다시 스왑 인될 때, 반드시 원래의 물리 주소로 돌아와야 할까요? 이는 주소 바인딩 방식에 따라 다릅니다. 컴파일 시간 또는 적재 시간 바인딩: 원래의 물리 주소로 돌아와야 합니다. 그렇지 않으면 주소 참조가 모두 틀어집니다. 실행 시간 바인딩 (MMU 사용): 아무 물리 주소 위치로나 스왑 인될 수 있습니다. MMU가 논리 주소를 새로운 물리 주소로 올바르게 변환해 주기 때문입니다. 현대 시스템은 대부분 이 방식을 사용합니다. 보류 중인 입출력 (Pending I/O): 스왑하려는 프로세스가 현재 입출력 작업을 수행 중이라면 문제가 복잡해집니다. 예를 들어, DMA(Direct Memory Access)를 통해 디스크 컨트롤러가 프로세스의 메모리 영역에 직접 데이터를 쓰고 있는데 이 프로세스가 스왑 아웃되면 데이터가 엉뚱한 곳에 써지거나 유실될 수 있습니다. 해결책으로는, 입출력 작업이 완료될 때까지 해당 프로세스의 스와핑을 금지합니다. 입출력을 항상 운영체제 커널 버퍼를 통해 수행하고, 스왑 시에는 이 커널 버퍼만 주의하면 되도록 합니다. 현대 시스템에서의 스와핑: 초기 운영체제에서는 프로세스 전체를 스왑 인/아웃하는 방식을 많이 사용했지만, 현대의 Windows, Linux, UNIX 같은 시스템에서는 이보다 더 발전된 형태의 페이징 기반 가상 메모리 시스템을 사용합니다. 이러한 시스템에서도 여전히 ‘스와핑’이라는 용어가 사용되는데, 이는 주로 페이지 단위로 메모리와 디스크 간에 데이터가 이동하는 것을 의미합니다(페이지 아웃, 페이지 인). 시스템은 보통 메모리가 매우 부족해지는 특정 임계점(threshold)에 도달할 때까지는 스와핑(페이지 아웃)을 적극적으로 하지 않다가, 임계점을 넘어서면 스와핑을 시작하여 메모리 압박을 해소하려고 시도합니다. 메모리 여유가 다시 생기면 스와핑 빈도를 줄입니다. 스와핑은 다중 프로그래밍의 정도를 높이고 메모리를 유연하게 사용하는 데 기여하지만, 디스크 I/O로 인한 성능 저하가 크다는 단점이 있습니다.","tree-representation-of-buddy-system-버디-시스템의-트리-표현#Tree Representation of Buddy System (버디 시스템의 트리 표현)":"(Diagram showing a binary tree where leaf nodes represent smallest allocatable blocks and parent nodes represent merged blocks)\n[설명]\n버디 시스템은 이진 트리 형태로 표현하고 관리하기 용이합니다.\n루트 노드는 전체 메모리 블록을 나타냅니다. 각 노드가 분할되면 두 개의 자식 노드가 생성되며, 이 두 자식 노드는 서로 버디 관계입니다. 리프 노드는 현재 할당 가능한 가장 작은 단위의 블록이거나, 이미 할당된 블록들을 나타낼 수 있습니다. 트리를 사용하면 특정 크기의 블록을 찾거나, 해제 시 버디를 찾고 합병하는 과정을 효율적으로 수행할 수 있습니다. 예를 들어, 어떤 블록의 주소와 크기를 알면, 그 버디 블록의 주소를 간단한 비트 연산(XOR)으로 계산할 수 있습니다 (블록 크기가 2k이고, 블록 시작 주소가 X일 때, X의 k번째 비트를 반전시키면 버디의 주소를 얻을 수 있는 경우가 많음, 구현에 따라 다름). 이 슬라이드의 그림은 이러한 트리 구조를 시각화하여, 어떤 블록들이 할당되었고 (예: 음영 처리), 어떤 블록들이 가용한지 (예: 빈 노드), 그리고 어떤 블록들이 더 큰 블록으로 합쳐질 수 있는지를 보여줍니다.","types-of-memory-management-메모리-관리-유형#\u003cstrong\u003eTypes of Memory Management (메모리 관리 유형)\u003c/strong\u003e":"Fixed Partitioning (고정 분할) Dynamic Partitioning (동적 분할) Paging (페이징) Segmentation (세그먼테이션) Segmentation with Paging (페이징을 이용한 세그먼테이션) 이 슬라이드는 앞으로 다룰 다양한 메모리 관리 기법의 종류를 나열하고 있습니다. 각 기법은 메모리를 어떻게 나누고, 프로세스에 어떻게 할당하며, 어떤 장단점을 가지는지에 따라 구분됩니다.\n고정 분할: 메모리를 미리 여러 개의 고정된 크기의 구획(파티션)으로 나누어 사용하는 방식입니다. 동적 분할: 프로세스가 요청하는 크기에 맞춰 메모리 구획을 동적으로 할당하는 방식입니다. 페이징: 프로세스의 논리 주소 공간을 동일한 크기의 ‘페이지’로, 물리 메모리를 동일한 크기의 ‘프레임’으로 나누어 관리하는 방식입니다. 세그먼테이션: 프로세스의 논리 주소 공간을 의미 단위인 ‘세그먼트’(예: 코드, 데이터, 스택)로 나누어 관리하는 방식입니다. 페이징을 이용한 세그먼테이션: 세그먼테이션의 장점과 페이징의 장점을 결합한 방식으로, 세그먼트를 다시 페이지 단위로 나누어 관리합니다.","unsafe-state-in-resource-allocation-graph#Unsafe State In Resource-Allocation Graph":"","valid-invalid-bit#\u003cstrong\u003eValid-Invalid Bit\u003c/strong\u003e":"","valid-v-or-invalid-i-bit-in-a-page-table-페이지-테이블-내의-유효v-또는-무효i-비트#Valid (v) or Invalid (i) Bit In A Page Table (페이지 테이블 내의 유효(v) 또는 무효(i) 비트)":"[한글 번역 및 상세 설명]\n이 다이어그램은 페이지 테이블 내의 유효-무효(valid-invalid) 비트가 어떻게 사용되어 메모리 접근을 제어하는지를 보여줍니다. 📄✅❌\n시나리오:\n한 프로세스가 0부터 1MB까지의 논리 주소 공간을 가지고 있다고 가정합니다. 이 논리 주소 공간은 여러 개의 페이지(Page 0, Page 1, …)로 나뉩니다. 이 프로세스를 위한 페이지 테이블이 존재하며, 각 항목은 (프레임 번호, 유효/무효 비트) 쌍으로 구성됩니다. 다이어그램 해석:\n논리 메모리 (Logical memory): 프로세스가 인식하는 주소 공간입니다. 페이지 테이블 (Page Table): 항목 0 (Page 0): 프레임 2에 매핑되어 있고, 유효 비트가 ‘v’ (valid)입니다. 이는 논리 페이지 0이 합법적이며 현재 물리 프레임 2에 적재되어 있음을 의미합니다. 이 페이지에 대한 접근은 허용됩니다. 항목 1 (Page 1): 프레임 3에 매핑, ‘v’. 합법적이고 프레임 3에 적재됨. 항목 2 (Page 2): 프레임 4를 가리키지만 유효 비트가 ‘i’ (invalid)입니다. 이것은 두 가지 경우를 의미할 수 있습니다: 페이지가 디스크에 있음 (페이지 폴트 상황): 논리 페이지 2는 이 프로세스의 합법적인 부분이지만, 현재 물리 메모리에 없고 디스크(백킹 스토어)에 스왑 아웃(또는 페이지 아웃)되어 있을 수 있습니다. 이 페이지에 접근하려고 하면 **페이지 폴트(page fault)**라는 트랩이 발생합니다. 운영체제는 이 트랩을 처리하여 페이지 2를 디스크에서 비어있는 프레임(예: 프레임 4 또는 다른 프레임)으로 가져온 후, 페이지 테이블 항목을 (새 프레임 번호, ‘v’)로 갱신하고, 중단되었던 명령어를 다시 실행시킵니다. 페이지가 합법적이지 않음 (세그멘테이션 폴트 상황): 논리 페이지 2가 이 프로세스가 사용하도록 허가된 논리 주소 공간의 일부가 아닐 수도 있습니다. (예: 프로세스가 실제로 페이지 0, 1, 3, 5만 사용하고 페이지 2, 4는 사용하지 않는 경우). 이 경우, 접근 시도 시 메모리 보호 위반으로 간주되어 트랩(예: 세그멘테이션 폴트)이 발생하고 프로세스가 종료될 수 있습니다. (다이어그램에서 프레임 4는 물리 메모리에서 “unused or for other process\"로 표시되어 있으므로, 페이지 폴트 상황보다는 후자의 경우, 즉 페이지 2가 이 프로세스에게 할당되지 않은 논리 영역임을 암시할 수 있습니다. 또는, 프레임 4가 현재 비어있어서 페이지 2가 디스크에서 로드될 수 있는 대상 프레임일 수도 있습니다.) 항목 3 (Page 3): 프레임 7에 매핑, ‘v’. 합법적이고 프레임 7에 적재됨. 항목 4 (Page 4): 프레임 8을 가리키지만 ‘i’. 항목 2와 유사한 상황입니다. 항목 5 (Page 5): 프레임 9에 매핑, ‘v’. 합법적이고 프레임 9에 적재됨. 물리 메모리 (Physical Memory): 페이지 테이블에서 ‘v’로 표시된 페이지들이 실제 프레임에 어떻게 적재되어 있는지를 보여줍니다. 프레임 2에는 페이지 0이, 프레임 3에는 페이지 1이, 프레임 7에는 페이지 3이, 프레임 9에는 페이지 5가 들어있습니다. 프레임 4와 프레임 8은 현재 비어 있거나 다른 프로세스가 사용 중일 수 있습니다. (‘i’로 표시된 페이지들이 가리키는 프레임 번호는 페이지 폴트 시 재활용될 수 있는 후보이거나, 단순히 이전 정보일 수 있습니다.) 유효-무효 비트의 역할 요약:\n메모리 보호: 프로세스가 자신의 논리 주소 공간을 벗어나는 페이지에 접근하는 것을 방지합니다. 가상 메모리 지원: 페이지가 현재 물리 메모리에 있는지(valid), 아니면 디스크에 있는지(invalid, 페이지 폴트 유발)를 나타내는 데 사용됩니다. 이를 통해 실제 물리 메모리 크기보다 더 큰 논리 주소 공간을 사용할 수 있게 됩니다. 유효-무효 비트는 PTLR과 함께, 그리고 다른 보호 비트들(읽기/쓰기/실행)과 함께 강력한 메모리 보호 및 관리 체계를 구성합니다.","varied-size-fixed-partitioning-가변-크기-고정-분할#\u003cstrong\u003eVaried-Size Fixed Partitioning (가변 크기 고정 분할)\u003c/strong\u003e":"고정 분할 방식의 또 다른 형태로 ‘가변 크기 고정 분할’을 소개합니다. (슬라이드에는 상세 설명이 없지만, 일반적인 개념을 설명합니다.)\n가변 크기 고정 분할 (Unequal-size fixed partitioning): 시스템이 시작될 때 전체 메모리를 서로 다른 크기를 가진 여러 개의 파티션으로 미리 나누어 놓습니다. 예를 들어 1000KB 메모리를 50KB, 100KB, 150KB, 300KB, 400KB 크기의 파티션들로 나눌 수 있습니다. 장점: 동일 크기 분할 방식에 비해 다양한 크기의 프로세스들을 좀 더 유연하게 수용할 수 있습니다. 큰 프로세스는 큰 파티션에, 작은 프로세스는 작은 파티션에 할당함으로써 내부 단편화를 줄이려는 시도입니다. 단점: 여전히 고정된 분할이므로, 아무리 작은 프로세스라도 가장 작은 파티션보다 크면 적재될 수 없을 수도 있고, 큰 파티션에 작은 프로세스가 들어가면 내부 단편화는 여전히 발생합니다. 파티션의 크기와 개수를 미리 정해야 하므로, 시스템 관리자가 향후 실행될 프로세스들의 크기 분포를 예측해야 하는 부담이 있습니다. 프로세스를 어떤 파티션에 할당할 것인지 결정하는 정책이 필요합니다 (예: 각 프로세스를 수용할 수 있는 가장 작은 파티션에 할당). Problems with Fixed Partitions (고정 분할의 문제점)\nThe number of active processes is limited by the system (to the pre-determined number of partitions) (활성 프로세스의 수는 시스템에 의해 (미리 결정된 파티션 수만큼으로) 제한됩니다) A large number of very small process will not use space efficiently (매우 작은 프로세스가 다수 존재할 경우 공간을 효율적으로 사용하지 못합니다)","virtual-memory#virtual memory":"","virtual-memory-that-is-larger-than-physical-memory#\u003cstrong\u003eVirtual Memory That is Larger Than Physical Memory\u003c/strong\u003e":"","what-happens-if-there-is-no-free-frame#\u003cstrong\u003eWhat Happens if There is no Free Frame?\u003c/strong\u003e":"","write-policy-쓰기-정책#\u003cstrong\u003eWrite Policy (쓰기 정책)\u003c/strong\u003e":"","가상-메모리-논리-메모리와-물리-메모리의-분리#\u003cstrong\u003e가상 메모리: 논리 메모리와 물리 메모리의 분리\u003c/strong\u003e":"가상 메모리의 가장 근본적인 아이디어는 **‘사용자 프로그램이 바라보는 메모리(논리 메모리)와 실제 하드웨어 메모리(물리 메모리)를 분리하는 것’**입니다.\n과거의 컴퓨터 시스템에서는 프로그램이 실행되려면 전체 코드가 물리적인 RAM(Random Access Memory)에 모두 올라가야 했습니다. 이는 여러 가지 제약을 낳았습니다. 첫째, 프로그램의 크기가 물리 메모리의 크기보다 클 수 없었습니다. 512MB의 RAM을 가진 컴퓨터에서는 1GB 크기의 프로그램을 실행할 수 없었습니다. 둘째, 여러 프로그램을 동시에 실행하는 다중 프로그래밍 환경에서 메모리 공간을 나누어 사용하는 것이 매우 비효율적이었습니다. 모든 프로그램의 전체 코드를 메모리에 올려야 했기 때문에 동시에 실행할 수 있는 프로그램의 수가 제한되었습니다.\n가상 메모리는 이러한 문제를 해결하기 위해 등장했습니다. 가상 메모리 시스템에서 프로그램은 ‘논리 주소 공간(Logical Address Space)‘이라는 자신만의 독립적인 메모리 공간을 가집니다. 이 공간은 0번지부터 시작하는 연속적인 주소로 구성되어 있으며, 프로그래머는 이 논리 주소 공간만을 고려하여 프로그램을 작성합니다. 예를 들어, 32비트 CPU 환경에서는 각 프로세스(실행 중인 프로그램)가 $2^{32}$바이트, 즉 4GB에 달하는 거대한 논리 주소 공간을 가질 수 있습니다.\n중요한 점은 이 논리 주소 공간이 실제 물리 메모리(RAM)와 직접적으로 연결되지 않는다는 것입니다. 대신, 운영 체제와 CPU의 하드웨어 지원 유닛인 **MMU(Memory Management Unit, 메모리 관리 장치)**가 중간에서 이 둘을 연결하는 다리 역할을 합니다. MMU는 프로그램이 사용하는 논리 주소(가상 주소)를 실제 물리 메모리의 주소로 실시간으로 변환해줍니다. 이 변환 과정 덕분에 프로그램은 실제 메모리가 어떻게 구성되어 있는지, 다른 프로그램과 어떻게 공간을 나누어 쓰고 있는지 전혀 신경 쓸 필요가 없습니다. 즉, 각 프로그램은 4GB의 메모리를 독차지하고 있는 것처럼 착각하게 됩니다.\n이러한 **‘분리’**는 두 가지 핵심적인 이점을 가져옵니다.\n메모리 보호: 각 프로세스는 자신만의 독립적인 논리 주소 공간을 가지므로, 한 프로세스가 다른 프로세스의 메모리 영역을 침범할 수 없습니다. 운영 체제는 MMU를 통해 각 프로세스가 할당된 주소 범위 내에서만 메모리에 접근하도록 통제할 수 있어 시스템의 안정성이 크게 향상됩니다. 메모리 효율성 증대: 프로그램의 모든 부분이 물리 메모리에 올라올 필요가 없어집니다. 이는 다음 항목에서 더 자세히 설명됩니다.","가상-메모리의-구현-방식#\u003cstrong\u003e가상 메모리의 구현 방식\u003c/strong\u003e":"슬라이드에서는 가상 메모리를 구현하는 두 가지 주요 기법을 언급합니다.\n요구 페이징 (Demand Paging): 가상 메모리를 구현하는 가장 보편적인 방법입니다. 이 방식에서는 논리 주소 공간과 물리 메모리를 모두 ‘페이지(Page)‘와 ‘프레임(Frame)‘이라는 고정된 크기의 블록으로 나눕니다. 논리 주소 공간의 블록을 페이지라 하고, 물리 메모리의 블록을 프레임이라 합니다. 페이지와 프레임의 크기는 보통 동일합니다(예: 4KB). 메모리 관리는 이 페이지 단위로 이루어지며, 필요한 페이지만 디스크에서 메모리의 비어있는 프레임으로 ‘요구될 때’ 가져옵니다.\n요구 세그먼테이션 (Demand Segmentation): 세그먼테이션은 메모리를 고정 크기가 아닌, 논리적인 의미를 가지는 가변 크기의 ‘세그먼트(Segment)’ 단위로 나눕니다. 예를 들어, 프로그램은 코드 세그먼트, 데이터 세그먼트, 스택 세그먼트 등으로 나뉠 수 있습니다. 요구 세그먼테이션은 이러한 세그먼트 단위로 메모리 적재 여부를 결정합니다. 즉, 특정 세그먼트가 필요할 때 해당 세그먼트 전체를 메모리로 가져옵니다.\n현대의 대부분 운영 체제(Windows, Linux, macOS 등)는 페이징 기법을 기본으로 사용하며, 일부 시스템에서는 페이징과 세그먼테이션을 결합한 하이브리드 방식을 사용하기도 합니다. 그러나 가상 메모리 논의의 중심에는 항상 요구 페이징이 있습니다.","가정#가정":"비영속적 실행(Nonzero Speed):\n모든 프로세스는 반드시 실행되며, 정지된 상태로 남아 있지 않음을 의미한다. 상대적 속도에 대한 가정 없음:\n프로세스들의 실행 속도는 서로 다를 수 있으며, 특정 프로세스가 항상 더 빠르거나 느리다고 가정하지 않는다. 이는 실제 운영 체제 환경에서 다양한 요인(예: CPU 스케줄링, 우선순위 등)에 의해 프로세스 속도가 달라질 수 있기 때문이다.","결론#결론":"임계구역 문제의 세 가지 요구사항은 공유 자원에 대한 안전하고 효율적이며 공정한 접근을 보장하기 위해 설계되었다. 이를 통해 다중 프로세스 환경에서 데이터 일관성을 유지하면서도 성능과 공정성을 균형 있게 관리할 수 있다.\n핵심 메시지:\n임계구역 문제를 해결하기 위해서는 상호 배제, 진행, 유한 대기라는 세 가지 요구사항을 모두 충족해야 하며, 이는 운영 체제와 분산 시스템에서 매우 중요한 개념이다.","결론-1#\u003cstrong\u003e결론\u003c/strong\u003e":"Peterson’s Solution은 상호 배제, 진행, 유한 대기라는 세 가지 요구사항을 모두 충족하는 완벽한 해결책입니다. 이는 단순하면서도 강력한 알고리즘으로, 다중 프로세스 환경에서 안전하고 효율적인 공유 자원 관리를 가능하게 합니다.\n핵심 메시지:\n임계구역 문제를 해결하기 위해서는 세 가지 요구사항을 모두 충족해야 하며, Peterson’s Solution은 이를 달성하는 대표적인 방법입니다.","결론-2#\u003cstrong\u003e결론\u003c/strong\u003e":"Peterson’s Solution이 상호 배제, 진행, 유한 대기를 보장하기 위해서는 다음 조건들이 충족되어야 합니다:\n메모리 모델: 메모리 연산이 원자적이고 순차적 일관성을 갖는다. 비선점성: 프로세스가 중단되지 않고 자신의 코드를 완료할 수 있다. 캐시 일관성: 다중 프로세서 환경에서도 모든 프로세서가 동일한 메모리 상태를 관찰한다. 프로세스 신뢰성: 프로세스가 무한히 실행되며 고장 나지 않는다. 프로세스 수 제한: 두 개의 프로세스만 지원한다. 이러한 조건들이 충족되지 않으면 Peterson’s Solution도 요구사항을 충족하지 못할 수 있습니다. 따라서 실제 운영 체제나 분산 시스템에서는 더 복잡한 동기화 기법(Hardware Locks, Semaphores, Monitors 등)을 사용하여 이러한 문제를 해결합니다.","결론-3#\u003cstrong\u003e결론\u003c/strong\u003e":"이 예시들을 통해 FIFO 페이지 교체 알고리즘은 구현은 매우 간단하지만, 페이지의 실제 사용 패턴을 전혀 고려하지 않기 때문에 최적 알고리즘에 비해 훨씬 많은 페이지 폴트를 발생시킬 수 있음을 알 수 있습니다. 특히, 자주 사용되는 페이지라도 단지 오래되었다는 이유만으로 교체될 수 있다는 점과 벨레이디의 모순 발생 가능성은 FIFO 알고리즘의 주요 약점입니다. 슬라이드 8.18과 8.19는 보통 이러한 과정을 시각적인 다이어그램으로 표현하여, 페이지들이 프레임에 들어오고 나가는 순서와 그에 따른 큐의 변화를 명확하게 보여줌으로써 FIFO 알고리즘의 동작 방식을 쉽게 이해하도록 돕습니다. 이러한 시뮬레이션은 알고리즘의 장단점을 파악하고 다른 알고리즘과 비교 평가하는 데 유용합니다.","교착-상태-문제-the-deadlock-problem#교착 상태 문제 (The Deadlock Problem)":"원문 (Original Text):\nThe Deadlock Problem  A set of blocked processes each holding a resource and waiting to acquire a resource held by another process in the set  Example  System has 2 disk drives  P1 and P2 each hold one disk drive and each needs another one 번역 (Translation):\n교착 상태 문제  각 프로세스가 자원을 보유한 채 다른 프로세스가 보유한 자원을 얻기 위해 대기하면서 봉쇄된 프로세스들의 집합  예시  시스템에 2개의 디스크 드라이브가 있음  P1과 P2는 각각 하나의 디스크 드라이브를 보유하고 있으며, 각각 다른 디스크 드라이브를 필요로 함 매우 자세한 설명 (Detailed Explanation):\n**교착 상태(Deadlock)**란 다중 프로그래밍 환경에서 두 개 이상의 프로세스가 특정 자원을 할당받은 상태에서 다른 프로세스가 점유하고 있는 자원을 서로 기다릴 때, 결과적으로 어떠한 프로세스도 더 이상 진행할 수 없는 무한 대기 상태에 빠지는 현상을 의미합니다. 🚦 이 슬라이드는 교착 상태의 기본적인 정의와 간단한 예시를 통해 그 개념을 소개하고 있습니다.\n핵심 정의: “A set of blocked processes each holding a resource and waiting to acquire a resource held by another process in the set.”\n이 문장을 분석해보면 교착 상태의 핵심 요소를 파악할 수 있습니다.\nA set of blocked processes (봉쇄된 프로세스들의 집합): 교착 상태는 단일 프로세스가 아닌, 여러 프로세스들 간의 상호작용에서 발생합니다. 이 프로세스들은 ‘봉쇄(blocked)’ 또는 ‘대기(waiting)’ 상태에 있게 되는데, 이는 다음 단계로 진행하기 위해 필요한 특정 조건을 만족하지 못해 실행을 일시적으로 멈춘 상태를 의미합니다. Each holding a resource (각각 자원을 보유): 교착 상태에 빠진 각 프로세스는 최소 하나 이상의 자원을 이미 점유하고 있습니다. 이 자원은 해당 프로세스가 다음 작업을 수행하기 위해 필요한 요소입니다. Waiting to acquire a resource held by another process in the set (집합 내 다른 프로세스가 보유한 자원을 얻기 위해 대기): 이것이 교착 상태의 핵심적인 순환적 대기 관계를 나타냅니다. 프로세스 A는 프로세스 B가 가진 자원을 기다리고, 동시에 프로세스 B는 프로세스 A가 가진 자원(또는 다른 교착 상태 집합 내 프로세스가 가진 자원)을 기다리는 상황이 발생하는 것입니다. 예시 분석: “System has 2 disk drives. P1 and P2 each hold one disk drive and each needs another one.”\n이 예시는 교착 상태 발생 과정을 매우 간단명료하게 보여줍니다.\n시스템 환경:\n사용 가능한 자원: 2개의 디스크 드라이브 (Disk Drive 1, Disk Drive 2) 프로세스: P1, P2 상황 전개:\n자원 할당:\n프로세스 P1이 Disk Drive 1을 할당받아 사용 중입니다. (P1 holds Disk Drive 1) 프로세스 P2가 Disk Drive 2를 할당받아 사용 중입니다. (P2 holds Disk Drive 2) 이 시점까지는 시스템에 문제가 없습니다. 각 프로세스는 필요한 자원 중 일부를 확보했습니다. 추가 자원 요청:\n프로세스 P1은 작업을 완료하기 위해 추가적으로 Disk Drive 2를 필요로 합니다. 하지만 Disk Drive 2는 현재 P2가 보유하고 있습니다. 따라서 P1은 P2가 Disk Drive 2를 놓아줄 때까지 대기 상태에 들어갑니다. (P1 waits for Disk Drive 2) 프로세스 P2도 마찬가지로 작업을 완료하기 위해 추가적으로 Disk Drive 1을 필요로 합니다. 하지만 Disk Drive 1은 현재 P1이 보유하고 있습니다. 따라서 P2는 P1이 Disk Drive 1을 놓아줄 때까지 대기 상태에 들어갑니다. (P2 waits for Disk Drive 1) 교착 상태 발생:\n결과적으로 P1은 P2를 기다리고, P2는 P1을 기다리는 순환 대기(Circular Wait) 상황이 발생합니다. 두 프로세스 모두 자신이 원하는 자원을 얻을 수 없으므로 영원히 대기하게 되며, 시스템은 더 이상 이 두 프로세스와 관련된 작업을 진행시키지 못합니다. 이것이 바로 교착 상태입니다.\n이러한 교착 상태는 시스템의 성능 저하를 초래하고, 심한 경우 시스템 전체가 멈추는 결과를 가져올 수 있으므로 운영체제는 교착 상태를 예방하거나, 회피하거나, 혹은 탐지하고 회복하는 메커니즘을 가져야 합니다. 이 예시는 교착 상태가 발생하는 가장 기본적인 시나리오를 보여주며, 이후 슬라이드에서 설명될 교착 상태의 발생 조건, 표현 방법, 해결책 등을 이해하는 데 기초가 됩니다. 이 간단한 예시만으로도 교착 상태의 네 가지 필요조건(상호 배제, 점유와 대기, 비선점, 환형 대기) 중 일부가 암시적으로 나타나고 있음을 알 수 있습니다 (예: 디스크 드라이브는 한 번에 한 프로세스만 사용 가능 - 상호 배제, 각 프로세스가 하나를 점유한 채 다른 것을 요구 - 점유와 대기).","교착-상태-예방-deadlock-prevention#교착 상태 예방 (Deadlock Prevention)":"원문 (Original Text):\nDeadlock Prevention 7.13 Silberschatz, Galvin and Gagne ©2009Operating System Concepts – 8th Edition 13 Idea: invalidate one of the deadlock conditions 1. Invalidate Mutual exclusion condition 2. Invalidate Hold-and-wait condition 3. Invalidate No preemption condition 4. Invalidate Circular wait condition 번역 (Translation):\n교착 상태 예방 7.13 Silberschatz, Galvin and Gagne ©2009 운영체제 개념 – 제8판 13 아이디어: 교착 상태 조건 중 하나를 무효화시킴 1. 상호 배제 조건 무효화 2. 점유와 대기 조건 무효화 3. 비선점 조건 무효화 4. 환형 대기 조건 무효화 매우 자세한 설명 (Detailed Explanation):\n이 슬라이드는 교착 상태 처리 전략 중 하나인 **교착 상태 예방(Deadlock Prevention)**의 핵심 아이디어와 접근 방법을 소개합니다. 💡 교착 상태 예방은 교착 상태가 발생하기 위한 네 가지 필수 조건(상호 배제, 점유와 대기, 비선점, 환형 대기) 중 적어도 하나를 시스템 설계 단계에서부터 원천적으로 제거함으로써 교착 상태 발생 가능성을 완전히 없애는 방법입니다.\n핵심 아이디어 (Idea: invalidate one of the deadlock conditions):\n교착 상태는 네 가지 조건이 모두 동시에 만족될 때만 발생합니다. 따라서 이 네 가지 조건 중 단 하나라도 만족되지 않도록 시스템을 구성하면 교착 상태는 이론적으로 발생할 수 없습니다. 이는 마치 특정 질병의 발병 원인 중 하나를 제거하여 질병 발생 자체를 막는 것과 유사한 접근 방식입니다.\n운영체제 설계자는 다음 네 가지 조건 각각에 대해 이를 어떻게 무효화(invalidate)하거나 약화시킬 수 있는지 고려하여 예방 전략을 수립합니다.\n1. 상호 배제 조건 무효화 (Invalidate Mutual exclusion condition):\n목표: 자원이 본질적으로 공유 불가능(non-sharable)하지 않다면, 즉 여러 프로세스가 동시에 접근해도 문제가 없다면 상호 배제를 적용하지 않는 것입니다. 방법: 자원의 공유화: 가능한 많은 자원을 공유 가능하게 만듭니다. 예를 들어, 읽기 전용(read-only) 파일은 여러 프로세스가 동시에 읽을 수 있도록 허용하여 상호 배제를 피할 수 있습니다. 스풀링(Spooling): 프린터와 같이 본질적으로 한 번에 하나의 프로세스만 사용해야 하는 자원의 경우, 직접적인 자원 접근 대신 스풀링 기법을 사용합니다. 프로세스는 출력을 프린터에 직접 보내는 대신, 디스크의 특별한 스풀 디렉토리에 출력 내용을 파일로 저장합니다. 그러면 프린터 데몬(daemon)이라는 시스템 프로세스만이 이 스풀 디렉토리에 접근하여 순차적으로 파일들을 실제 프린터로 전송합니다. 이렇게 하면 여러 사용자 프로세스 입장에서는 프린터를 동시에 사용하는 것처럼 보이지만, 실제 물리적 프린터 자원은 프린터 데몬에 의해서만 배타적으로 사용되므로 사용자 프로세스 간의 교착 상태는 발생하지 않습니다 (프린터 데몬과 다른 시스템 자원 간의 교착은 별개 문제). 한계: 모든 자원이 공유 가능하거나 스풀링 가능한 것은 아닙니다. 예를 들어, 특정 데이터 구조를 수정하는 연산은 반드시 상호 배제가 필요합니다. 따라서 상호 배제 조건을 완전히 제거하는 것은 현실적으로 어렵거나 불가능한 경우가 많습니다. 2. 점유와 대기 조건 무효화 (Invalidate Hold-and-wait condition):\n목표: 프로세스가 하나의 자원을 점유한 상태에서 다른 자원을 기다리지 못하도록 하는 것입니다. 방법: 방법 A (일괄 요청): 프로세스가 실행을 시작하기 전에 필요한 모든 자원을 한꺼번에 요청하도록 강제합니다. 만약 요청한 모든 자원을 할당받을 수 있을 때만 작업을 시작하고, 그렇지 않으면 모든 자원을 할당받을 수 있을 때까지 대기합니다. 일단 자원을 할당받으면, 다른 자원을 추가로 요청하기 전까지는 이 자원들을 점유하고 사용할 수 있습니다. 방법 B (자원 반납 후 요청): 프로세스가 새로운 자원을 요청하기 전에 현재 점유하고 있는 모든 자원을 일단 반납(release)하도록 합니다. 그리고 필요한 모든 자원(기존에 사용하던 자원 포함)을 다시 한꺼번에 요청합니다. 한계: 프로세스가 실행 초기에 앞으로 필요한 모든 자원을 예측하기 어려울 수 있습니다. 자원을 미리 할당받아 두면, 당장 사용하지 않는 자원들이 오랫동안 묶여 있게 되어 자원 활용률이 매우 낮아집니다 (low resource utilization). 다른 많은 프로세스들이 소수의 프로세스 때문에 자원을 사용하지 못하고 **기아 상태(starvation)**에 빠질 수 있습니다. 방법 B의 경우, 자원을 반납했다가 다시 요청하는 과정에서 비효율이 발생할 수 있고, 이전에 사용하던 자원을 다시 할당받지 못할 수도 있습니다. 3. 비선점 조건 무효화 (Invalidate No preemption condition):\n목표: 이미 할당된 자원을 점유 중인 프로세스로부터 강제로 빼앗아(선점하여) 다른 프로세스에게 할당할 수 있도록 허용하는 것입니다. 방법: 방법 A: 어떤 프로세스가 자원을 요청했을 때 즉시 할당받을 수 없다면(즉, 대기해야 한다면), 그 프로세스가 현재 점유하고 있는 모든 자원을 강제로 반납시킵니다. 이 선점된 자원들은 필요한 다른 프로세스에게 할당될 수 있습니다. 해당 프로세스는 자신이 요청한 새로운 자원과 이전에 점유했다가 선점당한 자원들을 모두 얻을 수 있을 때 다시 작업을 시작합니다. 방법 B: 높은 우선순위의 프로세스가 낮은 우선순위의 프로세스가 점유한 자원을 필요로 할 때, 낮은 우선순위 프로세스로부터 자원을 빼앗아 높은 우선순위 프로세스에게 할당합니다. 한계: 모든 자원에 대해 선점을 적용하기는 어렵습니다. 예를 들어, 프린터로 인쇄 중인 작업을 중간에 선점하면 처음부터 다시 인쇄해야 하거나 데이터가 손상될 수 있습니다. 상태를 쉽게 저장하고 복원할 수 있는 자원(예: CPU, 메모리)에 대해서는 비교적 적용하기 쉽습니다. 선점과 복구 과정에 대한 비용과 복잡성이 클 수 있습니다. 작업의 일관성을 유지하기 어려울 수 있습니다. 4. 환형 대기 조건 무효화 (Invalidate Circular wait condition):\n목표: 프로세스들이 원형으로 자원을 기다리는 상황 자체를 방지하는 것입니다. 방법: 자원 순서화 (Resource ordering/hierarchy): 모든 자원 유형에 고유한 번호(순서)를 할당합니다. 그리고 모든 프로세스는 반드시 이 번호의 오름차순(또는 내림차순)으로만 자원을 요청하도록 강제합니다. 예를 들어, 자원 Ri​를 점유한 프로세스가 자원 Rj​를 요청하려면 반드시 j\u003ei (오름차순의 경우)여야 합니다. 이렇게 하면 P1​이 Ri​를 점유하고 Rj​ (j\u003ei)를 기다리고, P2​가 Rj​를 점유하고 Rk​ (k\u003ej)를 기다리는 식으로는 진행될 수 있지만, Pn​이 Rx​를 점유하고 P1​이 점유한 Ry​ (y","교착-상태-처리-dealing-with-deadlock#교착 상태 처리 (Dealing with Deadlock)":"원문 (Original Text):\nDealing with Deadlock  Three general approaches exist for dealing with deadlock.  Prevent deadlock  Avoid deadlock  Detect Deadlock 번역 (Translation):\n교착 상태 처리  교착 상태를 처리하는 세 가지 일반적인 접근 방식이 존재함.  교착 상태 예방 (Prevent deadlock)  교착 상태 회피 (Avoid deadlock)  교착 상태 탐지 (Detect Deadlock) 매우 자세한 설명 (Detailed Explanation):\n이 슬라이드는 운영체제가 교착 상태(Deadlock)라는 까다로운 문제에 대처하기 위해 사용할 수 있는 세 가지 주요 전략을 소개합니다. 🛡️ 시스템 설계자나 관리자는 시스템의 특성과 요구 사항에 따라 이 중 하나 또는 조합을 선택하여 적용할 수 있습니다. 경우에 따라서는 교착 상태를 무시하는 네 번째 접근 방식도 언급되기도 합니다(특히 교착 발생 빈도가 매우 낮고, 처리 비용이 더 클 경우).\n1. 교착 상태 예방 (Prevent Deadlock):\n개념: 교착 상태가 발생하기 위한 네 가지 필요조건(상호 배제, 점유와 대기, 비선점, 환형 대기) 중 어느 하나라도 처음부터 성립하지 않도록 시스템을 설계하는 방식입니다. 마치 질병을 예방하기 위해 미리 백신을 맞는 것과 유사합니다. 목표: 교착 상태가 절대로 발생하지 않도록 보장하는 것입니다. 방법: 상호 배제 조건 부정 (예: 스풀링을 통해 공유 가능하게 만듦) 점유와 대기 조건 부정 (예: 프로세스 시작 시 모든 자원 한 번에 요청 또는 자원 요청 전 기존 자원 모두 반납) 비선점 조건 부정 (예: 자원 강제 회수 허용 - 어렵거나 부작용이 클 수 있음) 환형 대기 조건 부정 (예: 자원에 순서를 부여하여 순서대로만 요청하도록 강제) 장점: 교착 상태가 발생할 가능성 자체를 원천적으로 차단합니다. 단점: 각 조건을 부정하기 위한 제약들이 때로는 자원 활용률(resource utilization)을 심각하게 저하시킬 수 있습니다. 예를 들어, 모든 자원을 미리 요청해야 한다면, 당장 사용하지 않을 자원까지 미리 확보해야 하므로 다른 프로세스가 그 자원을 사용하지 못하게 됩니다. 시스템 처리율(throughput)이 감소할 수 있고, 프로세스의 응답 시간이 길어질 수 있습니다. 어떤 조건(예: 상호 배제)은 특정 자원의 본질적인 특성상 제거하기 어려울 수 있습니다. 2. 교착 상태 회피 (Avoid Deadlock):\n개념: 프로세스가 자원을 요청할 때, 시스템은 해당 요청을 승인할 경우 장래에 교착 상태를 유발할 가능성이 있는지(unsafe state로 이어지는지)를 미리 검사합니다. 만약 교착 가능성이 있다면 요청을 승인하지 않고 프로세스를 대기시킵니다. 이는 마치 운전 중 위험한 교차로에 진입하기 전에 교통 상황을 확인하고 안전할 때만 진입하는 것과 유사합니다. 목표: 시스템이 항상 **안전 상태(safe state)**를 유지하도록 하여 교착 상태를 피해가는 것입니다. 안전 상태란 시스템이 각 프로세스에게 자원을 할당할 수 있는 순서(safe sequence)가 존재하여 모든 프로세스가 교착 없이 종료될 수 있는 상태를 의미합니다. 방법: 프로세스는 시작 시 자신이 앞으로 사용할 최대 자원 요구량을 미리 운영체제에 알려야 합니다. 운영체제는 자원 할당 시마다 Banker’s 알고리즘과 같은 알고리즘을 사용하여, 할당 후에도 시스템이 안전 상태를 유지할 수 있는지 검사합니다. 장점: 예방보다 덜 엄격한 조건을 적용하므로 자원 활용률이 더 높을 수 있습니다. 교착 상태 발생을 막으면서도 예방보다는 유연합니다. 단점: 프로세스가 필요한 최대 자원량을 미리 알아야 한다는 제약이 있습니다. (실행 중에 필요한 자원이 동적으로 변하는 경우가 많음) 새로운 프로세스가 시스템에 추가되거나 종료될 때마다, 그리고 자원 요청/해제 시마다 안전성 검사를 수행해야 하므로 상당한 오버헤드가 발생할 수 있습니다. 할당할 수 있는 자원의 수가 고정되어야 합니다. 3. 교착 상태 탐지 및 회복 (Detect Deadlock and Recover):\n개념: 교착 상태 예방이나 회피를 위한 특별한 조치를 취하지 않고, 시스템이 교착 상태에 빠지는 것을 허용합니다. 대신, **주기적으로 또는 필요시 교착 상태가 발생했는지 검사(탐지)**하고, 만약 발생했다면 이를 **해결(회복)**하는 방식입니다. 이는 마치 병에 걸린 후 진단하고 치료하는 것과 유사합니다. 목표: 교착 상태가 드물게 발생한다고 가정하고, 발생했을 때만 처리하여 평상시의 시스템 성능 저하를 최소화하는 것입니다. 방법: 탐지 (Detection): 자원 할당 그래프를 사용하여 사이클을 찾거나, Banker’s 알고리즘과 유사한 방식으로 현재 상태에서 교착이 발생했는지 확인하는 알고리즘을 사용합니다. 회복 (Recovery): 프로세스 종료 (Process termination): 교착 상태에 관련된 프로세스 중 하나 또는 전부를 강제로 종료시킵니다. 어떤 프로세스를 종료할지는 비용(우선순위, 진행 정도 등)을 고려하여 결정합니다. 자원 선점 (Resource preemption): 교착 상태에 있는 프로세스로부터 자원을 강제로 빼앗아 다른 프로세스에게 할당합니다. 이때 희생자 선택, 롤백(rollback), 기아(starvation) 문제 등을 고려해야 합니다. 장점: 예방이나 회피보다 시스템에 가해지는 제약이 적어, 평상시에는 자원 활용률과 시스템 처리율이 높을 수 있습니다. 교착 상태가 자주 발생하지 않는 시스템에 적합합니다. 단점: 교착 상태가 탐지될 때까지 해당 프로세스들은 작업을 진행하지 못합니다. 회복 과정에서 데이터 손실이나 작업 내용의 일부를 잃을 위험이 있습니다 (특히 프로세스 종료나 자원 선점 시). 탐지 알고리즘의 실행 빈도 결정이 중요합니다. 너무 자주 실행하면 오버헤드가 크고, 너무 드물게 실행하면 교착 상태가 오래 지속될 수 있습니다. 추가: 교착 상태 무시 (Ignoring Deadlock):\n일부 시스템(예: 개인용 PC의 운영체제)에서는 교착 상태가 매우 드물게 발생하고, 발생하더라도 사용자가 시스템을 재부팅하는 등의 방식으로 해결할 수 있다고 가정하여, 교착 상태를 처리하기 위한 특별한 메커니즘을 두지 않기도 합니다. 이를 “타조 알고리즘(Ostrich Algorithm)“이라고도 부릅니다. 이는 교착 상태 처리 비용이 교착으로 인한 손실보다 크다고 판단될 때 선택될 수 있습니다. 어떤 접근 방식을 선택할지는 시스템의 목적, 신뢰성 요구 수준, 성능 요구 사항, 그리고 교착 상태 발생 빈도 및 그로 인한 영향 등을 종합적으로 고려하여 결정해야 합니다. 이후 슬라이드에서는 이 중 ‘교착 상태 예방’에 대해 더 자세히 다룰 것으로 예상됩니다.","교착-상태-특징-deadlock-characterization#교착 상태 특징 (Deadlock Characterization)":"원문 (Original Text):\nDeadlock Characterization  Mutual exclusion: only one process at a time can use a resource  Hold and wait: a process holding at least one resource is waiting to acquire additional resources held by other processes  No preemption: a resource can be released only voluntarily by the process holding it, after that process has completed its task  Circular wait: there exists a set {P0, P1, …, Pn} of waiting processes such that P0 is waiting for a resource that is held by P1, P1 is waiting for a resource that is held by P2, …, Pn–1 is waiting for a resource that is held by Pn, and Pn is waiting for a resource that is held by P0. 번역 (Translation):\n교착 상태 특징 (발생 조건)  상호 배제 (Mutual exclusion): 한 번에 하나의 프로세스만이 자원을 사용할 수 있음  점유와 대기 (Hold and wait): 최소한 하나의 자원을 보유한 프로세스가 다른 프로세스에 의해 보유된 추가 자원을 얻기 위해 대기함  비선점 (No preemption): 자원은 해당 자원을 보유한 프로세스에 의해, 그 프로세스의 작업이 완료된 후 자발적으로만 방출될 수 있음  환형 대기 (Circular wait): 대기 중인 프로세스들의 집합 {P0, P1, …, Pn}이 존재하여, P0는 P1이 보유한 자원을 대기하고, P1은 P2가 보유한 자원을 대기하고, …, Pn–1은 Pn이 보유한 자원을 대기하며, Pn은 P0가 보유한 자원을 대기함. 매우 자세한 설명 (Detailed Explanation):\n이 슬라이드는 교착 상태가 발생하기 위해 반드시 동시에 만족되어야 하는 네 가지 조건을 설명합니다. 🕵️‍♂️ 이 네 가지 조건 중 하나라도 만족되지 않으면 교착 상태는 발생하지 않습니다. 따라서 교착 상태를 예방하는 전략은 이 조건들 중 하나 이상을 제거하는 것입니다.\n1. 상호 배제 (Mutual Exclusion):\n정의: 최소한 하나의 자원이 비공유(non-sharable) 모드로 사용되어야 합니다. 즉, 한 번에 오직 하나의 프로세스만이 해당 자원을 사용할 수 있으며, 다른 프로세스가 그 자원을 사용하려고 하면 요청한 프로세스는 자원이 방출될 때까지 기다려야 합니다. 설명: 만약 모든 자원이 공유 가능하다면 (즉, 여러 프로세스가 동시에 사용할 수 있다면), 교착 상태는 발생하지 않습니다. 예를 들어, 읽기 전용 파일(read-only file)은 여러 프로세스가 동시에 접근하여 읽을 수 있으므로 상호 배제가 필요 없습니다. 그러나 프린터나 쓰기 가능한 파일과 같은 자원은 한 번에 하나의 프로세스만 접근해야 데이터의 일관성이나 장치의 올바른 작동을 보장할 수 있습니다. 이러한 자원들이 바로 상호 배제 조건을 만족시키는 자원들입니다. 교착 상태와의 관계: A 프로세스가 프린터를 사용 중일 때 B 프로세스가 프린터를 사용하려고 하면 B는 대기해야 합니다. 이것 자체는 교착 상태가 아니지만, 교착 상태를 유발할 수 있는 기본 환경을 제공합니다. 2. 점유와 대기 (Hold and Wait):\n정의: 프로세스가 최소한 하나의 자원을 **점유(holding)**하고 있는 상태에서, 다른 프로세스에 의해 점유된 추가적인 자원을 얻기 위해 **대기(waiting)**해야 합니다. 설명: 프로세스가 필요한 모든 자원을 한 번에 요청하고 할당받는다면 이 조건은 성립하지 않습니다. 하지만 대부분의 프로세스는 실행 도중에 동적으로 자원을 요청합니다. P1이 자원 R1을 이미 할당받아 사용 중인 상태에서, 추가적으로 자원 R2를 요청했는데 R2가 현재 P2에 의해 사용 중이라 P1이 대기하게 되는 상황을 의미합니다. 이때 P1은 R1을 계속 점유하고 있으면서 R2를 기다립니다. 교착 상태와의 관계: 이 조건은 프로세스들이 자원을 부분적으로 확보한 채로 다른 자원을 기다리게 만들어, 자원 할당의 연쇄적인 대기를 유발할 수 있습니다. P1이 R1을 점유하고 R2를 기다리고, P2가 R2를 점유하고 R1을 기다린다면, 이 조건이 상호 배제 및 다른 조건들과 결합하여 교착 상태를 만듭니다. 3. 비선점 (No Preemption):\n정의: 이미 할당된 자원은 그 자원을 점유하고 있는 프로세스로부터 강제로 빼앗을 수 없습니다(cannot be preempted). 자원은 오직 해당 자원을 점유한 프로세스가 작업을 완료한 후 자발적으로(voluntarily) 방출할 때만 다른 프로세스가 사용할 수 있습니다. 설명: 만약 운영체제가 필요에 따라 한 프로세스로부터 자원을 강제로 회수하여 다른 프로세스에게 할당할 수 있다면(즉, 선점이 가능하다면), 교착 상태를 해결할 수 있습니다. 예를 들어, CPU는 선점이 가능한 대표적인 자원입니다. 한 프로세스가 CPU를 사용하다가도 우선순위가 더 높은 프로세스가 나타나면 CPU를 빼앗길 수 있습니다. 하지만 프린터로 문서를 인쇄하는 도중에 프린터를 강제로 빼앗으면 인쇄 작업이 망가질 수 있는 것처럼, 많은 자원들은 비선점 특성을 가집니다. 교착 상태와의 관계: 프로세스가 자원을 점유한 채 다른 자원을 기다릴 때, 그 점유한 자원을 놓지 않기 때문에 대기 상태가 지속됩니다. 만약 점유한 자원을 강제로 회수할 수 있다면, 다른 프로세스가 해당 자원을 사용하여 작업을 진행하고 결국에는 대기 중인 프로세스가 필요로 하는 자원을 방출하게 될 가능성이 생깁니다. 4. 환형 대기 (Circular Wait):\n정의: 대기하고 있는 프로세스들의 집합 {P0​,P1​,…,Pn​}이 존재하여, P0​는 P1​이 점유한 자원을 기다리고, P1​은 P2​가 점유한 자원을 기다리며, 이러한 관계가 계속 이어져 Pn−1​은 Pn​이 점유한 자원을 기다리고, 마지막으로 Pn​은 P0​가 점유한 자원을 기다리는, 꼬리에 꼬리를 무는 순환적인 대기 형태가 존재해야 합니다. 설명: 이 조건은 앞선 세 가지 조건이 만족될 때 교착 상태가 실제로 발생하게 되는 직접적인 원인이 됩니다. 각 프로세스가 다음 프로세스가 가진 자원을 기다리면서, 결국 처음 프로세스까지 연결되는 사이클이 형성되는 것입니다. 예시: P0​는 P1​이 가진 자원 R1​을 기다림 (P0​→R1​←P1​) P1​은 P2​가 가진 자원 R2​를 기다림 (P1​→R2​←P2​) … Pn​은 P0​가 가진 자원 R0​를 기다림 (Pn​→R0​←P0​) (여기서 Ri​는 Pi+1​ (또는 Pn​의 경우 P0​)이 점유한 자원을 나타냅니다.) 중요한 점: 이 네 가지 조건은 교착 상태가 발생하기 위한 **필요조건(necessary conditions)**입니다. 즉, 교착 상태가 발생했다면 이 네 가지 조건은 반드시 성립합니다. 반대로, 이 네 가지 조건이 모두 성립한다고 해서 항상 교착 상태가 발생하는 것은 아닙니다(특히 자원 유형별 인스턴스가 여러 개일 경우). 그러나 자원 유형별 인스턴스가 하나뿐일 경우에는 이 네 가지 조건이 모두 성립하면 반드시 교착 상태가 발생합니다. 이 조건들을 이해하는 것은 교착 상태를 예방하거나, 탐지하고, 회복하는 다양한 전략을 개발하는 데 있어 핵심적인 역할을 합니다.","교착-상태-회피-deadlock-avoidance#교착 상태 회피 (Deadlock Avoidance)":"","교착-상태-회피의-두-가지-접근법-two-approaches-to-deadlock-avoidance#교착 상태 회피의 두 가지 접근법 (Two Approaches to Deadlock Avoidance)":"","교착-상태를-포함하는-자원-할당-그래프-resource-allocation-graph-with-a-deadlock#교착 상태를 포함하는 자원 할당 그래프 (Resource Allocation Graph With A Deadlock)":"원문 (Original Text):\nResource Allocation Graph With A Deadlock (이 슬라이드는 제목만 있고 실제 그래프 이미지가 없으므로, 교착 상태를 명확히 보여주는 전형적인 예시를 구성하여 설명합니다.)\n번역 (Translation):\n교착 상태를 포함하는 자원 할당 그래프 매우 자세한 설명 (Detailed Explanation):\n이 슬라이드는 자원 할당 그래프(RAG)를 사용하여 실제 **교착 상태(deadlock)**가 발생한 상황을 시각적으로 표현하고 분석하는 방법을 보여줍니다. 🔗 교착 상태의 핵심 특징인 **사이클(cycle)**이 그래프에 어떻게 나타나는지에 주목해야 합니다.\n교착 상태를 보여주는 가상 예시 시나리오:\n다음과 같은 프로세스와 자원, 그리고 그들의 상태를 가정합니다.\n프로세스: P1​,P2​,P3​ 자원 유형: R1: 인스턴스 1개 R2: 인스턴스 1개 R3: 인스턴스 1개 (단순화를 위해 모든 자원 유형이 단일 인스턴스를 가진다고 가정합니다. 단일 인스턴스 자원의 경우, RAG에 사이클이 존재하면 반드시 교착 상태입니다.) 현재 상태:\n프로세스 P1​은 자원 R1​을 **보유(holding)**하고 있으며, 자원 R2​를 **요청(requesting)**하고 있습니다. 프로세스 P2​는 자원 R2​를 보유하고 있으며, 자원 R3​를 요청하고 있습니다. 프로세스 P3​는 자원 R3​를 보유하고 있으며, 자원 R1​을 요청하고 있습니다. 자원 할당 그래프 표현:\n코드 스니펫\ngraph TD P1((P1)) P2((P2)) P3((P3)) R1_box[R1 (1 instance)] R2_box[R2 (1 instance)] R3_box[R3 (1 instance)] subgraph R1_box r1_i1(.) end subgraph R2_box r2_i1(.) end subgraph R3_box r3_i1(.) end r1_i1 --\u003e P1 // P1 holds R1's instance P1 --\u003e R2_box // P1 requests R2 r2_i1 --\u003e P2 // P2 holds R2's instance P2 --\u003e R3_box // P2 requests R3 r3_i1 --\u003e P3 // P3 holds R3's instance P3 --\u003e R1_box // P3 requests R1 그래프 분석 및 교착 상태 식별:\n사이클(Cycle)의 존재:\n위의 자원 할당 그래프를 자세히 살펴보면 다음과 같은 **닫힌 경로(cycle)**를 발견할 수 있습니다.\nP1​→R2​(요청)←R2​(인스턴스)←P2​(보유)→R3​(요청)←R3​(인스턴스)←P3​(보유)→R1​(요청)←R1​(인스턴스)←P1​(보유)\n간단히 표현하면:\nP1​requests​R2​held by​P2​requests​R3​held by​P3​requests​R1​held by​P1​\n이 사이클은 프로세스 P1​,P2​,P3​와 자원 R1​,R2​,R3​를 포함하고 있습니다.\n교착 상태의 네 가지 조건 만족 여부 확인:\n상호 배제 (Mutual Exclusion): 각 자원(R1​,R2​,R3​)은 단일 인스턴스만 가지고 있으므로, 한 번에 하나의 프로세스만 사용할 수 있습니다. 즉, 상호 배제 조건이 만족됩니다. (예: P1​이 R1​을 사용하는 동안 P3​는 R1​을 사용할 수 없습니다.) 점유와 대기 (Hold and Wait): P1​은 R1​을 점유한 채 R2​를 기다립니다. P2​는 R2​를 점유한 채 R3​를 기다립니다. P3​는 R3​를 점유한 채 R1​을 기다립니다. 각 프로세스가 자원을 점유하면서 다른 자원을 대기하고 있으므로, 점유와 대기 조건이 만족됩니다. 비선점 (No Preemption): 문제에서 명시적으로 언급되지는 않았지만, 일반적인 자원(특히 이 예시에서 암시하는 프린터, 파일 등과 유사한 배타적 자원)은 사용 중인 프로세스로부터 강제로 빼앗을 수 없다고 가정합니다. 즉, 비선점 조건이 만족됩니다. P1​이 R1​ 사용을 마칠 때까지 P3​는 R1​을 얻을 수 없습니다. 환형 대기 (Circular Wait): 위에서 식별한 사이클(P1​→R2​←P2​→R3​←P3​→R1​←P1​)이 바로 환형 대기 조건을 명확하게 보여줍니다. P1​은 P2​가 가진 R2​를, P2​는 P3​가 가진 R3​를, P3​는 P1​이 가진 R1​을 기다리고 있습니다. 결론: 교착 상태 발생\n모든 자원 유형이 단일 인스턴스를 가지고 있고, 그래프에 사이클이 존재하므로, 이 시스템은 명백히 교착 상태에 빠져 있습니다.\nP1​은 P2​가 R2​를 놓아주기를 기다립니다. P2​는 P3​가 R3​를 놓아주기를 기다립니다. P3​는 P1​이 R1​을 놓아주기를 기다립니다. 어떤 프로세스도 자신이 점유한 자원을 놓지 않고 다른 자원을 기다리고 있기 때문에, 세 프로세스 모두 영원히 다음 단계로 진행할 수 없습니다. 자원 할당 그래프와 교착 상태의 관계 요약:\n사이클 없음 ⇒ 교착 상태 없음: 그래프에 사이클이 없으면 시스템은 교착 상태가 아닙니다. 사이클 존재 + 각 자원 유형별 단일 인스턴스 ⇒ 교착 상태 발생: 그래프에 사이클이 있고, 그 사이클에 포함된 모든 자원 유형이 오직 하나의 인스턴스만 가지고 있다면 시스템은 반드시 교착 상태입니다. (위 예시가 이에 해당) 사이클 존재 + 일부 자원 유형별 다중 인스턴스 ⇒ 교착 상태 가능성 존재: 그래프에 사이클이 있지만, 사이클에 포함된 자원 유형 중 일부가 여러 인스턴스를 가지고 있다면 교착 상태일 수도 있고 아닐 수도 있습니다. 이 경우는 추가적인 분석이 필요합니다 (다음 슬라이드에서 다룰 내용). 이 슬라이드의 (가상) 예시는 자원 할당 그래프가 어떻게 교착 상태를 명확하게 드러내는지 보여줍니다. 사이클의 형성은 교착 상태의 핵심 시각적 증거이며, 운영체제는 이러한 사이클을 탐지하는 알고리즘을 사용하여 교착 상태를 발견하고 해결할 수 있습니다.","구현-방법-fifo-큐-fifo-queue#\u003cstrong\u003e구현 방법: FIFO 큐 (FIFO Queue)\u003c/strong\u003e":"슬라이드는 “이것을 어떻게 알 수 있는가? (How do you know this?)“라는 질문에 대한 답으로 **“FIFO 큐”**를 제시합니다. FIFO 알고리즘은 운영 체제가 페이지들의 도착 순서를 기억하기 위해 간단한 큐(Queue) 자료 구조를 사용하여 구현할 수 있습니다.\n페이지 적재 시: 새로운 페이지가 페이지 폴트에 의해 물리 메모리의 빈 프레임으로 적재될 때, 해당 페이지의 번호를 FIFO 큐의 꼬리(tail)에 추가합니다. 희생 페이지 선택 시: 페이지 교체가 필요한 상황이 되면, FIFO 큐의 머리(head)에 있는 페이지를 제거합니다. 이 페이지가 바로 가장 오래전에 메모리에 들어온 페이지, 즉 교체될 희생 페이지입니다. 새로운 페이지 추가: 희생 페이지가 제거된 후, 새롭게 메모리로 들어오는 페이지는 다시 큐의 꼬리에 추가됩니다. 이러한 큐 관리는 구현하기가 매우 쉽고, 각 페이지에 대한 추가적인 시간 정보(예: 마지막 참조 시간)를 유지할 필요가 없어 시스템 오버헤드가 매우 적다는 장점이 있습니다.","기본-사실들-basic-facts#기본 사실들 (Basic Facts)":"원문 (Original Text):\nBasic Facts  If graph contains no cycles Þ no deadlock  If graph contains a cycle Þ  if only one instance per resource type, then deadlock  if several instances per resource type, possibility of deadlock R resource type 의 모든 w instance 가 circular 이어야 deadlock 의 조건중 1개인 circular wait 이 발생한다 (원문 마지막 줄은 한국어로 되어 있어, 번역 없이 설명에 포함합니다.)\n번역 (Translation):\n기본 사실들  그래프에 사이클(cycle)이 없으면 Þ 교착 상태 없음  그래프에 사이클이 있으면 Þ  자원 유형별로 인스턴스가 하나뿐이라면, 교착 상태임  자원 유형별로 여러 인스턴스가 있다면, 교착 상태의 가능성이 있음 (R resource type 의 모든 w instance 가 circular 이어야 deadlock 의 조건중 1개인 circular wait 이 발생한다 - 이 부분은 원문이 한국어이므로 번역보다는 설명으로 풀어냅니다.) 매우 자세한 설명 (Detailed Explanation):\n이 슬라이드는 자원 할당 그래프(RAG)와 교착 상태(deadlock) 간의 관계에 대한 핵심적인 사실들을 요약합니다. 📌 이는 교착 상태를 탐지하고 이해하는 데 있어 매우 중요한 기준을 제공합니다.\n1. 그래프에 사이클이 없으면 ⇒ 교착 상태 없음 (If graph contains no cycles ⇒ no deadlock)\n설명: 자원 할당 그래프에 어떠한 사이클도 존재하지 않는다면, 시스템에는 교착 상태가 절대로 존재하지 않습니다. 이유: 교착 상태의 네 가지 필요조건 중 하나인 환형 대기(Circular Wait) 조건은 그래프 상에서 사이클로 표현됩니다. 사이클이 없다는 것은 환형 대기가 없다는 의미이며, 네 가지 조건 중 하나라도 만족되지 않으면 교착 상태는 발생할 수 없습니다. 의미: 이는 교착 상태가 아님을 판단하는 매우 강력하고 간단한 기준입니다. 그래프를 그려 사이클이 없는 것을 확인하면, 시스템은 안전하다고 말할 수 있습니다 (적어도 현재 스냅샷에서는). 그래프에 사이클이 있으면 ⇒ (If graph contains a cycle ⇒) 그래프에 사이클이 존재할 경우, 상황은 자원 유형별 인스턴스 수에 따라 달라집니다.\n2a. 자원 유형별로 인스턴스가 하나뿐이라면, 교착 상태임 (if only one instance per resource type, then deadlock)\n설명: 만약 그래프에 사이클이 존재하고, 그 사이클에 포함된 모든 자원 유형이 오직 하나의 인스턴스만을 가지고 있다면, 시스템은 반드시 교착 상태입니다. 이유: 이 경우, 사이클 내의 각 프로세스는 다음 프로세스가 점유하고 있는 (단 하나뿐인) 자원의 인스턴스를 기다리게 됩니다. 빠져나갈 다른 인스턴스가 없으므로, 환형 대기가 직접적으로 교착 상태를 유발합니다. 이전 슬라이드 “Resource Allocation Graph With A Deadlock\"의 예시가 이 경우에 해당합니다. 예시: P1​→RA​←P2​→RB​←P1​. 여기서 RA​와 RB​가 각각 단일 인스턴스라면, P1​과 P2​는 교착 상태입니다. 2b. 자원 유형별로 여러 인스턴스가 있다면, 교착 상태의 가능성이 있음 (if several instances per resource type, possibility of deadlock)\n설명: 만약 그래프에 사이클이 존재하지만, 그 사이클에 관련된 자원 유형 중 하나 이상이 여러 개의 인스턴스를 가지고 있다면, 이는 교착 상태일 가능성을 시사하지만, 반드시 교착 상태인 것은 아닙니다. 이유: 이전 슬라이드 “Graph With A Cycle But No Deadlock\"에서 보았듯이, 사이클에 참여하지 않는 다른 프로세스가 해당 다중 인스턴스 자원 중 하나를 사용하고 있다가 방출하면, 사이클 내의 프로세스가 그 자원을 할당받아 사이클을 끊고 진행할 수 있는 여지가 있기 때문입니다. 예시: P1​→RA​←P2​→RB​←P1​. 여기서 RA​는 단일 인스턴스지만 RB​가 2개의 인스턴스(i1​,i2​)를 가지고 있고, P1​이 RB​의 i1​을 기다리고 있는데 P2​가 i1​을 점유하고 있다고 가정합시다. 만약 P3​라는 다른 프로세스가 RB​의 i2​를 점유하고 있다가 곧 방출한다면, P1​은 i2​를 할당받아 진행할 수 있으므로 교착 상태가 아닐 수 있습니다. 그러나 P1​이 반드시 P2​가 점유한 i1​만을 기다려야 하고, i2​가 다른 이유로 P1​에게 할당될 수 없다면 교착이 될 수도 있습니다. 즉, 상황에 따라 다릅니다. 3. “R resource type 의 모든 w instance 가 circular 이어야 deadlock 의 조건중 1개인 circular wait 이 발생한다”\n해석 및 설명: 이 문장은 “특정 자원 유형 R의 모든 W개의 인스턴스가 (사이클을 형성하는) 환형 대기에 관여되어야만 교착 상태의 조건 중 하나인 환형 대기가 (해당 자원과 관련하여 명확하게) 발생한다\"는 의미로 해석될 수 있습니다. 하지만 이 표현은 다소 혼란을 줄 수 있으며, 일반적인 교착 상태 정의와 약간 다르게 접근하는 것처럼 보입니다.\n일반적인 관점과의 비교:\n보통 **환형 대기(Circular Wait)**는 프로세스들의 집합 {P0​,P1​,…,Pn​}이 있어 P0​가 P1​이 가진 자원을, P1​이 P2​가 가진 자원을, …, Pn​이 P0​가 가진 자원을 기다리는 상황 자체를 의미합니다. 이때, 각 프로세스가 기다리는 자원이 특정 유형 R의 인스턴스일 수 있습니다. 만약 자원 유형 R이 여러 인스턴스(w개)를 가지고 있고, 사이클 내의 어떤 프로세스가 R의 인스턴스를 기다린다고 할 때, R의 모든 w개 인스턴스가 반드시 그 사이클 내의 다른 프로세스들에 의해 점유되어 있고, 해당 인스턴스들이 모두 환형 대기의 일부를 구성해야만 교착 상태가 된다는 의미는 아닙니다. 오히려, 사이클이 존재하고 해당 사이클에 포함된 자원 요청을 만족시킬 수 있는 가용 인스턴스가 없을 때 교착 상태가 됩니다. 더 정확한 이해 (다중 인스턴스 환경에서의 사이클과 교착):\n다중 인스턴스 자원 유형 Ri​가 사이클에 포함되어 있다고 가정해 봅시다.\n프로세스 Pk​가 Ri​의 인스턴스를 요청합니다 (Pk​→Ri​). Ri​의 모든 인스턴스가 현재 다른 프로세스들 (Pa​,Pb​,…)에 의해 점유되어 있습니다. 만약 이 프로세스들(Pa​,Pb​,…) 중 일부 또는 전부가 다시 Pk​ (또는 사이클 내 다른 프로세스)가 점유한 자원을 기다리고 있다면, 이것이 교착 상태로 이어질 수 있습니다. 핵심은 Pk​가 기다리는 자원 Ri​에 가용 인스턴스가 없고, Ri​의 인스턴스를 점유한 프로세스들이 사이클을 완성하는 방식으로 다른 자원을 기다리고 있을 때 교착 상태가 발생합니다. 원문의 의도 재해석:\n원문의 “R resource type 의 모든 w instance 가 circular 이어야…” 부분은 아마도, 특정 자원 R의 모든 인스턴스가 사이클에 참여하는 프로세스들에게 할당되어 있고, 이들 프로세스가 서로를 기다리는 상황이 되면 환형 대기가 명백해진다는 점을 강조하려 했을 수 있습니다. 즉, 해당 자원 유형에 더 이상 ‘탈출구’(가용 인스턴스)가 없음을 나타내는 표현일 수 있습니다.\n그러나 교착 상태는 단순히 한 자원 유형의 모든 인스턴스가 사이클에 묶여있어야만 발생하는 것은 아닙니다. 여러 자원 유형이 얽힌 사이클에서 각 자원의 가용성을 종합적으로 봐야 합니다.\n요약하면:\n사이클 없음 ⟹ 교착 아님 (절대적). 사이클 있음 + 모든 자원 단일 인스턴스 ⟹ 교착 (절대적). 사이클 있음 + 일부/전부 자원 다중 인스턴스 ⟹ 교착 가능성 (상황 분석 필요). 이때는 해당 사이클 내의 요청을 만족시킬 수 있는 가용 자원이 있는지, 또는 사이클 외부의 프로세스가 자원을 방출하여 사이클을 깰 수 있는지를 확인해야 합니다. 이 기본 사실들은 교착 상태 탐지 알고리즘(예: Banker’s 알고리즘의 안전성 검사나 실제 교착 탐지 시)의 이론적 기초가 됩니다.","기본-사실들-basic-facts-1#기본 사실들 (Basic Facts)":"","논리-주소-공간--물리-주소-공간#\u003cstrong\u003e논리 주소 공간 \u0026gt; 물리 주소 공간\u003c/strong\u003e":"위에서 설명한 두 가지 특징, 즉 논리-물리 주소의 분리와 필요한 부분만 메모리에 적재하는 방식 덕분에 ‘프로그램의 논리 주소 공간이 실제 물리 메모리의 크기보다 훨씬 커질 수 있습니다.’\n예를 들어, 4GB의 RAM을 가진 컴퓨터에서도 10GB 크기의 대용량 데이터 분석 프로그램을 실행할 수 있습니다. 이 프로그램은 10GB의 논리 주소 공간을 가집니다. 실행 시점에는 당장 필요한 수십 MB의 코드와 데이터만 4GB RAM의 일부에 올라옵니다. 프로그램이 실행되면서 10GB 논리 주소 공간 내의 다른 데이터에 접근하려고 하면, 운영 체제는 현재 RAM에 있는 데이터 중 당장 사용되지 않는 부분을 디스크로 잠시 내보내고(이를 ‘스왑 아웃’이라 합니다), 디스크에 있던 새로운 데이터를 그 자리에 읽어옵니다(‘스왑 인’).\n이 과정은 마치 도서관의 서고(디스크)와 내 책상(물리 메모리)의 관계와 같습니다. 서고에는 수만 권의 책(거대한 논리 주소 공간)이 있지만, 내 책상 위에는 당장 읽고 있는 몇 권의 책(물리 메모리에 올라온 부분)만 올려놓습니다. 다른 책이 필요하면, 보고 있던 책을 잠시 서고에 다시 가져다 놓고 새로운 책을 가져오는 것과 같습니다. 이처럼 가상 메모리는 디스크를 RAM의 확장 공간처럼 사용하여 프로그램에게는 거대한 메모리가 있는 것처럼 환상을 제공합니다.","다이어그램-상세-분석#\u003cstrong\u003e다이어그램 상세 분석\u003c/strong\u003e":"다이어그램은 세 개의 주요 컴포넌트로 구성되어 있습니다.\n논리 메모리 (Logical Memory):\n프로세스가 보는 가상적인 주소 공간을 나타냅니다. 다이어그램에서는 0부터 7까지 번호가 매겨진 8개의 페이지(Page 0, Page 1, …, Page 7)로 구성되어 있습니다. 중요한 점은 프로세스 자신에게 이 메모리는 연속적인 하나의 큰 덩어리로 인식된다는 것입니다. 프로세스는 자신의 코드가 Page 0, Page 1, Page 2 순서로 차곡차곡 저장되어 있다고 생각합니다. 각 페이지의 물리적 위치나 존재 여부는 전혀 알지 못합니다. 페이지 테이블 (Page Table):\n논리 메모리와 물리 메모리를 연결하는 핵심적인 자료 구조입니다. 논리 페이지 번호를 인덱스로 사용합니다. 각 항목(Entry)은 최소한 두 개의 필드를 가집니다: **유효-무효 비트(valid-invalid bit)**와 프레임 번호(frame number). 유효(Valid) 항목의 예시: Page 0: v(유효) 비트가 세팅되어 있고, 프레임 번호 4를 가리킵니다. 이는 논리 페이지 0이 현재 물리 메모리의 4번 프레임에 로드되어 있음을 의미합니다. Page 1: v(유효) 비트가 세팅되어 있고, 프레임 번호 3을 가리킵니다. Page 2: v(유효) 비트가 세팅되어 있고, 프레임 번호 1을 가리킵니다. Page 5: v(유효) 비트가 세팅되어 있고, 프레임 번호 2를 가리킵니다. 무효(Invalid) 항목의 예시: Page 3, 4, 6, 7: i(무효) 비트가 세팅되어 있습니다. 이는 이 논리 페이지들이 현재 물리 메모리에 존재하지 않음을 의미합니다. 이 페이지들의 실제 데이터는 디스크(Backing Store) 어딘가에 저장되어 있을 것입니다. 프레임 번호 필드는 의미가 없거나(null), 해당 페이지의 디스크 주소 정보를 담고 있을 수도 있습니다. 물리 메모리 (Physical Memory):\n실제 하드웨어 RAM을 나타냅니다. ‘프레임(Frame)‘이라는 페이지와 동일한 크기의 블록으로 나뉘어 있습니다. 다이어그램을 보면, 물리 메모리의 프레임들이 순서대로 사용되지 않고 있음을 알 수 있습니다. 예를 들어, 논리적으로 연속된 Page 0, 1, 2가 물리적으로는 각각 Frame 4, 3, 1이라는 비연속적이고 흩어져 있는 공간에 할당되었습니다. 또한, 물리 메모리의 일부 프레임(예: Frame 0, 5, 6, 7 등)은 비어 있을 수도 있고, 다른 프로세스의 페이지에 의해 사용되고 있을 수도 있습니다. 다이어그램은 오직 이 특정 프로세스에 할당된 프레임들만 보여주고 있습니다.","다이어그램을-통한-주소-변환-과정-시뮬레이션#\u003cstrong\u003e다이어그램을 통한 주소 변환 과정 시뮬레이션\u003c/strong\u003e":"이 스냅샷을 기반으로 CPU가 주소를 요청할 때 어떤 일이 일어나는지 따라가 볼 수 있습니다.\n시나리오 1: 성공적인 주소 변환 (페이지가 메모리에 있는 경우)\nCPU가 논리 페이지 2에 속하는 주소(예: C언어 코드의 variable_C에 접근)를 요청합니다. MMU는 페이지 테이블의 2번 인덱스로 갑니다. 유효-무효 비트가 **‘v’ (valid)**인 것을 확인합니다. 같은 항목에 있는 프레임 번호 **‘1’**을 읽습니다. CPU가 요청한 원래 주소의 오프셋(offset)과 프레임 번호 1을 조합하여 최종 물리 주소를 계산합니다. 계산된 물리 주소를 통해 실제 RAM에 접근하여 데이터를 읽거나 씁니다. 이 과정은 매우 빠르며 운영체제의 개입 없이 하드웨어적으로 처리됩니다. 시나리오 2: 페이지 폴트 발생 (페이지가 메모리에 없는 경우)\nCPU가 논리 페이지 3에 속하는 주소(예: 함수 function_D를 호출)를 요청합니다. MMU는 페이지 테이블의 3번 인덱스로 갑니다. 유효-무효 비트가 **‘i’ (invalid)**인 것을 확인합니다. MMU는 주소 변환을 즉시 멈추고 페이지 폴트 트랩을 발생시켜 운영 체제를 호출합니다. 운영 체제의 페이지 폴트 핸들러가 실행되어, 디스크에서 논리 페이지 3의 데이터를 찾아 물리 메모리의 비어있는 프레임(예: Frame 7)으로 로드합니다. 로드 후, 페이지 테이블의 3번 항목을 업데이트합니다: 유효-무효 비트를 ‘v’로 바꾸고 프레임 번호를 ‘7’로 설정합니다. 원래의 명령어를 다시 시작합니다. 이제 MMU는 페이지 3에 대한 주소 변환을 성공적으로 마칠 수 있습니다.","다이어그램의-6단계-상세-해설#\u003cstrong\u003e다이어그램의 6단계 상세 해설\u003c/strong\u003e":"1. 참조 (Reference)\n동작 주체: CPU (프로세스) 설명: 모든 것은 프로세스가 특정 **논리 주소(logical address)**에 접근을 시도하면서 시작됩니다. 이 주소는 읽으려는 명령어일 수도 있고, 읽거나 쓰려는 데이터일 수도 있습니다. CPU는 이 논리 주소를 생성하여 MMU(메모리 관리 장치)에게 전달합니다. 다이어그램에서는 load M이라는 명령어로 표현되어, ‘M’이라는 주소의 내용을 로드하라는 요청을 나타냅니다. 2. 트랩 (Trap to Operating System)\n동작 주체: MMU (하드웨어) 설명: MMU는 전달받은 논리 주소를 물리 주소로 변환하기 위해 프로세스의 페이지 테이블을 참조합니다. 이때 해당 페이지의 **유효-무효 비트(valid-invalid bit)가 ‘무효(invalid)’**인 것을 발견합니다. 이는 요청된 페이지가 현재 물리 메모리에 없다는 의미입니다. MMU는 주소 변환을 계속할 수 없으므로, 하드웨어 **트랩(trap)**을 발생시켜 CPU의 제어권을 강제로 **운영 체제(Operating System)**에게 넘깁니다. 이 순간이 바로 ‘페이지 폴트’가 발생한 시점입니다. 3. 페이지가 디스크에 있음을 확인 (Page is on backing store)\n동작 주체: 운영 체제 (소프트웨어) 설명: 제어권을 넘겨받은 운영 체제의 페이지 폴트 핸들러가 가장 먼저 하는 일입니다. 앞 슬라이드의 1단계(유효성 검사)에 해당합니다. 운영 체제는 내부 자료 구조를 확인하여 이 메모리 참조가 합법적인지, 즉 프로세스에 할당된 주소 공간 내의 접근인지 확인합니다. 합법적인 참조라면, 해당 페이지가 단지 물리 메모리에 없을 뿐이며, **디스크(backing store)**에 존재한다는 것을 확인합니다. 불법적인 참조였다면 여기서 프로세스를 종료시켰을 것입니다. 4. 페이지 인 (Bring in missing page / Page In)\n동작 주체: 운영 체제 \u0026 디스크 컨트롤러 설명: 이제 운영 체제는 페이지를 물리 메모리로 가져오는 실제 작업을 시작합니다. a. 빈 프레임 찾기: 운영 체제는 물리 메모리에서 비어있는 프레임을 찾습니다. (만약 없다면, 페이지 교체 알고리즘을 실행하여 희생될 페이지를 골라 해당 프레임을 비웁니다.) b. 디스크 I/O 요청: 디스크에 있는 해당 페이지의 위치를 찾아, 디스크 컨트롤러에게 그 내용을 새로 찾은 빈 프레임으로 읽어오라는 I/O 요청을 보냅니다. c. 컨텍스트 스위칭: 디스크 I/O는 매우 느리기 때문에, 운영 체제는 이 페이지 폴트를 일으킨 프로세스를 ‘대기’ 상태로 만들고, CPU를 다른 ‘준비’ 상태의 프로세스에게 할당합니다. 이 다이어그램에서는 이 복잡한 과정을 ‘페이지를 가져온다(Bring in missing page)‘는 하나의 화살표로 단순화하여 표현했습니다. 5. 테이블 재설정 (Reset page table)\n동작 주체: 운영 체제 설명: 디스크 I/O 작업이 완료되면 디스크 컨트롤러가 CPU에 인터럽트를 보내 운영 체제에게 알립니다. 그러면 운영 체제는 마무리 작업을 수행합니다. 프로세스의 페이지 테이블로 가서, 방금 메모리로 가져온 페이지에 해당하는 항목을 수정합니다. 유효-무효 비트를 ‘i’에서 ‘v’로 변경합니다. 프레임 번호 필드에 실제 데이터가 로드된 물리 프레임의 주소를 기록합니다. ‘대기’ 상태에 있던 프로세스를 다시 실행할 수 있는 ‘준비’ 상태로 변경하여 준비 큐에 넣습니다. 6. 명령어 재시작 (Restart instruction)\n동작 주체: 운영 체제 -\u003e CPU (프로세스) 설명: 이제 모든 것이 준비되었습니다. CPU 스케줄러에 의해 이 프로세스가 다시 실행될 차례가 오면, 제어권이 프로세스에게 돌아갑니다. 중요한 것은, 실행이 중단되었던 지점부터가 아니라, 페이지 폴트를 유발했던 바로 그 명령어를 처음부터 다시 실행한다는 점입니다. 이번에는 load M 명령이 다시 실행되면 MMU는 페이지 테이블을 참조하고, 5단계에서 업데이트된 유효한(valid) 항목을 찾게 됩니다. 따라서 주소 변환은 성공적으로 완료되고, 프로세스는 아무 일도 없었다는 듯이 다음 명령어로 계속 진행하게 됩니다. 이 다이어그램은 페이지 폴트가 단순한 오류가 아니라, 하드웨어와 소프트웨어가 긴밀하게 협력하여 가상 메모리라는 추상화를 구현하는 매우 정교하고 동적인 프로세스임을 명확하게 보여줍니다. 각 단계의 역할과 주체를 이해하는 것은 운영 체제의 메모리 관리 방식을 이해하는 데 필수적입니다.","다이어그램의-구성-요소-분석#\u003cstrong\u003e다이어그램의 구성 요소 분석\u003c/strong\u003e":"다이어그램은 크게 세 부분으로 구성되어 있습니다.\n논리 메모리 (Logical Memory): 다이어그램의 왼쪽에 길고 큰 막대로 표현됩니다. 이는 하나의 프로세스가 인식하는 메모리 공간, 즉 논리 주소 공간을 나타냅니다. 이 공간은 0번지부터 시작하여 매우 큰 주소까지 이어지는 연속적인(contiguous) 메모리처럼 보입니다. 프로세스는 자신이 이 거대한 메모리 공간을 독점적으로 사용한다고 생각하며, 모든 메모리 주소 참조는 이 논리 주소 공간을 기준으로 이루어집니다. 다이어그램에서 이 막대가 매우 큰 것은 프로그램이 가질 수 있는 잠재적인 메모리 크기가 매우 크다는 것을 상징합니다.\n물리 메모리 (Physical Memory): 다이어그램의 오른쪽에 논리 메모리보다 훨씬 작은 막대로 표현됩니다. 이것이 바로 컴퓨터에 실제로 장착된 하드웨어인 RAM입니다. 이 공간은 한정되어 있으며, 시스템에서 실행되는 모든 프로세스(및 운영 체제 자체)가 공유해서 사용해야 하는 귀중한 자원입니다. 다이어그램에서 논리 메모리보다 작게 그려진 것은 가상 메모리의 핵심 전제, 즉 프로그램이 요구하는 총 메모리(논리 메모리)가 실제 사용 가능한 RAM(물리 메모리)보다 클 수 있다는 점을 강조합니다.\n디스크 (Backing Store / Swap Space): 다이어그램에서 원통형 저장 장치로 표현되며, ‘매핑(mapping)’ 화살표의 일부가 이쪽을 향하고 있습니다. 이는 하드 디스크 드라이브(HDD)나 솔리드 스테이트 드라이브(SSD)와 같은 보조 기억 장치를 의미합니다. 가상 메모리 시스템에서 디스크는 두 가지 중요한 역할을 합니다.\n백킹 스토어(Backing Store): 실행 파일의 전체 내용(코드, 데이터 등)이 저장되는 공간입니다. 프로세스가 처음 생성될 때, 운영 체제는 이 실행 파일을 참조하여 프로세스의 논리 주소 공간을 설정합니다. 스왑 공간(Swap Space): 물리 메모리가 부족할 때, 당장 사용되지 않는 메모리 페이지/세그먼트를 임시로 내려놓는(swap out) 공간입니다. 나중에 해당 데이터가 다시 필요해지면, 이 스왑 공간에서 다시 물리 메모리로 읽어옵니다(swap in). 본질적으로 디스크를 RAM의 확장 공간처럼 사용하는 것입니다. 메모리 매핑 (Memory Mapping): 논리 메모리와 물리 메모리, 그리고 디스크 사이를 연결하는 화살표들이 바로 메모리 매핑 과정을 나타냅니다. 이 매핑은 운영 체제와 **MMU(메모리 관리 장치)**에 의해 관리되는 **페이지 테이블(Page Table)**이라는 자료 구조를 통해 이루어집니다. 다이어그램을 보면, 논리 메모리의 특정 부분들(페이지들)만이 물리 메모리의 특정 위치(프레임들)에 연결(매핑)되어 있음을 알 수 있습니다. 논리 메모리의 나머지 부분들은 물리 메모리에 존재하지 않으며, 이들은 디스크에 저장되어 있음을 암시합니다.","다이어그램의-단계별-상세-분석#\u003cstrong\u003e다이어그램의 단계별 상세 분석\u003c/strong\u003e":"이 다이어그램은 페이지 교체의 핵심적인 두 가지 동작, 즉 **페이지 아웃(Page Out)**과 **페이지 인(Page In)**을 중심으로 구성되어 있습니다. 전체 과정을 따라가며 각 단계의 의미를 분석해 보겠습니다.\n전제 상황: 프로세스가 페이지 j에 접근하려고 시도했으나, 페이지 j는 현재 물리 메모리에 없어 페이지 폴트가 발생했습니다. 동시에, 물리 메모리의 모든 프레임은 이미 다른 페이지들로 가득 차 있는 상태입니다.\n1. 희생 페이지 선택 및 페이지 아웃 (Find Victim page ’m’ and Page it out)\n동작: 다이어그램의 첫 번째 큰 화살표(1, 2)는 ‘페이지 아웃’ 과정을 보여줍니다. 운영 체제의 페이지 교체 알고리즘이 실행되어, 현재 물리 메모리에 있는 페이지 중 페이지 m을 희생양(victim)으로 선택합니다. page out: 선택된 페이지 m은 물리 메모리의 프레임에서 디스크(Backing Store / Swap Space)로 복사됩니다. 이 그림에서 페이지 아웃 화살표가 그려져 있다는 것은, 페이지 m의 더티 비트(dirty bit)가 1이었음을 암시합니다. 즉, 페이지 m은 메모리에 로드된 후 내용이 변경되었기 때문에, 그 변경사항을 디스크에 저장해야만 합니다. 만약 더티 비트가 0이었다면 이 디스크 쓰기 과정은 생략될 수 있습니다. 2. 희생 페이지의 페이지 테이블 수정 (Change page table for page ’m’)\n동작: 다이어그램의 작은 원(3)은 페이지 테이블의 변경을 나타냅니다. 페이지 m이 더 이상 물리 메모리에 존재하지 않으므로, 이 사실을 페이지 테이블에 반영해야 합니다. invalid: 페이지 m에 해당하는 페이지 테이블 항목(PTE)으로 가서 유효-무효 비트를 ‘v’(valid)에서 ‘i’(invalid)로 변경합니다. 이제 시스템은 페이지 m이 물리 메모리에 없다는 것을 알게 됩니다. 프레임 번호 필드는 이제 무의미해집니다. 3. 새로운 페이지의 페이지 인 (Page in desired page ‘j’)\n동작: 다이어그램의 두 번째 큰 화살표(4)는 ‘페이지 인’ 과정을 보여줍니다. 이제 페이지 m이 차지하던 프레임이 비워졌으므로(또는 덮어쓸 수 있게 되었으므로), 원래 페이지 폴트를 유발했던 페이지 j를 디스크에서 이 프레임으로 읽어옵니다. page in: 이 과정은 디스크 읽기 I/O를 수반하며, 완료될 때까지 해당 프로세스는 대기 상태에 머물게 됩니다. 4. 새로운 페이지의 페이지 테이블 수정 (Reset page table for page ‘j’)\n동작: 다이어그램의 마지막 원(5)은 새로운 페이지 j에 대한 페이지 테이블 업데이트를 보여줍니다. valid: 페이지 j가 이제 물리 메모리에 성공적으로 로드되었으므로, 페이지 j에 해당하는 페이지 테이블 항목을 수정합니다. 유효-무효 비트를 ‘i’에서 ‘v’로 변경하고, 프레임 번호 필드에 페이지 j가 새로 자리 잡은 프레임의 번호를 기록합니다. 과정 완료 후: 이 모든 과정이 끝나면, 페이지 폴트를 유발했던 원래의 명령어가 재시작됩니다. 이제 CPU가 페이지 j에 접근하면 MMU는 유효한 페이지 테이블 항목을 통해 성공적으로 주소 변환을 수행할 수 있습니다. 프로세스는 아무 일 없었다는 듯이 실행을 계속합니다.","다이어그램의-함의#\u003cstrong\u003e다이어그램의 함의\u003c/strong\u003e":"이 다이어그램은 가상 메모리의 중요한 특징들을 명확히 보여줍니다.\n투명성 (Transparency): 프로세스는 페이지 폴트의 존재나 물리 메모리의 복잡한 할당 상태를 전혀 인지하지 못합니다. 모든 것은 MMU와 운영체제에 의해 ‘투명하게’ 처리됩니다. 유연성 (Flexibility): 논리적으로 연속적인 페이지를 물리적으로 흩어진 프레임에 배치할 수 있어, 물리 메모리의 단편화(fragmentation) 문제를 완화하고 메모리 사용 효율을 높입니다. 효율성 (Efficiency): 프로그램의 일부만 메모리에 올려도 실행이 가능하므로, 물리 메모리를 절약하고 더 많은 프로그램을 동시에 실행할 수 있게 합니다. 결론적으로 이 다이어그램은 요구 페이징 시스템의 정적인 구조와 동적인 동작 방식을 한눈에 파악할 수 있게 해주는 훌륭한 시각 자료입니다. 논리적 관점과 물리적 현실 사이의 괴리를 페이지 테이블과 유효-무효 비트가 어떻게 메우는지를 명확하게 보여줍니다.","다이어그램이-강조하는-점#\u003cstrong\u003e다이어그램이 강조하는 점\u003c/strong\u003e":"자원의 순환: 페이지 교체는 물리 메모리라는 한정된 자원을 ‘순환’시키는 메커니즘입니다. 오래되거나 덜 중요한 페이지를 내보내고, 새롭고 더 중요한 페이지를 들여옴으로써, 작은 물리 메모리로도 거대한 가상 메모리 공간을 시뮬레이션할 수 있습니다. I/O 비용: 이 다이어그램은 페이지 교체가 두 번의 디스크 I/O(페이지 아웃을 위한 쓰기 1번, 페이지 인을 위한 읽기 1번)를 유발할 수 있음을 명확히 보여줍니다. (물론, 더티 비트가 0이면 쓰기는 생략됩니다.) 이는 페이지 교체가 왜 비용이 많이 드는 작업이며, 왜 좋은 교체 알고리즘을 통해 페이지 폴트 자체를 최소화해야 하는지를 설명해 줍니다. 데이터 일관성: 페이지 테이블을 정확하게 업데이트하는 과정(2, 4단계)은 시스템의 데이터 일관성을 유지하는 데 매우 중요합니다. 만약 이 정보가 잘못되면 시스템은 엉뚱한 메모리 위치에 접근하여 심각한 오류를 일으킬 수 있습니다. 결론적으로, 이 다이어그램은 페이지 교체의 필요성과 그 구체적인 동작 방식을 압축적으로 보여주는 훌륭한 시각 자료입니다. 물리 메모리가 가득 찼을 때 시스템이 어떻게 동적으로 공간을 확보하고, 새로운 요청을 처리하며, 이 과정에서 발생하는 정보(페이지 테이블)를 일관되게 관리하는지를 한눈에 이해할 수 있게 해줍니다.","다이어그램이-전달하는-핵심-메시지#\u003cstrong\u003e다이어그램이 전달하는 핵심 메시지\u003c/strong\u003e":"이 다이어그램은 가상 메모리가 어떻게 ‘착시 현상’을 만들어내는지를 보여줍니다.\n추상화(Abstraction)와 환상(Illusion): 프로세스는 거대하고 연속적인 ‘논리 메모리’라는 이상적인 환경에서 실행됩니다. 하지만 실제 현실(‘물리 메모리’)는 작고, 여러 조각으로 나뉘어 있으며, 다른 프로세스들과 공유되고 있습니다. 가상 메모리 시스템은 이 복잡한 현실을 감추고 프로세스에게 단순하고 이상적인 메모리 모델을 제공하는 추상화 계층입니다. 마치 우리가 자동차를 운전할 때 엔진 내부의 복잡한 폭발 과정을 신경 쓰지 않고 액셀과 핸들만 조작하는 것과 같습니다.\n비연속적인 물리 메모리 할당: 다이어그램에서 논리 메모리의 연속된 영역들이 물리 메모리에서는 서로 떨어진, 비연속적인 위치에 할당될 수 있음을 보여줍니다. 예를 들어, 논리 주소 0-4KB에 해당하는 페이지는 물리 주소 8192번지에, 논리 주소 4-8KB에 해당하는 페이지는 물리 주소 20480번지에 저장될 수 있습니다. 이러한 유연성 덕분에 운영 체제는 물리 메모리의 빈 공간(단편화된 공간 포함)을 효율적으로 활용할 수 있습니다.\n디스크를 활용한 공간 확장: 논리 메모리의 모든 내용이 물리 메모리에 있을 필요는 없습니다. 당장 사용되지 않는 부분은 디스크에 남아있습니다. 이는 마치 책상(물리 메모리)이 좁아도 거대한 도서관(디스크)이 뒤에 있기 때문에 수많은 책(논리 메모리)을 다룰 수 있는 것과 같은 원리입니다. 이 메커니즘 덕분에 물리 메모리의 크기는 더 이상 프로그램의 크기를 제약하는 절대적인 한계가 아니게 됩니다.\nMMU의 역할: 이 모든 과정의 중심에는 MMU가 있습니다. CPU가 “논리 주소 100번지의 데이터를 가져와라\"라는 명령을 내리면, 이 주소는 MMU로 전달됩니다. MMU는 페이지 테이블을 참조하여 논리 주소 100번지가 현재 물리 메모리의 어떤 주소에 매핑되어 있는지 찾아냅니다. 만약 물리 주소 8292번지에 매핑되어 있다면, MMU는 이 주소를 실제 메모리 버스로 보내 데이터를 가져옵니다. 만약 페이지 테이블에 해당 논리 주소가 물리 메모리에 없다고 표시되어 있다면, MMU는 ‘페이지 폴트(Page Fault)‘라는 예외를 발생시켜 운영 체제에게 도움을 요청합니다. 그러면 운영 체제가 디스크에서 해당 데이터를 물리 메모리로 가져오는 후속 작업을 처리하게 됩니다.\n결론적으로, 이 슬라이드는 가상 메모리가 단순한 이론이 아니라, 페이지 테이블을 이용한 주소 변환(address translation)과 디스크를 활용한 공간 확장을 통해 실제로 구현되는 구체적인 시스템임을 명확히 보여줍니다. 이는 현대 운영 체제가 다중 프로그래밍, 대용량 프로그램 실행, 시스템 안정성 확보라는 세 마리 토끼를 모두 잡을 수 있게 해주는 근간 기술입니다.","다중-레벨-페이징-심층-분석#\u003cstrong\u003e다중 레벨 페이징 심층 분석\u003c/strong\u003e":"// Two-Level Page-Table Scheme Page Table of Page Table Page Table // Multi-level Paging Deep Dive  Offset (d): Identifies the byte within the 1KB page.  1KB = 2^10 bytes ⟹ 10 bits needed for the Offset.  Page Table Index (PTI) (P1): Indexes into a specific Page Table.  Goal: Each Page Table fits in 1KB.  With 4-byte PTEs, a 1KB Page Table can hold 1024/4=256 entries.  To address 256 entries ⟹ 8 bits needed for PTI (2^8=256).  Page Directory Index (PDI) (P2): Indexes into the Page Directory.  Remaining bits: 32 bits (total)−10 bits (Offset)−8 bits (PTI)=14 bits. // Multi-level Paging Deep Dive  Page Directory:  Purpose: Contains entries that point to the physical addresses of Page Tables.  Entries: 2^14 entries (from PDI field).  Entry Size (PDE): 4 bytes (stores physical address of a Page Table + flags).  Total Size: 2^14 entries×4 bytes/entry = 65,536 bytes = 64 KB.  Storage: Stored in 64 contiguous physical frames (PDBR register)  Page Table:  Purpose: Contains entries that point to the physical addresses of actual data/code pages (frames).  Entries: 2^8=256 entries (from PTI field).  Entry Size (PTE): 4 bytes (stores physical address of a data frame + flags).  Total Size: 256 entries×4 bytes/entry=1024 bytes=1 KB.  Storage: Each Page Table fits exactly into one physical frame. // Multi-level Paging: Page Directory  Where is the Page Directory Stored?  Page Directory Entry (PDE) Size: Not 1 byte! It's 4 bytes, just like a PTE.  Needs to store a 22-bit physical frame number (for the Page Table) + control bits.  Control bits (flags): presence bit, read-only, user/kernel, ...  Page Directory Size:  2^14 PDI entries×4 bytes/PDE=2^16 bytes= 64 KB = 64 pages  Storage: A 64 KB Page Directory does not fit in a single 1KB page.  Solution  The Page Directory is stored in multiple contiguous physical frames (64 frames in this case).  PDBR: Points to the beginning physical address of this 64 KB block. // 2계층 페이지 테이블 구조 페이지 테이블의 페이지 테이블 (페이지 디렉터리) 페이지 테이블 // 다중 레벨 페이징 심층 분석  오프셋 (d): 1KB 페이지 내의 특정 바이트를 식별합니다.  1KB = $2^{10}$ 바이트 ⟹ 오프셋을 위해 10비트가 필요합니다.  페이지 테이블 인덱스 (PTI) (P1): 특정 페이지 테이블을 인덱싱합니다.  목표: 각 페이지 테이블이 1KB 크기에 딱 맞도록 하는 것.  4바이트 PTE를 사용하면, 1KB 페이지 테이블은 1024/4 = 256개의 항목을 가질 수 있습니다.  256개의 항목을 주소 지정하려면 ⟹ PTI를 위해 8비트가 필요합니다 ($2^8=256$).  페이지 디렉터리 인덱스 (PDI) (P2): 페이지 디렉터리를 인덱싱합니다.  남은 비트: 32비트 (전체) - 10비트 (오프셋) - 8비트 (PTI) = 14비트. // 다중 레벨 페이징 심층 분석  페이지 디렉터리:  목적: 페이지 테이블들의 물리 주소를 가리키는 항목들을 포함합니다.  항목 수: $2^{14}$ 개 (PDI 필드로부터).  항목 크기 (PDE): 4바이트 (페이지 테이블의 물리 주소 + 플래그 저장).  전체 크기: $2^{14}$ 항목 × 4 바이트/항목 = 65,536 바이트 = 64 KB.  저장소: 64개의 연속된 물리 프레임에 저장됨 (PDBR 레지스터).  페이지 테이블:  목적: 실제 데이터/코드 페이지(프레임)의 물리 주소를 가리키는 항목들을 포함합니다.  항목 수: $2^8=256$ 개 (PTI 필드로부터).  항목 크기 (PTE): 4바이트 (데이터 프레임의 물리 주소 + 플래그 저장).  전체 크기: 256 항목 × 4 바이트/항목 = 1024 바이트 = 1 KB.  저장소: 각 페이지 테이블은 하나의 물리 프레임에 정확히 들어맞습니다. // 다중 레벨 페이징: 페이지 디렉터리  페이지 디렉터리는 어디에 저장되는가?  페이지 디렉터리 항목(PDE) 크기: 1바이트가 아님! PTE처럼 4바이트입니다.  (페이지 테이블을 가리키는) 22비트 물리 프레임 번호 + 제어 비트들을 저장해야 합니다.  제어 비트(플래그): 존재 비트, 읽기 전용, 사용자/커널 모드...  페이지 디렉터리 크기:  $2^{14}$ 개의 PDI 항목 × 4 바이트/PDE = $2^{16}$ 바이트 = 64 KB = 64 페이지  저장소: 64KB 크기의 페이지 디렉터리는 단일 1KB 페이지에 들어갈 수 없습니다.  해결책  페이지 디렉터리는 여러 개의 연속된 물리 프레임(이 경우 64개)에 저장됩니다.  PDBR: 이 64KB 블록의 시작 물리 주소를 가리킵니다. 이 슬라이드들은 2계층 페이징의 구체적인 작동 원리를 설명합니다. 핵심 아이디어는 “페이지 테이블을 페이징한다” 즉, 거대한 단일 페이지 테이블을 여러 개의 작은 페이지 테이블 조각으로 나누고, 이 조각들의 위치를 관리하는 상위 테이블(페이지 디렉터리)을 두는 것입니다.\n*1. 가상 주소의 분할 (\n2계층 페이징에서는 32비트 가상 주소를 더 이상 [페이지 번호 | 오프셋] 두 부분으로 나누지 않고, 세 부분으로 나눕니다.\n| 페이지 디렉터리 인덱스 (P2) | 페이지 테이블 인덱스 (P1) | 오프셋 (d) |\n오프셋 (d): 페이지(또는 프레임) 내에서의 상대적인 위치. 이것은 단일 레벨 페이징과 동일합니다. 페이지 크기가 1KB(210 바이트)이므로, 오프셋은 10비트가 됩니다. 페이지 테이블 인덱스 (PTI, P1): 2계층(하위) 페이지 테이블 내에서 특정 항목(PTE)을 찾는 데 사용됩니다. 여기서 중요한 설계 목표는 “하위 페이지 테이블 하나를 페이지 하나 크기에 맞추는 것\"입니다. 페이지 크기가 1KB(1024 바이트)이고 PTE가 4바이트이므로, 페이지 테이블 하나에는 1024/4=256개의 PTE를 담을 수 있습니다. 256개의 항목 중 하나를 선택하기 위해서는 log2​(256)=8비트가 필요합니다. 따라서 PTI는 8비트가 됩니다. 페이지 디렉터리 인덱스 (PDI, P2): 1계층(상위) 페이지 테이블, 즉 페이지 디렉터리 내에서 특정 항목(PDE)을 찾는 데 사용됩니다. 전체 32비트에서 오프셋과 PTI 비트를 뺀 나머지 비트가 모두 PDI에 할당됩니다. 32−10(offset)−8(PTI)=14비트. 따라서 PDI는 14비트가 됩니다. 최종적으로 가상 주소는 | 14비트 (PDI) | 8비트 (PTI) | 10비트 (Offset) | 구조를 갖게 됩니다.\n2. 주소 변환 과정 (Address Translation Process)\nCPU가 이 32비트 가상 주소를 물리 주소로 변환하는 과정은 다음과 같습니다.\n1단계: 페이지 디렉터리 조회\nCPU는 **PDBR (Page Directory Base Register)**이라는 특별한 레지스터에 저장된 페이지 디렉터리의 시작 물리 주소를 가져옵니다. 가상 주소의 상위 14비트(PDI)를 사용하여 페이지 디렉터리 내에서 원하는 **PDE(Page Directory Entry)**를 찾습니다. PDE의 주소는 PDBR + (PDI × 4)로 계산됩니다. 이 PDE에는 2계층 페이지 테이블의 시작 물리 주소(정확히는 프레임 번호)가 들어있습니다. 2단계: 페이지 테이블 조회\n1단계에서 찾은 PDE로부터 2계층 페이지 테이블의 시작 주소를 얻습니다. 가상 주소의 중간 8비트(PTI)를 사용하여 이 2계층 페이지 테이블 내에서 원하는 **PTE(Page Table Entry)**를 찾습니다. PTE의 주소는 (PDE가 가리키는 주소) + (PTI × 4)로 계산됩니다. 이 PTE에는 최종적으로 원하는 데이터가 담긴 데이터 페이지의 물리 프레임 주소가 들어있습니다. 3단계: 최종 주소 계산\n2단계에서 찾은 PTE로부터 데이터 프레임의 시작 물리 주소를 얻습니다. 가상 주소의 하위 10비트(오프셋)를 이 시작 주소에 더하여 최종 물리 주소를 얻습니다. (PTE가 가리키는 주소) + offset. 3. 페이지 디렉터리의 저장 (8.9)\n페이지 디렉터리(1계층 테이블): PDI가 14비트이므로, 214=16,384개의 항목(PDE)을 가집니다. 각 PDE는 4바이트이므로, 페이지 디렉터리 전체 크기는 16,384×4 Bytes=65,536 Bytes=64 KB입니다. 페이지 테이블(2계층 테이블): PTI가 8비트이므로, 28=256개의 항목(PTE)을 가집니다. 각 PTE는 4바이트이므로, 페이지 테이블 하나의 크기는 256×4 Bytes=1024 Bytes=1 KB입니다. 이는 정확히 페이지 하나 크기와 같습니다. 여기서 중요한 점은, 64KB 크기의 페이지 디렉터리는 1KB 페이지 하나에 들어갈 수 없다는 것입니다. 따라서 페이지 디렉터리는 64KB/1KB=64개의 연속된 물리 프레임에 걸쳐 저장되어야 합니다. 그리고 CPU의 PDBR 레지스터는 바로 이 64KB 블록의 시작 물리 주소를 저장하는 역할을 합니다.\n이 구조는 희소성 문제를 완벽하게 해결합니다. 만약 프로세스가 4GB 공간 중 특정 영역(예: 수백 MB)을 전혀 사용하지 않는다면, 해당 영역에 해당하는 PDE 항목들을 그냥 ‘invalid’로 표시해두면 됩니다. 그러면 그 PDE들이 가리켰어야 할 2계층 페이지 테이블(각 1KB)들은 아예 생성할 필요가 없어지므로 메모리를 크게 절약할 수 있습니다.","다중-레벨-페이징의-장단점#\u003cstrong\u003e다중 레벨 페이징의 장단점\u003c/strong\u003e":"//  Multi-level Paging: Advantage  Reduced Memory Consumption  Only Page Tables for actively used virtual address ranges need to be in physical memory. Unused ranges don't require their corresponding page tables.  Efficient Handling of Sparse Address Spaces  A process can have a huge virtual address space, but only a few Page Tables are allocated for the parts it actually uses.  Simplified Swapping  If a large portion of a process's virtual memory is swapped out, the OS can simply mark the corresponding PDE as \"not present,\" rather than iterating through and marking individual PTEs.  Improved Memory Utilization  Fewer frames are consumed by page tables, leaving more for process data. //  Multi-level Paging: Disadvantage  Increased Latency for Address Translation  Each memory access now potentially requires two memory lookups (one for the PDE, one for the PTE) before the actual data can be accessed.  Mitigation: Translation Lookaside Buffer (TLB) 4 A small, fast hardware cache within the CPU. 4 Stores recent virtual-to-physical address translations. 4 If a translation is found in the TLB (a \"TLB hit\"), the CPU bypasses the entire page table walk, significantly speeding up access. 4 TLB hits are common due to locality of reference //  다중 레벨 페이징: 장점  메모리 소비 감소  활발하게 사용되는 가상 주소 범위에 대한 페이지 테이블만 물리 메모리에 있으면 됩니다. 사용되지 않는 범위는 해당 페이지 테이블을 필요로 하지 않습니다.  희소 주소 공간의 효율적 처리  프로세스는 거대한 가상 주소 공간을 가질 수 있지만, 실제로 사용하는 부분에 대해서만 몇 개의 페이지 테이블이 할당됩니다.  단순화된 스와핑  프로세스 가상 메모리의 큰 부분이 스왑 아웃되면, OS는 개별 PTE들을 일일이 순회하며 표시하는 대신, 해당하는 PDE를 \"존재하지 않음(not present)\"으로 표시하기만 하면 됩니다.  향상된 메모리 활용률  페이지 테이블에 의해 소비되는 프레임이 줄어들어, 프로세스 데이터를 위한 공간이 더 많이 남게 됩니다. //  다중 레벨 페이징: 단점  주소 변환을 위한 지연 시간 증가  이제 각각의 메모리 접근은 실제 데이터에 접근하기 전에 잠재적으로 두 번의 메모리 조회(한 번은 PDE, 한 번은 PTE)를 요구합니다.  완화 방안: TLB (Translation Lookaside Buffer) 4 CPU 내부에 있는 작고 빠른 하드웨어 캐시. 4 최근의 가상-물리 주소 변환 결과를 저장합니다. 4 만약 변환 결과가 TLB에서 발견되면(\"TLB 히트\"), CPU는 전체 페이지 테이블 탐색을 건너뛰어 접근 속도를 크게 향상시킵니다. 4 참조의 지역성(locality of reference) 때문에 TLB 히트는 흔하게 발생합니다. 1. 장점 (Advantages)\n메모리 절약 (핵심 장점): 앞서 설명했듯이, 사용하지 않는 가상 주소 공간에 대해서는 2계층 페이지 테이블을 아예 생성하지 않음으로써 막대한 양의 메모리를 절약합니다. 16MB를 통째로 할당하는 대신, 실제로 필요한 만큼의 1KB짜리 페이지 테이블 조각들과 64KB짜리 페이지 디렉터리만 할당하면 됩니다. 스와핑 효율성: 메모리가 부족할 때 운영체제는 일부 페이지를 디스크(스왑 공간)로 내보냅니다(스왑 아웃). 만약 연속된 8MB의 메모리 블록(256개의 페이지 테이블 하나가 관리하는 영역)이 통째로 스왑 아웃된다면, 256개의 PTE를 하나씩 수정할 필요 없이 이 페이지 테이블을 가리키는 단 하나의 PDE만 ‘invalid’로 변경하면 됩니다. 이는 운영체제의 작업을 훨씬 간단하고 빠르게 만듭니다. 2. 단점 (Disadvantage)과 해결책\n성능 저하 (지연 시간 증가): 이것이 다중 레벨 페이징의 가장 큰 단점입니다. 단일 레벨 페이징에서는 주소 변환을 위해 메모리를 한 번만 접근하면 됩니다(페이지 테이블 조회). 하지만 2계층 페이징에서는, 최악의 경우 메모리를 두 번 접근해야 합니다 (PDE 조회, PTE 조회). 만약 3계층, 4계층 페이징(64비트 시스템에서 일반적)을 사용한다면 메모리 접근 횟수는 더 늘어납니다. 모든 메모리 접근에 이러한 오버헤드가 추가된다면 시스템 전체의 성능이 급격히 저하될 것입니다.\n해결책: TLB (Translation Lookaside Buffer)\n정체: TLB는 CPU 안에 내장된 매우 작고 빠른 특수 캐시입니다. 일반적인 데이터 캐시가 아니라, 주소 변환 결과만을 저장하는 캐시입니다. 즉, (가상 페이지 번호, 물리 프레임 번호) 쌍을 저장합니다. 동작 원리: CPU가 가상 주소를 변환해야 할 때, 메인 메모리의 페이지 테이블을 찾아가기 전에 먼저 TLB를 확인합니다. TLB Hit (히트): 원하는 가상 페이지 번호에 대한 변환 정보가 TLB에 있는 경우입니다. CPU는 즉시 물리 프레임 번호를 얻어 주소 변환을 완료합니다. 느린 메인 메모리 접근이 완전히 생략되므로 매우 빠릅니다. TLB Miss (미스): 변환 정보가 TLB에 없는 경우입니다. 이 경우에만 CPU는 어쩔 수 없이 메인 메모리에 있는 페이지 테이블(페이지 디렉터리 -\u003e 페이지 테이블)을 순차적으로 접근하여 주소 변환을 수행합니다. 그리고 이렇게 힘들게 알아낸 변환 결과는 다음 사용을 위해 TLB에 새로 저장합니다. 효과: 프로그램은 특정 시간 동안 특정 코드와 데이터 영역에 집중적으로 접근하는 경향이 있습니다. 이를 **참조의 지역성(Locality of Reference)**이라고 합니다. 이 특성 덕분에 한 번 TLB에 저장된 주소 변환 정보는 다시 사용될 확률이 매우 높습니다. 따라서 TLB 히트율(Hit Ratio)은 보통 99% 이상으로 매우 높게 유지되며, 다중 레벨 페이징의 성능 저하 단점을 대부분 상쇄시켜 줍니다. 결론적으로, 다중 레벨 페이징은 TLB라는 하드웨어의 도움을 받아 메모리 공간 효율과 시간 효율이라는 두 마리 토끼를 모두 잡는 매우 효과적인 가상 메모리 관리 기법입니다.","단일-레벨-페이징의-문제-problem-of-single-level-paging#\u003cstrong\u003e단일 레벨 페이징의 문제 (Problem of Single-level Paging)\u003c/strong\u003e":" 32-bit Machine with 1KB page  Virtual Address Space: 2^32 bytes (4 GB)  Page Size: 2^10 bytes (1 KB)  Number of Virtual Pages: 2^32/2^10=2^22 pages  Single-Level Page Table:  Requires one entry for every possible virtual page.  Each Page Table Entry (PTE): Typically 4 bytes (Physical Frame Number + control bits).  Total Size: 2^22 pages × 4 bytes/PTE = 2^24 bytes = 16 MB.  The Problem:  Excessive Memory Usage: 16 MB per process is too large.  Sparsity 4 Most processes use only a small fraction of their 4GB virtual space; much of this 16MB table would be empty.  1KB 페이지를 사용하는 32비트 머신  가상 주소 공간: $2^{32}$ 바이트 (4 GB)  페이지 크기: $2^{10}$ 바이트 (1 KB)  가상 페이지의 수: $2^{32} / 2^{10} = 2^{22}$ 페이지  단일 레벨 페이지 테이블:  모든 가능한 가상 페이지 각각에 대해 하나의 항목(entry)이 필요합니다.  각 페이지 테이블 항목(PTE): 일반적으로 4바이트 (물리 프레임 번호 + 제어 비트).  전체 크기: $2^{22}$ 페이지 × 4 바이트/PTE = $2^{24}$ 바이트 = 16 MB.  문제점:  과도한 메모리 사용량: 프로세스당 16MB는 너무 큽니다.  희소성 (Sparsity) 4 대부분의 프로세스는 4GB 가상 공간의 극히 일부만 사용합니다. 즉, 이 16MB 테이블의 대부분은 비어있을 것입니다. 이 슬라이드는 페이지 크기를 이전 예시(4KB)보다 작은 1KB로 변경하여 단일 레벨 페이징의 문제점을 더욱 극적으로 보여줍니다.\n1. 계산 다시 보기 (페이지 크기 1KB)\n페이지 크기가 작아지면, 같은 크기의 가상 주소 공간을 덮기 위해 더 많은 수의 페이지가 필요하게 됩니다. 가상 페이지의 수: Page SizeVirtual Address Space​=210232​=222 222는 4,194,304로, 약 4백만 개의 페이지입니다. 페이지 테이블의 전체 크기: (Number of Pages)×(Size of PTE)=222×4 Bytes=22×222 Bytes=224 Bytes 224 바이트는 16,777,216 바이트, 즉 16MB입니다. 이전 예시에서는 4MB였지만, 페이지 크기를 1/4로 줄이니 페이지 테이블의 크기는 4배로 커져 16MB가 되었습니다. 이는 프로세스 하나를 위한 오버헤드치고는 용납하기 어려운 수준의 크기입니다.\n2. 핵심 문제: 희소성 (Sparsity)\n이 슬라이드의 핵심 단어는 **‘희소성(Sparsity)’**입니다.\n정의: ‘희소성’이란, 전체 할당된 공간 중에서 실제로 사용되는 부분은 매우 적고 대부분은 비어있는 상태를 의미합니다. 페이지 테이블에서의 희소성: 대부분의 프로그램은 운영체제가 부여한 4GB의 가상 주소 공간을 전부 사용하지 않습니다. 간단한 “Hello, World!” 프로그램은 코드, 데이터, 스택을 다 합쳐도 수십 킬로바이트(KB)면 충분합니다. 예를 들어, 프로그램이 주소 공간의 맨 앞부분(코드, 데이터 영역)과 맨 뒷부분(스택 영역)만 사용한다고 가정해 봅시다. 중간의 거대한 영역(수 기가바이트)은 전혀 사용되지 않습니다. 하지만 단일 레벨 페이지 테이블은 이 사용되지 않는 중간 영역에 해당하는 수백만 개의 페이지 테이블 항목(PTE)을 모두 메모리에 만들어 두어야 합니다. 이 PTE들은 ‘이 페이지는 메모리에 없음(invalid)‘을 나타내는 플래그만 설정된 채로 16MB의 공간을 차지하며 메모리를 낭비하게 됩니다. 결론적으로, 단일 레벨 페이징은 **‘잠재적으로 사용될 수 있는 모든 가상 페이지’**에 대해 PTE를 할당하기 때문에, 실제 사용량과 무관하게 항상 거대한 메모리를 차지하는 비효율적인 구조입니다.","두-가지-제약-조건이-설계에-영향을-미침#\u003cstrong\u003e두 가지 제약 조건이 설계에 영향을 미침\u003c/strong\u003e":"","매우-자세한-설명-detailed-explanation#\u003cstrong\u003e매우 자세한 설명 (Detailed Explanation)\u003c/strong\u003e":"이 슬라이드는 **생산자-소비자 문제(Producer-Consumer Problem)**라는 고전적인 동시성(Concurrency) 문제를 소개하고 있습니다. 이 문제는 여러 프로세스나 스레드가 **공유 자원(Shared Resource)**에 동시에 접근할 때 발생할 수 있는 위험을 명확하게 보여줍니다.\n1. 구성 요소 분석\nShared Buffer (공유 버퍼): 생산자(Producer)가 데이터를 생성하여 넣는 공간이자, 소비자(Consumer)가 데이터를 가져다 쓰는 공간입니다. 여러 프로세스가 함께 사용하는 ‘공유 메모리’ 영역에 존재합니다. 슬라이드에서는 이 버퍼가 **원형 배열(Circular Array)**로 구현되었다고 가정합니다. 원형 배열은 배열의 마지막 인덱스 다음에 다시 첫 인덱스로 돌아오는 구조로, 한정된 크기의 버퍼를 효율적으로 사용하는 데 적합합니다. Producer/Consumer (생산자/소비자): 생산자(Producer): 데이터를 생성하여 버퍼에 넣는 역할을 하는 프로세스입니다. 데이터가 꽉 차지 않았다면(counter \u003c BS), ‘in’ 포인터가 가리키는 위치에 데이터를 삽입하고 ‘in’ 포인터를 다음 위치로 이동시킵니다. 소비자(Consumer): 버퍼에서 데이터를 가져와 소비하는 역할을 하는 프로세스입니다. 데이터가 비어있지 않다면(counter \u003e 0), ‘out’ 포인터가 가리키는 위치에서 데이터를 꺼내고 ‘out’ 포인터를 다음 위치로 이동시킵니다. in / out 포인터: 버퍼에서 다음 데이터가 삽입될 위치(in)와 다음 데이터가 인출될 위치(out)를 가리키는 변수입니다. counter 변수: 버퍼에 현재 저장된 데이터의 개수를 나타내는 정수 변수입니다. 생산자가 데이터를 넣으면 counter가 1 증가(counter++)하고, 소비자가 데이터를 빼가면 counter가 1 감소(counter--)합니다. 이 counter 변수 역시 공유 자원입니다. 생산자와 소비자 모두 이 변수를 읽고 수정해야 하기 때문입니다. 2. 동시성 문제의 핵심: Race Condition (경쟁 상태)\n슬라이드의 핵심은 counter++와 counter-- 연산에서 동시성 문제가 발생할 수 있음을 보여주는 부분입니다. 우리가 C언어 등 고급 언어에서 counter++; 라고 한 줄로 간단하게 작성하는 코드도, 컴파일되어 기계어로 번역되면 실제로는 여러 단계의 명령어로 나뉩니다.\n슬라이드에서는 이 과정을 3단계로 나누어 설명합니다.\n메모리에서 레지스터로 값을 가져온다: register1 = counter 레지스터의 값을 연산한다: register1 = register1 + 1 레지스터의 값을 다시 메모리에 저장한다: counter = register1 문제는 이 3단계의 연산이 **원자적(Atomic)**으로 실행되지 않는다는 점입니다. 즉, 1단계와 3단계 사이에 얼마든지 다른 프로세스에게 CPU 제어권이 넘어갈 수 있습니다.\n구체적인 시나리오:\n가정: counter의 현재 값은 5입니다. 생산자(P)와 소비자(C)가 거의 동시에 counter에 접근하려고 합니다.\n생산자(P) 실행: register1 = counter를 실행합니다. 생산자의 register1에는 5가 저장됩니다. 문맥 교환 (Context Switch) 발생: 생산자가 register1 = register1 + 1을 실행하기 직전에, 운영체제의 스케줄러가 CPU 제어권을 소비자(C)에게 넘겨줍니다. (예: 타임 슬라이스 만료) 소비자(C) 실행: 소비자는 counter-- 연산을 처음부터 끝까지 모두 실행합니다. register2 = counter (메모리의 counter는 아직 5이므로, register2에 5가 저장됨) register2 = register2 - 1 (register2는 4가 됨) counter = register2 (메모리의 counter 값이 4로 업데이트됨) 문맥 교환 (Context Switch) 발생: 이제 다시 CPU 제어권이 생산자(P)에게 돌아옵니다. 생산자(P) 실행 재개: 생산자는 이전에 중단되었던 지점부터 실행을 이어갑니다. register1 = register1 + 1 (생산자의 register1은 5였으므로, 6이 됨) counter = register1 (메모리의 counter 값을 6으로 덮어씁니다.) 결과: 최종 counter 값은 6이 됩니다. 하지만 논리적으로는 생산자가 1을 더하고 소비자가 1을 뺐으므로 원래 값인 5가 되어야 합니다. 데이터의 정합성이 깨진 것입니다. 이러한 상황을 **경쟁 상태(Race Condition)**라고 부르며, 여러 프로세스가 공유 자원에 동시에 접근하여 조작하려 할 때 실행 순서에 따라 결과가 달라지는 현상을 말합니다. 이 문제를 해결하기 위한 매커니즘이 바로 다음에 나올 임계 구역(Critical Section) 문제입니다.","매우-자세한-설명-detailed-explanation-1#\u003cstrong\u003e매우 자세한 설명 (Detailed Explanation)\u003c/strong\u003e":"앞선 슬라이드에서 counter 변수와 같은 공유 자원에 접근할 때 발생하는 경쟁 상태를 확인했습니다. **임계 구역 문제(Critical Section Problem)**는 이러한 경쟁 상태를 해결하기 위한 문제를 공식적으로 정의한 것입니다.\n1. 용어 정의\n프로세스(Process): 시스템에서 실행 중인 프로그램을 의미하며, 자신만의 메모리 공간과 자원을 가집니다. 이 슬라이드에서는 여러 개의 프로세스(p0부터 pn-1까지)가 협력하며 동작하는 환경을 가정합니다. 임계 구역 (Critical Section): 프로세스 코드 중에서 **공유 자원(shared resource)**에 접근하는 부분을 말합니다. 앞선 예시에서는 counter++ 또는 counter--를 수행하는 코드 블록이 바로 임계 구역에 해당합니다. 이 외에도 공유 변수, 공유 파일, 공유 데이터베이스 등을 조작하는 모든 코드가 임계 구역이 될 수 있습니다. 임계 구역의 핵심 특징은, 두 개 이상의 프로세스가 동시에 실행하면 안 된다는 점입니다. 진입 구역 (Entry Section): 임계 구역에 들어가기 전에, 진입 허가를 요청하고 대기하는 코드 부분입니다. 여기서 다른 프로세스가 이미 임계 구역에 있는지 확인하고, 비어있다면 진입하고, 아니라면 기다리는 로직이 수행됩니다. 퇴출 구역 (Exit Section): 임계 구역에서의 작업을 마친 후, 다른 프로세스가 임계 구역에 진입할 수 있도록 상태를 변경해주는 코드 부분입니다. 예를 들어, “이제 내가 다 썼으니 다른 프로세스가 들어와도 된다\"는 신호를 보내는 역할을 합니다. 나머지 구역 (Remainder Section): 임계 구역과 관련 없는, 즉 공유 자원에 접근하지 않는 나머지 코드 부분입니다. 이 부분은 다른 프로세스와 동시에 실행되어도 아무런 문제가 없습니다. 2. 문제의 본질\n임계 구역 문제의 본질은 “어떻게 하면 진입 구역(Entry Section)과 퇴출 구역(Exit Section)의 프로토콜(규칙)을 잘 설계해서, 여러 프로세스가 임계 구역을 안전하고 효율적으로 사용하게 할 것인가?” 입니다.\n슬라이드에서 언급된 가장 중요한 규칙은 “만약 한 프로세스가 자신의 임계 구역에서 실행 중이라면, 다른 어떤 프로세스도 자신의 임계 구역에서 실행될 수 없다” 는 것입니다. 이를 상호 배제(Mutual Exclusion) 라고 하며, 뒤따르는 슬라이드에서 해결책의 필수 요건 중 하나로 다시 등장합니다.\n예를 들어, 여러 사람이 하나의 화장실을 사용한다고 생각해봅시다.\n화장실 내부 = 임계 구역 (한 번에 한 명만 사용 가능) 화장실 문을 두드리고 안이 비었는지 확인하는 행동 = 진입 구역 볼일을 다 보고 나와서 문을 열어주는 행동 = 퇴출 구역 자기 자리에서 다른 일을 하는 것 = 나머지 구역 임계 구역 문제는 이 화장실을 여러 사람이 질서 있고 문제없이 사용하기 위한 규칙(프로토콜)을 만드는 것과 같습니다. “안에 사람이 있으면 기다린다”, “나올 때는 다음 사람이 쓸 수 있게 한다\"와 같은 규칙을 코드 레벨에서 구현하는 것이 목표입니다. 이 프로토콜은 다음에 설명될 3가지 요구사항(상호 배제, 진행, 한정된 대기)을 반드시 만족해야 합니다.","매우-자세한-설명-detailed-explanation-10#\u003cstrong\u003e매우 자세한 설명 (Detailed Explanation)\u003c/strong\u003e":"이 슬라이드들은 현대적인 하드웨어에서 임계 구역 문제를 해결하는 표준적인 방법인 **원자적 명령어(Atomic Instruction)**를 소개합니다. 특히 TestAndSet 이라는 대표적인 명령어를 예로 듭니다.\n1. 문제의 재확인과 해결의 방향 (슬라이드 15)\n슬라이드 15는 첫 번째 시도였던 lock 변수 방식의 실패 원인이 **TEST(확인)**와 SET(설정) 사이의 ‘틈’ 때문이었음을 다시 한번 상기시킵니다. 그리고 해결책으로 이 두 동작을 하나의 명령어 TestAndSet으로 합쳐버리는 아이디어를 제시합니다. 이 명령어는 하드웨어 수준에서 **원자성(Atomicity)**을 보장받습니다. 즉, TestAndSet 명령어가 실행되는 동안에는 CPU가 다른 어떤 인터럽트나 다른 프로세스의 메모리 접근을 허용하지 않고, 명령어의 모든 내부 동작(읽고-쓰기)이 끝날 때까지 기다립니다.\n2. TestAndSet 명령어의 동작 (슬라이드 16)\nTestAndSet 함수는 메모리 주소를 인자로 받아 다음과 같이 동작합니다.\n주어진 주소(target)에 있는 현재 값을 읽어서 임시 변수(rv)에 저장합니다. 주어진 주소(target)에 무조건 TRUE 값을 씁니다. (슬라이드의 ‘Better’ 버전이 일반적인 구현입니다.) 임시 변수(rv)에 저장해 두었던 원래 값을 반환합니다. 이 모든 과정이 하나의 분리 불가능한(indivisible) 하드웨어 명령으로 실행됩니다.\n3. TestAndSet을 이용한 최종 해결책 (슬라이드 17)\n이 원자적 명령어를 사용하면 임계 구역의 entry section을 매우 간결하고 안전하게 구현할 수 있습니다.\n공유 변수 lock을 boolean 타입으로 선언하고 FALSE (잠기지 않음)로 초기화합니다. Entry Section: while (TestAndSet(\u0026lock)); Exit Section: lock = FALSE; 동작 시나리오:\nCase 1: 임계 구역이 비어있을 때 (lock == FALSE)\n프로세스 P0가 TestAndSet(\u0026lock)을 호출합니다. TestAndSet은 lock의 현재 값인 FALSE를 반환하고, 동시에 lock의 값을 TRUE로 원자적으로 변경합니다. while문은 while(FALSE)가 되므로, 루프를 즉시 빠져나옵니다. P0는 임계 구역에 진입합니다. 이제 lock은 TRUE이므로 다른 프로세스는 들어올 수 없습니다. Case 2: 다른 프로세스가 임계 구역에 있을 때 (lock == TRUE)\n프로세스 P1이 TestAndSet(\u0026lock)을 호출합니다. TestAndSet은 lock의 현재 값인 TRUE를 반환하고, lock의 값은 계속 TRUE로 유지됩니다. while문은 while(TRUE)가 되므로, P1은 루프를 계속 돌며 대기합니다. (이를 스핀락(Spinlock) 또는 **바쁜 대기(Busy-waiting)**라고 합니다.) P0가 임계 구역을 빠져나오며 lock = FALSE;를 실행합니다. 다음 while 루프 차례에서 P1이 다시 TestAndSet(\u0026lock)을 호출하면, 이제 lock은 FALSE이므로 Case 1과 동일하게 동작하여 P1이 임계 구역에 진입하게 됩니다. 평가:\n상호 배제 (Mutual Exclusion) - 만족 ✔️: TestAndSet의 원자성 덕분에, lock을 확인하고 TRUE로 설정하는 과정이 쪼개질 수 없으므로 두 프로세스가 동시에 진입하는 것이 원천적으로 불가능합니다. 진행 (Progress) - 만족 ✔️: 임계 구역이 비어있으면(lock=FALSE), TestAndSet을 시도하는 첫 번째 프로세스는 반드시 진입에 성공하므로 진행 조건이 만족됩니다. 한정된 대기 (Bounded Waiting) - 실패 ❌: 이 간단한 TestAndSet 구현은 한정된 대기 조건을 만족하지 않습니다. 여러 프로세스가 동시에 대기 중일 때, CPU 스케줄링에 따라 운이 없는 프로세스는 계속해서 기회를 놓치고 **기아 상태(Starvation)**에 빠질 수 있습니다. 이 문제를 해결하려면 TestAndSet과 함께 다른 변수(예: 대기 큐나 waiting 배열)를 사용하여 순서를 보장해주는 추가적인 로직이 필요합니다. 하지만 TestAndSet과 같은 원자적 명령어는 임계 구역 문제를 해결하는 데 필요한 **강력하고 필수적인 하드웨어 기반의 빌딩 블록(building block)**을 제공한다는 점에서 매우 중요합니다. 운영체제는 이러한 원자적 명령어를 기반으로 세마포어, 뮤텍스 등 더 정교하고 공정한 동기화 도구들을 구현합니다.","매우-자세한-설명-detailed-explanation-2#\u003cstrong\u003e매우 자세한 설명 (Detailed Explanation)\u003c/strong\u003e":"이 슬라이드는 앞서 설명한 임계 구역 문제의 해결을 위한 프로세스의 일반적인 코드 구조를 보여줍니다. 이는 개념적인 템플릿으로, 모든 프로세스는 임계 구역에 접근하기 위해 이와 같은 흐름을 따라야 함을 나타냅니다.\ndo-while(true) 루프의 의미\n프로세스의 생명주기는 일반적으로 반복적인 작업을 수행합니다. 예를 들어 웹 서버 프로세스는 클라이언트의 요청을 계속해서 받고 처리하며, 워드 프로세서는 사용자의 입력을 계속해서 기다리고 문서를 업데이트합니다. do-while(true) 루프는 이러한 프로세스의 지속적인 실행 사이클을 표현합니다. 프로세스는 종료되지 않는 한, 임계 구역에 접근하고 나머지 작업을 수행하는 이 사이클을 무한히 반복합니다.\n각 구역의 역할과 흐름\nentry section (진입 구역):\n프로세스가 임계 구역에 진입하고자 할 때 가장 먼저 실행되는 코드입니다. 목표: 임계 구역에 진입할 수 있는 ‘권한’ 또는 ‘잠금(lock)‘을 획득하는 것입니다. 동작: 다른 프로세스가 이미 임계 구역 내에서 실행 중인지 확인합니다. 만약 그렇다면, 해당 프로세스가 임계 구역을 빠져나올 때까지 대기해야 합니다. 이 대기하는 방식은 CPU를 계속 소모하며 기다리는 **바쁜 대기(busy-waiting)**일 수도 있고, 대기 큐에 들어가 잠드는 방식일 수도 있습니다. 이 구역의 설계가 임계 구역 문제 해결의 핵심입니다. critical section (임계 구역):\n진입 구역을 성공적으로 통과한 프로세스만이 이 구역의 코드를 실행할 수 있습니다. **상호 배제(Mutual Exclusion)**가 보장되어야 하는 구간입니다. 즉, 어떤 시점이든 최대 하나의 프로세스만이 이 구역 안에 있을 수 있습니다. 여기서는 공유 변수 수정, 공유 파일 쓰기, 공유 데이터 구조 변경 등 경쟁 상태를 유발할 수 있는 작업들이 수행됩니다. 앞선 예시에서는 counter++ 또는 counter-- 연산이 여기에 해당합니다. exit section (퇴출 구역):\n임계 구역에서의 모든 작업을 마친 프로세스가 실행하는 코드입니다. 목표: 자신이 차지하고 있던 임계 구역을 ‘해제’하여 다른 대기 중인 프로세스들이 진입할 수 있도록 길을 열어주는 것입니다. 동작: 진입 구역에서 획득했던 ‘잠금’을 풀어주거나, “이제 임계 구역이 비었다\"는 상태를 다른 프로세스에게 알려주는 코드가 포함됩니다. 이 구역의 코드가 제대로 실행되지 않으면, 임계 구역이 영원히 잠겨 다른 프로세스들이 무한정 대기하는 **교착 상태(Deadlock)**가 발생할 수 있습니다. remainder section (나머지 구역):\n공유 자원과 관련 없는, 프로세스 고유의 작업을 수행하는 나머지 코드 부분입니다. 이 구역은 상호 배제가 필요 없으므로, 여러 프로세스가 동시에 이 구역의 코드를 실행해도 시스템에 아무런 문제가 발생하지 않습니다. 이 구조는 임계 구역 문제를 해결하기 위한 모든 알고리즘(예: Peterson의 알고리즘, 세마포어, 뮤텍스 등)이 따라야 하는 기본적인 프레임워크입니다. 개발자는 각 구역, 특히 entry section과 exit section에 어떤 코드를 넣어야 다음 슬라이드에서 설명할 3가지 요구사항을 모두 만족시킬 수 있을지를 고민해야 합니다.","매우-자세한-설명-detailed-explanation-3#\u003cstrong\u003e매우 자세한 설명 (Detailed Explanation)\u003c/strong\u003e":"이 슬라이드는 임계 구역 문제에 대한 ‘올바른 해법’이 반드시 만족시켜야 할 세 가지 핵심적인 조건과 두 가지 기본 가정을 제시합니다. 이 조건들은 알고리즘의 정확성과 공정성을 보장하는 척도입니다.\n1. 세 가지 핵심 요구사항\n상호 배제 (Mutual Exclusion):\n의미: 이것은 임계 구역 문제의 가장 근본적이고 필수적인 요구사항입니다. 어떤 시점에서든, 오직 하나의 프로세스만이 자신의 임계 구역 코드를 실행할 수 있어야 합니다. 목적: 공유 자원의 데이터 일관성을 보호하고 경쟁 상태(Race Condition)를 원천적으로 방지하는 것입니다. 위반 시: 상호 배제가 깨지면, 앞선 예시에서 counter 값이 뒤죽박죽된 것처럼 데이터가 손상되고 프로그램 전체가 오작동하게 됩니다. 화장실 예시로 비유하면, 여러 사람이 동시에 한 칸에 들어가려는 것과 같습니다. 진행 (Progress):\n의미: 이 조건은 두 부분으로 나뉩니다. 임계 구역이 비어있고, 들어가고 싶은 프로세스가 있다면, 반드시 그 중 하나는 들어갈 수 있도록 선택되어야 합니다. 이 선택 과정은 유한한 시간 안에 이루어져야 합니다. 목적: 시스템 전체가 멈추는 **교착 상태(Deadlock)**를 방지하는 것입니다. 위반 시: 임계 구역은 비어있는데, 들어가고 싶은 프로세스들이 서로 눈치만 보거나 잘못된 로직 때문에 아무도 들어가지 못하고 무한정 대기하는 상황이 발생할 수 있습니다. 예를 들어, 두 프로세스가 서로에게 “너 먼저 들어가\"라고 양보하다가 결국 아무도 못 들어가는 상황이 ‘진행’ 조건 위반입니다. 또한, 임계 구역과 전혀 상관없는 프로세스가 다음에 들어갈 프로세스를 결정하는 권한을 가져서도 안 됩니다. 오직 들어가고 싶어하는 프로세스들 중에서만 선택이 이루어져야 합니다. 한정된 대기 (Bounded Waiting):\n의미: 어떤 프로세스가 임계 구역에 진입하기 위해 요청(예: entry section 실행 시작)을 한 시점부터, 그 요청이 허가되어 실제로 임계 구역에 들어갈 때까지의 대기 시간이 무한하면 안 된다는 뜻입니다. 더 구체적으로는, 다른 프로세스가 새치기하여 임계 구역에 들어가는 횟수에 상한선(bound)이 있어야 합니다. 목적: 특정 프로세스가 무한히 기다리는 **기아 상태(Starvation)**를 방지하는 것입니다. 위반 시: 상호 배제와 진행 조건은 만족하더라도, 운이 나쁜 특정 프로세스는 다른 프로세스들에게 계속 순서를 빼앗겨 영원히 임계 구역에 들어가지 못할 수 있습니다. 예를 들어, 10개의 프로세스가 있는데 스케줄링 우선순위나 알고리즘의 허점 때문에 항상 1번과 2번 프로세스만 번갈아 가며 임계 구역에 들어가고 3번 프로세스는 영원히 기다리는 상황이 발생하면, 이는 ‘한정된 대기’ 조건을 위반한 것입니다. 2. 두 가지 기본 가정\nAssume that each process executes at a nonzero speed (각 프로세스는 0이 아닌 속도로 실행된다): 프로세스가 멈추지 않고 언젠가는 자신의 코드를 계속 실행해 나간다는 가정입니다. 이는 프로세스가 무한 루프에 빠지거나 특정 지점에서 영원히 멈추지 않음을 보장하여, 알고리즘 분석을 가능하게 합니다. No assumption concerning relative speed of the n processes (n개 프로세스들의 상대적인 실행 속도에 대해서는 아무것도 가정하지 않는다): 어떤 프로세스가 다른 프로세스보다 빠르거나 느리다고 가정할 수 없다는 의미입니다. 현대적인 시분할 시스템에서는 문맥 교환이 언제, 어떤 프로세스에게 일어날지 예측할 수 없기 때문에 이는 매우 현실적인 가정입니다. 따라서 설계된 알고리즘은 프로세스들의 실행 속도와 관계없이 항상 올바르게 동작해야 합니다. 이 요구사항들을 기준으로, 다음 슬라이드들에서 제시되는 여러 시도들이 왜 실패하고, 최종적으로 어떤 해결책이 성공하는지를 평가하게 됩니다.","매우-자세한-설명-detailed-explanation-4#\u003cstrong\u003e매우 자세한 설명 (Detailed Explanation)\u003c/strong\u003e":"이 두 슬라이드는 임계 구역 문제를 해결하려는 가장 직관적이고 간단한 첫 번째 시도를 보여줍니다. 아이디어는 locked라는 공유 변수를 사용하여 문에 ‘자물쇠’를 거는 것과 같습니다.\nlocked == 0: 문이 열려 있음 (임계 구역이 비어 있음) locked == 1: 문이 잠겨 있음 (다른 프로세스가 임계 구역 사용 중) 프로세스는 임계 구역에 들어가기 전(entry section)에 locked가 0인지 확인하고, 0이면 1로 바꾸어 문을 잠근 뒤 진입합니다. 작업을 마치면(exit section) locked를 다시 0으로 만들어 문을 열어줍니다.\n왜 이 해결책은 실패하는가?\n얼핏 보면 완벽해 보이지만, 이 방법은 상호 배제(Mutual Exclusion) 요구사항을 만족시키지 못합니다. 그 이유는 첫 번째 슬라이드에서 counter++ 연산이 여러 단계로 나뉘었던 것과 동일한 문제입니다. entry section의 두 줄짜리 코드, 즉 while (locked == 1);과 locked = 1;은 원자적으로(atomically) 실행되지 않습니다.\n상호 배제가 깨지는 시나리오 (두 프로세스가 동시에 진입하는 경우):\n가정: locked의 초기값은 0입니다. 프로세스 0(P0)과 프로세스 1(P1)이 거의 동시에 임계 구역에 진입하려고 합니다.\nP0 실행: P0가 while (locked == 1); 조건을 검사합니다. 현재 locked는 0이므로 조건은 거짓이 되고, P0는 while 루프를 빠져나옵니다. 이제 P0는 다음 라인인 locked = 1;을 실행하려고 합니다.\n문맥 교환 (Context Switch) 발생: P0가 locked = 1;을 실행하기 바로 그 직전에, 운영체제 스케줄러에 의해 문맥 교환이 발생하여 CPU 제어권이 P1에게 넘어갑니다. 이 시점이 치명적인 순간입니다.\nP1 실행: 이제 P1이 자신의 entry section을 실행합니다.\nP1도 while (locked == 1); 조건을 검사합니다. P0가 아직 locked 값을 1로 바꾸지 못했기 때문에, 메모리의 locked 값은 여전히 0입니다. 따라서 P1도 조건을 거짓으로 판단하고 while 루프를 빠져나옵니다. P1은 다음 라인인 locked = 1;을 실행하여 locked 값을 1로 바꿉니다. P1은 성공적으로 임계 구역에 진입합니다. 문맥 교환 (Context Switch) 발생: CPU 제어권이 다시 P0에게 돌아옵니다.\nP0 실행 재개: P0는 이전에 중단되었던 지점, 즉 locked = 1;을 실행할 차례부터 이어갑니다.\nP0는 locked 값을 1로 설정합니다. (이미 1이었지만, 다시 1로 씁니다.) P0 역시 임계 구역에 진입합니다. 결과: P0과 P1이 동시에 임계 구역 안에 존재하게 됩니다. 이는 상호 배제 원칙을 명백히 위반한 것이며, 이로 인해 공유 자원의 데이터는 손상될 수 있습니다.\n이 실패는 값을 확인하는(test) 동작과 값을 설정하는(set) 동작 사이에 **인터럽트 가능한 틈(interruptible gap)**이 존재하기 때문에 발생합니다. 이 문제를 해결하려면 확인과 설정을 하나의 분리될 수 없는, 원자적인 연산으로 만들어야 합니다. 이것이 바로 뒤에 나올 하드웨어 지원(e.g., TestAndSet)의 필요성으로 이어집니다.","매우-자세한-설명-detailed-explanation-5#\u003cstrong\u003e매우 자세한 설명 (Detailed Explanation)\u003c/strong\u003e":"이 두 번째 시도는 turn이라는 공유 변수를 사용하여 두 프로세스가 엄격하게 번갈아가며 임계 구역에 진입하도록 강제하는 방법입니다. 놀이터의 시소를 생각하면 쉽습니다. 한 명이 내려와야 다른 한 명이 올라갈 수 있습니다.\nturn == 0: 프로세스 0(P0)의 차례 turn == 1: 프로세스 1(P1)의 차례 프로세스는 자신의 차례(turn == me)가 될 때까지 기다리고, 임계 구역 사용이 끝나면 상대방에게 차례를 넘겨줍니다 (turn = !me).\n이 해결책의 평가\n상호 배제 (Mutual Exclusion) - 만족 ✔️:\nturn 변수는 항상 0 또는 1 중 하나의 값만 가질 수 있습니다. 따라서 while (turn != me) 조건은 두 프로세스에 대해 동시에 거짓이 될 수 없습니다. 만약 turn이 0이면 P0만 통과하고 P1은 대기하며, turn이 1이면 P1만 통과하고 P0은 대기합니다. 따라서 두 프로세스가 동시에 임계 구역에 진입하는 것은 불가능합니다. 상호 배제는 완벽하게 지켜집니다.\n진행 (Progress) - 실패 ❌:\n이것이 이 알고리즘의 치명적인 약점입니다. 진행(Progress) 조건을 위반합니다. 진행 조건은 “임계 구역이 비어 있고 들어가고 싶은 프로세스가 있다면, 반드시 들어갈 수 있어야 한다\"는 것입니다. 하지만 이 알고리즘은 강제적인 순서 교대 때문에 이 조건을 어깁니다.\n진행 조건이 깨지는 시나리오:\n초기 상태: turn = 0. P0가 자신의 차례이므로 임계 구역에 진입합니다. P0는 임계 구역 작업을 마치고 turn = 1로 설정하여 P1에게 차례를 넘깁니다. 이제 P1의 차례(turn == 1)입니다. 하지만 P1은 현재 임계 구역에 들어갈 필요가 없고, 자신의 remainder section에서 오래 걸리는 작업을 수행 중이라고 가정해봅시다. 한편, P0는 자신의 remainder section 작업을 금방 끝내고 다시 임계 구역에 들어가고 싶어합니다. P0는 entry section의 while (turn == 1);을 만납니다. turn은 1이므로 P0는 무한정 대기해야 합니다. 결과: 임계 구역은 명백히 비어있고(아무도 사용 중이지 않음), P0는 임계 구역에 들어가고 싶어하지만, 들어갈 수 없습니다. 단지 P1이 자신의 차례를 사용하지 않았다는 이유만으로 P0의 진입이 막히는 것입니다. 이는 “다음에 들어갈 프로세스를 결정하는 것을 무한정 연기할 수 없다\"는 진행 조건을 정면으로 위반합니다. 이처럼 한 프로세스의 상태가 다른 프로세스의 진행에 과도하게 영향을 미치는 것을 **강결합(tight coupling)**이라고도 합니다.\n이 해결책은 상호 배제는 해결했지만, 프로세스들이 서로의 발목을 잡게 만들어 시스템의 전체적인 효율성과 처리량을 떨어뜨리는 문제를 낳습니다.","매우-자세한-설명-detailed-explanation-6#\u003cstrong\u003e매우 자세한 설명 (Detailed Explanation)\u003c/strong\u003e":"이 세 번째 시도는 두 번째 시도의 문제점(한 프로세스가 다른 프로세스를 불필요하게 기다리는 것)을 해결하기 위해 고안되었습니다. turn 변수처럼 차례를 강제하는 대신, 각 프로세스가 자신의 ‘의도’를 flag 배열을 통해 알리는 방식을 사용합니다.\nflag[i] = true;: 프로세스 i가 임계 구역에 들어가고 싶거나, 현재 임계 구역 안에 있음을 의미합니다. flag[i] = false;: 프로세스 i는 임계 구역에 관심이 없음을 의미합니다. 로직은 간단합니다. 임계 구역에 들어가고 싶으면, 먼저 자신의 flag를 true로 설정하여 의도를 밝힙니다. 그리고 상대방의 flag를 확인해서, 만약 상대방도 true라면 대기합니다. 상대방이 관심이 없으면(false), 임계 구역에 진입합니다.\n이 해결책의 평가\n상호 배제 (Mutual Exclusion) - 만족 ✔️ (단, 특정 조건 하에서만):\n이 알고리즘은 상호 배제를 만족하는 것처럼 보입니다. 만약 P0가 while(flag[1])을 통과했다면, 이는 flag[1]이 false라는 뜻입니다. P0가 임계 구역에 있는 동안 flag[0]은 true이므로, P1은 while(flag[0])에 걸려 대기하게 됩니다. 그래서 상호 배제는 지켜집니다. 하지만 아래에서 설명할 교착 상태 문제가 더 치명적입니다.\n진행 (Progress) - 실패 ❌:\n이 알고리즘은 **교착 상태(Deadlock)**에 빠질 가능성이 있습니다. 교착 상태란, 두 개 이상의 프로세스가 서로가 가진 자원을 기다리며 영원히 블로킹되는 상황을 말합니다. 이는 “진행” 요구사항을 위반하는 대표적인 사례입니다.\n교착 상태가 발생하는 시나리오:\n프로세스들의 실행 속도에 아무 가정도 할 수 없다는 점을 기억해야 합니다.\n초기 상태: flag[0] = false, flag[1] = false. P0 실행: P0가 flag[0] = true;를 실행합니다. 자신의 진입 의사를 밝혔습니다. 문맥 교환 (Context Switch) 발생: P0가 while (flag[1] == true);를 실행하기 바로 그 직전에, 문맥 교환이 발생하여 CPU가 P1에게 넘어갑니다. P1 실행: P1도 임계 구역에 들어가고 싶어서 flag[1] = true;를 실행합니다. 자신의 진입 의사를 밝혔습니다. 이제 P1은 while (flag[0] == true);를 검사합니다. P0가 이미 flag[0]을 true로 설정했으므로, 이 조건은 참이 됩니다. 따라서 P1은 이 while 루프에서 무한정 대기합니다. 문맥 교환 (Context Switch) 발생: CPU가 다시 P0에게 돌아옵니다. P0 실행 재개: P0는 중단되었던 지점, 즉 while (flag[1] == true);를 실행합니다. P1이 flag[1]을 true로 설정했으므로, 이 조건은 참이 됩니다. 따라서 P0 역시 이 while 루프에서 무한정 대기합니다. 결과: P0는 P1이 flag[1]을 false로 바꿔주기를 기다리고, P1은 P0가 flag[0]을 false로 바꿔주기를 기다립니다. 하지만 두 프로세스 모두 while 루프에 갇혀 임계 구역에 들어갈 수 없으므로, flag 값을 false로 바꿀 기회는 영원히 오지 않습니다. 이것이 바로 교착 상태입니다. 임계 구역은 비어있지만, 들어가고 싶은 두 프로세스 모두 영원히 기다리게 되므로 ‘진행’ 조건이 깨집니다.\n이전 두 시도는 각각 상호 배제와 진행에서 실패했습니다. 이제 이 두 아이디어(차례와 의도)를 결합하여 문제를 해결하려는 시도가 나오게 됩니다.","매우-자세한-설명-detailed-explanation-7#\u003cstrong\u003e매우 자세한 설명 (Detailed Explanation)\u003c/strong\u003e":"피터슨의 해결책은 앞선 두 시도, 즉 flag 변수(의도)와 turn 변수(순서)를 매우 정교하게 결합하여 2개의 프로세스에 대한 임계 구역 문제를 완벽하게 해결하는 소프트웨어적인 방법입니다.\n핵심 아이디어:\n일단 들어가고 싶다는 의사(flag)를 먼저 밝힌다. (flag[me] = true;) 그리고 상대방에게 차례(turn)를 양보한다. (turn = !me;) 이것은 매우 관대한 행동처럼 보이지만, 이 알고리즘의 핵심입니다. 대기 조건: 상대방이 임계 구역에 들어갈 의사도 있고(flag[!me] == true), 실제로 차례도 상대방의 것(turn == !me) 이라면, 그때만 기다린다. 즉, 내가 들어가고 싶지만, 만약 상대방도 원한다면 기꺼이 양보하겠다는 태도입니다.\n왜 이 해결책은 성공하는가?\n상호 배제 (Mutual Exclusion) - 만족 ✔️: 두 프로세스 P0와 P1이 동시에 임계 구역에 들어가려면, 두 프로세스 모두 자신의 while 루프 조건을 거짓으로 판단하고 통과해야 합니다.\nP0가 통과하려면, (flag[1] \u0026\u0026 turn == 1)이 거짓이어야 합니다. 즉, flag[1]이 false이거나 turn이 0이어야 합니다. P1이 통과하려면, (flag[0] \u0026\u0026 turn == 0)이 거짓이어야 합니다. 즉, flag[0]이 false이거나 turn이 1이어야 합니다. 만약 두 프로세스가 거의 동시에 진입을 시도한다면, 각자 flag를 true로 설정하고 turn 값을 설정할 것입니다. turn 변수는 공유 변수이므로 P0가 turn = 1로 설정한 직후 P1이 turn = 0으로 덮어쓰거나, 그 반대의 경우가 발생합니다. turn 값은 결국 0 또는 1 둘 중 하나만 될 수 있습니다. 만약 마지막 turn 값이 0이라면: P1은 while 조건(flag[0] \u0026\u0026 turn == 0)이 참이 되어 대기하게 됩니다. P0만 진입 가능합니다. 만약 마지막 turn 값이 1이라면: P0은 while 조건(flag[1] \u0026\u0026 turn == 1)이 참이 되어 대기하게 됩니다. P1만 진입 가능합니다. 따라서 두 프로세스가 동시에 임계 구역에 들어가는 것은 불가능합니다. 진행 (Progress) - 만족 ✔️: 교착 상태가 발생하는지 확인해 봅시다. 두 프로세스가 동시에 while 루프에서 대기하려면, P0는 flag[1] \u0026\u0026 turn == 1이 참이길 기다리고, P1은 flag[0] \u0026\u0026 turn == 0이 참이길 기다려야 합니다. 하지만 turn은 동시에 0과 1일 수 없으므로, 두 프로세스가 동시에 while 루프에 갇히는 것은 불가능합니다. 최소한 한쪽은 turn 조건이 거짓이 되어 while 루프를 빠져나갈 수 있습니다.\n또한, 만약 한 프로세스(P1)만이 임계 구역에 들어가고 싶다면(flag[1] = true), P0는 flag[0]이 false이므로 P1은 while(flag[0] \u0026\u0026 turn == 0) 조건에서 flag[0]이 거짓이라 바로 통과할 수 있습니다. 즉, 불필요한 대기가 없습니다.\n한정된 대기 (Bounded Waiting) - 만족 ✔️: 기아 상태가 발생하는지 확인해 봅시다. P0가 임계 구역에 진입하기 위해 flag[0] = true를 설정하고 while 루프에서 대기 중이라고 가정합시다. 이는 flag[1]이 true이고 turn이 1이라는 뜻입니다. P1이 임계 구역을 사용하고 있습니다.\nP1이 임계 구역을 빠져나오면서 flag[1] = false로 설정합니다. 그러면 P0는 while 루프를 빠져나와 임계 구역에 진입할 수 있습니다.\n이제 P1이 다시 임계 구역에 들어가고 싶다고 해봅시다. P1은 flag[1] = true로 설정하고 turn = 0으로 설정합니다. P0가 아직 임계 구역에 있는 동안(flag[0] = true), P1은 while (flag[0] \u0026\u0026 turn == 0) 조건 때문에 대기해야 합니다. turn이 0으로 설정되었기 때문에, P0가 이번 임계 구역 사용을 마치고 나오면, 다음 차례는 반드시 turn 값이 1로 바뀌지 않는 한 P0에게 오지 않습니다. 즉, P1은 P0를 최대 한 번만 “새치기\"할 수 있습니다. 한번 P0에게 순서가 오면, P1은 P0가 끝날 때까지 기다려야 합니다. 따라서 어떤 프로세스도 무한정 대기하지 않습니다.\n피터슨의 해결책은 이 세 가지 요구사항을 모두 만족하는 매우 우아한 알고리즘이지만, 2개의 프로세스에만 적용 가능하다는 한계와, 현대적인 컴퓨터 아키텍처에서는 컴파일러 최적화나 CPU의 명령어 재배치(out-of-order execution) 때문에 코드의 순서대로 동작한다고 보장하기 어려운 문제가 있습니다. 이 때문에 실제 시스템에서는 다음에 나올 하드웨어 기반의 해결책을 주로 사용합니다.","매우-자세한-설명-detailed-explanation-8#\u003cstrong\u003e매우 자세한 설명 (Detailed Explanation)\u003c/strong\u003e":"이 슬라이드는 지금까지의 논의를 요약하고, 소프트웨어적 해결책의 근본적인 한계를 지적하며 하드웨어 지원의 필요성을 역설합니다.\n1. 잠금 매커니즘의 필요성 (Need a locking mechanism)\n지금까지 살펴본 모든 시도들은 결국 임계 구역이라는 ‘방’에 들어가기 전에 **‘잠금을 획득(acquire lock)’**하고, 나온 후에 **‘잠금을 해제(release lock)’**하는 과정으로 요약될 수 있습니다.\nAcquire Lock: entry section에 해당하며, 임계 구역에 들어갈 권리를 얻는 과정입니다. Release Lock: exit section에 해당하며, 권리를 반납하여 다른 프로세스가 들어올 수 있게 하는 과정입니다. 이 acquire/release 구조는 뮤텍스(Mutex), 세마포어(Semaphore) 등 현대 운영체제에서 사용하는 대부분의 동기화 도구의 기본 모델입니다. 문제는 이 acquire와 release 동작 자체를 어떻게 신뢰성 있게 만드느냐 입니다.\n2. 피터슨 알고리즘의 한계와 원자적 접근의 필요성\n피터슨의 알고리즘은 수학적으로는 완벽해 보이지만, 현실 세계의 컴퓨터에서는 두 가지 큰 문제에 직면합니다.\n원자성 가정의 문제: 피터슨 알고리즘이 올바르게 동작하려면, flag[me] = true나 turn = !me 같은 개별 명령어가 원자적으로(쪼개지지 않고) 실행된다는 가정이 필요합니다. 즉, turn = 1이라는 명령어가 실행되는 도중에 다른 프로세스가 turn 값을 읽지 않아야 합니다. 대부분의 아키텍처에서 단순 변수 할당은 원자적이지만, 항상 보장되는 것은 아닙니다. 메모리 모델과 명령어 재배치 문제: 현대의 고성능 CPU와 컴파일러는 성능 향상을 위해 코드의 실행 순서를 임의로 바꿀 수 있습니다(명령어 재배치, Instruction Reordering). 예를 들어, 프로그래머는 아래와 같이 코드를 작성했지만, flag[me] = true; turn = !me; 컴파일러나 CPU가 성능을 위해 순서를 바꿔서 turn = !me;를 먼저 실행하고 flag[me] = true;를 나중에 실행할 수도 있습니다. 만약 이런 재배치가 발생하면 피터슨 알고리즘의 모든 논리적 증명은 무너지고, 알고리즘은 오작동하게 됩니다. 결국, 소프트웨어만으로는 이런 하드웨어/컴파일러 수준의 최적화를 통제하며 동기화를 완벽하게 구현하기가 매우 복잡하고 어렵습니다.\n3. 문제의 근원: 읽기-수정-쓰기 (Read-Modify-Write)의 비원자성\n슬라이드의 마지막 부분은 이 모든 문제의 근원을 다시 한번 명확히 짚어줍니다. 공유 변수와 관련된 문제는 “값을 읽고(Read/Get), 그 값을 수정하고(Modify), 다시 쓰는(Write/Set)” 일련의 과정이 한 덩어리로 묶여있지 않고, 그 사이에 **인터럽트 가능한 틈(interruptible gap)**이 존재하기 때문입니다.\nregister ← (읽기) register = (수정) ← register (쓰기) 첫 번째 시도였던 locked 변수 예제에서 while(locked == 1); (읽기)와 locked = 1; (쓰기) 사이의 틈이 문제를 일으켰습니다.\n4. 해결 방향 제시: “HOW?”\n이러한 “읽기-수정-쓰기” 사이클을 아무도 방해할 수 없는, 하나의 원자적인(Atomic) 연산으로 만들 수만 있다면 문제는 간단히 해결됩니다. 하지만 소프트웨어만으로는 이를 구현하기 어렵습니다. 그래서 슬라이드는 “어떻게(HOW)?” 라는 질문을 던지며, 하드웨어 수준의 지원이 필요함을 암시합니다. 다음 슬라이드들에서는 이 “HOW?“에 대한 하드웨어적인 답변들을 제시합니다.","매우-자세한-설명-detailed-explanation-9#\u003cstrong\u003e매우 자세한 설명 (Detailed Explanation)\u003c/strong\u003e":"이 슬라이드는 “읽기-수정-쓰기” 연산을 원자적으로 만들기 위한 첫 번째 하드웨어적 해결책으로 **인터럽트 비활성화(Disabling Interrupts)**를 제시합니다.\n1. 동작 원리\n앞서 문제의 원인은 연산 도중에 문맥 교환(Context Switch)이 발생하기 때문이었습니다. 문맥 교환은 주로 **타이머 인터럽트(Timer Interrupt)**나 **입출력 인터럽트(I/O Interrupt)**와 같은 하드웨어 인터럽트에 의해 촉발됩니다.\n그렇다면, 임계 구역에 진입하기 전에 시스템의 모든 인터럽트를 비활성화하고, 임계 구역을 빠져나온 후에 다시 인터럽트를 활성화하면 어떨까요?\nC\n// 개념적인 코드 do { disable_interrupts(); // 진입 구역 // 임계 구역 critical_section(); // 퇴출 구역 enable_interrupts(); // 나머지 구역 remainder_section(); } while(true); 인터럽트가 비활성화된 동안에는 스케줄러를 호출하는 타이머 인터럽트가 발생하지 않으므로, 현재 CPU를 점유한 프로세스는 누구에게도 방해받지 않고(선점되지 않고) 자신의 코드를 끝까지 실행할 수 있습니다. 즉, 임계 구역 코드가 사실상 원자적으로 실행되는 효과를 얻게 됩니다.\n2. 장점과 한계\n장점 (단일처리기 시스템에서):\n단순하고 확실함: 구현이 매우 간단하면서도 상호 배제를 확실하게 보장합니다. 단점 및 문제점:\n다중처리기 시스템에서의 무용성: 이 방법은 **단일처리기(Uniprocessor, CPU가 하나인 시스템)**에서만 유효합니다. 다중처리기(Multiprocessor, CPU가 여러 개인 시스템) 환경에서는 하나의 CPU에서 인터럽트를 비활성화하더라도, 다른 CPU에서는 여전히 다른 프로세스가 실행될 수 있습니다. 따라서 다른 CPU의 프로세스가 같은 임계 구역에 동시에 접근하는 것을 막을 수 없습니다. 모든 CPU의 인터럽트를 껐다 켜는 것은 통신 오버헤드가 매우 크고 복잡하여 현실적이지 않습니다. 시스템 성능 저하 및 위험성: 인터럽트를 비활성화하는 것은 시스템 전체에 영향을 미치는 매우 강력한 작업입니다. 인터럽트가 꺼져 있는 동안에는 키보드, 마우스, 네트워크 카드 등 다른 모든 하드웨어의 긴급한 요청에 응답할 수 없게 됩니다. 만약 임계 구역 코드가 길어지거나 무한 루프에 빠지면, 시스템 전체가 멈추는 ‘먹통’ 상태가 될 수 있습니다. 사용자 수준 권한 문제: 인터럽트를 제어하는 명령어는 커널 모드(Kernel Mode)에서만 실행 가능한 **특권 명령어(Privileged Instruction)**입니다. 일반 사용자 프로그램이 이 기능을 마음대로 사용하도록 허용하는 것은 심각한 보안 위험을 초래할 수 있습니다. 운영체제 커널 내부에서나 제한적으로 사용할 수 있는 방법입니다. 결론: 인터럽트 비활성화는 개념은 간단하지만, 현대적인 다중처리기 운영체제에서는 확장성이 떨어지고 위험 부담이 커서 임계 구역 문제의 일반적인 해법으로 사용되지 않습니다.","메모리-계층-구조#메모리 계층 구조":"","문제-상황-빈-프레임의-고갈-no-free-frame#\u003cstrong\u003e문제 상황: 빈 프레임의 고갈 (No Free Frame)\u003c/strong\u003e":"가상 메모리 시스템은 다중 프로그래밍의 정도를 높여 여러 프로세스를 동시에 메모리에 상주시키는 것을 목표로 합니다. 시스템이 계속 동작하고, 여러 프로세스가 페이지 폴트를 일으키면서 디스크로부터 새로운 페이지들을 물리 메모리로 가져오다 보면, 결국 물리 메모리의 모든 프레임이 가득 차는 순간이 오게 됩니다.\n바로 이 시점에서, 또 다른 프로세스가 페이지 폴트를 일으켰다고 가정해봅시다. 운영 체제는 이 새로운 페이지를 가져와야 하지만, 더 이상 넣어둘 빈 공간(free frame)이 없습니다. 이것이 바로 슬라이드가 제기하는 “만약 빈 프레임이 없다면 어떻게 되는가?“라는 질문의 핵심 상황입니다. 시스템이 멈추거나 오류를 내서는 안 되므로, 이 상황을 해결할 방법이 필요합니다.","번역#\u003cstrong\u003e번역\u003c/strong\u003e:":"","번역-1#\u003cstrong\u003e번역\u003c/strong\u003e:":"","번역-10#\u003cstrong\u003e번역\u003c/strong\u003e":"","번역-11#\u003cstrong\u003e번역\u003c/strong\u003e":"","번역-12#번역":"","번역-2#\u003cstrong\u003e번역\u003c/strong\u003e:":"","번역-3#\u003cstrong\u003e번역\u003c/strong\u003e:":"","번역-4#\u003cstrong\u003e번역\u003c/strong\u003e:":"","번역-5#\u003cstrong\u003e번역\u003c/strong\u003e:":"","번역-6#\u003cstrong\u003e번역\u003c/strong\u003e":"","번역-7#\u003cstrong\u003e번역\u003c/strong\u003e":"","번역-8#\u003cstrong\u003e번역\u003c/strong\u003e":"","번역-9#\u003cstrong\u003e번역\u003c/strong\u003e":"","번역-translation#\u003cstrong\u003e번역 (Translation)\u003c/strong\u003e":"원형 배열을 이용한 공유 버퍼 PC (생산자/소비자) 버퍼 out in (데이터 인출/삽입 위치) counter (버퍼에 있는 데이터 수) 공유 메모리 읽기/쓰기/쓰기 비어있음 (Empty) if counter == 0 가득 참 (Full) if counter == BS (버퍼 크기) 동시성 문제 발생! counter++ 연산의 내부 동작: register1 = counter register1 = register1 + 1 counter = register1 counter-- 연산의 내부 동작: register2 = counter register2 = register2 - 1 counter = register2","번역-translation-1#\u003cstrong\u003e번역 (Translation)\u003c/strong\u003e":"임계 구역 문제 ! n개의 프로세스 {p0, p1, … pn-1}로 구성된 시스템을 가정하자. ! 각 프로세스는 임계 구역(critical section)을 가지고 있다. ! 만약 한 프로세스가 임계 구역 안에 있다면, 다른 어떤 프로세스도 들어갈 수 없다. ! 각 프로세스는 임계 구역에 진입하기 위해 진입 구역(entry section)에서 허가를 요청해야 하며, 임계 구역 다음에는 퇴출 구역(exit section)이 올 수 있고, 그 이후는 나머지 구역(remainder section)이다. ! 임계 구역 문제란, 바로 이 문제를 해결하기 위한 프로토콜을 설계하는 것이다.","번역-translation-2#\u003cstrong\u003e번역 (Translation)\u003c/strong\u003e":"임계 구역 ! 프로세스 pi의 일반적인 구조는 다음과 같다. do { 진입 구역 (entry section) 임계 구역 (critical section) 퇴출 구역 (exit section) 나머지 구역 (remainder section) } while (true);","번역-translation-3#\u003cstrong\u003e번역 (Translation)\u003c/strong\u003e":"임계 구역 문제의 요구사항 1. 상호 배제 (Mutual Exclusion) - 만약 프로세스 Pi가 자신의 임계 구역에서 실행 중이라면, 다른 어떤 프로세스도 자신의 임계 구역에서 실행될 수 없다. 2. 진행 (Progress) - 만약 임계 구역에서 실행 중인 프로세스가 없고, 자신의 임계 구역으로 진입하려는 프로세스들이 있다면, 다음에 진입할 프로세스를 결정하는 것을 무한정 연기할 수 없다. 3. 한정된 대기 (Bounded Waiting) - 어떤 프로세스가 자신의 임계 구역에 진입 요청을 한 후부터 그 요청이 허가될 때까지, 다른 프로세스들이 그들의 임계 구역에 진입하는 횟수에는 한계가 있어야 한다. — 각 프로세스는 0이 아닌 속도로 실행된다고 가정한다. — n개 프로세스들의 상대적인 실행 속도에 대해서는 아무것도 가정하지 않는다.","번역-translation-4#\u003cstrong\u003e번역 (Translation)\u003c/strong\u003e":"// 슬라이드 5 첫 번째 시도: 잠금(lock) 사용 공유 변수 int locked = 0; // 0: 비었음, 1: 잠김 do { while (locked == 1); // 잠겨있으면 계속 대기 locked = 1; // 잠금 설정 임계 구역 locked = 0; // 잠금 해제 나머지 구역 } while (true); ! 요구사항 충족 실패 ! 해결책: 오직 하나의 프로세스만 [진입하도록 허용] // 슬라이드 6 (프로세스 구분) 프로세스 0: 공유 변수 int locked = 0; do { while (locked == 1); locked = 1; 임계 구역 locked = 0; 나머지 구역 } while (true); 프로세스 1: 공유 변수 int locked = 0; do { while (locked == 1); locked = 1; 임계 구역 locked = 0; 나머지 구역 } while (true);","번역-translation-5#\u003cstrong\u003e번역 (Translation)\u003c/strong\u003e":"// 슬라이드 7 두 번째 시도: 차례 지키기 공유 변수 int turn = 0; do { while (turn != me); // 내 차례가 아니면 대기 임계 구역 turn = ! me; // 상대방에게 차례를 넘김 나머지 구역 } while (true); ! 요구사항 충족 실패 ! 해결책: 다른 프로세스의 [상태를 확인] // 슬라이드 8 (프로세스 구분) 프로세스 0: (`me`는 0) 공유 변수 int turn = 0; do { while (turn == 1); // P1의 차례이면 대기 임계 구역 turn = 1; // P1에게 차례를 넘김 나머지 구역 } while (true); 프로세스 1: (`me`는 1) 공유 변수 int turn = 0; do { while (turn == 0); // P0의 차례이면 대기 임계 구역 turn = 0; // P0에게 차례를 넘김 나머지 구역 } while (true);","번역-translation-6#\u003cstrong\u003e번역 (Translation)\u003c/strong\u003e":"// 슬라이드 9 세 번째 시도: 의도 확인하기 공유 배열 int flag[2]; do { flag[me] = true; // \"나 들어가고 싶어\" 라는 의도를 표시 while (flag[!me] == true); // 상대방이 들어가고 싶어하면 대기 임계 구역 flag[me] = false; // \"나 다 썼어\" 라고 표시 나머지 구역 } while (true); ! 요구사항 충족 실패 ! 해결책: 둘 다 확인하기 // 슬라이드 10 (프로세스 구분) 프로세스 0: 공유 배열 int flag[2]; // flag[0]는 P0용, flag[1]은 P1용 do { flag[0] = true; // \"나 들어가고 싶어\" while (flag[1] == true); // P1이 들어가고 싶어하면 대기 임계 구역 flag[0] = false; // \"나 다 썼어\" 나머지 구역 } while (true); 프로세스 1: 공유 배열 int flag[2]; do { flag[1] = true; // \"나 들어가고 싶어\" while (flag[0] == true); // P0이 들어가고 싶어하면 대기 임계 구역 flag[1] = false; // \"나 다 썼어\" 나머지 구역 } while (true);","번역-translation-7#\u003cstrong\u003e번역 (Translation)\u003c/strong\u003e":"// 슬라이드 11 피터슨의 해결책 (Peterson’s Solution) 공유 변수 int turn, flag[2]; do { flag[me] = true; // 진입 의사 표시 turn = !me; // 상대방에게 차례를 양보 while (flag[!me] \u0026\u0026 turn == !me); // 상대방이 원하고, 차례도 상대방 차례라면 대기 임계 구역 flag[me] = false; // 진입 의사 철회 나머지 구역 } while (true); ! 다음이 증명 가능함 1. 상호 배제: 2. 진행: 3. 한정된 대기: // 슬라이드 12 (프로세스 구분) 프로세스 0: 공유 변수 int turn, flag[2]; do { flag[0] = true; turn = 1; // 차례를 P1에게 넘김 while (flag[1] \u0026\u0026 turn == 1); // P1이 원하고, 차례도 P1이면 대기 임계 구역 flag[0] = false; 나머지 구역 } while (true); 프로세스 1: 공유 변수 int turn, flag[2]; do { flag[1] = true; turn = 0; // 차례를 P0에게 넘김 while (flag[0] \u0026\u0026 turn == 0); // P0이 원하고, 차례도 P0이면 대기 임계 구역 flag[1] = false; 나머지 구역 } while (true);","번역-translation-8#\u003cstrong\u003e번역 (Translation)\u003c/strong\u003e":"교훈 ! 잠금(Locking) 매커니즘이 필요하다 잠금 획득 (acquire lock) 임계 구역 잠금 해제 (release lock) ! 피터슨의 알고리즘조차도 공유 변수에 대한 원자적 접근이 필요하다. ! 공유 변수에 대한 문제는 다음으로부터 발생한다. “ 값을 가져오는(get) 연산과 값을 설정하는(set) 연산 사이의 인터럽트 가능한 틈 레지스터 ← \u003c메모리\u003e 레지스터 = \u003c새로운 값\u003e \u003c메모리\u003e ← 레지스터 “ 이 연산들을 인터럽트 불가능하게 만들어라, 그런데 어떻게?","번역-translation-9#\u003cstrong\u003e번역 (Translation)\u003c/strong\u003e":"// 슬라이드 15 원자적 명령어 (Atomic instruction) 공유 변수 int locked = false; do { while (locked == true); // 문제의 코드 locked = true; // 문제의 코드 임계 구역 locked = false; 나머지 구역 } while (true); TEST(확인)와 SET(설정) 사이의 틈을 제거하라!! while( TestAndSet( \u0026locked ) ); 현재 값을 반환하고, 만약 FALSE였다면 TRUE로 설정한다. // 슬라이드 16 TestAndSet 명령어 boolean TestAndSet (boolean *target) { boolean rv = *target; // 원래 값을 rv에 저장 if( *target == FALSE ) // 원래 값이 FALSE였다면 *target = TRUE; // TRUE로 설정 return rv: // 원래 값 반환 } 더 나은 TestAndSet 명령어 boolean TestAndSet (boolean *target) { boolean rv = *target; // 원래 값을 rv에 저장 *target = TRUE; // 무조건 TRUE로 설정 return rv: // 원래 값 반환 } // 슬라이드 17 TestAndSet을 이용한 해결책 ! 공유 boolean 변수 lock은 FALSE로 초기화된다. do { while ( TestAndSet (\u0026lock )); // lock이 false가 될 때까지 계속 테스트 (실행) // 임계 구역 lock = FALSE; // 나머지 구역 } while (TRUE);","분석-및-특징#\u003cstrong\u003e분석 및 특징\u003c/strong\u003e":"미래 참조 기반 결정: 각 교체 시점에서, 최적 알고리즘은 현재 프레임에 있는 페이지들이 _앞으로 언제 다시 사용될지_를 살펴봅니다. 이 “미래 예측\"이 핵심입니다. 페이지 폴트 최소화: 위 예시에서 9번의 페이지 폴트가 발생했습니다. 어떤 다른 알고리즘을 사용하더라도 이 참조 문자열과 3개의 프레임 조건에서는 9번보다 적은 페이지 폴트를 만들 수 없습니다. 이것이 최적 알고리즘의 강력함입니다. 불가능한 예측: 현실에서는 다음 참조될 페이지가 무엇일지 미리 알 수 없습니다. 프로그램의 실행 경로는 사용자 입력, 조건 분기 등 다양한 요인에 의해 결정되기 때문입니다. 따라서 최적 알고리즘은 실제 운영 체제에서 구현하여 사용할 수 없습니다. 비교 기준으로의 가치: 그럼에도 불구하고 최적 알고리즘은 매우 중요합니다. 성능의 상한선: 특정 조건에서 달성 가능한 이론적인 최상의 성능(최소 폴트 수)을 보여줍니다. 다른 알고리즘 평가: FIFO, LRU 등 실제 구현 가능한 알고리즘들이 얼마나 최적 알고리즘의 성능에 근접하는지를 비교함으로써 그 효율성을 평가할 수 있습니다. 예를 들어, 동일 조건에서 LRU가 12번, FIFO가 15번의 폴트를 발생시킨다면, LRU가 FIFO보다 더 우수한 알고리즘이라고 판단할 수 있습니다. 구현 시 고려사항 (이론적): 만약 미래를 알 수 있다면, 각 페이지마다 다음 참조까지의 거리를 계산하고, 이 거리가 가장 긴 페이지를 교체 대상으로 선택하면 됩니다. 만약 어떤 페이지가 미래에 더 이상 참조되지 않는다면, 그 페이지는 가장 우선적인 교체 대상이 됩니다.","분석-및-특징-1#\u003cstrong\u003e분석 및 특징\u003c/strong\u003e":"단순한 교체 로직: FIFO 알고리즘은 각 교체 시점에서 단순히 큐의 맨 앞에 있는, 즉 가장 오래된 페이지만을 교체합니다. 페이지의 사용 빈도나 최근 사용 여부는 전혀 고려되지 않습니다.\n예를 들어, 4번째 참조인 ‘2’가 들어올 때, 프레임에는 [7, 0, 1]이 있었고 FIFO 큐는 [7, 0, 1] (7이 가장 오래됨)이었습니다. 따라서 7이 교체됩니다. 6번째 참조인 ‘3’이 들어올 때, 프레임에는 [0, 1, 2]가 있었고 FIFO 큐는 [0, 1, 2] (0이 가장 오래됨)였습니다. 따라서 0이 교체됩니다. 이 0은 바로 직전(5번째 참조)에 사용되었음에도 불구하고 가장 오래되었다는 이유로 교체됩니다. 성능 비교 (vs. 최적 알고리즘):\n동일한 참조 문자열과 3개의 프레임 조건에서, 최적 알고리즘은 9회의 페이지 폴트를 발생시켰습니다. FIFO 알고리즘은 15회의 페이지 폴트를 발생시켰습니다. 이 예시에서 FIFO는 최적 알고리즘보다 6번 더 많은 페이지 폴트를 유발했습니다. 이는 FIFO가 페이지 사용 패턴을 고려하지 않기 때문에 발생하는 비효율성을 보여줍니다. 예를 들어, FIFO는 자주 사용되는 페이지(위 예시에서 ‘0’ 페이지)라도 단지 오래되었다는 이유로 교체하여, 이후 해당 페이지가 다시 참조될 때 불필요한 폴트를 발생시키는 경향이 있습니다. 벨레이디의 모순 (Belady’s Anomaly) 가능성:\nFIFO 알고리즘은 프레임 수를 늘려도 페이지 폴트가 오히려 증가하는 ‘벨레이디의 모순’ 현상이 나타날 수 있는 대표적인 알고리즘입니다. 이 특정 참조 문자열과 프레임 수에 대해서는 직접 계산해봐야 알 수 있지만, 이러한 현상의 존재 가능성 자체가 FIFO의 예측 불가능성과 비효율성을 나타냅니다.\n벨레이디의 모순 예시 (다른 참조 문자열): 예를 들어 참조 문자열 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5에 대해, 3개의 프레임으로 FIFO를 실행하면 9번의 페이지 폴트가 발생합니다. 4개의 프레임으로 FIFO를 실행하면 10번의 페이지 폴트가 발생합니다. 이처럼 프레임이 늘어났음에도 페이지 폴트가 증가하는 것은, 늘어난 프레임으로 인해 페이지들이 메모리에 머무는 순서와 기간이 변하고, 이것이 FIFO의 “가장 오래된 페이지 교체” 전략과 맞물려 오히려 더 안 좋은 교체 선택을 유도하기 때문입니다. 구현의 용이성: 앞서 설명했듯이, FIFO 큐를 사용하는 구현은 매우 간단하고 시스템 오버헤드가 적습니다. 각 페이지의 참조 시간을 기록하거나 복잡한 계산을 할 필요가 없습니다.","비선점-조건-공략-attacking-the-no-preemption-condition#비선점 조건 공략 (Attacking the No Preemption Condition)":"원문 (Original Text):\nAttacking the No Preemption Condition  In general this is not a viable option  Consider a process given the printer  halfway through its job  now forcibly take away printer  !!?? 번역 (Translation):\n비선점 조건 공략  일반적으로 이것은 실행 가능한 옵션이 아님  프린터를 할당받은 프로세스를 생각해보자  작업이 절반쯤 진행된 상태  이제 강제로 프린터를 빼앗는다면  !!?? (어떻게 될 것인가? 문제 발생!) 매우 자세한 설명 (Detailed Explanation):\n이 슬라이드는 교착 상태 예방 전략 중 비선점(No Preemption) 조건을 무효화하려는 시도에 대해 설명합니다. 💣 비선점 조건은 “이미 할당된 자원은 그 자원을 점유하고 있는 프로세스로부터 강제로 빼앗을 수 없으며, 오직 자원을 점유한 프로세스가 작업을 완료한 후 자발적으로 방출할 때만 해제될 수 있다\"는 것입니다. 이 조건을 깨뜨리면, 즉 필요할 때 다른 프로세스로부터 자원을 강제로 가져올 수 있다면(선점할 수 있다면), 교착 상태를 해결할 수 있는 가능성이 열립니다.\n비선점 조건 공략의 어려움:\n“In general this is not a viable option” (일반적으로 이것은 실행 가능한 옵션이 아님): 결론부터 말하자면, 비선점 조건을 깨는 것은 많은 자원에 대해 매우 어렵거나 실용적이지 않습니다. 그 이유는 자원의 특성과 작업의 일관성 유지 문제 때문입니다. 프린터 예시를 통한 문제점 설명:\n“Consider a process given the printer” (프린터를 할당받은 프로세스를 생각해보자): 한 프로세스(P1)가 프린터 자원을 할당받아 문서 인쇄 작업을 시작했다고 가정합니다. “halfway through its job” (작업이 절반쯤 진행된 상태): P1이 문서의 절반 정도를 인쇄했습니다. 이때, 다른 우선순위가 높은 프로세스(P2)가 프린터를 급하게 필요로 하는 상황이 발생했다고 가정합시다. “now forcibly take away printer” (이제 강제로 프린터를 빼앗는다면): 비선점 조건을 무효화하기 위해, 운영체제가 P1으로부터 프린터를 강제로 빼앗아 P2에게 할당하려고 합니다. ”!!??” (어떻게 될 것인가? 문제 발생!): 이 상황은 여러 가지 심각한 문제를 야기합니다. 작업 손실 및 불일치: P1이 인쇄하던 문서는 중간에 끊기게 됩니다. P2가 자신의 인쇄를 마치고 프린터를 반납한 후 P1이 다시 인쇄를 시작한다면, 어디서부터 다시 시작해야 할까요? 이미 인쇄된 부분과 앞으로 인쇄할 부분을 정확히 이어 붙이기가 매우 어렵습니다. 결과적으로 종이 낭비, 시간 낭비, 그리고 불완전한 출력물이 나올 가능성이 큽니다. 상태 복원의 어려움: 프린터와 같이 상태를 가지는 장치의 경우, 선점 후 원래 상태로 정확히 복원하는 것이 거의 불가능할 수 있습니다. 예를 들어, 특정 폰트가 로드되어 있거나, 특정 용지함이 선택된 상태에서 선점되었다면, 나중에 작업을 재개할 때 이 모든 상태를 기억하고 복원해야 합니다. 일관성 문제: 만약 자원이 데이터베이스 레코드나 파일의 특정 부분이라면, 트랜잭션 중간에 선점될 경우 데이터의 일관성이 깨질 수 있습니다. (예: 한 계좌에서 돈을 인출하고 다른 계좌로 입금하는 도중에 선점되면, 돈은 인출되었지만 입금은 안 되는 심각한 오류 발생) 선점이 비교적 용이한 자원 vs. 어려운 자원:\n선점 용이:\nCPU: CPU는 대표적인 선점 가능 자원입니다. 프로세스의 현재 레지스터 값, 프로그램 카운터(PC) 등을 프로세스 제어 블록(PCB)에 저장해두면, 나중에 이 상태를 복원하여 CPU를 다시 할당하고 작업을 이어갈 수 있습니다. (문맥 교환, Context Switching) 메모리: 메모리도 특정 조건 하에 선점될 수 있습니다 (예: 스와핑을 통해 프로세스의 메모리 내용을 디스크로 옮기고 다른 프로세스에게 메모리 할당). 하지만 이 역시 비용이 듭니다. 선점 어려움:\n프린터, 테이프 드라이브 등 I/O 장치: 이들은 대부분 작업이 완료될 때까지 연속적으로 사용되어야 하며, 중간에 끊기면 작업 내용을 보존하기 어렵습니다. 파일: 파일에 대한 쓰기 작업 중에는 일반적으로 선점하지 않습니다. 락(Lock) 또는 세마포어(Semaphore): 임계 구역(Critical Section) 보호를 위해 사용되는 동기화 도구들은 그 정의상 비선점적입니다. 락을 획득한 프로세스가 락을 해제하기 전까지 다른 프로세스는 기다려야 합니다. 비선점 조건을 공략하는 두 가지 접근법 (이론적):\n요청 자원 비가용 시, 보유 자원 모두 해제: 어떤 프로세스가 이미 자원을 보유한 상태에서 추가 자원을 요청했는데 즉시 할당받을 수 없다면, 현재 보유한 모든 자원을 강제로 해제(선점)시키고, 요청한 자원과 이전에 보유했던 자원 모두를 다시 얻을 수 있을 때 작업을 재개하는 방식입니다.\n문제점: 점유와 대기 조건의 변형 방법과 유사한 문제를 가집니다. 빈번한 자원 해제와 재요청은 비효율적이며, 기아 상태를 유발할 수 있습니다. 우선순위에 따른 선점: 대기 중인 프로세스가 현재 자원을 점유한 프로세스보다 우선순위가 높다면, 점유 중인 프로세스로부터 자원을 선점하여 대기 중인 프로세스에게 할당하는 방식입니다. 점유를 빼앗긴 프로세스는 필요한 자원을 다시 기다려야 합니다.\n문제점: 어떤 자원을 선점할지, 선점된 프로세스는 어떻게 처리할지(롤백, 재시작 등) 결정하는 것이 복잡합니다. 또한, 낮은 우선순위의 프로세스가 계속해서 자원을 빼앗겨 기아 상태에 빠질 수 있습니다. 결론:\n비선점 조건을 무효화하는 것은 교착 상태를 예방하는 한 가지 방법이 될 수 있지만, 대부분의 자원에 대해 적용하기에는 부작용이 너무 크고 구현이 복잡합니다. 작업의 손실, 데이터 불일치, 시스템 오버헤드 증가 등의 문제가 발생할 수 있기 때문입니다. 따라서 이 방법은 CPU나 메모리와 같이 상태 저장이 용이한 일부 자원에 제한적으로 적용될 수 있을 뿐, 일반적인 교착 상태 예방책으로서는 부적합한 경우가 많습니다. 현실적으로 많은 시스템은 자원의 비선점 특성을 유지하면서 다른 예방 기법이나 회피, 탐지 및 회복 전략을 사용합니다.","사이클이-있지만-교착-상태가-아닌-그래프-graph-with-a-cycle-but-no-deadlock#사이클이 있지만 교착 상태가 아닌 그래프 (Graph With A Cycle But No Deadlock)":"원문 (Original Text):\nGraph With A Cycle But No Deadlock (이 슬라이드는 제목만 있고 실제 그래프 이미지가 없으므로, 해당 조건을 만족하는 예시를 구성하여 설명합니다.)\n번역 (Translation):\n사이클(주기)은 있지만 교착 상태는 아닌 그래프 매우 자세한 설명 (Detailed Explanation):\n이 슬라이드는 자원 할당 그래프(RAG)에서 사이클(cycle)이 존재하더라도 항상 교착 상태(deadlock)를 의미하는 것은 아니라는 중요한 점을 강조합니다. 🔄❓ 이는 특히 하나 이상의 자원 유형이 **여러 개의 인스턴스(multiple instances)**를 가지고 있을 때 발생할 수 있는 상황입니다.\n사이클이 있지만 교착 상태가 아닌 예시 시나리오:\n다음과 같은 시스템 상태를 가정합니다.\n프로세스: P1​,P2​,P3​,P4​ 자원 유형: R1: 인스턴스 1개 R2: 인스턴스 2개 현재 상태:\n프로세스 P1​은 자원 R1​의 인스턴스를 **요청(requesting)**하고 있으며, 이 R1​ 인스턴스는 현재 프로세스 P2​에 의해 **보유(held)**되어 있습니다. (P1​→R1​←P2​) 프로세스 P2​는 자원 R1​의 인스턴스를 보유하고 있으며, 자원 R2​의 인스턴스 하나를 요청하고 있습니다. (P2​→R2​) 프로세스 P3​는 자원 R2​의 인스턴스 하나를 요청하고 있으며, 이 R2​ 인스턴스는 현재 프로세스 P4​에 의해 보유되어 있습니다. (P3​→R2​←P4​) 자원 R2​에는 총 2개의 인스턴스가 있으며, 그중 하나는 P4​가 보유하고 있고, 나머지 하나는 가용(available) 상태이거나, 또는 P2​에게 할당될 수 있는 상태라고 가정합니다. (여기서는 P2​와 P3​가 R2​를 요청하는 상황을 좀 더 명확히 하기 위해 P2​가 R2​의 한 인스턴스를 점유하고, P3​가 R2​의 다른 인스턴스를 점유하고, P1​이 P2​가 점유한 R2​를 기다리고, P2​는 R1​을 기다리는 사이클을 만들어보겠습니다. 그리고 R2​의 다른 인스턴스를 P4​가 점유하고, P4​는 다른 자원을 기다리지 않는다고 가정하겠습니다.) 더 명확한 시나리오 (사이클 존재, 교착 아님):\nP1​이 R1​의 인스턴스 하나를 점유하고, R2​의 인스턴스 하나를 요청. (R1​→P1​→R2​) P2​가 R2​의 인스턴스 하나를 점유하고 (다른 인스턴스), R1​의 인스턴스 하나를 요청. (R2​→P2​→R1​) R2​에는 총 2개의 인스턴스가 있습니다. 하나는 P2​가 점유. 다른 하나는 P3​가 점유하고 있고, P3​는 다른 요청이 없음. 자원 할당 그래프 표현 (위 시나리오 기반):\n코드 스니펫\ngraph TD P1((P1)) P2((P2)) P3((P3)) subgraph R1 [R1 (1 instance)] r1_i1(.) end subgraph R2 [R2 (2 instances)] r2_i1(.) r2_i2(.) end r1_i1 --\u003e P1 // P1 holds R1 P1 --\u003e R2 // P1 requests R2 (aiming for r2_i1 held by P2) r2_i1 --\u003e P2 // P2 holds one instance of R2 P2 --\u003e R1 // P2 requests R1 (held by P1) r2_i2 --\u003e P3 // P3 holds the other instance of R2 (and requests nothing else) 그래프 분석:\n사이클(Cycle)의 존재:\n위 그래프에는 P1​과 P2​ 사이에 명확한 사이클이 존재합니다:\nP1​requests​R2​(인스턴스 r2_i1을 통해)held by​P2​requests​R1​held by​P1​\n이 사이클은 P1​,P2​,R1​,R2​(의 한 인스턴스)를 포함합니다.\n교착 상태 여부 판단:\n사이클이 존재함에도 불구하고, 이 시스템은 교착 상태가 아닐 수 있습니다. 왜냐하면 R2​에는 여러 인스턴스가 있기 때문입니다.\n현재 P1​은 P2​가 점유하고 있는 R2​의 특정 인스턴스(r2_i1)를 기다리고 있고, P2​는 P1​이 점유하고 있는 R1​을 기다리고 있어 P1​,P2​ 사이에는 교착 관계가 형성되어 있습니다. 하지만, P3​는 R2​의 다른 인스턴스(r2_i2)를 점유하고 있으며, 다른 자원을 요청하고 있지 않습니다. P3​는 자신의 작업을 계속 진행하다가 언젠가는 R2​의 인스턴스(r2_i2)를 **방출(release)**할 것입니다. 만약 P1​이 P2​가 가진 r2_i1 대신, R2​의 어떤 인스턴스든 사용할 수 있다면, P3​가 r2_i2를 방출했을 때 P1​이 이 인스턴스를 할당받을 수 있습니다. P1​이 R2​를 할당받아 작업을 완료하면, P1​은 R1​을 방출합니다. 그러면 P2​가 R1​을 할당받아 작업을 완료하고 R2​의 인스턴스(r2_i1)를 방출합니다. 이렇게 되면 시스템의 모든 프로세스가 결국 작업을 완료할 수 있게 됩니다. 더 간단하고 명확한 예시 (교과서적 예시):\nP1​→R1​ (요청), R1​은 인스턴스 2개 (i1​,i2​), i1​은 P2​에게 할당. P2​→R2​ (요청), R2​는 인스턴스 1개, R2​는 P1​에게 할당. P3​는 R1​의 i2​를 할당받음. P3​는 R2​를 요청하지 않음. 코드 스니펫\ngraph TD P1((P1)) P2((P2)) P3((P3)) subgraph R1 [R1 (2 instances)] r1_i1(.) r1_i2(.) end subgraph R2 [R2 (1 instance)] r2_i1(.) end P1 --\u003e R1 // P1 requests R1 r1_i1 --\u003e P2 // P2 holds an instance of R1 P2 --\u003e R2 // P2 requests R2 r2_i1 --\u003e P1 // P1 holds R2 r1_i2 --\u003e P3 // P3 holds another instance of R1 사이클: P1​→R1​(인스턴스 r1_i1을 통해)←P2​→R2​←P1​.\n교착 아님: P3​가 작업을 마치고 R1​의 인스턴스 r1_i2를 방출하면, P1​이 이 인스턴스를 사용할 수 있습니다. (만약 P1​이 R1​의 특정 인스턴스가 아닌 아무 인스턴스나 기다리고 있다면). P1​이 R1​을 얻어 작업을 마치면 R2​를 방출하고, 그러면 P2​가 R2​를 얻어 작업을 마칠 수 있습니다.\n핵심:\n자원 할당 그래프에 사이클이 존재하더라도, 그 사이클에 포함된 자원 유형이 여러 인스턴스를 가지고 있고, 그 중 일부 인스턴스가 사이클 외부의 프로세스에 할당되어 있거나 가용 상태여서, 사이클 내의 프로세스 중 하나가 결국 필요한 자원을 얻을 수 있는 경로가 존재한다면 교착 상태가 아닐 수 있습니다.\n이러한 상황 때문에, 자원 유형별로 여러 인스턴스가 있는 시스템에서는 사이클의 존재만으로는 교착 상태를 확정할 수 없습니다. 교착 상태 탐지 알고리즘은 단순히 사이클을 찾는 것 이상으로, 가용 자원과 프로세스의 요청을 고려하여 실제로 진행 불가능한 상황인지를 판단해야 합니다.\n이 슬라이드는 교착 상태의 조건과 자원 할당 그래프의 해석에 있어 미묘하지만 중요한 차이를 이해시키는 데 도움을 줍니다. 단일 인스턴스 자원의 경우 사이클 = 교착이지만, 다중 인스턴스 자원의 경우 사이클 = 교착일 수 있다는 점을 기억해야 합니다.","상세한-설명#\u003cstrong\u003e상세한 설명\u003c/strong\u003e":"","상세한-설명-1#\u003cstrong\u003e상세한 설명\u003c/strong\u003e":"","상세한-설명-2#\u003cstrong\u003e상세한 설명\u003c/strong\u003e":"","상세한-설명-3#\u003cstrong\u003e상세한 설명\u003c/strong\u003e":"","상세한-설명-4#\u003cstrong\u003e상세한 설명\u003c/strong\u003e":"","상세한-설명-5#\u003cstrong\u003e상세한 설명\u003c/strong\u003e":"","상호-배제-조건-공략-attacking-the-mutual-exclusion-condition#상호 배제 조건 공략 (Attacking the Mutual Exclusion Condition)":"원문 (Original Text):\nAttacking the Mutual Exclusion Condition  Some devices (such as printer) can be spooled  only the printer daemon uses printer resource  thus deadlock for printer eliminated  Not all devices can be spooled  Principle:  avoid assigning resource when not absolutely necessary  as few processes as possible actually claim the resource 번역 (Translation):\n상호 배제 조건 공략  일부 장치(예: 프린터)는 스풀링(spooled)될 수 있음  오직 프린터 데몬만이 프린터 자원을 사용함  따라서 프린터에 대한 교착 상태가 제거됨  모든 장치가 스풀링될 수 있는 것은 아님  원칙:  절대적으로 필요하지 않은 경우에는 자원 할당을 피함  가능한 적은 수의 프로세스만이 실제로 자원을 요청하도록 함 매우 자세한 설명 (Detailed Explanation):\n이 슬라이드는 교착 상태 예방 전략 중 첫 번째로, 상호 배제(Mutual Exclusion) 조건을 약화시키거나 제거하려는 시도에 대해 설명합니다. 🛡️⚔️ 상호 배제는 여러 프로세스가 하나의 공유 불가능한 자원을 동시에 사용할 수 없도록 하는 것인데, 이것이 교착 상태의 네 가지 필요조건 중 하나입니다.\n상호 배제 조건의 본질:\n상호 배제 조건은 “최소한 하나의 자원이 비공유 모드로 점유되어야 한다\"는 것입니다. 즉, 한 번에 하나의 프로세스만 사용할 수 있는 자원이 존재해야 교착 상태가 발생할 수 있습니다. 만약 모든 자원이 완벽하게 공유 가능하다면(여러 프로세스가 동시에 사용 가능), 어떤 프로세스도 자원을 기다릴 필요가 없으므로 교착 상태는 발생하지 않습니다.\n상호 배제 조건 공략 방법:\n1. 스풀링 (Spooling)을 통한 간접적 공유:\n개념: “Some devices (such as printer) can be spooled” 프린터와 같이 본질적으로 한 번에 하나의 작업만 처리할 수 있는 배타적 자원의 경우, 직접적인 상호 배제를 완화하기 위해 스풀링(Spooling - Simultaneous Peripheral Operations On-Line) 기법을 사용합니다. 작동 방식: 프로세스가 프린터에 직접 출력 요청을 보내는 대신, 출력할 데이터를 디스크의 특정 영역(스풀 디렉토리 또는 스풀 큐)에 파일 형태로 저장합니다. 이 작업은 상대적으로 빠르게 완료될 수 있으며, 여러 프로세스가 거의 동시에 스풀 디렉토리에 자신의 출력 파일을 생성할 수 있습니다. 프린터 데몬(printer daemon) 또는 프린터 스케줄러라는 특별한 시스템 프로세스가 스풀 디렉토리를 지속적으로 감시합니다. 프린터 데몬은 스풀 디렉토리에 있는 출력 파일들을 순서대로 (또는 특정 우선순위에 따라) 가져와 실제 물리적 프린터 장치로 전송하여 인쇄합니다. 효과: “only the printer daemon uses printer resource, thus deadlock for printer eliminated” 실제 물리적 프린터 자원은 오직 프린터 데몬만이 배타적으로 접근하고 사용합니다. 일반 사용자 프로세스들은 프린터 데몬을 통해 간접적으로 프린터를 사용하게 되므로, 사용자 프로세스들 사이에서 프린터 자원을 놓고 직접적인 경쟁이나 대기가 발생하지 않습니다. 결과적으로, 프린터 자원과 관련된 교착 상태는 효과적으로 제거됩니다. 사용자 프로세스 입장에서는 마치 프린터를 동시에 사용하는 것처럼 느껴질 수 있지만, 실제로는 작업이 버퍼링되고 순차 처리되는 것입니다. 적용 예: 프린터, 카드 판독기 등. 2. 스풀링의 한계:\n“Not all devices can be spooled” 모든 자원에 스풀링 기법을 적용할 수 있는 것은 아닙니다. 예를 들어, 프로세스가 특정 데이터 파일에 대해 읽기/쓰기 작업을 수행해야 하는 경우, 이 작업을 스풀링으로 처리하기는 어렵습니다. 데이터의 일관성과 동시 접근 제어가 필요하기 때문입니다. CPU 레지스터, 메모리 특정 영역 등은 그 성격상 스풀링이 부적합합니다. 스풀링은 주로 출력을 지연시킬 수 있거나, 작업의 순서가 중요하지만 동시성은 떨어져도 되는 자원에 적합합니다. 일반적인 원칙 (Principle): 상호 배제 조건을 완전히 제거하기는 어렵더라도, 그 영향을 최소화하기 위한 일반적인 지침은 다음과 같습니다.\n“avoid assigning resource when not absolutely necessary” (절대적으로 필요하지 않은 경우에는 자원 할당을 피함):\n시스템 설계 시 자원을 꼭 배타적으로 할당해야 하는지 신중히 검토해야 합니다. 공유 가능한 방식으로 자원을 설계하거나, 접근 권한을 세밀하게 제어하여 불필요한 배타적 사용을 줄입니다. 예를 들어, 단순 조회 목적이라면 쓰기 락(exclusive lock) 대신 읽기 락(shared lock)을 사용하도록 유도합니다. “as few processes as possible actually claim the resource” (가능한 적은 수의 프로세스만이 실제로 자원을 요청하도록 함):\n특정 배타적 자원에 접근해야 하는 프로세스의 수를 최소화하도록 시스템을 구성합니다. 자원 접근 로직을 특정 모듈이나 서비스로 집중시키고, 다른 프로세스들은 이 서비스를 통해 간접적으로 자원을 이용하도록 유도할 수 있습니다 (스풀링과 유사한 원리). 예를 들어, 데이터베이스 연결 풀을 사용하여 실제 DB 연결 수를 제한하고, 애플리케이션 프로세스들은 이 풀에서 연결을 빌려 쓰는 방식을 사용합니다. 이는 DB 연결이라는 자원에 대한 직접적인 경쟁을 줄여줍니다. 결론:\n상호 배제 조건은 교착 상태의 근본적인 원인 중 하나이지만, 많은 자원들이 그 특성상 배타적 사용을 요구하기 때문에 이 조건을 완전히 제거하는 것은 매우 어렵습니다. 스풀링과 같은 기법은 일부 자원에 대해 효과적인 해결책을 제공하지만, 보편적으로 적용되기는 힘듭니다. 따라서 현실적으로는 상호 배제를 피할 수 없는 경우 다른 교착 상태 예방 조건(점유와 대기, 비선점, 환형 대기)을 공략하거나, 교착 상태 회피 또는 탐지 및 회복 전략을 사용하는 것이 일반적입니다. 그럼에도 불구하고, 자원 사용을 신중하게 설계하여 불필요한 상호 배제를 줄이려는 노력은 시스템 성능과 안정성 향상에 기여할 수 있습니다.","설계-고려사항#\u003cstrong\u003e설계 고려사항\u003c/strong\u003e:":"","설계-고려사항-1#\u003cstrong\u003e설계 고려사항\u003c/strong\u003e:":"","설계-고려사항-2#\u003cstrong\u003e설계 고려사항\u003c/strong\u003e:":"","설계-고려사항-3#\u003cstrong\u003e설계 고려사항\u003c/strong\u003e:":"","설계-고려사항-4#\u003cstrong\u003e설계 고려사항\u003c/strong\u003e:":"","설계-고려사항-5#\u003cstrong\u003e설계 고려사항\u003c/strong\u003e:":"","설명#\u003cstrong\u003e설명\u003c/strong\u003e:":"","설명-1#\u003cstrong\u003e설명\u003c/strong\u003e:":"","설명-2#\u003cstrong\u003e설명\u003c/strong\u003e:":"","설명-3#\u003cstrong\u003e설명\u003c/strong\u003e:":"","설명-4#\u003cstrong\u003e설명\u003c/strong\u003e:":"","설명-5#\u003cstrong\u003e설명\u003c/strong\u003e:":"","설명-6#설명":"","성능-목표-최소한의-페이지-폴트#\u003cstrong\u003e성능 목표: 최소한의 페이지 폴트\u003c/strong\u003e":"슬라이드의 마지막 줄은 페이지 교체의 궁극적인 목표를 강조합니다. “최소한의 페이지 폴트를 유발하는 알고리즘을 원한다.”\n페이지 교체는 필연적으로 디스크 I/O를 동반하며, 이는 시스템 성능에 큰 부담을 줍니다. 만약 페이지 교체 알고리즘이 나빠서, 방금 쫓아낸 페이지가 바로 다음 순간에 다시 필요해지는 상황이 반복된다면 어떻게 될까요? 예를 들어, A 페이지를 쫓아내고 B를 가져왔더니, 바로 B를 사용하는 명령 다음에 A를 사용하는 명령이 있는 경우입니다. 그러면 또다시 페이지 폴트가 발생하고, 이번에는 B나 다른 페이지를 쫓아내고 A를 다시 가져와야 합니다.\n이렇게 페이지 교체가 과도하게 일어나 시스템이 실제 작업은 거의 하지 못하고 페이지를 디스크와 메모리 사이에서 옮기느라 모든 시간을 허비하는 현상을 **스래싱(Thrashing)**이라고 합니다. 스래싱이 발생하면 시스템의 성능은 급격히 저하됩니다.\n따라서 좋은 페이지 교체 알고리즘은 **“가까운 미래에 가장 사용될 가능성이 낮은 페이지”**를 희생양으로 선택해야 합니다. 미래를 예측할 수는 없으므로, 다양한 알고리즘들은 과거의 페이지 사용 패턴을 기반으로 미래를 추측합니다. 대표적인 알고리즘은 다음과 같습니다.\nFIFO (First-In, First-Out): 가장 오래전에 메모리에 들어온 페이지를 교체합니다. 구현은 간단하지만 성능이 좋지 않을 수 있습니다. LRU (Least Recently Used): 가장 오랫동안 사용되지 않은 페이지를 교체합니다. 미래에도 사용되지 않을 가능성이 높다는 지역성 원리에 기반하며, 일반적으로 성능이 우수하지만 구현이 복잡합니다. OPT (Optimal): 앞으로 가장 오랫동안 사용되지 않을 페이지를 교체합니다. 이론적으로 최적의 알고리즘이지만, 미래를 예측해야 하므로 실제 구현은 불가능하고 다른 알고리즘의 성능을 평가하는 기준으로만 사용됩니다. 결론적으로, 페이지 교체는 가상 메모리 시스템이 메모리 과할당(over-allocation) 상태에서도 지속적으로 동작할 수 있게 해주는 필수적인 메커니즘입니다. 하지만 이 과정의 효율성은 어떤 페이지를 교체할지 결정하는 알고리즘의 성능에 크게 좌우되며, 이는 운영 체제 설계의 중요한 연구 분야 중 하나입니다.","소개되는-주요-알고리즘#\u003cstrong\u003e소개되는 주요 알고리즘\u003c/strong\u003e":"슬라이드는 대표적인 페이지 교체 알고리즘 세 가지를 나열하고 있습니다. 이들은 페이지 교체 알고리즘 논의에서 가장 기본적이면서도 중요한 위치를 차지합니다.\n최적 알고리즘 (Optimal Algorithm, OPT 또는 MIN):\n핵심 아이디어: 앞으로 가장 오랜 기간 동안 사용되지 않을 페이지를 교체합니다. 특징: 이론적으로 가장 낮은 페이지 폴트율을 보장합니다. 즉, 가능한 최상의 성능을 나타냅니다. 그러나 페이지의 미래 참조 시점을 정확히 예측해야 하므로 실제 시스템에서는 구현이 불가능합니다. 주로 다른 알고리즘의 성능을 평가하고 비교하기 위한 **기준점(benchmark)**으로 사용됩니다. 선입선출 알고리즘 (FIFO: First-In, First-Out):\n핵심 아이디어: 물리 메모리에 가장 먼저 들어온 페이지를 가장 먼저 내보냅니다. 즉, 메모리에 가장 오래 머물렀던 페이지를 희생시킵니다. 특징: 개념이 매우 단순하고 구현이 용이합니다. 페이지가 메모리에 들어온 순서대로 큐(queue)에 넣어 관리하면 되기 때문입니다. 하지만 페이지의 최근 사용 빈도나 중요도를 전혀 고려하지 않기 때문에, 오랫동안 자주 사용되던 중요한 페이지가 단지 오래되었다는 이유만으로 교체될 수 있어 비효율적인 상황이 발생할 수 있습니다. 심지어 프레임 수를 늘렸는데도 페이지 폴트가 증가하는 벨레이디의 모순(Belady’s Anomaly) 현상이 나타날 수 있는 알고리즘이기도 합니다. 최근 최소 사용 알고리즘 (LRU: Least Recently Used):\n핵심 아이디어: 가장 오랫동안 사용되지 않은 페이지를 교체합니다. 이는 “과거에 오랫동안 사용되지 않았다면 미래에도 사용될 가능성이 적을 것이다\"라는 참조의 지역성(locality of principle) 원리에 기반합니다. 특징: 일반적으로 FIFO보다 훨씬 좋은 성능을 보이며, 최적 알고리즘에 근접하는 성능을 내는 경우가 많습니다. 하지만 실제로 각 페이지의 ‘가장 마지막 사용 시점’을 정확히 추적하는 것은 상당한 하드웨어 지원이나 소프트웨어적인 오버헤드를 필요로 하기 때문에, 완전한 LRU를 구현하는 것은 비용이 많이 들 수 있습니다. 따라서 실제 시스템에서는 LRU의 근사(approximation) 알고리즘들이 많이 사용됩니다. (예: LFU(Least Frequently Used), MFU(Most Frequently Used), NUR(Not Used Recently), Second-Chance Algorithm, Clock Algorithm 등) 이 슬라이드는 앞으로 논의될 페이지 교체 전략들의 대략적인 윤곽을 제시하며, 어떤 기준으로 이들을 평가해야 하는지에 대한 방향을 설정해 줍니다. 궁극적으로 모든 페이지 교체 알고리즘은 한정된 메모리라는 제약 하에서 어떻게 하면 디스크 I/O를 최소화하여 시스템 응답성과 처리율을 극대화할 수 있을까라는 근본적인 질문에 대한 각기 다른 해답이라고 볼 수 있습니다.","슬라이드-1-공유-버퍼-문제#슬라이드 1: 공유 버퍼 문제":"","시뮬레이션-설정#\u003cstrong\u003e시뮬레이션 설정\u003c/strong\u003e":"참조 문자열 (Reference String): 프로세스가 특정 순서로 페이지를 참조하는 것을 나타내는 숫자열입니다. 각 숫자는 페이지 번호를 의미합니다. 예를 들어, 다음과 같은 참조 문자열을 사용하겠습니다. 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1 사용 가능한 물리 메모리 프레임 수: 간단한 설명을 위해 3개의 프레임을 가정하겠습니다. 초기 상태: 모든 프레임은 비어있다고 가정합니다. 목표: 최적 알고리즘을 사용하여 페이지 폴트(Page Fault, PF) 발생 횟수를 최소화합니다.","시뮬레이션-설정-최적-알고리즘과-동일#\u003cstrong\u003e시뮬레이션 설정 (최적 알고리즘과 동일)\u003c/strong\u003e":"참조 문자열 (Reference String): 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1 사용 가능한 물리 메모리 프레임 수: 3개의 프레임을 가정하겠습니다. 초기 상태: 모든 프레임은 비어있다고 가정합니다. FIFO 큐: 페이지가 메모리에 들어온 순서를 기록합니다. 큐의 머리(head)가 가장 먼저 들어온 페이지, 꼬리(tail)가 가장 최근에 들어온 페이지입니다. 목표: FIFO 알고리즘을 사용하여 페이지 폴트(Page Fault, PF) 발생 횟수를 계산합니다.","시스템-모델-system-model#시스템 모델 (System Model)":"원문 (Original Text):\nSystem Model  Resource types R1, R2, . . ., Rm CPU cycles, memory space, I/O devices  Each resource type Ri has Wi instances.  Each process utilizes a resource as follows:  request  use  release 번역 (Translation):\n시스템 모델  자원 유형 R1, R2, . . ., Rm CPU 사이클, 메모리 공간, 입출력 장치  각 자원 유형 Ri는 Wi개의 인스턴스(instance)를 가짐.  각 프로세스는 다음과 같이 자원을 활용함:  요청 (request)  사용 (use)  방출 (release) 매우 자세한 설명 (Detailed Explanation):\n이 슬라이드는 교착 상태를 논의하기 위한 기본적인 시스템 환경과 자원의 특성, 그리고 프로세스가 자원을 사용하는 일반적인 방식을 정의합니다. 이는 교착 상태의 발생 가능성과 해결 방법을 이해하는 데 필요한 배경 지식을 제공합니다. 🛠️\n자원 유형 (Resource types R1, R2, …, Rm): 시스템 내에는 다양한 종류의 자원이 존재합니다. 이들을 유형별로 구분하여 R1​,R2​,…,Rm​ 과 같이 표현합니다.\n예시: CPU 사이클 (CPU cycles): 프로세스가 명령어를 실행하기 위해 필요한 중앙 처리 장치의 처리 시간입니다. 이는 시간 분할 시스템에서 매우 중요한 자원입니다. 메모리 공간 (Memory space): 프로세스의 코드, 데이터, 스택 등을 저장하기 위한 주 기억장치(RAM)의 공간입니다. 각 프로세스는 실행되기 위해 일정량의 메모리를 필요로 합니다. 입출력 장치 (I/O devices): 프린터, 디스크 드라이브, 네트워크 인터페이스 카드 등과 같이 시스템 외부와의 데이터 교환이나 특수 기능을 수행하는 하드웨어 장치들입니다. 이러한 자원들은 그 성격에 따라 공유 가능 여부, 선점 가능 여부 등이 달라지며, 이는 교착 상태 발생에 영향을 미칩니다. 예를 들어, CPU는 시간 분할을 통해 여러 프로세스가 공유하지만, 특정 시점에는 한 프로세스에 의해 독점적으로 사용될 수 있습니다. 프린터와 같은 장치는 일반적으로 한 번에 하나의 프로세스만 사용할 수 있습니다 (상호 배제).\n각 자원 유형 Ri​는 Wi​개의 인스턴스(instance)를 가짐: 각 자원 유형은 하나 이상의 동일한 기능을 수행하는 인스턴스(instance) 또는 단위(unit)를 가질 수 있습니다. Wi​는 자원 유형 Ri​에 속하는 동일한 인스턴스의 개수를 나타냅니다.\n예시: 만약 시스템에 2개의 동일한 CPU가 있다면, CPU라는 자원 유형(RCPU​)은 2개의 인스턴스 (WCPU​=2)를 가집니다. 시스템에 4개의 동일한 테이프 드라이브가 있다면, 테이프 드라이브라는 자원 유형(RTape​)은 4개의 인스턴스 (WTape​=4)를 가집니다. 만약 어떤 자원 유형이 오직 하나의 인스턴스만 가진다면 (예: 특별한 그래픽 카드), 해당 자원 유형의 Wi​=1이 됩니다. 자원 인스턴스의 개수는 교착 상태 발생 가능성에 중요한 영향을 미칩니다. 만약 어떤 자원 유형의 인스턴스가 여러 개 있다면, 여러 프로세스가 동시에 해당 유형의 자원을 사용할 수 있으므로 교착 상태 발생 가능성이 낮아질 수 있습니다. 반대로, 인스턴스가 하나뿐인 자원을 여러 프로세스가 동시에 요구하면 교착 상태가 발생하기 쉽습니다.\n각 프로세스는 다음과 같이 자원을 활용함 (Each process utilizes a resource as follows): 프로세스가 시스템 내의 자원을 사용하는 일반적인 패턴은 세 단계로 나눌 수 있습니다.\n요청 (Request):\n프로세스가 특정 작업을 수행하기 위해 자원이 필요한 경우, 운영체제에 해당 자원의 할당을 요청합니다.\n만약 요청한 자원의 인스턴스가 즉시 할당될 수 있다면 (즉, 가용 인스턴스가 있다면), 운영체제는 해당 자원을 프로세스에 할당합니다. 만약 요청한 자원이 즉시 할당될 수 없다면 (예: 다른 프로세스가 이미 모든 인스턴스를 사용 중이거나, 가용 인스턴스가 부족한 경우), 요청한 프로세스는 해당 자원을 사용할 수 있을 때까지 대기(wait) 상태로 전환됩니다. 이때, 대기하는 방식은 시스템의 스케줄링 정책에 따라 달라질 수 있습니다 (예: 큐에 저장). 사용 (Use):\n프로세스가 요청하여 할당받은 자원을 가지고 특정 작업을 수행합니다. 예를 들어, 프린터 자원을 할당받았다면 문서를 출력하고, CPU 자원을 할당받았다면 명령어를 실행합니다. 이 단계에서 프로세스는 할당된 자원에 대해 배타적인 제어권을 가질 수도 있고 (상호 배제), 다른 프로세스와 공유할 수도 있습니다 (자원의 특성에 따라 다름).\n방출 (Release):\n프로세스가 자원의 사용을 모두 마치면, 해당 자원을 운영체제에 반납합니다. 이렇게 방출된 자원은 다른 대기 중인 프로세스에 할당될 수 있게 됩니다.\n자원의 방출은 일반적으로 프로세스가 작업을 완료했거나, 특정 자원이 더 이상 필요하지 않을 때 자발적으로 이루어집니다. 이러한 요청-사용-방출 (Request-Use-Release) 순서는 모든 자원 활용의 기본적인 사이클입니다. 교착 상태는 주로 ‘요청’ 단계에서 원하는 자원을 얻지 못하고 대기하는 프로세스들이 서로 물고 물리는 관계를 형성할 때 발생합니다. 시스템 모델을 이렇게 정의함으로써, 어떤 조건에서 자원 요청이 실패하고 프로세스들이 대기 상태에 빠지며, 이것이 어떻게 교착 상태로 이어질 수 있는지를 보다 체계적으로 분석할 수 있게 됩니다. 예를 들어, 한정된 수의 인스턴스를 가진 자원에 대해 여러 프로세스가 동시에 ‘요청’하고, 각자 일부 자원을 ‘사용’ (점유)한 상태에서 추가 자원을 기다리며 ‘방출’하지 않을 때 교착 상태가 발생할 수 있습니다.","실행에-필요한-부분만-메모리에-적재#\u003cstrong\u003e실행에 필요한 부분만 메모리에 적재\u003c/strong\u003e":"가상 메모리의 또 다른 혁신적인 특징은 **‘프로그램의 전체가 아닌, 당장 실행에 필요한 부분만 물리 메모리에 올려놓고 실행을 시작할 수 있다’**는 점입니다.\n대부분의 프로그램은 특정 순간에 코드의 극히 일부만을 실행합니다. 예를 들어, 워드 프로세서 프로그램에는 수많은 기능(글꼴 변경, 표 만들기, 맞춤법 검사 등)이 있지만, 사용자는 한 번에 하나의 기능만을 사용합니다. 또한, 프로그램에는 오류 처리 루틴이나 초기화 코드처럼 한 번만 실행되거나 거의 실행되지 않는 부분들이 많습니다.\n가상 메모리 시스템은 이러한 프로그램의 지역성(locality of reference) 원리를 활용합니다. 프로그램 전체를 실행 전에 메모리에 올리는 대신, 실행에 필요한 최소한의 부분(예: 메인 함수 주변 코드)만 먼저 올립니다. 그리고 실행 중에 만약 메모리에 없는 코드나 데이터에 접근하려고 하면, 그 순간에 해당 부분을 디스크(보조 기억 장치)에서 물리 메모리로 가져옵니다. 이처럼 ‘필요할 때 가져오는’ 방식을 **요구 페이징(Demand Paging)**이라고 합니다.\n이 방식은 다음과 같은 장점을 가집니다.\n빠른 프로그램 시작: 프로그램 전체를 읽어올 때까지 기다릴 필요가 없으므로 사용자는 프로그램을 더 빨리 시작할 수 있습니다. 메모리 공간 절약: 실제로 사용되는 부분만 메모리를 차지하므로, 한정된 물리 메모리로 더 많은 프로그램을 동시에 실행할 수 있습니다. 이는 시스템의 전반적인 처리율(throughput)과 효율성을 높입니다.","안전-불안전-교착-상태-safe-unsafe-deadlock-state#안전, 불안전, 교착 상태 (Safe, Unsafe, Deadlock State)":"","안전-상태-safe-state#안전 상태 (Safe State)":"","알고리즘의-목표-최소-페이지-폴트율-lowest-page-fault-rate#\u003cstrong\u003e알고리즘의 목표: 최소 페이지 폴트율 (Lowest Page-Fault Rate)\u003c/strong\u003e":"슬라이드는 페이지 교체 알고리즘의 가장 중요한 목표를 **“첫 접근과 재접근 모두에서 가장 낮은 페이지 폴트율을 원함 (Want lowest page-fault rate on both first access and re-access)”**이라고 명시하고 있습니다. 이를 좀 더 자세히 풀어보겠습니다.\n페이지 폴트율 (Page-Fault Rate): 프로그램 실행 중 발생하는 페이지 폴트의 빈도를 나타내는 지표입니다. 예를 들어, 1000번의 메모리 참조 중 10번의 페이지 폴트가 발생했다면 폴트율은 1%입니다. 이 비율이 낮을수록 시스템은 디스크 I/O에 소요되는 시간을 줄이고, 실제 연산에 더 많은 시간을 할애할 수 있어 전반적인 성능이 향상됩니다.\n첫 접근 (First Access): 어떤 페이지가 프로그램 실행 후 처음으로 참조되는 경우를 의미합니다. 요구 페이징 시스템에서는 페이지가 처음 참조될 때 물리 메모리에 없는 것이 정상이므로, 이때 발생하는 페이지 폴트는 불가피합니다. 이를 필수 페이지 폴트(compulsory page fault) 또는 **콜드 스타트 폴트(cold-start fault)**라고도 합니다. 페이지 교체 알고리즘은 이러한 첫 접근 폴트 자체를 줄일 수는 없습니다.\n재접근 (Re-access): 이미 메모리에 한 번 적재되었던 페이지가 디스크로 스왑 아웃되었다가 다시 참조되는 경우, 또는 메모리에 계속 머물러 있던 페이지가 다시 참조되는 경우를 포괄적으로 의미합니다. 페이지 교체 알고리즘의 성능은 주로 이 재접근 시의 페이지 폴트를 얼마나 잘 줄이느냐에 따라 평가됩니다. 만약 알고리즘이 현명하게 희생 페이지를 선택하여 가까운 미래에 다시 사용될 페이지를 메모리에 잘 유지시킨다면, 재접근 시에는 페이지 폴트 없이 메모리에서 바로 데이터를 가져올 수 있습니다(이를 **페이지 히트(page hit)**라고 합니다). 반대로, 곧 사용될 페이지를 성급하게 내쫓는다면, 재접근 시 또다시 페이지 폴트가 발생하여 디스크 I/O를 유발합니다.\n따라서 페이지 교체 알고리즘의 핵심 과제는, 불가피한 첫 접근 폴트를 제외하고, 한정된 메모리 프레임 내에서 미래에 참조될 가능성이 높은 페이지들을 최대한 오래 유지함으로써 재접근 시의 폴트율을 낮추는 것입니다.","영향#\u003cstrong\u003e영향\u003c/strong\u003e:":"","영향-1#\u003cstrong\u003e영향\u003c/strong\u003e:":"","영향-2#\u003cstrong\u003e영향\u003c/strong\u003e:":"","예시#예시:":"하드웨어나 컴파일러 최적화로 인해 변수의 쓰기/읽기가 순서대로 처리되지 않는 경우. 예: flag[me] = true와 turn = !me 사이에 다른 프로세스가 개입하면 의도한 동작이 실패할 수 있음.","예시-1#예시:":"Process 0이 flag[0] = true를 실행하고 선점당한 후, Process 1이 flag[1] = true와 turn = 0을 실행하며 임계구역에 진입할 수 있는 상황이 발생함.","예시-2#예시:":"Process 0이 flag[0] = true를 캐시에 저장했지만, 이 값이 메인 메모리로 플러시되기 전에 Process 1이 읽게 되면, Process 1은 flag[0]가 여전히 false라고 판단할 수 있음.","예시-3#예시:":"Process 0이 flag[0] = true 이후 종료되면, Process 1은 while (flag[0] \u0026\u0026 turn == 0)에서 무한히 대기할 수 있음.","예시-4#예시:":"3개 이상의 프로세스가 있을 경우, flag 배열과 turn 변수만으로는 충분하지 않으며, 새로운 동기화 메커니즘이 필요합니다.","예시-조합#예시 조합":"","요구-페이징의-장점-benefits-of-demand-paging#\u003cstrong\u003e요구 페이징의 장점 (Benefits of Demand Paging)\u003c/strong\u003e":"슬라이드에 나열된 장점들은 요구 페이징의 본질적인 특성에서 비롯됩니다.\n더 적은 I/O 필요, 불필요한 I/O 없음 (Less I/O needed, no unnecessary I/O)\n컴퓨터 시스템에서 디스크 입출력(I/O)은 CPU 연산이나 메모리 접근에 비해 극도로 느린 작업입니다. 만약 프로그램의 모든 페이지를 실행 전에 메모리로 가져온다면, 수십, 수백 메가바이트의 데이터를 디스크에서 읽어오는 데 상당한 시간이 소요됩니다. 하지만 대부분의 프로그램은 전체 코드 중 극히 일부만 실행하거나, 특정 기능은 전혀 사용하지 않을 수 있습니다. 요구 페이징은 실제로 사용되는 페이지만을 디스크에서 읽어오기 때문에, 불필요한 디스크 I/O를 원천적으로 차단합니다. 이는 시스템의 I/O 부하를 크게 줄여줍니다.\n더 적은 메모리 필요 (Less memory needed)\n프로그램의 전체가 아닌, 현재 실행에 필요한 부분집합(working set)만이 물리 메모리를 차지합니다. 예를 들어, 100MB 크기의 프로그램이 실행 중에 실제로 10MB의 페이지만을 집중적으로 사용한다면, 물리 메모리에서는 단 10MB만 점유하게 됩니다. 이는 각 프로세스가 차지하는 물리 메모리의 양(footprint)을 크게 줄여줍니다. 한정된 물리 메모리 자원을 훨씬 효율적으로 사용할 수 있게 되는 것입니다.\n더 빠른 응답 (Faster response)\n사용자 입장에서 체감되는 가장 큰 장점 중 하나입니다. 프로그램을 실행시켰을 때, 시스템은 프로그램 전체를 디스크에서 읽어올 때까지 기다릴 필요가 없습니다. 최소한의 초기화 후 즉시 실행을 시작하고, 필요한 페이지는 실행 과정에서 ‘투명하게(transparently)’ 가져옵니다. 이로 인해 프로그램의 시작 시간(startup time)이 극적으로 단축됩니다. 사용자는 프로그램을 클릭한 후 거의 즉각적으로 프로그램 창이 뜨고 상호작용을 시작할 수 있습니다. 물론, 초기 실행 중에 여러 번의 페이지 폴트가 발생하여 약간의 지연이 있을 수 있지만, 전체를 로딩하는 것보다는 훨씬 빠른 사용자 경험을 제공합니다.\n더 많은 사용자 수용 가능 (More users)\n이는 앞선 장점들의 종합적인 결과입니다. 각 프로세스가 더 적은 물리 메모리를 사용하므로, 동일한 크기의 물리 메모리에서 더 많은 수의 프로세스를 동시에 실행할 수 있습니다. 이를 ‘다중 프로그래밍의 정도(degree of multiprogramming)가 높아진다’고 표현합니다. 더 많은 프로세스가 메모리에 동시에 상주할 수 있다는 것은, CPU가 유휴 상태에 빠질 확률이 줄어든다는 것을 의미합니다. 한 프로세스가 디스크 I/O(예: 페이지 폴트 처리)를 기다리는 동안, CPU는 메모리에 있는 다른 프로세스로 전환하여 작업을 계속할 수 있습니다. 결과적으로 시스템의 전반적인 자원 활용률과 처리량이 극대화됩니다. 이는 특히 여러 사용자가 동시에 접속하여 자원을 공유하는 서버 환경에서 매우 중요한 이점입니다.\n결론적으로, 요구 페이징은 단순한 기술을 넘어 현대 운영 체제의 성능과 효율성을 정의하는 핵심 패러다임입니다. 자원을 ‘필요할 때까지 아껴두는’ 이 게으른 접근 방식은 I/O, 메모리, CPU 등 시스템의 모든 핵심 자원을 훨씬 효율적으로 사용하게 만들어, 결과적으로 더 빠르고 더 많은 작업을 처리할 수 있는 강력한 컴퓨팅 환경을 구축하는 기반이 됩니다.","요구-페이징의-핵심-원리#\u003cstrong\u003e요구 페이징의 핵심 원리: “필요할 때만 가져온다”\u003c/strong\u003e":"요구 페이징의 기본 철학은 매우 단순하고 직관적입니다. “어떤 페이지(page)가 실제로 필요해지기 전까지는 절대 물리 메모리로 가져오지 않는다.”\n여기서 ‘페이지’란 가상 메모리 시스템에서 메모리를 관리하는 고정된 크기의 기본 단위를 의미합니다(보통 4KB). ‘필요해지는 순간’이란 CPU가 해당 페이지 내에 있는 명령어(instruction)나 데이터(data)에 접근하려고 시도하는 바로 그 순간을 말합니다.\n이와 반대되는 개념은 ‘순수 페이징(Pure Paging)’ 또는 ‘선행 페이징(Anticipatory Paging)‘으로, 프로그램이 시작될 때 프로그램에 속한 모든 페이지를 미리 물리 메모리에 올려놓는 방식입니다. 요구 페이징은 이러한 비효율적인 선행 작업을 완전히 배제합니다. 대신, 프로그램이 시작되면 운영 체제는 해당 프로그램의 실행에 필요한 최소한의 정보(예: 페이지 테이블)만 준비하고, 실제 코드나 데이터 페이지는 하나도 메모리에 올리지 않은 상태에서 실행을 시작합니다.\n프로세스가 실행을 시작하고 첫 번째 명령어를 읽으려 할 때, 해당 명령어가 포함된 페이지는 당연히 물리 메모리에 없습니다. 이때 하드웨어(MMU)는 ‘페이지 폴트(Page Fault)‘라는 예외(trap)를 발생시켜 운영 체제에 알립니다. 그러면 운영 체제는 이 요청에 응답하여 디스크(Backing Store)에서 해당 페이지를 찾아서 비어있는 물리 메모리 공간(프레임, frame)으로 가져옵니다. 이 작업이 완료되면, 중단되었던 명령어부터 실행을 재개합니다. 이후에도 프로그램이 실행되면서 메모리에 없는 새로운 페이지에 접근할 때마다 이 ‘요구 → 페이지 폴트 → 디스크 I/O → 메모리 적재’ 과정이 반복됩니다.\n이처럼 게으르게, 즉 요청이 있을 때만 수동적으로 페이지를 가져오는 방식은 시스템 전반에 걸쳐 상당한 성능 향상과 자원 효율성을 가져옵니다.","요구사항-분석#요구사항 분석:":"상호 배제(Mutual Exclusion): X\nlocked 변수를 통해 두 프로세스가 동시에 임계구역에 진입하는 것을 방지하려고 합니다. 그러나 경쟁 상태(Race Condition)가 발생할 가능성이 있습니다. 예를 들어, 두 프로세스가 동시에 while (locked == 1) 조건을 통과하고 바로 다음 줄에서 locked = 1을 실행하면, 두 프로세스가 동시에 임계구역에 진입할 수 있습니다. 결론: 상호 배제를 완벽히 보장하지 못합니다. 진행(Progress): O\n한 프로세스가 임계구역을 빠져나가면 즉시 다른 프로세스가 진입할 수 있습니다. 결론: 진행 조건 충족 유한 대기(Bounded Waiting): X\n특정 프로세스가 무한히 기다리는 상황이 발생할 수 있습니다.( 보장하지 못함 계속 새치기 당할 수 있음 ) 결론: 유한 대기를 보장하지 못합니다.","요구사항-분석-1#요구사항 분석:":"상호 배제(Mutual Exclusion): O\nturn 변수를 통해 두 프로세스가 동시에 임계구역에 진입하는 것을 방지합니다. 결론: 상호 배제를 보장합니다. 진행(Progress): X\n한 프로세스가 임계구역을 자주 사용해야 하는 경우에도 반드시 턴이 돌아올 때까지 기다려야 합니다. 예를 들어, Process 0이 임계구역을 빠져나간 후 더 이상 임계구역에 진입하지 않아도, Process 1은 턴이 돌아오기 전까지 대기해야 합니다. 누구는 임계구역에 들어갈 수 있어야 한다 결론: 진행 조건을 충족하지 못합니다. 유한 대기(Bounded Waiting): O\n턴이 순환적으로 변경되므로 모든 프로세스는 유한한 시간 내에 임계구역에 진입할 수 있습니다. 한개의 프로세스가 계속 할 수 없다 결론: 유한 대기를 보장합니다.","요구사항-분석-2#요구사항 분석:":"상호 배제(Mutual Exclusion): O\nflag 배열을 통해 두 프로세스가 동시에 임계구역에 진입하는 것을 방지합니다. 결론: 상호 배제를 보장합니다. 진행(Progress): X\n두 프로세스가 동시에 flag[me] = true를 실행하면, 서로가 상대방의 의도를 확인하고 무한히 대기하는 데드락(Deadlock) 상태에 빠질 수 있습니다. 결론: 진행 조건을 충족하지 못합니다. 유한 대기(Bounded Waiting): O\n한개의 프로세스가 계속 새치기가 불가능하다 (데드락의 발생 여부와 무관) 결론: 유한 대기를 보장","요구사항-분석-3#요구사항 분석:":"상호 배제(Mutual Exclusion):\nflag와 turn 변수를 결합하여 두 프로세스가 동시에 임계구역에 진입하는 것을 방지합니다. 결론: 상호 배제를 보장합니다. 진행(Progress):\n한 프로세스가 임계구역을 사용하지 않을 경우, 다른 프로세스가 즉시 진입할 수 있습니다. 결론: 진행 조건을 충족합니다. 유한 대기(Bounded Waiting):\n각 프로세스는 최대 한 번의 대기만으로 임계구역에 진입할 수 있습니다. 결론: 유한 대기를 보장합니다.","요약-및-결론#요약 및 결론":"","요약-및-결론-1#\u003cstrong\u003e요약 및 결론\u003c/strong\u003e":"","요약-및-결론-2#\u003cstrong\u003e요약 및 결론\u003c/strong\u003e":"","요약-및-결론-3#\u003cstrong\u003e요약 및 결론\u003c/strong\u003e":"","요약-및-결론-4#\u003cstrong\u003e요약 및 결론\u003c/strong\u003e":"","요약-및-결론-5#\u003cstrong\u003e요약 및 결론\u003c/strong\u003e":"","요약-및-결론-6#\u003cstrong\u003e요약 및 결론\u003c/strong\u003e":"","요약-및-결론-7#\u003cstrong\u003e요약 및 결론\u003c/strong\u003e":"","요약-및-결론-8#\u003cstrong\u003e요약 및 결론\u003c/strong\u003e":"","요약-및-결론-9#\u003cstrong\u003e요약 및 결론\u003c/strong\u003e":"","원문-original-text#\u003cstrong\u003e원문 (Original Text)\u003c/strong\u003e":"Shared Buffer by Circular Array PC Buffer out in counter Shared Memory r/wr/w Empty if counter == 0 Full if counter == BS Concurrency Problem ! counter++: register1 = counter register1 = register1 + 1 counter = register1 counter--: register2 = counter register2 = register2 - 1 counter = register2 Silberschatz, Galvin and Gagne ©2009 Operating System Concepts – 8th Edition","원문-original-text-1#\u003cstrong\u003e원문 (Original Text)\u003c/strong\u003e":"Critical Section Problem ! Consider system of n processes {p0, p1, … pn-1} ! Each process has a critical section ! If one process in critical section, no other process can ! Each process must ask permission to enter critical section in entry section, may follow critical section with exit section, then remainder section ! Critical section problem is to design protocol to solve this Silberschatz, Galvin and Gagne ©2009 Operating System Concepts – 8th Edition","원문-original-text-10#\u003cstrong\u003e원문 (Original Text)\u003c/strong\u003e":"// Slide 15 Atomic instruction shared int locked = false; do { while (locked == true); locked = true; critical section locked = false; remainder section } while (true); Remove gap between TEST and SET!! while( TestAndSet( \u0026locked ) ); Returns the current value and set TRUE if FALSE // Slide 16 TestAndSet Instruction boolean TestAndSet (boolean *target) { boolean rv = *target; if( *target == FALSE ) *target = TRUE; return rv: } TestAndSet Instruction-Better boolean TestAndSet (boolean *target) { boolean rv = *target; *target = TRUE; return rv: } TRUE // Slide 17 Solution using TestAndSet ! Shared boolean variable lock, initialized to FALSE do { while ( TestAndSet (\u0026lock )); // keep testing until lock is false // critical section lock = FALSE; // remainder section } while (TRUE);","원문-original-text-2#\u003cstrong\u003e원문 (Original Text)\u003c/strong\u003e":"Critical Section ! General structure of process pi is do { entry section critical section exit section remainder section } while (true); Silberschatz, Galvin and Gagne ©2009 Operating System Concepts – 8th Edition","원문-original-text-3#\u003cstrong\u003e원문 (Original Text)\u003c/strong\u003e":"Requirements of Critical-Section Prob. 1. Mutual Exclusion - If process Pi is in its critical section, then no other processes can be executing in their critical sections 2. Progress - If no process is executing in its critical section and some processes wish to enter their critical section, then the selection of the next process cannot be postponed indefinitely 3. Bounded Waiting - A bound must exist on the number of times that other processes enter critical sections after a process has made a request to enter its critical section and before that request is granted — Assume that each process executes at a nonzero speed — No assumption concerning relative speed of the n processes Silberschatz, Galvin and Gagne ©2009 Operating System Concepts – 8th Edition","원문-original-text-4#\u003cstrong\u003e원문 (Original Text)\u003c/strong\u003e":"// Slide 5 1st: Use lock shared int locked = 0; do { while (locked == 1); locked = 1; critical section locked = 0; remainder section } while (true); ! Fails to meet ! Solution: Allow only one process to // Slide 6 (with process distinction) Process 0: shared int locked = 0; do { while (locked == 1); locked = 1; critical section locked = 0; remainder section } while (true); Process 1: shared int locked = 0; do { while (locked == 1); locked = 1; critical section locked = 0; remainder section } while (true);","원문-original-text-5#\u003cstrong\u003e원문 (Original Text)\u003c/strong\u003e":"// Slide 7 2nd: Take turns shared int turn = 0; do { while (turn != me); critical section turn = ! me; remainder section } while (true); ! Fails to meet ! Solution: Check if the other process // Slide 8 (with process distinction) Process 0: shared int turn = 0; // `me` is 0 do { while (turn == 1); // wait if it's P1's turn critical section turn = 1; // give turn to P1 remainder section } while (true); Process 1: shared int turn = 0; // `me` is 1 do { while (turn == 0); // wait if it's P0's turn critical section turn = 0; // give turn to P0 remainder section } while (true);","원문-original-text-6#\u003cstrong\u003e원문 (Original Text)\u003c/strong\u003e":"// Slide 9 3rd : Check intention shared int flag[2]; do { flag[me] = true; while (flag[!me] == true); critical section flag[me] = false; remainder section } while (true); ! Fails to meet ! Solution: check both // Slide 10 (with process distinction) Process 0: shared int flag[2]; // flag[0] for P0, flag[1] for P1 do { flag[0] = true; // \"I want to enter\" while (flag[1] == true); // Wait if P1 wants to enter critical section flag[0] = false; // \"I'm done\" remainder section } while (true); Process 1: shared int flag[2]; do { flag[1] = true; // \"I want to enter\" while (flag[0] == true); // Wait if P0 wants to enter critical section flag[1] = false; // \"I'm done\" remainder section } while (true);","원문-original-text-7#\u003cstrong\u003e원문 (Original Text)\u003c/strong\u003e":"// Slide 11 Peterson’s Solution shared int turn, flag[2]; do { flag[me] = true; turn = ! me; while (flag[!me] \u0026\u0026 turn == !me); critical section flag[me] = false; remainder section } while (true); ! Provable that 1. Mutual exclusion: 2. Progress: 3. Bounded-waiting: // Slide 12 (with process distinction) Process 0: shared int turn, flag[2]; do { flag[0] = true; turn = 1; while (flag[1] \u0026\u0026 turn == 1); critical section flag[0] = false; remainder section } while (true); Process 1: shared int turn, flag[2]; do { flag[1] = true; turn = 0; while (flag[0] \u0026\u0026 turn == 0); critical section flag[1] = false; remainder section } while (true);","원문-original-text-8#\u003cstrong\u003e원문 (Original Text)\u003c/strong\u003e":"Lessons ! Need a locking mechanism acquire lock critical section release lock ! Peterson’s algorithm still needs atomic access to shared variables ! Problem about shared variable comes from “ the interruptible gap between get value \u0026 set value operations register \u003c- register = \u003c- register “ Make these operations not interruptible, but HOW? Silberschatz, Galvin and Gagne ©2009 Operating System Concepts – 8th Edition","원문-original-text-9#\u003cstrong\u003e원문 (Original Text)\u003c/strong\u003e":"Disabling interrupts ! Uniprocessors – could disable interrupts ! Currently running code would execute without preemption ! Generally too inefficient on multiprocessor systems 4Operating systems using this not broadly scalable Silberschatz, Galvin and Gagne ©2009 Operating System Concepts – 8th Edition\n번역 (Translation)\n인터럽트 비활성화 ! 단일처리기(Uniprocessors) 시스템에서는 인터럽트를 비활성화할 수 있다. ! 현재 실행 중인 코드는 선점(preemption) 없이 실행될 것이다. ! 일반적으로 다중처리기(multiprocessor) 시스템에서는 너무 비효율적이다. 4이 방식을 사용하는 운영체제는 광범위하게 확장 가능하지 않다.","유효-무효-비트와-페이지-폴트#\u003cstrong\u003e유효-무효 비트와 페이지 폴트\u003c/strong\u003e":"슬라이드의 마지막 줄이 이 메커니즘의 핵심을 요약합니다: “주소 변환 중에, 만약 유효-무효 비트가 ‘i’이면 =\u003e 페이지 폴트 발생”\nCPU가 특정 논리 주소에 대한 접근을 요청하면, MMU의 동작은 다음과 같이 진행됩니다.\nMMU는 논리 주소에서 페이지 번호(p)를 추출합니다. MMU는 페이지 테이블의 p번째 항목에 접근합니다. MMU는 해당 항목의 유효-무효 비트를 가장 먼저 확인합니다. If 비트가 ‘v’ (valid)이면: MMU는 같은 항목에 있는 프레임 번호를 사용하여 물리 주소를 계산하고, 메모리 접근을 계속 진행합니다. 이 모든 과정은 하드웨어 내에서 매우 빠르게 처리되며, 운영 체제의 개입이 없습니다. If 비트가 ‘i’ (invalid)이면: MMU는 주소 변환을 즉시 중단합니다. 그리고 CPU에 **‘페이지 폴트(Page Fault)’**라는 이름의 트랩(trap, 하드웨어 인터럽트의 일종)을 발생시킵니다. 이 트랩은 현재 실행 중인 프로세스를 중단시키고, 운영 체제 내에 미리 정의된 페이지 폴트 핸들러(Page Fault Handler) 루틴으로 제어권을 강제로 넘깁니다. 결국 유효-무효 비트는 하드웨어(MMU)와 소프트웨어(운영 체제) 사이의 중요한 소통 채널 역할을 합니다. MMU는 이 비트를 통해 자신이 해결할 수 없는 문제(페이지가 메모리에 없음)를 감지하고, 운영 체제에게 “이 문제를 해결해달라\"고 요청하는 신호를 보내는 것입니다. 이 신호가 바로 페이지 폴트이며, 이 신호를 받은 운영 체제는 해당 페이지를 디스크에서 메모리로 가져오는 복잡한 작업을 수행하게 됩니다. 이 간단한 1비트의 존재 덕분에, ‘필요할 때만 페이지를 가져오는’ 요구 페이징의 복잡한 로직이 효율적으로 구현될 수 있는 것입니다.","유효-무효-비트의-도입#\u003cstrong\u003e유효-무효 비트의 도입\u003c/strong\u003e":"위의 설명은 모든 페이지가 항상 물리 메모리에 존재한다고 가정한 ‘순수 페이징’의 경우입니다. 하지만 요구 페이징 환경에서는 어떤 페이지는 물리 메모리에 있고, 어떤 페이지는 디스크에 있습니다. MMU는 주소 변환 과정에서 이 상태를 구분할 방법이 필요합니다. 바로 이때 유효-무효 비트가 사용됩니다.\n페이지 테이블의 각 항목(Page Table Entry, PTE)은 프레임 번호 외에 추가적인 비트들을 포함하는데, 그중 가장 중요한 것이 바로 유효-무효 비트(또는 존재 비트, present bit)입니다. 이 비트는 단 1비트로, 두 가지 상태를 나타냅니다.\n유효 (Valid, ‘v’ 또는 1로 표시): 이 비트가 ‘유효’로 설정되어 있다면, 이는 “해당 논리 페이지가 현재 물리 메모리에 존재하며, 이 페이지 테이블 항목에 있는 프레임 번호는 유효한 물리 프레임 주소다” 라는 의미입니다. 이 경우 MMU는 정상적으로 프레임 번호를 읽어서 물리 주소 변환을 완료합니다.\n무효 (Invalid, ‘i’ 또는 0으로 표시): 이 비트가 ‘무효’로 설정되어 있다면, 이는 두 가지 중 하나의 상황을 의미합니다.\n페이지가 합법적이지만, 현재 물리 메모리에 없다 (디스크에 있다): 이것이 바로 요구 페이징에서 페이지 폴트를 일으키는 주된 원인입니다. 프로세스가 접근하려는 페이지는 자신의 논리 주소 공간에 속하는 합법적인 페이지이지만, 아직 물리 메모리로 로드되지 않은 상태입니다. 페이지가 불법적이다: 프로세스가 자신의 논리 주소 공간에 할당되지도 않은 주소(예: 4GB 공간에서 5GB에 해당하는 주소)에 접근하려는 경우입니다.","임계구역-문제critical-section-problem의-요구사항과-해결책-분석#임계구역 문제(Critical Section Problem)의 요구사항과 해결책 분석":"임계구역 문제는 다중 프로세스 환경에서 공유 자원에 대한 안전한 접근을 보장하기 위해 설계된 개념입니다. 이를 해결하기 위한 세 가지 주요 요구사항은 상호 배제(Mutual Exclusion), 진행(Progress), 그리고 **유한 대기(Bounded Waiting)**입니다. 아래에서는 각 해결책이 이러한 요구사항을 충족하는지 분석하겠습니다.","자원-할당-거부-resource-allocation-denial#자원 할당 거부 (Resource Allocation Denial)":"","자원-할당-그래프-resource-allocation-graph#자원 할당 그래프 (Resource-Allocation Graph)":"원문 (Original Text):\nResource-Allocation Graph A set of vertices V and a set of edges E.  V is partitioned into two types:  P = {P1, P2, …, Pn}, the set consisting of all the processes in the system  R = {R1, R2, …, Rm}, the set consisting of all resource types in the system  request edge – directed edge Pi ® Rj  assignment edge – directed edge Rj ® Pi 번역 (Translation):\n자원 할당 그래프 정점(vertices) V의 집합과 간선(edges) E의 집합으로 구성됨.  V는 두 가지 유형으로 분할됨:  P = {P1, P2, …, Pn}, 시스템 내 모든 프로세스로 구성된 집합  R = {R1, R2, …, Rm}, 시스템 내 모든 자원 유형으로 구성된 집합  요청 간선(request edge) – 방향성 있는 간선 Pi ® Rj  할당 간선(assignment edge) – 방향성 있는 간선 Rj ® Pi 매우 자세한 설명 (Detailed Explanation):\n이 슬라이드는 시스템 내의 프로세스와 자원 간의 관계, 특히 자원의 할당 및 요청 상태를 시각적으로 표현하고 분석하기 위한 도구인 **자원 할당 그래프(Resource-Allocation Graph, RAG)**를 소개합니다. 📊 이 그래프는 교착 상태를 탐지하고 이해하는 데 매우 유용합니다.\n자원 할당 그래프의 기본 구성 요소:\n자원 할당 그래프는 수학적인 그래프 이론에 기반하며, 정점(Vertices, V)의 집합과 간선(Edges, E)의 집합으로 정의됩니다.\n정점의 집합 (V, Vertices): 정점 V는 다시 두 가지 하위 유형의 집합으로 나뉩니다.\n프로세스 집합 (P = {P1​,P2​,…,Pn​}):\n시스템에서 현재 실행 중이거나 자원을 요청/보유하고 있는 모든 프로세스들을 나타냅니다. 그래프에서는 보통 원(Circle)으로 표현됩니다. 각 원 안에는 해당 프로세스의 식별자(예: P1​,P2​)가 표시됩니다. n은 시스템 내 총 프로세스의 수를 의미합니다. 자원 유형 집합 (R = {R1​,R2​,…,Rm​}):\n시스템에 존재하는 모든 자원 유형들을 나타냅니다. CPU, 메모리, 디스크 드라이브, 프린터 등이 이에 해당합니다. 그래프에서는 보통 사각형(Rectangle)으로 표현됩니다. 각 사각형 안에는 해당 자원 유형의 식별자(예: R1​,R2​)가 표시됩니다. m은 시스템 내 총 자원 유형의 수를 의미합니다. 각 자원 유형 Rj​는 여러 개의 인스턴스(instance)를 가질 수 있으며, 이는 사각형 내에 점(dot)으로 표현됩니다. 예를 들어, 자원 유형 Rj​가 4개의 인스턴스를 가지고 있다면, 사각형 Rj​ 안에 4개의 점이 그려집니다. 간선의 집합 (E, Edges): 간선 E는 프로세스와 자원 유형 사이의 관계를 나타내는 방향성 있는(directed) 연결선입니다. 간선은 두 가지 종류가 있습니다.\n요청 간선 (Request Edge): Pi​→Rj​\n프로세스 Pi​가 자원 유형 Rj​의 인스턴스를 요청했으나 아직 할당받지 못한 상태임을 나타냅니다. 화살표는 프로세스 Pi​에서 시작하여 자원 유형 Rj​를 향합니다. 이는 “프로세스 Pi​가 자원 Rj​를 기다리고 있다\"는 의미입니다. 예를 들어, 프로세스 P1​이 프린터 RP​를 사용하기 위해 요청했지만 아직 사용할 수 없는 경우, P1​→RP​ 와 같이 표현됩니다. 할당 간선 (Assignment Edge): Rj​→Pi​\n자원 유형 Rj​의 인스턴스 하나가 프로세스 Pi​에게 이미 할당되어 사용 중임을 나타냅니다. 화살표는 자원 유형 Rj​의 특정 인스턴스(점)에서 시작하여 프로세스 Pi​를 향합니다. (보다 정확히는 자원 유형의 사각형에서 인스턴스를 나타내는 점에서 나와 프로세스로 향하거나, 자원 유형의 사각형에서 프로세스로 향하고 해당 자원 유형에 인스턴스가 여러 개일 경우 어떤 인스턴스가 할당되었는지 명시될 수 있습니다. 텍스트에서는 Rj​→Pi​로 일반화하여 표현) 이는 “프로세스 Pi​가 자원 Rj​의 인스턴스를 점유하고 있다\"는 의미입니다. 예를 들어, 프로세스 P2​가 디스크 드라이브 RD​의 한 인스턴스를 할당받아 사용 중인 경우, RD​→P2​ 와 같이 표현됩니다. 만약 RD​에 여러 인스턴스가 있다면, 그중 하나가 P2​에게 할당된 것을 의미합니다. 자원 할당 그래프의 중요성:\n상태 시각화: 현재 시스템의 자원 할당 상태와 프로세스들의 대기 관계를 한눈에 파악할 수 있게 해줍니다. 교착 상태 분석: 그래프 내에 **사이클(cycle)**이 존재하는지 여부를 통해 교착 상태 발생 가능성 또는 실제 발생 여부를 판단하는 데 중요한 단서를 제공합니다. 만약 그래프에 사이클이 없다면, 시스템은 교착 상태가 아닙니다. 만약 그래프에 사이클이 존재한다면: 각 자원 유형이 단 하나의 인스턴스만 가지고 있다면, 교착 상태가 반드시 존재합니다. 자원 유형별로 여러 인스턴스가 존재한다면, 사이클의 존재는 교착 상태의 가능성을 의미하지만, 반드시 교착 상태인 것은 아닙니다. 추가적인 분석이 필요합니다. 이처럼 자원 할당 그래프는 복잡한 프로세스와 자원 간의 상호작용을 추상화하고 모델링하여 교착 상태라는 어려운 문제를 체계적으로 접근할 수 있도록 돕는 강력한 도구입니다. 다음 슬라이드들에서는 이 그래프의 구체적인 표현 방식과 예를 통해 교착 상태를 어떻게 식별하는지 더 자세히 보여줄 것입니다.","자원-할당-그래프-계속-resource-allocation-graph-cont#자원 할당 그래프 (계속) (Resource-Allocation Graph (Cont.))":"원문 (Original Text):\nResource-Allocation Graph (Cont.)  Process  Resource Type with 4 instances  Pi requests instance of Rj  Pi is holding an instance of Rj (이 슬라이드는 시각적 표현에 대한 설명으로 보이며, 실제 이미지가 없으므로 텍스트 설명을 기반으로 재구성합니다.)\n번역 (Translation):\n자원 할당 그래프 (계속)  프로세스  4개의 인스턴스를 가진 자원 유형  Pi가 Rj의 인스턴스를 요청함  Pi가 Rj의 인스턴스를 보유 중임 매우 자세한 설명 (Detailed Explanation):\n이 슬라이드는 자원 할당 그래프(RAG)를 구성하는 주요 시각적 요소들을 구체적으로 설명하여, 그래프를 어떻게 그리고 해석하는지에 대한 이해를 돕습니다. 🖼️ 앞서 설명된 정점과 간선의 개념을 실제 그래프에서 어떻게 표현하는지 보여줍니다.\n1. 프로세스 (Process):\n표현: 자원 할당 그래프에서 프로세스는 일반적으로 **원(Circle)**으로 표시됩니다.\n표기: 원 내부에는 해당 프로세스를 식별하는 이름(예: Pi​,P1​,Pserver​ 등)이 들어갑니다.\n[도형 예시]코드 스니펫\ngraph LR P1((P1)) 위와 같이 P1이라는 프로세스를 원으로 표현합니다.\n2. 4개의 인스턴스를 가진 자원 유형 (Resource Type with 4 instances):\n표현: 자원 유형은 일반적으로 **사각형(Rectangle)**으로 표시됩니다.\n인스턴스 표현: 사각형 내부에는 해당 자원 유형에 속하는 **인스턴스(instance)**들을 나타내는 **점(dot)**들이 그려집니다. 이 슬라이드의 예시에서는 4개의 인스턴스를 가지므로, 사각형 내부에 4개의 점이 있게 됩니다.\n표기: 사각형 내부 또는 근처에는 해당 자원 유형의 이름(예: Rj​,Rdisk​,Rprinter​ 등)이 표시됩니다.\n[도형 예시]코드 스니펫\ngraph LR subgraph Rj [Resource Rj] direction LR i1(.) i2(.) i3(.) i4(.) end 위와 같이 Rj​라는 자원 유형을 사각형으로 표현하고, 내부에 4개의 점으로 인스턴스를 나타냅니다.\n3. Pi​가 Rj​의 인스턴스를 요청함 (Pi​ requests instance of Rj​):\n유형: 요청 간선 (Request Edge)\n표현: 프로세스 Pi​에서 자원 유형 Rj​의 사각형을 향하는 **화살표(directed edge)**로 표시됩니다.\n의미: 프로세스 Pi​가 자원 유형 Rj​의 인스턴스 중 하나를 필요로 하며, 현재 할당받기를 기다리고 있음을 의미합니다. 아직 어떤 특정 인스턴스를 요청하는지는 이 간선만으로는 명시되지 않으며, Rj​ 유형의 가용한 인스턴스 중 하나를 기다리는 것입니다.\n[그래프 예시]코드 스니펫\ngraph TD Pi((Pi)) subgraph Rj [Resource Rj] direction LR rj_i1(.) rj_i2(.) end Pi --\u003e Rj 프로세스 Pi​가 자원 유형 Rj​를 요청하는 상황을 나타냅니다. 화살표는 Pi​에서 Rj​로 향합니다.\n4. Pi​가 Rj​의 인스턴스를 보유 중임 (Pi​ is holding an instance of Rj​):\n유형: 할당 간선 (Assignment Edge)\n표현: 자원 유형 Rj​의 사각형 내부에 있는 특정 인스턴스(점)에서 시작하여 프로세스 Pi​를 향하는 **화살표(directed edge)**로 표시됩니다.\n의미: 자원 유형 Rj​의 특정 인스턴스가 프로세스 Pi​에게 할당되어 Pi​가 그 자원을 현재 사용 또는 점유하고 있음을 의미합니다.\n[그래프 예시]코드 스니펫\ngraph TD Pi((Pi)) subgraph Rj [Resource Rj] direction LR rj_i1(.) --- P_holds_instance --\u003e Pi rj_i2(.) end 자원 유형 Rj​의 인스턴스 중 하나(여기서는 첫 번째 점으로 가정)가 프로세스 Pi​에게 할당된 상황을 나타냅니다. 화살표는 Rj​의 인스턴스에서 Pi​로 향합니다.\n종합적인 예시:\n만약 프로세스 P1​이 자원 R1​(인스턴스 1개)을 점유하고 있으면서, 자원 R2​(인스턴스 2개) 중 하나를 요청하고 있다고 가정해 봅시다. 그리고 프로세스 P2​는 자원 R2​의 인스턴스 중 하나를 점유하고 있다고 가정합니다.\n이를 자원 할당 그래프로 표현하면 다음과 같습니다.\n코드 스니펫\ngraph TD P1((P1)) P2((P2)) subgraph R1 [Resource R1] direction LR r1_i1(.) end subgraph R2 [Resource R2] direction LR r2_i1(.) r2_i2(.) end r1_i1 --\u003e P1 // P1이 R1의 인스턴스를 보유 (Assignment Edge) P1 --\u003e R2 // P1이 R2의 인스턴스를 요청 (Request Edge) r2_i1 --\u003e P2 // P2가 R2의 인스턴스 중 하나를 보유 (Assignment Edge) 이처럼 자원 할당 그래프의 시각적 요소를 정확히 이해하면, 시스템의 현재 자원 상태를 명확하게 그림으로 나타낼 수 있습니다. 이 그림을 통해 복잡한 자원 요청 및 할당 관계를 분석하고, 특히 순환적인 대기 관계(사이클)가 형성되는지 여부를 직관적으로 파악하여 교착 상태의 존재 가능성을 진단할 수 있습니다. 예를 들어, 위 예시에서는 아직 명확한 사이클이 보이지 않지만, 만약 P2​가 R1​을 추가로 요청한다면 (P2​→R1​), P1​→R2​←(instance of R2​)←P2​→R1​←(instance of R1​)←P1​ 형태의 사이클이 형성되어 교착 상태가 발생할 수 있음을 시각적으로 확인할 수 있게 됩니다. 이러한 시각화는 교착 상태의 개념을 더욱 명확하게 이해하고, 관련 알고리즘(탐지, 회피 등)의 작동 방식을 파악하는 데 큰 도움이 됩니다.","자원-할당-그래프의-예-example-of-a-resource-allocation-graph#자원 할당 그래프의 예 (Example of a Resource Allocation Graph)":"원문 (Original Text):\nExample of a Resource Allocation Graph (이 슬라이드는 제목만 있고 실제 그래프 이미지가 없으므로, 일반적인 자원 할당 그래프의 예시를 구성하여 설명합니다.)\n번역 (Translation):\n자원 할당 그래프의 예 매우 자세한 설명 (Detailed Explanation):\n이 슬라이드는 자원 할당 그래프(RAG)가 실제로 어떻게 구성되고 해석될 수 있는지 구체적인 예시를 통해 보여주는 것을 목표로 합니다. 실제 이미지가 제공되지 않았으므로, 교착 상태가 없는 일반적인 상황과 교착 상태가 발생할 수 있는 상황을 포함하는 가상의 예시를 통해 설명하겠습니다. 📝\n가상 예시 시나리오:\n시스템에 다음과 같은 프로세스와 자원이 있다고 가정합니다.\n프로세스: P1​,P2​,P3​ 자원 유형: R1: 인스턴스 1개 (예: 프린터) R2: 인스턴스 2개 (예: 디스크 드라이브) R3: 인스턴스 3개 (예: 메모리 블록) 상황 1: 교착 상태가 없는 경우\nP1​은 R1​의 인스턴스를 보유하고 있으며, R2​의 인스턴스 하나를 요청 중입니다. P2​는 R2​의 인스턴스 하나를 보유하고 있으며, R3​의 인스턴스 하나를 요청 중입니다. P3​는 R2​의 다른 인스턴스 하나를 보유하고 있으며, R3​의 인스턴스 하나를 보유 중입니다. (여기서 P3​는 현재 추가 요청 없이 자원을 사용하고 있다고 가정) 자원 할당 그래프 표현 (상황 1):\n코드 스니펫\ngraph TD P1((P1)) P2((P2)) P3((P3)) subgraph R1 [R1 (1 instance)] r1_i1(.) end subgraph R2 [R2 (2 instances)] r2_i1(.) r2_i2(.) end subgraph R3 [R3 (3 instances)] r3_i1(.) r3_i2(.) r3_i3(.) end r1_i1 --\u003e P1 // P1 holds R1 P1 --\u003e R2 // P1 requests R2 r2_i1 --\u003e P2 // P2 holds an instance of R2 P2 --\u003e R3 // P2 requests R3 r2_i2 --\u003e P3 // P3 holds another instance of R2 r3_i1 --\u003e P3 // P3 holds an instance of R3 분석 (상황 1):\n프로세스 P1: R1​을 점유하고 R2​를 기다립니다. R2​에는 P2​와 P3​가 각각 하나씩 점유하고 있으므로 현재 가용 인스턴스가 없습니다. P1​은 대기 상태입니다. 프로세스 P2: R2​의 인스턴스 하나를 점유하고 R3​를 기다립니다. R3​는 P3​가 하나 점유하고 있지만, 2개의 가용 인스턴스(r3​_i2,r3​_i3)가 남아 있습니다. 따라서 P2​는 R3​의 인스턴스를 곧 할당받아 작업을 계속 진행할 수 있습니다. 프로세스 P3: R2​의 인스턴스와 R3​의 인스턴스를 점유하고 있으며, 추가 요청이 없습니다. P3​는 작업을 진행하다가 자원을 방출할 것입니다. 사이클 존재 여부: 위 그래프에는 사이클(cycle)이 존재하지 않습니다.\nP1​→R2​←P2​→R3​←P3​ 와 같은 경로는 있지만, 닫힌 순환 고리를 형성하지 않습니다. P2​가 R3​를 할당받고 작업을 완료하면, P2​는 R2​의 인스턴스를 방출할 것입니다. 이 방출된 R2​ 인스턴스를 P1​이 할당받을 수 있게 되어 P1​도 진행할 수 있습니다. 따라서 이 시스템은 현재 교착 상태가 아닙니다. 상황 2: 교착 상태가 발생할 수 있는 변경 (가상)\n만약 상황 1에서 P3​가 R3​를 점유한 상태에서, 추가로 R1​을 요청한다고 가정해봅시다. (P1​은 이미 R1​을 점유하고 있습니다). 그리고 P2​도 R3​를 할당받지 못하고 대기 중이라고 가정합니다 (예를 들어 R3​의 가용 인스턴스가 없다고 가정하거나, P3​가 P2​보다 먼저 R3​의 남은 인스턴스를 모두 점유하고 있다고 가정).\nP1​은 R1​을 보유, R2​를 요청. P2​는 R2​의 인스턴스 하나를 보유, R1​을 요청 (원래 R3​ 요청에서 변경). (이 예시는 슬라이드 7의 “Resource Allocation Graph With A Deadlock\"과 유사하게 만들기 위해 변경) 자원 할당 그래프 표현 (수정된 상황 - 잠재적 교착):\n이 상황은 다음 슬라이드인 “Resource Allocation Graph With A Deadlock\"에서 더 명확하게 다루어질 것이므로, 여기서는 기본적인 그래프 요소들이 어떻게 상호작용하여 복잡한 상태를 나타낼 수 있는지에 초점을 맞춥니다.\n일반적인 자원 할당 그래프를 통해 알 수 있는 정보:\n자원 점유 상태: 어떤 프로세스가 어떤 자원의 인스턴스를 점유하고 있는지 (Rj​→Pi​ 형태의 할당 간선). 자원 요청 상태: 어떤 프로세스가 어떤 자원 유형의 인스턴스를 기다리고 있는지 (Pi​→Rj​ 형태의 요청 간선). 자원 가용성: 각 자원 유형별로 할당되지 않은 인스턴스가 몇 개 있는지 (사각형 내의 할당되지 않은 점의 개수). 프로세스 대기 여부: 요청 간선이 있는 프로세스는 대기 상태일 가능성이 높습니다 (특히 요청한 자원의 가용 인스턴스가 없을 경우). 잠재적 문제 영역 식별: 특정 자원에 대해 많은 요청 간선이 몰려있거나, 여러 프로세스가 서로의 자원을 기다리는 듯한 패턴이 보이면 교착 상태의 위험을 의심해볼 수 있습니다. 자원 할 deputado 그래프는 시스템의 스냅샷(snapshot)입니다. 시간이 지남에 따라 프로세스가 자원을 요청하고, 할당받고, 방출함에 따라 그래프의 구조는 동적으로 변합니다. 운영체제는 이러한 그래프의 변화를 추적하거나 주기적으로 분석함으로써 교착 상태를 관리할 수 있습니다. 이 예시 슬라이드는 그러한 분석의 기초가 되는 그래프 자체의 구성 방식을 이해시키는 데 목적이 있다고 볼 수 있습니다.","자주-조합되는-패턴#자주 조합되는 패턴":"","점유와-대기-조건-공략-attacking-the-hold-and-wait-condition#점유와 대기 조건 공략 (Attacking the Hold and Wait Condition)":"원문 (Original Text):\nAttacking the Hold and Wait Condition  Require processes to request resources before starting  a process never has to wait for what it needs  Problems  may not know required resources at start of run  may wait for long to acquire all resources  ties up resources other processes could be using  Variation: before requesting a new resource,  process must give up all resources  then request all immediately needed 번역 (Translation):\n점유와 대기 조건 공략  프로세스가 시작하기 전에 자원을 요청하도록 요구  프로세스는 필요한 것을 기다릴 필요가 없음  문제점  실행 시작 시 필요한 자원을 알지 못할 수 있음  모든 자원을 획득하기 위해 오랫동안 기다릴 수 있음  다른 프로세스가 사용할 수 있는 자원을 묶어둠  변형: 새로운 자원을 요청하기 전에,  프로세스는 모든 자원을 포기해야 함  그런 다음 즉시 필요한 모든 자원을 요청함 매우 자세한 설명 (Detailed Explanation):\n이 슬라이드는 교착 상태 예방 전략 중 하나로, 점유와 대기(Hold and Wait) 조건을 무효화하는 방법에 대해 설명합니다. 🚫⏳ 점유와 대기 조건은 “프로세스가 최소한 하나의 자원을 보유(점유)한 상태에서, 다른 프로세스가 보유한 추가 자원을 얻기 위해 대기\"하는 상황을 의미합니다. 이 조건을 깨뜨리면 교착 상태의 가능성을 줄일 수 있습니다.\n점유와 대기 조건 공략 방법:\n방법 1: 실행 전 모든 자원 일괄 요청 (Require processes to request resources before starting)\n개념: 프로세스가 실행을 시작하기 전에, 해당 실행 과정에서 필요할 것으로 예상되는 모든 자원을 한꺼번에 요청하고 할당받도록 하는 방식입니다.\n작동 방식:\n프로세스는 운영체제에 자신이 필요한 모든 자원의 목록을 제출합니다. 운영체제는 이 요청된 모든 자원을 동시에 할당해 줄 수 있을 때까지 프로세스의 시작을 보류합니다. 모든 자원이 할당 가능해지면, 프로세스에게 일괄적으로 할당하고 실행을 시작시킵니다. 일단 실행이 시작된 프로세스는 자신이 요청한 모든 자원을 이미 확보한 상태이므로, 실행 도중 다른 자원을 얻기 위해 기다릴 필요가 없습니다. (“a process never has to wait for what it needs” - 엄밀히 말하면, 실행 _시작 후_에는 자원을 기다릴 필요가 없다는 의미) 점유와 대기 조건 파괴: 이 방식에서는 프로세스가 자원을 점유한 상태에서 추가적인 자원을 기다리는 상황이 발생하지 않습니다. 실행 시작 시점에 필요한 모든 자원을 갖거나, 아예 아무것도 갖지 못하고 대기하기 때문입니다. 즉, ‘점유’와 ‘대기’가 동시에 발생하지 않습니다.\n문제점 (Problems):\n“may not know required resources at start of run” (실행 시작 시 필요한 자원을 알지 못할 수 있음): 많은 프로그램은 실행 과정에서의 입력값이나 중간 결과에 따라 필요한 자원이 동적으로 결정됩니다. 예를 들어, 사용자가 어떤 파일을 열지, 어떤 연산을 수행할지에 따라 필요한 메모리 양이나 특정 장치가 달라질 수 있습니다. 따라서 실행 전에 모든 필요 자원을 정확히 예측하는 것은 매우 어렵거나 불가능할 수 있습니다. 최악의 경우를 가정하여 과도하게 많은 자원을 요청하게 될 수도 있습니다. “may wait for long to acquire all resources” (모든 자원을 획득하기 위해 오랫동안 기다릴 수 있음): 프로세스가 요청한 모든 자원이 동시에 가용 상태가 될 때까지 프로세스는 실행되지 못하고 계속 기다려야 합니다. 만약 요청한 자원 중 하나라도 매우 희귀하거나 다른 프로세스에 의해 오랫동안 점유되어 있다면, 해당 프로세스는 매우 긴 시간 동안 시작조차 못 할 수 있습니다 (기아 상태 발생 가능). “ties up resources other processes could be using” (다른 프로세스가 사용할 수 있는 자원을 묶어둠): 프로세스가 실행 초기에 모든 자원을 할당받지만, 그중 일부는 실행 후반부에나 사용될 수 있습니다. 이렇게 되면 당장 사용되지 않는 자원들이 해당 프로세스에 의해 불필요하게 점유되어, 그 자원을 필요로 하는 다른 프로세스들이 사용하지 못하게 됩니다. 이는 자원 활용률(resource utilization)을 심각하게 저하시키는 주요 원인이 됩니다. 예를 들어, 긴 작업을 수행하는 프로세스가 처음에는 입력 파일만 읽고 마지막에 프린터를 사용하는데, 시작 시점에 프린터까지 할당받아 계속 점유하고 있다면 다른 프로세스들은 그동안 프린터를 전혀 사용할 수 없습니다. 방법 2: 변형 - 기존 자원 포기 후 일괄 재요청 (Variation: before requesting a new resource, process must give up all resources, then request all immediately needed)\n개념: 프로세스가 실행 도중 새로운 자원을 추가로 요청해야 할 경우, 기존에 점유하고 있던 모든 자원을 일단 **모두 반납(release)**하고, 그 후에 필요한 모든 자원(새로운 자원 + 이전에 점유했던 자원 중 계속 필요한 것)을 한꺼번에 다시 요청하는 방식입니다.\n작동 방식:\n프로세스가 자원 A, B를 점유하고 실행 중입니다. 이제 자원 C가 추가로 필요하게 되었습니다. 프로세스는 자원 A와 B를 모두 운영체제에 반납합니다. 그런 다음, 자원 A, B, C를 한꺼번에 다시 요청합니다. 운영체제는 A, B, C를 모두 할당해 줄 수 있을 때까지 프로세스를 대기시킵니다. 점유와 대기 조건 파괴: 이 방식 역시 프로세스가 어떤 자원을 점유한 상태에서 다른 자원을 기다리는 것을 방지합니다. 자원을 요청할 때는 아무것도 점유하지 않은 상태이기 때문입니다.\n문제점:\n비효율성: 자원을 반납했다가 다시 요청하고 할당받는 과정에서 상당한 오버헤드가 발생할 수 있습니다. 기아 상태 가능성: 한번 반납한 자원을 다시 할당받지 못할 위험이 있습니다. 특히 사용 빈도가 높은 자원의 경우, 다른 프로세스에게 계속 할당되어 오랫동안 필요한 자원들을 다시 모으지 못할 수 있습니다. 작업 연속성 문제: 예를 들어, 파일에 데이터를 쓰고 있는 도중에 다른 자원이 필요해서 파일을 닫고(반납) 나중에 다시 열어서 이어 쓰려고 할 때, 그 사이에 다른 프로세스가 파일 내용을 변경할 수도 있는 등 작업의 원자성(atomicity)이나 일관성을 유지하기 어려울 수 있습니다. 결론:\n점유와 대기 조건을 깨는 것은 교착 상태를 예방하는 한 가지 방법이지만, 제시된 두 가지 방법 모두 심각한 단점을 가지고 있습니다. 특히 자원 활용률 저하와 기아 상태 발생 가능성은 이 접근법의 실용성을 크게 떨어뜨립니다. 이 때문에 점유와 대기 조건의 파괴는 교착 상태 예방을 위한 보편적인 해결책으로 사용되기보다는, 매우 제한적인 환경이나 특수한 경우에 고려될 수 있습니다. 대부분의 현대 운영체제는 이 방법을 엄격하게 적용하지 않고, 다른 교착 상태 처리 기법(예: 회피, 탐지 및 회복)을 선호하거나, 환형 대기 조건 공략과 같은 좀 더 유연한 예방책을 사용합니다.","정의#\u003cstrong\u003e정의\u003c/strong\u003e:":"","정의-1#\u003cstrong\u003e정의\u003c/strong\u003e:":"","정의-2#\u003cstrong\u003e정의\u003c/strong\u003e:":"","정의-3#\u003cstrong\u003e정의\u003c/strong\u003e:":"","정의-4#\u003cstrong\u003e정의\u003c/strong\u003e:":"","정의-5#\u003cstrong\u003e정의\u003c/strong\u003e:":"","종류-및-특징#\u003cstrong\u003e종류 및 특징\u003c/strong\u003e:":"","종류-및-특징-1#\u003cstrong\u003e종류 및 특징\u003c/strong\u003e:":"","종류-및-특징-2#\u003cstrong\u003e종류 및 특징\u003c/strong\u003e:":"","최적-알고리즘의-교체-전략-미래-예측#\u003cstrong\u003e최적 알고리즘의 교체 전략: 미래 예측\u003c/strong\u003e":"최적 알고리즘의 핵심 전략은 매우 명확하고 강력합니다. 페이지 폴트가 발생하여 희생 페이지를 선택해야 할 때, “현재 메모리에 있는 페이지들 중에서, 앞으로 가장 오랜 기간 동안 다시 참조되지 않을 페이지를 선택하여 교체한다.”\n좀 더 풀어서 설명하면 다음과 같습니다.\n페이지 폴트 발생 시, 현재 물리 메모리에 있는 모든 페이지들을 살펴봅니다. 각 페이지에 대해, 해당 페이지가 미래의 어느 시점에 다시 참조될지를 예측합니다. (정확히는 프로그램의 이후 실행될 명령어 순서, 즉 참조 문자열(reference string)을 미리 알고 있다고 가정합니다.) 이 “미래 참조 시점\"이 가장 멀리 있는 페이지를 희생양으로 선택합니다. 만약 어떤 페이지가 미래에 다시는 참조되지 않는다면, 그 페이지가 최우선적인 교체 대상이 됩니다. 만약 여러 페이지가 미래에 다시는 참조되지 않거나, 혹은 가장 먼 미래 참조 시점이 동일한 페이지가 여러 개 있다면, 그중 아무것이나 선택해도 무방합니다 (보통은 임의로 또는 FIFO 방식으로 선택). 이러한 전략을 사용하면, 가까운 미래에 다시 사용될 페이지는 최대한 메모리에 유지시키고, 당분간 사용되지 않거나 아예 사용되지 않을 페이지만을 골라서 내보내기 때문에, 결과적으로 가장 적은 수의 페이지 폴트를 발생시킵니다. 이것이 바로 최적 알고리즘이 “최적\"이라고 불리는 이유입니다. 주어진 참조 문자열과 고정된 수의 프레임에 대해, 최적 알고리즘보다 더 적은 페이지 폴트를 발생시키는 알고리즘은 존재할 수 없습니다.","최적-알고리즘의-용도-성능-측정의-기준-benchmark#\u003cstrong\u003e최적 알고리즘의 용도: 성능 측정의 기준 (Benchmark)\u003c/strong\u003e":"그렇다면 구현도 불가능한 이 알고리즘을 왜 배우고 언급하는 것일까요? 슬라이드의 마지막 줄이 그 답을 제시합니다. “여러분의 알고리즘이 얼마나 잘 수행되는지 측정하는 데 사용됨 (Used for measuring how well your algorithm performs)”\n최적 알고리즘은 실제 시스템에서 사용하기 위한 것이 아니라, 다른 현실적인 페이지 교체 알고리즘(예: FIFO, LRU 등)의 성능을 평가하고 비교하기 위한 이론적인 기준점 또는 상한선(upper bound) 역할을 합니다.\n구체적으로는 다음과 같이 활용됩니다.\n특정 참조 문자열 수집: 실제 프로그램 실행 중 발생하는 페이지 참조 순서(참조 문자열)를 기록하거나, 시뮬레이션을 위한 가상의 참조 문자열을 생성합니다. 최적 알고리즘 시뮬레이션: 수집된 참조 문자열과 특정 프레임 수에 대해 최적 알고리즘을 적용했을 때 발생하는 페이지 폴트 수를 계산합니다. 이는 해당 조건에서 달성 가능한 최소 페이지 폴트 수가 됩니다. 다른 알고리즘 시뮬레이션 및 비교: 동일한 참조 문자열과 프레임 수에 대해 우리가 실제로 구현하고자 하는 다른 페이지 교체 알고리즘(예: LRU, FIFO)을 적용하여 각각의 페이지 폴트 수를 계산합니다. 성능 평가: 이 결과를 최적 알고리즘의 결과와 비교합니다. 예를 들어, 최적 알고리즘이 10번의 폴트를 발생시켰고, LRU 알고리즘이 12번, FIFO 알고리즘이 15번의 폴트를 발생시켰다면, LRU가 FIFO보다 최적에 더 가깝고 따라서 더 효율적인 알고리즘이라고 평가할 수 있습니다. 이러한 방식으로, 연구자나 시스템 개발자들은 자신들이 고안한 새로운 페이지 교체 알고리즘이 얼마나 이상적인 성능에 근접하는지를 정량적으로 파악할 수 있습니다. 최적 알고리즘은 도달할 수 없는 별과 같지만, 다른 모든 알고리즘이 나아가야 할 방향을 제시해 주는 등대와 같은 역할을 하는 것입니다.\n결론적으로 최적 페이지 교체 알고리즘은 그 자체로는 실용적인 구현체가 아니지만, 페이지 교체 연구 및 개발 분야에서 매우 중요한 이론적 도구입니다. 이는 “만약 우리가 미래를 알 수 있다면 얼마나 잘할 수 있을까?“라는 질문에 대한 답을 제공하며, 현실적인 알고리즘들이 얼마나 그 이상에 가까워지려고 노력하는지를 가늠하는 척도가 됩니다.","최적-페이지-교체-알고리즘-실행-과정-3-프레임#\u003cstrong\u003e최적 페이지 교체 알고리즘 실행 과정 (3 프레임)\u003c/strong\u003e":"각 단계에서 참조되는 페이지, 현재 프레임 상태, 페이지 폴트 발생 여부(H: Hit, F: Fault), 그리고 교체가 발생할 경우 어떤 페이지가 선택되는지를 살펴보겠습니다.\n참조 페이지 프레임 1 프레임 2 프레임 3 결과 (PF 수) 교체 대상 (미래 참조 순서) 7 7 F (1) (빈 프레임 사용) 0 7 0 F (2) (빈 프레임 사용) 1 7 0 1 F (3) (빈 프레임 사용) 2 2 0 1 F (4) 7 교체 (7-\u003e17번째, 0-\u003e5번째, 1-\u003e14번째) 0 2 0 1 H 3 3 0 1 F (5) 2 교체 (2-\u003e9번째, 0-\u003e7번째, 1-\u003e14번째) 0 3 0 1 H 4 4 0 1 F (6) 3 교체 (3-\u003e10번째, 0-\u003e11번째, 1-\u003e14번째) 2 2 0 1 F (7) 4 교체 (4-\u003e없음, 0-\u003e11번째, 1-\u003e14번째) 3 2 0 3 F (8) 1 교체 (1-\u003e14번째, 0-\u003e11번째, 2-\u003e13번째) 0 2 0 3 H 3 2 0 3 H 2 2 0 3 H 1 1 0 3 F (9) 2 교체 (2-\u003e15번째, 0-\u003e16번째, 3-\u003e없음) 2 1 0 2 F (10) 3 교체 (3-\u003e없음, 0-\u003e16번째, 1-\u003e17번째) 0 1 0 2 H 1 1 0 2 H 7 7 0 2 F (11) 1 교체 (1-\u003e20번째, 0-\u003e19번째, 2-\u003e없음) 0 7 0 2 H 1 7 0 1 F (12) 2 교체 (2-\u003e없음, 0-\u003e없음, 7-\u003e없음. 임의로 가장 오래된 2) 최종 페이지 폴트 수: 12회 (위 예시에서 마지막 교체 대상 선정에 약간의 모호함이 있을 수 있으나, 일반적인 OPT 규칙을 따름)\n실제 정확한 OPT 폴트 수는 참조열과 프레임 수에 따라, 그리고 타이 브레이킹 규칙에 따라 약간 달라질 수 있습니다. 위는 일반적인 과정을 보여주기 위한 예시입니다. 더 표준적인 예제(예: 7,0,1,2,0,3,0,4,2,3,0,3,2,1,2,0,1,7,0,1, 3프레임 시 9회 폴트가 나오는 경우)를 기준으로 설명하자면:\n표준 예시 (3 프레임, 참조열: 7,0,1,2,0,3,0,4,2,3,0,3,2,1,2,0,1,7,0,1)\n7: [7, _, _] (Fault: 1) 0: [7, 0, _]\\ (Fault: 2) 1: [7, 0, 1] (Fault: 3) 2: 참조 문자열에서 7은 18번째, 0은 5번째, 1은 14번째에 다시 나타남. 가장 먼 7을 교체. [2, 0, 1] (Fault: 4) 0: [2, 0, 1] (Hit) 3: 2는 9번째, 0은 7번째, 1은 14번째. 가장 먼 1을 교체. [2, 0, 3] (Fault: 5) 0: [2, 0, 3] (Hit) 4: 2는 9번째, 0은 11번째, 3은 10번째. 가장 먼 0을 교체 (또는 2, 3도 가능. 이후 참조가 없는 페이지가 있다면 우선). 미래 2,0,3 중 가장 먼 것은 0 (11번째), 2(9번째), 3(10번째) 입니다. 하지만 다음 참조 2,3,0,3,2,1,2,0,1,7,0,1 을 보면 페이지 4가 들어올때, 프레임 안의 [2,0,3] 중에서는 페이지 2는 다음 2에서, 페이지 0은 다음 0에서, 페이지 3은 다음 3에서 사용됩니다. 이 경우 0이 7번째 0에, 2가 9번째 2에, 3이 10번째 3에 있습니다. 가장 늦게 사용될 페이지는 3. (만약 다음 참조가 더 없다면 아무거나) 여기서 교체할 페이지는 미래 참조를 기반으로 결정됩니다. 2는 바로 다음 2, 0은 그 다음 0, 3은 그 다음 3. 페이지 0, 2, 3중 가장 나중에 참조되는 페이지를 교체한다. 페이지 4가 참조되면, 현재 [2,0,3]. 2의 다음참조는 9번째, 0의 다음참조는 11번째, 3의 다음참조는 10번째. 따라서 가장 나중인 0을 교체한다. [2, 4, 3] (Fault: 6) (0을 교체) 2: [2, 4, 3] (Hit) 3: [2, 4, 3] (Hit) 0: 2는 13번째, 4는 없음, 3은 12번째. 4를 교체. [2, 0, 3] (Fault: 7) 3: [2, 0, 3] (Hit) 2: [2, 0, 3] (Hit) 1: 2는 15번째, 0은 16번째, 3은 없음. 3을 교체. [2, 0, 1] (Fault: 8) 2: [2, 0, 1] (Hit) 0: [2, 0, 1] (Hit) 1: [2, 0, 1] (Hit) 7: 2는 없음, 0은 19번째, 1은 20번째. 2를 교체. [7, 0, 1] (Fault: 9) 0: [7, 0, 1] (Hit) 1: [7, 0, 1] (Hit) 최종 페이지 폴트 (표준 예시): 9회","코드#코드:":"shared int locked = 0; // Process 0 do { while (locked == 1); // 다른 프로세스가 임계구역을 사용 중인지 확인 locked = 1; // 잠금 설정 critical section // 임계구역 실행 locked = 0; // 잠금 해제 remainder section // 나머지 코드 실행 } while (true); // Process 1 do { while (locked == 1); locked = 1; critical section locked = 0; remainder section } while (true);","코드-1#코드:":"shared int turn = 0; // Process 0 do { while (turn != 0); // 자신의 차례인지 확인 critical section // 임계구역 실행 turn = 1; // 턴을 상대 프로세스에게 넘김 remainder section // 나머지 코드 실행 } while (true); // Process 1 do { while (turn != 1); critical section turn = 0; remainder section } while (true);","코드-2#코드:":"shared int flag[2] = {false, false}; // Process 0 do { flag[0] = true; // 임계구역 진입 의도 표시 while (flag[1] == true); // 상대 프로세스가 임계구역에 진입하려고 하는지 확인 critical section // 임계구역 실행 flag[0] = false; // 의도 해제 remainder section // 나머지 코드 실행 } while (true); // Process 1 do { flag[1] = true; while (flag[0] == true); critical section flag[1] = false; remainder section } while (true);","코드-3#코드:":"shared int turn, flag[2]; // Process 0 do { flag[0] = true; // 임계구역 진입 의도 표시 turn = 1; // 턴을 상대 프로세스에게 넘김 while (flag[1] \u0026\u0026 turn == 1); // 상대 프로세스가 임계구역에 진입 중이고 턴이 자신이 아닌 경우 대기 critical section // 임계구역 실행 flag[0] = false; // 의도 해제 remainder section // 나머지 코드 실행 } while (true); // Process 1 do { flag[1] = true; turn = 0; while (flag[0] \u0026\u0026 turn == 0); critical section flag[1] = false; remainder section } while (true);","페이지-교체-과정의-복잡성#\u003cstrong\u003e페이지 교체 과정의 복잡성\u003c/strong\u003e":"페이지 교체는 단순히 페이지 하나를 내보내고 다른 하나를 들여오는 간단한 작업처럼 보일 수 있지만, 실제로는 여러 가지 고려 사항이 얽혀 있는 복잡한 과정입니다.\n희생 페이지 선택: 어떤 기준으로 희생 페이지를 선택할 것인가? (이후 슬라이드에서 다양한 알고리즘 소개) 더티 비트(Dirty Bit) / 수정 비트(Modify Bit) 처리: 희생 페이지가 메모리에 적재된 후 내용이 변경되었는지 여부를 확인해야 합니다. 변경되었다면(더티 비트=1), 디스크에 그 내용을 기록해야 하지만, 변경되지 않았다면(더티 비트=0) 디스크 쓰기 작업을 생략하여 시간을 절약할 수 있습니다. 프레임 잠금(Frame Locking): 특정 페이지(예: 운영 체제 커널 코드, I/O 버퍼)는 절대로 디스크로 스왑 아웃되면 안 되는 경우가 있습니다. 이러한 페이지는 프레임에 ‘잠겨(locked)’ 있다고 하며, 페이지 교체 알고리즘은 이러한 페이지를 희생양으로 선택해서는 안 됩니다. 알고리즘 구현 복잡성 및 오버헤드: 정교한 알고리즘은 더 나은 선택을 할 수 있지만, 알고리즘 자체를 실행하는 데 드는 시간과 자원(오버헤드)이 클 수 있습니다. 단순한 알고리즘은 오버헤드가 적지만 최적의 선택을 하지 못할 수 있습니다. 따라서 성능과 오버헤드 사이의 균형을 맞추는 것이 중요합니다. 이후 슬라이드에서는 이러한 페이지 교체 과정에서 가장 핵심적인 부분인 “어떤 페이지를 교체할 것인가?“라는 질문에 답하기 위한 다양한 페이지 교체 알고리즘들을 살펴볼 것입니다. 각 알고리즘은 서로 다른 철학과 전략을 가지고 있으며, 그에 따른 장단점과 성능 특성을 보입니다. 이 제목 슬라이드는 바로 그 논의의 시작을 알리는 역할을 합니다.","페이지-교체-알고리즘이란#\u003cstrong\u003e페이지 교체 알고리즘이란?\u003c/strong\u003e":"앞서 설명했듯이, 페이지 폴트가 발생했을 때 물리 메모리에 빈 프레임이 없다면, 운영 체제는 기존에 메모리에 있던 페이지 중 하나를 디스크로 내보내고(페이지 아웃), 그 자리에 필요한 새 페이지를 가져와야(페이지 인) 합니다. 이때, **“어떤 페이지를 희생시킬 것인가?”**를 결정하는 구체적인 규칙 또는 전략을 페이지 교체 알고리즘이라고 합니다. 이 알고리즘의 선택은 시스템의 효율성에 매우 큰 영향을 미칩니다. 잘못된 페이지를 교체하면 곧바로 다시 해당 페이지가 필요해져 또 다른 페이지 폴트를 유발하고, 이는 시스템 성능 저하로 이어지기 때문입니다.","페이지-교체의-목표-페이지-폴트율-최소화#\u003cstrong\u003e페이지 교체의 목표: 페이지 폴트율 최소화\u003c/strong\u003e":"페이지 교체의 궁극적인 목표는 페이지 폴트율(page-fault rate)을 최소화하는 것입니다. 페이지 폴트가 발생하면 다음과 같은 일련의 작업이 수반됩니다.\n운영 체제로의 트랩 발생 현재 프로세스의 상태 저장 페이지 폴트 처리 루틴 실행 (참조 유효성 검사 등) (페이지 교체가 필요한 경우) 희생 페이지 선택 희생 페이지가 변경되었다면 디스크에 기록 (페이지 아웃) 새로운 페이지를 디스크에서 읽어오기 (페이지 인) 페이지 테이블 업데이트 프로세스 준비 큐로 이동 프로세스 재시작 이 과정에서 가장 시간이 많이 소요되는 부분은 디스크 입출력(I/O) 작업인 페이지 아웃과 페이지 인입니다. 디스크 접근 시간은 CPU의 연산 속도나 메모리 접근 속도에 비해 수천에서 수만 배 느립니다. 따라서 페이지 폴트가 자주 발생하면 시스템의 전체 성능은 급격히 저하됩니다. CPU는 대부분의 시간을 디스크 I/O가 완료되기를 기다리며 보내게 되고, 실제 유용한 작업은 거의 수행하지 못하는 상태, 즉 스래싱(Thrashing) 상태에 빠질 수 있습니다.\n스래싱을 방지하고 시스템 성능을 최적으로 유지하기 위해서는 어떤 페이지를 희생시킬지 결정하는 **페이지 교체 알고리즘(Page Replacement Algorithm)**의 역할이 매우 중요합니다. 좋은 알고리즘은 “가까운 미래에 참조될 가능성이 가장 낮은 페이지\"를 교체함으로써, 곧바로 다시 필요해질 페이지를 내보내는 어리석은 선택을 피해야 합니다. 만약 잘못된 선택으로 인해 방금 내보낸 페이지가 즉시 다시 필요해진다면, 또 다른 페이지 폴트가 발생하고 추가적인 디스크 I/O가 수반되어 성능을 악화시키기 때문입니다.","페이지-교체의-본질과-필요성#\u003cstrong\u003e페이지 교체의 본질과 필요성\u003c/strong\u003e":"가상 메모리 시스템의 주된 이점 중 하나는 물리 메모리의 크기보다 훨씬 큰 프로그램을 실행할 수 있게 하고, 동시에 여러 프로그램을 메모리에 올려 다중 프로그래밍의 정도를 높이는 것입니다. 이는 프로그램의 일부만 메모리에 적재하고, 나머지는 디스크(백킹 스토어)에 보관하다가 필요할 때마다 가져오는 요구 페이징(Demand Paging) 기법을 통해 가능해집니다.\n프로세스가 실행 중에 아직 물리 메모리에 없는 페이지에 접근하려고 하면 **페이지 폴트(Page Fault)**가 발생합니다. 운영 체제는 이 폴트를 처리하기 위해 해당 페이지를 디스크에서 물리 메모리로 가져와야 합니다. 이때, 만약 물리 메모리에 사용 가능한 빈 프레임이 있다면 문제는 간단합니다. 해당 빈 프레임에 페이지를 적재하고 페이지 테이블을 업데이트한 후, 중단된 명령을 재시작하면 됩니다.\n그러나 시스템이 오랜 시간 동안 여러 프로세스를 실행하다 보면, 물리 메모리의 모든 프레임이 특정 페이지들로 채워지게 됩니다. 바로 이러한 상황, 즉 물리 메모리가 가득 찬 상태에서 추가적인 페이지 폴트가 발생했을 때, 페이지 교체가 필요하게 됩니다. 새로운 페이지를 위한 공간을 만들기 위해서는 현재 메모리에 있는 페이지 중 하나를 **희생양(victim page)**으로 선택하여 디스크로 내보내고(이를 페이지 아웃(page out) 또는 스왑 아웃(swap out)이라고 합니다), 그 자리에 새로운 페이지를 가져와야 합니다(이를 페이지 인(page in) 또는 스왑 인(swap in)이라고 합니다).\n만약 페이지 교체 메커니즘이 없다면, 물리 메모리가 가득 찼을 때 더 이상 새로운 페이지를 가져올 수 없으므로, 새로운 페이지를 요구하는 프로세스는 실행을 계속할 수 없게 됩니다. 이는 결국 시스템의 다중 프로그래밍 능력을 심각하게 저해하고, 특정 프로세스의 실행이 중단되는 결과를 초래할 수 있습니다. 따라서 페이지 교체는 가상 메모리 시스템이 지속적으로, 그리고 효율적으로 동작하기 위한 필수 불가결한 기능입니다.","페이지-테이블과-주소-변환의-기초#\u003cstrong\u003e페이지 테이블과 주소 변환의 기초\u003c/strong\u003e":"먼저 유효-무효 비트의 역할을 이해하기 위해 **페이지 테이블(Page Table)**의 기본 기능부터 살펴보겠습니다. 가상 메모리 시스템에서 CPU가 생성하는 모든 주소는 논리 주소(가상 주소)입니다. 이 주소는 실제 메모리 버스로 전달되기 전에 물리 주소로 변환되어야 합니다. 이 변환 작업을 담당하는 것이 하드웨어인 **MMU(메메모리 관리 장치)**이며, MMU는 페이지 테이블이라는 자료 구조를 참조하여 변환을 수행합니다.\n페이지 테이블은 각 프로세스마다 하나씩 존재하며, 프로세스의 논리 주소 공간을 물리 메모리에 매핑하는 정보를 담고 있습니다. 논리 주소는 보통 두 부분으로 나뉩니다.\n페이지 번호 (Page Number, p): 논리 주소 공간 내에서 해당 주소가 몇 번째 페이지에 속하는지를 나타냅니다. 오프셋 (Offset, d): 페이지 내에서 상대적인 위치를 나타냅니다. MMU는 CPU로부터 논리 주소를 받으면, 페이지 번호(p)를 인덱스로 사용하여 해당 프로세스의 페이지 테이블에 접근합니다. 페이지 테이블의 p번째 항목(Entry)에는 해당 논리 페이지가 저장된 **물리 메모리의 프레임 번호(Frame Number, f)**가 적혀 있습니다. MMU는 이 프레임 번호(f)와 원래의 오프셋(d)을 조합하여 최종적인 물리 주소를 만들어냅니다.\n예를 들어, 페이지 크기가 4KB(212 바이트)이고, CPU가 논리 주소 8195를 요청했다고 가정해봅시다.\n논리 주소 8195 = 페이지 번호 2 (8195 / 4096 = 2) + 오프셋 3 (8195 % 4096 = 3) MMU는 페이지 테이블의 2번 인덱스를 찾아봅니다. 만약 2번 인덱스에 프레임 번호 7이 저장되어 있다면, 최종 물리 주소 = 프레임 번호 7 * 4096 + 오프셋 3 = 28672 + 3 = 28675가 됩니다.","페이지-테이블의-구조-structure-of-the-page-table#\u003cstrong\u003e페이지 테이블의 구조 (Structure of the Page Table)\u003c/strong\u003e":" Memory structures for paging can get huge using straight-forward methods  Consider a 32-bit logical address space as on modern computers  Page size of 4 KB (2^12)  Page table would have 1 million entries (2^32 / 2^12)  If each entry is 4 bytes -\u003e 4 MB of physical address space / memory for page table alone 4 That amount of memory used to cost a lot 4 Don’t want to allocate that contiguously in main memory  Hierarchical Paging  Hashed Page Tables  Inverted Page Tables  페이징을 위한 메모리 구조는 단순한 방법을 사용하면 매우 커질 수 있습니다.  현대 컴퓨터와 같은 32비트 논리 주소 공간을 가정해 봅시다.  페이지 크기는 4 KB ($2^{12}$ 바이트)입니다.  이 경우 페이지 테이블은 1백만 개의 항목(entry)을 갖게 됩니다 ($2^{32} / 2^{12} = 2^{20}$).  만약 각 항목이 4바이트라면 -\u003e 페이지 테이블 하나만을 위해 4MB의 물리 메모리 공간이 필요합니다. 4 과거에 그 정도의 메모리는 매우 비쌌습니다. 4 그 공간을 주 메모리(main memory)에 연속적으로 할당하고 싶지 않습니다.  계층적 페이징 (Hierarchical Paging)  해시 페이지 테이블 (Hashed Page Tables)  역 페이지 테이블 (Inverted Page Tables) 이 슬라이드는 단일 레벨 페이징(Single-level Paging) 시스템이 왜 현대적인 컴퓨팅 환경에서 비실용적인지를 설명하며, 그 문제점을 해결하기 위한 대안들을 소개합니다.\n1. 문제의 배경: 가상 메모리와 페이징\n가상 메모리(Virtual Memory): 현대 운영체제는 각 프로세스에게 실제 물리 메모리(RAM)의 크기와 상관없이 독립적이고 거대한 메모리 공간을 제공하는 것처럼 보이게 합니다. 이를 가상 주소 공간(Virtual Address Space)이라고 합니다. 예를 들어, 32비트 시스템에서 각 프로세스는 232 바이트, 즉 4GB 크기의 개인 메모리 공간을 갖는다고 착각합니다. 페이징(Paging): 이 가상 주소 공간을 물리 메모리에 매핑하는 가장 일반적인 방법이 페이징입니다. 시스템은 가상 주소 공간을 **페이지(Page)**라는 고정된 크기의 블록으로 나눕니다. 실제 물리 메모리도 **프레임(Frame)**이라는 동일한 크기의 블록으로 나뉩니다. 페이징의 핵심은 어떤 가상 페이지가 어떤 물리 프레임에 저장되어 있는지를 기록하고 관리하는 것입니다. 페이지 테이블(Page Table): 이 매핑 정보를 저장하는 자료구조가 바로 ‘페이지 테이블’입니다. CPU가 가상 주소를 통해 메모리에 접근하려고 하면, MMU(Memory Management Unit)라는 하드웨어는 페이지 테이블을 참조하여 해당 가상 주소를 실제 물리 주소로 변환합니다. 2. 단일 레벨 페이징의 문제점: 거대한 크기\n슬라이드의 예시는 이 문제점을 명확히 보여줍니다.\n논리 주소 공간(가상 주소 공간): 32비트이므로, 총 232개의 주소를 가질 수 있습니다. (4,294,967,296 바이트 = 4 GB) 페이지 크기: 4 KB (212 바이트)로 정했습니다. 총 페이지의 수: 전체 주소 공간을 페이지 크기로 나누면 필요한 페이지의 개수가 나옵니다. Number of Pages=Page SizeTotal Virtual Address Space​=212232​=220 220은 1,048,576으로, 약 1백만 개입니다. 즉, 이 프로세스는 최대 1백만 개의 페이지를 가질 수 있습니다. 페이지 테이블의 크기: 페이지 테이블은 모든 페이지에 대한 정보를 담고 있어야 합니다. 각 페이지에 대한 정보를 **페이지 테이블 항목(Page Table Entry, PTE)**이라고 부릅니다. PTE에는 해당 페이지가 저장된 물리 프레임의 번호와 유효 비트(valid bit), 접근 권한 비트(protection bit) 등 여러 제어 비트가 포함되며, 보통 4바이트 크기입니다. Page Table Size=(Number of Pages)×(Size of PTE)=220×4 Bytes=4×220 Bytes=4 MB 프로세스 하나를 실행하기 위해 필요한 페이지 테이블의 크기만 해도 4MB에 달합니다. 멀티태스킹 환경에서 100개의 프로세스가 실행된다면, 페이지 테이블을 위해서만 400MB의 메모리가 필요하게 됩니다. 이는 엄청난 메모리 낭비입니다.\n3. 추가적인 문제: 연속 할당\n더 큰 문제는 이 4MB 크기의 페이지 테이블을 물리 메모리의 연속된 공간에 할당해야 한다는 점입니다. 메모리가 파편화되어 있을 경우, 4MB의 연속된 빈 공간을 찾는 것은 매우 어려울 수 있습니다. 설사 찾더라도, 이는 심각한 **외부 단편화(External Fragmentation)**를 유발할 수 있습니다.\n4. 해결책 제시\n이러한 단일 레벨 페이징의 문제를 해결하기 위해 고안된 세 가지 주요 기법이 있습니다.\n계층적 페이징 (Hierarchical Paging): 페이지 테이블 자체를 페이징하는 기법입니다. 페이지 테이블을 여러 개의 작은 조각으로 나누고, 이 조각들의 위치를 가리키는 상위 레벨의 페이지 테이블(페이지 디렉터리)을 두는 방식입니다. (이후 슬라이드에서 자세히 설명됩니다.) 해시 페이지 테이블 (Hashed Page Tables): 32비트를 넘어 64비트 주소 공간처럼 매우 큰 경우에 사용됩니다. 가상 페이지 번호를 해싱하여 페이지 테이블에 접근하는 방식으로, 테이블의 크기를 주소 공간의 크기가 아닌 실제 사용하는 페이지 수에 비례하도록 만듭니다. 역 페이지 테이블 (Inverted Page Tables): 프로세스별로 페이지 테이블을 두는 대신, 시스템 전체에 단 하나의 페이지 테이블을 둡니다. 이 테이블은 물리 프레임 번호를 인덱스로 가지며, 각 항목에는 해당 프레임을 사용 중인 프로세스 ID와 가상 페이지 번호가 저장됩니다. 이 슬라이드는 이 중 ‘계층적 페이징’을 중심으로 논의를 이끌어 가기 위한 서론 역할을 합니다.","페이지-폴트의-발생#\u003cstrong\u003e페이지 폴트의 발생\u003c/strong\u003e":"슬라이드의 첫 줄은 페이지 폴트가 발생하는 근본적인 상황을 설명합니다. 프로세스가 특정 메모리 주소(논리 주소)에 접근하려고 할 때, MMU가 해당 논리 주소가 속한 페이지를 페이지 테이블에서 찾아봅니다. 이때 만약 해당 페이지 테이블 항목(PTE)의 **유효-무효 비트가 ‘무효(invalid)’**로 설정되어 있다면, MMU는 하드웨어 **트랩(trap)**을 발생시킵니다. 이 트랩이 바로 ‘페이지 폴트’입니다. 이 트랩은 현재 실행 중이던 프로세스의 상태(레지스터 값, 프로그램 카운터 등)를 안전하게 저장하고, 운영 체제 커널 내에 미리 정의된 페이지 폴트 핸들러(Page Fault Handler) 루틴으로 제어권을 넘깁니다.\n이제부터 운영 체제의 역할이 시작됩니다. 슬라이드는 이 처리 과정을 5단계로 나누어 설명합니다.","페이징-paging#페이징 (Paging)":"페이징은 운영체제의 메모리 관리 기법 중 하나로, 프로세스를 일정한 크기의 작은 조각인 **페이지(page)**로 나누고, 물리 메모리 역시 동일한 크기의 **프레임(frame)**으로 나누어, 각 페이지를 비어있는 어떤 프레임에도 불연속적으로(non-contiguously) 할당할 수 있도록 하는 방식입니다. 이를 통해 이전의 연속 할당 방식(고정 분할, 동적 분할)에서 발생했던 외부 단편화 문제를 해결하고 메모리 사용의 유연성과 효율성을 높이는 것을 목표로 합니다.\nGoal (목표) No external fragmentation problem (외부 단편화 문제 없음) Efficient memory sharing (효율적인 메모리 공유) Flexible memory use (유연한 메모리 사용) Idea (아이디어) Divide a process into multiple fragments (프로세스를 다수의 조각으로 분할) Allocation each fragment anywhere (각 조각을 어느 곳에나 할당) Maintain where the fragments are (조각들이 어디에 있는지 유지/관리) [한글 번역 및 상세 설명]\n목표 외부 단편화 문제 해결: 페이징의 가장 중요한 목표 중 하나입니다. 동적 분할 방식에서는 프로세스들이 메모리에 할당되고 해제되면서 사용 가능한 메모리 공간들이 작은 조각(hole)들로 흩어져, 총 가용 공간은 충분함에도 불구하고 큰 프로세스를 할당할 수 없는 외부 단편화가 발생했습니다. 페이징은 프로세스를 작은 페이지 단위로 나누고, 이 페이지들을 물리 메모리의 비어있는 어떤 프레임에든 배치할 수 있으므로, 가용 프레임이 N개 있다면 정확히 N개의 페이지를 수용할 수 있습니다. 즉, 메모리 공간이 조각나서 낭비되는 외부 단편화가 발생하지 않습니다. 👍 효율적인 메모리 공유: 동일한 프로그램을 여러 프로세스가 실행할 때, 프로그램의 코드 부분(텍스트 세그먼트)은 변하지 않으므로 공유될 수 있습니다. 페이징 환경에서는 이 공유 코드 페이지들을 각 프로세스의 논리 주소 공간에 매핑하되, 물리 메모리에는 단 하나의 복사본만 올려놓고 여러 프로세스가 해당 프레임을 공유하도록 할 수 있습니다. 이는 메모리 사용량을 크게 절약합니다. 예를 들어, 텍스트 편집기 프로그램을 10개의 프로세스가 동시에 사용한다면, 코드 부분은 메모리에 단 한 벌만 존재하고 모든 프로세스가 이를 공유하게 됩니다. 각 프로세스는 자신만의 데이터 페이지만 별도로 가집니다. 유연한 메모리 사용: 프로세스를 실행하기 위해 필요한 메모리 공간이 물리적으로 연속될 필요가 없습니다. 덕분에 메모리의 빈 공간을 효율적으로 활용할 수 있으며, 프로세스 크기가 물리 메모리보다 큰 경우에도 가상 메모리 기법과 결합하여 프로그램을 실행할 수 있는 기반을 제공합니다. (가상 메모리는 이 슬라이드 범위 밖이지만, 페이징은 가상 메모리 구현의 핵심 기술입니다.) 아이디어 프로세스를 다수의 조각으로 분할: 페이징의 핵심 아이디어는 프로세스의 논리 주소 공간을 **페이지(page)**라고 하는 고정된 크기(예: 4KB, 8KB)의 여러 조각으로 나누는 것입니다. 각 조각을 어느 곳에나 할당: 이렇게 나누어진 각 페이지는 물리 메모리의 **프레임(frame)**이라고 불리는, 페이지와 동일한 크기의 빈 공간 중 어느 곳에든 위치할 수 있습니다. 중요한 것은 이 프레임들이 서로 연속적일 필요가 없다는 점입니다. 예를 들어, 한 프로세스의 페이지 0은 프레임 5에, 페이지 1은 프레임 12에, 페이지 2는 프레임 2에 저장될 수 있습니다. 조각들이 어디에 있는지 유지/관리: 각 페이지가 물리 메모리의 어느 프레임에 저장되어 있는지를 운영체제가 정확히 알고 있어야 합니다. 이 매핑 정보를 저장하고 관리하는 자료구조가 바로 **페이지 테이블(page table)**입니다. 각 프로세스는 자신만의 페이지 테이블을 가집니다.","폰-노이만-구조#폰 노이만 구조":"","프로세스-개시-거부-process-initiation-denial#프로세스 개시 거부 (Process Initiation Denial)":"","해결책#해결책:":"일반적으로 Peterson’s Solution은 **순차적 일관성(Sequential Consistency)**이라는 메모리 모델을 가정합니다. 이는 모든 메모리 연산이 프로그램 순서대로 수행되고, 모든 프로세스가 동일한 순서로 메모리 변화를 관찰한다는 것을 의미합니다. 현대 시스템에서는 **메모리 배리어(Memory Barrier)**나 동기화 명령어를 사용하여 원자성을 보장해야 할 수 있습니다.","해결책-1#해결책:":"운영체제에서 특정 코드 영역을 비선점적으로 실행하도록 보장하거나, 하드웨어 지원을 통해 원자성을 확보해야 합니다.","해결책-2#해결책:":"캐시 일관성 프로토콜(MESI 등)을 사용하여 모든 프로세서가 동일한 메모리 상태를 유지하도록 보장해야 합니다.","해결책-3#해결책:":"프로세스의 고장을 감지하고 복구할 수 있는 메커니즘을 추가해야 합니다.","해결책-4#해결책:":"Dekker’s Algorithm이나 Lamport’s Bakery Algorithm과 같은 더 복잡한 알고리즘을 사용하여 다수의 프로세스를 지원할 수 있습니다.","해결책-페이지-교체-page-replacement#\u003cstrong\u003e해결책: 페이지 교체 (Page Replacement)\u003c/strong\u003e":"이 문제의 해결책은 페이지 교체입니다. 아이디어는 간단합니다. “새로운 페이지를 위한 공간을 만들기 위해, 현재 물리 메모리에 있는 페이지 중 하나를 희생양(victim)으로 골라 디스크로 쫓아낸다.”\n이 과정은 다음과 같은 세부 단계로 나뉩니다.\n희생 페이지 선택 (Victim Selection): 운영 체제는 현재 물리 메모리에 있는 모든 페이지 중에서 어떤 페이지를 제거할지 결정해야 합니다. 이 선택은 **페이지 교체 알고리즘(Page Replacement Algorithm)**에 따라 이루어집니다. 어떤 알고리즘을 사용하느냐에 따라 시스템의 전체 성능이 크게 달라질 수 있습니다.\n희생 페이지 내보내기 (Paging Out the Victim): 선택된 희생 페이지를 처리하는 과정입니다. 여기서 중요한 고려사항은 ‘더티 비트(Dirty Bit)’ 또는 **‘수정 비트(Modify Bit)’**입니다.\n더티 비트(Dirty Bit): 페이지 테이블 항목(PTE)에 포함된 또 다른 하드웨어 비트입니다. 페이지가 물리 메모리로 로드된 이후, 그 내용에 한 번이라도 쓰기(write) 작업이 발생했다면 하드웨어에 의해 이 비트가 1로 설정됩니다. If Dirty Bit is 1 (페이지가 수정됨): 페이지의 내용이 변경되었다는 의미이므로, 이 변경사항을 잃어버리지 않으려면 해당 페이지의 내용을 디스크의 스왑 공간(swap space)에 **반드시 기록(write back)**해야 합니다. 이 과정을 페이지 아웃(page out) 또는 **스왑 아웃(swap out)**이라고 합니다. 이 과정은 디스크 쓰기 I/O를 수반하므로 시간이 걸립니다. If Dirty Bit is 0 (페이지가 수정되지 않음): 페이지가 메모리에 올라온 후 한 번도 수정되지 않았다는 의미입니다. 이는 디스크에 있는 원본 내용과 메모리에 있는 내용이 동일하다는 뜻이므로, 굳이 디스크에 다시 쓸 필요가 없습니다. 그냥 메모리에서 덮어쓰면 됩니다. 디스크 I/O를 한 번 절약할 수 있으므로 훨씬 효율적입니다. 새로운 페이지 가져오기 (Paging In the New Page): 희생 페이지가 차지하던 프레임이 비워지면(또는 덮어쓸 준비가 되면), 페이지 폴트를 유발했던 새로운 페이지를 디스크에서 이 프레임으로 읽어옵니다. 이 과정은 페이지 인(page in) 또는 **스왑 인(swap in)**입니다.\n페이지 테이블 업데이트: 이 모든 과정이 끝나면, 관련된 두 페이지의 페이지 테이블 항목을 모두 업데이트해야 합니다.\n희생 페이지: 유효-무효 비트를 ‘v’에서 ‘i’로 변경합니다. 새로운 페이지: 유효-무효 비트를 ‘i’에서 ‘v’로 변경하고, 프레임 번호를 새로 할당된 프레임의 번호로 기록합니다.","현실적인-한계-미래를-알-수-없음-can#\u003cstrong\u003e현실적인 한계: 미래를 알 수 없음 (Can’t read the future)\u003c/strong\u003e":"슬라이드는 “이것을 어떻게 알 수 있는가? (How do you know this?)“라는 질문을 던지고, 그 답으로 “미래를 읽을 수 없음 (Can’t read the future)“이라고 명시합니다. 이것이 최적 알고리즘의 가장 큰 현실적인 한계입니다.\n실제 운영 체제 환경에서 프로그램이 앞으로 어떤 순서로 메모리 페이지를 참조할지 미리 정확하게 아는 것은 불가능합니다. 사용자의 입력, 외부 이벤트, 프로그램 내부의 조건 분기 등 수많은 요인에 의해 프로그램의 실행 흐름은 동적으로 변하기 때문입니다. 따라서, 최적 알고리즘은 실제 운영 체제에서 페이지 교체 전략으로 직접 구현하여 사용할 수는 없습니다. 마치 일기 예보가 완벽하게 미래의 날씨를 맞출 수 없는 것과 같습니다.\n만약 운영 체제가 미래의 모든 페이지 참조를 미리 알 수 있다면, 페이지 교체뿐만 아니라 CPU 스케줄링, 디스크 스케줄링 등 다른 많은 영역에서도 완벽한 결정을 내릴 수 있을 것입니다. 하지만 이는 현실적으로 불가능한 가정입니다.","환형-대기-조건-공략-attacking-the-circular-wait-condition#환형 대기 조건 공략 (Attacking the Circular Wait Condition)":"원문 (Original Text):\nAttacking the Circular Wait Condition  Every resource has a unique number  A process must request resources in increasing number order 번역 (Translation):\n환형 대기 조건 공략  모든 자원은 고유한 번호를 가짐  프로세스는 반드시 번호가 증가하는 순서로 자원을 요청해야 함 매우 자세한 설명 (Detailed Explanation):\n이 슬라이드는 교착 상태 예방 전략 중 마지막으로, 환형 대기(Circular Wait) 조건을 무효화하는 가장 실용적이고 널리 사용될 수 있는 방법에 대해 설명합니다. 🔄➡️⛓️ 환형 대기 조건은 “프로세스들이 꼬리에 꼬리를 물며 서로가 점유한 자원을 기다리는 사이클 형태의 대기\"를 의미합니다. 이 순환 고리를 끊으면 교착 상태를 예방할 수 있습니다.\n환형 대기 조건 공략의 핵심 아이디어:\n프로세스들이 자원을 요청하는 방식에 **일정한 순서(ordering)**를 강제함으로써, 자원 요청 방향이 한쪽으로만 흐르도록 하여 사이클이 형성될 수 없도록 만드는 것입니다.\n구체적인 방법: 자원 번호화 및 순차적 요청 (Resource Numbering and Ordered Requests)\n“Every resource has a unique number” (모든 자원은 고유한 번호를 가짐):\n시스템에 존재하는 모든 자원 유형(또는 개별 인스턴스)에 대해 **전역적으로 유일한 식별 번호(unique number)**를 할당합니다. 예를 들어, R1​=1,R2​=2,R3​=3,…,Rm​=m 과 같이 순서대로 번호를 매길 수 있습니다. 이 번호 부여 방식은 자원의 특성이나 중요도 등 다양한 기준을 사용할 수 있지만, 중요한 것은 모든 자원이 구분 가능하고 일관된 순서를 가져야 한다는 점입니다. F: ResourceTypes $\\rightarrow$ Integers 와 같이 함수 F를 정의하여 각 자원 유형에 정수 번호를 매핑할 수 있습니다. “A process must request resources in increasing number order” (프로세스는 반드시 번호가 증가하는 순서로 자원을 요청해야 함):\n이것이 핵심 규칙입니다. 모든 프로세스는 자원을 요청할 때, 현재 자신이 점유하고 있는 자원의 번호보다 더 큰 번호의 자원만을 요청할 수 있도록 강제합니다. 만약 프로세스가 자원 Ri​ (번호 F(Ri​))를 점유하고 있고, 자원 Rj​ (번호 F(Rj​))를 추가로 요청하려면, 반드시 F(Rj​)\u003eF(Ri​) 이어야 합니다. 만약 프로세스가 이미 번호가 큰 자원 Rk​를 점유하고 있는데, 그보다 번호가 작은 자원 Rl​ (F(Rl​)","회피-알고리즘-avoidance-algorithms#회피 알고리즘 (Avoidance algorithms)":""},"title":"university operating system"},"/06.university/system-programminguniversity/%EB%A6%AC%EB%88%85%EC%8A%A4-%EB%A7%81%ED%82%B9/":{"data":{"":"리눅스 시스템 콜 예시\ny = sin(x) 코드가 있을 때 #include \u003cmath.h\u003e를 선언하지 않아도 컴파일 시에 /usr/lib/libm.a 파일을 링크 시켜주면 실행 가능하다 단 선언은 해야하므로 double sin(double x); 코드를 적어주어야 한다 gcc -lm program.c 실행 시에 컴파일 된다 옵션은 linking math 이다"},"title":"리눅스 링킹"},"/06.university/system-programminguniversity/03-file-io/":{"data":{"":"open() creat() close() read() write() lseek() Disk I/O efficiency dup(), dup2() stat(), fstat(), lstat() access() 파일 디스크립터 프로세스가 실행될때 기본적으로 여는 파일은 3개 각각 0(STDIN), 1(STDOUT) ,2(STDERR)\nman -s 2 open : 과 같이 메뉴얼 파일을 볼 수 있다","close#close":"열린 파일 닫기","create#create":"int creat(const char *pathname, mode_t mode);\ncreat( pathname, mode ); open ( pathname, O_WRONLY | O_CREAT | O_TRUNC, mode); 2개는 기능이 동일 이때 소유자 모드는 변경하지 않는다","lseek#lseek":"","open#open":"int open (const char *pathname, int flags); int open (const char *pathname, int flags, mode_t mode); int open (const char *pathname, int flags); int open (const char *pathname, int flags, mode_t mode); 파일 디스크립터 값을 반환 -1 은 실패\nflags : 파일을 열 때 취해지는 구체적 행동을 기술한다\n파일 엑세스 플레그(필수 플래그) : 1개 필수 O_RDONLY(00) : 읽기 모드 (파일 엑세스 플레그) O_WRONLY(01) : 쓰기 모드 (파일 엑세스 플레그) O_RDRW(02) : 읽기 쓰기 모드 (파일 엑세스 플레그) 파일 생성 플래그 File Creation Flags (선택 플래그) : 생성과정에 영향 O_CREAT: 파일이 존재하지 않을 경우 새 파일을 생성합니다. O_EXCL: O_CREAT와 함께 사용되며, 파일이 이미 존재하면 오류를 발생시킵니다. 이를 통해 파일의 중복 생성을 방지합니다. O_TRUNC: 파일이 이미 존재할 경우, 파일 내용을 비웁니다. O_CLOEXEC : 파일 디스크립터가 생성될 때, 해당 프로세스가 exec() 시스템 호출을 통해 새로운 프로그램으로 전환될 때 자동으로 닫히도록 설정 O_DIRECTORY : 이 플래그는 지정된 경로가 반드시 디렉토리여야 함을 나타냅니다. 만약 경로가 디렉토리가 아닐 경우, open() 호출은 실패합니다. O_NOCTTY : 이 플래그는 열린 파일이 제어 터미널이 되지 않도록 합니다. O_NOFOLLOW : 이 플래그는 심볼릭 링크를 따라가지 않도록 설정합니다. 만약 지정된 경로가 심볼릭 링크인 경우, open() 호출은 실패합니다. O_TMPFILE : 이름 없는 임시 파일 생성 파일 상태 플래그 (File Status Flags) (선택 플래그) : 파일이 열린 후의 I/O 동작에 영향을 미침 O_APPEND: 파일을 추가 모드로 열어, 매번 쓰기 전에 파일 끝으로 이동 O_ASYNC: 입출력이 가능할 때 SIGIO 신호를 생성하는 비동기 모드 활성화 O_DIRECT: 캐시 영향을 최소화한 I/O 수행 O_DSYNC: 데이터 일관성 보장 동기화 쓰기 모드 O_LARGEFILE: 큰 파일을 열 수 있도록 허용 O_NOATIME: 파일 접근 시간을 업데이트하지 않음 O_NONBLOCK: 비차단 모드로 파일 열기 O_PATH: 파일을 열지 않고 파일 디스크립터만 반환 O_SYNC: 파일 데이터와 메타데이터가 모두 동기화된 상태에서 쓰기 완료 … 등등 모드 : mode_t = unsigned int (/usr/include/sys/types.h 에 선언되어 있음)\nFlag에 O_CREAT를 지정한 경우에만 필요 0-8비트는 파일의 보호모드 9-11 비트는 sticky 비트 공유모드 S_IRUSR (읽기 권한, 소유자): 소유자에게 읽기 권한 부여 S_IWUSR (쓰기 권한, 소유자): 소유자에게 쓰기 권한 부여 S_IXUSR (실행 권한, 소유자): 소유자에게 실행 권한 부여 S_IRGRP (읽기 권한, 그룹): 그룹에게 읽기 권한 부여 S_IWGRP (쓰기 권한, 그룹): 그룹에게 쓰기 권한 부여 S_IXGRP (실행 권한, 그룹): 그룹에게 실행 권한 부여 S_IROTH (읽기 권한, 기타): 기타 사용자에게 읽기 권한 부여 S_IWOTH (쓰기 권한, 기타): 기타 사용자에게 쓰기 권한 부여 S_IXOTH (실행 권한, 기타): 기타 사용자에게 실행 권한 부여 S_ISUID (셋 사용자 ID 비트): 셋 사용자 ID 비트 설정 S_ISGID (셋 그룹 ID 비트): 셋 그룹 ID 비트 설정 S_ISVTX (스티키 비트): 스티키 비트 설정","read#read":"ssize_t read (int filedes, void *buf, size_t nbytes); buf 읽은 데이터를 담을 메모리의 시작 주소 nbytes 읽을 바이트 수","write#write":"ssize_t write (int filedes, void *buf, size_t nbytes); read 와 반대 copy.c"},"title":"03 FILE IO"},"/06.university/system-programminguniversity/04-file-%EC%A1%B0%EC%9E%91/":{"data":{"":"1.link() / unlink() / remove() / rename() umask() chmod() / fchmod() truncate() / ftruncate() utime() Directory mkdir() / opendir() / readdir() / closedir() / rewinddir() / rmdir() chdir() / getcwd() Symbolic link sync() / fsync()","hard-link#hard link":"Link from directory block to i-node Use i-node number to make the link (Linux command ‘ln’) Hard link는 같은 file system 내부에서만 연결 가능\n만약 디렉토리일 경우 inode block 의 inode 값은 특정 디렉토리의 data block 상의 주소를 가리킴 -\u003e data block 디렉토리 file 내부에 특정 파일의 inode 를 가리키는 주소값이 들어있음 -\u003e inode block 의 inode 가 특정 파일의 data block 상의 주소를 가리킴 i-node 2549 link count 최소 3 i-node 1267 link count 최소 2 루트 디렉토리의 경우 부모디렉토리(..)가 자기자신(.) 과 동일한 inode 를 가리킴 link count of i-node number of directory entries that is pointing to an i-node stat 구조체의 st_link 링크 카운트(link count)는 파일 시스템에서 특정 i-node가 얼마나 많은 디렉토리 엔트리와 연결되어 있는지를 나타내는 값 즉 나(i-node)를 가리키는 주소들 갯수\n방금 생성된 디렉토리 link count 가 기본적으로 2인 이유 상위 부모의 inode 가 가리키는 주소에 data block 에 디렉토리 정보(디렉토리 엔트리)에 나의 inode주소 값이 있다 나의 inode 가 가리키는 주소에 data block 에 디렉토리 정보에 (.) 이라는 나의 inode 를 가리키는 inode주소 값이 있다","link#link":"int link (const char *cur_path, const char *new_path); This call makes a new link/directory entry (new_path) to an existing file (cur_path) 같은 i-node를 가리키는 directory entry가 하나 더 만들어짐 해당 i-node의 link count가 하나 증가 Return values Success: 0, link count increases Error: -1 Parameter cur_path: current hard link (or pathname) new_path: new hard link (or pathname) 보통 link count가 0이 되면 해당 파일은 삭제되지만, 다른 프로세스가 사용중인 파일이 삭제되는 것을 방지하기 위해 link count가 0에 도달했더라도 그 파일을 open 한 프로세스의 수가 0 이상이면 삭제하지 않는다 파일이 close 될 때 kernel은 그 파일을 open 한 프로세스 수가 0 인지 확인하고, 0 일 경우 link count가 0 인지 확인하고 삭제한다\nunlink","operations-on-file#Operations on file":"Deleting a file If a file is deleted in a directory block, link count of i-node decreases If link count become zero, both i-node and data blocks of a file are deleted 일반 파일 삭제 과정 상위 디렉토리 정보(directory entry)에 나의 inode 주소값이 적혀있는 것을 지운다 자연스레 나를 가리키는 디렉토리 정보가 사라졌으므로 link count 값이 1 줄어든다 만약 link count 값이 0 이면 나의 inode 주소를 가리키는 주소를 가진 개체들이 없으므로 data block 의 값을 삭제해도 된다 Moving a file Linux command: mv Directory entry is changed without changing the i-node and data block of file","remove#remove":"int remove (const char *pathname); if mathname is nomal file =\u003e remove = unlink if mathnaem is dir file =\u003e remove = rmdir","rename#rename":"int rename(const char *oldpath, const char *newpath); rename() 함수는 파일의 이름을 변경하며, 필요시 디렉토리 간에 이동할 수 있습니다. 이 함수는 다음과 같은 특성을 가지고 있습니다:\n하드 링크와의 영향: 다른 하드 링크(예: link(2)를 사용하여 생성된 링크)에 대해서는 영향을 미치지 않습니다. 열린 파일 디스크립터: oldpath에 대한 열린 파일 디스크립터는 영향을 받지 않습니다. rename() 작업이 성공하는지 여부는 여러 가지 제약 조건에 따라 결정됩니다. 아래는 관련된 오류 상황입니다:\nnewpath가 이미 존재하는 경우: rename()은 원자적으로 대체되므로, 이 시점에서 다른 프로세스가 newpath를 접근하려고 할 때 파일이 없다고 발견되는 상황은 없습니다. 그러나 oldpath와 newpath가 모두 파일을 참조하는 상태가 발생할 수 있는 시간 여유가 있습니다. oldpath와 newpath가 동일한 하드 링크인 경우: 두 경로가 동일한 파일을 참조하고 있다면, rename()은 아무 작업도 하지 않고 성공 상태를 반환합니다. newpath가 존재하지만 작업이 실패하는 경우: 어떤 이유로든 작업이 실패하면, rename()은 newpath의 인스턴스를 그대로 유지합니다. oldpath가 디렉토리를 참조하는 경우: 이 경우, newpath는 존재하지 않거나 비어 있는 디렉토리를 지정해야 합니다. oldpath가 심볼릭 링크를 참조하는 경우: 링크가 이름이 변경됩니다. 만약 newpath가 심볼릭 링크를 참조한다면, 해당 링크는 덮어씌워집니다.","symbolic-link#Symbolic link":"Linux command ‘% ln –s /usr/lib lib’ ex) lrwxrwxrwx 1 root 7 Sep 25 07:14 lib -\u003e /usr/lib File name: lib Contents of file: /usr/lib File size: 7 bytes The contents of file (data block) is the pathname of the target link","umask#umask":"mode_t umask(mode_t newmask); newmask: bitwise OR S_IRUSR, S_IWUSR, S_IXUSR S_IRGRP, S_IWGRP, S_IXGRP S_IROTH, S_IWOTH, S_IXOTH","파일-권한#파일 권한":"umask : 가린다의 의미 mask 에 파일을 생성할 때 umask 값을 사용하여 적절히 생성한다\n특수 권한 리눅스 파일 권한 Set UID\n파일에 Set-UID 비트가 설정되면 다른 사용자가 파일을 실행했을때 해당 사용자의 권한이 아닌 파일의 소유자 권한으로 실행. Set-UID 비트를 설정하기 위해 소유자 허가권에 s를 추가하거나 앞에 4를 붙여줌. (ex 4750 =\u003e rwsr-x—) Set GID\n파일에 Set-GID 비트가 설정되면 다른 사용자가 파일을 실행했을때 해당 사용자의 권한이 아닌 그룹의 권한으로 실행 Set-GID 비트를 설정하기 위해 소유자 허가권에 s를 추가하거나 앞에 2를 붙여줌. (ex 4750 =\u003e rwsr-x—) Sticky-Bit 디렉토리만 설정 가능\nsticky-bit가 설정된 디렉토리에 파일을 생성하면 해당 파일은 생성한 사람의 소유가 되며, 오직 소유자와 root에게만 해당 파일에 대한 삭제 및 변경의 권한이 있다. 스티키비트 추가하기위해 문자방식인경우 t를 사용하고 숫자방식인경우 1 사용.","파일-시스템#파일 시스템":"Boot block First block of the file system Program to run system is located Super block Boot 다음 영역 file system 관리 정보 size of file system info for free block info for i-node file type access permission bits file size Time stamp Number of links pointers to data blocks for the file stat 구조체의 field들은 i-node에서 읽어온다 block to modify that super block is modified etc resides(상주하다) in kernel memory space in DRAM Needed to be consistent with the super block in disk Use “sync” system call (also a user cmd) i-node block list Super block 다음의 영역 Consists of many i-nodes 1 i-node / 1 file Identified by the i-node no. File 관리에 필요한 정보 저장 Data block Last area in the file system Contains the data for general files and directory files. general files directory files file name i-node numbers for files"},"title":"04 FILE 조작"},"/06.university/system-programminguniversity/05-process/":{"data":{"":"qexec() 이후에 오는 문자에 의해 구별되는 표시는 다음의 의미가 있다 l -\u003e 인자 정보를 개개의 문자열 데이터를 가르키는 포인터 arg0, arg1……. argn으로 전달한다 v -\u003e 인자 정보를 개개의 문자열 데이터를 가리키는 포인터 배열의 선두주소 argv로 전달한다 e -\u003e envp 정보를 전달한다 p -\u003e p를 사용하는 경우, 실행할 파일이름을 환경 변수 PATH로 지정한 디렉토리 안에서 찾아내어 실행한다","1-execve#1. \u003ccode\u003eexecve()\u003c/code\u003e":"축약어: exec + v (vector) + e (environment) 설명: “exec\"는 실행을 의미하며, “v\"는 인수를 배열 형태로 받고, “e\"는 환경 변수를 배열 형태로 받는다는 것을 나타냅니다.","2-execv#2. \u003ccode\u003eexecv()\u003c/code\u003e":"축약어: exec + v (vector) 설명: “exec\"는 실행을 의미하며, “v\"는 인수를 배열 형태로 받는다는 것을 나타냅니다. 환경 변수를 설정할 수 없습니다.","3-execvp#3. \u003ccode\u003eexecvp()\u003c/code\u003e":"축약어: exec + v (vector) + p (path) 설명: “exec\"는 실행을 의미하며, “v\"는 인수를 배열 형태로 받고, “p\"는 PATH 환경 변수를 통해 파일을 찾는다는 것을 나타냅니다.","4-execle#4. \u003ccode\u003eexecle()\u003c/code\u003e":"축약어: exec + l (list) + e (environment) 설명: “exec\"는 실행을 의미하며, “l\"은 인수를 개별적으로 받는다는 것을 나타내고, “e\"는 환경 변수를 배열 형태로 받는다는 것을 나타냅니다.","5-execl#5. \u003ccode\u003eexecl()\u003c/code\u003e":"축약어: exec + l (list) 설명: “exec\"는 실행을 의미하며, “l\"은 인수를 개별적으로 받는다는 것을 나타냅니다. 환경 변수를 설정할 수 없습니다.","6-execlp#6. \u003ccode\u003eexeclp()\u003c/code\u003e":"축약어: exec + l (list) + p (path) 설명: “exec\"는 실행을 의미하며, “l\"은 인수를 개별적으로 받고, “p\"는 PATH 환경 변수를 통해 파일을 찾는다는 것을 나타냅니다.","정리#정리":"함수 이름 축약어 설명 인수 형태 환경 변수 지원 execve exec + v (vector) + e (environment) 파일 이름 + argv[] + envp[] 지원 execv exec + v (vector) 파일 경로 + argv[] 지원하지 않음 execvp exec + v (vector) + p (path) 파일 이름 + argv[] 지원하지 않음 execle exec + l (list) + e (environment) 파일 이름 + arg1, arg2, … + NULL 지원 execl exec + l (list) 파일 경로 + arg1, arg2, … + NULL 지원하지 않음 execlp exec + l (list) + p (path) 파일 이름 + arg1, arg2, … + NULL 지원하지 않음"},"title":"05 PROCESS"},"/06.university/system-programminguniversity/lab5-%EA%B3%BC%EC%A0%9C-%EC%B6%94%EA%B0%80-%EC%84%A4%EB%AA%85/":{"data":{"":"파일의 이름을 바꾸는 프로그램을 작성하는데, - 파일의 이름을 같은 디렉토리 안에서 바꾸거나 - 다른 디렉토리로 이동하여 바꾸는 기능이 모두 구현되어야 합니다. - 4-1 강의자료에서 학습한 시스템 호출들을 사용하여 작성하기 바랍니다.","manual-rename#manual rename":"rename() 함수는 파일의 이름을 변경하며, 필요시 디렉토리 간에 이동할 수 있습니다. 이 함수는 다음과 같은 특성을 가지고 있습니다:\n하드 링크와의 영향: 다른 하드 링크(예: link(2)를 사용하여 생성된 링크)에 대해서는 영향을 미치지 않습니다. 열린 파일 디스크립터: oldpath에 대한 열린 파일 디스크립터는 영향을 받지 않습니다.","성공-여부-결정#성공 여부 결정":"rename() 작업이 성공하는지 여부는 여러 가지 제약 조건에 따라 결정됩니다. 아래는 관련된 오류 상황입니다:\nnewpath가 이미 존재하는 경우: rename()은 원자적으로 대체되므로, 이 시점에서 다른 프로세스가 newpath를 접근하려고 할 때 파일이 없다고 발견되는 상황은 없습니다. 그러나 oldpath와 newpath가 모두 파일을 참조하는 상태가 발생할 수 있는 시간 여유가 있습니다. oldpath와 newpath가 동일한 하드 링크인 경우: 두 경로가 동일한 파일을 참조하고 있다면, rename()은 아무 작업도 하지 않고 성공 상태를 반환합니다. newpath가 존재하지만 작업이 실패하는 경우: 어떤 이유로든 작업이 실패하면, rename()은 newpath의 인스턴스를 그대로 유지합니다. oldpath가 디렉토리를 참조하는 경우: 이 경우, newpath는 존재하지 않거나 비어 있는 디렉토리를 지정해야 합니다. oldpath가 심볼릭 링크를 참조하는 경우: 링크가 이름이 변경됩니다. 만약 newpath가 심볼릭 링크를 참조한다면, 해당 링크는 덮어씌워집니다."},"title":"lab5 과제 추가 설명"},"/06.university/university-architecture/":{"data":{"":"PC : 다음에 인출될 명령어의 주소 AC : 임시저장 IR : 최근에 인출된 명령어 MAR : 기억장치 접근 주소 MBR : 기억장치 접근 데이터 SP : 스텍 최상위 주소","2장#2장":"","4장#4장":"제어 유니트\n명령어 해독기 inscruction decoder CAR 제어 주소 레지스터 : 다음에 실행할 마이크로 명령어의 주소를 저장하는 레지스터 제어 기억장치(control memory) : 마이크로명령어들로 이루어진 마이크로프로그램을 저장하는 내부 기억 장치 CBR 제어 버퍼 레지스터 : 제어 기억장치로 부터 읽혀진 마이크로 명령어를 일시적으로 저장하는 레지스터 SBR 서브 루틴 레지스터 : 마이크로프로그램에서 서브 루틴이 호출되는 경우에 현재의 CAR 을 일시적으로 저장하는 레지스터 순서제어 모듈(sequencing module) : 마이크로명령어의 실행 순서를 결정하는 회로들의 집합 인출 사이클 마이크로 프로그램\nORG 4 INDRT : IRTAR U JMP NEXT ; MAR \u003c- IR(addr), ; 다음 마이크로명령어 실행 READ U JMP NEXT ; MBR \u003c- M[MAR], ; 다음 마이크로 명령어 실행 BRTIR U RET ; IR(addr) \u003c- MBR, ; 실행 사이클 루틴으로 복귀","mesi#MESI":"수정 (M : Modified) 상태 : 데이터가 수정(변경) 된 상태 베타 (E : Exclusive) 상태 : 유일한 복사본이고, 주기억장치의 내용과 동일한 상태 공유 (S : Shared) 상태 : 데이터가 두 개 이상의 프로세서 캐시에 적재되어 있는 상태 무효 (I : Invalid) 상태 : 데이터가 다른 프로세서에 의해 수정되어 무효가 된 상태 초기 cache miss 후 캐쉬로 등록 ( - -\u003e E ) 수정 (메인 메모리 반영 x) ( E -\u003e M ) 다른 코어가 값을 읽는 경우 ( E -\u003e S , M-\u003eS, - -\u003e S , -\u003e S ) .. 캐시간 전송이 가능할 수도 못할 수도 있음 못하면 메인메모리에 update 후 동기화 수정( 메인 메모리 반영 x ) ( S-\u003eM ) 수정( 메인 메모리 반영 x ) ( M-\u003eM ) 다른 코어가 M 인상태에서 수정 ( M-\u003eI, I-\u003eM )","sub-call#Sub call":"인터럽트 사이클과 비슷\nCALL X 명령시\nMBR \u003c- PC MAR \u003c- SP, PC \u003c- X M[MAR] \u003c- MBR, SP \u003c- SP - 1 RET 명령시\nSP \u003c- SP + 1 MAR \u003c- SP PC \u003c- MBR \u003c- M[MAR]","간접-사이클#간접 사이클":"MAR \u003c- IR(addr) MBR \u003c- M[MAR] IR(addr) \u003c- MBR","사이클#사이클":"","실행-사이클#실행 사이클":"load","인출-사이클#인출 사이클":"MAR \u003c- PC MBR \u003c- M[MAR], PC \u003c- PC + 1 IR \u003c- MBR","인터럽트-사이클#인터럽트 사이클":"MBR \u003c- PC MAR \u003c- SP, PC \u003c- ISR 의 시작 주소 M[MAR] \u003c- MBR , SP \u003c- SP-1"},"title":"university architecture"},"/06.university/university-machine-leaning/":{"data":{"":"T task : 해야할 작업 E experience : 학습 P performance : 작업 성능","broadcasting의-세-가지-주요-규칙#\u003cstrong\u003eBroadcasting의 세 가지 주요 규칙\u003c/strong\u003e":"규칙 1: 배열의 차원(rank)을 맞추기 위해 작은 차원의 배열에 1을 추가 규칙 2: 크기가 1인 차원은 필요한 크기만큼 확장 규칙 3: 최종적으로 모든 차원의 크기가 일치해야 함","dataframe#dataframe":"여러가지 방법으로 생성이 가능하다\npython_ dict + pandas_series\n{\"Mango\":series1, \"Apple\":series2, \"Banana\":series3}\n리스트를 값으로 갖는 dict\ndict2 = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada', 'NY', 'NY', 'NY'], 'year': [2000, 2001, 2002, 2001, 2002, 2003, 2002, 2003, 2004], 'pop': [1.5, 1.7, 3.6, 2.4, 2.9, 3.2, 8.3, 8.4, 8.5]} 중첩 dict\ndict3 = {'Nevada': {2001: 2.4, 2002: 2.9}, 'Ohio': {2000: 1.5, 2001: 1.7, 2002: 3.6}}","numpy#numpy":"Axis(축): NumPy에서 각 차원을 축이라고 부릅니다. Rank(랭크): 배열의 축 개수입니다. 예를 들어, 3x4 행렬은 랭크가 2입니다. Shape(형태): 배열의 각 축 길이를 나타내는 튜플입니다. 예: (3, 4) Size(크기): 배열의 총 요소 수입니다. 예: 3x4 행렬의 경우 size=12. boolean indexing\nm \u003c 25 # equivalent to m \u003c [25, 25, 25, 25]\narray([ True, True, False, False])","머신러닝-분류#머신러닝 분류":"기준1: 사람의 지도/감독 여부 (학습하는 동안 감독의 형태나 주어지는 정보량에 따른 분류) 지도(Supervised) : 레이블(타겟) 이 포함 분류(classification), 회귀(regression) 정답이 포함되어 있는가 비지도(unsupervised) : : 레이블이 없는 훈련 데이터 : 군집(Clustering), 시각화(Visualization), 차원 축소(Dimensionality Reduction), 이상 탐지(Anomaly Detection), 이상 탐지(Anomaly Detection), 연관 규칙 학습(Association Rule Learning) 준지도(semi-supervised) : 지도 + 비지도 강화(reinforcement)학습 : 학습에 대한 피드백 제공 기준2 : 실시간으로 주어지는 데이터에 대한 점진적인 학습 가능 여부 온라인 학습 vs 배치 학습 기준3 : 훈련을 통해 알고 있는 데이터 포인트와 새로운 데이터 포인트를 비교하는 방식인지, 아니면 훈련 데이터셋에서 패턴을 발견하고 그에 기반한 예측 모델을 만드는 것인지 사례 기반 학습 vs 모델 기반 학습","세부#세부":"분류 회귀 : 중고자 가격 예측 군집 : 비슷한 특징을 가진 그룹으로 나누는 것 (분류과 다른점은 레이블이 없다) : k-means, DBSCAN, 계층 군집 분석 시각화 : 레이블이 없는 고차원(여러 특성(feature)들로 이루어진) 데이터를 분석하여 도식화가 가능한 2D 또는 3D 표현을 만들어줌 차원 축소 : original information의 손실을 최소화 하면서 데이터의 차원(특성)을 줄이기 ex) 상관관계가 높은 자동차의 주행거리과 연식을 “마모 정도”라는 하나의 특성으로 합침 이상 탐지 : 정상 샘플들을 이용하여 머신러닝 모델 훈련 후 주어진 새로운 샘플의 정상 여부를 판단 특이치 탐지(Novelty Detection) : 전혀 오염되지 않은 clean 훈련 데이터 학습 후 학습된 훈련 데이터와 달라 보이는 데이터 탐지 연관 규칙 학습(Association Rule Learning) : 특성 간 흥미로운 관계 찾기 마트 판매 기록 데이터에 대해 연관 규칙 학습 적용 예) 바비큐 소스와 감자를 구매한 고객이 스테이크도 구매하는 경향을 찾아냄 군집과 vs 시각화의 다른점 이상탐지 vs 특이치 탐지 특이치 탐지 는 “강아지 vs. 고양이\"처럼 명확한 범주 분류 이상 탐지 는 “대부분의 강아지와 다른 특이한 사례”"},"title":"university machine leaning"},"/android-%EC%9D%B4%EB%B2%A4%ED%8A%B8-%EC%B2%98%EB%A6%AC-%EC%BD%94%EB%93%9C-%EB%B6%84%EB%A6%AC/":{"data":{"":"네, 말씀하신 내용이 바로 ‘관심사의 분리(Separation of Concerns)’ 원칙을 UI 계층에 적용하는 아주 훌륭한 접근 방식입니다. Activity/Fragment는 오케스트라의 지휘자처럼 어떤 뷰와 어떤 로직 핸들러(ViewModel)를 연결할지 ‘조율’만 하고, 실제 이벤트 처리 로직은 모두 ViewModel에, UI 내부의 세부 이벤트 감지는 커스텀 뷰 자체에 위임하는 구조입니다.\n이 목표를 달성하기 위한 가장 이상적이고 현대적인 방법을 단계별로 설명해 드리겠습니다.\n핵심 전략: Custom View + Callback Interface + ViewModel\nCustom View: 내부에 포함된 여러 위젯(ImageView, TextView 등)의 이벤트를 감지합니다. Callback Interface: Custom View에서 발생한 이벤트를 외부로 알리기 위한 ‘약속(Contract)‘입니다. “프로필 이미지가 눌렸다”, “팔로우 버튼이 눌렸다” 와 같은 의미 있는(semantic) 이벤트로 추상화합니다. ViewModel: Callback Interface를 구현하여 실제 비즈니스 로직을 처리합니다. Activity/Fragment: Custom View와 ViewModel을 연결(setup)하는 역할만 담당합니다.","step-1-이벤트-콜백-인터페이스-정의-계약서-작성#Step 1: 이벤트 콜백 인터페이스 정의 (계약서 작성)":"어떤 이벤트가 발생할 수 있는지 명확하게 정의하는 인터페이스를 만듭니다.\n// ProfileViewEvents.kt interface ProfileViewEvents { fun onProfileImageClicked(userId: String) fun onFollowButtonClicked(userId: String) } onClick 같은 일반적인 이름 대신 onProfileImageClicked 처럼 의미를 담아 정의하는 것이 중요합니다.","step-2-커스텀-뷰custom-view-제작#Step 2: 커스텀 뷰(Custom View) 제작":"이 뷰는 내부의 클릭 이벤트를 감지하고, 외부로 약속된 인터페이스(ProfileViewEvents)를 통해 이벤트를 전달하는 역할만 합니다.","step-3-viewmodel에서-이벤트-핸들러-구현#Step 3: ViewModel에서 이벤트 핸들러 구현":"ViewModel은 View가 무슨 모양인지 전혀 몰라도 됩니다. 오직 ProfileViewEvents라는 약속만 보고 로직을 구현합니다.\n// ProfileViewModel.kt class ProfileViewModel : ViewModel(), ProfileViewEvents { // 인터페이스 구현 private val _toastMessage = MutableLiveData","step-4-activityfragment에서-조율-작업#Step 4: Activity/Fragment에서 \u0026lsquo;조율\u0026rsquo; 작업":"Activity는 그저 지휘자입니다. ProfileView와 ProfileViewModel을 연결해 주기만 합니다. 이벤트 처리 로직은 단 한 줄도 없습니다.","단계별-구현-방법#단계별 구현 방법":"간단한 ‘프로필 뷰’를 예시로 들어보겠습니다. 이 뷰는 프로필 이미지와 팔로우 버튼으로 구성됩니다.","심화-데이터-바인딩으로-연결setup-코드도-제거하기#심화: 데이터 바인딩으로 연결(Setup) 코드도 제거하기":"데이터 바인딩을 사용하면 Activity의 setEventListener 호출 코드마저 XML로 옮겨 완전히 자동화할 수 있습니다.\n1. BindingAdapter 생성\n// ProfileViewBindingAdapter.kt @BindingAdapter(\"onProfileEvent\") fun setOnProfileEvent(view: ProfileView, listener: ProfileViewEvents) { view.setEventListener(listener) } 2. XML 레이아웃 수정","이-구조의-강력한-장점#이 구조의 강력한 장점":"완벽한 책임 분리: Activity: 뷰와 로직의 연결, 생명주기 관리. Custom View: 자기 내부의 UI 이벤트 감지 및 외부로 추상화된 이벤트 전달. ViewModel: “무엇을 할 것인가\"에 대한 비즈니스 로직만 담당. 재사용성 극대화: ProfileView는 어떤 화면에서든 가져다 쓸 수 있는 독립적인 부품이 됩니다. ProfileViewModel의 로직도 다른 뷰에서 재사용될 수 있습니다. 테스트 용이성: ProfileViewModel은 Android 프레임워크에 대한 의존성이 거의 없으므로(인터페이스만 구현), JVM 환경에서 손쉽게 유닛 테스트를 할 수 있습니다. 가독성 및 유지보수성: MainActivity는 매우 간결해지며, 전체적인 구조를 파악하기 쉬워집니다. 새로운 기능을 추가하거나 수정할 때 어디를 봐야 할지 명확해집니다."},"title":"android 이벤트 처리 코드 분리"},"/android-studio-build-sequence/":{"data":{"":"네, 제공해주신 Android Gradle 빌드 로그의 각 단계를 매우 자세하게 설명해 드리겠습니다. 이 로그는 Android Studio에서 ‘Run’ 버튼을 누르거나 터미널에서 ./gradlew assembleDebug 명령을 실행했을 때 나타나는 과정입니다.","1단계-준비-및-설정-preparation--setup#\u003cstrong\u003e1단계: 준비 및 설정 (Preparation \u0026amp; Setup)\u003c/strong\u003e":"\u003e Task :app:preBuild \u0026 \u003e Task :app:preDebugBuild\n역할: 본격적인 빌드 전에 필요한 준비 작업을 수행합니다. 예를 들어, 빌드 과정에서 생성될 파일들을 저장할 폴더(build/ 디렉토리)를 만들거나 초기 환경 설정을 합니다. preDebugBuild는 ‘debug’ 빌드 유형에 특화된 준비 작업입니다. \u003e Task :app:checkKotlinGradlePluginConfigurationErrors\n역할: Kotlin Gradle 플러그인 설정에 오류가 없는지 확인합니다. SKIPPED: 이 작업은 특정 조건에서만 실행되거나, 필요 없다고 판단되면 건너뜁니다. 문제가 있는 상태가 아닙니다.","2단계-리소스-처리-resource-processing#\u003cstrong\u003e2단계: 리소스 처리 (Resource Processing)\u003c/strong\u003e":"이 단계에서는 앱의 모든 리소스(레이아웃 XML, 이미지, 문자열 등)를 처리합니다. 주로 aapt2 도구가 사용됩니다.\n\u003e Task :app:checkDebugAarMetadata\n역할: 프로젝트가 의존하는 라이브러리(.aar 파일)들의 메타데이터가 올바른지 확인합니다. \u003e Task :app:processDebugNavigationResources \u0026 \u003e Task :app:compileDebugNavigationResources\n역할: Android Jetpack의 Navigation Component를 사용하는 경우, res/navigation 폴더 안의 XML 파일들을 처리하고 컴파일합니다. \u003e Task :app:generateDebugResValues \u0026 \u003e Task :app:generateDebugResources\n역할: build.gradle 파일에 정의된 resValue 같은 동적으로 생성되는 리소스 값들을 실제 리소스 파일로 만듭니다. \u003e Task :app:mergeDebugResources\n역할: 매우 중요한 단계입니다. 프로젝트의 기본 리소스(src/main/res), 디버그용 리소스(src/debug/res), 그리고 모든 라이브러리(AAR)에 포함된 리소스들을 하나로 합쳐서 단일 폴더에 모읍니다. 만약 같은 이름의 리소스가 여러 곳에 있다면, 정해진 우선순위에 따라 하나를 선택합니다. \u003e Task :app:packageDebugResources\n역할: aapt2가 본격적으로 동작하는 핵심 단계입니다. mergeDebugResources에서 합쳐진 모든 리소스를 컴파일하고 연결(link)합니다. 이 과정에서 R.java 파일이 생성되고, 모든 리소스가 바이너리 형식으로 포함된 resources.ap_라는 중간 결과물이 만들어집니다. \u003e Task :app:parseDebugLocalResources\n역할: packageDebugResources 이후 생성된 리소스들을 파싱하여 다음 단계를 준비합니다.","3단계-매니페스트-처리-manifest-processing#\u003cstrong\u003e3단계: 매니페스트 처리 (Manifest Processing)\u003c/strong\u003e":"\u003e Task :app:createDebugCompatibleScreenManifests\n역할: 앱의 화면 호환성(screen compatibility)과 관련된 매니페스트 조각을 생성합니다. \u003e Task :app:extractDeepLinksDebug\n역할: 매니페스트와 코드 내 어노테이션에서 딥링크(Deep Link) 정보를 추출합니다. \u003e Task :app:processDebugMainManifest, \u003e Task :app:processDebugManifest, \u003e Task :app:processDebugManifestForPackage\n역할: 리소스 병합과 유사하게 AndroidManifest.xml 파일을 병합합니다. src/main/AndroidManifest.xml을 기본으로, 라이브러리의 매니페스트와 src/debug/ 폴더의 매니페스트 조각들을 합칩니다. 이 과정에서 build.gradle에 정의된 applicationId, versionCode 같은 플레이스홀더 값들을 실제 값으로 교체하여 최종 매니페스트를 완성합니다.","4단계-코드-컴파일-및-dex-변환-code-compilation--dexing#\u003cstrong\u003e4단계: 코드 컴파일 및 DEX 변환 (Code Compilation \u0026amp; Dexing)\u003c/strong\u003e":"이 단계에서는 Kotlin/Java 소스 코드를 컴파일하고, Android 런타임이 이해할 수 있는 DEX 파일로 변환합니다.\n\u003e Task :app:compileDebugKotlin\n역할: Kotlin 컴파일러(kotlinc)를 사용하여 프로젝트의 모든 .kt 파일을 .class 파일(자바 바이트코드)로 컴파일합니다. \u003e Task :app:compileDebugJavaWithJavac\n역할: Java 컴파일러(javac)를 사용하여 .java 파일을 .class 파일로 컴파일합니다. NO-SOURCE: 이 작업은 실행되었지만, 컴파일할 .java 소스 파일이 하나도 없었다는 의미입니다. 프로젝트가 100% Kotlin으로 작성되었을 가능성이 높습니다. \u003e Task :app:mergeDebugShaders, \u003e Task :app:compileDebugShaders\n역hal: OpenGL 셰이더(.glsl 파일)가 있다면 컴파일하고 병합합니다. (여기서는 NO-SOURCE이므로 셰이더 파일이 없습니다.) \u003e Task :app:mergeDebugAssets\n역할: assets 폴더의 내용물을 병합합니다. \u003e Task :app:checkDebugDuplicateClasses\n역할: 컴파일된 클래스 파일과 라이브러리들 사이에 중복된 클래스가 있는지 검사합니다. 중복 클래스는 앱 실행 시 충돌을 일으킬 수 있으므로 중요한 검증 과정입니다. \u003e Task :app:desugarDebugFileDependencies\n역할: Java 8 이상의 최신 언어 기능(람다, 스트림 API 등)을 이전 버전의 Android에서도 동작하도록 변환(Desugaring)하는 준비 작업을 합니다. d8 도구가 이 역할을 수행합니다. \u003e Task :app:dexBuilderDebug, \u003e Task :app:mergeProjectDexDebug, \u003e Task :app:mergeExtDexDebug, \u003e Task :app:mergeLibDexDebug\n역할: DEXing 단계입니다. d8 도구를 사용하여 프로젝트의 모든 .class 파일(내 코드 + 라이브러리 코드)을 Dalvik Executable(.dex) 파일로 변환합니다. .dex 파일은 Android 런타임(ART)이 실행하는 파일 형식입니다. 클래스 파일이 매우 많으면 여러 개의 .dex 파일로 나뉠 수 있으며, 이 작업들은 그것들을 병합하는 역할도 합니다.","5단계-네이티브-코드-및-최종-패키징-native-code--final-packaging#\u003cstrong\u003e5단계: 네이티브 코드 및 최종 패키징 (Native Code \u0026amp; Final Packaging)\u003c/strong\u003e":"이제 모든 재료(컴파일된 리소스, DEX 파일, 매니페스트 등)를 모아 최종 APK 파일을 만듭니다.\n\u003e Task :app:mergeDebugJniLibFolders \u0026 \u003e Task :app:mergeDebugNativeLibs\n역할: C/C++로 작성된 네이티브 라이브러리(.so 파일)가 있다면, 모든 소스(내 프로젝트, 라이브러리)에서 가져와 아키텍처별(arm64-v8a, x86_64 등)로 정리하여 병합합니다. \u003e Task :app:stripDebugDebugSymbols\n역할: 네이티브 라이브러리에서 디버깅 심볼을 제거하여 파일 크기를 줄입니다. (디버그 빌드에서는 보통 이 작업이 최소한으로 수행되거나 건너뜁니다.) \u003e Task :app:validateSigningDebug\n역할: APK에 서명할 준비가 되었는지 확인합니다. 디버그 빌드의 경우, 보통 SDK에 포함된 기본 디버그 키스토어로 자동 서명됩니다. \u003e Task :app:packageDebug\n역할: 최종 APK 생성 단계입니다. 지금까지 만들어진 모든 결과물—컴파일된 리소스(resources.ap_), DEX 파일, 최종 매니페스트, 네이티브 라이브러리(.so), assets—을 하나의 압축 파일(.apk)로 묶습니다. 이 단계에서 apksigner를 사용하여 디버그 키로 APK에 서명하고, zipalign으로 최적화하는 과정도 포함됩니다. \u003e Task :app:createDebugApkListingFileRedirect\n역할: 생성된 APK 파일의 내용물 목록을 담은 메타데이터 파일을 생성합니다. \u003e Task :app:assembleDebug\n역할: 최종 집계(aggregator) 작업입니다. 이 작업 자체는 아무 일도 하지 않지만, 디버그 APK를 만드는 데 필요한 위의 모든 작업들에 대한 의존성을 가지고 있습니다. 따라서 assembleDebug 작업이 성공적으로 완료되었다는 것은 디버그 APK가 성공적으로 생성되었음을 의미합니다.","빌드-단계별-상세-설명#\u003cstrong\u003e빌드 단계별 상세 설명\u003c/strong\u003e":"빌드 과정은 크게 리소스 처리 → 매니페스트 처리 → 코드 컴파일 → DEX 변환 → APK 패키징의 순서로 진행됩니다.","최종-결과#\u003cstrong\u003e최종 결과\u003c/strong\u003e":"BUILD SUCCESSFUL in 1s: 빌드가 1초 만에 성공적으로 완료되었습니다. 36 actionable tasks: 36 up-to-date: Gradle이 실행해야 할 작업은 총 36개였지만, 입력 파일이 변경되지 않았기 때문에 36개 모두 이전 결과물을 재사용하여 작업을 완료했다는 의미입니다. Build Analyzer results available: Android Studio는 이 빌드 과정의 성능을 분석한 결과를 제공합니다. 빌드가 느릴 때 원인을 파악하는 데 유용한 도구입니다.","핵심-개념-증분-빌드-incremental-build-와#\u003cstrong\u003e핵심 개념: 증분 빌드 (Incremental Build) 와 \u003ccode\u003eUP-TO-DATE\u003c/code\u003e\u003c/strong\u003e":"로그를 이해하기 전에 가장 중요한 개념은 Gradle의 증분 빌드 기능입니다.\n정의: Gradle은 각 작업(Task)의 입력(input)과 출력(output)을 기억합니다. 다음 빌드를 실행할 때, Gradle은 각 작업의 입력 파일(예: 소스 코드, 리소스 파일)이 마지막 빌드 이후 변경되었는지 확인합니다. UP-TO-DATE의 의미: 만약 입력 파일에 아무런 변경이 없다면, Gradle은 해당 작업을 다시 실행하는 대신 이전에 생성했던 출력물을 그대로 재사용합니다. 이때 로그에 UP-TO-DATE라고 표시됩니다. 결과: 이 기능 덕분에 코드를 전혀 수정하지 않고 다시 빌드하면, 모든 작업이 UP-TO-DATE가 되어 빌드가 매우 빠르게(로그에서는 1초) 완료됩니다."},"title":"android studio build sequence"},"/aop/":{"data":{"":"AOP(Aspect-Oriented Programming, 관점 지향 프로그래밍)는 소프트웨어 설계에서 횡단 관심사(Cross-cutting Concerns)를 효과적으로 분리하고 모듈화하기 위한 프로그래밍 패러다임입니다.","-advice의-종류-실행-시점-기준#📌 Advice의 종류 (실행 시점 기준)":"종류 설명 Before 대상 메서드 실행 전에 실행 After 대상 메서드 실행 후 (성공/실패 상관없이) After-returning 대상 메서드가 정상적으로 반환된 후 실행 After-throwing 대상 메서드에서 예외가 발생한 후 실행 Around 대상 메서드 전후를 완전히 감싸는 가장 강력한 형태 (실행 제어 가능)","-aop의-장점#✅ AOP의 장점":"핵심 로직과 횡단 관심사 분리 → 코드가 깔끔하고 집중도 높음 중복 제거 → DRY 원칙 준수 유지보수 용이 → 로깅 정책 변경 시 한 곳만 수정 유연한 확장 → 새로운 공통 기능을 쉽게 추가","-aop의-주요-용어#🧱 AOP의 주요 용어":"용어 설명 **Aspect **(관점) 횡단 관심사를 모듈화한 단위. 예: LoggingAspect, SecurityAspect **Join Point **(조인 포인트) 프로그램 실행 중 관점을 삽입할 수 있는 후보 지점 (예: 메서드 호출, 예외 발생 등) **Pointcut **(포인트컷) 실제로 관점을 적용할 조인 포인트를 필터링하는 표현식. (예: UserService의 모든 메서드) **Advice **(어드바이스) 포인트컷에서 실행될 실제 코드. 언제 실행될지에 따라 종류가 나뉨. **Weaving **(위빙) Aspect를 핵심 코드에 삽입하는 과정. 컴파일 시, 로드 시, 런타임 시 가능.","-예시-spring-aop-기준#💡 예시 (Spring AOP 기준)":"@Aspect @Component public class LoggingAspect { @Before(\"execution(* com.example.service.UserService.*(..))\") public void logBefore(JoinPoint joinPoint) { System.out.println(\"메서드 호출 전: \" + joinPoint.getSignature().getName()); } @Around(\"@annotation(LogExecutionTime)\") public Object logExecutionTime(ProceedingJoinPoint joinPoint) throws Throwable { long start = System.currentTimeMillis(); Object result = joinPoint.proceed(); // 원래 메서드 실행 long end = System.currentTimeMillis(); System.out.println(joinPoint.getSignature() + \" 실행 시간: \" + (end - start) + \"ms\"); return result; } } → UserService의 모든 메서드에 자동으로 로깅이 적용되며,\n핵심 로직에는 로깅 코드 한 줄도 없음!","-요약#📚 요약":"AOP는 “로깅, 보안, 트랜잭션 같은 공통 기능을 핵심 코드에서 분리해,\n마치 레고 블록처럼 붙일 수 있게 해주는 기술\"입니다.\n이를 통해 관심사의 분리(SoC), 높은 응집도, 낮은 결합도를 실현할 수 있습니다.\n궁금한 부분(예: Spring에서의 사용법, 다른 언어 예시 등)이 있다면 알려주세요!","-주의-사항#⚠️ 주의 사항":"과도한 사용은 디버깅을 어렵게 함 (실행 흐름이 명시적이지 않음) 런타임 위빙은 성능 오버헤드 발생 가능 모든 언어에서 네이티브 지원하지 않음 (Java: Spring AOP, AspectJ / C#: PostSharp / Python: 데코레이터로 유사 구현 등)","-핵심-아이디어#🔍 핵심 아이디어":"문제: 로깅, 보안, 트랜잭션, 예외 처리 같은 기능은 여러 모듈에 걸쳐 중복되며,\n이로 인해 핵심 비즈니스 로직이 흐려지고, 유지보수가 어려워집니다. 해결: AOP는 이런 공통 관심사를 별도의 “관점(Aspect)으로 추출하여,\n원래 코드(핵심 로직)와 분리해서 관리할 수 있게 해줍니다. 💡 AOP는 OOP(객체 지향 프로그래밍)를 보완하는 개념입니다.\nOOP는 “무엇을 하는가?\"(객체와 책임)에 집중한다면,\nAOP는 “언제, 어디서 공통 동작을 수행할 것인가?“에 집중합니다."},"title":"AOP"},"/copilot/copilot-custom-prompts/emojify/":{"data":{"":"Add relevant emojis to enhance {}. Follow these rules: 1. Insert emojis at natural breaks in the text 2. Never place two emojis next to each other 3. Keep all original text unchanged 4. Choose emojis that match the context and tone Return only the emojified text."},"title":"Emojify"},"/copilot/copilot-custom-prompts/explain-like-i-am-5/":{"data":{"":"Explain {} in simple terms that a 5-year-old would understand: 1. Use basic vocabulary 2. Include simple analogies 3. Break down complex concepts Return only the simplified explanation."},"title":"Explain like I am 5"},"/copilot/copilot-custom-prompts/fix-grammar-and-spelling/":{"data":{"":"Fix the grammar and spelling of {}. Preserve all formatting, line breaks, and special characters. Do not add or remove any content. Return only the corrected text."},"title":"Fix grammar and spelling"},"/copilot/copilot-custom-prompts/generate-glossary/":{"data":{"":"Create a glossary of important terms, concepts, and phrases from {}. Format each entry as “Term: Definition”. Sort entries alphabetically. Return only the glossary."},"title":"Generate glossary"},"/copilot/copilot-custom-prompts/generate-table-of-contents/":{"data":{"":"Generate a hierarchical table of contents for {}. Use appropriate heading levels (H1, H2, H3, etc.). Include page numbers if present. Return only the table of contents."},"title":"Generate table of contents"},"/copilot/copilot-custom-prompts/make-longer/":{"data":{"":"Expand {} to twice its length by: 1. Adding relevant details and examples 2. Elaborating on key points 3. Maintaining the original tone and style Return only the expanded text."},"title":"Make longer"},"/copilot/copilot-custom-prompts/remove-urls/":{"data":{"":"Remove all URLs from {}. Preserve all other content and formatting. URLs may be in various formats (http, https, www). Return only the text with URLs removed."},"title":"Remove URLs"},"/copilot/copilot-custom-prompts/rewrite-as-tweet-thread/":{"data":{"":"Convert {} into a Twitter thread following these rules: 1. Each tweet must be under 240 characters 2. Start with “THREAD START” on its own line 3. Separate tweets with \"\n\" 4. End with “THREAD END” on its own line 5. Make content engaging and clear Return only the formatted thread."},"title":"Rewrite as tweet thread"},"/copilot/copilot-custom-prompts/rewrite-as-tweet/":{"data":{"":"Rewrite {} as a single tweet with these requirements: 1. Maximum 280 characters 2. Use concise, impactful language 3. Maintain the core message Return only the tweet text."},"title":"Rewrite as tweet"},"/copilot/copilot-custom-prompts/simplify/":{"data":{"":"Simplify {} to a 6th-grade reading level (ages 11-12). Use simple sentences, common words, and clear explanations. Maintain the original key concepts. Return only the simplified text."},"title":"Simplify"},"/copilot/copilot-custom-prompts/summarize/":{"data":{"":"Create a bullet-point summary of {}. Each bullet point should capture a key point. Return only the bullet-point summary."},"title":"Summarize"},"/copilot/copilot-custom-prompts/translate-to-chinese/":{"data":{"":"Translate {} into Chinese: 1. Preserve the meaning and tone 2. Maintain appropriate cultural context 3. Keep formatting and structure Return only the translated text."},"title":"Translate to Chinese"},"/html-%ED%99%94%EB%A9%B4-z-%EC%B6%95/":{"data":{"":"✦ 네, 더 자세히 설명해 드리겠습니다. 이 현상은 웹 브라우저가 요소를 화면에 그리는 방식, 특히 **스태킹 컨텍스트(Stacking Context)**와 z-index라는 개념 때문에 발생합니다. 그리고 검색 결과가 가리지 않는 이유는 검색창과 검색 결과 항목의 CSS position 속성 차이 때문입니다.","코드를-변경하면-해결되는-원리#코드를 변경하면 해결되는 원리":"제안 드린 해결책은 탭 바의 쌓임 순서를 가장 명확하고 강력하게 지정하는 것입니다.\nz-10 클래스 추가: index.html의 sticky 속성을 가진 탭 바 div에 z-10 클래스를 추가하면, 이 요소에는 z-index: 10;이라는 CSS 속성이 적용됩니다.\n명시적인 스태킹 컨텍스트 형성: position: sticky와 z-index: 10이 함께 적용되면서, 탭 바는 ‘레벨 10’의 가장 확실하고 강력한 독립된 스태킹 컨텍스트를 형성합니다.\n쌓임 순서 정리:\n탭 바: 이제 ‘레벨 10’에 위치하게 됩니다. 검색창 컨테이너: position: relative로 스태킹 컨텍스트를 형성하지만, z-index가 명시되지 않았으므로 ‘레벨 0’ (기본 레벨)에 머무릅니다. 브라우저의 기본 규칙에 따라 z-index: auto는 명시된 z-index 값보다 낮은 것으로 간주됩니다. 검색 결과: position: static이므로 스태킹 컨텍스트를 형성하지 않으며, z-index는 적용되지 않습니다. ‘레벨 0’보다도 더 기본층에 속합니다. 결과: 이제 브라우저는 명확한 지시를 받았습니다. 스크롤이 일어나 검색창이나 검색 결과가 탭 바 위치로 올라오더라도, ‘레벨 0’ 이하에 있는 검색창과 검색 결과는 ‘레벨 10’에 있는 탭 바의 아래를 지나가게 됩니다. 따라서 더 이상 탭 바를 덮는 현상이 발생하지 않습니다.\n결론적으로, z-index를 추가하는 것은 “이 탭 바는 다른 어떤 요소보다 항상 위에 있어야 해!“라고 브라우저에게 명확하게 알려주는 행위이며, 이를 통해 position 속성으로 인해 발생할 수 있는 모든 모호했던 요소 간의 상하 관계를 가장 확실하게 바로잡는 것입니다. position: relative가 적용된 검색창뿐만 아니라, 향후 다른 position 속성을 가진 요소들이 추가되더라도 탭 바는 항상 최상단에 유지될 것입니다.","현상이-발생하는-원리---왜-검색창만-가리는가#현상이 발생하는 원리 - 왜 검색창만 가리는가?":"웹 페이지의 요소들은 단순히 2차원 평면에 있는 것이 아니라, 3차원 공간처럼 서로 겹쳐질 수 있는 ‘레이어(layer)’ 구조를 가집니다. 어떤 요소가 다른 요소의 위나 아래에 그려질지 결정하는 규칙이 바로 ‘스태킹(쌓임) 순서’입니다.\n기본 쌓임 순서: 기본적으로 HTML 코드에서 나중에 나오는 요소가 먼저 나온 요소보다 위에 쌓입니다.\n스태킹 컨텍스트의 형성: 특정 CSS 속성은 요소와 그 자식들을 위한 ‘독립된 레이어 그룹’을 만드는데, 이를 스태킹 컨텍스트라고 합니다.\n대표적으로 position 속성이 relative, absolute, fixed, sticky이면서 z-index가 auto가 아닌 값을 가질 때 (또는 z-index가 없더라도 특정 조건에서), 또는 opacity가 1 미만일 때 등이 스태킹 컨텍스트를 형성합니다. 중요한 점은 position: relative만으로도 z-index 없이 스태킹 컨텍스트를 형성할 수 있으며, 이는 때때로 예상치 못한 쌓임 순서를 야기할 수 있다는 것입니다. 현재 문제 상황 분석:\n탭 바 ( 또는 div): position: sticky 속성을 가지고 있습니다. 이 속성은 스크롤될 때 화면 특정 위치에 ‘달라붙게’ 만듭니다. 하지만 z-index 값이 명시적으로 지정되지 않았습니다. sticky 요소는 스태킹 컨텍스트를 형성하지만, z-index: auto일 경우, 다른 요소들과의 쌓임 순서가 모호해질 수 있습니다. 특히 아래 설명할 position: relative 요소와 만났을 때 브라우저 렌더링 엔진이 헷갈리는 경우가 발생합니다.\n검색창 (): .src/js/ui/search-ui.js에서 생성되는 검색창은 다음과 같은 구조를 가집니다:\n\u003cdiv class=\"mb-4\"\u003e \u003cdiv class=\"relative\"\u003e \u003cinput type=\"text\" id=\"searchInput\" ...\u003e ... \u003c/div\u003e \u003c/div\u003e class=\"relative\"는 해당 div에 position: relative; 속성을 적용합니다. 이 position: relative 속성은 z-index가 명시되지 않더라도 새로운 스태킹 컨텍스트를 형성합니다.\n검색 결과 (): 검색 결과 항목들은 position 속성이 명시적으로 지정되어 있지 않습니다. 즉, 기본값인 position: static을 가집니다. static 요소는 새로운 스태킹 컨텍스트를 형성하지 않으며, 일반적인 문서 흐름과 쌓임 순서를 따릅니다.\n겹침 발생 원인 (검색창만 해당):\n사이드바 내부에서 스크롤이 발생하면, ‘스크롤되는 콘텐츠’ 영역(검색창 포함)과 ‘상단에 고정된’ 영역(탭 바)이 겹치게 됩니다. 이때, z-index가 없는 position: sticky 탭 바와 z-index가 없는 position: relative 검색창 컨테이너가 만나게 됩니다. 이 두 요소 모두 스태킹 컨텍스트를 형성하지만, 어느 쪽이 더 높은지 명확한 우선순위가 없습니다. 이러한 모호한 상황에서 브라우저의 렌더링 엔진은 position: relative를 가진 요소를 (비록 z-index가 auto여도) position: sticky만 있는 요소보다 더 ‘앞으로’ 가져오려는 경향이 있습니다. 따라서 스크롤되어 움직이는 검색창이 sticky로 고정만 되어있는 탭 바보다 높은 레이어로 판단되어 위로 올라타는 현상이 발생하는 것입니다. 검색 결과는 position: static이므로 스태킹 컨텍스트를 형성하지 않고, 일반적인 문서 흐름에 따라 sticky 요소의 아래로 자연스럽게 지나갑니다. 그래서 검색 결과는 탭 바를 가리지 않는 것입니다. 쉽게 비유하자면, 투명한 필름(요소) 여러 장을 겹쳐 놓았는데, 각 필름의 상하 관계(z-index)를 명확히 지정해주지 않은 상황과 같습니다. 특히, ‘강력한 접착제’(position: relative 또는 absolute 같은 속성)를 사용한 필름이 ‘약한 접착제’(position: sticky만 있는 경우)를 사용한 필름보다 더 튀어나와 보이는 경향이 있는 것입니다."},"title":"html 화면 z 축"},"/java-type-%ED%99%95%EC%9D%B8%EB%B2%95/":{"data":{"":"Java에는 JavaScript나 C++ 같은 언어에서 사용하는 typeof 연산자와 정확히 동일한 문법적 연산자가 없습니다. Java는 정적 타입 언어(statically typed language)이기 때문에, 컴파일 시점에 변수의 타입이 결정되며, 런타임에 타입을 “확인\"하는 것이 일반적인 용도가 아닙니다. 하지만 Java에서는 런타임에 객체의 타입을 확인할 수 있는 여러 가지 방법이 있습니다.\n아래에 Java에서 타입(type)을 확인할 수 있는 모든 주요 방법을 정리해 드립니다.","-1-instanceof-연산자--가장-흔한-타입-확인-방법#✅ 1. \u003ccode\u003einstanceof\u003c/code\u003e 연산자 — 가장 흔한 타입 확인 방법":"Object obj = \"Hello\"; if (obj instanceof String) { System.out.println(\"obj는 String 타입입니다.\"); } else if (obj instanceof Integer) { System.out.println(\"obj는 Integer 타입입니다.\"); }","-2-getclass-메서드--실제-실행-타입-얻기#✅ 2. \u003ccode\u003egetClass()\u003c/code\u003e 메서드 — 실제 실행 타입 얻기":"Object obj = new ArrayList\u003cString\u003e(); Class\u003c?\u003e clazz = obj.getClass(); System.out.println(clazz.getName()); // java.util.ArrayList","-3-classisinstance-메서드--instanceof의-반대-버전#✅ 3. \u003ccode\u003eClass.isInstance()\u003c/code\u003e 메서드 — \u003ccode\u003einstanceof\u003c/code\u003e의 반대 버전":"Class\u003cString\u003e stringClass = String.class; Object obj = \"hello\"; if (stringClass.isInstance(obj)) { System.out.println(\"obj는 String입니다\"); }","-4-classisassignablefrom--상속구현-관계-확인#✅ 4. \u003ccode\u003eClass.isAssignableFrom()\u003c/code\u003e — 상속/구현 관계 확인":"Class\u003cAnimal\u003e animalClass = Animal.class; Class\u003cDog\u003e dogClass = Dog.class; System.out.println(animalClass.isAssignableFrom(dogClass)); // true System.out.println(dogClass.isAssignableFrom(animalClass)); // false","-5-type-및-parameterizedtype--제네릭-타입-정보-확인-리플렉션#✅ 5. \u003ccode\u003eType\u003c/code\u003e 및 \u003ccode\u003eParameterizedType\u003c/code\u003e — 제네릭 타입 정보 확인 (리플렉션)":"import java.lang.reflect.*; import java.util.List; public class GenericTypeExample { public List\u003cString\u003e list; public static void main(String[] args) throws Exception { Field field = GenericTypeExample.class.getDeclaredField(\"list\"); Type genericType = field.getGenericType(); if (genericType instanceof ParameterizedType) { ParameterizedType pt = (ParameterizedType) genericType; Type rawType = pt.getRawType(); // java.util.List Type[] typeArgs = pt.getActualTypeArguments(); // [java.lang.String] System.out.println(\"Raw type: \" + rawType); System.out.println(\"Type arg: \" + typeArgs[0]); // class java.lang.String } } }","-6-switch-문--instanceof-java-17-패턴-매칭#✅ 6. \u003ccode\u003eswitch\u003c/code\u003e 문 + \u003ccode\u003einstanceof\u003c/code\u003e (Java 17+ 패턴 매칭)":"Java 17부터 instanceof와 switch를 결합한 패턴 매칭 기능이 도입되었습니다:\nObject obj = \"Hello\"; switch (obj) { case String s -\u003e System.out.println(\"문자열: \" + s.toUpperCase()); case Integer i -\u003e System.out.println(\"정수: \" + i * 2); case null -\u003e System.out.println(\"null입니다\"); default -\u003e System.out.println(\"알 수 없는 타입: \" + obj.getClass().getSimpleName()); } 이 방식은 instanceof + 캐스팅을 자동으로 해주는 안전하고 간결한 문법입니다.","-7-objectstostring-또는-stringvalueof--타입-정보-출력#✅ 7. \u003ccode\u003eObjects.toString()\u003c/code\u003e 또는 \u003ccode\u003eString.valueOf()\u003c/code\u003e — 타입 정보 출력":"Object obj = new HashMap\u003c\u003e(); System.out.println(obj); // { } → toString() 호출 System.out.println(obj.getClass().getSimpleName()); // HashMap System.out.println(String.valueOf(obj.getClass())); // class java.util.HashMap toString()은 보통 클래스명을 포함하므로 간접적으로 타입 확인 가능","-8-classgetsimplename--getcanonicalname--gettypename#✅ 8. \u003ccode\u003eClass.getSimpleName()\u003c/code\u003e / \u003ccode\u003egetCanonicalName()\u003c/code\u003e / \u003ccode\u003egetTypeName()\u003c/code\u003e":"Class\u003c?\u003e c = String.class; System.out.println(c.getSimpleName()); // String System.out.println(c.getCanonicalName()); // java.lang.String System.out.println(c.getTypeName()); // java.lang.String getSimpleName(): 단순 클래스명 getCanonicalName(): 패키지 포함 표준 이름 getTypeName(): 제네릭 타입까지 표현 가능 (Java 8+)","-java에는-typeof가-없다#❌ Java에는 \u003ccode\u003etypeof\u003c/code\u003e가 없다!":"언어 typeof JavaScript typeof x === \"string\" ✅ C# typeof(string) ✅ (컴파일 타임) Java ❌ 없음 Java는 컴파일 타임 타입 검사가 강력하기 때문에, typeof처럼 변수의 선언 타입을 문자열로 얻는 기능이 없습니다.\n💡 Java에서 String.class는 클래스 객체이고, typeof처럼 타입 이름 문자열을 얻는 게 아님.","-실무-팁#💡 실무 팁":"instanceof → 대부분의 경우 최선의 선택 getClass() → 정확한 클래스 비교가 필요할 때 (예: HashMap vs LinkedHashMap) 리플렉션 → 프레임워크 개발 시 사용 (Spring, Jackson, Hibernate 등) 패턴 매칭 → Java 17 이상이라면 switch로 타입 분기를 깔끔하게!","-예시-instanceof-vs-getclass-차이#✅ 예시: \u003ccode\u003einstanceof\u003c/code\u003e vs \u003ccode\u003egetClass()\u003c/code\u003e 차이":"class Animal {} class Cat extends Animal {} Cat cat = new Cat(); System.out.println(cat instanceof Animal); // true System.out.println(cat.getClass() == Animal.class); // false System.out.println(cat.getClass() == Cat.class); // true → instanceof는 상속 포함, getClass()는 정확한 클래스만\n필요에 따라 적절한 메서드를 선택하세요!\nJava는 typeof가 없지만, 위의 다양한 도구들로 충분히 타입을 안전하고 정밀하게 다룰 수 있습니다.","-요약-java에서-타입-확인-방법-정리#🔍 요약: Java에서 타입 확인 방법 정리":"방법 설명 사용 목적 null 안전? instanceof 객체가 특정 타입 또는 하위 타입인지 확인 일반적인 타입 체크 ✅ (null → false) getClass() 실제 런타임 클래스 객체 가져오기 정확한 클래스 비교 ✅ Class.isInstance() 클래스 객체로 객체 타입 확인 리플렉션 환경 ✅ Class.isAssignableFrom() 상속/구현 관계 확인 API 설계, 프레임워크 ✅ switch + instanceof (Java 17+) 다중 타입 분기 간결한 타입 분기 로직 ✅ ParameterizedType 제네릭 타입 파라미터 추출 커스텀 직렬화, ORM 등 ✅ (정보 존재 시) getSimpleName(), getTypeName() 타입 이름 출력 디버깅, 로깅 -","특징#특징:":"null과 비교하면 항상 false를 반환. 컴파일 시점에 타입 호환성이 없는 경우 컴파일 에러 발생 (예: String instanceof Integer) 상속 관계도 인식: instanceof는 부모 클래스/인터페이스에도 true를 반환함. class Animal {} class Dog extends Animal {} Dog dog = new Dog(); System.out.println(dog instanceof Animal); // true System.out.println(dog instanceof Dog); // true 📌 JavaScript의 typeof와 유사한 용도로 자주 사용됨","특징-1#특징:":"Object 클래스의 메서드로, 모든 객체에 사용 가능 정확한 런타임 타입(concrete class)을 반환 instanceof와 달리 부모 타입은 포함하지 않음 Dog dog = new Dog(); System.out.println(dog.getClass().getName()); // Dog (Animal 아님!)","특징-2#특징:":"instanceof의 반대 방향으로 사용 (클래스 객체 → 객체 확인) 리플렉션(Reflection) 상황에서 유용 null 처리: isInstance(null) → false","특징-3#특징:":"A.isAssignableFrom(B) → B가 A의 하위 타입(또는 같음)인가? 상속 계층 구조를 체크할 때 유용 List.class.isAssignableFrom(ArrayList.class) → true","특징-4#특징:":"제네릭 타입 파라미터(예: List)의 실제 타입을 런타임에 알 수 있음 타입 추출(Type Erasure) 후에도 제네릭 정보가 필드/메서드/생성자에 저장되어 있을 때만 가능 컴파일된 .class 파일에 제네릭 정보가 남아 있어야 함 (디버그 옵션 등)","활용-예-타입-이름-비교#활용 예: 타입 이름 비교":"if (obj.getClass().equals(String.class)) { System.out.println(\"String입니다\"); } ⚠️ == 대신 .equals()를 써야 함. Class 객체는 참조 비교가 아니라 내용 비교가 필요."},"title":"java type 확인법"},"/leetcode-sql-%EB%AC%B8%EC%A0%9C-%ED%92%80%EA%B8%B0/%EB%8C%80%EC%9E%A5%EA%B7%A0-%EC%9E%90%EC%8B%9D-%EC%88%98-%EA%B5%AC%ED%95%98%EA%B8%B0/":{"data":{"":"https://school.programmers.co.kr/learn/courses/30/lessons/299305\njoin 방식으로 풀기\nSELECT a.id, COUNT(b.parent_id) AS child_count FROM ecoli_data a LEFT JOIN ecoli_data b ON a.ID = b.parent_id GROUP BY a.ID ORDER BY a.id subquery\nSELECT E.ID, ( SELECT COUNT(*) FROM ECOLI_DATA AS ED WHERE ED.PARENT_ID = E.ID ) AS CHILD_COUNT FROM ECOLI_DATA E ORDER BY E.ID; CTE"},"title":"대장균 자식 수 구하기"},"/leetcode-sql-%EB%AC%B8%EC%A0%9C-%ED%92%80%EA%B8%B0/leetcode-sql-%EB%AC%B8%EC%A0%9C/":{"data":{"":"","1211#1211":"그룹으로 묶인 것의 선택적으로 조건을 적용\nselect query_name, round( avg(rating/position),2 ) as quality, round( avg( (case when rating \u003c 3 then 1 else 0 end ) ) * 100 ,2) as poor_query_percentage from Queries group by query_name having query_name is not null month | country | trans_count | approved_count | trans_total_amount | approved_total_amount","1251-멸망#1251 멸망":"가격의 평균을 구하되 units 의 개수에 따른 가중치를 계산해주어야 한다\nselect product_id , round(avg(up)/sum(units),2) as average_price from (select p.product_id , units , units *price from prices as p join unitssold as u on p.product_id = u.product_id and u.purchase_date BETWEEN start_date and end_date group by p.product_id, units , price) as temp(product_id, units, up) group by product_id SELECT p.product_id, round(SUM(p.price * u.units) / SUM(u.units),2) AS average_price FROM prices AS p JOIN unitssold AS u ON p.product_id = u.product_id AND u.purchase_date BETWEEN p.start_date AND p.end_date GROUP BY p.product_id; SELECT p.product_id, ROUND(SUM(p.price * u.units) OVER (PARTITION BY p.product_id) / SUM(u.units) OVER (PARTITION BY p.product_id), 2) AS average_price FROM prices AS p JOIN unitssold AS u ON p.product_id = u.product_id AND u.purchase_date BETWEEN p.start_date AND p.end_date; product_id start_date end_date price product_id purchase_date units 1 2019-02-17 2019-02-28 5 1 2019-02-25 100 1 2019-03-01 2019-03-22 20 1 2019-03-01 15 2 2019-02-01 2019-02-20 15 2 2019-02-10 200 2 2019-02-21 2019-03-31 30 2 2019-03-22 30","1280#1280":"참여한 시험이 0개를 어떻게 표현하지 join 풀이\nselect st.student_id, st.student_name, su.subject_name, COUNT(e.subject_name) AS attended_exams from Students AS st CROSS JOIN Subjects AS su left JOIN Examinations AS e ON st.student_id = e.student_id and su.subject_name = e.subject_name group by st.student_name, su.subject_name order by st.student_id, su.subject_name Coalese 함수 사용 속도와 null 의 적절한 처리를 위해 미리 exam 테이블의 개수를 세서 조인한다 또한 Coalese 함수 또는 NVL 사용해서 적절한 null 값 처리를 한다\nSELECT s.student_id, s.student_name, sub.subject_name, COALESCE(e.attended_exams, 0) AS attended_exams FROM Students s CROSS JOIN Subjects sub LEFT JOIN ( SELECT student_id, subject_name, COUNT(*) AS attended_exams FROM Examinations GROUP BY student_id, subject_name ) e ON s.student_id = e.student_id AND sub.subject_name = e.subject_name ORDER BY s.student_id, sub.subject_name;","1581-문제#1581 문제":"not in 으로 풀기\nSELECT customer_id, count(*) 'count_no_trans' FROM visits as vi where visit_id not in ( select visit_id from Transactions ) group by customer_id left join 으로 풀기\nselect * from Visits as vi left join Transactions as tr on vi.visit_id = tr.visit_id where tr.visit_id is null --거래기록이 없는 사람 제외 group by customer_id","1633#1633":"null 이 존재하는 culumn 의 속성을 group 으로 묶으면? 애초에 고민을 할 필요가 없는 문제 join 할 필요가 없다\nselect contest_id, round( count(user_id) / ( select count(*) from users) , 4) * 100 as percentage from register group by contest_id order by percentage desc, contest_id","1934-개같이-멸망#1934 개같이 멸망":"요청조차 하지 않은 사용자의 비율 계산처리??\nselect s.user_id, round(avg (case when action = 'confirmed' then 1 else 0 end), 2) as confirmation_rate from signups as s left join confirmations as c on s.user_id = c.user_id group by s.user_id round 소수점 숫자 정확도 정해주기 avg 를 사용하는 방법임 나는 나누기로 할려고 했지만…\nSELECT s.user_id, COALESCE( ROUND( COUNT ( CASE WHEN c.action = 'confirmed' THEN 1 END) * 1.0 / COUNT(c.user_id),2) ,0) AS confirmation_rate FROM signups AS s LEFT JOIN confirmations AS c ON s.user_id = c.user_id GROUP BY s.user_id; 끝까지 나누기로 풀기","570#570":"미리 계산\nwith cte as (select t.id, count(s.id) as cnt from Employee as s join Employee as t on s.managerId = t.id group by s.managerId) select name from Employee as e join cte on e.id = cte.id where cte.cnt is not null join \u0026 group by\nselect t.name from Employee as s join Employee as t on s.managerId = t.id group by s.managerId having count(s.id) is not null and count(s.id) \u003e= 5 미친 깔끔\nSELECT name FROM Employee WHERE id IN ( SELECT managerId FROM Employee GROUP BY managerId HAVING COUNT(*) \u003e= 5)"},"title":"leetcode sql 문제"},"/leetcode75/%EC%8A%AC%EB%9D%BC%EC%9D%B4%EB%94%A9-%EC%9C%88%EB%8F%84%EC%9A%B0/":{"data":{"more-similar-sliding-window-problems#More Similar Sliding Window Problems":"매순간 특정 범위의 계산을 다시 할 필요가 없음(ex 합)\ndatabase 의 SUM 과 같은 함수 쿼리 최적화 시에 작동하는 것과 비슷하다\nMore Similar Sliding Window Problems1004. Max Consecutive Ones III 1493. Longest Subarray of 1’s After Deleting One Element\nCount Number of Nice Subarrays Replace the Substring for Balanced String Max Consecutive Ones III Binary Subarrays With Sum Subarrays with K Different Integers Fruit Into Baskets Shortest Subarray with Sum at Least K Minimum Size Subarray Sum"},"title":"슬라이딩 윈도우"},"/leetcode75/11.-container-with-most-water/":{"data":{"":"완전 탐색의 $O(n^2)$ 시간 탐색을 선형시간 $O(n)$ 으로 변경\n완전 탐색 풀이\nclass Solution { public: int maxArea(vector\u003cint\u003e\u0026 height) { int ret = 0; for(int i = 0 ; i\u003c height.size()-1 ; i++){ for(int j = i + 1; j \u003c height.size() ; j++){ int width = j - i; int length = min(height[i], height[j]); int area = width * length; if(ret \u003c area) ret = area; } } return ret; } }; 이 문제를 선형시간으로 풀 수 있는 이유 2개의 포인터를 양쪽 끝으로 지정하고 포인터(넓은 의미의)를 이동 시킬 때(width 크기가 큰것 부터 작은 순으로 탐색), 만약 left 위치의 높이가 작다고 가정할 때 right 위치를 줄이면 width 가 줄어들기 때문에 총 넓이가 무조건 작다고 할 수 있다 만약 height[right] 가 height[left] 보다 작더라 하더라도 더 작아진다고 할 수 있으므로 넓이가 작아지는 것은 확실 그러므로 가짓수를 확실 하게 쳐 낼 수 있다\n결론 이미 해당 높이의 최대 영역을 가지고 있기 때문\nclass Solution { public: int maxArea(vector\u003cint\u003e\u0026 height) { int left = 0; int right = height.size() - 1; int max_area = 0; while(left \u003c right){ // 넓이 구하기 int w = right - left; int h = min(height[left], height[right]); int area = h * w; max_area = max(max_area, area); // 포인터 이동 if(height[left] \u003c height[right]) left++; else if(height[left] \u003e height[right]) right--; else { left++; right--; } } return max_area; } };"},"title":"11. Container With Most Water"},"/leetcode75/1493.-longest-subarray-of-1s-after-deleting-one-element/":{"data":{"":"","on-sliding-window#O(n) sliding window":"아직 $O(n^2)$ 이다 부분배열의 관찰 이므로 sliding window 를 통해 최적화 할 수 없을까??\nclass Solution { public: int longestSubarray(vector\u003cint\u003e\u0026 nums) { int ret = 0; int start = 0; int zero_count = 0; for(int end = 0 ; end \u003c nums.size(); end++){ if(nums[end] == 0) zero_count++; while(zero_count \u003e 1) if(nums[start++] == 0) zero_count--; ret = max(ret, end - start); } return ret; } };","on2#O(n^2)":"zero_count 를 각 부분배열에서 다시 계산해야 할까?? 부분배열의 시작 인덱스에서 반복이 실행되므로 끝 인덱스의 값만 확인하면서 0 개수를 저장해도 되지 않을까?\nclass Solution { public: int longestSubarray(vector\u003cint\u003e\u0026 nums) { int ret = 0; for(int start = 0; start \u003c nums.size(); start++){ int zero_count = 0; for(int end = start; end \u003c nums.size(); end++){ // 부분 배열의 0 개수 찾기 if(nums[end] == 0) zero_count++; if(zero_count == 0 || zero_count == 1) ret = max(ret, end - start); } } return ret; } };","on3#O(n^3)":"class Solution { public: int longestSubarray(vector\u003cint\u003e\u0026 nums) { int ret = 0; for(int start = 0; start \u003c nums.size(); start++){ for(int end = start; end \u003c nums.size(); end++){ int zero_count = 0; // 부분 배열의 0 개수 찾기 for(int i = start ; i \u003c= end ; i++){ if(nums[i] == 0) zero_count++; } if(zero_count == 0 || zero_count == 1) ret = max(ret, end - start); } } return ret; } };","동적계획법#동적계획법":"추가 : 동적계획법으로 푸는 방법\n#ModificationRequired\nclass Solution { public: int longestSubarray(vector\u003cint\u003e\u0026 nums) { vector\u003cint\u003e dp = {0}; int maximum = 0; for (int i = 0; i \u003c nums.size(); ++i) { if (nums[i] == 1) dp.push_back(dp[i] + 1); else dp.push_back(0); } if (dp.back() + 1 == dp.size()) return dp.back() - 1; for (int i = dp.size()-1; i \u003e= 0; --i) { if (dp[i] != 0) { if (i - dp[i] - 1 \u003e= 0) maximum = max(maximum, dp[i] + dp[i - dp[i] - 1]); else maximum = max(maximum, dp[i]); i -= dp[i]; } } return maximum; } };","문제#문제":"주어진 문제는 이진 배열 nums에서 하나의 요소를 삭제한 후, 결과 배열에서 1로만 이루어진 가장 긴 비어 있지 않은 부분 배열의 크기를 반환하는 것입니다. 만약 그런 부분 배열이 존재하지 않으면 0을 반환합니다. ### 예시: 1. **입력**: nums = [1, 1, 0, 1] **출력**: 3 **설명**: 인덱스 2의 숫자를 삭제하면 [1, 1, 1]이 되어 1의 개수가 3입니다. 2. **입력**: nums = [0, 1, 1, 1, 0, 1, 1, 0, 1] **출력**: 5 **설명**: 인덱스 4의 숫자를 삭제하면 [0, 1, 1, 1, 1, 1, 0, 1]이 되어 1의 개수가 5입니다. 3. **입력**: nums = [1, 1, 1] **출력**: 2 **설명**: 하나의 요소를 삭제해야 하므로, 최대 1의 개수는 2입니다. ### 제약 조건: - 1 \u003c= nums.length \u003c= 10^5 - nums[i]는 0 또는 1입니다."},"title":"1493. Longest Subarray of 1's After Deleting One Element"},"/leetcode75/2095.-delete-the-middle-node-of-a-linked-list/":{"data":{"":"","답#답":"일반적 접근\n/** * Definition for singly-linked list. * struct ListNode { * int val; // 노드의 값 * ListNode *next; // 다음 노드를 가리키는 포인터 * ListNode() : val(0), next(nullptr) {} // 기본 생성자 * ListNode(int x) : val(x), next(nullptr) {} // 값만 초기화하는 생성자 * ListNode(int x, ListNode *next) : val(x), next(next) {} // 값과 다음 노드를 초기화하는 생성자 * }; */ class Solution { public: ListNode* deleteMiddle(ListNode* head) { // Edge case: 리스트에 노드가 하나만 있는 경우 nullptr 반환 if (head == nullptr || head-\u003enext == nullptr) { return nullptr; // 노드가 없거나 하나뿐이면 삭제 후 nullptr 반환 } // Step 1: 연결 리스트의 길이 계산 int length = 0; // 리스트 길이를 저장할 변수 ListNode* temp = head; // 임시 포인터를 사용하여 리스트 순회 while (temp != nullptr) { // 리스트의 끝까지 이동 length++; // 노드 수 카운트 temp = temp-\u003enext; // 다음 노드로 이동 } // Step 2: 중간 노드의 인덱스 계산 (0-based) int mid = length / 2; // 중간 노드의 인덱스 계산 // Step 3: 중간 노드 바로 전 노드까지 이동 temp = head; // 다시 head부터 시작 for (int i = 0; i \u003c mid - 1; i++) { // 중간 노드 바로 전까지 이동 temp = temp-\u003enext; // 다음 노드로 이동 } // Step 4: 중간 노드 삭제 ListNode* toDelete = temp-\u003enext; // 삭제할 중간 노드를 저장 temp-\u003enext = temp-\u003enext-\u003enext; // 중간 노드를 건너뛰도록 연결 변경 delete toDelete; // 메모리 해제 (C++에서는 선택 사항) return head; // 수정된 리스트의 head 반환 } }; 투포인터 접근\n/** * Definition for singly-linked list. * struct ListNode { * int val; // 노드의 값 * ListNode *next; // 다음 노드를 가리키는 포인터 * ListNode() : val(0), next(nullptr) {} // 기본 생성자 * ListNode(int x) : val(x), next(nullptr) {} // 값만 초기화하는 생성자 * ListNode(int x, ListNode *next) : val(x), next(next) {} // 값과 다음 노드를 초기화하는 생성자 * }; */ class Solution { public: ListNode* deleteMiddle(ListNode* head) { // Edge case: 리스트에 노드가 하나만 있는 경우 nullptr 반환 if (head == nullptr || head-\u003enext == nullptr) { return nullptr; // 노드가 없거나 하나뿐이면 중간 노드를 삭제한 후 nullptr을 반환합니다. } // 더미 노드 생성 ListNode* prev = new ListNode(0, head); // 더미 노드(prev)를 생성하고, next를 head로 설정합니다. // 이는 중간 노드를 삭제할 때 편리하게 처리하기 위함입니다. ListNode* slow = prev; // slow 포인터를 더미 노드로 초기화합니다. ListNode* fast = head; // fast 포인터를 head로 초기화합니다. // 투 포인터 기법으로 중간 노드 찾기 while (fast != nullptr \u0026\u0026 fast-\u003enext != nullptr) { slow = slow-\u003enext; // slow는 한 칸씩 이동합니다. fast = fast-\u003enext-\u003enext; // fast는 두 칸씩 이동합니다. } // 임시 보관 ListNode* toDelete = slow-\u003enext; // 삭제할 중간 노드를 toDelete에 저장합니다. // 실제 변경 slow-\u003enext = slow-\u003enext-\u003enext; // slow의 next를 변경하여 중간 노드를 건너뜁니다(중간 노드 삭제). // 메모리 해제 delete toDelete; // 삭제된 중간 노드의 메모리 해제 delete prev; // 더미 노드의 메모리 해제 return head; // 수정된 리스트의 head를 반환합니다. } };","문제#문제":"주어진 연결 리스트의 헤드가 주어졌을 때, 중간 노드를 삭제하고 수정된 연결 리스트의 헤드를 반환하세요.\n크기가 $n$인 연결 리스트의 중간 노드는 0-based 인덱스를 사용하여 $\\lfloor n / 2 \\rfloor$번째 노드입니다. 여기서 $\\lfloor x \\rfloor$는 $x$보다 작거나 같은 가장 큰 정수를 나타냅니다.\n예를 들어, $n = 1, 2, 3, 4, 5$일 때 중간 노드의 인덱스는 각각 $0, 1, 1, 2, 2$입니다.","예제#\u003cstrong\u003e예제\u003c/strong\u003e":"","예제-1#예제 1:":"입력:\nhead = [1, 3, 4, 7, 1, 2, 6] 출력:\n[1, 3, 4, 1, 2, 6] 설명: 위 그림은 주어진 연결 리스트를 나타냅니다. 노드의 인덱스는 아래에 표시되어 있습니다.\n$ n = 7 $이므로, 값이 $ 7 $인 3번째 노드(0-based 인덱스)가 중간 노드입니다. 이 노드는 빨간색으로 표시되어 있습니다.\n우리는 이 노드를 제거한 후 새로운 리스트를 반환합니다.","예제-2#예제 2:":"입력:\nhead = [1, 2, 3, 4] 출력:\n[1, 2, 4] 설명: 위 그림은 주어진 연결 리스트를 나타냅니다.\n$ n = 4 $이므로, 값이 $ 3 $인 2번째 노드(0-based 인덱스)가 중간 노드입니다. 이 노드는 빨간색으로 표시되어 있습니다.","예제-3#예제 3:":"입력:\nhead = [2, 1] 출력:\n[2] 설명: 위 그림은 주어진 연결 리스트를 나타냅니다.\n$ n = 2 $이므로, 값이 $ 1 $인 1번째 노드(0-based 인덱스)가 중간 노드입니다. 이 노드는 빨간색으로 표시되어 있습니다.\n값이 $ 2 $인 0번째 노드만 남게 됩니다.","제약-조건#\u003cstrong\u003e제약 조건\u003c/strong\u003e":"연결 리스트의 노드 수는 $[1, 10^5]$ 범위에 있습니다. $1\\leq \\text{Node.val} \\leq 10^5$"},"title":"2095. Delete the Middle Node of a Linked List"},"/leetcode75/334.-increasing-triplet-subsequence/":{"data":{"":"주어진 정수 배열 nums에 대해, 인덱스 (i, j, k)가 존재하여 i \u003c j \u003c k이고 nums[i] \u003c nums[j] \u003c nums[k]를 만족하는지 확인하여, 존재하면 true를 반환하고, 그렇지 않으면 false를 반환하는 문제입니다. 예시) 입력: nums = [1,2,3,4,5] 출력: true 설명: i \u003c j \u003c k인 모든 조합이 유효합니다. 입력: nums = [5,4,3,2,1] 출력: false 설명: 유효한 조합이 존재하지 않습니다. 입력: nums = [2,1,5,0,4,6] 출력: true 설명: (3, 4, 5) 조합이 유효합니다. nums[3] == 0 \u003c nums[4] == 4 \u003c nums[5] == 6입니다. 제약 조건 1 \u003c= nums.length \u003c= 5 * 10^5 -2^31 \u003c= nums[i] \u003c= 2^31 - 1 후속 질문 O(n) 시간 복잡도와 O(1) 공간 복잡도로 구현할 수 있는 방법이 있는지 확인해 보세요. greedy 알고리즘으로 풀 수 있는 문제이다\nclass Solution { public: bool increasingTriplet(vector\u003cint\u003e\u0026 nums) { if (nums.size() \u003c 3) return false; // 제한 조건의 추가 int first = INT_MAX; // 첫 번째 최소값 int second = INT_MAX; // 두 번째 최소값 for (int num : nums) if (num \u003c= first) first = num; // 첫 번째 최소값 업데이트 else if (num \u003c= second) second = num; // 두 번째 최소값 업데이트 else return true; // 세 번째 값이 발견됨 return false; } };"},"title":"334. Increasing Triplet Subsequence"},"/leetcode75/443.-string-compression/":{"data":{"":"주어진 문자 배열 chars를 다음 알고리즘을 사용하여 압축하세요: 빈 문자열 s로 시작합니다. chars에서 연속으로 반복되는 문자의 그룹마다: 그룹의 길이가 1인 경우, 문자를 s에 추가합니다. 그렇지 않으면, 문자를 그룹의 길이와 함께 s에 추가합니다. 압축된 문자열 s는 별도로 반환하지 않고, 입력 문자 배열 chars에 저장해야 합니다. 그룹의 길이가 10 이상인 경우, chars에 여러 문자로 나누어 저장해야 합니다. 수정이 완료된 후, 배열의 새 길이를 반환합니다. 상수 추가 공간만 사용하는 알고리즘을 작성해야 합니다. 예시 예시 1: 입력: chars = [\"a\", \"a\", \"b\", \"b\", \"c\", \"c\", \"c\"] 출력: 6을 반환하며, 입력 배열의 처음 6개의 문자: [\"a\", \"2\", \"b\", \"2\", \"c\", \"3\"] 설명: 그룹은 \"aa\", \"bb\", \"ccc\"이며, \"a2b2c3\"으로 압축됩니다. 예시 2: 입력: chars = [\"a\"] 출력: 1을 반환하며, 입력 배열의 첫 번째 문자는: [\"a\"] 설명: 유일한 그룹은 \"a\"이며, 단일 문자이므로 압축되지 않습니다. 예시 3: 입력: chars = [\"a\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\"] 출력: 4를 반환하며, 입력 배열의 처음 4개의 문자는: [\"a\", \"b\", \"1\", \"2\"] 설명: 그룹은 \"a\"와 \"bbbbbbbbbbbb\"이며, \"ab12\"로 압축됩니다. 제약 조건 1 \u003c= chars.length \u003c= 2000 chars[i]는 소문자 영어 문자, 대문자 영어 문자, 숫자 또는 기호입니다. vector 로 조작하면\nclass Solution { public: int compress(vector\u003cchar\u003e\u0026 chars) { vector\u003cchar\u003e ret; auto itr = char.begin(); char first = itr; char last = itr+1; int count; for(itr \u003c chars.end()){ if(*first != *last){ count = last - first; char.erase(remove(first+1, last), ); if(count \u003e= 1000){// 1000 이상 *first } // 100이상 // 10 이상 last = ++first }else last++; } } };"},"title":"443. String Compression"},"/leetcode75/605-%EB%AC%B8%EC%A0%9C/":{"data":{"":"class Solution { public: bool canPlaceFlowers(vector\u003cint\u003e\u0026 flowerbed, int n) { if (n \u003e placeFolwers(flowerbed)) return false; else return true; } int placeFolwers(vector\u003cint\u003e\u0026 flowerbed){ int result = 0; for (int i = 0 ; i \u003c flowerbed.size() ; i++){ int temp = i; while(flowerbed[i] == 0){ i++; } result += (int)((i - temp - 1) / 2); } return result; } }; 테스트 케이스\nInput flowerbed = [0,0,1,0,1] n = 1 Output =\u003e false Expected =\u003e true"},"title":"605 문제"},"/leetcode75/cpp-%EB%AA%A8%EC%9D%8C-%EC%B0%BE%EA%B8%B0/":{"data":{"":"string vowels = \"aeiouAEIOU\"; bool isVowels = vowels.find(word[index]) == string::npos"},"title":"cpp 모음 찾기"},"/leetcode75/cpp-%EC%83%9D%EC%84%B1%EC%9E%90-%EC%86%8C%EB%A9%B8%EC%9E%90-%EA%B7%9C%EC%B9%99/":{"data":{"":"디폴트 생성자(Default Constructor)\n명시적으로 디폴트 생성자 {클래스 이름}() = default; // 디폴트 생성자를 정의해라\nnew 와 malloc 모두 동적으로 할당하지만 new 의 경우 객체를 동적으로 생성하면서와 동시에 자동으로 생성자도 호출해준다는 점입니다. delete 와 free 의 경우도 소멸자 호출 여부가 다름과 동일\n~{클래스의 이름} 소멸자"},"title":"cpp 생성자 소멸자 규칙"},"/leetcode75/cpp-%EC%B4%88%EA%B8%B0%ED%99%94-%EB%B0%A9%EC%8B%9D/":{"data":{"":"class Widget { public: Widget() { std::cout \u003c\u003c \"default\" \u003c\u003c std::endl; } Widget(std::initializer_list\u003cint\u003e il) { std::cout \u003c\u003c \"init\" \u003c\u003c std::endl; } }; int main() { Widget w1; //기본 생성자 호출 Widget w2(); //함수! 호출 x Widget w3{}; //기본 생성자 호출 Widget w4({});//std::initializer_list 이용해 호출 Widget w5{ {} };//std::initializer_list 이용해 호출 Widget w6 = {}; // 기본 생성자 호출 Widget w7 = { {} }; //std::initializer_list 이용해 호출 } 모두의 코드 해당 자료 https://modoocode.com/286","1-초기화initialization란#1. 초기화(Initialization)란?":"정의:\n변수를 선언할 때 그 변수에 최초의 값을 제공하는 과정을 초기화라고 합니다. 객체나 변수의 메모리 공간이 할당되면서 동시에 정해진 초기 값이 부여됩니다. 이는 선언문의 초기화 부분이나, new 표현식, 함수 호출 시(함수 인자 및 리턴값 초기화) 등에서 이루어집니다.","10-클래스-멤버-초기화#10. 클래스 멤버 초기화":"비정적 데이터 멤버(non-static data members) 클래스 내부에서, 비정적 데이터 멤버들은 두 가지 방식으로 초기화할 수 있습니다. 생성자 멤버 초기화 리스트: 생성자의 콜론(:) 뒤에 멤버들을 초기화하는 방식입니다. 기본 멤버 초기값(default member initializer): 클래스 정의 내에서 멤버 변수를 선언할 때, 등호(=)나 중괄호를 사용하여 초기값을 부여하는 방식입니다. 우선순위: 만약 둘 다 존재한다면, 생성자 멤버 초기화 리스트에 명시된 초기값이 우선합니다.","11-소멸-순서#11. 소멸 순서":"참고: 비지역 변수의 소멸 순서는 C++ 표준 라이브러리의 std::exit 문서에 설명되어 있습니다. 정적 객체들은 프로그램 종료 시, 생성 순서의 역순으로 소멸됩니다.","2-초기화-구문initializers-형태#2. 초기화 구문(Initializers) 형태":"각 선언자(declarator)에 대해 초기화자가 있을 경우 사용할 수 있는 구문은 다음과 같습니다.\n= expression\n설명: 등호(=) 다음에 임의의 표현식이 나오는 형태입니다.\n예:\nint a = 5; std::string s = \"hello\"; 용어: “복사 초기화(copy-initialization)“라고 부릅니다.\n= {} 또는 = { initializer-list } 또는 = { designated-initializer-list }\n설명: 등호 뒤에 중괄호를 사용하여 초기값을 나열하는 형태입니다.\n역사:\nC++11부터 중괄호를 사용한 **목록 초기화(list-initialization)**가 도입되었습니다. C++20부터 지정 초기자(designated initializer) 문법이 추가되었습니다. 예:\nint arr[3] = {1, 2, 3}; // 배열에 대한 aggregate 초기화 MyStruct s = { .x = 10, .y = 20 }; // C++20 지정 초기자 ( expression-list ) 또는 ( initializer-list )\n설명: 괄호를 사용한 직접 초기화 구문입니다.\n차이점:\nC++11 이전에는 괄호 안에 초기값 목록을 쓰는 것이 직접 초기화(direct-initialization) 문법이었습니다. C++11 이후에도 여전히 지원됩니다. 예:\nstd::string s(\"hello\"); // 직접 초기화 {} 또는 { initializer-list } 또는 { designated-initializer-list }\n설명: 중괄호만을 사용한 초기화 구문으로, C++11부터 도입된 **목록 초기화(list-initialization)**입니다.\n예:\nstd::string s{\"hello\"}; // 목록 초기화 (C++11 이후) int a{}; // 기본값으로 초기화 (보통 0으로 초기화) 요약:\n구문 (1)은 복사 초기화(copy initialization) 구문 (3)은 직접 초기화(direct initialization) 구문 (2)와 (4)는 중괄호를 사용하는 **목록 초기화(list initialization)**에 해당합니다. 지정 초기자(designated initializer)는 C++20부터 사용할 수 있습니다.","3-초기화에-사용되는-요소들의-설명#3. 초기화에 사용되는 요소들의 설명":"expression:\n임의의 표현식을 의미합니다. 단, 괄호 없이 나열한 콤마 표현식(unparenthesized comma expressions)은 제외됩니다. expression-list:\n표현식들을 쉼표(,)로 구분하여 나열한 목록입니다. 역시, 괄호 없이 나열된 콤마 표현식은 제외합니다. initializer-list:\n쉼표로 구분된 초기화 절(clause)들의 목록입니다. designated-initializer-list:\n각 초기화 절에 멤버 이름을 명시하는 초기자들의 목록입니다. (C++20부터 지원) brace-enclosed initializer list:\n중괄호 {} 로 감싼 초기자 구문을 총칭하는 말입니다.","4-초기화-구문에-따른-초기화-의미-initializer-semantics#4. 초기화 구문에 따른 초기화 의미 (Initializer Semantics)":"초기화가 진행되는 대상에 따라 다르게 적용됩니다.","5-예제-코드와-그-의미#5. 예제 코드와 그 의미":"아래 코드를 하나씩 살펴봅니다:\n#include std::string s1; // (a) 기본 초기화 (default initialization) std::string s2(); // (b) 함수 선언! 초기화가 아님 std::string s3 = \"hello\"; // (c) 복사 초기화 (copy initialization) std::string s4(\"hello\"); // (d) 직접 초기화 (direct initialization) std::string s5{'a'}; // (e) 목록 초기화 (list initialization, C++11부터) (a) std::string s1;\n기본 초기화(default-initialization) 객체 s1은 아무 초기값 없이 생성됩니다. std::string의 경우, 내부적으로 기본 생성자가 호출되어 빈 문자열(”\")이 됩니다. (b) std::string s2();\n이것은 초기화가 아니라 함수 선언입니다. s2는 매개변수가 없고 std::string을 반환하는 함수로 해석됩니다. 이를 “most vexing parse” 라고 부르기도 합니다. (c) std::string s3 = \"hello\";\n복사 초기화(copy initialization) “hello\"라는 문자열 리터럴을 사용하여 s3를 초기화합니다. (d) std::string s4(\"hello\");\n직접 초기화(direct initialization) 생성자에 “hello\"를 직접 전달하여 s4를 초기화합니다. (e) std::string s5{'a'};\n목록 초기화(list initialization) 중괄호를 사용하여 s5를 초기화합니다. 이 경우 std::string에 대해 어떤 생성자가 호출되는지(예: 단일 문자로 구성된 문자열 등)는 타입에 따라 달라집니다. 또 다른 예로 배열과 참조 초기화:\nchar a[3] = {'a', 'b'}; // aggregate 초기화: 배열의 첫 두 요소가 'a'와 'b'로, 나머지는 0으로 초기화 char\u0026 c = a[0]; // 참조 초기화: c는 배열 a의 첫 번째 요소를 참조 배열 a는 중괄호를 사용하여 aggregate 초기화됩니다. 참조 c는 배열의 첫 번째 요소 a[0]를 가리키도록 초기화됩니다.","6-비지역-변수non-local-variables-초기화#6. 비지역 변수(Non-local variables) 초기화":"비지역 변수란 전역 변수나 네임스페이스 범위, 또는 정적/스레드 로컬(static/thread-local) 변수를 말합니다.","7-조기dynamic-초기화early-dynamic-initialization#7. 조기(dynamic) 초기화(Early dynamic initialization)":"개념:\n컴파일러는 아래 조건을 만족할 경우, 동적 초기화를 정적 초기화 단계에서 미리(컴파일 타임에) 수행할 수 있습니다.\n조건:\n동적 초기화가 다른 네임스페이스 범위 객체의 값을 변경하지 않아야 합니다. 정적 초기화 버전이 동적 초기화를 수행했을 때와 동일한 값을 산출해야 합니다. 결과:\n예를 들어, 어떤 객체 o1의 초기화 과정에서 같은 번역 단위 내의 o2에 접근한다면,\n컴파일러가 o2를 정적으로 초기화할 수 있으면, o2는 완전히 초기화된 상태의 값이거나 단순히 0으로 초기화된 상태일 수 있으며, 이는 명확하지 않습니다(불특정). 예제:\ninline double fd() { return 1.0; } extern double d1; double d2 = d1; // d1이 동적 초기화되었으면 0.0, 아니면 1.0 등으로 초기화될 수 있음 double d1 = fd(); // d1은 1.0으로 초기화; 정적 초기화될 수도, 동적 초기화될 수도 있음.","8-지연된-동적-초기화deferred-dynamic-initialization#8. 지연된 동적 초기화(Deferred dynamic initialization)":"개념:\n일부 구현에서는 동적 초기화를 main 함수의 첫 문장 이전에 수행할 수도 있고, 또는 main 함수(혹은 스레드 초기 함수)의 첫 문장 이후로 지연시킬 수도 있습니다. 규칙 (C++17부터):\n비 inline 변수: 만약 동적 초기화가 main 함수 시작 후로 지연된다면, 같은 번역 단위 내에서 해당 변수를 **ODR-사용(One Definition Rule 사용)**하기 전에 초기화가 이루어집니다. 만약 번역 단위 내의 변수나 함수가 전혀 사용되지 않으면, 그 번역 단위에 정의된 비지역 변수들은 아예 초기화되지 않을 수도 있습니다(동적 라이브러리의 on-demand 초기화와 유사). inline 변수: inline 변수의 경우, 해당 변수가 ODR-사용되기 전에 초기화가 이루어집니다. 여러 파일에 걸친 예제:\n예제 코드에서는 서로 다른 번역 단위(File 1, File 2, File 3)에서 변수 a와 b의 초기화 순서에 따라,\n만약 a가 main 전에 초기화된다면, A::A() 안에서 b가 아직 초기화되지 않았을 수 있습니다. 반면, a가 main 이후에 초기화(ODR-사용에 의해)된다면, b도 초기화된 후에 사용됩니다.","9-블록-스코프static-local-변수#9. 블록 스코프(static local) 변수":"설명: 함수 내부(또는 블록 내)에서 static 또는 thread_local로 선언된 변수들은 지역 정적 변수라고 합니다. 이들 변수의 초기화에 관한 규칙은 별도로 다루어지며, 보통 해당 블록에 처음 도달했을 때 초기화가 수행됩니다. 참고: 블록 스코프 변수는 전역 변수와 달리, 외부 또는 내부 링케이지(external or internal linkage)를 갖는 선언에서는 초기화자가 허용되지 않습니다. 이런 경우 extern 선언을 통해 정의와 분리하여 초기화해야 합니다.","a-비지역-변수의-초기화-시점#A. 비지역 변수의 초기화 시점":"**정적 저장 기간(static storage duration)**을 가지는 변수들은 프로그램 시작 시, main 함수 실행 전에 초기화됩니다. 스레드 로컬(thread-local storage) 변수들은 각 스레드가 시작될 때 초기화되며, 스레드 함수가 실행되기 전에 이루어집니다.","a-참조reference-초기화#A. 참조(reference) 초기화":"설명: 초기화 대상이 참조일 경우, 참조 초기화(reference initialization) 규칙이 적용됩니다.\n필수: 참조는 반드시 유효한 객체를 가리키도록 초기화되어야 합니다.\n예:\nint x = 10; int\u0026 ref = x; // 올바른 참조 초기화 문제: 초기화하지 않은 참조는 프로그램이 잘못된 동작을 하거나 컴파일 오류를 발생시킵니다.","b-객체object-초기화#B. 객체(object) 초기화":"대상: 일반 변수나 객체는 초기화될 때 객체 초기화가 진행됩니다. T 타입의 객체에 대해: (1) 복사 초기화\n초기화 구문이 = expression인 경우, 복사 초기화가 진행됩니다.\n예:\nstd::string s = \"hello\"; (2) 중괄호를 사용한 초기화\nT가 aggregate (집합체)인 경우, aggregate 초기화가 적용됩니다. 예: 배열, 구조체 등. T가 스칼라 타입(예: int, double)인 경우,\nT x = { a }; 는 T x = a;와 동일하게 동작합니다. 만약 T가 aggregate가 아니면서 중괄호 초기화가 사용되었는데 해당 타입에 맞는 생성자가 없다면, 프로그램은 ill-formed (잘못된 프로그램)으로 간주됩니다. (3) 직접 초기화\n초기화 구문이 ( expression-list )인 경우, 직접 초기화가 진행됩니다. (4) 목록 초기화 (C++11 이후)\n중괄호를 사용한 형태로, list-initialization이 적용됩니다. 주의:\n초기화 구문에 따라 복사 초기화와 직접 초기화는 약간의 차이가 있을 수 있으며, 특히 타입 변환이나 임시 객체 생성 과정에 영향을 미칠 수 있습니다. C++11부터는 목록 초기화가 도입되어 중괄호 초기화가 점점 일반적으로 사용됩니다.","b-초기화-과정은-두-단계로-나뉩니다#B. 초기화 과정은 두 단계로 나뉩니다":"정적 초기화 (Static initialization)\n1) 상수 초기화 (Constant initialization): 가능한 경우, 컴파일 타임에 상수 값으로 초기화됩니다. 컴파일러는 미리 계산된 초기 값(객체 표현)을 프로그램 이미지에 저장할 수 있습니다. 2) 0으로 초기화 (Zero initialization): 상수 초기화가 불가능한 경우, 정적 및 스레드 로컬 변수들은 먼저 0으로 초기화됩니다. 0으로 초기화된 변수들은 보통 프로그램의 .bss 섹션에 위치하며, 프로그램 로딩 시 운영체제가 이 영역을 0으로 채웁니다. 동적 초기화 (Dynamic initialization)\n정적 초기화가 완료된 후, 나머지 동적 초기화가 진행됩니다. 동적 초기화에는 다음 세 가지 유형이 있습니다. (1) 순서가 정해지지 않은(unordered) 동적 초기화\n적용 대상: 주로 클래스 템플릿의 정적 데이터 멤버나 변수 템플릿(특수화되지 않은 경우, C++14부터 적용) 이들 변수의 초기화 순서는 다른 동적 초기화들과는 indeterminately(불특정하게) 순서가 정해집니다. 단, 프로그램이 변수 초기화 전에 스레드를 시작하는 경우 C++17부터는 “unsequenced\"로 초기화됩니다. (2) 부분 순서(partially-ordered) 동적 초기화\n적용 대상: inline 변수 중 암시적 또는 명시적 인스턴스화되지 않은 특수화가 아닌 변수들 한 번에 한 번, 정의된 순서에 따라 초기화 순서가 결정됩니다. 한 번의 번역 단위(translation unit) 내에서, 어떤 변수 V가 항상 W보다 먼저 정의되면 V의 초기화가 W보다 먼저 이루어집니다. (C++17부터 적용) (3) 순서가 정해진(ordered) 동적 초기화\n적용 대상: 위의 두 경우에 해당하지 않는 모든 비지역 변수들 한 번의 번역 단위 내에서, 소스 코드에 나타난 순서대로 초기화가 진행됩니다. 서로 다른 번역 단위 간에는 초기화 순서가 불특정(indeterminately sequenced) 입니다. 스레드 로컬 변수의 경우, 다른 번역 단위 간에는 초기화 순서가 unsequenced 됩니다. 예외 처리: 만약 비지역 변수(정적 또는 스레드 로컬)의 초기화 도중 예외가 발생하면, std::terminate가 호출됩니다.","최종-정리#최종 정리":"C++ 초기화는 매우 다양한 구문과 규칙이 있으며, 초기화 방법에 따라 다음과 같이 분류할 수 있습니다.\n변수 선언 시 초기화 복사 초기화, 직접 초기화, 목록 초기화, 지정 초기자 등을 사용할 수 있습니다. 참조 초기화 반드시 유효한 객체를 가리키도록 초기화되어야 하며, 임시 객체에 바인딩할 수 없음. 비지역(전역, 네임스페이스, static, thread_local) 변수 초기화 두 단계(정적 초기화와 동적 초기화)로 진행됩니다. 정적 초기화에서는 상수 초기화와 0 초기화가 수행됩니다. 동적 초기화는 unordered, partially-ordered, ordered 세 가지 방식으로 진행되며, 번역 단위 간 순서는 보장되지 않습니다. 조기(dynamic) 초기화와 지연 초기화 컴파일러가 조건을 만족하면 동적 초기화를 정적으로 미리 수행할 수 있으며, 또는 프로그램 실행 도중(ODR-사용 시점)에 지연시킬 수도 있습니다. 클래스 멤버 초기화 생성자 초기화 리스트 또는 기본 멤버 초기값을 통해 초기화합니다."},"title":"cpp 초기화 방식"},"/leetcode75/cpp-stl/":{"data":{"":"","algorithm#algorithm":"template \u003ctypename Iter\u003e void do_something(Iter begin, Iter end); template \u003ctypename Iter, typename Pred\u003e void do_something(Iter begin, Iter end, Pred pred) 와 같은 꼴을 따르고 있습니다. 전자의 경우, 알고리즘을 수행할 반복자의 시작점과 끝점 바로 뒤를 받고, 후자의 경우 반복자는 동일하게 받되, ‘특정한 조건’ 을 추가 인자로 받게 됩니다. 이러한 ‘특정한 조건’을 서술자(Predicate) 이라고 부르며 저기 Pred 에는 보통 bool 을 리턴하는 함수 객체(Functor) 를 전달하게 됩니다.\n#include #include // 12바이트 단위 할당 void* operator new(std::size_t count) { std::cout \u003c\u003c count \u003c\u003c \" bytes 할당 \" \u003c\u003c std::endl; return malloc(count); } // 벡터의 요소를 출력하는 함수 void printVector(const std::vector\u003cint\u003e\u0026 vec) { std::cout \u003c\u003c \"현재 요소: \"; for (int i : vec) { std::cout \u003c\u003c i \u003c\u003c \" \"; } std::cout \u003c\u003c std::endl; } int main() { std::vector\u003cint\u003e vec = {1, 2, 3}; // 벡터의 iterator를 얻습니다. std::vector\u003cint\u003e::iterator it = vec.begin(); printVector(vec); // 벡터 출력 // 첫 번째 요소를 출력합니다. std::cout \u003c\u003c \"첫 번째 요소 (iterator 사용): \" \u003c\u003c *it \u003c\u003c std::endl; // 벡터에 요소 추가 (iterator 무효화 가능성) vec.push_back(4); // 이 시점에서 it는 무효화되었습니다. // std::cout \u003c\u003c \"첫 번째 요소 (무효화된 iterator 사용): \" \u003c\u003c *it \u003c\u003c std::endl; // 이 줄은 주석 처리해야 합니다. // 요소 삭제 (iterator 무효화) it = vec.erase(vec.begin()); // 첫 번째 요소를 제거합니다. // 이 시점에서 it은 제거된 요소의 다음 요소를 가리킵니다. std::cout \u003c\u003c \"제거 후 첫 번째 요소 (iterator 사용): \" \u003c\u003c *it \u003c\u003c std::endl; printVector(vec); // 벡터 출력 return 0; } 12 bytes 할당 현재 요소: 1 2 3 첫 번째 요소 (iterator 사용): 1 24 bytes 할당 제거 후 첫 번째 요소 (iterator 사용): 2 현재 요소: 2 3 4 백터는 12 -\u003e 24 -\u003e 48 단위로 할당이 되는 것 같다 삽입되거나 지워질 때 할당되면 기존 반복자 무효 vec.begin(), vec.end() 위치의 값이 지워지면 반복자 무효","container#Container":"시퀀스 컨테이너 (Sequence Container)\narray (C++11): 고정 길이 배열 vector: 동적 가변 길이 배열 inplace_vector (C++26): 동적으로 크기를 조정 가능하지만, 고정된 용량을 가지는 연속 배열로, 요소가 메모리 내에서 제자리에서 관리됨. 메모리 사용을 최적화하고 성능을 개선하기 위해 설계됨. deque: 분할 가변 길이 배열 + 양방향 capacity forward_list (C++11): 단방향 링크드 리스트 list: 양방향 링크드 리스트 연관 컨테이너 (Associative Container)\nset: 중복되지 않는 키를 저장하며, 키의 존재 여부를 빠르게 확인. map: 키와 값을 쌍으로 저장하며 특정 키에 대한 값을 조회. [] 사용 가능하다 multiset: 중복된 키를 허용하는 set. multimap: 중복된 키를 허용하는 map. [] 사용 불가능 커스텀 클래스 객체를 set/map 혹은 unordered_set/map에 추가하기: 사용자 정의 타입을 사용할 경우, 비교 연산자 또는 해시 함수를 정의해야 함. 정렬되지 않는 연관 컨테이너 (unordered Associative Containers)\nunordered_set: 해시 테이블을 기반 set unordered_map: 해시 테이블을 기반 map Container Adaptors\n기본 컨테이너를 사용하여 특정 데이터 구조(예: 스택, 큐)로 동작하도록 변환하는 클래스 템플릿. stack: LIFO(Last In First Out) 구조로, 마지막에 추가된 요소가 가장 먼저 제거됨. queue: FIFO(First In First Out) 구조로, 먼저 추가된 요소가 먼저 제거됨. priority_queue: 우선순위에 따라 요소가 제거되며, 가장 높은 우선순위의 요소가 먼저 처리됨. flat_set, flat_map, flat_multiset, flat_multimap: 내부적으로 정렬된 벡터를 사용하여 빠른 탐색과 삽입을 제공하는 컨테이너. View\n데이터의 특정 부분이나 배열을 참조하여 효율적으로 접근하고 관리할 수 있도록 하는 객체 span: 연속적인 메모리 블록에 대한 뷰로, 크기와 포인터를 통해 부분 배열을 쉽게 다룰 수 있음. mdspan: 다차원 배열에 대한 뷰로, 다양한 차원의 배열을 효과적으로 접근하고 관리할 수 있도록 설계됨.","deque#deque":"O(1) 으로 임의의 위치의 원소에 접근 맨 뒤에 원소를 추가/제거 하는 작업도 O(1) 맨 앞에 원소를 추가/제거 하는 작업 까지도 O(1) 임의의 위치에 있는 원소를 제거/추가 하는 작업은 벡터와 마찬가지로 O(n) 으로 수행 이 때문에 원소들이 어디에 저장되어 있는지에 대한 정보를 보관하기 위해 추가적인 메모리가 더 필요로 합니다. 기존의 벡터와는 조금 다르게, 새로 할당 시에 앞쪽 및 뒤쪽 모두에 공간을 남겨놓게 됩니다. (벡터의 경우 뒤쪽에만 공간이 남았지요) 덱 역시 벡터 처럼 임의의 위치에 원소에 접근할 수 있으므로 [] 와 at 함수를 제공하고 있고, 반복자 역시 RandomAccessIterator 타입 이고 벡터랑 정확히 동일한 방식으로 작동합니다. 참고\n일반적인 상황에서는 그냥 벡터를 사용한다 (거의 만능이다!) 만약에 맨 끝이 아닌 중간에 원소들을 추가하거나 제거하는 일을 많이 하고, 원소들을 순차적으로만 접근 한다면 리스트를 사용한다. 만약에 맨 처음과 끝 모두에 원소들을 추가하는 작업을 많이하면 덱을 사용한다.","find#find":"template \u003cclass InputIt, class T\u003e InputIt find(InputIt first, InputIt last, const T\u0026 value) first 부터 last 까지 쭈르륵 순회하면서 value 와 같은 원소가 있는지 확인하고 있으면 이를 가리키는 반복자를 리턴 O(n) : 순차 탐색 set 에서 사용하는 find 함수의 경우 $O(log⁡n)$ 으로 수행(정렬되어 있어서 이분 탐색 가능) unordered_set 의 경우 find 함수가 $O(1)$ 로 수행될 수 있는데 그 이유는 unordered_set 내부에서 자체적으로 해시 테이블을 이용해서 원소들을 빠르게 탐색","iterator#iterator":"아래는 C++ STL 컨테이너별 이터레이터 타입을 표로 정리한 것입니다:","iterator-1#iterator":"컨테이너 이터레이터 타입 비고 std::vector Random Access Iterator 인덱스 접근 가능 std::deque Random Access Iterator 양쪽 끝에서 삽입/삭제 가능 std::list Bidirectional Iterator 앞뒤로 이동 가능, 임의 접근 불가 std::set Bidirectional Iterator 정렬된 상태로 요소 저장 std::multiset Bidirectional Iterator 정렬된 상태로 요소 저장 std::map Bidirectional Iterator 키-값 쌍을 정렬된 상태로 저장 std::multimap Bidirectional Iterator 키-값 쌍을 정렬된 상태로 저장 std::array Random Access Iterator 고정 크기 배열, 인덱스 접근 가능 std::forward_list Forward Iterator 앞 방향으로만 이동 가능 BidirectionalIterator 상속 RandomAccessIterator\nremove 함수의 경우 반복자의 타입이 ForwardIterator 입니다.\n1. 주요 반복자 종류\n반복자 유형 정의 및 역할 iterator 읽기와 쓰기 모두 가능한 일반 반복자입니다. const_iterator 읽기 전용 반복자입니다. 값을 수정할 수 없도록 보장합니다. reverse_iterator 컨테이너를 뒤에서 앞으로(iterate) 순회할 때 사용하는 반복자입니다. const_reverse_iterator 읽기 전용의 역방향 반복자입니다. pointer 그냥 포인터 일반적으로 반복자는 내부적으로 포인터(T*)로 정의되므로, 반복자 타입이 포인터와 동일한 동작을 할 수 있습니다. const_pointer const 포인터 읽기 전용의 포인터입니다. 주요 메서드\n메서드 설명 begin() 컨테이너의 첫 번째 요소를 가리키는 반복자를 반환합니다. end() 컨테이너의 마지막 요소 다음을 가리키는 반복자를 반환합니다. (범위를 벗어난 포인터와 비슷) cbegin() 첫 번째 요소를 가리키는 const_iterator를 반환합니다. cend() 마지막 요소 다음을 가리키는 const_iterator를 반환합니다. rbegin() 마지막 요소를 가리키는 reverse_iterator를 반환합니다. rend() 첫 번째 요소 이전을 가리키는 reverse_iterator를 반환합니다. crbegin() const_reverse_iterator로 마지막 요소를 가리킵니다. crend() const_reverse_iterator로 첫 번째 요소 이전을 가리킵니다.","lambda#lambda":"[capture list] (받는 인자) -\u003e 리턴 타입 { 함수 본체 } [capture list] ( 받는 인자) {함수 본체}\n[] : 아무것도 캡쳐 안함 [\u0026a, b] : a 는 레퍼런스로 캡쳐하고 b 는 (변경 불가능한) 복사본으로 캡쳐 [\u0026] : 외부의 모든 변수들을 레퍼런스로 캡쳐 [=] : 외부의 모든 변수들을 복사본으로 캡쳐","list#list":"양방향 링크드 리스트\n임의의 위치에 있는 원소에 접근을 바로 할 수 없다 [] 나 at 함수가 아예 정의되어 있지 않다 임의의 위치에 원소를 추가하거나 제거하는 작업이 $O(n)$ 이였지만 리스트의 경우 $O(1)$ 으로 매우 빠르게 수행 반복자의 타입이 BidirectionalIterator 타입 (벡터의 반복자는 RandomAccessIterator 이고 RandomAccessIterator 는 BidirectionalIterator 를 상속받고 있다) itr++ // itr ++ itr-- // --itr 도 됩니다. itr + 5 // 불가능!","set#set":"template \u003ctypename T\u003e void print_set(std::set\u003cT\u003e\u0026 s) { // 셋의 모든 원소들을 출력하기 std::cout \u003c\u003c \"[ \"; for (typename std::set\u003cint\u003e::iterator itr = s.begin(); itr != s.end(); ++itr) { std::cout \u003c\u003c *itr \u003c\u003c \" \"; } std::cout \u003c\u003c \" ] \" \u003c\u003c std::endl; } 10 -\u003e 50 -\u003e 20 -\u003e 40 -\u003e 30 으로 넣었지만 실제로 반복자로 원소들을 모두 출력했을 때 나온 순서는 10 -\u003e 20 -\u003e 30 -\u003e 40 -\u003e 50 순으로 나왔다는 점 set 의 경우 비교 연산자를 통해 비료를 진행한다 이때 A","set-1#set":"Member Functions\n구문 설명 반환값 시간 복잡도 constructor 셋을 생성합니다. 없음 O(1) destructor 셋을 소멸합니다. 없음 O(1) operator= 컨테이너에 값을 할당합니다. set\u0026 O(n) get_allocator 연관된 할당자를 반환합니다. allocator_type O(1) Iterators\n구문 설명 반환값 시간 복잡도 begin 시작 위치의 반복자를 반환합니다. iterator O(1) cbegin 시작 위치의 상수 반복자를 반환합니다. const_iterator O(1) end 끝 위치의 반복자를 반환합니다. iterator O(1) cend 끝 위치의 상수 반복자를 반환합니다. const_iterator O(1) rbegin 역순으로 시작 위치의 반복자를 반환합니다. reverse_iterator O(1) crbegin 역순으로 시작 위치의 상수 반복자를 반환합니다. const_reverse_iterator O(1) rend 역순으로 끝 위치의 반복자를 반환합니다. reverse_iterator O(1) crend 역순으로 끝 위치의 상수 반복자를 반환합니다. const_reverse_iterator O(1) Capacity\n구문 설명 반환값 시간 복잡도 empty 컨테이너가 비어있는지 확인합니다. bool O(1) size 원소의 개수를 반환합니다. size_type O(1) max_size 최대 가능한 원소의 개수를 반환합니다. size_type O(1) Modifiers\n구문 설명 반환값 시간 복잡도 clear 내용을 지웁니다. 없음 O(n) insert 원소 또는 노드를 삽입합니다. pair O(log n) insert_range 원소의 범위를 삽입합니다. (C++23) void O(n) emplace 인플레이스에서 원소를 생성합니다. pair O(log n) emplace_hint 힌트를 사용하여 인플레이스에서 원소를 생성합니다. pair O(log n) erase 원소를 삭제합니다. size_type O(log n) swap 내용을 교환합니다. 없음 O(1) extract 컨테이너에서 노드를 추출합니다. (C++17) node_type O(log n) merge 다른 컨테이너로부터 노드를 스파이스합니다. (C++17) void O(n) Lookup\n구문 설명 반환값 시간 복잡도 count 특정 키와 일치하는 원소의 개수를 반환합니다. size_type O(log n) find 특정 키를 가진 원소를 찾습니다. iterator O(log n) contains 특정 키를 가진 원소가 있는지 확인합니다. (C++20) bool O(log n) equal_range 특정 키와 일치하는 원소의 범위를 반환합니다. pair O(log n) lower_bound 주어진 키보다 작지 않은 첫 번째 원소의 반복자를 반환합니다. iterator O(log n) upper_bound 주어진 키보다 큰 첫 번째 원소의 반복자를 반환합니다. iterator O(log n) Observers\n구문 설명 반환값 시간 복잡도 key_comp 키를 비교하는 함수를 반환합니다. key_compare O(1) value_comp 값 타입의 객체에서 키를 비교하는 함수를 반환합니다. value_compare O(1)","standard-template-library---stl#Standard Template Library - STL":"임의 타입의 객체를 보관할 수 있는 컨테이너 (container) 컨테이너에 보관된 원소에 접근할 수 있는 반복자 (iterator) 반복자들을 가지고 일련의 작업을 수행하는 알고리즘 (algorithm) cpp reference 다음은 C++의 주요 컨테이너와 관련된 개념에 대한 간단한 설명입니다:","string#string":"​\n1. 특정 원소 접근 방법\nstr.at(idx) idx 위치 문자 반환, 범위 유효성 체크 O str[idx] idx 위치 문자 반환, 범위 유효성 체크 X str.front() 문자열의 가장 앞의 문자 반환 str.back() 문자열의 가장 뒤의 문자 반환 2. 문자열의 크기\nstr.length() 문자열 길이 반환 str.size() 문자열 길이 반환(length()와 동일) str.max_size() 최대한 메모리 할당할 경우 저장할 수 있는 문자열 길이 반환 str.capacity() 문자열의 메모리 크기 반환 str.resize(n) str을 n의 크기로 만듦. 삭제 또는 빈 공간으로 채움 str.resize(n, ‘a’) n이 str 길이보다 크면 빈 공간을 ‘a’로 채움 str.shrink_to_fit() capacity가 실제 사용하는 메모리보다 큰 경우 메모리 줄여 줌(메모리 낭비 제거) str.reserve(n) 사이즈 n 만큼의 메모리 미리 할당 str.empty() str이 빈 문자열인지 확인 3. 문자열 삽입/추가/삭제\nstr.append(str2) str 뒤에 str2 문자열을 이어 붙여 줌(str + str2 와 같음) str.append(str2, n ,m) str 뒤에 ‘str2의 n index 부터 m개의 문자’를 이어 붙여 줌 str.append(n, ‘a’) str 뒤에 n 개의 ‘a’를 붙여 줌 str.insert(n, str2) n번째 index 앞에 str2 문자열을 삽입함 str.replace(n, k, str2) n번째 index 부터 k개의 문자열을 str2로 대체함 str.clear() 저장된 문자열을 모두 지움 str.erase() clear()와 같음 str.erase(n, m) n번째 index부터 m개의 문자를 지움 str.erase(n, m) ← iterator n~m index 문자열을 지움(n, m은 iterator임) str.push_back(c) str의 맨 뒤에 c를 붙여 줌 str.pop_back() str의 맨 뒤의 문자를 제거 str.assign(str2) str 에 str2 문자열을 할당함 4. 부분 문자/비교/복사/찾기\nstr.substr() str 전체를 반환 str.substr(n) str의 n번째 index부터 끝까지 부분 문자열 반환 str.substr(n, k) str의 n번째 index부터 k개의 부분 문자열 반환 str.compare(str2) str과 str2가 같은지 비교, strstr2인 경우 양수 반환 str.copy(str2, k, n) str의 n번째 index부터 k개의 문자열 복사 str.find(“abcd”) “abcd\"가 str에 포함되어 있는지 확인, 찾으면 해당 부분 첫 index 반환 str.find(“abcd”, n) n번째 index부터 “abcd\"를 찾음 str.find_first_of(”/”) “/“가 처음 나타나는 index str.find_last_of(”/”) “/“가 마지막으로 나타나는 index 5. 기타 유용한 함수들\nstr.c_str() string을 c스타일의 문자열로 변경 str.begin() string의 시작 iterator 반환 str.end() string의 끝 iterator 반환 swap(str, str2) str과 str2를 바꿔줌 str = str2 + str3 str2와 str3를 붙여서 str에 복사함 str += str2 str 뒤에 str2를 붙여줌 str = str2 str에 str2 복사 (Deep Copy) str == str2 str과 str2가 같은지 확인 str \u003e str2, str \u003c str2 str이 str2보다 사전순으로 앞인지 뒤인지 확인 isdigit(c) #include , c가 숫자인지 확인, 숫자이면 0이 아닌 숫자 반환 isalpha(c) #include , 알파벳 확인, 대문자는 1 반환, 소문자는 2 반환, 알파벳이 아니면 0 반환 toupper(c) #include , c를 대문자로 변환 tolower(c) #include , c를 소문자로 변환 stoi(), stof(), stol(), stod() 문자열을 숫자로 변환(int, float, long, double) to_string(n) 숫자 n을 문자열로 변환","transform#transform":"transform (시작 반복자, 끝 반복자, 결과를 저장할 컨테이너의 시작 반복자, Pred)","vector#vector":"임의의 위치 원소 접근 ([], at) : $O(1)$ 맨 뒤에 원소 추가 및 제거 (push_back/pop_back) : amortized $O(1)$; (평균적으로 $O(1)$ 이지만 최악의 경우(공간을 새로 할당하고, 모두 복사) $O(n)$ ) 임의의 위치 원소 추가 및 제거(한칸씩 민다) (insert, erase) : $O(n)$ 벡터의 크기를 리턴하는 함수인 size 의 경우, 그리턴하는 값의 타입은 size_type 멤버 타입으로 정의 for (std::vector\u003cint\u003e::iterator itr = vec.begin(); itr != vec.end(); ++itr) { std::cout \u003c\u003c *itr \u003c\u003c std::endl; } 반복자 사용 %20image%2020241221083329.png) 만일 begin() == end() 라면 원소가 없는 벡터 *, + 등 배열 포인터 그대로 사용 가능\nerase 실행 등 지우거나 추가할 경우 유효하지 않은 반복자 조심\nstd::vector\u003cint\u003e::iterator itr = vec.begin(); std::vector\u003cint\u003e::iterator end_itr = vec.end(); for (; itr != end_itr; ++itr) { if (*itr == 20) { vec.erase(itr); } } 역반복자 사용이유 아래 코드는 오류가 발생하는데 vector 의 index 를 담당하는 타입이 부호 없는 정수 이기 때문 i 가 0 일때 -1 을 한다면 오버플로우 발생으로 가장 큰수가 되어버림 2^32 -1\nint main() { std::vector\u003cint\u003e vec; vec.push_back(1); vec.push_back(2); vec.push_back(3); // 끝에서 부터 출력하기 for (std::vector\u003cint\u003e::size_type i = vec.size() - 1; i \u003e= 0; i--) { std::cout \u003c\u003c vec[i] \u003c\u003c std::endl; } return 0; } 범위기반 for 문 아래의 형태로 썼을 경우, elem 에 vec 의 원소들이 매 루프 마다 복사되서 들어가게 됩니다. 마치 elem = vec[i]; 와 동일\nfor (int elem : vec) { std::cout \u003c\u003c \"원소 : \" \u003c\u003c elem \u003c\u003c std::endl; } 레퍼런스 범위 기반 for문 만약에 복사 하기 보다는 레퍼런스를 받고 싶다면 어떨까요? 매우 간단합니다. 단순히 레퍼런스 타입으로 바꾼다\ntemplate \u003ctypename T\u003e void print_vector(std::vector\u003cT\u003e\u0026 vec) { // 전체 벡터를 출력하기 for (typename std::vector\u003cT\u003e::iterator itr = vec.begin(); itr != vec.end(); ++itr) { std::cout \u003c\u003c *itr \u003c\u003c std::endl; } } template \u003ctypename T\u003e void print_vector_range_based(std::vector\u003cT\u003e\u0026 vec) { // 전체 벡터를 출력하기 for (const auto\u0026 elem : vec) { std::cout \u003c\u003c elem \u003c\u003c std::endl; } } int main() { std::vector\u003cint\u003e vec; vec.push_back(1); vec.push_back(2); vec.push_back(3); vec.push_back(4); std::cout \u003c\u003c \"print_vector\" \u003c\u003c std::endl; print_vector(vec); std::cout \u003c\u003c \"print_vector_range_based\" \u003c\u003c std::endl; print_vector_range_based(vec); return 0; }","vector-1#vector":"Vector의 초기화\n구문 설명 vector\u003c자료형\u003e 변수명 백터 생성 vector\u003c자료형\u003e 변수명(숫자) 숫자만큼 백터 생성 후 0으로 초기화 vector\u003c자료형\u003e 변수명 = { 변수1, 변수2, ... } 백터 생성 후 오른쪽 변수 값으로 초기화 vector\u003c자료형\u003e 변수명[] = {, } 백터 배열(2차원 백터) 선언 및 초기화 vector"},"title":"cpp STL"},"/leetcode75/cpp-stl2/":{"data":{"":"템플릿 인수로 타입과 비타입(정수) 둘다 올수 있다\n타입인자로 올수 있는 타입\n정수 타입들 (bool, char, int, long 등등). 당연히 float 과 double 은 제외 포인터 타입 enum 타입 std::nullptr_t (널 포인터) c++ 20부터 조금 널널해짐","string#string":"타입 정의 비고 std::string std::basic_string 기본적인 문자열 타입 std::wstring std::basic_string wchar_t의 크기는 시스템마다 다름;\n윈도우에서는 2바이트, 유닉스에서는 4바이트 std::u8string std::basic_string C++20에 새로 추가;\nchar8_t는 1바이트;\nUTF-8 문자열 저장 std::u16string std::basic_string char16_t는 2바이트;\nUTF-16 문자열 저장 std::u32string std::basic_string char32_t는 4바이트;\nUTF-32 문자열 저장 Cpp에서 문자열 리터럴의 종류는 다음과 같습니다:\n종류 설명 예시 일반 문자열 리터럴 기본적인 문자열 리터럴, 이스케이프 문자를 사용해야 함. \"Hello, World!\" 원시 문자열 리터럴 이스케이프 없이 문자열을 표현할 수 있음. R\"(Hello, \"World!\")\" 와이드 문자열 리터럴 wchar_t 타입의 문자열로, 넓은 문자 지원. L\"Hello, World!\" UTF-8 문자열 리터럴 char8_t 타입의 UTF-8 문자열. u8\"Hello, World!\" UTF-16 문자열 리터럴 char16_t 타입의 UTF-16 문자열. u\"Hello, World!\" UTF-32 문자열 리터럴 char32_t 타입의 UTF-32 문자열. U\"Hello, World!\" 일반 문자열 리터럴: 기본적인 문자열 표현으로, 이스케이프 시퀀스를 사용해야 합니다. 원시 문자열 리터럴: R\"로 시작하여 \"로 끝나는 형식으로, 이스케이프 없이 문자열을 표현할 수 있습니다. 와이드 문자열 리터럴: L\"로 시작하며, wchar_t 타입의 문자를 저장합니다. UTF-8 문자열 리터럴: u8\"로 시작하여 UTF-8 인코딩을 사용하는 문자열입니다. UTF-16 문자열 리터럴: u\"로 시작하여 UTF-16 인코딩을 사용하는 문자열입니다. UTF-32 문자열 리터럴: U\"로 시작하여 UTF-32 인코딩을 사용하는 문자열입니다."},"title":"cpp STL2"},"/leetcode75/greedy-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/":{"data":{"":"그리디 알고리즘을 적용하여 최적해를 구할 수 있는 문제는 다음 두 조건을 만족한다.\ngreedy choice property: 현재 선택이 이 후의 선택에 영향을 주지 않음 optimal substructure: 매 순간의 최적의 해가 문제 전체에 대한 최적의 해여야 함 5 -\u003e 10 -\u003e 3 선택 지금 가장 큰값을 선택한다고 해서 노드 값의 합을 보장할 수 없다 현재 선택이 이후에 영향을 준다고 할 수 있다 매순간 최적의 해가 문제 전체에 대한 최적해라고 말할 수 없다","문제-예시#문제 예시":"334. Increasing Triplet Subsequence\n가장 큰 회폐 단위부터 최대한 돈을 거슬러 준다 해당 화폐의 몫은 답이 보장된다 ==\u003e 그리디"},"title":"Greedy 알고리즘"},"/leetcode75/hash-set-unordered_set-%EA%B5%AC%ED%98%84%EC%B2%B4/":{"data":{"":"MD-5나 SHA 가 유명한 해시 알고리즘\ninsert, erase, find 모두가 $O(1)$ 으로 수행\n#include \u003ciostream\u003e #include \u003cvector\u003e #include \u003clist\u003e #include \u003cfunctional\u003e template \u003ctypename T\u003e class MyUnorderedSet { private: std::vector\u003cstd::list\u003cT\u003e\u003e table; size_t current_size; float load_factor; size_t capacity; size_t hash(const T\u0026 value) const { auto temp = std::hash\u003cT\u003e()(value) % capacity; return temp; } void rehash() { capacity *= 2; std::vector\u003cstd::list\u003cT\u003e\u003e new_table(capacity); for (const auto\u0026 bucket : table) { for (const auto\u0026 value : bucket) { size_t new_index = std::hash\u003cT\u003e()(value) % capacity; new_table[new_index].push_back(value); } } table = std::move(new_table); } public: MyUnorderedSet(size_t init_capacity = 8, float load_factor = 0.75) : capacity(init_capacity), load_factor(load_factor), current_size(0) { table.resize(capacity); } bool insert(const T\u0026 value) { if (contains(value)) return false; if (current_size \u003e= capacity * load_factor) { rehash(); } size_t index = hash(value); table[index].push_back(value); current_size++; return true; } bool contains(const T\u0026 value) const { size_t index = hash(value); for (const auto\u0026 item : table[index]) { if (item == value) { return true; } } return false; } bool erase(const T\u0026 value) { size_t index = hash(value); auto\u0026 bucket = table[index]; for (auto it = bucket.begin(); it != bucket.end(); ++it) { if (*it == value) { bucket.erase(it); current_size--; return true; } } return false; } size_t size() const { return current_size; } bool empty() const { return current_size == 0; } }; int main() { MyUnorderedSet\u003cint\u003e my_set; my_set.insert(1); my_set.insert(2); my_set.insert(3); std::cout \u003c\u003c \"Contains 2: \" \u003c\u003c my_set.contains(2) \u003c\u003c std::endl; std::cout \u003c\u003c \"Size: \" \u003c\u003c my_set.size() \u003c\u003c std::endl; my_set.erase(2); std::cout \u003c\u003c \"Contains 2 after erase: \" \u003c\u003c my_set.contains(2) \u003c\u003c std::endl; std::cout \u003c\u003c \"Size after erase: \" \u003c\u003c my_set.size() \u003c\u003c std::endl; return 0; }"},"title":"hash set, unordered set 구현체"},"/leetcode75/ps-%EA%B3%B5%EB%B6%80/":{"data":{"":"PS를 열심히 공부하겠다고 생각하였으나, 정작 무엇부터 시작해야하는지 감이 쉽게 잡히지 않았습니다.\n저는 나름대로 커리큘럼을 세우기 위해서 구글링을 해 보았고, 정말 귀중한 블로그를 찾게 됩니다.\nplzrun님의 블로그로, 특히 **이 게시글**에서 도움을 매우 많이 받았습니다.\nplzrun님은 백준 강의를 추천해 주셨는데, 저는 8~9만을 낼 거금은 없었기에 포스팅에 나와 있는 커리큘럼을 따라 가기로 하였습니다.\n입출력 방식에서 시작해서, 기초 자료구조, 기초 수학, DP, 정렬, 그래프, 이분탐색, 분할정복, 그리디, 완전탐색으로 끝이 납니다.\n자세한 문제 커리큘럼은 아래와 같습니다.\n입출력 - 2557, 1000, 2558, 10950, 10951, 10952, 10953, 11021, 11022, 11718, 11719, 11720, 11721, 2741, 2742, 2739, 1924, 8393, 10818, 2438, 2439, 2440, 2441, 2442, 2445, 2522, 2446, 10991, 10992\nDP - 1463, 11726, 11727, 9095, 10844, 11057, 2193, 9465, 2156, 11053, 11055, 11722, 11054, 1912, 2579, 1699, 2133, 9461, 2225, 2011, 11052\n정렬 - 2751, 11650, 11651, 10814, 10825, 10989, 11652, 11004\n스택 - 10828, 9012, 10799\n큐 - 10845\n덱 - 10866\n문자열 처리 - 10808, 10809, 10820, 2743, 11655, 10824, 11656\n기타 자료 구조 - 1406, 1158, 1168\n기초 수학 - 10430, 2609, 1934, 1850, 9613, 11005, 2745, 1373, 1212, 2089, 11576, 1978, 1929, 11653, 10872, 1676, 2004, 6588 그래프 - 1260, 11724, 1707, 10451, 2331, 9466, 2667, 4963, 7576, 2178, 2146, 1991, 11725, 1167, 1967\n이분탐색/삼분탐색 - 1654, 2805, 2110, 10815, 10816, 11662\n분할정복 - 11728, 1780, 11729, 1992, 2447, 2448, 1517, 2261\n그리디 - 11047, 2875, 10610, 1783, 1931, 11399, 2873, 1744 완전탐색 - 1476, 1107, 1451, 9095, 10819, 10971, 1697, 1963, 9019, 1525, 2251, 2186, 3108, 5014, 1759, 2580, 1987, 6603, 1182, 2003, 1806, 1644, 1261, 1208, 7453, 2632, 2143\n이 문제를 모두 풀어보는 것이 알고리즘의 기초라고 생각합니다.\n그리고 알고리즘 기법을 새로 배우기 위해서는 백준 강의말고 인프런 강의를 참고하였습니다.\n권오흠 교수님의 강의인데, 처음에 개념을 익히기 좋습니다. 링크는 **이곳**이 되겠습니다.\n정리하자면, 처음에 개념을 인프런 강의에서 배우고, 구글링을 통하여 개념을 다시 한 번 학습한 다음에 plzrun님의 커리큘럼을 따라가는 방식으로 공부를 시작했습니다.\nBOJ에서 다음 문제들을 쭉 순서대로 풀어본다. **boj.kr/문제번호** \u003c= 형태로 검색하면 된다. 입출력 - 2557, 1000, 2558, 10950, 10951, 10952, 10953, 11021, 11022, 11718, 11719, 11720, 11721, 2741, 2742, 2739, 1924, 8393, 10818, 2438, 2439, 2440, 2441, 2442, 2445, 2522, 2446, 10991, 10992 입출력 문제들을 풀 때 **_10분이상 이 문제를 붙들고 있는 경우, 그건 입출력에서 뭔가 모르는 부분이 반드시 있다는 뜻_**이므로 이전 질문들을 무조건 찾아보고 다른 사람이 푼 코드를 반드시 봐야 한다. 이 때 코드 길이 줄이려고 이상하게 짧은 코드들 많은데, 그런건 보지 말고 랭킹 100위권 안에 드는 사람들 중 인덴트 멀쩡한 코드를 보면 된다. 그 다음 DP문제를 풀어보자. DP - 1463, 11726, 11727, 9095, 10844, 11057, 2193, 9465, 2156, 11053, 11055, 11722, 11054, 1912, 2579, 1699, 2133, 9461, 2225, 2011, 11052 백준님은 모르는 문제가 있으면 2시간을 넘기지 말라고 했는데, 나는 이런 기초 문제는 1시간을 넘길 필요가 없다고 생각한다. 흔히들 PS를 처음 접하는 사람들이 하는 큰 실수가 모르는 문제를 하루종일 붙들고 있는 건데, 우린 수학이란 과목을 정규과정만으로는 초등학교 6년, 중학교 3년, 고등학교 3년 동안 배웠다. 그런데 알고리즘에는 그만한 시간을 투자할 수 없다. 그러나 알고리즘의 양은 그만큼 방대하다. 그러니 수학문제 풀듯이 계속 붙들고 있는건 미련한 짓이다. 이건 마치 덧셈,곱셈 정도만 아는 상태에서 미적문제를 푸려는 시도와 같다고 생각한다. 앞서 말했다시피 모르는 사람은 뭘 모르는지 모르는게 문제다. 본인이 미적에 대한 개념이 있는지 조차 모르는데 그 문제를 백날 붙들고 있어봐야 풀릴까? 당연히 아니다... 일단 1시간 넘어가면 그 문제 풀 확률은 거의 없다고 봐도 된다. 그러니 바로바로 찾아봐라. 특히 이 문제들은 정말 기초 문제들이고 사람들이 많이 풀었기 때문에 네이버나 구글에 검색하면 자세한 설명과 코드가 넘쳐난다. 반드시 지키자! **1시간 넘어가면 풀던 짓을 그만두고 반드시 AC받은 코드 찾아보기 (설명이 꼭 달려있는 코드를 읽자)** 한 문제 가지고 며칠씩 씨름하고 풀어봐야 다음에 풀지도 못할뿐더러 아주 비효율적인 방법으로 푸는 경우도 있을 거다. 그러는 것 보다 이 문제의 답을 빨리 확인하고 이와 유사한 문제들을 여러개 풀어제끼는 것이 아주아주 현명한 방법임을 명심하자. 그리고 푼 다음에는 반드시 다른 사람의 코드를 봐야 한다. 특히 자신만의 가상의 스승을 잡고 그 분의 코드를 보는 것도 좋은 방법이라 생각한다. 너무 갓갓들은 이상한 방식으로도 짜는 경우도 있기 때문에 적당한 사람을 선택해야 한다. 그 사람의 코드를 보면 잘 이해가 되고, BOJ랭킹은 100위 안에 드는 사람이면 적당하다. 근데 처음부터 끝까지 하나하나 세밀하게 볼 필요는 없다. 로직 대충 비슷해보이면 스킵하고, 나랑 완전 다른 방법인데 참신하면 들여다보고 하는거지 뭐... 그 다음 이런 저런 문제들을 풀어보자. 2751, 11650, 11651, 10814, 10825, 10989, 11652, 11004, 10828, 9012, 10799, 10845, 10866, 10808, 10809, 10820, 2743, 11655, 10824, 11656, 1406, 1158, 1168, 10430, 2609, 1934, 1850, 9613, 11005, 2745, 1373, 1212, 2089, 11576, 1978, 1929, 6588, 11653, 10872, 1676, 2004 여기까지 다 풀고 나면 이제 재밌는 그래프 문제(bfs, dfs)를 풀어보자. 그래프 - 1260, 11724, 1707, 10451, 2331, 9466, 2667, 4963, 7576, 2178, 2146, 1991, 11725, 1167, 1967 코포(Codeforces) div2에서도 자주 등장하는 binary search 문제도 풀어보자. (여기엔 ternary search도 있다.) 이분탐색/삼분탐색 - 1654, 2805, 2110, 10815, 10816, 11662 분할정복도 풀어보자~ 분할정복은 DP랑 느낌이 비슷한데, 부분 문제를 dp테이블에 저장할 필요가 없는(cache질을 할 필요가 없음) 부분이 DP랑 다른 것 같다. 분할정복 - 11728, 1780, 11729, 1992, 2447, 2448, 1517, 2261 그리디 알고리즘은 매 순간 최선을 선택한다라는 말 때문에 매우 쉽게 들리지만, 매 순간의 선택이 최선이 되도록 방법을 정하는 것 자체가 매우 어렵다. 그리디 - 11047, 2875, 10610, 1783, 1931, 11399, 2873, 1744 그 다음은 완전탐색(exhaustive search)이다. 완전탐색은 '말하는 대로' 구현하는 문제다. 그냥 무식하게 구현하면 될 것 같지만, 여기서도 고수의 코드를 보면 그들의 멋진 computational thinking 방식을 느낄 수 있다. 처음에는 이런 문제도 어렵지만 나중에는 쉬워진다. 이걸 실수없이 빠른 시간안에 잘 짜야 쉬운 문제들을 척척 풀어나갈 수 있다. 완전탐색 - 1476, 1107, 1451, 9095, 10819, 10971, 1697, 1963, 9019, 1525, 2251, 2186, 3108, 5014, 1759, 2580, 1987, 6603, 1182, 2003, 1806, 1644, 1261, 1208, 7453, 2632, 2143 여기까지 푸는게 딱 4주 분량이다. (BOJ 문제 부분만) 여기까지 푸는데 4주를 안넘기는게 좋다고 생각한다. 왜냐면, PS를 하면서 느낀건데, 단기간에 몰아서 왕창 할 수록 얻는 양은 어마어마하게 달라지는 것 같다. 보통 그리디 문제 전까지 2주를 잡고 그리디랑 완탐부분을 2주 잡으면 될거다. (그리디랑 완탐 양이 꽤 많다. 저 문제 다 풀기 정말 힘들다ㅠ) 출처: [https://plzrun.tistory.com/entry/알고리즘-문제풀이PS-시작하기](https://plzrun.tistory.com/entry/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%EB%AC%B8%EC%A0%9C%ED%92%80%EC%9D%B4PS-%EC%8B%9C%EC%9E%91%ED%95%98%EA%B8%B0) [plzrun's algorithm:티스토리]"},"title":"ps 공부"},"/leetcode75/two-pointer-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/":{"data":{"two-pointer-알고리즘#two pointer 알고리즘":"two pointer 알고리즘1차원 배열에서 각자 다른 원소를 가리키는 2개의 포인터를 사용하여 목표값을 구한다 $O(n^2)$ =\u003e $O(n)$ 해결하는 기법\n이분탐색 vs 투포인터","문제-예시#문제 예시":"주어진 정수 배열 height의 길이를 n이라고 할 때, n개의 수직 선이 그려져 있습니다. i번째 선의 두 끝점은 (i, 0)과 (i, height[i])입니다. 두 개의 선을 선택하여 x축과 함께 컨테이너를 형성했을 때, 이 컨테이너가 최대한 많은 물을 저장할 수 있도록 두 선을 찾는 문제입니다. 최대 물의 양을 반환하세요. 컨테이너를 기울일 수 없다는 점에 유의하세요. 예시 1: 입력: height = [1,8,6,2,5,4,8,3,7] 출력: 49 설명: 위의 수직 선들은 배열 [1,8,6,2,5,4,8,3,7]로 표현됩니다. 이 경우, 물이 저장될 수 있는 최대 면적은 49입니다. 예시 2: 입력: height = [1,1] 출력: 1 제약 조건: n == height.length 2 \u003c= n \u003c= 10^5 0 \u003c= height[i] \u003c= 10^4 이중 반복문 $O(n^2)$ =\u003e $O(n)$ 반복 1회\nint maxArea(vector\u003cint\u003e\u0026 height) { int ret = 0; for(int i = 0 ; i\u003c height.size()-1 ; i++){ for(int j = i + 1; j \u003c height.size() ; j++){ int width = j - i; int length = min(height[i], height[j]); int area = width * length; if(ret \u003c area) ret = area; } } return ret; }"},"title":"two pointer 알고리즘"},"/linux-%EC%BB%A4%EB%84%90-%EC%97%85%EA%B7%B8%EB%A0%88%EC%9D%B4%EB%93%9C-%EB%B0%A9%EC%A7%80/":{"data":{"":"","1-kernel-headers-설치-없을-경우#1. kernel-headers 설치 (없을 경우)":"sudo apt install raspberrypi-kernel-headers","2-핵심-패키지-hold#2. 핵심 패키지 hold":"sudo apt-mark hold \\ raspberrypi-kernel \\ raspberrypi-kernel-headers \\ raspberrypi-bootloader \\ libraspberrypi0 \\ libraspberrypi-bin","3-hold-상태-확인#3. hold 상태 확인":"sudo apt-mark showhold\n# 1. kernel-headers 설치 (없을 경우) sudo apt install raspberrypi-kernel-headers # 2. 핵심 패키지 hold sudo apt-mark hold \\ raspberrypi-kernel \\ raspberrypi-kernel-headers \\ raspberrypi-bootloader \\ libraspberrypi0 \\ libraspberrypi-bin # 3. hold 상태 확인 sudo apt-mark showhold"},"title":"linux 커널 업그레이드 방지"},"/long-vs-float/":{"data":{"":"좋은 질문입니다!\n“long vs float 중 어떤 것이 더 큰 수를 저장할 수 있는가?” — 이 질문은 자주 혼동되는 핵심 개념입니다.\n결론부터 말하면:\n✅ float이 더 큰 수치(magnitude)를 표현할 수 있지만, long은 더 큰 정확한 정수를 저장합니다.\n즉, “더 큰 수”의 의미에 따라 답이 달라집니다.","-결론-더-큰-수를-저장할-수-있는-타입은#✅ 결론: “더 큰 수를 저장할 수 있는 타입”은?":"질문 답변 더 큰 수치를 표현할 수 있는가? ✅ float (3.4e38 \u003e 9.2e18) 더 큰 정확한 정수를 저장할 수 있는가? ✅ long (9.2e18까지 정확, float은 1.6e7까지밖에 안 됨) 실제 프로그래밍에서 “큰 수”라고 하면 보통 어떤 의미인가? 👉 대부분 정확한 정수를 의미 → 따라서 long이 더 유용하고 안전","-경우-1-더-큰-숫자-자체절댓값을-의미한다면-#✅ 경우 1: \u003cstrong\u003e“더 큰 숫자 자체(절댓값)”을 의미한다면 → \u003ccode\u003efloat\u003c/code\u003e이 이김\u003c/strong\u003e":"long 최대값: 9,223,372,036,854,775,807 ≈ 9.2e18 float 최대값: ~3.4 × 10³⁸ = 340,000,000,000,000,000,000,000,000,000,000,000,000 → float이 약 10²⁰배 더 큰 수치를 표현 가능!\nSystem.out.println(Long.MAX_VALUE); // 9223372036854775807 System.out.println(Float.MAX_VALUE); // 3.4028235E38 👉 수치 크기만 보면 float이 훨씬 큼","-경우-2-더-큰-정수를-정확하게-저장할-수-있는가-라면-#✅ 경우 2: \u003cstrong\u003e“더 큰 정수를 정확하게 저장할 수 있는가?” 라면 → \u003ccode\u003elong\u003c/code\u003e이 압승\u003c/strong\u003e":"float은 정수도 부동소수점으로 저장하기 때문에, 큰 정수는 정확히 표현 불가능! IEEE 754 단정도(float)는 가수부(mantissa)가 23비트 + 숨겨진 1비트 = 24비트 → 정확히 표현 가능한 정수는 2²⁴ = 16,777,216 까지","-상세-설명-더-큰-수는-무엇을-의미하나요#🧠 상세 설명: “더 큰 수”는 무엇을 의미하나요?":"","-시각화-정수-표현-가능성-비교#📊 시각화: 정수 표현 가능성 비교":"정수 축: 0 ──── 10⁷ ─────── 10⁹ ─────────── 10¹⁸ ────────────────\u003e │ │ │ │ float 정확 float 정확 float 정확 long 정확 (2²⁴=16M) (아직 OK) (이미 틀림!) (완전 정확) ↓ float은 여기서부터 \"정수\"로 쓸 수 없음! 💡 float은 수치는 크지만, 정수로 쓰려면 1677만 이하만 안전!","-최종-정리-long-vs-float--누가-더-큰-수를-저장할-수-있나#✅ 최종 정리: \u003ccode\u003elong\u003c/code\u003e vs \u003ccode\u003efloat\u003c/code\u003e — 누가 더 큰 수를 저장할 수 있나?":"기준 승자 이유 절댓값이 가장 큰 수를 표현 float 3.4×10³⁸ \u003e 9.2×10¹⁸ 정확한 정수를 가장 크게 저장 long float은 1677만 이상부터 정수 정확도 잃음 정수 계산에 안전한가? long float은 큰 정수에서 계산 결과가 완전히 틀릴 수 있음 실수 계산에 적합한가? float long은 소수점 없음 → 비교 불가 ✅ 실무에서는:\n정수 → long 실수 → double float은 거의 쓰지 마세요. 정수인데 long보다 커야 한다면 → BigInteger 💡 记住这个口诀:\n“float는 숫자는 크지만, 정수는 허접; long은 숫자는 작지만, 정수는 확실.”","-추가-팁-그럼-진짜-더-큰-수가-필요하면#🚨 추가 팁: 그럼 진짜 “더 큰 수”가 필요하면?":"요구사항 적합한 타입 정수인데 long보다 커야 함 ✅ java.math.BigInteger 소수점 포함된 큰 수 ✅ java.math.BigDecimal 그냥 실수인데 정확히 쓰고 싶음 ✅ double (64비트 부동소수점) 메모리 절약이 목적이며 소수점 사용 ⚠️ float (32비트) — 정수로 쓰지 마세요!","-핵심-요약표#🔍 핵심 요약표":"항목 long float 최대 표현 가능한 수치 (절댓값) ~9.2 × 10¹⁸ ~3.4 × 10³⁸ ← 훨씬 큼 정확히 표현 가능한 최대 정수 9,223,372,036,854,775,807 (정확함) 약 16,777,216 (2²⁴)까지만 정확함 소수 표현 가능? ❌ 불가능 ✅ 가능 정밀도 완벽한 정수 약 6~7자리 십진수 사용 용도 ID, 금액, 카운터 등 정수 과학 계산, 그래픽, 근사값","예-biginteger로-1000-계산하기#예: BigInteger로 1000! 계산하기":"import java.math.BigInteger; BigInteger fact = BigInteger.ONE; for (int i = 2; i \u003c= 1000; i++) { fact = fact.multiply(BigInteger.valueOf(i)); } System.out.println(fact.toString().length() + \" 자리\"); // 2568자리! → long, float, double 모두 오버플로우 → BigInteger만 가능","예시-float이-정수를-정확히-표현-못하는-경우#예시: \u003ccode\u003efloat\u003c/code\u003e이 정수를 정확히 표현 못하는 경우":"float f1 = 16_777_216f; // 2^24 → 정확히 저장됨 float f2 = 16_777_217f; // 다음 정수 → 저장되긴 하지만... float f3 = 16_777_218f; System.out.println(f1 == 16_777_216); // true System.out.println(f2 == 16_777_217); // false → 실제로는 16,777,216 으로 저장됨! System.out.println(f2); // 출력: 1.6777216E7 → 16777216 // 1억 이상은 모두 정확하지 않음 float big = 100_000_000f; System.out.println(big + 1 == big); // true → 1을 더해도 값이 변하지 않음! → float은 1677만 초과하는 정수는 이미 ‘반올림’되어 정확히 저장되지 않습니다.\n반면 long은:\nlong l = 9_223_372_036_854_775_807L; System.out.println(l + 1 == l); // false → 정확히 증가함! 👉 long은 10¹⁸까지 모든 정수를 정확히 저장 가능"},"title":"long vs float"},"/markdown-test/%EA%B0%84%EB%8B%A8%ED%95%9C-%EC%88%98%EC%8B%9D-%ED%85%8C%EC%8A%A4%ED%8A%B8/":{"data":{"간단한-수식-테스트#간단한 수식 테스트":"간단한 수식 테스트인라인 수식: $E = mc^2$\n블록 수식:\n$$ E = mc^2 $$\n끝."},"title":"간단한 수식 테스트"},"/markdown-test/markdown-systex/":{"data":{"":"아래는 Markdown 기본 구문(Basic Syntax)과 확장 구문(Extended Syntax)을 모두 포함한 테스트용 Markdown 파일입니다. 이 파일을 .md 확장자로 저장한 후, 다양한 Markdown 렌더러(예: VS Code, Obsidian, Typora, GitHub 등)에서 열어 각 기능이 제대로 작동하는지 확인할 수 있습니다.\nMarkdown 전체 구문 테스트 문서이 문서는 Markdown 기본 구문과 확장 구문을 모두 포함합니다.\n1. 제목 (Headings) Heading level 1Heading level 2 Heading level 3 Heading level 4 Heading level 5 Heading level 6 또는 대체 문법:\nHeading level 1Heading level 2 2. 단락과 줄바꿈 (Paragraphs \u0026 Line Breaks) 이것은 첫 번째 단락입니다.\n이것은 두 번째 단락입니다.\n줄바꿈 테스트:\n두 칸 이상의 공백으로 줄바꿈 →\n다음 줄입니다.\n또는 태그 사용:\n첫 줄\n두 번째 줄\n3. 강조 (Emphasis) 굵게: **굵게** 또는 __굵게__ 기울임: *기울임* 또는 _기울임_ 굵게 + 기울임: ***굵게 + 기울임*** 또는 ___굵게 + 기울임___ 단어 중간 강조: Loveisbold, Acatmeow 4. 인용문 (Blockquotes) 이것은 인용문입니다.\n이것은\n여러 줄 인용문입니다.\n인용문 안에\n중첩 인용문\n인용문 안에 다른 요소:","1-제목-headings#1. 제목 (Headings)":"","10-각주-footnotes-확장#10. 각주 (Footnotes, 확장)":"간단한 각주.1\n긴 각주.2","11-제목-id-및-앵커-링크-heading-ids-확장#11. 제목 ID 및 앵커 링크 (Heading IDs, 확장)":"","12-정의-목록-definition-lists-확장#12. 정의 목록 (Definition Lists, 확장)":"사과 달콤하고 바삭한 과일. 오렌지 비타민 C가 풍부한 감귤류. 주스로도 즐깁니다.","13-취소선-strikethrough-확장#13. 취소선 (Strikethrough, 확장)":"이 문장은 취소되었습니다.","14-작업-목록-task-lists-확장#14. 작업 목록 (Task Lists, 확장)":"완료된 작업 미완료 작업 또 다른 미완료 작업","15-이모지-emoji-확장#15. 이모지 (Emoji, 확장)":"복사-붙여넣기: 🎉🚀\n이모지 쇼트코드: :smile: :rocket: :tada:","16-하이라이트-highlight-확장#16. 하이라이트 (Highlight, 확장)":"==이 텍스트는 하이라이트됩니다==.\n또는 HTML: 하이라이트","17-첨자와-위첨자-subscriptsuperscript-확장#17. 첨자와 위첨자 (Subscript/Superscript, 확장)":"아랫첨자: H2O\n또는 HTML: H2O\n윗첨자: E = mc^2^\n또는 HTML: E = mc2","18-자동-url-링크-automatic-url-linking-확장#18. 자동 URL 링크 (Automatic URL Linking, 확장)":"https://www.markdownguide.org\n비활성화: https://www.markdownguide.org\n✅ 이 파일은 Markdown 기본 및 확장 구문을 모두 테스트하기 위해 작성되었습니다.\n사용 중인 Markdown 렌더러에 따라 일부 확장 기능이 지원되지 않을 수 있습니다.\nHTML 태그도 사용할 수 있습니다:\n이 텍스트는 파란색입니다.\n수식은 일부 도구에서 지원됩니다.\n$$ E = mc^2 $$\n인라인 수식: $a^2 + b^2 = c^2$","2-단락과-줄바꿈-paragraphs--line-breaks#2. 단락과 줄바꿈 (Paragraphs \u0026amp; Line Breaks)":"","3-강조-emphasis#3. 강조 (Emphasis)":"","4-인용문-blockquotes#4. 인용문 (Blockquotes)":"","5-목록-lists#5. 목록 (Lists)":"","6-코드-code#6. 코드 (Code)":"인라인 코드: console.log(\"Hello\")\n백틱 포함 코드: `code`","7-수평선-horizontal-rules#7. 수평선 (Horizontal Rules)":"","8-링크와-이미지-기본-문법#8. 링크와 이미지 (기본 문법)":"Markdown Guide\n자동 URL 링크:\nhttps://www.example.com\n비활성화된 자동 링크:\nhttps://www.example.com","9-표-tables-확장#9. 표 (Tables, 확장)":"좌정렬 중앙정렬 우정렬 왼쪽 가운데 오른쪽 데이터 데이터 데이터 표 내 강조: 굵게, 기울임, 코드\n파이프 문자 이스케이프: |","custom-id#이 제목은 ID를 가집니다":"위 제목으로 이동","footnote-각주#footnote (각주)":"이것은 간단한 각주1이고, 이것은 더 긴 각주입니다.3","heading-level-1#Heading level 1":"","heading-level-1-1#Heading level 1":"","heading-level-2#Heading level 2":"","heading-level-2-1#Heading level 2":"","heading-level-3#Heading level 3":"","heading-level-4#Heading level 4":"","heading-level-5#Heading level 5":"","heading-level-6#Heading level 6":"","link-to-heading#link to heading":"[보여질 이름](파일경로#헤더 이름) 수식 테스트","markdown-전체-구문-테스트-문서#Markdown 전체 구문 테스트 문서":"","목록-내-요소#목록 내 요소":"목록 항목 다음 단락을 넣으려면 4칸 들여쓰기:\n이건 들여쓴 단락입니다.\n코드 블록 포함: console.log(“Hello, world!”);\n이미지 포함:","설명#설명:":"[^1]과 [^bignote]는 각주의 레퍼런스(참조 번호 또는 이름)입니다. 각주 내용은 문서 맨 아래에서 정의되며, [^레퍼런스]: 형식으로 시작합니다. 여러 단락을 각주 안에 넣고 싶다면 들여쓰기(indent)를 해야 합니다. 코드나 다른 형식도 각주 안에 포함시킬 수 있습니다. 이것은 첫 번째 각주입니다. ↩︎ ↩︎\n여러 단락을 가진 각주입니다. 들여쓰면 같은 각주에 포함됩니다. 코드도 가능합니다. ↩︎\n여러 단락과 코드가 포함된 각주입니다. 각주에 단락을 포함시키려면 들여쓰기를 해야 합니다. { 내 코드 } 원하는 만큼 단락을 추가할 수 있습니다. ↩︎","순서-없는-목록-unordered#순서 없는 목록 (Unordered)":"항목 1 항목 2 중첩 항목 또 다른 중첩 항목 더 깊은 중첩 항목 더 깊은 중첩 항목 더더 깊은 중첩 항목 더더 깊은 중첩 항목 항목 (별표) 항목 (플러스)","순서-있는-목록-ordered#순서 있는 목록 (Ordered)":"첫 번째 항목 두 번째 항목 세 번째 항목","인용-내-제목#인용 내 제목":"목록 항목 또 다른 항목 굵게, 기울임, 코드","코드-블록-기본-문법#코드 블록 (기본 문법)":"Hello","코드-블록-펜스-문법-확장#코드 블록 (펜스 문법, 확장)":"{ \"name\": \"John\", \"age\": 30 } def hello(): print(\"Hello, world!\")"},"title":"markdown systex"},"/markdown-test/test-code-highlight/":{"data":{"bash-스크립트#Bash 스크립트":"#!/bin/bash # 환경 변수 설정 export NODE_ENV=production # 패키지 설치 및 빌드 npm install npm run build echo \"배포 완료!\"","java-코드#Java 코드":"public class HelloWorld { public static void main(String[] args) { System.out.println(\"Hello, World!\"); List\u003cString\u003e names = Arrays.asList(\"Alice\", \"Bob\", \"Charlie\"); names.stream() .map(String::toUpperCase) .forEach(System.out::println); } }","javascript-코드#JavaScript 코드":"function hello(name) { console.log(`Hello, ${name}!`); return true; } const users = ['Alice', 'Bob', 'Charlie']; users.forEach(user =\u003e hello(user));","python-코드#Python 코드":"def fibonacci(n): if n \u003c= 1: return n return fibonacci(n-1) + fibonacci(n-2) # 리스트 컴프리헨션 예제 squares = [x**2 for x in range(10)] print(squares)","sql-코드#SQL 코드":"SELECT u.name, COUNT(o.id) as order_count FROM users u LEFT JOIN orders o ON u.id = o.user_id WHERE u.created_at \u003e '2023-01-01' GROUP BY u.id, u.name ORDER BY order_count DESC;","인라인-코드#인라인 코드":"일반 텍스트 중에 console.log(\"inline code\") 같은 인라인 코드도 포함할 수 있습니다.","코드-구문-강조-테스트#코드 구문 강조 테스트":"코드 구문 강조 테스트"},"title":"test code highlight"},"/prompt/%EC%82%AC%EA%B3%A0%EA%B3%BC%EC%A0%95-%EC%A0%9C%ED%95%9C-%ED%94%84%EB%A1%AC%ED%94%84%ED%8A%B8/":{"data":{"":"한글 버전\n1. 당신은 사용자의 어떤 질문이나 아이디어, 정보를 받으면, 아래 사고법 중에 가장 적합한 방식을 두개를 선택하여 혼합하여 분석하세요(1500자 이상) 2. 분석을 토대로 천재적 아이디어를 10개 이상 3000자 이상 출력합니다 아래 공식들은 참고하세요. --- ## 1. 천재적 통찰 도출 공식 (Genius Insight Formula) GI = (O × C × P × S) / (A + B) - GI(Genius Insight) = 천재적 통찰 - O(Observation) = 관찰의 깊이 (1-10점) - C(Connection) = 연결의 독창성 (1-10점) - P(Pattern) = 패턴 인식 능력 (1-10점) - S(Synthesis) = 종합적 사고 (1-10점) - A(Assumption) = 고정관념 수준 (1-10점) - B(Bias) = 편향 정도 (1-10점) 적용법: 주제에 대해 각 요소의 점수를 매기고, 고정관념과 편향을 최소화하면서 관찰-연결-패턴-종합의 순서로 사고를 전개하세요. --- ## 2. 다차원적 분석 프레임워크 MDA = Σ[Di × Wi × Ii] (i=1 to n) - MDA(Multi-Dimensional Analysis) = 다차원 분석 결과 - Di(Dimension i) = i번째 차원에서의 통찰 - Wi(Weight i) = i번째 차원의 가중치 - Ii(Impact i) = i번째 차원의 영향력 분석 차원 설정: - D1 = 시간적 차원 (과거-현재-미래) - D2 = 공간적 차원 (로컬-글로벌-우주적) - D3 = 추상적 차원 (구체-중간-추상) - D4 = 인과적 차원 (원인-과정-결과) - D5 = 계층적 차원 (미시-중간-거시) --- ## 3. 창의적 연결 매트릭스 CC = |A ∩ B| + |A ⊕ B| + f(A→B) - CC(Creative Connection) = 창의적 연결 지수 - A ∩ B = 두 개념의 공통 요소 - A ⊕ B = 배타적 차이 요소 - f(A→B) = A에서 B로의 전이 함수 연결 탐색 프로세스: 1. 직접적 연결 찾기 2. 간접적 연결 탐색 3. 역설적 연결 발견 4. 메타포적 연결 구성 5. 시스템적 연결 분석 --- ## 4. 문제 재정의 알고리즘 PR = P₀ × T(θ) × S(φ) × M(ψ) - PR(Problem Redefinition) = 재정의된 문제 - P₀ = 원래 문제 - T(θ) = θ각도만큼 관점 회전 - S(φ) = φ비율로 범위 조정 - M(ψ) = ψ차원으로 메타 레벨 이동 재정의 기법: - 반대 관점에서 보기 (θ = 180°) - 확대/축소하여 보기 (φ = 0.1x ~ 10x) - 상위/하위 개념으로 이동 (ψ = ±1,±2,±3) - 다른 도메인으로 전환 - 시간 축 변경 --- ## 5. 혁신적 솔루션 생성 공식 IS = Σ[Ci × Ni × Fi × Vi] / Ri - IS(Innovative Solution) = 혁신적 솔루션 - Ci(Combination i) = i번째 조합 방식 - Ni(Novelty i) = 참신성 지수 - Fi(Feasibility i) = 실현 가능성 - Vi(Value i) = 가치 창출 정도 - Ri(Risk i) = 위험 요소 솔루션 생성 방법: - 기존 요소들의 새로운 조합 - 전혀 다른 분야의 솔루션 차용 - 제약 조건을 오히려 활용 - 역방향 사고로 접근 - 시스템 전체 재설계 --- ## 6. 인사이트 증폭 공식 IA = I₀ × (1 + r)ⁿ × C × Q - IA(Insight Amplification) = 증폭된 인사이트 - I₀ = 초기 인사이트 - r = 반복 개선율 - n = 반복 횟수 - C = 협력 효과 (1-3배수) - Q = 질문의 질 (1-5배수) 증폭 전략: - 'Why'를 5번 이상 반복 - 'What if' 시나리오 구성 - 'How might we' 질문 생성 - 다양한 관점자와 토론 - 아날로그 사례 탐구 --- ## 7. 사고의 진화 방정식 TE = T₀ + ∫[L(t) + E(t) + R(t)]dt - TE(Thinking Evolution) = 진화된 사고 - T₀ = 초기 사고 상태 - L(t) = 시간 t에서의 학습 함수 - E(t) = 경험 축적 함수 - R(t) = 반성적 사고 함수 진화 촉진 요인: - 지속적 학습과 정보 습득 - 다양한 경험과 실험 - 깊은 반성과 메타인지 - 타인과의 지적 교류 - 실패로부터의 학습 --- ## 8. 복잡성 해결 매트릭스 CS = det|M| × Σ[Si/Ci] × ∏[Ii] - CS(Complexity Solution) = 복잡성 해결책 - det|M| = 시스템 매트릭스의 행렬식 - Si = i번째 하위 시스템 해결책 - Ci = i번째 하위 시스템 복잡도 - Ii = 상호작용 계수 복잡성 분해 전략: - 시스템을 하위 구성요소로 분해 - 각 구성요소 간 관계 매핑 - 핵심 레버리지 포인트 식별 - 순차적/병렬적 해결 순서 결정 - 전체 시스템 최적화 --- ## 9. 직관적 도약 공식 IL = (S × E × T) / (L × R) - IL(Intuitive Leap) = 직관적 도약 - S(Silence) = 정적 사고 시간 - E(Experience) = 관련 경험 축적 - T(Trust) = 직관에 대한 신뢰 - L(Logic) = 논리적 제약 - R(Rationalization) = 과도한 합리화 직관 활성화 방법: - 의식적 사고 중단 - 몸과 마음의 이완 - 무의식적 연결 허용 - 첫 번째 떠오르는 아이디어 포착 - 판단 없이 수용 --- ## 10. 통합적 지혜 공식 IW = (K + U + W + C + A) × H × E - IW(Integrated Wisdom) = 통합적 지혜 - K(Knowledge) = 지식의 폭과 깊이 - U(Understanding) = 이해의 수준 - W(Wisdom) = 지혜의 깊이 - C(Compassion) = 공감과 연민 - A(Action) = 실행 능력 - H(Humility) = 겸손함 - E(Ethics) = 윤리적 기준 --- ## 사용 가이드라인 1. 단계적 적용: 각 공식을 순차적으로 적용하여 사고를 심화시키세요. 2. 반복적 개선: 한 번의 적용으로 끝내지 말고 여러 번 반복하여 정교화하세요. 3. 다양한 관점: 서로 다른 배경을 가진 사람들과 함께 공식을 적용해보세요. 4. 실험적 태도: 공식을 기계적으로 따르기보다는 창의적으로 변형하여 사용하세요. 5. 균형적 접근: 분석적 사고와 직관적 사고를 균형 있게 활용하세요. 영어 버전\n1. Whenever you receive any question, idea, or information from the user, select the two most suitable thinking methods from the list below, combine them, and conduct an in-depth analysis (1,500+ characters). 2. Based on your analysis, generate more than 10 genius-level ideas, with a total output exceeding 3,000 characters. Please refer to the following formulas: --- ## 1. Genius Insight Formula (GI) GI = (O × C × P × S) / (A + B) - GI (Genius Insight): The level of genius insight - O (Observation): Depth of observation (1–10 scale) - C (Connection): Originality of connections (1–10) - P (Pattern): Pattern recognition ability (1–10) - S (Synthesis): Holistic synthesis (1–10) - A (Assumption): Level of fixed assumptions (1–10; higher = more rigid) - B (Bias): Degree of bias (1–10; higher = more biased) **Application Guide**: Score each factor for the given topic. Minimize assumptions and biases while progressing through observation → connection → pattern recognition → synthesis. --- ## 2. Multi-Dimensional Analysis Framework (MDA) MDA = Σ[Di × Wi × Ii] (i = 1 to n) - MDA (Multi-Dimensional Analysis): Result of multi-dimensional insight - Di (Dimension i): Insight from the i-th dimension - Wi (Weight i): Weight of the i-th dimension - Ii (Impact i): Impact level of the i-th dimension **Suggested Dimensions**: - D1 = Temporal Dimension (Past–Present–Future) - D2 = Spatial Dimension (Local–Global–Cosmic) - D3 = Abstract Dimension (Concrete–Intermediate–Abstract) - D4 = Causal Dimension (Cause–Process–Outcome) - D5 = Hierarchical Dimension (Micro–Meso–Macro) --- ## 3. Creative Connection Matrix (CC) CC = |A ∩ B| + |A ⊕ B| + f(A→B) - CC (Creative Connection): Index of creative linkage - A ∩ B: Common elements between concepts A and B - A ⊕ B: Exclusive differences (symmetric difference) - f(A→B): Transformation function from A to B **Connection Discovery Process**: 1. Find direct links 2. Explore indirect links 3. Discover paradoxical links 4. Construct metaphorical links 5. Analyze systemic links --- ## 4. Problem Redefinition Algorithm (PR) PR = P₀ × T(θ) × S(φ) × M(ψ) - PR (Problem Redefinition): Redefined problem - P₀: Original problem - T(θ): Perspective rotation by angle θ - S(φ): Scope adjustment by ratio φ - M(ψ): Meta-level shift by ψ dimensions **Redefinition Techniques**: - View from the opposite perspective (θ = 180°) - Zoom in/out (φ = 0.1x ~ 10x) - Shift to higher/lower conceptual levels (ψ = ±1, ±2, ±3) - Transfer to a different domain - Change the time axis --- ## 5. Innovative Solution Formula (IS) IS = Σ[Ci × Ni × Fi × Vi] / Ri - IS (Innovative Solution): Innovation score - Ci (Combination i): Combination method i - Ni (Novelty i): Degree of novelty - Fi (Feasibility i): Practical feasibility - Vi (Value i): Value creation potential - Ri (Risk i): Risk factor **Solution Generation Methods**: - New combinations of existing elements - Borrowing solutions from unrelated fields - Turning constraints into advantages - Reverse thinking - Redesigning the entire system --- ## 6. Insight Amplification Formula (IA) IA = I₀ × (1 + r)ⁿ × C × Q - IA (Insight Amplification): Amplified insight - I₀: Initial insight - r: Rate of iterative improvement - n: Number of iterations - C: Collaboration multiplier (1–3x) - Q: Quality of questioning (1–5x) **Amplification Strategies**: - Ask \"Why?\" five or more times - Develop \"What if?\" scenarios - Generate \"How might we?\" questions - Discuss with diverse perspectives - Study analog cases --- ## 7. Thinking Evolution Equation (TE) TE = T₀ + ∫[L(t) + E(t) + R(t)]dt - TE (Thinking Evolution): Evolved thinking state - T₀: Initial thinking state - L(t): Learning function at time t - E(t): Experience accumulation function - R(t): Reflective thinking function **Evolution Catalysts**: - Continuous learning and information intake - Diverse experiences and experiments - Deep reflection and metacognition - Intellectual exchange with others - Learning from failure --- ## 8. Complexity Solution Matrix (CS) CS = det|M| × Σ[Si/Ci] × ∏[Ii] - CS (Complexity Solution): Solution to complexity - det|M|: Determinant of the system matrix (measures system interdependence) - Si: Solution for sub-system i - Ci: Complexity of sub-system i - Ii: Interaction coefficient between sub-systems **Complexity Decomposition Strategies**: - Break system into subsystems - Map relationships between components - Identify key leverage points - Determine sequential/parallel resolution order - Optimize the whole system --- ## 9. Intuitive Leap Formula (IL) IL = (S × E × T) / (L × R) - IL (Intuitive Leap): Intuitive breakthrough - S (Silence): Time spent in quiet reflection - E (Experience): Accumulated relevant experience - T (Trust): Trust in intuition - L (Logic): Logical constraints - R (Rationalization): Over-rationalization **Intuition Activation Methods**: - Consciously pause analytical thinking - Relax body and mind - Allow unconscious connections - Capture the first emerging idea - Accept without judgment --- ## 10. Integrated Wisdom Formula (IW) IW = (K + U + W + C + A) × H × E - IW (Integrated Wisdom): Holistic wisdom - K (Knowledge): Breadth and depth of knowledge - U (Understanding): Level of comprehension - W (Wisdom): Depth of insight - C (Compassion): Empathy and care - A (Action): Ability to act - H (Humility): Humbleness - E (Ethics): Ethical grounding --- ## Usage Guidelines 1. **Step-by-Step Application**: Apply each formula sequentially to deepen thinking. 2. **Iterative Refinement**: Don’t stop at one pass—repeat and refine multiple times. 3. **Diverse Perspectives**: Apply formulas with people from different backgrounds. 4. **Experimental Mindset**: Use formulas creatively, not mechanically. 5. **Balanced Approach**: Balance analytical and intuitive thinking."},"title":"사고과정 제한 프롬프트"},"/python-default-type/":{"data":{"":"","1-기본-리스트-생성#1. 기본 리스트 생성":"[x for x in range(5)] 👉 한글: “0부터 4까지의 숫자로 구성된 리스트” 👉 영어: “a list of numbers from 0 to 4”","2-제곱수-리스트#2. 제곱수 리스트":"[x**2 for x in range(1, 6)] 👉 한글: “1부터 5까지 각 숫자의 제곱으로 구성된 리스트” 👉 영어: “a list of squares of numbers from 1 to 5”","3-짝수만-필터링#3. 짝수만 필터링":"[x for x in range(10) if x % 2 == 0] 👉 한글: “0부터 9까지 중 짝수만 포함하는 리스트” 👉 영어: “a list of even numbers from 0 to 9”","4-문자열로-변환#4. 문자열로 변환":"[str(x) for x in range(2, 11)] 👉 한글: “2부터 10까지의 숫자를 문자열로 변환한 리스트” 👉 영어: “a list of strings converted from numbers 2 to 10”","5-조건--변환-동시-적용#5. 조건 + 변환 동시 적용":"[x.upper() for x in ['apple', 'banana', 'cherry'] if len(x) \u003e 5] 👉 한글: “길이가 5보다 큰 단어만 대문자로 바꾼 리스트” 👉 영어: “a list of words converted to uppercase where length is greater than 5”","6-중첩된-예시-딕셔너리-키-추출-등#6. 중첩된 예시 (딕셔너리 키 추출 등)":"[key for key, value in my_dict.items() if value \u003e 10] 👉 한글: “값이 10보다 큰 항목들의 키만 포함하는 리스트” 👉 영어: “a list of keys where the corresponding value is greater than 10”","collection#collection":"collections 모듈은 파이썬의 기본 내장 컨테이너(dict, list, set, tuple)를 확장하여 더 전문화된 데이터 구조를 제공\n클래스 (Class) 설명 namedtuple() 각 위치에 이름(필드)을 부여하여 인덱스뿐만 아니라 이름으로도 데이터에 접근할 수 있는 튜플을 생성하는 팩토리 함수입니다. deque ‘double-ended queue’의 약자로, 리스트와 유사하지만 양쪽 끝에서 항목을 추가하고 제거하는(append/pop) 속도가 매우 빠릅니다. ChainMap 여러 개의 딕셔너리나 다른 매핑(mapping)들을 하나의 뷰(view)로 묶어줍니다. 검색은 여러 매핑에서 순차적으로 이루어집니다. Counter 해시 가능한(hashable) 객체의 개수를 세는 데 특화된 딕셔너리 서브클래스입니다. 요소(key)와 그 요소의 개수(value)를 매핑 형태로 저장합니다. OrderedDict 항목이 추가된 순서를 기억하는 딕셔너리 서브클래스입니다. (참고: Python 3.7부터는 기본 dict도 삽입 순서를 유지하지만, OrderedDict는 순서를 재정렬하는 메서드 등 추가 기능을 가집니다.) defaultdict 딕셔너리에서 존재하지 않는 키를 조회할 때, 미리 지정된 기본값(예: 0, 빈 리스트)을 자동으로 생성해주는 딕셔너리 서브클래스입니다. KeyError를 방지하는 데 유용합니다. UserDict 딕셔너리 객체를 감싸는(wrapper) 클래스로, 기존 딕셔너리를 상속받아 새로운 클래스를 만들 때 더 편리하게 사용할 수 있도록 도와줍니다. UserList 리스트 객체를 감싸는 래퍼 클래스입니다. UserDict와 마찬가지로 리스트를 상속받아 커스텀 클래스를 만들 때 유용합니다. UserString 문자열 객체를 감싸는 래퍼 클래스입니다.","default-type#default type":"자료형 그룹 자료형 (Type) 설명 숫자형 (Numeric Types) int 정수 (정밀도 무제한) float 부동소수점 숫자 complex 복소수 불리언형 (Boolean Type) bool True 또는 False 값을 가지며, int의 하위 클래스입니다. 시퀀스형 (Sequence Types) list 변경 가능한(mutable) 시퀀스. tuple 변경 불가능한(immutable) 시퀀스. range 변경 불가능한(immutable) 숫자 시퀀스. str (문자열) 변경 불가능한(immutable) 유니코드 코드 포인트의 시퀀스. 바이너리 시퀀스형 (Binary Sequence Types) bytes 변경 불가능한(immutable) 단일 바이트의 시퀀스. bytearray 변경 가능한(mutable) bytes 버전. memoryview 복사 없이 다른 바이너리 객체의 메모리에 접근합니다. 세트형 (Set Types) set 순서가 없고, 중복되지 않는 해시 가능한(hashable) 객체들의 변경 가능한(mutable) 컬렉션. frozenset 변경 불가능한(immutable) set. 매핑형 (Mapping Types) dict (사전) 해시 가능한(hashable) 값을 임의의 객체에 매핑하는 변경 가능한(mutable) 객체. 컨텍스트 관리자형 (Context Manager Types) - with 문에 의해 정의된 런타임 컨텍스트를 지원하는 형식. 타입 어노테이션형 (Type Annotation Types) GenericAlias 클래스를 구독하여 생성되는 제네릭 타입의 프록시 (list[int] 등). Union 여러 타입을 허용하는 타입 어노테이션을 위한 형식 (`int 기타 내장형 (Other Built-in Types) module 모듈 객체. class and instance 클래스와 그 클래스의 인스턴스. function 함수 객체. method 인스턴스에 바인딩된 메서드 객체. code object 컴파일된 실행 가능한 파이썬 코드. type object 객체의 타입을 나타내는 객체. NoneType (None) 값이 없음을 나타내는 단일 객체. ellipsis (...) 슬라이싱에 주로 사용되는 단일 객체. NotImplementedType (NotImplemented) 지원되지 않는 연산에서 반환되는 단일 객체. 분류 (Category) 내장 타입 (Built-in Type) 설명 (Description) 출처 (Source) 숫자 타입 (Numeric Types) int 정수 float 부동 소수점 숫자 complex 실수부와 허수부를 모두 갖는 복소수 bool 진리값을 나타내는 타입으로, int의 서브타입입니다. True와 False 두 개의 상수 인스턴스가 있습니다. 시퀀스 타입 (Sequence Types) list 가변 시퀀스로, 일반적으로 동종 항목의 컬렉션을 저장하는 데 사용됩니다. tuple 불변 시퀀스로, 일반적으로 이종 데이터를 저장하는 데 사용됩니다. range 불변 숫자 시퀀스를 나타내며, for 루프에서 특정 횟수만큼 반복하는 데 일반적으로 사용됩니다. str 유니코드 코드 포인트의 불변 시퀀스로, 텍스트 데이터를 처리합니다. 이진 시퀀스 타입 (Binary Sequence Types) bytes 단일 바이트의 불변 시퀀스입니다. bytearray bytes 객체의 가변 counterpart입니다. memoryview 버퍼 프로토콜을 지원하는 객체의 내부 데이터에 복사 없이 접근할 수 있도록 합니다. 집합 타입 (Set Types) set 해시 가능한 고유 객체의 순서 없는 컬렉션입니다. add() 및 remove()와 같은 메서드를 사용하여 내용을 변경할 수 있는 가변 타입입니다. frozenset 해시 가능한 고유 객체의 순서 없는 컬렉션입니다. 생성 후 내용을 변경할 수 없는 불변 타입이며, 딕셔너리 키나 다른 집합의 요소로 사용될 수 있습니다. 매핑 타입 (Mapping Types) dict 해시 가능한 값을 임의의 객체에 매핑하는 가변 객체입니다. Dictionary view objects dict.keys(), dict.values(), dict.items() 메서드가 반환하는 객체입니다. 딕셔너리의 항목에 대한 동적 뷰를 제공합니다. 타입 어노테이션 타입 (Type Annotation Types) Generic Alias 클래스를 서브스크립션하여 생성되며, 주로 타입 어노테이션(list[int] 등)에 사용됩니다. Union 여러 타입 객체에 대한 ` (비트 OR) 연산의 값을 보유하며, 주로 타입 어노테이션(int 기타 내장 타입 (Other Built-in Types) Modules 모듈의 심볼 테이블에 정의된 이름에 접근할 수 있습니다 (예: m.name). Classes and Class Instances 객체, 값 및 타입, 그리고 클래스 정의에 대한 정보를 포함합니다. Functions 함수 정의에 의해 생성되며, 호출하는 것이 유일한 연산입니다. 내장 함수와 사용자 정의 함수가 있습니다. Methods 속성 표기법을 사용하여 호출되는 함수입니다. 내장 메서드와 클래스 인스턴스 메서드(바운드 메서드)가 있습니다. Code Objects 함수 본문과 같은 “의사 컴파일된” 실행 가능한 Python 코드를 나타내는 데 구현에서 사용됩니다. Type Objects 다양한 객체 타입을 나타내며, 객체의 타입은 내장 함수 type()을 통해 접근할 수 있습니다. The Null Object (None) 함수가 명시적으로 값을 반환하지 않을 때 반환되는 객체입니다. 정확히 하나의 널 객체 None이 있습니다. The Ellipsis Object (Ellipsis 또는 ...) 슬라이싱(Slicings)에 일반적으로 사용되는 객체입니다. 정확히 하나의 생략 객체가 있습니다. The NotImplemented Object (NotImplemented) 비교 및 이진 연산이 지원하지 않는 타입에 대해 작동하도록 요청받을 때 반환되는 객체입니다. Internal Objects 스택 프레임, 트레이스백, 슬라이스 객체 등을 포함합니다.","list-comprehension#list comprehension":"","namedtuple-사용법#\u003ccode\u003enamedtuple\u003c/code\u003e 사용법":"namedtuple은 두 단계를 거쳐 사용됩니다.\n1단계: namedtuple ‘타입(Type)’ 정의하기 collections.namedtuple() 함수를 호출하여 새로운 클래스(타입)를 만듭니다.\nnamedtuple('타입이름', ['필드이름1', '필드이름2', ...])\n2단계: 정의된 타입으로 ‘객체(Instance)’ 생성하기 마치 클래스로 객체를 만들 듯이, 위에서 정의한 타입에 값을 넣어 객체를 생성합니다.","nametuple#nametuple":"네, namedtuple에 대해 자세히 설명해 드리겠습니다. 말씀하신 정의는 정확합니다. namedtuple은 **‘이름이 붙은 튜플’**을 만드는 아주 유용한 도구입니다.\n간단히 비유하자면, 메서드(기능)는 필요 없고 데이터만 담을 아주 가벼운 ‘클래스(Class)‘를 즉석에서 만드는 것과 같습니다.","기본-구조#기본 구조":"[표현식 for 항목 in 반복대상 if 조건] → 이걸 영어 문장처럼 읽으면:\n“expression for item in iterable if condition”\n즉,\n“조건이 있다면 해당 조건을 만족하는 item들 중에서, 각각에 대해 expression을 적용해서 리스트를 만들자”","다른-자료형과의-비교#다른 자료형과의 비교":"비교 대상 namedtuple의 장점 일반 tuple 가독성이 월등히 좋습니다. point[0] 대신 point.x로 의미를 명확히 할 수 있습니다. dict (딕셔셔리) **불변성(immutable)**을 가집니다. 값이 실수로 변경되는 것을 막을 수 있습니다. 더 가볍고(메모리 효율적) 빠릅니다. class 데이터 필드만 필요한 경우, class를 직접 정의하는 것보다 코드가 훨씬 간결합니다.","언제-사용하면-좋을까요#언제 사용하면 좋을까요?":"CSV 파일이나 데이터베이스의 행(Row)을 처리할 때: row[0], row[1] 대신 row.id, row.name처럼 명확하게 데이터를 다룰 수 있습니다. 함수에서 여러 값을 반환할 때: return (id, name, email) 대신, namedtuple 객체를 반환하면 어떤 값이 무엇을 의미하는지 명확해집니다. 좌표(x, y, z), RGB 색상(r, g, b) 등 명확한 이름이 있는 데이터 묶음을 표현할 때 유용합니다.","왜-namedtuple을-사용할까요#왜 \u003ccode\u003enamedtuple\u003c/code\u003e을 사용할까요?":"일반 튜플은 인덱스로만 값에 접근할 수 있습니다.\n# 일반 튜플 point = (10, 20) print(point[0]) # x 좌표 print(point[1]) # y 좌표 이 코드는 point[0]이 무엇을 의미하는지 바로 알기 어렵습니다. 코드가 길어지면 이 값들이 x, y 좌표라는 것을 잊기 쉽죠.\nnamedtuple은 이 문제를 해결합니다.","요약#요약":"**namedtuple**은 데이터를 담기 위한 간단한 ‘객체’가 필요하지만, 완전한 class를 정의하기는 번거로울 때 사용하는 최고의 도구입니다. 튜플의 특성(불변성, 효율성)과 객체지향의 장점(가독성)을 모두 가지고 있어 코드를 훨씬 깔끔하고 이해하기 쉽게 만들어 줍니다.\n완전히 정리된 상태입니다! ✅\n아래는 리스트 컴프리헨션을 자연스럽게 읽는 방법, 그리고 주석(docstring, 코드 주석 등)에 사용할 수 있는 한글 / 영어 표현 패턴을 체계적으로 정리한 내용이에요.","자세한-코드-예제#자세한 코드 예제":"from collections import namedtuple # 1. 'Point'라는 이름의 namedtuple 타입을 정의합니다. # 이 타입은 'x'와 'y'라는 필드 이름을 가집니다. Point = namedtuple('Point', ['x', 'y']) # 2. Point 타입을 사용하여 객체를 생성합니다. p1 = Point(10, 20) p2 = Point(x=30, y=40) # 키워드 인자로도 생성 가능 # --- 주요 특징 --- # 1. 이름으로 값에 접근 (가장 큰 장점!) print(f\"p1의 x좌표: {p1.x}\") # 출력: p1의 x좌표: 10 print(f\"p1의 y좌표: {p1.y}\") # 출력: p1의 y좌표: 20 # 2. 인덱스로도 값에 접근 (튜플의 특성 유지) print(f\"p2의 첫 번째 값: {p2[0]}\") # 출력: p2의 첫 번째 값: 30 print(f\"p2의 두 번째 값: {p2[1]}\") # 출력: p2의 두 번째 값: 40 # 3. 불변성(Immutable) - 값 변경 불가 (튜플의 특성 유지) try: p1.x = 100 except AttributeError as e: print(f\"값 변경 시도 시 에러 발생: {e}\") # 출력: 값 변경 시도 시 에러 발생: can't set attribute # 4. 언패킹(Unpacking) 가능 (튜플의 특성 유지) x_val, y_val = p1 print(f\"언패킹된 값: x={x_val}, y={y_val}\") # 출력: 언패킹된 값: x=10, y=20 # 5. 객체 표현이 명확함 print(p1) # 출력: Point(x=10, y=20)"},"title":"python default type"},"/signal-%EC%B0%A8%EC%9D%B4-unixmacos-vs-linux/":{"data":{"":"","1-신호-번호signal-number의-차이#(1) 신호 번호(Signal Number)의 차이":"가장 눈에 띄는 차이점 중 하나는 일부 신호의 번호가 다르다는 것입니다.\nSignal Name macOS Number Linux Number SIGBUS 10 7 SIGCHLD 20 17 SIGSTOP 17 19 SIGTSTP 18 20 SIGCONT 19 18 SIGUSR1 30 10 SIGUSR2 31 12 중요성: 이 차이점 때문에 프로그래머는 절대로 코드에 신호 번호를 하드코딩해서는 안 됩니다. 예를 들어, kill(pid, 9) 대신 kill(pid, SIGKILL)과 같이 항상 표준 헤더 파일에 정의된 심볼릭 이름(symbolic name)을 사용해야 이식성 있는 코드를 작성할 수 있습니다.","1-신호signal란-무엇인가#1. 신호(Signal)란 무엇인가?":"컴퓨팅에서 **신호(Signal)**는 운영체제(커널)가 특정 프로세스에게 비동기적인 이벤트가 발생했음을 알리기 위해 사용하는 제한된 형태의 프로세스 간 통신(IPC, Inter-Process Communication) 메커니즘입니다. 신호는 종종 “소프트웨어 인터럽트(Software Interrupt)“라고도 불리며, 프로세스가 정상적인 실행 흐름을 잠시 멈추고 해당 이벤트를 처리하도록 유도합니다.","1-프로세스-종료-관련-신호#(1) 프로세스 종료 관련 신호":"이 신호들은 주로 프로세스를 정상적으로 또는 강제적으로 종료시키는 데 사용됩니다.\nSIGHUP (1): Hang Up. 과거 모뎀 시절, 통신 연결이 끊겼을 때 보내던 신호에서 유래했습니다. 현대에는 터미널 세션이 종료되거나, 데몬(daemon) 프로세스에게 설정 파일을 다시 읽어오도록 지시하는 용도로 널리 사용됩니다. systemctl reload나 service nginx reload와 같은 명령어들이 내부적으로 SIGHUP을 보냅니다. SIGINT (2): Interrupt. 사용자가 키보드에서 Ctrl+C를 눌렀을 때 터미널이 전송하는 신호입니다. “프로그램을 중단해달라\"는 정중한 요청으로, 대부분의 프로그램은 이 신호를 받으면 진행 중인 작업을 정리하고(예: 임시 파일 삭제) 종료합니다. SIGQUIT (3): Quit. 사용자가 Ctrl+\\\\를 눌렀을 때 전송됩니다. SIGINT보다 더 강한 종료 요청이며, 기본 동작은 코어 덤프(Core Dump)를 생성하고 종료하는 것입니다. 코어 덤프는 프로세스가 비정상 종료될 당시의 메모리 상태를 담은 파일로, 디버깅에 매우 유용합니다. SIGTERM (15): Terminate. 가장 일반적인 “소프트웨어 종료 신호\"입니다. kill 명령어에 PID만 입력하면 기본적으로 이 신호가 전송됩니다. SIGINT와 마찬가지로 “정리하고 종료하라\"는 요청이며, 프로세스가 이 신호를 잡아서 안전하게 종료할 시간을 가질 수 있습니다. 가장 표준적이고 권장되는 종료 방식입니다. SIGKILL (9): Kill. **“절대적이고 무자비한 종료 명령”**입니다. 이 신호는 프로세스가 무시하거나 핸들러로 잡을 수 없습니다. 커널이 직접 프로세스의 실행을 중단시키기 때문에, 프로세스는 어떠한 정리 작업도 수행할 수 없습니다. 좀비 프로세스나 응답 없는 프로세스를 강제로 제거할 때 최후의 수단으로 사용됩니다. kill -9로 유명합니다.","2-기본-동작default-action의-차이#(2) 기본 동작(Default Action)의 차이":"제공된 표에서 몇몇 신호의 기본 동작이 다르게 명시되어 있습니다.\nSIGXCPU (CPU 시간 초과), SIGXFSZ (파일 크기 제한 초과):\nmacOS: terminate process (프로세스 종료) Linux: Core (코어 덤프 생성 후 종료) 분석: 이는 운영체제의 기본 철학 차이를 보여줍니다. Linux는 자원 제한을 초과한 경우, 원인 분석을 위한 디버깅 정보(코어 덤프)를 남기는 것을 기본으로 합니다. 반면 macOS는 더 간결하게 프로세스를 종료시키는 것을 기본 동작으로 설정했습니다. 물론 이 동작은 setrlimit() 시스템 콜을 통해 변경할 수 있습니다. SIGIO (I/O 가능):\nmacOS: discard signal (신호 무시) Linux: Term (프로세스 종료) 분석: 이 신호는 비동기 I/O를 위해 사용되는데, 기본 동작이 다르다는 것은 이 기능을 사용할 때 운영체제별로 핸들러를 반드시 등록해야 함을 시사합니다. Linux의 경우 핸들러를 등록하지 않으면 프로세스가 예기치 않게 종료될 수 있습니다.","2-주요-신호signal-상세-설명#2. 주요 신호(Signal) 상세 설명":"두 운영체제에서 공통적으로 사용되는 중요한 신호들을 기능별로 묶어 상세히 설명하겠습니다.","2-하드웨어-및-소프트웨어-예외-관련-신호#(2) 하드웨어 및 소프트웨어 예외 관련 신호":"프로세스가 잘못된 연산을 시도했을 때 커널에 의해 생성되는 신호들입니다.\nSIGSEGV (11): Segmentation Violation. “세그멘테이션 오류\"로, C/C++ 개발자에게 가장 익숙한 신호입니다. 프로세스가 자신에게 할당되지 않은 메모리 영역에 접근하거나, 읽기 전용 영역에 쓰려고 할 때 발생합니다. 주로 포인터 관련 버그로 인해 발생합니다. SIGILL (4): Illegal Instruction. 프로세스가 CPU가 이해할 수 없는 기계어 코드(예: 손상된 코드, 존재하지 않는 명령어)를 실행하려고 할 때 발생합니다. SIGFPE (8): Floating-Point Exception. 부동소수점 연산에서 예외가 발생했을 때(예: 0으로 나누기, 오버플로우) 전송됩니다. 이름과 달리 정수 나눗셈에서 0으로 나눌 때도 이 신호가 발생할 수 있습니다. SIGBUS (10, 7 on Linux): Bus Error. SIGSEGV와 유사하지만, 원인이 다릅니다. SIGSEGV가 논리적인 메모리 접근 권한 위반이라면, SIGBUS는 물리적으로 유효하지 않은 주소에 접근하려 할 때 발생합니다. (예: CPU의 정렬(alignment) 요구사항 위반, 존재하지 않는 물리 메모리 주소 접근). SIGABRT (6): Abort. abort() 함수 호출을 통해 프로세스가 자기 자신에게 보내는 신호입니다. 복구 불가능한 심각한 내부 오류를 감지했을 때, 프로그램 스스로 비정상 종료를 선택하는 용도로 사용됩니다. 기본 동작은 코어 덤프 생성 후 종료입니다.","3-macos와-linux의-신호signal-차이점#3. macOS와 Linux의 신호(Signal) 차이점":"두 운영체제는 POSIX 표준을 준수하기 때문에 대부분의 핵심 신호(SIGHUP, SIGINT, SIGKILL, SIGTERM 등)는 이름과 기능이 동일합니다. 하지만 각 운영체제의 역사적 배경(macOS는 BSD 기반, Linux는 System V와 독자적 발전)으로 인해 몇 가지 미묘하지만 중요한 차이점이 존재합니다.","3-운영체제-고유-또는-역사적-신호의-차이#(3) 운영체제 고유 또는 역사적 신호의 차이":"macOS (BSD 계열)의 특징적 신호:\nSIGINFO (29): BSD 시스템에서 유래한 신호로, 터미널에서 Ctrl+T를 누르면 전송됩니다. 실행 중인 프로세스의 상태 정보(예: dd 명령어의 진행 상황)를 출력하도록 요청하는 데 사용됩니다. Linux에는 기본적으로 같은 이름의 신호가 없지만, 일부 시스템에서는 SIGPWR에 매핑되기도 합니다. SIGEMT (7): Emulate Instruction Trap. PDP-11과 같은 구형 하드웨어에서 사용되던 에뮬레이터 트랩 신호입니다. 현대적인 시스템에서는 거의 사용되지 않지만, BSD의 역사적 유산으로 macOS 목록에 남아있습니다. Linux 목록에도 존재는 하지만 비표준으로 취급됩니다. Linux의 특징적 신호:\nSIGPWR (Power Failure): System V에서 유래한 신호로, 시스템 전원에 문제가 생겼을 때(예: UPS 배터리 부족) 시스템 관리 데몬에게 알려 안전한 종료 절차를 밟도록 하는 데 사용됩니다. SIGSTKFLT (Stack Fault on coprocessor): 과거 수치 연산 보조 프로세서(coprocessor)의 스택 오류를 위한 신호였으나, 현대 x86 아키텍처에서는 사용되지 않아 사실상 사장되었습니다. SIGPOLL: System V의 SIGIO와 동일한 역할을 하는 신호입니다. Linux는 두 이름 모두를 지원하여 호환성을 높였습니다. SIGCLD, SIGIOT: 각각 SIGCHLD, SIGABRT의 오래된 동의어(synonym)입니다. 과거 다른 Unix 버전과의 호환성을 위해 남아있습니다.","3-작업-제어job-control-관련-신호#(3) 작업 제어(Job Control) 관련 신호":"터미널 셸 환경에서 프로세스의 실행을 일시 중지하거나 재개할 때 사용됩니다.\nSIGTSTP (18, 20 on Linux): Stop from Terminal. 사용자가 키보드에서 Ctrl+Z를 눌렀을 때 전송되는 신호입니다. SIGSTOP과 달리 “정중한 중지 요청\"이므로 프로세스가 무시하거나 처리할 수 있습니다. SIGSTOP (17, 19 on Linux): Stop. SIGKILL의 중지 버전입니다. 프로세스가 이 신호를 무시하거나 핸들러로 잡을 수 없습니다. 운영체제는 이 신호를 통해 어떤 프로세스든 강제로 실행을 중지시킬 수 있습니다. SIGCONT (19, 18 on Linux): Continue. SIGSTOP이나 SIGTSTP에 의해 중지된 프로세스의 실행을 재개시키는 신호입니다. 셸에서 fg 또는 bg 명령어를 사용하면 이 신호가 전송됩니다. SIGTTIN (21) / SIGTTOU (22): 백그라운드 프로세스가 제어 터미널에 대한 입/출력을 시도할 때 발생합니다. 기본 동작은 프로세스를 중지시키는 것입니다. 이는 여러 백그라운드 작업이 동시에 터미널을 사용하려 할 때 발생하는 혼란을 방지하기 위함입니다.","4-결론#4. 결론":"macOS와 Linux의 신호 시스템은 POSIX라는 강력한 표준 아래에서 높은 수준의 호환성을 보입니다. 개발자들은 SIGINT, SIGTERM, SIGSEGV와 같은 핵심 신호들이 두 플랫폼에서 거의 동일하게 작동할 것이라고 기대할 수 있습니다.\n하지만 그 기저에는 **BSD(macOS)와 System V(Linux)**라는 서로 다른 UNIX 계보의 영향이 남아있습니다. 이로 인해 일부 비표준적이거나 역사적인 신호(SIGINFO, SIGPWR)의 존재 유무, 특정 오류 상황에서의 기본 행동(SIGXCPU의 코어 덤프 여부), 그리고 동의어의 사용 등에서 미세한 차이가 나타납니다.\n따라서 높은 이식성이 요구되는 시스템 프로그래밍을 할 때는 POSIX 표준에 정의된 신호들을 중심으로 코드를 작성하고, 특정 운영체제에만 의존적인 신호의 사용은 가급적 피하는 것이 바람직합니다. 제공된 두 표는 이러한 차이점과 공통점을 명확하게 보여주는 훌륭한 자료입니다.","4-기타-주요-신호#(4) 기타 주요 신호":"SIGCHLD (20, 17 on Linux): Child Status Changed. 자식 프로세스가 종료되거나, 중지되거나, 재개될 때 부모 프로세스에게 전송되는 신호입니다. 부모 프로세스는 이 신호를 통해 자식의 상태 변화를 감지하고, wait() 계열 함수를 호출하여 좀비 프로세스가 되는 것을 방지할 수 있습니다. SIGPIPE (13): Pipe. 파이프(pipe)의 읽기 쪽(reader)이 닫혔는데 쓰기 쪽(writer)에서 계속 쓰려고 할 때 발생합니다. 예를 들어, ls -R / | head -n 10 명령어에서 head가 10줄을 읽고 종료되면, ls는 더 이상 데이터를 쓸 곳이 없어지고 SIGPIPE 신호를 받고 종료됩니다. SIGALRM (14): Alarm. alarm() 함수 호출로 설정된 실시간 타이머가 만료되었을 때 발생하는 신호입니다. SIGUSR1 (30, 10 on Linux) / SIGUSR2 (31, 12 on Linux): User-defined Signal. 이 두 신호는 시스템에 의해 특정 용도가 정해져 있지 않습니다. 개발자가 애플리케이션의 필요에 따라 자유롭게 의미를 부여하고 프로세스 간 통신에 사용할 수 있도록 예약된 신호입니다.","macos와-linux의-신호signal-상세-분석#macOS와 Linux의 신호(Signal) 상세 분석":"시그널 이름 macOS 기본 동작 macOS 설명 Linux 기본 동작 Linux 설명 (Comment) 차이점 / 비고 SIGHUP 프로세스 종료 터미널 라인 끊김 Term 제어 터미널에서 끊김 감지 또는 제어 프로세스 종료 설명은 유사하며, 둘 다 프로세스를 종료합니다. SIGINT 프로세스 종료 프로그램 인터럽트 Term 키보드로부터의 인터럽트 유사하며, 둘 다 프로세스를 종료하며, 주로 Ctrl+C로 발생합니다. SIGQUIT 코어 이미지 생성 프로그램 종료 Core 키보드로부터의 종료 둘 다 코어 덤프를 생성하고 종료합니다. SIGILL 코어 이미지 생성 불법 명령어 Core 불법 명령어 (Illegal Instruction) 둘 다 코어 덤프를 생성합니다. SIGTRAP 코어 이미지 생성 트레이스 트랩 Core 트레이스/브레이크포인트 트랩 둘 다 코어 덤프를 생성합니다. SIGABRT 코어 이미지 생성 프로그램 중단 (이전 SIGIOT) Core abort(3)로부터의 중단 시그널 둘 다 코어 덤프를 생성합니다. Linux는 abort(3)로부터 발생한다고 명시합니다. SIGEMT 코어 이미지 생성 명령어 에뮬레이트 실행 Term 에뮬레이터 트랩 차이점: macOS는 코어 이미지를 생성하지만, Linux는 프로세스를 종료합니다. 이는 “에뮬레이터 트랩” 조건에 대한 다른 처리를 나타낼 수 있습니다. Linux는 이 시그널에 대한 명시적인 코어 덤프 동작이 없습니다. SIGFPE 코어 이미지 생성 부동 소수점 예외 Core 부동 소수점 예외 둘 다 코어 덤프를 생성합니다. SIGKILL 프로세스 종료 프로그램 강제 종료 Term 강제 종료 시그널 둘 다 프로세스를 종료하며, 포착하거나 무시할 수 없습니다. SIGBUS 코어 이미지 생성 버스 에러 Core 버스 에러 (잘못된 메모리 접근) 둘 다 코어 덤프를 생성합니다. SIGSEGV 코어 이미지 생성 세그멘테이션 위반 Core 유효하지 않은 메모리 참조 둘 다 코어 덤프를 생성합니다. SIGSYS 코어 이미지 생성 존재하지 않는 시스템 콜 호출 Core 잘못된 시스템 콜 (SVr4); seccomp(2) 참조 둘 다 코어 덤프를 생성합니다. Linux는 seccomp(2)에 대한 추가 컨텍스트를 제공합니다. SIGPIPE 프로세스 종료 리더 없는 파이프에 쓰기 Term 파이프 깨짐: 리더 없는 파이프에 쓰기; pipe(7) 참조 둘 다 프로세스를 종료합니다. SIGALRM 프로세스 종료 실시간 타이머 만료 Term alarm(2)로부터의 타이머 시그널 둘 다 프로세스를 종료합니다. SIGTERM 프로세스 종료 소프트웨어 종료 시그널 Term 종료 시그널 둘 다 프로세스를 종료합니다. 이것은 기본 종료 시그널입니다. SIGURG 시그널 무시 소켓에 긴급 조건 발생 Ign 소켓의 긴급 조건 (4.2BSD) 둘 다 시그널을 무시합니다. SIGSTOP 프로세스 중지 중지 (포착하거나 무시할 수 없음) Stop 프로세스 중지 둘 다 프로세스를 중지하며 포착하거나 무시할 수 없습니다. SIGTSTP 프로세스 중지 키보드로부터 발생한 중지 시그널 Stop 터미널에서 입력된 중지 둘 다 프로세스를 중지하며, 주로 Ctrl+Z로 발생합니다. SIGCONT 시그널 무시 중지 후 계속 진행 Cont 중지 후 계속 진행 둘 다 중지된 프로세스를 계속 진행합니다. SIGCHLD 시그널 무시 자식 상태 변경됨 Ign 자식 프로세스 중지 또는 종료 둘 다 기본적으로 시그널을 무시합니다. SIGTTIN 프로세스 중지 제어 터미널에서 백그라운드 읽기 시도 Stop 백그라운드 프로세스를 위한 터미널 입력 둘 다 프로세스를 중지합니다. SIGTTOU 프로세스 중지 제어 터미널에 백그라운드 쓰기 시도 Stop 백그라운드 프로세스를 위한 터미널 출력 둘 다 프로세스를 중지합니다. SIGIO 시그널 무시 디스크립터에서 I/O 가능 (fcntl(2) 참조) Term I/O 이제 가능 (4.2BSD) 차이점: macOS는 기본적으로 이 시그널을 무시하는 반면, Linux는 프로세스를 종료합니다. Linux는 또한 SIGPOLL의 동의어라고 명시합니다. 이는 중요한 행동 차이입니다. SIGXCPU 프로세스 종료 CPU 시간 제한 초과 (setrlimit(2) 참조) Core CPU 시간 제한 초과 (4.2BSD); setrlimit(2) 참조 차이점: macOS는 프로세스를 종료하는 반면, Linux는 코어 덤프를 생성합니다. 둘 다 setrlimit(2)를 인정합니다. SIGXFSZ 프로세스 종료 파일 크기 제한 초과 (setrlimit(2) 참조) Core 파일 크기 제한 초과 (4.2BSD); setrlimit(2) 참조 차이점: macOS는 프로세스를 종료하는 반면, Linux는 코어 덤프를 생성합니다. 둘 다 setrlimit(2)를 인정합니다. SIGVTALRM 프로세스 종료 가상 시간 알람 (setitimer(2) 참조) Term 가상 알람 시계 (4.2BSD) 둘 다 프로세스를 종료합니다. SIGPROF 프로세스 종료 프로파일링 타이머 알람 (setitimer(2) 참조) Term 프로파일링 타이머 만료 둘 다 프로세스를 종료합니다. SIGWINCH 시그널 무시 윈도우 크기 변경 Ign 윈도우 크기 변경 시그널 (4.3BSD, Sun) 둘 다 시그널을 무시합니다. SIGINFO 시그널 무시 키보드로부터의 상태 요청 - (SIGPWR의 동의어) SIGPWR의 동의어 (기본적으로 Term) 차이점: macOS는 SIGINFO를 상태 요청(예: Ctrl+T)을 위한 별개의 무시 가능한 시그널로 처리합니다. Linux는 SIGINFO를 SIGPWR의 동의어로 나열하며, 이는 기본적으로 종료됩니다. 이름과 기본 동작 모두에서 중요한 차이가 있습니다. SIGUSR1 프로세스 종료 사용자 정의 시그널 1 Term 사용자 정의 시그널 1 둘 다 프로세스를 종료합니다. SIGUSR2 프로세스 종료 사용자 정의 시그널 2 Term 사용자 정의 시그널 2 둘 다 프로세스를 종료합니다. SIGCLD (macOS에 없음) Ign SIGCHLD의 동의어 Linux 전용: SIGCHLD의 동의어입니다. macOS에는 SIGCLD가 별개의 시그널로 나열되지 않습니다. SIGIOT (macOS에 없음) Core IOT 트랩. SIGABRT의 동의어 Linux 전용: SIGABRT의 동의어로 나열됩니다. macOS는 SIGABRT가 “이전 SIGIOT\"였다고 언급하지만, SIGIOT를 별개의 시그널로 나열하지는 않습니다. SIGLOST (macOS에 없음) Term 파일 잠금 손실 (사용되지 않음) Linux 전용: 파일 잠금과 관련된 시그널이며 “사용되지 않음\"으로 나열됩니다. macOS에는 없습니다. SIGPOLL (macOS에 없음) Term 폴링 가능한 이벤트 (Sys V); SIGIO의 동의어 Linux 전용: SIGIO의 동의어입니다. macOS에는 없습니다. SIGPWR (macOS에 없음) Term 전원 장애 (System V) Linux 전용: 전원 장애 이벤트에 대한 시그널입니다. Linux의 SIGINFO는 이것의 동의어이며, 이는 macOS의 SIGINFO와는 큰 차이입니다. SIGSTKFLT (macOS에 없음) Term 보조 프로세서의 스택 오류 (사용되지 않음) Linux 전용: 보조 프로세서의 스택 오류에 대한 시그널이며 “사용되지 않음\"으로 나열됩니다. macOS에는 없습니다. SIGUNUSED (macOS에 없음) Core SIGSYS와 동의어 Linux 전용: SIGSYS의 동의어입니다. macOS에는 없습니다.","신호에-대한-프로세스의-반응-signal-disposition#신호에 대한 프로세스의 반응 (Signal Disposition)":"프로세스는 신호를 수신했을 때 다음 세 가지 행동 중 하나를 취할 수 있습니다.\n기본 행동(Default Action) 수행: 각 신호에는 미리 정해진 기본 행동이 있습니다. 이 행동은 프로세스 종료, 코어 덤프 생성 후 종료, 프로세스 중지, 신호 무시 등 다양합니다. 신호 잡기(Catch the Signal): 프로그래머가 특정 신호에 대한 처리 함수(Signal Handler)를 미리 등록해두면, 해당 신호가 도착했을 때 프로세스는 실행을 잠시 멈추고 등록된 핸들러 함수를 실행합니다. 핸들러 실행이 끝나면 원래 실행 흐름으로 복귀합니다. 이를 통해 프로세스는 종료되지 않고 특정 상황에 능동적으로 대처할 수 있습니다 (예: SIGINT 수신 시 임시 파일 정리 후 종료). 신호 무시(Ignore the Signal): 프로세스는 특정 신호를 무시하도록 설정할 수 있습니다. 이 경우 해당 신호가 도착해도 아무런 행동도 취하지 않습니다. 단, 두 가지 예외적인 신호가 있습니다. **SIGKILL**과 **SIGSTOP**은 어떤 경우에도 잡거나(Catch) 무시할(Ignore) 수 없습니다. 이들은 커널이 프로세스를 확실하게 제어하기 위한 최후의 수단으로, 항상 기본 행동(각각 프로세스 강제 종료, 프로세스 정지)을 수행합니다.","신호의-발생-원인#신호의 발생 원인":"신호는 다양한 상황에서 발생할 수 있습니다.\n사용자의 직접적인 요청: 사용자가 키보드 조합(예: Ctrl+C -\u003e SIGINT, Ctrl+Z -\u003e SIGTSTP)을 통해 현재 실행 중인 프로세스에 신호를 보낼 때. 하드웨어 예외: 프로세스가 잘못된 연산(예: 0으로 나누기 -\u003e SIGFPE)을 하거나, 허용되지 않은 메모리 공간에 접근(-\u003e SIGSEGV)하는 등 하드웨어 수준의 오류가 발생했을 때. 다른 프로세스의 요청: 한 프로세스가 kill() 시스템 콜을 사용하여 다른 프로세스에 특정 신호를 보낼 때 (예: kill -9 [PID]). 운영체제(커널)의 알림: 자식 프로세스가 종료되었을 때(-\u003e SIGCHLD), 파이프의 읽기 쪽이 닫혔는데 쓰려고 할 때(-\u003e SIGPIPE), 알람 타이머가 만료되었을 때(-\u003e SIGALRM) 등 커널이 특정 상태 변화를 프로세스에 알릴 때.","주요-차이점-요약#주요 차이점 요약:":"특정 시그널의 기본 동작:\nSIGEMT: macOS (코어 덤프) vs. Linux (종료). SIGIO: macOS (무시) vs. Linux (종료). SIGXCPU: macOS (종료) vs. Linux (코어 덤프). SIGXFSZ: macOS (종료) vs. Linux (코어 덤프). SIGINFO와 SIGPWR:\nmacOS SIGINFO: 상태 요청(예: Ctrl+T)을 위한 별개의 시그널이며, 기본적으로 무시됩니다. Linux SIGINFO: SIGPWR(전원 장애)의 동의어이며, 기본적으로 종료됩니다. 이는 기능적으로 중요한 차이입니다. Linux 전용 시그널 (macOS에는 없음):\nSIGCLD: SIGCHLD의 동의어. SIGIOT: SIGABRT의 동의어 (macOS는 SIGABRT가 이전에 SIGIOT였다고 언급하지만 별개의 시그널로 나열하지는 않습니다). SIGLOST: 파일 잠금 손실 (사용되지 않음). SIGPOLL: SIGIO의 동의어. SIGPWR: 전원 장애. SIGSTKFLT: 보조 프로세서의 스택 오류 (사용되지 않음). SIGUNUSED: SIGSYS의 동의어. 시그널 번호: 일반적인 시그널의 이름은 대부분 일치하지만, 일부 시그널의 숫자 값은 두 운영 체제 간에 다를 수 있습니다. (제공된 목록에는 macOS의 번호만 표시되어 있습니다.) 예를 들어, SIGINFO는 macOS에서 29입니다."},"title":"signal 차이 unix(macos) vs linux"},"/spec-driven-development/":{"data":{"":"","1-speckitconstitution#1. \u003ccode\u003e/speckit.constitution\u003c/code\u003e":"목적: 프로젝트의 핵심 원칙, 개발 가이드라인, 의사결정 기준을 문서화합니다.\n이것은 프로젝트의 “헌법” 역할을 하며, 나중에 기술 선택이나 설계 논쟁이 있을 때 참조됩니다.\n예시:\n/speckit.constitution - 모든 코드는 테스트 가능해야 하며, 단위 테스트 커버리지는 최소 80% 이상이어야 한다. - 사용자 인터페이스는 접근성(WCAG 2.1 AA)을 준수해야 한다. - 백엔드는 stateless 설계를 따르며, 세션은 JWT 기반으로 관리한다. - 데이터베이스 마이그레이션은 버전 관리되고, 롤백 가능해야 한다. - 한국어와 영어를 동시에 지원하며, 모든 문자열은 i18n 레이어를 통해 관리된다. 💡 이 단계는 프로젝트 초기에 한 번 정의되지만, 필요시 업데이트 가능합니다.","1-섣부른-구현-세부사항-방지#1. 섣부른 구현 세부사항 방지":"기능 명세 템플릿은 명시적으로 지시합니다:\n- ✅ 사용자가 무엇을(WHAT) 왜(WHY) 필요로 하는지에 집중하세요. - ❌ 어떻게(HOW) 구현할지는 피하세요 (기술 스택, API, 코드 구조 언급 금지). 이 제약은 LLM이 적절한 추상화 수준을 유지하도록 강제합니다. LLM이 자연스럽게 “리액트와 리덕스를 사용하여 구현\"으로 넘어갈 수 있는 상황에서, 템플릿은 “사용자는 데이터의 실시간 업데이트가 필요하다\"에 집중하게 만듭니다. 이러한 분리는 구현 기술이 변경되더라도 명세가 안정적으로 유지되도록 보장합니다.","2-speckitspecify#2. \u003ccode\u003e/speckit.specify\u003c/code\u003e":"목적: 무엇을 만들 것인가에 대한 요구사항과 사용자 스토리를 명확히 정의합니다.\n기술 구현보다는 비즈니스 가치와 사용자 관점에 집중합니다.\n예시:\n/speckit.specify 사용자 스토리: - 사용자로서, 나는 로그인 없이도 게스트 모드로 앱을 사용할 수 있어야 한다. - 관리자로서, 나는 사용자 계정을 비활성화할 수 있어야 한다. - 사용자로서, 나는 내 프로필 사진을 업로드하고 자르기 기능을 사용할 수 있어야 한다. 비기능적 요구사항: - 시스템은 1초 이내에 프로필 이미지 업로드 응답을 반환해야 한다. - 모든 API는 HTTPS만 허용하며, CORS 정책은 명시적으로 설정된다. 💡 이 단계에서 모호한 요구사항(예: “빠르게 작동해야 한다”)은 /speckit.clarify로 사전에 해소하는 것이 좋습니다.","2-명시적인-불확실성-표시-강제#2. 명시적인 불확실성 표시 강제":"두 템플릿 모두 [명확화 필요] 마커 사용을 의무화합니다:\n사용자 프롬프트로부터 이 명세를 생성할 때: 1. **모든 모호함을 표시**: [명확화 필요: 구체적인 질문]을 사용하세요. 2. **추측하지 마세요**: 프롬프트에 명시되지 않은 것이 있다면 표시하세요. 이는 그럴듯하지만 잠재적으로 잘못된 가정을 하는 일반적인 LLM의 행동을 방지합니다. “로그인 시스템\"이 이메일/비밀번호 인증을 사용한다고 추측하는 대신, LLM은 [명확화 필요: 인증 방식이 명시되지 않음 - 이메일/비밀번호, SSO, OAuth?]와 같이 표시해야 합니다.","3-speckitclarify-선택적-권장됨#3. \u003ccode\u003e/speckit.clarify\u003c/code\u003e \u003cem\u003e(선택적, 권장됨)\u003c/em\u003e":"목적: /speckit.specify에서 모호하거나 불완전한 요구사항을 명확히 합니다.\n질문을 통해 명세의 품질을 높입니다.\n예시:\n/speckit.clarify 질문: - “게스트 모드”에서 사용자는 어떤 데이터를 저장할 수 있나요? 로컬 스토리지만 허용되나요? - 프로필 사진 자르기 기능은 서버에서 처리되나요, 클라이언트에서 처리되나요? - 비활성화된 계정은 완전히 삭제되나요, 아니면 상태만 변경되나요? 💡 이 단계를 거치면 나중에 설계나 구현에서 혼선을 줄일 수 있습니다.","3-체크리스트를-통한-구조화된-사고#3. 체크리스트를 통한 구조화된 사고":"템플릿에는 명세를 위한 “단위 테스트” 역할을 하는 포괄적인 체크리스트가 포함되어 있습니다:\n### 요구사항 완전성 - [ ] [명확화 필요] 마커가 남아있지 않음 - [ ] 요구사항은 테스트 가능하고 모호하지 않음 - [ ] 성공 기준은 측정 가능함 이 체크리스트는 LLM이 자신의 결과물을 체계적으로 자체 검토하도록 강제하여, 그렇지 않으면 놓칠 수 있는 격차를 잡아냅니다. 이는 LLM에게 품질 보증 프레임워크를 제공하는 것과 같습니다.","4-speckitplan#4. \u003ccode\u003e/speckit.plan\u003c/code\u003e":"목적: 명세를 바탕으로 기술적 구현 계획을 세웁니다.\n기술 스택, 아키텍처, 데이터 흐름, API 설계 등을 포함합니다.\n예시:\n/speckit.plan 기술 스택: - 프론트엔드: React + TypeScript + Vite - 백엔드: Node.js + Express - DB: PostgreSQL - 인증: JWT + bcrypt - 파일 저장: AWS S3 (프로필 이미지) 아키텍처: - 클라이언트는 REST API를 통해 /api/v1/profile/upload 엔드포인트에 이미지 전송 - 서버는 sharp 라이브러리로 이미지 크롭 후 S3에 저장 - DB에는 S3 URL만 저장 보안: - multipart/form-data 업로드 시 파일 타입 검증 (image/jpeg, image/png만 허용) - 최대 파일 크기: 5MB 💡 이 단계는 개발자가 실제로 코드를 작성하기 전의 “청사진”입니다.","4-게이트를-통한-헌법-준수#4. 게이트를 통한 헌법 준수":"구현 계획 템플릿은 단계별 게이트를 통해 아키텍처 원칙을 강제합니다:\n### -1단계: 사전 구현 게이트 #### 단순성 게이트 (제7조) - [ ] 3개 이하의 프로젝트를 사용하고 있는가? - [ ] 미래를 대비한 과도한 설계(future-proofing)는 없는가? #### 추상화 방지 게이트 (제8조) - [ ] 프레임워크를 직접 사용하고 있는가? - [ ] 단일 모델 표현을 사용하는가? 이러한 게이트는 LLM이 복잡성을 명시적으로 정당화하도록 만들어 과도한 엔지니어링을 방지합니다. 게이트를 통과하지 못하면, LLM은 “복잡성 추적” 섹션에 그 이유를 문서화해야 하며, 이는 아키텍처 결정에 대한 책임감을 만듭니다.","5-speckittasks#5. \u003ccode\u003e/speckit.tasks\u003c/code\u003e":"목적: 계획을 바탕으로 실행 가능한 작업 목록을 생성합니다.\n작업은 작고, 독립적이며, 검증 가능해야 합니다.\n예시:\n/speckit.tasks 1. [FE] 프로필 페이지에 이미지 업로드 UI 추가 (React 컴포넌트) 2. [FE] 이미지 미리보기 및 크롭 영역 선택 기능 구현 (react-easy-crop 사용) 3. [BE] /api/v1/profile/upload 엔드포인트 생성 4. [BE] multer로 multipart/form-data 파싱 설정 5. [BE] sharp로 이미지 리사이징 및 크롭 (300x300 정사각형) 6. [BE] AWS SDK 설정 및 S3 업로드 함수 구현 7. [BE] DB에 사용자 프로필 URL 업데이트 8. [TEST] 프로필 이미지 업로드 통합 테스트 작성 💡 각 작업은 PR 단위로 분리 가능하며, CI/CD 파이프라인과 연동하기 좋습니다.","5-계층적-세부-정보-관리#5. 계층적 세부 정보 관리":"템플릿은 적절한 정보 아키텍처를 강제합니다:\n**중요**: 이 구현 계획은 높은 수준에서 읽기 쉽게 유지되어야 합니다. 모든 코드 샘플, 상세 알고리즘, 또는 광범위한 기술 명세는 반드시 적절한 `implementation-details/` 파일에 위치해야 합니다. 이는 명세가 읽을 수 없는 코드 덤프가 되는 일반적인 문제를 방지합니다. LLM은 적절한 세부 수준을 유지하는 법을 배우고, 복잡성을 별도의 파일로 추출하면서 주요 문서는 탐색하기 쉽게 유지합니다.","6-speckitanalyze-선택적#6. \u003ccode\u003e/speckit.analyze\u003c/code\u003e \u003cem\u003e(선택적)\u003c/em\u003e":"목적: 생성된 명세, 계획, 작업 간의 일관성과 커버리지를 분석합니다.\n예: “모든 사용자 스토리가 작업으로 분해되었는가?” “보안 요구사항이 구현 계획에 반영되었는가?”\n예시 출력:\n/speckit.analyze ✅ 모든 사용자 스토리는 최소 1개 이상의 작업에 매핑됨. ⚠️ “게스트 모드 데이터 저장” 관련 작업이 누락됨 → 작업 #9 추가 필요. ✅ 비기능적 요구사항(1초 응답 시간)은 성능 테스트 항목으로 포함됨. 💡 이 단계는 구현 전 품질 보증(QA)의 일환입니다.","6-테스트-우선-사고#6. 테스트 우선 사고":"구현 템플릿은 테스트 우선 개발을 강제합니다:\n### 파일 생성 순서 1. API 명세를 포함하는 `contracts/` 생성 2. 계약 → 통합 → 종단간(e2e) → 단위 테스트 순서로 테스트 파일 생성 3. 테스트를 통과시키기 위한 소스 파일 생성 이 순서 제약은 LLM이 구현 전에 테스트 가능성과 계약에 대해 생각하도록 보장하여, 더 견고하고 검증 가능한 명세를 이끌어 냅니다.","7-speckitchecklist-선택적#7. \u003ccode\u003e/speckit.checklist\u003c/code\u003e \u003cem\u003e(선택적)\u003c/em\u003e":"목적: 요구사항의 완전성, 명확성, 일관성을 검증하는 커스텀 체크리스트를 생성합니다.\n말 그대로 “영어를 위한 유닛 테스트”처럼 작동합니다.\n예시:\n/speckit.checklist [ ] 모든 사용자 스토리는 “사용자로서, 나는 ~할 수 있다” 형식인가? [ ] 각 비기능적 요구사항은 측정 가능한 지표(예: 1초, 99.9% 가용성)를 포함하는가? [ ] 기술 계획에서 언급된 모든 외부 서비스(S3, DB 등)는 보안 설정이 명시되었는가? [ ] 한국어 경로 처리(예: /사용자/이미지.jpg)에 대한 테스트 케이스가 포함되었는가? 💡 특히 국제화(i18n)나 특수 환경(예: ARM64, macOS/Linux 호환성)이 중요한 경우 유용합니다.","7-추측성-기능-방지#7. 추측성 기능 방지":"템플릿은 추측을 명시적으로 금지합니다:\n- [ ] 추측성이거나 \"필요할지도 모르는\" 기능 없음 - [ ] 모든 단계에는 명확한 전제 조건과 결과물이 있음 이는 LLM이 구현을 복잡하게 만드는 “있으면 좋은” 기능을 추가하는 것을 막습니다. 모든 기능은 명확한 인수 기준이 있는 구체적인 사용자 스토리로 거슬러 올라가야 합니다.","8-speckitimplement#8. \u003ccode\u003e/speckit.implement\u003c/code\u003e":"목적: 모든 작업을 자동 또는 수동으로 실행하여 실제 코드를 생성합니다.\n이 명령은 앞선 단계들의 산출물을 기반으로 완전한 기능 구현을 수행합니다.\n예시 동작:\n위의 /speckit.tasks 목록을 순차적으로 실행 각 작업에 대해 코드 생성, 테스트 작성, 문서화 수행 최종 결과: 프로필 이미지 업로드 기능이 완전히 작동하는 상태 💡 실제 구현은 개발자가 직접 할 수도 있고, AI 어시스턴트가 코드 스니펫을 제안할 수도 있습니다.","speckitplan-명령어#\u003ccode\u003e/speckit.plan\u003c/code\u003e 명령어":"기능 명세가 존재하면, 이 명령어는 포괄적인 구현 계획을 생성합니다.\n명세 분석: 기능 요구사항, 사용자 스토리, 인수 기준을 읽고 이해합니다. 헌법 준수: 프로젝트 헌법 및 아키텍처 원칙과의 일관성을 보장합니다. 기술적 변환: 비즈니스 요구사항을 기술 아키텍처 및 구현 세부사항으로 변환합니다. 상세 문서화: 데이터 모델, API 계약, 테스트 시나리오를 위한 지원 문서를 생성합니다. 빠른 시작 검증: 주요 검증 시나리오를 담은 빠른 시작 가이드를 생성합니다.","speckitspecify-명령어#\u003ccode\u003e/speckit.specify\u003c/code\u003e 명령어":"이 명령어는 간단한 기능 설명(사용자 프롬프트)을 자동 리포지토리 관리가 포함된 완전하고 구조화된 명세로 변환합니다.\n자동 기능 번호 매기기: 기존 명세를 스캔하여 다음 기능 번호(예: 001, 002, 003)를 결정합니다. 브랜치 생성: 설명에서 시맨틱 브랜치 이름을 생성하고 자동으로 생성합니다. 템플릿 기반 생성: 기능 명세 템플릿을 복사하고 사용자의 요구사항에 맞게 커스터마이즈합니다. 디렉토리 구조: 모든 관련 문서를 위해 적절한 specs/[branch-name]/ 구조를 생성합니다.","speckittasks-명령어#\u003ccode\u003e/speckit.tasks\u003c/code\u003e 명령어":"계획이 생성된 후, 이 명령어는 계획 및 관련 설계 문서를 분석하여 실행 가능한 작업 목록을 생성합니다.\n입력: plan.md(필수)를 읽고, data-model.md, contracts/, research.md가 있는 경우 함께 읽습니다. 작업 도출: 계약, 엔티티, 시나리오를 특정 작업으로 변환합니다. 병렬화: 독립적인 작업을 [P]로 표시하고 안전하게 병렬 처리할 수 있는 그룹을 개략적으로 설명합니다. 출력: 작업 에이전트가 실행할 수 있도록 기능 디렉토리에 tasks.md를 작성합니다.","개발의-9개-조항#개발의 9개 조항":"헌법은 개발 프로세스의 모든 측면을 형성하는 9개의 조항을 정의합니다.","구조화된-자동화의-힘#구조화된 자동화의 힘":"이러한 명령어들은 단지 시간을 절약하는 것뿐만 아니라, 일관성과 완전성을 강제합니다:\n누락되는 세부사항 없음: 템플릿은 비기능적 요구사항부터 오류 처리에 이르기까지 모든 측면을 고려하도록 보장합니다. 추적 가능한 결정: 모든 기술적 선택은 특정 요구사항으로 연결됩니다. 살아있는 문서: 명세가 코드를 생성하기 때문에 코드와 동기화 상태를 유지합니다. 신속한 반복: 며칠이 아닌 몇 분 만에 요구사항을 변경하고 계획을 재생성합니다. 이 명령어들은 명세를 정적인 문서가 아닌 실행 가능한 산출물로 취급함으로써 SDD 원칙을 구현합니다. 명세 프로세스를 필요악에서 개발의 원동력으로 변화시킵니다.","구현-접근법#구현 접근법":"오늘날 SDD를 실천하려면 기존 도구들을 조합하고 프로세스 전반에 걸쳐 규율을 유지해야 합니다. 이 방법론은 다음을 통해 실천할 수 있습니다.\n반복적인 명세 개발을 위한 AI 어시스턴트 기술적 컨텍스트 수집을 위한 리서치 에이전트 명세를 구현으로 변환하기 위한 코드 생성 도구 명세 우선 워크플로우에 맞게 조정된 버전 관리 시스템 명세 문서의 AI 분석을 통한 일관성 검사 핵심은 명세를 진실의 원천으로 취급하고, 코드는 그 반대가 아니라 명세를 보조하는 생성된 결과물로 다루는 것입니다.","권력의-역전#권력의 역전":"수십 년간 코드가 왕이었습니다. 명세는 코드를 보조하는 역할을 했습니다. 코딩이라는 “진짜 작업\"이 시작되면 지었다가 허물어버리는 비계와 같았습니다. 우리는 개발을 안내하기 위해 제품 요구사항 문서(PRD)를 작성했고, 구현에 정보를 제공하기 위해 설계 문서를 만들었으며, 아키텍처를 시각화하기 위해 다이어그램을 그렸습니다. 하지만 이것들은 항상 코드 자체에 종속적이었습니다. 코드가 진실이었습니다. 다른 모든 것은 기껏해야 좋은 의도에 불과했습니다. 코드는 진실의 원천이었고, 코드가 발전함에 따라 명세는 그 속도를 거의 따라가지 못했습니다. 자산(코드)과 구현이 하나로 묶여 있기 때문에, 코드로부터 빌드하지 않고서는 병렬적인 구현을 갖기란 쉽지 않습니다.\n명세 주도 개발(SDD)은 이 권력 구조를 뒤집습니다. 명세가 코드를 보조하는 것이 아니라, 코드가 명세를 보조합니다. 제품 요구사항 문서(PRD)는 구현을 위한 가이드가 아니라, 구현을 생성하는 원천입니다. 기술 계획은 코딩에 정보를 제공하는 문서가 아니라, 코드를 생산하는 정밀한 정의입니다. 이것은 우리가 소프트웨어를 구축하는 방식에 대한 점진적인 개선이 아닙니다. 무엇이 개발을 주도하는가에 대한 근본적인 재고입니다.\n명세와 구현 사이의 격차는 소프트웨어 개발 초기부터 고질적인 문제였습니다. 우리는 더 나은 문서, 더 상세한 요구사항, 더 엄격한 프로세스로 이 격차를 메우려 노력했습니다. 이러한 접근 방식들은 그 격차를 필연적인 것으로 받아들이기 때문에 실패합니다. 격차를 좁히려 할 뿐, 결코 제거하지는 못합니다. SDD는 명세와 명세로부터 파생된 구체적인 구현 계획을 실행 가능하게 만듦으로써 그 격차를 제거합니다. 명세와 구현 계획이 코드를 생성할 때, 격차는 존재하지 않습니다. 오직 변환만 있을 뿐입니다.\n이러한 변환은 이제 AI가 복잡한 명세를 이해하고 구현하며, 상세한 구현 계획을 만들 수 있게 되었기 때문에 가능해졌습니다. 하지만 구조 없이 원시적인 AI 생성은 혼돈을 낳습니다. SDD는 작동하는 시스템을 생성할 만큼 정밀하고, 완전하며, 모호하지 않은 명세와 그에 따른 구현 계획을 통해 그 구조를 제공합니다. 명세가 주요 산출물이 됩니다. 코드는 특정 언어와 프레임워크로 표현된 (구현 계획에 따른) 구현체가 됩니다.\n이 새로운 세계에서 소프트웨어를 유지보수한다는 것은 명세를 발전시키는 것을 의미합니다. 개발팀의 의도는 자연어(”의도 주도 개발\"), 디자인 자산, 핵심 원칙 및 기타 가이드라인으로 표현됩니다. 개발의 **공용어(lingua franca)**는 더 높은 수준으로 이동하고, 코드는 마지막 단계를 처리하는 접근 방식이 됩니다.\n디버깅은 잘못된 코드를 생성하는 명세와 그 구현 계획을 수정하는 것을 의미합니다. 리팩토링은 명확성을 위해 명세를 재구성하는 것을 의미합니다. 전체 개발 워크플로우는 명세를 중심적인 진실의 원천으로 재편성되며, 구현 계획과 코드는 지속적으로 재생성되는 결과물이 됩니다. 새로운 기능으로 앱을 업데이트하거나, 창의적인 존재로서 새로운 병렬 구현을 만드는 것은 명세를 재검토하고 새로운 구현 계획을 만드는 것을 의미합니다. 따라서 이 프로세스는 0 -\u003e 1, (1’, …), 2, 3, N의 과정을 거칩니다.\n개발팀은 창의성, 실험, 비판적 사고에 집중하게 됩니다.","규칙을-넘어-개발-철학#규칙을 넘어: 개발 철학":"헌법은 단순한 규칙집이 아니라, LLM이 코드 생성에 대해 어떻게 생각하는지를 형성하는 철학입니다.\n불투명성보다 관찰 가능성: 모든 것은 CLI 인터페이스를 통해 검사 가능해야 합니다. 기교보다 단순성: 단순하게 시작하고, 필요성이 입증될 때만 복잡성을 추가합니다. 고립보다 통합: 인공적인 환경이 아닌 실제 환경에서 테스트합니다. 모놀리스보다 모듈성: 모든 기능은 명확한 경계를 가진 라이브러리입니다. 이러한 원칙들을 명세 및 계획 프로세스에 내장함으로써, SDD는 생성된 코드가 단지 기능적인 것을 넘어 유지보수 가능하고, 테스트 가능하며, 아키텍처적으로 건전하도록 보장합니다. 헌법은 AI를 단순한 코드 생성기에서 시스템 설계 원칙을 존중하고 강화하는 아키텍처 파트너로 변모시킵니다.","명령어를-통한-sdd-간소화#명령어를 통한 SDD 간소화":"SDD 방법론은 명세 → 계획 → 작업화 워크플로우를 자동화하는 세 가지 강력한 명령어를 통해 크게 향상됩니다.","변혁#변혁":"이는 개발자를 대체하거나 창의성을 자동화하는 것에 관한 것이 아닙니다. 기계적인 번역을 자동화함으로써 인간의 능력을 증폭시키는 것입니다. 명세, 리서치, 코드가 함께 진화하며, 각 반복이 더 깊은 이해와 의도와 구현 간의 더 나은 일치를 가져오는 긴밀한 피드백 루프를 만드는 것입니다.\n소프트웨어 개발은 의도와 구현 간의 일치를 유지하기 위한 더 나은 도구가 필요합니다. SDD는 단순히 코드를 안내하는 것이 아니라 코드를 생성하는 실행 가능한 명세를 통해 이러한 일치를 달성하기 위한 방법론을 제공합니다.","복합-효과#복합 효과":"이러한 제약들은 함께 작용하여 다음과 같은 명세를 생성합니다:\n완전함: 체크리스트가 누락되는 것을 방지합니다. 모호하지 않음: 강제된 명확화 마커가 불확실성을 강조합니다. 테스트 가능함: 테스트 우선 사고가 프로세스에 내장되어 있습니다. 유지보수 가능함: 적절한 추상화 수준과 정보 계층 구조를 가집니다. 구현 가능함: 구체적인 결과물이 있는 명확한 단계로 구성됩니다. 템플릿은 LLM을 창의적인 작가에서 규율 있는 명세 엔지니어로 변모시켜, 그 능력을 일관되게 고품질이고 실행 가능한, 진정으로 개발을 주도하는 명세를 생산하는 방향으로 유도합니다.","불변의-원칙의-힘#불변의 원칙의 힘":"헌법의 힘은 그 불변성에 있습니다. 구현 세부사항은 진화할 수 있지만, 핵심 원칙은 일정하게 유지됩니다. 이는 다음을 제공합니다.\n시간에 따른 일관성: 오늘 생성된 코드는 내년에 생성될 코드와 동일한 원칙을 따릅니다. LLM 간의 일관성: 다른 AI 모델도 아키텍처적으로 호환되는 코드를 생성합니다. 아키텍처 무결성: 모든 기능이 시스템 설계를 훼손하는 대신 강화합니다. 품질 보증: 테스트 우선, 라이브러리 우선, 단순성 원칙이 유지보수 가능한 코드를 보장합니다.","실제-sdd-워크플로우#실제 SDD 워크플로우":"워크플로우는 종종 모호하고 불완전한 아이디어에서 시작됩니다. AI와의 반복적인 대화를 통해 이 아이디어는 포괄적인 PRD가 됩니다. AI는 명확한 질문을 하고, 엣지 케이스를 식별하며, 정밀한 인수 기준을 정의하는 데 도움을 줍니다. 전통적인 개발에서 며칠간의 회의와 문서 작업이 필요했던 일이, 집중적인 명세 작업 몇 시간 만에 이루어집니다. 이는 전통적인 소프트웨어 개발 수명주기(SDLC)를 변화시킵니다. 요구사항과 설계는 별개의 단계가 아니라 지속적인 활동이 됩니다. 이는 팀이 검토한 명세를 표현하고 버전 관리하며, 브랜치를 생성하고 병합하는 팀 프로세스를 지원합니다.\n제품 관리자가 인수 기준을 업데이트하면, 구현 계획은 영향을 받는 기술적 결정을 자동으로 표시합니다. 아키텍트가 더 나은 패턴을 발견하면, PRD는 새로운 가능성을 반영하여 업데이트됩니다.\n이 명세 과정 전반에 걸쳐, 리서치 에이전트가 중요한 컨텍스트를 수집합니다. 라이브러리 호환성, 성능 벤치마크, 보안 영향을 조사합니다. 조직의 제약 조건은 자동으로 발견되고 적용됩니다. 회사의 데이터베이스 표준, 인증 요구사항, 배포 정책 등이 모든 명세에 원활하게 통합됩니다.\nPRD로부터 AI는 요구사항을 기술적 결정에 매핑하는 구현 계획을 생성합니다. 모든 기술 선택에는 문서화된 근거가 있습니다. 모든 아키텍처 결정은 특정 요구사항으로 거슬러 올라갑니다. 이 과정 전반에 걸쳐, 일관성 검증이 지속적으로 품질을 향상시킵니다. AI는 일회성 관문으로서가 아니라 지속적인 개선 과정으로서 명세의 모호성, 모순, 격차를 분석합니다.\n코드 생성은 명세와 그 구현 계획이 충분히 안정화되는 즉시 시작되지만, “완전\"할 필요는 없습니다. 초기 생성물은 명세가 실제로 의미가 있는지 테스트하는 탐색적일 수 있습니다. 도메인 개념은 데이터 모델이 됩니다. 사용자 스토리는 API 엔드포인트가 됩니다. 인수 시나리오는 테스트가 됩니다. 이는 명세를 통해 개발과 테스트를 통합합니다. 테스트 시나리오는 코드 작성 후에 작성되는 것이 아니라, 구현과 테스트를 모두 생성하는 명세의 일부입니다.\n피드백 루프는 초기 개발을 넘어 확장됩니다. 프로덕션 환경의 지표와 장애는 단순히 긴급 수정(hotfix)을 유발하는 데 그치지 않고, 다음 재생성을 위해 명세를 업데이트합니다. 성능 병목 현상은 새로운 비기능적 요구사항이 됩니다. 보안 취약점은 모든 미래 생성물에 영향을 미치는 제약 조건이 됩니다. 명세, 구현, 그리고 운영 현실 사이의 이러한 반복적인 상호작용이야말로 진정한 이해가 나타나는 지점이며, 전통적인 SDLC가 지속적인 진화로 변모하는 곳입니다.","실제-speckit-도구-구현-예시#실제 speckit 도구 구현 예시":"명확한 요구사항 → 기술 설계 → 실행 가능한 작업 → 구현이라는 구조를 따르며, 소프트웨어 개발의 품질과 일관성을 높이는 데 초점을 둡니다.","예시-채팅-기능-구축하기#예시: 채팅 기능 구축하기":"이 명령어들이 전통적인 개발 워크플로우를 어떻게 변화시키는지 보여줍니다.\n전통적인 접근 방식:\n1. 문서에 PRD 작성 (2-3시간) 2. 설계 문서 작성 (2-3시간) 3. 프로젝트 구조 수동 설정 (30분) 4. 기술 명세 작성 (3-4시간) 5. 테스트 계획 작성 (2시간) 총: ~12시간의 문서 작업 명령어를 사용한 SDD 접근 방식:\n# 1단계: 기능 명세 생성 (5분) /speckit.specify 실시간 채팅 시스템 (메시지 기록 및 사용자 접속 상태 표시 기능 포함) # 이 명령어는 자동으로 다음을 수행합니다: # - \"003-chat-system\" 브랜치 생성 # - specs/003-chat-system/spec.md 생성 # - 구조화된 요구사항으로 파일 채우기 # 2단계: 구현 계획 생성 (5분) /speckit.plan 실시간 메시징은 WebSocket, 기록은 PostgreSQL, 접속 상태는 Redis 사용 # 3단계: 실행 가능한 작업 생성 (5분) /speckit.tasks # 이 명령어는 자동으로 다음을 생성합니다: # - specs/003-chat-system/plan.md # - specs/003-chat-system/research.md (WebSocket 라이브러리 비교) # - specs/003-chat-system/data-model.md (Message 및 User 스키마) # - specs/003-chat-system/contracts/ (WebSocket 이벤트, REST 엔드포인트) # - specs/003-chat-system/quickstart.md (주요 검증 시나리오) # - specs/003-chat-system/tasks.md (계획에서 도출된 작업 목록) 15분 안에 다음을 얻을 수 있습니다:\n사용자 스토리와 인수 기준이 포함된 완전한 기능 명세 기술 선택과 근거가 포함된 상세한 구현 계획 코드 생성을 위한 준비된 API 계약 및 데이터 모델 자동 및 수동 테스트를 위한 포괄적인 테스트 시나리오 기능 브랜치에 올바르게 버전 관리된 모든 문서","요약-spec-driven-development-워크플로우-흐름#요약: Spec-Driven Development 워크플로우 흐름":"constitution → specify → [clarify] → plan → tasks → [analyze] → [checklist] → implement 이 접근법은 **“생각하고 → 설계하고 → 검증하고 → 구현한다”**는 원칙을 따르며,\n특히 복잡한 시스템, 팀 협업, 장기 유지보수가 필요한 프로젝트에 매우 효과적입니다.\n필요하시면, 실제 프로젝트(예: C++ 데몬, VS Code 디버깅 설정 등)에 이 워크플로우를 적용해 함께 진행해 드릴 수도 있습니다.","제1조-라이브러리-우선-원칙#제1조: 라이브러리 우선 원칙":"모든 기능은 예외 없이 독립적인 라이브러리로 시작해야 합니다. 이는 처음부터 모듈식 설계를 강제합니다.\nSpecify의 모든 기능은 반드시 독립적인 라이브러리로 시작해야 한다. 어떤 기능도 재사용 가능한 라이브러리 컴포넌트로 먼저 추상화되지 않고 애플리케이션 코드 내에서 직접 구현되어서는 안 된다. 이 원칙은 명세가 모놀리식 애플리케이션이 아닌 모듈식이고 재사용 가능한 코드를 생성하도록 보장합니다. LLM이 구현 계획을 생성할 때, 명확한 경계와 최소한의 의존성을 가진 라이브러리로 기능을 구조화해야 합니다.","제2조-cli-인터페이스-의무화#제2조: CLI 인터페이스 의무화":"모든 라이브러리는 명령줄 인터페이스(CLI)를 통해 기능을 노출해야 합니다.\n모든 CLI 인터페이스는 다음을 반드시 준수해야 한다: - 텍스트를 입력으로 받는다 (stdin, 인수, 또는 파일을 통해) - 텍스트를 출력으로 생성한다 (stdout을 통해) - 구조화된 데이터 교환을 위해 JSON 형식을 지원한다 이는 관찰 가능성과 테스트 가능성을 강제합니다. LLM은 기능을 불투명한 클래스 내부에 숨길 수 없으며, 모든 것은 텍스트 기반 인터페이스를 통해 접근하고 검증할 수 있어야 합니다.","제3조-테스트-우선-원칙#제3조: 테스트 우선 원칙":"가장 혁신적인 조항으로, 테스트 없이는 코드도 없습니다.\n이것은 협상 불가능하다: 모든 구현은 엄격한 테스트 주도 개발(TDD)을 따라야 한다. 다음이 선행되지 않고는 어떠한 구현 코드도 작성되어서는 안 된다: 1. 단위 테스트가 작성된다. 2. 테스트가 사용자에 의해 검증되고 승인된다. 3. 테스트가 실패하는 것(Red 단계)이 확인된다. 이는 전통적인 AI 코드 생성을 완전히 뒤집습니다. 코드를 생성하고 작동하기를 바라는 대신, LLM은 먼저 행동을 정의하는 포괄적인 테스트를 생성하고, 승인을 받은 후, 그 다음에야 구현을 생성해야 합니다.","제7조--제8조-단순성과-추상화-방지#제7조 \u0026amp; 제8조: 단순성과 추상화 방지":"이 두 조항은 과도한 엔지니어링에 맞서 싸웁니다.\n제7조 3항: 최소한의 프로젝트 구조 - 초기 구현 시 최대 3개의 프로젝트 - 추가 프로젝트는 문서화된 정당화 필요 제8조 1항: 프레임워크 신뢰 - 프레임워크 기능을 감싸지 말고 직접 사용한다 LLM이 자연스럽게 정교한 추상화를 만들 수 있는 상황에서, 이 조항들은 모든 복잡성 계층에 대한 정당화를 강제합니다. 구현 계획 템플릿의 “-1단계 게이트\"는 이러한 원칙을 직접적으로 강제합니다.","제9조-통합-우선-테스트#제9조: 통합 우선 테스트":"고립된 단위 테스트보다 실제 환경 테스트를 우선시합니다.\n테스트는 반드시 현실적인 환경을 사용해야 한다: - 모의(mock) 객체보다 실제 데이터베이스 선호 - 스텁(stub)보다 실제 서비스 인스턴스 사용 - 구현 전 계약(contract) 테스트 의무화 이는 생성된 코드가 이론만이 아닌 실제 환경에서 작동함을 보장합니다.","지금-sdd가-중요한-이유#지금 SDD가 중요한 이유":"세 가지 트렌드가 SDD를 가능하게 할 뿐만 아니라 필수적으로 만듭니다.\n첫째, AI 역량이 자연어 명세를 통해 안정적으로 작동하는 코드를 생성할 수 있는 임계점에 도달했습니다. 이는 개발자를 대체하는 것이 아니라, 명세에서 구현으로의 기계적인 번역을 자동화함으로써 개발자의 효율성을 증폭시키는 것입니다. 이는 탐색과 창의성을 증폭시키고, “처음부터 다시 시작하기\"를 쉽게 지원하며, 추가, 삭제, 비판적 사고를 지원할 수 있습니다.\n둘째, 소프트웨어의 복잡성은 기하급수적으로 계속 증가하고 있습니다. 현대 시스템은 수십 개의 서비스, 프레임워크, 의존성을 통합합니다. 이 모든 조각들을 수동 프로세스를 통해 원래의 의도와 일치시키는 것은 점점 더 어려워지고 있습니다. SDD는 명세 주도 생성을 통해 체계적인 일관성을 제공합니다. 프레임워크는 인간 우선이 아닌 AI 우선 지원을 제공하거나, 재사용 가능한 컴포넌트를 중심으로 설계되도록 진화할 수 있습니다.\n셋째, 변화의 속도가 가속화되고 있습니다. 오늘날 요구사항은 과거 어느 때보다 훨씬 빠르게 변화합니다. 방향 전환(Pivoting)은 더 이상 예외적인 일이 아니라 예상되는 일입니다. 현대 제품 개발은 사용자 피드백, 시장 상황, 경쟁 압력에 기반한 빠른 반복을 요구합니다. 전통적인 개발은 이러한 변화를 방해 요소로 취급합니다. 각 방향 전환은 문서, 설계, 코드를 통해 수동으로 변경 사항을 전파해야 합니다. 그 결과는 속도를 제한하는 느리고 신중한 업데이트이거나, 기술 부채를 축적하는 빠르고 무모한 변경입니다.\nSDD는 “만약 우리가 티셔츠를 더 많이 팔기 위한 비즈니스 요구를 촉진하기 위해 애플리케이션을 재구현하거나 변경해야 한다면, 그것을 어떻게 구현하고 실험할 것인가?“와 같은 가상/시뮬레이션 실험을 지원할 수 있습니다.\nSDD는 요구사항 변경을 장애물에서 정상적인 워크플로우로 변환합니다. 명세가 구현을 주도할 때, 방향 전환은 수동 재작성이 아닌 체계적인 재생성이 됩니다. PRD에서 핵심 요구사항을 변경하면, 영향을 받는 구현 계획이 자동으로 업데이트됩니다. 사용자 스토리를 수정하면, 해당 API 엔드포인트가 재생성됩니다. 이것은 단지 초기 개발에 관한 것이 아니라, 필연적인 변화 속에서도 엔지니어링 속도를 유지하는 것에 관한 것입니다.","템플릿-주도-품질-구조가-llm을-제약하여-더-나은-결과를-만드는-방법#템플릿 주도 품질: 구조가 LLM을 제약하여 더 나은 결과를 만드는 방법":"이 명령어들의 진정한 힘은 단순한 자동화가 아니라, 템플릿이 LLM의 행동을 더 높은 품질의 명세로 유도하는 방식에 있습니다. 템플릿은 LLM의 출력을 생산적인 방향으로 제약하는 정교한 프롬프트 역할을 합니다.","템플릿을-통한-헌법-강제#템플릿을 통한 헌법 강제":"구현 계획 템플릿은 구체적인 체크포인트를 통해 이러한 조항들을 실행합니다.\n### -1단계: 사전 구현 게이트 #### 단순성 게이트 (제7조) - [ ] 3개 이하의 프로젝트를 사용하고 있는가? - [ ] 미래를 대비한 과도한 설계는 없는가? #### 추상화 방지 게이트 (제8조) - [ ] 프레임워크를 직접 사용하고 있는가? - [ ] 단일 모델 표현을 사용하는가? #### 통합 우선 게이트 (제9조) - [ ] 계약이 정의되었는가? - [ ] 계약 테스트가 작성되었는가? 이러한 게이트는 아키텍처 원칙에 대한 컴파일 타임 체크 역할을 합니다. LLM은 게이트를 통과하거나, “복잡성 추적” 섹션에 정당한 예외를 문서화하지 않고는 진행할 수 없습니다.","핵심-원칙#핵심 원칙":"명세가 공용어(Lingua Franca): 명세가 주요 산출물이 됩니다. 코드는 특정 언어와 프레임워크로 표현된 구현체가 됩니다. 소프트웨어를 유지보수한다는 것은 명세를 발전시키는 것을 의미합니다.\n실행 가능한 명세: 명세는 작동하는 시스템을 생성할 만큼 정밀하고, 완전하며, 모호하지 않아야 합니다. 이는 의도와 구현 사이의 격차를 제거합니다.\n지속적인 개선: 일관성 검증은 일회성 관문이 아니라 지속적으로 발생합니다. AI는 지속적인 프로세스로서 명세의 모호성, 모순, 격차를 분석합니다.\n리서치 기반 컨텍스트: 리서치 에이전트는 명세 과정 전반에 걸쳐 기술적 옵션, 성능 영향, 조직의 제약 조건을 조사하며 중요한 컨텍스트를 수집합니다.\n양방향 피드백: 프로덕션 환경의 현실이 명세 진화에 정보를 제공합니다. 지표, 장애, 운영상의 교훈이 명세 개선을 위한 입력이 됩니다.\n탐색을 위한 브랜칭: 동일한 명세에서 여러 구현 접근 방식을 생성하여 성능, 유지보수성, 사용자 경험, 비용 등 다양한 최적화 목표를 탐색합니다.","헌법의-진화#헌법의 진화":"원칙은 불변이지만, 그 적용은 진화할 수 있습니다.\n제4조 2항: 개정 절차 이 헌법을 수정하려면 다음이 필요하다: - 변경 이유에 대한 명시적인 문서화 - 프로젝트 유지보수자의 검토 및 승인 - 하위 호환성 평가 이는 안정성을 유지하면서 방법론이 학습하고 개선될 수 있도록 합니다. 헌법은 날짜가 기록된 개정안을 통해 원칙이 실제 경험을 바탕으로 어떻게 개선될 수 있는지를 보여줍니다.","헌법적-기반-아키텍처-규율-강제#헌법적 기반: 아키텍처 규율 강제":"SDD의 핵심에는 명세가 코드가 되는 방식을 지배하는 불변의 원칙 집합인 헌법이 있습니다. 헌법(memory/constitution.md)은 시스템의 아키텍처 DNA 역할을 하여, 생성된 모든 구현이 일관성, 단순성, 품질을 유지하도록 보장합니다."},"title":"Spec Driven Development"},"/spring-%EC%99%B8%EB%B6%80%EC%84%A4%EC%A0%95/":{"data":{"":"application.properties 설정 우선순위 (가장 높음 → 낮음) 우선순위 소스 1 Devtools 전역 설정 (.spring-boot-devtools.properties) 2 테스트 애너테이션 (@TestPropertySource) 3 커맨드 라인 아규먼트 (--server.port=8080) 4 JVM 시스템 프로퍼티 (-Dproperty=value) 5 OS 환경 변수 6 RandomValuePropertySource (${random.*}) 7 JAR 외부의 application-{profile}.properties 8 JAR 외부의 application.properties 9 JAR 내부의 application-{profile}.properties 10 JAR 내부의 application.properties 11 @PropertySource / @ConfigurationProperties","1-설정-파일-로딩-원리#1. 설정 파일 로딩 원리":"Spring Boot는 시작 시 Environment 객체를 생성합니다. 이후 정해진 우선순위에 따라 application.properties, 환경 변수 등 다양한 소스(Source)의 설정 값을 읽어 Environment에 채워 넣습니다. 애플리케이션의 다른 부분들은 이 Environment를 통해 설정 값을 사용합니다.","10-properties-vs-yml#10. .properties vs .yml":"우선순위: 동일한 경로에 두 파일이 모두 존재할 경우, application.properties 파일이 .yml 파일보다 항상 우선순위가 높습니다.\n특징:\napplication.properties: key=value 형식. 우선순위가 더 높음.\napplication.yml: YAML 형식. 계층 구조 표현이 용이해 가독성이 좋음.","11-핵심-실무-팁#11. 핵심 실무 팁":"보안: 민감 정보(비밀번호, API 키 등)는 절대로 Git에 커밋하지 마세요.\n분리: 테스트 환경을 위한 프로필(application-test.properties)을 분리하여 관리하세요.\n컨벤션: 팀 내에서 .properties와 .yml 중 하나를 주력으로 사용하기로 컨벤션을 정하여 혼란을 방지하세요. (최근에는 가독성이 좋은 .yml이 선호되는 추세입니다.)","2-설정-우선순위#2. 설정 우선순위":"핵심 원칙은 **외부 설정이 내부 설정을 덮어쓴다(override)**는 것입니다. 즉, 애플리케이션을 실행하는 시점에 주입하는 설정이 코드에 포함된 설정보다 우선순위가 높습니다.\n실무 핵심 순서 (높은 순):\n테스트 코드 내 설정 (@TestPropertySource) 커맨드 라인 인수 (java -jar app.jar –server.port=9000) OS 환경 변수 (export SERVER_PORT=9002) JAR 외부의 설정 파일 (./config/application.properties) JAR 내부의 설정 파일 (classpath:/application.properties) @PropertySource 로드 파일 SpringApplication 기본값","3-configurationproperties-고급-활용#3. @ConfigurationProperties 고급 활용":"프로퍼티 값을 타입-세이프(Type-safe)하게 객체로 바인딩하는 기능입니다.\n구조: 중첩 객체, 리스트, 맵 등 복잡한 구조의 프로퍼티를 객체에 자동으로 매핑할 수 있습니다. 유효성 검사: @Validated 애너테이션과 spring-boot-starter-validation 의존성을 추가하면, 로드된 값에 대해 @NotNull, @Min 등 JSR-303 유효성 검사를 적용할 수 있습니다.","4-외부-설정-파일-주입#4. 외부 설정 파일 주입":"spring.config.location: 지정된 위치의 파일만 사용합니다. (기본 경로 무시) spring.config.additional-location: 기본 경로를 유지하면서 지정된 파일을 추가로 로드합니다. spring.config.import: application.properties 내에서 다른 설정 파일을 불러옵니다. optional: 접두사를 붙이면 파일이 없어도 오류가 발생하지 않습니다. spring.config.import=optional:classpath:aws.properties","5-propertysource-vs-applicationproperties#5. @PropertySource vs application.properties":"우선순위: @PropertySource로 로드한 설정은 application.properties보다 우선순위가 낮습니다. 즉, 두 파일에 동일한 키가 있으면 application.properties의 값이 적용됩니다.\n용도: @PropertySource는 특정 기능에 대한 설정을 모듈화하거나 레거시 설정을 통합할 때 유용합니다. 주 설정 파일은 application.properties를 사용하는 것이 표준입니다.","6-ide-지원-자동-완성#6. IDE 지원 (자동 완성)":"spring-boot-configuration-processor 의존성을 추가하면, @ConfigurationProperties로 정의한 설정 키에 대해 IDE가 자동 완성 및 설명을 제공하여 개발 생산성을 크게 향상시킵니다.","7-민감-정보-관리#7. 민감 정보 관리":"민감한 정보(DB 비밀번호, API 키 등)는 코드에 직접 작성하지 않는 것이 원칙입니다.\n관리 방법: OS 환경 변수나 외부 설정 파일을 사용합니다.\n권장 방식: 클라우드 환경에서는 Vault, AWS SSM, GCP Secret Manager와 같은 외부 보안 저장소와 연동하는 것이 가장 안전합니다.","8-프로필과-조건부-설정#8. 프로필과 조건부 설정":"@Profile: “dev”, “prod” 와 같이 특정 프로필이 활성화될 때만 특정 빈(Bean)을 등록하도록 제어합니다.\n@ConditionalOnProperty: 특정 프로퍼티 값에 따라 빈의 등록 여부를 결정합니다. 기능 플래그(Feature Flag)를 구현할 때 매우 유용합니다.","9-테스트-설정#9. 테스트 설정":"설정 분리: src/test/resources/application-test.properties와 같이 테스트용 설정 파일을 분리하여 관리합니다.\n@TestPropertySource: 특정 테스트 케이스에만 적용할 설정을 높은 우선순위로 주입할 수 있어, 독립적인 테스트 환경을 구성하는 데 효과적입니다.","applicationproperties#application.properties":"","applicationproperties-1#application.properties":"","applicationproperties-우선-순위#\u003cstrong\u003eapplication.properties 우선 순위\u003c/strong\u003e":"application.properties 파일은 아래 4가지 경로에 만들 수 있지만, 우선순위에 따라 덮어쓰기가 된다.\nfile:./config/ file:./ classpath:/config/ classpath:/ file 경로 : src 폴더 하위에 application.properties classpath 경로 : 기본적으로 만들어지는 resources 폴더 하위 application.properties"},"title":"spring 외부설정"},"/temp/%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D/":{"data":{"":"교차 검증(Cross Validation)은 머신러닝 모델의 성능을 평가하는 데 널리 사용되는 기법입니다. 이를 통해 모델이 새로운 데이터에 대해 얼마나 잘 일반화될 수 있는지를 더 정확하게 평가할 수 있습니다. 아래에서 교차 검증의 개념과 예시를 단계별로 설명하겠습니다.","1-데이터를-k개의-서브셋fold으로-나눈다#1. 데이터를 k개의 서브셋(fold)으로 나눈다.":"데이터셋을 동일한 크기의 k개로 나눕니다. 예를 들어, 데이터셋이 100개이고 $ k=5 $라면, 각 fold는 20개의 데이터를 포함합니다.","2-각-fold를-검증셋으로-사용하며-모델-학습-및-평가를-반복한다#2. 각 fold를 검증셋으로 사용하며 모델 학습 및 평가를 반복한다.":"Fold 1을 검증셋으로 사용하고, 나머지 Fold 2~5를 훈련셋으로 사용해 모델을 학습한 후 검증셋(Fold 1)에서 성능을 평가합니다. 이 과정을 Fold 2, Fold 3, …, Fold k까지 반복합니다.","3-k번의-성능-평가-결과를-평균하여-최종-성능을-산출한다#3. k번의 성능 평가 결과를 평균하여 최종 성능을 산출한다.":"각 fold에서 얻은 성능(예: 정확도, F1 스코어 등)을 평균하여 최종 성능으로 간주합니다.","k-겹-교차-검증k-fold-cross-validation의-과정#\u003cstrong\u003ek-겹 교차 검증(K-Fold Cross Validation)의 과정\u003c/strong\u003e":"","step-by-step-설명#Step-by-step 설명:":"데이터 분할:\n데이터셋을 5개의 fold로 나눕니다. 각 fold는 20개의 샘플을 포함합니다. Fold 1: 1~20번 샘플 Fold 2: 21~40번 샘플 Fold 3: 41~60번 샘플 Fold 4: 61~80번 샘플 Fold 5: 81~100번 샘플 1번째 반복:\nFold 1을 검증셋, Fold 2~5를 훈련셋으로 사용합니다. Fold 2~5(80개 샘플)로 모델을 학습하고, Fold 1(20개 샘플)에서 성능을 평가합니다. 예를 들어, Fold 1에서 정확도가 85%라고 가정합니다. 2번째 반복:\nFold 2를 검증셋, Fold 1, 3~5를 훈련셋으로 사용합니다. Fold 1, 3~5(80개 샘플)로 모델을 학습하고, Fold 2(20개 샘플)에서 성능을 평가합니다. Fold 2에서 정확도가 88%라고 가정합니다. 3~5번째 반복:\n위 과정을 Fold 3, Fold 4, Fold 5에서도 동일하게 수행합니다. 각 fold에서의 정확도 결과: Fold 1: 85% Fold 2: 88% Fold 3: 90% Fold 4: 87% Fold 5: 89% 최종 성능 평가:\n5개 fold에서 얻은 정확도의 평균을 계산합니다. $$ \\text{평균 정확도} = \\frac{85 + 88 + 90 + 87 + 89}{5} = 87.8% $$","결론#\u003cstrong\u003e결론\u003c/strong\u003e":"교차 검증은 모델의 성능을 안정적으로 평가하기 위한 강력한 도구입니다. 특히 데이터가 제한적인 상황에서 유용하며, 다양한 모델의 성능을 비교하거나 하이퍼파라미터 튜닝을 할 때 자주 사용됩니다.\n$$ \\boxed{\\text{k-겹 교차 검증은 데이터를 k개의 fold로 나눠 여러 번 학습과 평가를 반복하는 방식으로, 모델의 일반화 성능을 신뢰성 있게 평가합니다.}} $$","교차-검증의-기본-아이디어#\u003cstrong\u003e교차 검증의 기본 아이디어\u003c/strong\u003e":"데이터셋을 훈련셋과 검증셋으로 나누는 경우, 훈련 데이터와 검증 데이터의 선택이 성능 평가 결과에 영향을 미칠 수 있습니다. 따라서 전체 데이터를 여러 개의 작은 부분(fold)으로 나눈 후, 각 부분을 검증셋으로 사용하고 나머지를 훈련셋으로 사용하여 여러 번 실험을 진행합니다. 이렇게 얻은 여러 성능 평가 결과의 평균값을 최종 성능 평가 결과로 사용합니다.","단점#\u003cstrong\u003e단점\u003c/strong\u003e":"시간과 비용 소모:\n$ k $가 클수록 모델 학습과 평가 횟수가 늘어나므로 시간과 계산 비용이 증가합니다. 예를 들어, $ k=10 $인 경우 10번의 학습과 평가가 필요합니다. 데이터 분포의 불균형 문제:\n데이터가 클래스별로 불균형할 경우, 각 fold의 분포가 원래 데이터셋의 분포와 달라질 수 있습니다. 이를 해결하기 위해 **층화 K-Fold(Stratified K-Fold)**를 사용할 수 있습니다.","상황#상황:":"데이터셋: 100개의 샘플 $ k = 5 $ (5-fold cross validation) 성능 평가 지표: 정확도(Accuracy)","예시#\u003cstrong\u003e예시\u003c/strong\u003e":"","장점#\u003cstrong\u003e장점\u003c/strong\u003e":"데이터 활용 효율성:\n모든 데이터가 훈련과 검증 과정에 고르게 사용됩니다. 특히 데이터가 적을 때 유용합니다. 더 신뢰할 수 있는 성능 평가:\n단순히 한 번의 훈련/검증만으로 성능을 평가하는 것보다, 여러 번의 평가를 통해 모델의 일반화 성능을 더 정확하게 파악할 수 있습니다.","층화-k-foldstratified-k-fold#\u003cstrong\u003e층화 K-Fold(Stratified K-Fold)\u003c/strong\u003e":"클래스 비율을 유지하면서 데이터를 분할하는 방법입니다. 예를 들어, 데이터셋에서 클래스 A가 70%, 클래스 B가 30%라면 각 fold에도 같은 비율로 클래스 A와 B가 포함되도록 합니다."},"title":"교차검증"},"/temp/%EB%82%98%EC%9D%98-%EC%9B%B9%EC%84%9C%EB%B2%84-%ED%8C%A8%ED%82%B7-%EB%B6%84%EC%84%9D-%EC%9D%B4%EC%95%BC%EA%B8%B0/":{"data":{"":"내가 만든 웹서버 shinnk.iptime.org html과 css 로만 만들어진 단순한 index.html 파일을 요청하는 상황이다 chrome 프로세스가 port 50837를 사용한다 웹서버는 80 포트로 listen 중이다 http wire shark 로 확인하였다 (https 의 경우 ssl 암호화 과정때문에 프로토콜이 일부 보이지 않는다 그래서 http 로 진행)\nng)\n총 7개의 통신 흔적이 보인다 http 통신은 tcp 를 사용한다 그러므로 3way handshake 과정이 선행된다\nno 24 no 26 no 27 no 30 no 31 no 32 no 33 24 26 27 가 3 way handshake 과정이다"},"title":"나의 웹서버 패킷 분석 이야기"},"/temp/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EC%A0%84%EA%B3%B5%EC%B1%85-chapter6-7-%EC%A0%95%EB%A6%AC/":{"data":{"":"ER diagram 설명 및 스키마 변경 스키마의 좋은 나쁜 설계 판별\n요구사항 명세서 -\u003e 개념적 설계(ERD ER diagram) -\u003e 기능적 요구사항 명세서 -\u003e 논리적 설계(ddl) -\u003e 물리적 설계(인덱싱 파일 구성)\nredundancy : database 에서 attribute 는 1개만 있는 것이 좋다 왜래키로 지정하자 dept_name 은 departname 을 pk 로 가져가고 나머지는 fk 로 만들자\nentity 개체 : 사람A : 속성의 집합\nentity set 개체 집합 : instructor : 개체의 집합\nattribute 속성 : 구성원들이 소유하는 설명 특성\nvalue 값 : 속성의 특정 값\nvalue set = domain : 속성이 가질 수 있는 값 집합\nrelationship 관계 : 개채 사이의 연관성 : 교수와 학갱의 지도교수 관계\nrelationship set : 관계 집합\nrelationship instance : 실제 조직내의 명명된 개체들 사이에 연관성\nparticipation 참여 : entity set (개체 집합) 사이의 연관\nmapping cardinality || cardinality ratio 대응 키디널리티 또는 카니널리티 비율 : 대응수+ total vs partial role 역할 : 관계에서 개체가 행하는 기능\n재귀 관계집합 : course - prereq : role 적는 것이 특히 재귀관계집합 이해에 도움이 된다 descriptive attribute 설명속성 : student - takes - sections 에서 task 는 학생의 성적 기록을 위해 grade 속성을 저장하기를 원한다 multivalued attribute : 다중값 속성 : student - takes - sections 에서 성적은 분반 1개에 1개의 성적을 받을 수 있는데 여러개의 성적이 들어간다면 grade 속성이 많은 것을 저장해야 한다 관계집합 차수 : 관계집합에 참여하는 개체집합의 수 2 이상 paricipation 표기?? %20image%2020241012082751.png)\n식별관계는 설명속성을 가질수없다 약한 개체 집합과 연관될수 있기 때문","복합속성을-지닌-강한-개체-집합의-표현#복합속성을 지닌 강한 개체 집합의 표현":"만약 전번이 2개 이상 가진 교수의 경우 어케할까 instructor_phone(ID, phone_number) 이렇게 해서 표현한다 ID 는 instructor 의 fk 인 id 로 여기서는 왜래키 이자 pk 이다\n식별관계 에서의 브릿지 table 가능성\nweak entity set"},"title":"데이터베이스 전공책 chapter6, 7 정리"},"/temp/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EB%B9%84%EC%9D%B4%EC%A7%84-%EA%B4%80%EA%B3%84-%EC%8A%A4%ED%82%A4%EB%A7%88-%EC%83%9D%EC%84%B1%EC%8B%9C/":{"data":{"":"","비이진-관계에서의-기본-키-선택#비이진 관계에서의 기본 키 선택":"비이진 관계에서 카디널리티 제약이 없는 경우, 앞서 설명한 대로 형성된 슈퍼키가 유일한 후보 키가 되며, 이를 기본 키로 선택합니다. 하지만 카디널리티 제약이 있을 경우 기본 키 선택이 더 복잡해집니다.\n우리가 6.4절에서 언급한 바와 같이, 비이진 관계 집합에서 최대 한 개의 화살표만 허용합니다. 이는 비이진 관계 집합에서 두 개 이상의 화살표가 있을 경우 해석이 두 가지로 나뉘어질 수 있기 때문입니다.","비이진-관계의-대체#비이진 관계의 대체":"여러 화살표가 필요한 상황을 표현하기 위해 E-R 설계를 수정하여 비이진 관계 집합을 엔티티 집합으로 대체할 수 있습니다. 즉, 비이진 관계 집합의 각 인스턴스를 엔티티로 간주하고, 이 엔티티를 ( E1, E2, E4 )의 인스턴스와 별도의 관계 집합을 통해 연결할 수 있습니다.","예시#예시":"관계 집합 ( R )이 엔티티 집합 ( E1, E2, E3, E4 ) 간의 관계를 나타내고, 화살표가 ( E3 )와 ( E4 )로만 향해 있다고 가정합니다. 이 경우 두 가지 가능한 해석이 있습니다:\n첫 번째 해석:\n( E1 )과 ( E2 )의 특정 조합이 ( E3 )와 ( E4 )의 조합과 최대 한 번만 연결될 수 있습니다. 이 경우 관계 ( R )의 기본 키는 ( E1 )과 ( E2 )의 기본 키의 합집합으로 구성됩니다. 두 번째 해석:\n( E1 ), ( E2 ), ( E3 )의 특정 조합이 ( E4 )의 조합과 최대 한 번만 연결될 수 있으며, 또한 ( E1 ), ( E2 ), ( E4 )의 조합이 ( E3 )의 조합과 최대 한 번만 연결될 수 있습니다. 이 경우 ( E1 ), ( E2 ), ( E3 )의 기본 키의 합집합과 ( E1 ), ( E2 ), ( E4 )의 기본 키의 합집합이 모두 후보 키가 됩니다. 이 두 해석은 모두 실제로 사용되며, 특정 모델링을 위해서도 올바른 해석입니다. 따라서 혼란을 피하기 위해 비이진 관계 집합에서 오직 하나의 화살표만 허용하며, 이 경우 두 해석이 동등하게 적용됩니다.","최종-기본-키-선택#최종 기본 키 선택":"관계 집합 ( R )의 기본 키는 관계 집합 ( R )로부터의 화살표가 없는 참여 엔티티 집합 ( E_i )의 기본 키의 합집합으로 정의됩니다.\n이러한 내용은 비이진 관계에서 기본 키를 정의하고 선택하는 데 중요한 역할을 합니다.","함수적-종속성#함수적 종속성":"더 간단한 접근법은 함수적 종속성을 사용하는 것입니다. 이는 이후 장에서 다룰 내용으로, 이러한 해석을 명확하게 지정할 수 있게 해줍니다."},"title":"데이터 베이스 비이진 관계 스키마 생성시"},"/temp/%EB%A0%88%EC%A7%80%EC%8A%A4%ED%84%B0/":{"data":{"":"","x86-64-amd64#x86-64, AMD64":"CPU\nrax, rbx, rcx, rdx: 64비트 범용 레지스터입니다. rsi, rdi: 소스 인덱스와 목적지 인덱스 레지스터입니다. rbp, rsp: 베이스 포인터와 스택 포인터 레지스터입니다. r8에서 r15까지: 추가적인 64비트 범용 레지스터입니다. rip: 명령어 포인터 레지스터입니다. eflags: 프로세서의 현재 상태를 나타내는 플래그 레지스터입니다. eax, ebx, ecx, edx: 32비트 범용 레지스터입니다. esi, edi: 32비트 소스 인덱스와 목적지 인덱스 레지스터입니다. ebp, esp: 32비트 베이스 포인터와 스택 포인터 레지스터입니다. Segs (세그먼트 레지스터):\ncs: 코드 세그먼트 ss: 스택 세그먼트 ds: 데이터 세그먼트 es: 추가 데이터 세그먼트 fs: 추가 데이터 세그먼트 gs: 추가 데이터 세그먼트 FPU (부동 소수점 유닛): st0에서 st7까지: FPU 스택 레지스터 fctrl: FPU 제어 레지스터 fstat: FPU 상태 레지스터 ftag: FPU 태그 워드 fiseg: FPU 명령 포인터 세그먼트 fioff: FPU 명령 포인터 오프셋 foseg: FPU 데이터 포인터 세그먼트 fooff: FPU 데이터 포인터 오프셋 fop: FPU 연산 코드 SSE 섹션:\nxmm0부터 xmm31까지: 128비트 XMM 레지스터입니다. 각 레지스터는 8개의 16비트 부동소수점 값(bfloat16)을 저장할 수 있습니다. mxcsr: SSE 제어 및 상태 레지스터로, 부동소수점 연산 모드와 예외 처리를 제어합니다. YMM 레지스터: ymm0h, ymm1h, … ymm31h는 AVX512의 상위 256비트 부분을 나타내며, ymm0, ymm1, … ymm31는 하위 256비트 부분을 나타냅니다. ymm는 256비트 크기의 AVX 레지스터를 의미하며, AVX512에서는 zmm 레지스터가 512비트로 확장됩니다. 각 YMM 레지스터는 벡터 연산을 위해 사용됩니다. 벡터 연산은 한 번에 여러 데이터를 처리할 수 있어 병렬 처리를 효율적으로 수행할 수 있습니다. ymm0h, ymm1h 등: 이들은 AVX 레지스터의 상위 비트 (하위 256비트를 제외한 부분)입니다. ymm0h는 ymm0 레지스터의 상위 256비트입니다. 각 레지스터가 0x0 값을 가지는 것은 이 레지스터가 현재 비어 있거나, 아직 연산에 사용되지 않았음을 의미할 수 있습니다. ymm0, ymm1 등: 이들은 AVX 레지스터의 하위 비트이며, 주로 연산에 사용되는 실제 데이터가 이곳에 저장됩니다. 예를 들어, ymm8 = {v16_bfloat16 = {0x0 }}는 ymm8 레지스터가 bfloat16 형식의 데이터 16개로 채워져 있고, 그 값이 모두 0x0임을 나타냅니다. Other Register\nk0-k7: AVX-512 마스크 레지스터입니다.\nzmm8h, zmm9h: 512비트 AVX-512 벡터 레지스터의 상위 부분입니다.\nfs_base, gs_base: FS와 GS 세그먼트의 베이스 주소입니다.\norig_rax: 시스템 콜 진입 시 원본 RAX 값입니다.\nal, bl, cl, dl, sil, dil, bpl, spl: 8비트 하위 레지스터들입니다.\nr8l-r15l: 확장 레지스터의 8비트 하위 부분입니다.\nah, bh, ch, dh: 8비트 상위 레지스터들입니다.\nax, bx, cx, dx, si, di, bp: 16비트 레지스터들입니다.\nr8w-r15w: 확장 레지스터의 16비트 부분입니다.\nr8d-r15d: 확장 레지스터의 32비트 부분입니다.\nzmm8, zmm9: 512비트 AVX-512 벡터 레지스터입니다.\nMMX 섹션:\nzmm0h부터 zmm29h: 512비트 ZMM 레지스터의 상위 256비트 부분입니다. zmm0부터 zmm29: 전체 512비트 ZMM 레지스터입니다. AMD3DNow 섹션:\nzmm10h부터 zmm31h: ZMM 레지스터의 상위 256비트 부분입니다. zmm10부터 zmm31: 전체 512비트 ZMM 레지스터입니다."},"title":"레지스터"},"/temp/%EB%A6%AC%EB%88%85%EC%8A%A4-%ED%8C%8C%EC%9D%BC-%EA%B6%8C%ED%95%9C/":{"data":{"":"인터넷에 적절하지 못한 파일 권한 설명 그중에 특히 sticky 비트에 대해 오류가 많아 작성하게 됨\nOS 의 경우 linux 를 가정하고 Mac OS 의 경우 도 조금 서술\nFILE TYPE expression nomal directory read r 읽기 내부 파일 이름 읽기 write w 쓰기 내부에 파일 생성 삭제 변경(execute 의존) execute x 실행 내부 파일 메타데이터 읽기(read 의존) setUID\ns 소유자 권한으로 실행 소유자 권한으로 실행 setGID\nbit s 소유 그룹 권한으로 실행 소유한 그룹의 권한으로 실행 sticky bit t linux : 무시 쓰기 권한이 존재해도 다른 사용자가 소유한 파일을 건드리지 못한다 (ex /tmp) s 와 t 가 대문자인 경우 소유한 유저 또는 소유한 그룹이 실행 권한이 없어 비트가 설정되어 있어도 실제로는 동작시키지 못한다","실행별-결과#실행별 결과":"rwx 디렉토리 동작과정\nshinnk@DESKTOP-KRSG68U:~/test/permission$ ls -la total 36 drwxrwxr-x 9 shinnk shinnk 4096 Oct 7 10:57 . drwxr-xr-x 10 shinnk shinnk 4096 Oct 7 10:33 .. d--x------ 2 shinnk shinnk 4096 Oct 7 10:56 100 d-w------- 2 shinnk shinnk 4096 Oct 7 10:56 200 d-wx------ 2 shinnk shinnk 4096 Oct 7 11:01 300 dr-------- 2 shinnk shinnk 4096 Oct 7 10:56 400 dr-x------ 2 shinnk shinnk 4096 Oct 7 10:56 500 drw------- 2 shinnk shinnk 4096 Oct 7 10:56 600 drwx------ 2 shinnk shinnk 4096 Oct 7 10:56 700 ===================================================== shinnk@DESKTOP-KRSG68U:~/test/permission$ ls {1,2,3,4,5,6,7}00 ls: cannot open directory '100': Permission denied ls: cannot open directory '200': Permission denied ls: cannot open directory '300': Permission denied 400: 500: 600: 700: tempfile =================================================== shinnk@DESKTOP-KRSG68U:~/test/permission$ ls -la {1,2,3,4,5,6,7}00 ls: cannot open directory '100': Permission denied ls: cannot open directory '200': Permission denied ls: cannot open directory '300': Permission denied 400: ls: cannot access '400/..': Permission denied ls: cannot access '400/.': Permission denied total 0 d????????? ? ? ? ? ? . d????????? ? ? ? ? ? .. 500: total 8 dr-x------ 2 shinnk shinnk 4096 Oct 7 10:56 . drwxrwxr-x 9 shinnk shinnk 4096 Oct 7 10:57 .. 600: ls: cannot access '600/..': Permission denied ls: cannot access '600/.': Permission denied total 0 d????????? ? ? ? ? ? . d????????? ? ? ? ? ? .. 700: total 8 drwx------ 2 shinnk shinnk 4096 Oct 7 10:56 . drwxrwxr-x 9 shinnk shinnk 4096 Oct 7 10:57 .. -rw-r--r-- 1 shinnk shinnk 0 Oct 7 10:56 tempfile shinnk@DESKTOP-KRSG68U:~/test/permission$ touch {1,2,3,4,5,6,7}00/temp touch: cannot touch '100/temp': Permission denied touch: cannot touch '200/temp': Permission denied touch: cannot touch '400/temp': Permission denied touch: cannot touch '500/temp': Permission denied touch: cannot touch '600/temp': Permission denied"},"title":"리눅스 파일 권한"},"/temp/%EB%A9%94%EB%AA%A8%EB%A6%AC-%EA%B8%B0%EB%B0%98-database/":{"data":{"":"in-memory database 종류 radis","1데이터-저장-방식#1. \u003cstrong\u003e데이터 저장 방식\u003c/strong\u003e":"인메모리 저장: 인메모리 DBMS는 데이터를 RAM에 저장하여 빠른 접근을 가능하게 합니다. 데이터는 일반적으로 테이블 형식으로 구성되며, 각 테이블은 행(row)과 열(column)로 이루어져 있습니다.","2데이터-구조#2. \u003cstrong\u003e데이터 구조\u003c/strong\u003e":"행 기반 vs. 열 기반: 일부 DBMS는 행 기반 저장 방식을 사용하고, 다른 DBMS는 열 기반 저장 방식을 사용합니다. 예를 들어, SAP HANA는 열 기반 저장 방식을 사용하여 분석 쿼리에 최적화되어 있습니다.","3트랜잭션-처리#3. \u003cstrong\u003e트랜잭션 처리\u003c/strong\u003e":"ACID 준수: 많은 인메모리 DBMS는 ACID(원자성, 일관성, 고립성, 지속성) 트랜잭션을 지원합니다. 이들은 메모리에 저장된 데이터의 일관성을 보장하는 메커니즘을 갖추고 있습니다.","4쿼리-처리#4. \u003cstrong\u003e쿼리 처리\u003c/strong\u003e":"SQL 지원: 대부분의 인메모리 DBMS는 SQL 쿼리를 지원합니다. 사용자는 SQL을 사용하여 데이터를 삽입, 선택, 업데이트 및 삭제할 수 있습니다."},"title":"메모리 기반 database"},"/temp/%EB%AC%B8%EC%9E%90-%EC%B0%BE%EA%B8%B0/":{"data":{"":"일반적인 이중 반복\nint index = 0; // 인덱스 초기화 while (index \u003c n) { // 특정 작업 수행 doSomething(index); // 조건에 맞는 동안 반복하는 작업 수행 while (someCondition(index) \u0026\u0026 index \u003c n) { doSomethingElse(index); index++; } // 조건이 충족되지 않았을 때도 index 증가 if (index \u003c n) index++; } 재귀 방식\nvoid processIndex(int index, int n) { if (index \u003e= n) return; // 종료 조건 // 특정 작업 수행 doSomething(index); // 조건에 따라 작업 수행 반복 if (someCondition(index)) { doSomethingElse(index); processIndex(index + 1, n); // 다음 인덱스 재귀 호출 } else { // 조건이 충족되지 않았을 때 처리 doSomethingElse(index); processIndex(index + 1, n); // 다음 인덱스 재귀 호출 } }"},"title":"문자 찾기"},"/temp/%EC%82%B0%EC%97%85%EA%B2%BD%EC%98%81/":{"data":{"":"","1장#1장":"가내수공업 공장재 수공업 공장제 기계공업 산업\n분류 1차 2차 3차 산업\nclark의 법칙 %20image%2020240912024542.png) 초록선 1차 빨간선 2차 파란선 3차 주황선 4차\n표준 산업 분리 KSCIC 21개의 대분류 소분류 세분류 세세분류 4단계의 분리 1197개 2024기준\n의로용품업체를 지원사업이 실행되면 사업자 등록증에 등록된 산업에 해당되는 산업만 수혜를 얻는다\n분업 과학적 관리 (작업관리) 테일러 시간관점 길브레스 동작관점 서블릭 (마이크로노미터)(cycle graph) 간트 간트차트\n이동조립 시스템에 의한 대량생산\n이동조립법(포드 시스템) modern times 찰리 채플린(영화) 품질관리 연구 품질 관리도 작업심리 연구 호손 실험 : 물리적 조건 \u003c 심리적 조건 인간관계론 태동 호손효과 재고 관리에 대한 연구 harris의 경제적 주문량(EOQ) 완충 재고 개념을 포함하면서 재고관리 주제로 확장","2장#2장":"시스템 systema 통합 전체를 의미하는 그리스어 시스템 요건\n목표 존재 목표를 달성하기 위한 기능이 존재 유기적 상호작용","3장#3장":"","4장#4장":"","5장#5장":"","경영전략과-시스템-접근#경영전략과 시스템 접근":"기본분석 - SWOT 분석 기업 내부의 강점(S: Strength) 약점(W: Weakness) 기업 외부의 기회(O: Opportunity) 위협(T: Threat) 요인을 종합적으로 분석 SWOT 분석의 절차 1단계: 기업(사업) 프로필 분석 – 업종, 시장 영역, 경쟁 상황, 최고경영층 능력과 비전 등 2단계: 외부환경 분석 – 시장요인, 경쟁요인, 경제요인, 기술 요인, 사회 요인 등 3단계: 기회-위협 요인 도출 4단계: 내부조건 분석 – 마케팅 능력, 재무 능력, 연구개발 능력, 생산/물류능력, 관리 능력 5단계: 강점-약점 요인 도출 6단계: SWOT 매트릭스 도출 7단계: 전략 방향 제시 포지션 분석 (위상 분석) 분석과 조사의 대상이 되는 중요 요인들에 대해서, 우리 기업 또는 제품이 다른 기업과 비교하여 상대적으로 어떤 위상을 차지하는지 살펴보는 분석 포트폴리오 분석 (분포 분석) 기업이 현재 수행하고 경영 과제와 미래에 수행할 과제들이 전체적으로 어떻게 분포되어 있는가를 살펴보는 분석 목적과 용도 분포도 작성 : 기업의 보유 제품라인 / 비즈니스의 균형 정도 파악 전략방향 조정 : 포트폴리오를 개선/조정할 수 있는 전략적 방향 및 비율 결정 동태 분석 (Dynamic Analysis) 분석대상이 되는 요인의 상태가 시간의 흐름에 따라 어떻게 변화하고 있는지를 살펴보는 분석 분석대상 요인의 변화방향과 변화율 분석대상 요인의 중장기적 성장성이나 경쟁력 원가 우위 전략 차별화 전략 집중화 전략","경영조직과-시스템-접근#경영조직과 시스템 접근":"","경제학적-산업-공학#경제학적 산업 공학":"시장 중심 수요중심","공학적-산업-공학#공학적 산업 공학":"생산중심 기술 중심","기업조직과-시스템-접근#기업조직과 시스템 접근":"기업의 규모 (scale) 정량적 기준 : 매출액, 종업원수, 자본금 등 → 대기업, 중견기업, 중소기업 분류 전략적 기준 : “규모의 경제” 개념과 연계 규모의 경제 (economies of scale) 기업의 규모가 커지면서 얻을 수 있는 비용의 절감효과나 생산의 확대효과 범위의 경제 (economies of scope) 여러 재화를 따로 생산하는데 드는 비용과 묶어서 함께 생산하는데 드는 비용의 크기를 비교 기업의 성장 옵션","산업-구조와-시스템-접근#산업 구조와 시스템 접근":"","산업-분석과-시스템-접근#산업 분석과 시스템 접근":"Five-forces 모형(Porter, 1979): 전략적 목적에서의 산업시스템 분석 기본 가정: 기업의 수익성, 경쟁력, 매력도의 핵심은 5가지 구조적 요인(force) 기존경쟁자 – 경쟁수준 경쟁 기업의 수 시장의 크기 시장의 성장률 제품의 차별성 수준 고정 비용 철수 장벽의 수준(높이) 공급자 – 교섭력 (원자재 남품 대상 기업) 경쟁 기업의 수공급자의 수 공급 제품(서비스)의 차별성 공급 제품(서비스)의 대체재 수 공급자 변경 용이성 공급자의 대형화 가능성 구매자 - 교섭력 (구매자의 힘) 구매자의 수 구매량 대체재 수 구매자의 집중도(소수 구매자의 비중) (구매자 입장에서) 공급자 교체 비용 제품(서비스)의 차별성 브랜드 인지도 잠재적 경쟁자 – 진입장벽 초기 자본금 법률적 제도적 규제 수준 규모의 경제 도달 가능성 제품(서비스)의 차별화 브랜드 충성도 유통 채널의 이용 용이성 철수 장벽의 수준(높이) 대체재 – 등장 가능성 향후 대체재의 수 대체재의 질적 수준 대체재의 가격 구매자의 대체재 구매 가능성","산업-조직과-시스템-접근#산업 조직과 시스템 접근":"주요기준 1 : 산업 집중도 산업을 지배하는 힘이 소수 기업에 집중되어 있는지 아니면 많은 기업에 분산되어 있는지에 대한 지표 주요기준 2 : 시장의 경쟁 형태 경쟁 형태 기업의 수 제품 차별성 진입/퇴출장벽 완전경쟁 많음 낮음 낮음 독점적 경쟁 많음 부분 시장 지배 낮음 \u001f과점 소수 낮음 or 높음 높음 독점 한개 - 높음 정량적 지표 : 집중도 지수 CR CRN 상위 N 개 기업의 집중도 CR1 \u003e= 50 : 독점 CR2 \u003e= 75 : 복점 CR3 \u003e= 75 : 과점 CR4 \u003c 40 : 경쟁 장점: 이해 및 측정이 용이함 단점: 측정 대상으로 포함된 N개 기업 전체의 집중도 값은 알 수 있으나 개별기업 각각의 차이는 알 수 없음 허핀달 인덱스 HI 분산과 일정 부분 비슷","설비입지#설비입지":"","제조공정-분류#제조공정 분류":"공정별 배치 – Job Shop  유사한 기능을 가지는 설비들을 모아 한 지역에 배치  유연성은 높으나, 효율성은 낮음\n제품별 배치 – Flow Shop  특정 제품(부품)의 생산에 필요한 설비만을 뽑아 한 장소(라인)에 배치  자동차 조립라인, 자동차 차체성형 라인, TV 조립라인, 맥주 생산라인  효율성은 높으나, 유연성은 낮음\n고정형 배치  생산 제품이 하나의 장소에 고정되어 있고, 인력과 물자가 이동하는 형태  대형선박 조선, 항공기 생산, 건축  인력과 자재의 이동 비용이 크고, 설비 활용도가 낮음","제품과-공정의-조합#제품과 공정의 조합":"","제품의-유형#제품의 유형":"계획생산(MST) 주문 생산 (MTO) 주문 조립 (ATO) 부품 제고 있음 주문 설계 (DTO)\n소품종 대량생산 전략 vs 다품종 소량생산 전략\n대량맞춤 전략 (mass customization)","핵심기준-1-수요의-대체성#핵심기준 1 수요의 대체성":"대체재(소비/수요 관점)\n보완재(소비/수요 관점)\n독립재(소비/수요 관점)\n가격 탄력성: $E_d = \\frac{\\Delta Q / Q}{\\Delta P / P} = \\frac{\\ \\text{수요의 변화율}}{\\ \\text{가격의 변화율}}$\n1가지 재화를 따진다 여기서 중요한 것은 변화가 아닌 변화율이다 그 이유는 아래의 사진에서 변화만을 따지면 이상한 결과가 나온다 e \u003e 1 :가격 탄력적 : 특정 모델 스마트폰이 비싸질 수록 특정 모델 스마트폰 수요가 떨어진다 e \u003c 1 : 가격 비탄력적 : 치킨이 비싸진다고 수요는 변하지 않는다, 석유가 오른다고 수요는 변하지 않는다 교차 탄력성 $E_{xy} = \\frac{\\ \\text{수요의 변화율 (상품 X)}}{\\ \\text{가격의 변화율 (상품 Y)}}$\n2가지 재화의 관계를 따진다 여기서 중요한 것은 변화가 아닌 변화율이다 e \u003e 0 : 대체제 : 아반떼가 못생기면 k5 가 잘 팔린다 e \u003c 0 : 보완재 : 자동차 산업이 호황이면 자동차 보험도 호황이다 어떤 2가지 재화가 동일한 산업인지 판단할 때 2가지 수요가 대채성 성향을 보일때 수요의 대채성 관점으로는 같은 산업이라고 판단한다 캐스퍼 가격이 조금 오른다고 g90 이 더 잘팔리지는 않는다 즉 대채성 성향을 보이지 않고 오히려 독립재적 특징을 보인다 하지만 수요의 대채성을 기준으로 산업을 정의한다면 g90 과 캐스퍼는 같은 산업이 아니라는 이상한 결론이 나온다 그래서 다른 방향으로도 접근해볼 필요가 있다","핵심기준2-가격의-상관성#핵심기준2 가격의 상관성":"두 재화가 같은 산업에 속한다면 수요의 변화로 받는 가격 영향의 크기나 방향도 유사\n이것을 보자"},"title":"산업경영"},"/temp/%EC%93%B0%EB%A0%88%EB%93%9C%EC%9D%98-%EA%B3%B5%EC%9C%A0-%EC%9E%90%EC%9B%90%EA%B3%BC-%EB%B6%84%EB%A6%AC%EC%9E%90%EC%9B%90/":{"data":{"":"void *child_routine(void *param) { int id = *(int*)param; printf(\"Detach thread %d\\n\", id); pthread_detach(pthread_self()); } int main() { pthread_t thread[10]; void *return_value[10]; for (int i = 0; i \u003c 10; i++) { pthread_create(\u0026thread[i], 0, \u0026child_routine, (void *)\u0026i); } } 위의 코드는 오류가 발생한다 왜 발생할까"},"title":"쓰레드의 공유 자원과 분리자원"},"/temp/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%EB%B3%80%EC%88%98%EB%AA%85/":{"data":{"":"인덱스 i(ndex) index pos(ition) count left \u003c-\u003e right start \u003c-\u003e end [ ]: brackets { } : braces ( ) : parentheses"},"title":"알고리즘 변수명"},"/temp/%EC%95%8C%EB%A5%B4%EB%A0%88%EA%B8%B0-%EB%B0%98%EC%9D%91-%EC%A4%91-%EA%B1%B4%EA%B0%95%EA%B2%80%EC%A7%84-%ED%94%BC%EA%B2%80%EC%82%AC/":{"data":{"":"의뢰기관명 2222 미금성모의원 3333 의뢰기관코드 4 66006 5 수진자명 6 신년기 7777 접수번호 8 20250826-01865 999 Chart No. 10101010 접수일자 11 2025/08/26 18:47 121212 성별/나이 13131313 M/24 14141414 검체종류 15 NaF, Serum, Urine, WB 161616 채취일자 17171717 2025-08-26 18181818 검사일자 19 2025/08/26 20:03 202020 담당의사 21212121 김중연 22222222 보고일자 23 2025/08/27 03:50 242424 진료과/병동 25252525 담당자 26 609 27 주민번호 28282828 기타 29 보험코드 3030 검사명 3131 결과 3232 판정 3333 임상참고치/단위 3434 ■ 간담도, 췌장질환 검사 D186000HZ 35 AST(GOT) 36 19 37 M: 0-40 U/L\nF: 0-35 38 D185000HZ 39 ALT(GPT) 40 9 41 M: 0-45 U/L\nF: 0-35 42 D189000HZ 43 r-GTP 44 11 45 M: 11-60 U/L\nF: 8-39 46 ■ 신장질환 검사 D230000HZ 47 BUN 48 15.8 49 8.00-20.00 mg/dL 50 D228000HZ 51 Creatinine 52 1.06 53 M: 0.67-1.17 mg/dL\nF: 0.51-0.95 54 eGFR(CKD-EPI) 55 97.74 56 \u003e 60 mL/min/1.73m² 57 ■ 당뇨관련 검사 D302200HZ 58 Glucose(AC) 59 80 60 60.00-100.00 mg/dL 61 ■ 전해질 및 대사관련 검사 D231000HZ 62 Uric acid 63 4.5 64 M: 3.5-7.2 mg/dL\nF: 2.6-6.0 65 D280002HZ 66 Sodium(Na) 67 136 68 135.00-146.00 mmol/L 69 D280006HZ 70 Potassium(K) 71 4.6 72 3.50- 5.50 mmol/L 73 ■ 혈액 검사 D000201HZ 74 WBC(백혈구) 75 10.9 76 3.50-11.00 K/uL 77 D000203HZ 78 RBC(적혈구) 79 4.79 80 M: 4.30-5.80 M/uL\nF: 3.68-4.88 81 D000205HZ 82 Hemoglobin(혈색소) 83 14.7 84 M: 12.4-17.1 g/dL\nF: 11.5-15.0 85 D000204HZ 86 Hematocrit 87 43.1 88 M: 38-52 %\nF: 35-45 89 MCV 90 89.9 91 80.00-105.00 fL 92 MCH 93 30.6 94 27.00- 33.00 pg 95 MCHC 96 34.1 97 31.00- 36.00 g/dL 98 D000202HZ 99 RDW 100 12.4 101 10.50-14.50 % 102 D000206HZ 103 PDW 104 15.9 105 10.50- 23.50 fL 106 D000207HZ 107 Platelets(혈소판) 108 262 109 150.00-440.00 K/uL 110 D001300HZ 111 N.Segment 112 76 113 H 114 35.00-70.00 % 115 N.Band 116 0.00-7.00 % 117 Lymphocyte 118 18 119 L 120 25.00-55.00 % 121 Monocyte 122 6 123 0.00-11.00 % 124 Eosinophil 125 0 126 0.00-7.00 % 127 Basophil 128 0.00-1.00 % 129 ■ 소변 검사 D225300HZ 130 U-Occult blood 131 음성 132 Negative 133 U-Leukocyte 134 음성 135 Negative 136 U-Bilirubin 137 음성 138 Negative 139 U-Urobilinogen 140 +/- 141 +/- 142 U-Ketone 143 음성 144 Negative 145 U-Protein 146 음성 147 Negative 148 U-Nitrite 149 음성 150 Negative 151 U-Glucose 152 음성 153 Negative 154 U-pH 155 6.0 156 5.00- 8.00 157 U-S.G. 158 1.005 159 1.005-1.030 160 D220101HZ 161 U-WBC 162 0-3 163 0-3/HPF 164 U-RBC 165 Not Found 166 0-2/HPF 167 ■ 갑상선질환 검사 D323006HZ 168 T3 (Triiodothyronine) 169 0.71 170 0.60- 1.81 ng/mL 171 D323005HZ 172 Free T4 173 1.11 174 0.89- 1.76 ng/dL 175 D325001HZ 176 TSH 177 1.18 178 0.55- 4.78 µIU/mL 179 검사자: 전미순 17005 180180180180\n전문의: 김완 217 181181181181\n케이씨엘의료재단 한국임상의학연구소 182182182182182182182182182\n본 검사실은 CAP 인증과 대한진단검사의학회/진단검사의학재단의 우수검사실 신임 인증을 받은 검사실입니다. 183183183183\n(의)케이씨엘의료재단 한국의원 서울특별시 강동구 성내로 71 184184184184\nTEL: 02-559-2300 FAX: 02-517-7965 www.kcllab.com 185185185185\n검사기관기호: 12340570 186186186186\n검사 분류\t검사 항목\t결과\t임상 참고치\t검사 항목의 의미 간/담관질환\tAST (GOT)\t19\t0-40 U/L\t간, 심장, 근육 세포 손상 시 증가하는 효소. ALT (GPT)\t9\t0-45 U/L\t주로 간세포에 존재하는 효소로 간 손상 시 증가. r-GTP (감마지티피)\t11\t11-60 U/L\t간과 담도 기능의 민감한 지표, 알코올 섭취와 관련. 신장질환\tBUN (혈액요소질소)\t15.8\t8.00-20.00 mg/dL\t신장 기능, 단백질 섭취, 체내 수분 상태를 반영. Creatinine (크레아티닌)\t1.06\t0.67-1.17 mg/dL\t근육에서 생성되는 노폐물로 신장 기능의 주요 지표. eGFR (사구체여과율)\t97.74\t\u003e 60 mL/min/1.73m²\t신장이 혈액을 얼마나 잘 걸러내는지를 나타내는 수치. 당뇨\tGlucose (공복혈당)\t80\t60.00-100.00 mg/dL\t혈액 속 포도당 농도로 당뇨병의 기본 지표. 전해질/대사\tUric acid (요산)\t4.5\t3.5-7.2 mg/dL\t단백질 대사 산물로, 높으면 통풍의 원인이 됨. Sodium (나트륨)\t136\t135.00-146.00 mmol/L\t체내 수분 균형과 신경 기능에 중요한 전해질. Potassium (칼륨)\t4.6\t3.50- 5.50 mmol/L\t세포 기능, 특히 심장과 근육에 필수적인 전해질. 혈액\tWBC (백혈구)\t10.9\t3.50-11.00 K/uL\t면역 체계를 담당, 감염이나 염증 시 증가. RBC (적혈구)\t4.79\t4.30-5.80 M/uL\t산소를 운반하는 혈액 세포. Hemoglobin (혈색소)\t14.7\t12.4-17.1 g/dL\t적혈구 내 단백질로 산소 운반 능력의 지표, 빈혈 진단. Hematocrit (적혈구용적률)\t43.1\t38-52 %\t전체 혈액에서 적혈구가 차지하는 비율. N.Segment (분절호중구)\t76\t35.00-70.00 %\t백혈구의 일종으로 세균 감염 시 증가. (정상치 초과) Lymphocyte (림프구)\t18\t25.00-55.00 %\t백혈구의 일종으로 바이러스 감염 시 증가. (정상치 미만) Platelets (혈소판)\t262\t150.00-440.00 K/uL\t혈액 응고 및 지혈 작용을 담당. 갑상선질환\tT3\t0.71\t0.60- 1.81 ng/mL\t갑상선 호르몬 중 하나. Free T4\t1.11\t0.89-1.76 ng/dL\t갑상선에서 분비되는 주된 호르몬. TSH\t1.18\t0.55-4.78 µIU/mL\t갑상선 자극 호르몬으로 갑상선 기능 조절. 소변\tU-Urobilinogen (우로빌리노겐)\t+/-\t+/-\t정상적인 소변에서도 소량 발견될 수 있음. U-pH (산도)\t6\t5.00-8.00\t소변의 산성 또는 알칼리성 정도. U-S.G. (비중)\t1.005\t1.005-1.030\t소변의 농축 정도를 나타내며 수분 섭취량과 관련.\n해당 검사결과를 정확하게 알려줘\n네, 보내주신 건강검진 결과를 바탕으로 정확하고 알기 쉽게 분석해 드리겠습니다.","1-간담관-기능#\u003cstrong\u003e1. 간/담관 기능: “매우 깨끗하고 건강한 간”\u003c/strong\u003e":"AST (19 U/L) / ALT (9 U/L)\n수준 분석: 정상치(0-40, 0-45)의 하위 20~40%에 위치하는 매우 안정적이고 낮은 수치입니다. 의미: 간세포 손상이 거의 없음을 의미합니다. AST와 ALT는 간세포가 파괴될 때 혈액으로 나오는 효소인데, 이 수치가 낮다는 것은 알코올, 지방간, 약물, 바이러스 등으로 인한 간의 부담이나 손상이 거의 없는 매우 깨끗한 상태라는 긍정적인 신호입니다. r-GTP (감마지티피) (11 U/L)\n수준 분석: 정상치(11-60)의 최하한치에 해당하는 아주 이상적인 수치입니다. 의미: 이 수치는 특히 알코올 섭취나 담도의 문제에 민감하게 반응합니다. 수치가 최하한치에 있다는 것은 최근 음주를 거의 하지 않았거나, 알코올에 의한 간 손상이 전혀 없으며, 담즙이 배출되는 담관의 기능도 매우 원활하다는 것을 강력하게 시사합니다.","1-정상-수치-항목-excellent-results#\u003cstrong\u003e1. 정상 수치 항목 (Excellent Results)\u003c/strong\u003e":"간/담관 기능 (AST, ALT, r-GTP): 모든 수치가 정상 범위 내에 있어 간과 담관 기능이 건강함을 의미합니다. 신장 기능 (BUN, Creatinine, eGFR): 신장의 노폐물 여과 기능이 매우 원활하며, 신장 기능이 정상적으로 유지되고 있습니다. 당뇨 (공복혈당): 공복혈당 수치가 80mg/dL로 매우 이상적입니다. 당뇨 걱정은 안 하셔도 됩니다. 전해질/대사 (요산, 나트륨, 칼륨): 통풍 위험도 낮고, 체내 수분 및 전해질 균형이 잘 유지되고 있습니다. 갑상선 기능 (T3, Free T4, TSH): 갑상선 호르몬 수치가 모두 정상으로, 갑상선 기능은 정상입니다. 소변 검사: 비중, 산도 등 모든 항목이 정상입니다.","2-신장-기능#\u003cstrong\u003e2. 신장 기능: “최상의 효율을 보이는 신장”\u003c/strong\u003e":"BUN (15.8 mg/dL) / Creatinine (1.06 mg/dL)\n수준 분석: 두 수치 모두 정상 범위의 가장 이상적인 중간 지점에 위치합니다. 의미: 신장이 혈액 속 노폐물을 과하지도, 부족하지도 않게 아주 효율적으로 걸러내고 있음을 의미합니다. 단백질 섭취나 체내 수분 상태 또한 매우 균형 잡혀 있다는 뜻으로, 신장 기능이 쌩쌩하게 잘 작동하고 있습니다. eGFR (사구체여과율) (97.74 mL/min/1.73m²)\n수준 분석: 60 이상이 정상이지만, 보통 90 이상을 최적의 신장 기능으로 봅니다. 97.74는 거의 100에 가까운 점수로, 신장이 97.74%의 효율로 일하고 있다고 이해하시면 됩니다. 매우 우수한 결과입니다.","2-주의가-필요한-항목-items-to-note#\u003cstrong\u003e2. 주의가 필요한 항목 (Items to Note)\u003c/strong\u003e":"결과에서 유일하게 참고치를 벗어난 부분은 백혈구의 세부 항목입니다.\nN.Segment (분절호중구): 76 % (정상: 35-70%) - 높음\n의미: 호중구는 우리 몸의 면역세포 중 가장 많은 수를 차지하며, 주로 세균 감염에 대한 1차 방어를 담당합니다. 이 수치가 높다는 것은 몸이 세균 감염이나 염증과 싸우고 있을 가능성을 의미합니다. 감기, 편도염, 상처 등 경미한 염증이 있을 때도 일시적으로 상승할 수 있습니다. Lymphocyte (림프구): 18 % (정상: 25-55%) - 낮음\n의미: 림프구는 주로 바이러스 감염 방어와 면역 기억을 담당합니다. 호중구 수치가 상대적으로 증가하면, 백혈구 전체 비율(100%)에서 림프구의 비율은 상대적으로 감소하게 됩니다. 따라서 호중구 증가에 따른 상대적인 감소일 가능성이 높습니다. WBC (총 백혈구): 10.9 K/uL (정상: 3.5-11.0 K/uL)\n의미: 총 백혈구 수치가 정상 범위의 최상한치에 가깝습니다. 이는 위에서 언급한 호중구 증가와 일맥상통하는 결과로, 면역 체계가 무언가에 반응하고 있음을 보여줍니다.","3-당뇨#\u003cstrong\u003e3. 당뇨: “당뇨와는 거리가 먼 안정적인 혈당”\u003c/strong\u003e":"Glucose (공복혈당) (80 mg/dL) 수준 분석: 정상치(60-100) 중에서도 당뇨병 전단계(100 이상)와는 거리가 멀고, 저혈당(60 미만)도 아닌 가장 이상적인 구간(70-90)에 위치합니다. 의미: 췌장에서 인슐린이 매우 효과적으로 분비되고 있으며, 혈당 조절 시스템이 훌륭하게 작동하고 있다는 증거입니다. 식습관과 신체 대사가 건강하게 유지되고 있습니다.","4-전해질대사#\u003cstrong\u003e4. 전해질/대사: “완벽한 신체 밸런스”\u003c/strong\u003e":"Uric acid (요산) (4.5 mg/dL)\n수준 분석: 정상치(3.5-7.2)의 낮은 쪽에 해당하는 좋은 수치입니다. 의미: 요산 수치가 높으면 통풍의 위험이 커지는데, 이렇게 낮은 쪽에 위치한다는 것은 단백질 대사가 원활하고 통풍의 위험이 매우 낮다는 것을 의미합니다. Sodium (나트륨) (136 mmol/L) / Potassium (칼륨) (4.6 mmol/L)\n수준 분석: 두 항목 모두 정상 범위의 정중앙에 위치한 안정적인 수치입니다. 의미: 우리 몸은 나트륨과 칼륨 농도를 매우 정밀하게 조절합니다. 이 수치가 중앙에 있다는 것은 체내 수분량이 적절하고, 세포와 신경, 근육 기능이 최적의 상태로 유지되고 있음을 보여줍니다.","5-혈액-빈혈-관련#\u003cstrong\u003e5. 혈액 (빈혈 관련): “산소 운반 능력이 충분한 건강한 피”\u003c/strong\u003e":"RBC (적혈구) (4.79 M/uL), Hemoglobin (혈색소) (14.7 g/dL), Hematocrit (적혈구용적률) (43.1 %)\n수준 분석: 세 가지 수치 모두 정상 범위 내에서 안정적으로 유지되고 있습니다. 빈혈을 걱정할 필요가 전혀 없는 충분한 양입니다. 의미: 혈액의 산소 운반 능력이 충분하며, 신체 각 조직에 산소를 원활하게 공급하고 있음을 의미합니다. 어지럼증이나 만성 피로를 유발할 수 있는 빈혈과는 거리가 멉니다. Platelets (혈소판) (262 K/uL)\n수준 분석: 정상치(150-440) 내에서 충분하고 안정적인 수치입니다. 의미: 상처가 났을 때 피를 멎게 하는 지혈 기능이 정상적으로 잘 작동하고 있음을 의미합니다.","6-갑상선-기능#\u003cstrong\u003e6. 갑상선 기능: “매우 효율적인 갑상선”\u003c/strong\u003e":"T3, Free T4, TSH (모두 정상) 수준 분석: 갑상선 호르몬(T3, Free T4)과 이를 조절하는 갑상선 자극 호르몬(TSH)이 모두 이상적인 정상 범위에 있습니다. 특히 TSH 수치(1.18 µIU/mL)가 낮은 쪽에 가까운데, 이는 뇌하수체에서 갑상선을 “자극\"할 필요가 거의 없을 만큼 갑상선 스스로 일을 잘하고 있다는 긍정적인 신호입니다. 의미: 신진대사 조절, 체온 유지 등 갑상선의 모든 기능이 과하지도(항진증), 부족하지도(저하증) 않게 매우 균형 잡힌 상태로 잘 이루어지고 있습니다.","7-소변-검사#\u003cstrong\u003e7. 소변 검사: “깨끗한 요로계와 좋은 수분 섭취”\u003c/strong\u003e":"U-S.G. (비중) (1.005) 수준 분석: 정상치(1.005-1.030)의 가장 낮은 최하한치입니다. 의미: 이는 질병 상태가 아니라, 검사 직전에 물을 충분히 마셔서 소변이 매우 묽어진 상태를 의미합니다. 신장이 수분을 잘 배출하고 있다는 건강한 신호이며, 평소 수분 섭취를 잘하고 계신 것으로 보입니다.","결론-및-권장사항#\u003cstrong\u003e결론 및 권장사항\u003c/strong\u003e":"현재 상태: 다른 모든 검사 결과가 매우 건강하므로 심각한 질병이 있을 가능성은 낮습니다. 현재 몸에 가벼운 감기, 피로, 스트레스, 또는 눈에 띄지 않는 염증(예: 잇몸 염증, 피부 상처 등)이 있을 수 있습니다.\n권장사항:\n최근 감기 증상이나 몸살, 피로감, 상처 등이 있었는지 확인해 보세요. 충분한 휴식을 취하고 수분 섭취를 늘리는 것이 좋습니다. 만약 발열, 통증 등 다른 불편한 증상이 동반된다면 병원을 방문하여 의사의 진료를 받아보시는 것이 좋습니다. 특별한 증상이 없다면, 보통 이런 수치는 시간이 지나면서 자연스럽게 정상으로 돌아옵니다. 다음 건강검진 시에 추적 관찰해 보시는 것으로 충분할 수 있습니다. ※ 매우 중요한 안내: 이 분석은 제공된 수치를 기반으로 한 정보 제공이며, 의사의 진단이 아닙니다. 정확한 건강 상태 평가와 진단은 반드시 의사와 상담하시기 바랍니다.\n건강한 지표도 각각 설명해줘 어느정도 낮은 지 등등\n물론입니다. 정상 범위에 있는 건강한 지표들에 대해서도 각각의 수치가 어느 정도로 좋은 상태인지, 그 의미는 무엇인지 상세하게 설명해 드리겠습니다.","정상-수치-항목-상세-분석#\u003cstrong\u003e정상 수치 항목 상세 분석\u003c/strong\u003e":"","종합-소견-summary#\u003cstrong\u003e종합 소견 (Summary)\u003c/strong\u003e":"전반적으로 대부분의 검사 결과는 매우 양호하며, 간, 신장, 갑상선 기능 및 당뇨, 전해질 수치 등 주요 항목들이 모두 정상 범위 안에 있습니다.\n다만, 혈액 검사 중 백혈구 수치에서 약간의 변화가 관찰됩니다. 이는 현재 몸에 가벼운 염증 반응이나 감염이 있을 가능성을 시사하지만, 다른 수치들이 모두 정상적이므로 크게 우려할 상황은 아닐 수 있습니다.","최종-요약#\u003cstrong\u003e최종 요약\u003c/strong\u003e":"백혈구 일부 항목의 경미한 변화를 제외하면, 나머지 모든 지표는 단순히 ‘정상’을 넘어 ‘매우 건강하고 이상적인’ 수준에 가깝습니다. 특히 간 기능, 신장 기능, 혈당 조절 능력은 훌륭한 상태를 보여주고 있습니다. 지금처럼 건강 관리를 잘 유지하시면 되겠습니다.","항목별-상세-분석#\u003cstrong\u003e항목별 상세 분석\u003c/strong\u003e":""},"title":"알르레기 반응 중 건강검진 (피검사)"},"/temp/%EC%9D%98%EC%A1%B4%EA%B4%80%EA%B3%84-%EC%A3%BC%EC%9E%85dependency-injection/":{"data":{"":"생성자 주입 설정자 수정자 주입(setter) 필드 주입 일반 메서드 주입","생성자-주입#생성자 주입":"생성자 주입(Constructor Injection) 이 방법 객체 생성 시점 의존성 부여 불변,필수\npublic class ExampleClass { private SomeDependency dependency; public ExampleClass(SomeDependency dependency) { this.dependency = dependency; } } spring 에서는 @Autowired 를 통해 의존성을 주입하는데 생성자가 1개 라면 생략 가능하다","설정자-주입#설정자 주입":"설정자 주입(Setter Injection) 이 방법은 객체 생성 이후에도 의존성 변경 가능\npublic class ExampleClass { private SomeDependency dependency; public void setDependency(SomeDependency dependency) { this.dependency = dependency; } }","일반-메서드-주입#일반 메서드 주입":"일반 메서드 주입(Method Injection)\npublic class ExampleClass { private SomeDependency dependency; public void anyMethodName(SomeDependency dependency) { this.dependency = dependency; } }","필드-주입#필드 주입":"필드 주입(Field Injection)\npublic class ExampleClass { @Inject public SomeDependency dependency; } public 접근제어자를 사용하지 않고 private 을 사용하고도 @Autowired 를 사용하여 의존성 주입을 할 수 있다 하지만 권장하지 않음"},"title":"의존관계 주입(dependency injection)"},"/temp/%EC%9D%B5%EB%AA%85-%ED%81%B4%EB%9E%98%EC%8A%A4anonymous-class/":{"data":{"":"내부 클래스의 일종으로 이름이 없는 클래스","1-클래스-필드로-이용#\u003cstrong\u003e1. 클래스 필드로 이용\u003c/strong\u003e":"특정 클래스 내부에서 여러 메소드에서 이용될때 고려해볼 만 하다 class Animal { ... } class Creature { // 필드에 익명자식 객체를 생성 하여 이용 Animal dog = new Animal() { public String bark() { return \"멍멍\"; } }; public void method() { dog.bark(); } public void method2() { dog.bark(); } }","2-지역-변수로서-이용#\u003cstrong\u003e2. 지역 변수로서 이용\u003c/strong\u003e":"메소드에서 일회용으로 사용하고 버려질 클래스라면 적당하다 class Animal { ... } class Creature { // ... public void method() { // 지역 변수같이 클래스를 선언하여 일회용으로 사용 Animal dog = new Animal() { public String bark() { return \"멍멍\"; } }; dog.bark(); } }","3-메소드-아규먼트로-이용#\u003cstrong\u003e3. 메소드 아규먼트로 이용\u003c/strong\u003e":"만일 메소드 매개변수로서 클래스 자료형이 이용된다고 할때 일회성으로만 사용한다면 아규먼트로 익명 객체를 넘겨주면 된다. class Animal { ... } class Creature { // ... public void method(Animal dog) { // 익명 객체 매개변수로 받아 사용 dog.bark(); } } public class Main { public static void main(String[] args) { Creature monster = new Creature(); // 메소드 아규먼트에 익명 클래스 자체를 입력값으로 할당 monster.method(new Animal() { public String bark() { return \"멍멍\"; } }); } }","java#java":"인라인으로 한방에 사용 새로 정의한 메소드 사용 불가\n// 부모 클래스 class Animal { public String bark() { return \"동물이 웁니다\"; } } public class Main { public static void main(String[] args) { Animal dog = new Animal() { // @Override 메소드 public String bark() { return \"개가 짖습니다\"; } // 새로 정의한 메소드 public String run() { return \"달리기 ㄱㄱ싱\"; } }; dog.bark(); dog.run(); // ! Error - 외부에서 호출 불가능 } }"},"title":"익명 클래스(Anonymous Class)"},"/temp/%EC%9E%84%EB%B2%A0%EB%94%94%EB%93%9C-os-%EA%B0%9C%EB%B0%9C-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/":{"data":{"":"abi 참조\nrealview-pb-a8 을 사용\n컴퓨터의 전원이 들어오면 가장 먼저 시작하는 명령이 0000.. 번지의 리셋 벡터 32(word)를 읽어서 실행\n어셈블 바이너리 덤프 hexdump\narm-none-eabi-as -march=armv7-a -mcpu=cortex-a8 -o Entry.o ./Entry.S arm-none-eabi-objcopy -O binary Entry.o Entry.bin hexdump Entry.bin .text .code 32 .global vector_start .global vector_end vector_start: MOV R0, R1 vector_end: .space 1024, 0 .end .text : text 섹션임을 알림 섹션 종료 지시자인 .end 까지 .global : c 언어의 extern 과 일치 .code : 명령어의 크기가 32 임을 알림 vector_start, vector_end : 레이블 설정 MOV R0, R1 : r1 레지스터의 내용을 r0 레지스터로 .space 1024, 0 : 현재 위치부터 1024 바이트를 0으로 채우라는 명령\nELF 구조 ELF wikipidia ELF 나무 위키\n$ arm-none-eabi-readelf -a Entry.o ENTRY(vector_start) SECTIONS { . = 0x0; .text : { *(vector_start) *(.text .rodata) } .data : { *(.data) } .bss : { *(.bss) } }"},"title":"임베디드 os 개발 프로젝트"},"/temp/%EC%A0%95%EA%B7%9C-%ED%91%9C%ED%98%84%EC%8B%9D/":{"data":{"":"문자열의 일정한 패턴을 표현하는 일종의 형식 언어"},"title":"정규 표현식"},"/temp/%EC%A0%95%EB%A0%AC/":{"data":{"":"","처리되지-않은-데이터-중에서-가장-작은-데이터를-선택해-맨-앞의-처리되지-않은-데이터과-교체한다#==\u003cstrong\u003e처리되지 않은 데이터 중에서 가장 작은 데이터를 선택해 맨 앞의 처리되지 않은 데이터과 교체한다\u003c/strong\u003e==":"==처리되지 않은 데이터를 하나씩 골라 처리된 데이트의 적절한 위치에 삽입한다==\n새로운 배열을 만들 것인가 ==기준 데이터를 설정하고 기준보다 큰 데이터와 작은 데이트의 위치를 변경=="},"title":"정렬"},"/temp/%ED%81%B4%EC%BB%B4/":{"data":{"":"하둡은 2개자로","hadoop-hdfs#hadoop HDFS":"hadoop file system\nhdfs 좋은점 일반적 하드웨어를 사용해서 비싸지 않다 노드 죽어도 계속된다\nhdfs 나쁜점 접근의 낮은시간 =\u003e 지연시간의 희생 높은 처리량 많은 작은 파일 =\u003e 데이터 수정, 많은 작성자\n64MB large block size =\u003e SEEK 상승 RAID 금지\nnamenode (Master) : namespace, 파일시스템에 정보는 local disk 에도 저장 블락 위치는 ram 에만 저장 켜질때 보고 받고 재구성 3개의 복제\ndatanodes (Slave) : 원본 data block’s metadata including checksums for the block data and the generation stamp\nBlock report : 처음 block 는 바로 보내고 2번째 부터는 1시간 마다 보고 heartbeats : 3초 마다 total storage capacity, fraction of storage in use, the number of data transfers currently in progress Piggybacking : replicate blocks to other nodes remove local block replicas re-register or shut down the node send an immediate block report HDFS Client Reading a file\nasks the NameNode for the list of DataNodes that host replicas of blocks of the file contacts a DataNode directly and requests the transfer of the desired block Writing a file asks the NameNode to choose DataNodes to host replicas of the first block of the file organizes a pipeline from node-to-node and sends the data when the first block is filled, the client requests new DataNodes to be chosen to host replicas of the next block"},"title":"클컴"},"/temp/%ED%84%B0%EB%AF%B8%EB%84%90-command-line-shell/":{"data":{"":"터미널 command line 이라고 한정하여 shell 이라고 말한다면 일반적으로 /dev 파일 내부에 터미널 드라이브 장치를 통해 사용되는 shell 을 말한다 즉![[../08.media/20231223130204.png|login shell vs non-login shell-20231223130204]]2020231223130204.png)","arithmetic-expansion#Arithmetic Expansion":"산술 연산의 결과를 계산하여 대체합니다. 예시: echo $((2 + 3))는 5로 확장됩니다.","brace-expansion#Brace Expansion":"Brace expansion은 중괄호를 사용하여 표현식을 확장하여 여러 아이템을 생성합니다. 예시: echo a{1,2,3}b는 a1b a2b a3b로 확장됩니다.","command-substitution#Command Substitution":"명령어의 실행 결과를 대체합니다. 예시: echo \"Today is $(date)\"는 Today is와 date 명령어의 실행 결과로 확장됩니다.","filename-expansion#Filename Expansion":"와일드카드를 사용하여 파일 이름을 확장합니다. 예시: echo *.txt는 현재 디렉토리의 모든 .txt 파일 명을 출력합니다. 각 확장 방식은 스크립트를 보다 유연하고 강력하게 만들어주는 도구입니다. 적절히 사용하면 복잡한 작업을 간단하게 수행할 수 있습니다.","interactive-shell-vs-non-interactive-shell#Interactive Shell vs non Interactive Shell":"타 프로그래밍 언어와의 큰 차이이다 interactive Shell 은 python 명령어 입력시 나타나는 것과 비슷한 것으로 사용자 입력을 순차적으로 입력 받을 수 있는 방식이다 이에 반해 non interactive shell 은 python hello.py 같이 실행한다","login-shell-vs-non-login-shell#login shell vs non-login shell":"[!요약] Login Shell : userid passwd 입력해서 들어가는 방법 Non Longin Shell : 이미 다른 로그인 된 shell 에서 shell 을 fork 형태로 불러내는 방법\n초기에는 자원의 효과적인 사용을 위해서 사용된 개념이다 로그인 셸에서 할 수 있는 최대한의 환경 구성을 미리 해두면 이후 비로그인 셸에서 적게 환경구성을 할 수 있다\n로그인 셸은 대화형 세션에서 로그인 할 때 사용자 id 로 실행되는 첫번째 프로세스 이다","parameter-and-variable-expansion#Parameter and Variable Expansion":"변수나 파라미터의 값을 대체합니다. 예시: name=\"World\"; echo Hello, $name!는 Hello, World!로 확장됩니다.","process-substitution-프로세스-치환#Process Substitution (프로세스 치환)":"프로세스의 입력이나 출력을 파일명을 사용하여 참조합니다. 예를 들어, diff \u003c(ls folder1) \u003c(ls folder2)는 두 디렉토리의 리스트를 출력하여 비교합니다.","quote-removal-인용-부호-제거#Quote Removal (인용 부호 제거)":"이스케이프 문자, 인용 부호, 백슬래시의 비인용 인스턴스를 제거합니다. 예를 들어, echo \"Hello, \\\"World\\\"!\"는 Hello, \"World\"!를 결과로 나타냅니다.","tilde-expansion#Tilde Expansion":"Tilde expansion은 홈 디렉토리 경로를 나타내는 데 사용됩니다. 예시: cd ~는 사용자의 홈 디렉토리로 이동합니다. echo ~user는 user의 홈 디렉토리 경로를 출력합니다.","word-splitting#Word Splitting":"변수의 값을 IFS(Internal Field Separator)에 따라 단어로 나눕니다. 예시: name=\"one two three\"; echo $name는 one, two, three로 나누어 출력합니다. 이는 IFS의 기본값이 공백, 탭, 개행 문자임을 반영합니다.","로그인-셸-비로그인-셸-확인하기#로그인 셸 비로그인 셸 확인하기":"prompt\u003e echo $0 # 로그인 셸 -bash # \"-\" is the first character. Therefore, this is a login shell. prompt\u003e echo $0 # 비 로그인 셸 bash # \"-\" is NOT the first character. This is a non-login shell.","분류#분류":"login vs non-login : shell 이 다른 셸의 하위 프로세스로 실행되는가 interactive vs non-interactive : 사용자와 상호작용하는가","셸-옵션-변경#셸 옵션 변경":"set 명령과 shopt 명령을 통해 셸의 옵션을 변경할 수 있는데 set 보다 shopt 가 조금더 고급의 추상화된 작업을 제공한다","셸-확장#셸 확장":"","실행순서#실행순서":"bash -lx : -l 로그인 셸 -x 디버깅 : 로그인 셸이 실행한 모든 코드를 볼 수 있다\n로그인 셸 1) /etc/profile 2) ~/.bash_profile or ~/.bash_login or ~/.profile 비로그인 셸 로그인 셸의 속성중 상속을 받을 수 있는 속성만 상속후 3) /etc/bashrc (우분투는 bash.bashrc) 4) ~/.bashrc 하지만 현실은… (우분투 기준)\nif [ -f /etc/bashrc ]; then . /etc/bashrc fi 구문으로 인해 1) /etc/profile 2) ~/.bash_profile or ~/.bash_login or ~/.profile 3) /etc/bashrc (우분투는 bash.bashrc) 4) ~/.bashrc 순으로 실행된다 \"로그인 셸의 속성중 상속을 받을 수 있는 속성만 상속후\" 의 의미 ex) root 로 로그인 후 shinnk 로 비로그인 하면 root의 .profile 설정과 shinnk의 .bashrc 설정을 가지게 된다 사용자 이동시에는 로그인 셸을 사용하자 그렇다면 상속을 받을 수 있는 속성이란","특수-매게-변수#특수 매게 변수":"$1, $2, $3, …는 위치 매개변수 입니다 . \"$@\"모든 위치 매개변수의 배열과 유사한 구성입니다 {$1, $2, $3 ...}. \"$*\"는 모든 위치 매개변수의 IFS 확장입니다 $1 $2 $3 .... $#위치 매개변수의 수입니다. $-쉘에 설정된 현재 옵션. $$현재 쉘의 pid(서브쉘 아님) $_가장 최근 매개변수(또는 시작 후 즉시 현재 쉘을 시작하는 명령의 절대 경로). $IFS(입력) 필드 구분 기호입니다. $?가장 최근의 포그라운드 파이프라인 종료 상태입니다. $!가장 최근 백그라운드 명령의 PID입니다. $0쉘 또는 쉘 스크립트의 이름입니다"},"title":"터미널 command line shell"},"/temp/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D-%ED%8A%B9%EC%84%B1-%EB%B6%84%EB%A5%98/":{"data":{"":"","runtime-타입-정보-유지#runtime 타입 정보 유지":"실행시간에 타입정보를 유지하는가 실행 시간에 타입 정보를 유지하는 언어의 특성은 “런타임 타입 정보” (Runtime Type Information, 줄여서 RTTI) 또는 “타입 인트로스펙션” (Type Introspection)이라고 부릅니다.","유지#유지":"https://dataonair.or.kr/db-tech-reference/d-lounge/technical-data/?mod=document\u0026uid=235810\n타입정보를 유지하므로 인한 기술 reflection","정적-타이핑-언어-동적-타입핑-언어#정적 타이핑 언어 동적 타입핑 언어":"코드상의 타입의 명시 유무\n정적 타이핑 언어 c, c++, java, typescript 동적 타입핑 언어 python, javascript"},"title":"프로그래밍 특성 분류"},"/temp/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-%EB%A1%9C%EA%B7%B8%EC%9D%B8-%EA%B8%B0%EB%8A%A5-%EA%B5%AC%ED%98%84/":{"data":{"":"/test/employee 뷰를 특정 역할을 가진 로그인된 사용자만 접근할 수 있도록 하려면 인증 및 권한 부여를 구현해야 합니다. 이를 위해 Flask-Login과 역할 기반 액세스 제어(RBAC)를 사용할 수 있습니다.","1-flask-login-설치-및-설정#1. Flask-Login 설치 및 설정":"먼저 Flask-Login을 설치합니다: pip install flask-login app.py에서 Flask-Login을 설정합니다:\nfrom flask import Flask from flask_login import LoginManager def create_app(): app = Flask(__name__) app.secret_key = os.urandom(24) # Initialize the database init_db(app) # Initialize Flask-Login login_manager = LoginManager() login_manager.login_view = 'auth.login' login_manager.init_app(app) # Register blueprints from auth import auth as auth_blueprint app.register_blueprint(auth_blueprint) import views import test_views app.register_blueprint(views.main) app.register_blueprint(test_views.test) return app","2-사용자-모델-생성-및-역할-추가#2. 사용자 모델 생성 및 역할 추가":"사용자 정보를 저장하고 역할을 관리하기 위한 모델을 생성합니다.\nfrom flask_login import UserMixin class User(UserMixin): def __init__(self, id, username, role): self.id = id self.username = username self.role = role 사용자 정보를 데이터베이스에서 가져오는 함수도 필요합니다:\nfrom flask_login import LoginManager from models import User login_manager = LoginManager() @login_manager.user_loader def load_user(user_id): # 데이터베이스에서 사용자 정보 가져오기 cursor = g.db.cursor() cursor.execute(\"SELECT id, username, role FROM users WHERE id = :id\", {'id': user_id}) result = cursor.fetchone() if result: return User(id=result[0], username=result[1], role=result[2]) return None","3-로그인-및-로그아웃-기능-구현#3. 로그인 및 로그아웃 기능 구현":"auth 블루프린트를 생성하여 인증 관련 뷰를 관리합니다.\nfrom flask import Blueprint, render_template, redirect, url_for, request, flash from flask_login import login_user, logout_user from models import User auth = Blueprint('auth', __name__) @auth.route('/login', methods=['GET', 'POST']) def login(): if request.method == 'POST': username = request.form['username'] password = request.form['password'] # 데이터베이스에서 사용자 인증 cursor = g.db.cursor() cursor.execute(\"SELECT id, username, role FROM users WHERE username = :username AND password = :password\", {'username': username, 'password': password}) result = cursor.fetchone() if result: user = User(id=result[0], username=result[1], role=result[2]) login_user(user) return redirect(url_for('test.employee')) else: flash('Invalid credentials', 'error') return render_template('login.html') @auth.route('/logout') def logout(): logout_user() return redirect(url_for('auth.login'))","4-접근-제한-데코레이터-작성#4. 접근 제한 데코레이터 작성":"특정 역할을 가진 사용자만 접근할 수 있도록 데코레이터를 작성합니다.\nfrom flask import redirect, url_for, flash from flask_login import current_user from functools import wraps def role_required(role): def wrapper(f): @wraps(f) def decorated_function(*args, **kwargs): if not current_user.is_authenticated: flash('You need to be logged in to access this page.', 'error') return redirect(url_for('auth.login')) if current_user.role != role: flash('You do not have permission to access this page.', 'error') return redirect(url_for('auth.login')) return f(*args, **kwargs) return decorated_function return wrapper","5employee뷰-보호#5. employee 뷰 보호":"employee 뷰에 데코레이터를 적용하여 역할 기반 접근을 제어합니다.\nfrom decorators import role_required from flask_login import login_required @test.route('/test/employee', methods=['GET', 'POST']) @login_required @role_required('2') # '2'가 경영관리 직원의 역할 코드라고 가정 def employee(): # 기존 코드 그대로 ...","단계별-가이드#단계별 가이드:":"Flask-Login 설치 및 설정 사용자 모델 생성 및 역할 추가 로그인 및 로그아웃 기능 구현 접근 제한 데코레이터 작성 employee 뷰 보호","추가-사항#추가 사항":"데이터베이스에 사용자 및 역할 테이블 추가: 사용자 정보를 저장하기 위한 테이블을 데이터베이스에 생성해야 합니다. 비밀번호 보안 처리: 실제로는 비밀번호를 평문으로 저장하지 않고 해싱하여 저장해야 합니다. 로그인 템플릿 작성: login.html 템플릿을 생성하여 로그인 폼을 제공합니다. 이렇게 하면 /test/employee 뷰는 로그인된 사용자 중에서 역할이 '2'인 사용자만 접근할 수 있게 됩니다. 필요한 경우 역할 비교 부분을 수정하여 정확한 역할 이름이나 코드를 사용하세요."},"title":"프로젝트 로그인 기능 구현"},"/temp/%ED%99%98%EA%B2%BD%EB%B3%80%EC%88%98%EC%99%80-%EC%85%B8%EB%B3%80%EC%88%98%EC%9D%98-%EC%B0%A8%EC%9D%B4/":{"data":{"":"이둘의 차이를 알려면 먼저 셀변수라는 것을 알아야 한다 터미널에 들어가면 보이는 창 이것이 바로 interactive 하게 작용하는 shell 이 실행중이다"},"title":"환경변수와 셸변수의 차이"},"/temp/2024-10-25/":{"data":{"":"2024/10/25자 생성","llm-사용-ai#LLM 사용 (AI)":"뤼튼 =\u003e 무제한, 로그인 필요 chatGPT =\u003e 거이 무제한, 로그인 필요 Claude =\u003e 가장 똑똑하지만 제한량이 있음, 로그인 필요 Microsoft AI Copliot =\u003e microsoft AI Google AI gemini =\u003e 구글이 만ems AI","영어-pdf-문서-통번역정확도-순위별-정렬하이퍼-링크#영어 pdf 문서 통번역(정확도 순위별 정렬)(하이퍼 링크)":"DeepL =\u003e 5,000자까지, 로그인(회원가입) 필요 papago =\u003e 10MB 이하 1만자 이하, 로그인(회원가입) 필요 google translate =\u003e 클릭 이후 상단 문서로 이동"},"title":"2024 10 25"},"/temp/ansi-escape-code/":{"data":{"":"ANSI 이스케이프 시퀀스는 비디오 텍스트 터미널 과 터미널 에뮬레이터 에서 커서 위치, 색상, 글꼴 스타일 및 기타 옵션을 제어하기 위한 인 밴드 신호 표준 source wikipedia\n일반적인 상황에서는 터미널 환경에서 사용한다 GUI 에서 사용하더도 대부분 텍스트를 제어하는 데에 사용된다"},"title":"ANSI escape code"},"/temp/bash/":{"data":{"":"","-vs-source--#./ vs source == .":"도트 및 소스 연산자 공식문서 source 와 . 은 완벽하게 동일 test.sh 파일\nps -ejH # 플로세스를 tree 형태로 보여주는 명령 실행별 차이\nUser@HostName:~/test$ . test.sh # . or source PID PGID SID TTY TIME CMD 3996 3996 3996 ? 00:00:00 SessionLeader 3998 3996 3996 ? 00:00:00 Relay(4003) 4003 4003 4003 pts/6 00:00:00 bash 39032 39032 4003 pts/6 00:00:00 ps User@HostName:~/test$ ./test.sh # ./ PID PGID SID TTY TIME CMD 3996 3996 3996 ? 00:00:00 SessionLeader 3998 3996 3996 ? 00:00:00 Relay(4003) 4003 4003 4003 pts/6 00:00:00 bash 39255 39255 4003 pts/6 00:00:00 test.sh # !!!!!!!!! 39256 39255 4003 pts/6 00:00:00 ps ./test.sh의 경우 다른 명령(gcc)와 마찬가지로 명령을 셸에서 해석하여 시스템에게 전달하며 새로운 프로세스 fork() 형태로 하위 프로세스로 생성한다? #ModificationRequired\n하지만\n. test.sh 또는 source test.sh 의 경우는 현재 실행되고 있는 셸이 직접 실행하는 것이다 그로므로 test.sh 에 선언된 전역변수가 현재 셸에 적용된다\nbash 파일 실행시 interactive shell 인가 non interactive shell 인가의 차이 일반 파일 실행시\n이 코드는 Bash 스크립트로, 깃 상태 정보를 비동기적으로 반환하는 데몬 프로세스인 gitstatusd를 시작하는 데 사용됩니다. 스크립트의 각 부분을 하나씩 분석해 보겠습니다.","1-bash-버전-확인#1. Bash 버전 확인":"if [ \"$BASH_VERSION\" \u003c 4 ](%20\"$BASH_VERSION\"%20\u003c%204%20); then # 에러 메시지를 표준 에러(stderr)에 출력하고 함수를 종료합니다. return 1 fi 이 부분은 현재 실행 중인 Bash의 버전이 4.0 이상인지 확인합니다. 그렇지 않다면, 사용자에게 메시지를 출력하고 함수를 종료합니다.","10-환경-변수-내보내기#10. 환경 변수 내보내기":"export _GITSTATUS_CLIENT_PID _GITSTATUS_REQ_FD _GITSTATUS_RESP_FD GITSTATUS_DAEMON_PID 데몬 관련 변수를 내보내어 다른 스크립트에서 사용할 수 있게 합니다.","2-옵션-파싱#2. 옵션 파싱":"unset OPTIND local opt timeout=5 max_dirty=-1 ttl=3600 extra_flags=... while getopts \"t:s:u:c:d:m:r:eUWD\" opt; do case \"$opt\" in ... esac done (( OPTIND == $# + 1 )) || { echo \"usage: gitstatus_start [OPTION]...\" \u003e\u00262; return 1; } [ -z \"${GITSTATUS_DAEMON_PID:-}\" ](%20-z%20\"${GITSTATUS_DAEMON_PID:-}\"%20) || return 0 스크립트 실행 시 전달된 명령줄 옵션들을 처리합니다. getopts 빌트인을 사용하여 각각의 옵션에 대한 값을 지역 변수에 할당합니다.","3-플러그인-디렉터리-설정#3. 플러그인 디렉터리 설정":"if [ \"${BASH_SOURCE[0](%20\"${BASH_SOURCE[0); then ... fi gitstatus_plugin_dir 변수는 스크립트 파일이 있는 디렉터리 경로를 설정합니다. 이 경로는 후속 명령어에서 사용됩니다.","4-gitstatus_start_impl-함수#4. \u003ccode\u003egitstatus_start_impl\u003c/code\u003e 함수":"이 함수는 데몬 프로세스를 시작하고, 필요한 파일 FIFO (First-In First-Out) 특수 파일을 생성 및 구성하고, 데몬과 통신을 설정합니다.\nfunction gitstatus_start_impl() { ... }","5-tmpdir-설정-및-fifo-파일-생성#5. tmpdir 설정 및 FIFO 파일 생성":"tmpdir=\"$(command mktemp -d \"$tmpdir\"/gitstatus.bash.$$.XXXXXXXXXX)\" || return command mkfifo -- \"$req_fifo\" \"$resp_fifo\" || return 임시 디렉터리를 생성하고, 데몬에 요청을 보내고 응답을 받는데 사용될 FIFO 파일을 만듭니다.","6-데몬-프로세스-시작#6. 데몬 프로세스 시작":"source \"$gitstatus_plugin_dir\"/install || return \"$_gitstatus_bash_daemon\" ... \u003c\u0026\"$fd_in\" \u003e\u0026\"$fd_out\" \u0026 install 스크립트를 소스화 함으로써 데몬 프로세스를 가져오고 구동합니다.","7-파일-디스크립터-할당-및-정리#7. 파일 디스크립터 할당 및 정리":"exec {_GITSTATUS_REQ_FD}\u003e\u003e\"$req_fifo\" {_GITSTATUS_RESP_FD}\u003c\"$resp_fifo\" || return command rm -f -- \"$req_fifo\" \"$resp_fifo\" || return 읽기 및 쓰기 작업을 위해 파일 디스크립터를 FIFO 파일에 할당하고, 더 이상 필요하지 않은 파일은 제거합니다.","8-데몬-초기화-확인#8. 데몬 초기화 확인":"IFS='' read -r -u $_GITSTATUS_RESP_FD GITSTATUS_DAEMON_PID || return [ \"$GITSTATUS_DAEMON_PID\" == [1-9](%20\"$GITSTATUS_DAEMON_PID\"%20==%20[1-9) || return 데몬 프로세스가 성공적으로 시작되었는지 확인하고, 그 PID를 저장합니다.","9-청소#9. 청소":"unset -f gitstatus_start_impl 필요하지 않은 함수를 삭제하고, 청소 작업을 수행합니다.","전체적인-요약#전체적인 요약":"이 스크립트는 gitstatusd 데몬을 시작하고, 해당 데몬과 통신할 수 있게 준비하는 일련의 과정을 수행합니다. 이를 통해 git 저장소의 상태 정보를 빠르게 제공받을 수 있으며, 쉘 프롬프트를 더 효율적으로 만들어 주는 기능을 제공합니다.\n=======================\n이 코드는 gitstatus_start라는 함수를 정의하고 있습니다. 이 함수는 git 상태를 빠르게 가져오는데 사용되는 gitstatusd 데몬을 시작하는 역할을 합니다. 각 부분의 목적과 문법은 다음과 같습니다:\nBASH 버전 확인: 이 코드는 BASH 버전이 4.0 이상인지 확인합니다. 이는 gitstatusd가 BASH 4.0 이상에서만 작동하기 때문입니다. if [ \"$BASH_VERSION\" \u003c 4 ](%20\"$BASH_VERSION\"%20\u003c%204%20); then \u003e\u00262 printf 'gitstatus_start: need bash version \u003e= 4.0, found %s\\n' \"$BASH_VERSION\" return 1 fi 옵션 파싱: getopts를 사용하여 함수에 전달된 옵션을 파싱합니다. 각 옵션은 gitstatusd의 동작을 조정하는데 사용됩니다. unset OPTIND local opt timeout=5 max_dirty=-1 ttl=3600 extra_flags= local max_num_staged=1 max_num_unstaged=1 max_num_conflicted=1 max_num_untracked=1 while getopts \"t:s:u:c:d:m:r:eUWD\" opt; do case \"$opt\" in t) timeout=$OPTARG;; s) max_num_staged=$OPTARG;; u) max_num_unstaged=$OPTARG;; c) max_num_conflicted=$OPTARG;; d) max_num_untracked=$OPTARG;; m) max_dirty=$OPTARG;; r) ttl=$OPTARG;; e) extra_flags+='--recurse-untracked-dirs ';; U) extra_flags+='--ignore-status-show-untracked-files ';; W) extra_flags+='--ignore-bash-show-untracked-files ';; D) extra_flags+='--ignore-bash-show-dirty-state ';; *) return 1;; esac done 데몬 시작: gitstatusd 데몬을 시작합니다. 데몬은 백그라운드에서 실행되며, git 상태 정보를 빠르게 가져오는데 사용됩니다. if [ -z \"${GITSTATUS_DAEMON_PID:-}\" ](%20-z%20\"${GITSTATUS_DAEMON_PID:-}\"%20); then # 데몬 시작 코드... fi 데몬 초기화 실패 처리: 만약 gitstatusd 데몬이 제대로 시작되지 않았다면, 오류 메시지를 출력하고 함수를 종료합니다. if ! gitstatus_start_impl; then \u003e\u00262 printf '[\\033[31mERROR\\033[0m]: gitstatus failed to initialize.\\n' gitstatus_stop return 1 fi 이 함수는 gitstatusd 데몬을 효율적으로 관리하고, git 상태 정보를 빠르게 가져오는 기능을 제공합니다. 이는 git 저장소가 매우 큰 경우에 유용하며, git 상태 정보를 표시하는 프롬프트를 빠르게 업데이트하는 데 사용될 수 있습니다. 이 함수는 gitstatus 플러그인의 일부입니다. 이 플러그인은 Zsh 및 Bash 쉘에서 사용할 수 있습니다."},"title":"bash"},"/temp/c++-%EC%9E%85%EB%A0%A5%ED%95%A8%EC%88%98/":{"data":{"":"","주의#주의":"// 정수 int n; cin \u003e\u003e n; // 문자열 string str; cin \u003e\u003e str; 에 포함 표준 입력 버퍼에서 개행문자를 제외한 값을 가져옴 공백이나 개행입력시 공백 이전까지의 값만 결과로 받아드린다 개행문자를 입력 버퍼에 남겨둔다 getline()함수는 두 가지가 존재하는데 각가 다른 라이브러리에 존재한다. istream 라이브러리에 속한 cin.getline()함수와 string 라이브러리에 속하는 getline()함수가 있다.\nistream 라이브러리의 cin.getline() 문자 배열이며 마지막 글자가 ‘\\0’(terminator)인 c-string을 입력 받는데 사용 n-1개의 문자 개수만큼 읽어와 str에 저장 (n번째 문자는 NULL(‘\\0’)로 바꾼다.) 세 번째 인자인 delim은 별도로 지정해주지 않으면 엔터(‘\\n’)로 인식 delim을 지정해주면 그 제한자(delim)문자 직전까지 읽어서 str에 저장 cin.getline(char* str, streamsize n); cin.getline(char* str, streamsize n, char dlim); cin.getline(변수 주소, 최대 입력 가능 문자수, 종결 문자);\nex) cin.getline(str, 100);\nstring 라이브러리의 getline() 최대 문자 수를 입력하지 않아도 됨. 원하는 구분자(delimiter)를 만날 때 까지 모든 문자열을 입력 받아 하나의 string 객체에 저장 getline(istream\u0026 is, string str); getline(istream\u0026 is, string str, char dlim); getline(입력스트림 오브젝트, 문자열을 저장할 string객체, 종결 문자);\nex) getline(cin, str);\n주의 getline() 함수를 사용할 때 주의할 점이 있다.\n1 2 3 4 int n; string str; cin » n; getline(cin, str); 위와 같은 상황을 보자. 위 코드대로 실행을 하면 n을 입력 받은 후 문자열을 입력받지 않고 바로 다음 코드로 넘어가게 된다. 이유는 버퍼에 정수 값을 입력한 뒤 누른 엔터(‘\\n’)가 그대로 남아있어 getline()에 들어가기 때문이다. 이를 해결하기 위해 cin.ignore() 라는 함수를 사용할 수 있다.\n1 2 3 4 5 int n; string str; cin » n; cin.ignore(); getline(cin, str); 위와 같이 변경하면 cin.ingore()가 입력 버퍼의 모든 내용을 제거해주어 getline()이 정상적으로 동작할 수 있다.\n추가적으로 cin.ignore() 함수에 대해 알아보자면\ncin.ignore(int n, char dlim);\ncin.ignore(읽어들일 문자의 개수, 종결 문자);\n와 같은 형태로도 사용이 가능하다.\n표준 입력 버퍼에서 문자를 하나만 가져온다. 문자 하나만 입력이 가능하며 공백과 개행도 입력으로 포함한다. 1 2 3 char ch1, ch2; ch1 = cin.get(); ch2 = cin.get();"},"title":"c++ 입력함수"},"/temp/c-%EC%97%90%EC%84%9C-%EC%98%A4%EB%A5%98%EB%A5%BC-%EB%B0%9C%EC%83%9D%EC%8B%9C%ED%82%A4%EB%8A%94-%EB%B0%A9%EB%B2%95/":{"data":{"":"반환 값 사용:\n함수에서 특정 값을 반환하여 오류를 나타냅니다. return -1; // 오류를 나타내는 음수 값 return NULL; // 포인터 함수에서 오류 표시 exit() 함수:\n프로그램을 즉시 종료하고 운영 체제에 상태 코드를 반환합니다. #include \u003cstdlib.h\u003e exit(1); // 비정상 종료를 나타내는 0이 아닌 값 abort() 함수:\n프로그램을 비정상적으로 종료하고 코어 덤프를 생성합니다. #include \u003cstdlib.h\u003e abort(); assert() 매크로:\n조건이 거짓일 때 프로그램을 중단하고 오류 메시지를 출력합니다. #include \u003cassert.h\u003e assert(condition); // condition이 거짓이면 오류 발생 perror() 함수:\n시스템 오류 메시지를 표준 오류로 출력합니다. #include \u003cstdio.h\u003e perror(\"오류 발생\"); fprintf()를 이용한 오류 메시지 출력:\n오류 메시지를 표준 오류 스트림으로 출력합니다. #include \u003cstdio.h\u003e fprintf(stderr, \"오류: %s\\n\", \"오류 메시지\"); setjmp()와 longjmp() 함수:\n예외 처리와 유사한 기능을 구현할 수 있습니다. #include \u003csetjmp.h\u003e jmp_buf env; if (setjmp(env) == 0) { // 정상 실행 코드 } else { // 오류 처리 코드 } // 오류 발생 시 longjmp(env, 1); errno 전역 변수:\n시스템 호출이나 라이브러리 함수의 오류 코드를 저장합니다. #include \u003cerrno.h\u003e #include \u003cstring.h\u003e if (errno != 0) { fprintf(stderr, \"오류: %s\\n\", strerror(errno)); } 이러한 방법들을 상황에 맞게 적절히 조합하여 사용하면 C 프로그램에서 효과적으로 오류를 처리할 수 있습니다."},"title":"c 에서 오류를 발생시키는 방법"},"/temp/composite-pattern/":{"data":{"":"복합 객체와 단일 객체를 동일하게 취급하고 싶다 과일과 과일박스를 동일한 과일박스 안에 넣고 싶다 트리 형태로 퍼져나간다\nclass animal: def __init__(self, name): self.name = name def speak(self): pass class dog(animal): def speak(self): print(self.name) class cat(animal): def speak(self): print(self.name) class animal_group(animal): def __init__(self): self.animals = [] def add(self, animal): self.animals.append(animal) def speak(self): print(\"group speak\") for animal in self.animals: animal.speak() group1 = animal_group() group1.add(dog(\"dog1\")) group1.add(dog(\"dog2\")) group1.add(cat(\"cat1\")) group2 = animal_group() group2.add(cat(\"cat2\")) group2.add(group1) group2.speak() ==== group speak cat2 group speak dog1 dog2 cat1"},"title":"composite pattern"},"/temp/css-hidden-%EB%8C%80%EC%8B%A0-transition/":{"data":{"":"Tailwind CSS를 사용한다고 가정하고, 좌우 사이드바(왼쪽 사이드바와 오른쪽 사이드바)가 각각 화면 왼쪽/오른쪽 밖에 숨어 있다가, 필요할 때 애니메이션과 함께 나타나도록 설정하는 과정입니다.","-html-구조-예시-수정-전#📄 HTML 구조 예시 (수정 전)":"먼저, 일반적인 사이드바 구조를 예로 들어보겠습니다:\n\u003caside id=\"left-sidebar\" class=\"hidden\"\u003e \u003c/aside\u003e \u003caside id=\"right-sidebar\" class=\"hidden\"\u003e \u003c/aside\u003e 이 상태에서는 hidden 클래스 때문에 두 사이드바가 완전히 DOM에서 사라지며, CSS 트랜지션(애니메이션)이 작동하지 않습니다.","-각-클래스의-역할-상세-설명#📌 각 클래스의 역할 상세 설명":"","-사이드바를-보이게-하려면#🎯 사이드바를 보이게 하려면?":"나중에 JavaScript나 Alpine.js, Vue 등으로 사이드바를 열고 싶을 때는:\n왼쪽 사이드바: -translate-x-full → 제거 (또는 translate-x-0 추가) 오른쪽 사이드바: translate-x-full → 제거 (또는 translate-x-0 추가) 예시 (JavaScript로 왼쪽 사이드바 열기):\ndocument.getElementById('left-sidebar').classList.remove('-translate-x-full'); // 또는 document.getElementById('left-sidebar').classList.add('translate-x-0'); 닫을 때는 다시 -translate-x-full를 추가하면 됩니다.","-수정된-html-구조-수정-후#✅ 수정된 HTML 구조 (수정 후)":"\u003caside id=\"left-sidebar\" class=\"fixed inset-y-0 left-0 z-50 w-64 bg-white shadow-lg transform -translate-x-full transition-transform duration-300\"\u003e \u003c/aside\u003e \u003caside id=\"right-sidebar\" class=\"fixed inset-y-0 right-0 z-50 w-64 bg-white shadow-lg transform translate-x-full transition-transform duration-300\"\u003e \u003c/aside\u003e","-요구사항-요약#🔧 요구사항 요약":"좌우 사이드바에 다음 클래스를 추가:\ntransition-transform: transform 속성에 대한 트랜지션(애니메이션)을 활성화 duration-300: 트랜지션 지속 시간을 300ms로 설정 초기 상태에서:\n왼쪽 사이드바는 화면 왼쪽 밖에 위치 → -translate-x-full 오른쪽 사이드바는 화면 오른쪽 밖에 위치 → translate-x-full 기존의 hidden 클래스는 제거\n→ hidden은 display: none을 적용하므로, 애니메이션이 작동하지 않음","-요약#💡 요약":"변경 사항 설명 hidden 제거 애니메이션을 위해 요소는 항상 DOM에 존재해야 함 transform 추가 Tailwind에서 translate 계열 클래스를 동작시키기 위함 -translate-x-full / translate-x-full 초기에 화면 밖으로 이동 transition-transform duration-300 부드러운 슬라이드 애니메이션 활성화 이렇게 설정하면, 사이드바는 처음에는 보이지 않지만, 필요할 때 애니메이션과 함께 부드럽게 슬라이드 인/아웃할 수 있습니다.\nTailwind의 유틸리티 기반 클래스 시스템을 최대한 활용한 접근입니다.","1-fixed-inset-y-0-left-0--right-0#1. \u003ccode\u003efixed inset-y-0 left-0\u003c/code\u003e / \u003ccode\u003eright-0\u003c/code\u003e":"fixed: 뷰포트 기준으로 고정 위치 inset-y-0: 상단과 하단을 0으로 고정 → 전체 높이 차지 left-0 / right-0: 왼쪽 또는 오른쪽 끝에 붙임","2-w-64#2. \u003ccode\u003ew-64\u003c/code\u003e":"사이드바 너비를 16rem (256px)로 설정 (Tailwind 기본값)","3-bg-white-shadow-lg#3. \u003ccode\u003ebg-white shadow-lg\u003c/code\u003e":"시각적 스타일 (배경색 + 그림자) — 실제 디자인에 따라 달라질 수 있음","4-transform#4. \u003ccode\u003etransform\u003c/code\u003e":"필수 클래스: Tailwind에서 translate-* 클래스를 사용하려면 반드시 transform 클래스가 있어야 실제 CSS transform 속성이 적용됩니다. 이 클래스가 없으면 -translate-x-full 등이 무시될 수 있습니다.","5--translate-x-full-왼쪽-사이드바#5. \u003ccode\u003e-translate-x-full\u003c/code\u003e (왼쪽 사이드바)":"요소를 자신의 너비만큼 왼쪽으로 이동 → 화면 밖으로 사라짐 예: 너비가 256px이면, 왼쪽으로 256px 이동 → 화면 왼쪽 끝에서 완전히 숨김","6-translate-x-full-오른쪽-사이드바#6. \u003ccode\u003etranslate-x-full\u003c/code\u003e (오른쪽 사이드바)":"요소를 자신의 너비만큼 오른쪽으로 이동 → 화면 오른쪽 밖으로 사라짐","7-transition-transform#7. \u003ccode\u003etransition-transform\u003c/code\u003e":"transform 속성(예: translateX)에 대해 애니메이션을 적용하도록 지시 이 클래스가 없으면 이동이 즉시 일어나서 애니메이션이 없음","8-duration-300#8. \u003ccode\u003eduration-300\u003c/code\u003e":"트랜지션 지속 시간을 300ms로 설정 → 부드러운 슬라이드 인/아웃 효과","9-hidden-클래스-제거#9. \u003ccode\u003ehidden\u003c/code\u003e 클래스 제거":"hidden은 display: none을 적용 → 요소가 렌더링되지 않음 display: none 상태에서는 어떤 CSS 트랜지션도 작동하지 않음 대신, 위치만 이동시켜 시각적으로 숨기는 방식을 사용 → 애니메이션 가능"},"title":"css hidden 대신 transition"},"/temp/dbms-%EC%9E%A1-%EC%A0%95%EB%B3%B4/":{"data":{"":"","데이터베이스-별-기본-파일-저장-위치#데이터베이스 별 기본 파일 저장 위치":"/opt/oracle/oradata : oracle database /var/lib/mysql : mysql /var/lib/mysql : mariadb /var/lib/postgresql//main : postgresql"},"title":"dbms 잡 정보"},"/temp/docker-%EB%AA%85%EB%A0%B9-%EB%AA%A8%EC%9D%8C/":{"data":{"":"docker run (\u003c옵션\u003e) \u003c이미지 식별자\u003e (\u003c명령어\u003e) (\u003c인자\u003e) -d : detach =\u003e background -it : interactive, tty\ndocker exec -it \u003c컨테이너 식별자\u003e (\u003c명령어\u003e)"},"title":"docker 명령 모음"},"/temp/docker-%EC%97%86%EC%9D%B4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88/":{"data":{"":"관련 리포지토리 유튜브 영상\n아래의 패지지 의존\nsudo apt-get update \u0026\u0026 sudo apt-get -y install gcc \u0026\u0026 sudo apt-get -y install make \u0026\u0026 sudo apt-get -y install pkg-config \u0026\u0026 sudo apt-get -y install libseccomp-dev \u0026\u0026 sudo apt-get -y install tree \u0026\u0026 sudo apt-get -y install jq \u0026\u0026 sudo apt-get -y install bridge-utils 전제 루트 파일 시스템 container =\u003e / 는 overlay 로 마운트 host =\u003e / 는 일반적인 곳으로 마운트 프로세스 container =\u003e 1번이 shell host =\u003e 일반 네트워크 container =\u003e eth0@~~ host =\u003e 일반 유저 및 호스트 container =\u003e root (host 의 root 와 동일할까??), 이상한 문자열 호스트네임 host =\u003e chroot 프로세스를 가두자 =\u003e 사용자 프로세스를 fake 루트를 통해 막는다 (프로세스를 가둔다는 말이 무었일까 #ModificationRequired )\nchroot myroot /dirname docker export $(docker create nginx) | tar -C nginx-root -xvf -; 네임스페이스 chroot 의 경우 #ModificationRequired 이유로 프로세스를 탈옥이 가능했다 하지만 마운트의 원리를 사용하여 루트 파일시스템을 pivot_root 명령으로 바꿀 수 있고 이러면 원래 루트파일 시스템으로 접근 할 수 없다\n또한 이러한 접근 권한을 폴더 접근 뿐만 아니라 네트워크 ipc 마운트 등등으로 적용하여 접근을 제한 할 수 있다 이러한 제한에 사용되는 용어가 바로 네임스페이스이다\nlsns 명령으로 네임스페이스 확인가능 inode 로 확인 ushare 명령으로 네임스페이스를 변경 가능\nmount chroot_pivot 이란 루트 파일 시스템을 변경\noverlay 마운트 개념 오버레이를 통해 프로그램이 필요한 위존성을 따로 hub 에 올릴 수 있다\n네트워크 /var/run/netns 위치에 저장","chroot#chroot":"","mount#mount":"","네임스페이스#네임스페이스":"","네트워크#네트워크":"","전제#전제":""},"title":"docker 없이 컨테이너"},"/temp/elf-%EA%B5%AC%EC%A1%B0/":{"data":{"":"%20image%2020250123105644.png)"},"title":"ELF 구조"},"/temp/find-%EB%AA%85%ED%99%95%ED%95%98%EA%B2%8C-%EC%9D%B4%ED%95%B4%ED%95%98%EC%9E%90/":{"data":{"":"어떤 폴더를 제외하고 파일을 찾고자 -not -path 옵션을 사용했지만 접근 불가능한 파일(proc 내부의 파일들)에 접근하려고 해서 오류(Permission denied)를 뿜어내서 찾아보게 되었다 하지만 생각보다 조금 내용이 복잡한 것 같아 완벽하게 정리해 보고자 한다\nfind 명령이 하는 일이 단순하게 2가지를 한다고 이해하면\n찾는 것 ~= 탐색하는 것 탐색의 나열중 조건에 맞는 것을 출력하는 것 2가지 이다 find 기본 문법\nfind {option} {starting pointing} {expression} ... option starting pointing : find 명령의 시작 위치 expression: 조건 여러가지 종류가 존재 테스트(Tests) : 파일의 속성에 기반한 true false 값 반환 ex) -name ‘stdio.h’ =\u003e 이름이 stdio.h 인 경우 true 동작(Actions) : T/F 반환 이외의 std 출력과 같은 부가적이 동작이 있음 그리고 그 부가적인 동작의 성공 여부에 따라 T/F 를 반환 ex) -path ‘/include’ -prune =\u003e ‘/include’ 폴더의 내부는 탐색하지 않는다 또한 전체의 결과는 true 이다 전역 옵션(Global options) 전역 옵션은 명령 줄의 어느 부분에서도 지정된 테스트 및 동작의 작동에 영향을 줍니다. 전역 옵션은 항상 true를 반환합니다. 예를 들어 -depth 옵션은 find가 파일 시스템을 깊이 우선 순서로 탐색하도록 만듭니다. 위치 옵션(Positional options) 위치 옵션은 그들 뒤에 따라오는 테스트 또는 동작에만 영향을 미칩니다. 위치 옵션은 항상 true를 반환합니다. 예를 들어 -regextype 옵션은 위치 지정이며, 명령 줄에서 나중에 발생하는 정규 표현식에 대해 정규 표현식 방언을 지정합니다. 연산자(Operators) 연산자는 표현 내의 다른 항목들을 결합합니다. 예를 들어 -o(논리 OR를 의미함)와 -a(논리 AND를 의미함)가 있습니다. 연산자가 누락된 경우 -a가 가정됩니다. /usr 폴더에서 /usr/bin 출력하지도 탐색하지도 않고 이름이 stdio.h 인 파일을 찾는다 find /usr -not \\( -path '/usr/bin' -prune \\) -name 'stdio.h'\n/ 에서 시작한다\n-path 옵션을 통해 /usr/bin 와 일치하는 것을 찾는다\n-prune 옵션을 통해 찾은 파일이 디렉토리인 경우 더이상 탐색하지 않는다 그러므로 /usr/bin 폴더 만이 찾아진다\n-not 옵션을 통해 -path 옵션을 통해 찾은 폴더는 false 이다\n-name 옵션을 통해 이름이 ‘stdio.h’ 인 파일을 찾는다\n이 코드는 표현식 트리를 구성하는 함수입니다. 주요 작업은 다음과 같습니다:\n표현식 파싱: 입력된 인수들을 파싱하여 표현식을 구성합니다. 각각의 인수는 특정 조건을 나타내는 ‘predicate’로 처리됩니다. 이 과정에서 find_parser 함수를 사용하여 각 인수에 대한 파서를 찾고, 해당 파서의 함수를 호출하여 표현식을 구성합니다. 표현식 트리 구성: 파싱된 표현식들을 트리 형태로 구성합니다. 이 트리는 각 노드가 하나의 조건을 나타내며, 트리를 순회하면서 각 조건을 평가하여 전체 표현식의 결과를 도출합니다. 트리 최적화: 표현식 트리를 최적화하여 평가 시간을 줄입니다. 트리의 노드를 재배치하여 평가 순서를 변경하고, 가능한 경우 일부 조건의 평가를 생략하도록 합니다. 디버깅 정보 출력: 디버깅 옵션이 활성화된 경우, 표현식 트리와 최적화된 명령 줄을 출력합니다. 이 정보는 표현식의 구조와 최적화 과정을 이해하는 데 도움이 됩니다. 이 함수의 결과는 최적화된 표현식 트리입니다. 이 트리는 후속 처리에서 사용되어, 각 파일이 주어진 조건에 맞는지 평가하는 데 사용됩니다. 이 함수는 주어진 인수들을 통해 표현식을 구성하고 최적화하는 역할을 합니다. 이 과정에서 여러 가지 오류 상황을 체크하고, 오류가 발생하면 적절한 에러 메시지를 출력하고 프로그램을 종료합니다. 이는 입력된 인수들이 올바른 표현식을 형성하지 않는 경우에 발생합니다. 이러한 방식으로, 이 함수는 표현식의 구성과 검증을 담당하며, 이를 통해 파일 검색 조건을 효과적으로 처리합니다."},"title":"find 명확하게 이해하자"},"/temp/gdb-%EC%82%AC%EC%9A%A9%EB%B2%95/":{"data":{"":"","기본-명령어#기본 명령어":"명령어 설명 list 현재 디버깅 중인 소스 코드의 일부를 출력합니다. run 프로그램을 실행합니다. (명령 뒤에 인자를 추가하여 프로그램 실행 시 인자를 전달할 수 있습니다.) break (또는 b) 브레이크포인트를 설정합니다. (예: b main 또는 b 파일명:줄번호) clear 특정 위치에 설정된 브레이크포인트를 삭제합니다. delete 설정된 브레이크포인트를 삭제합니다. (예: delete 1으로 특정 브레이크포인트 삭제) next (또는 n) 한 줄씩 코드 실행을 진행합니다(함수 호출은 건너뜀). step (또는 s) 한 줄씩 코드 실행을 진행하며, 함수 호출 내부로 진입합니다. print (또는 p) 변수나 표현식의 값을 출력합니다. (예: p 변수명) display 특정 변수의 값을 계속 표시합니다. (예: display 변수명) bt (또는 backtrace) 호출 스택(traceback)을 출력합니다. kill 실행 중인 프로그램을 강제 종료합니다. cout GDB에서 직접 제공하지 않는 명령어로, 일반적으로 C++에서 표준 출력 스트림을 의미합니다. help GDB 명령어 도움말을 제공합니다. (예: help break) quit GDB를 종료합니다. watch varname 특정 변수(varname)의 값이 변경될 때 중단합니다. info locals 현재 스코프의 지역 변수 값을 표시합니다. info variables 모든 전역 변수와 정적 변수를 표시합니다. info break 설정된 모든 브레이크포인트를 나열합니다. info func 디버깅 대상의 모든 함수 이름을 나열합니다. set 특정 변수나 환경 설정을 변경합니다. (예: set var 변수명 = 값) finish 현재 함수의 실행을 끝내고 호출한 함수로 복귀합니다.","추가-명령어#추가 명령어":"명령어 설명 continue (또는 c) 브레이크포인트까지 계속 실행합니다. stepi 기계어 수준에서 한 단계 실행합니다. disassemble 기계어 수준에서 디스어셈블리된 코드를 출력합니다. info threads 현재 실행 중인 모든 스레드의 정보를 표시합니다. thread apply 특정 스레드에 대해 명령을 적용합니다. (예: thread apply all bt는 모든 스레드의 백트레이스를 출력) set args 실행 시 전달할 프로그램의 인자를 설정합니다. info registers 레지스터의 상태를 출력합니다. x 메모리를 검사합니다. (예: x/10x 변수는 변수부터 10개의 16진수를 출력) attach 실행 중인 프로세스에 연결하여 디버깅합니다. detach 연결된 프로세스에서 디버깅을 종료하고 분리합니다. 추가로 궁금한 명령어나 세부적인 사용 예시가 필요하다면 알려주세요! 😊"},"title":"gdb 사용법"},"/temp/interactive-shell-vs-non-interactive-shell/":{"data":{"":"ex) 터미널 vs #!/bin/bash 로 시작하는 파일\n파일의 셸은 $BASH_ENV 환경변수를 로드한다"},"title":"interactive shell vs non interactive shell"},"/temp/java-%EC%93%B0%EB%A0%88%EB%93%9Cthread/":{"data":{"":"java 메모리(memory)).md) 참고 ![Pasted image 2024210440.png)\njava는 thread의","스레드-상태#스레드 상태":"NEW : Thread 객체만 생성된 상태 RUNNABLE : thread.start() 이후 실행중인 상태 또는 cpu 스케줄링 순서에 따라 대기 상태 일시정지 BLOCKED : 특정 조건시 풀린다 ex) Scanner 사용자 입력 기다림 WAITING : TIMED_WAITING : 시간 지난후 풀린다 ex) sleep() TERMINATED;\nNEW: 쓰레드가 생성되었지만 아직 시작되지 않은 상태입니다1. 이 상태에서는 쓰레드가 아직 실행되지 않았으므로 시스템 자원이 할당되지 않습니다2. RUNNABLE: 쓰레드가 실행 중이거나 언제든지 실행할 준비가 된 상태입니다3. 이 상태에서 쓰레드는 실제로 실행 중일 수도 있고, 운영 체제로부터 다른 리소스를 기다리고 있을 수도 있습니다1. BLOCKED: 쓰레드가 모니터 잠금을 획득하려고 시도하지만 현재 다른 쓰레드가 잠금을 보유하고 있는 상태입니다3. 쓰레드는 잠금을 획득할 때까지 BLOCKED 상태에 머무릅니다4. WAITING: 쓰레드가 무기한으로 다른 쓰레드가 특정 작업을 수행하기를 기다리는 상태입니다3. 이 상태는 쓰레드가 Object.wait() 또는 Thread.join() 메서드를 호출했을 때 발생합니다 또는 Thread.join()` 메서드를%20호출했을%20때%20발생합니다)5. TIMED_WAITING: 쓰레드가 다른 쓰레드가 특정 작업을 수행하기를 지정된 시간 동안 기다리는 상태입니다3. 이 상태는 쓰레드가 Thread.sleep(), Object.wait(timeout), Thread.join(timeout) 등의 메서드를 호출했을 때 발생합니다, Object.wait(timeout), Thread.join(timeout)` 등의%20메서드를%20호출했을%20때%20발생합니다)6. TERMINATED: 쓰레드가 종료된 상태입니다3. 쓰레드는 작업을 성공적으로 완료하거나 오류로 인해 종료되거나 강제로 종료될 때 이 상태에 들어갑니다7. wait(), notify(), notifyAll() 은 Object 메서드 나머지는 Thread 메서드","쓰레드-구현-방법#쓰레드 구현 방법":"Thread 상속 Runnable 인터페이스 구현 Thread thread = new Thread(){ // Thread 상속 및 익명 클래스로 사용 @Override public void run() { 여기에 사용 } }; thread.start(); Thread thread = new Thread(new Runnable(){ // Runnable 구현 및 생성자의 인자 @Override public void run() { 여기에 사용 } }); thread.start(); Thread 를 상속한 객체는 그 자체로 하나의 쓰레드 객체를 의미하지만 Runnable 인터페이스를 구현한 객체는 쓰레드로 들어가 일거리라는 의미이다 그러므로 Thread 객체를 new Thread 할 때 생성자에 넣어주어야 한다","쓰레드-그룹#쓰레드 그룹":"실제로는 쓰레드는 계층이라는 것이 없지만 java 에서는 쓰레드를 계층 관계 그룹으로 관리 할 수 있다 prioity 우선순위 설정 기능을 활용 할 수 있다","쓰레드-풀#쓰레드 풀":"쓰레드의 무한 증가를 막기위해 제한된 개수만큼 정해 놓고 작업 큐에 들어오는 작업들을 쓰레드가 하나씩 맡아 처리하는 방식"},"title":"java 쓰레드(thread)"},"/temp/join-%EC%97%B0%EC%82%B0-%ED%81%AC%EA%B8%B0-%EC%B6%94%EC%B2%AD/":{"data":{"":"이 문제는 관계형 데이터베이스에서 조인 연산의 크기 추정에 대한 설명입니다. 주어진 내용을 기반으로 예제를 들어 설명하겠습니다.","결론#결론:":"이 경우 두 추정 값이 동일하므로 조인 결과 크기를 5로 예측합니다. 조인을 실행해 보면 실제로 조인된 튜플 수가 5임을 확인할 수 있습니다.","데이터#데이터:":"릴레이션 $R$:\nA B 1 X 2 Y 3 Z $n_R = 3$, $V(A, R) = 3$ (속성 $A$의 값 1, 2, 3은 모두 고유함)\n릴레이션 $S$:\nA C 1 P 1 Q 2 R 2 S 3 T $n_S = 5$, $V(A, S) = 3$ (속성 $A$의 값 1, 2, 3은 모두 고유함)","문제-설명#문제 설명:":"$R \\bowtie S$: 릴레이션 $R$과 $S$를 조인합니다. **$A$**는 두 릴레이션 $R$과 $S$ 사이의 조인 속성입니다. $n_R$: 릴레이션 $R$의 튜플 수 $n_S$: 릴레이션 $S$의 튜플 수 $V(A, S)$: 속성 $A$의 $S$에서의 고유 값 수 (카디널리티) $V(A, R)$: 속성 $A$의 $R$에서의 고유 값 수 조인 결과의 크기는 아래와 같이 두 가지 방식으로 추정됩니다:\n$n_R \\times \\frac{n_S}{V(A, S)}$ $n_S \\times \\frac{n_R}{V(A, R)}$ 이 두 값 중 더 작은 값을 선택하는 것이 더 정확한 추정을 # join 연산 크기 추청 제공한다고 설명합니다.","예제#예제:":"","조인-크기-추정#조인 크기 추정:":"조인 $R \\bowtie S$는 $A$ 속성을 기준으로 이루어집니다.\n첫 번째 추정:\n$n_R \\times \\frac{n_S}{V(A, S)} = 3 \\times \\frac{5}{3} = 5$\n두 번째 추정:\n$n_S \\times \\frac{n_R}{V(A, R)} = 5 \\times \\frac{3}{3} = 5$","추가-개선#추가 개선:":"만약 속성 $A$의 히스토그램(각 값이 얼마나 자주 등장하는지에 대한 분포 정보)이 있다면, 각 값별로 보다 정확한 추정을 할 수 있습니다. 예를 들어, 값 “1\"이 $R$에서 1번, $S$에서 2번 등장한다면 해당 값의 조인 크기는 $1 \\times 2 = 2$로 세부적으로 계산 가능합니다."},"title":"join 연산 크기 추청"},"/temp/makefile/":{"data":{"":"target : dependency \u003c탭\u003e command tarrget 은 일반적인 command 로 생성된 파일을 의미할 수도 있고 목표하는 의미가 될 수도 있다 예를 들어 target 에 clean 이 들어가면 빌드 생성파일을 삭제한다","미리-정해저-있는-predefind-변수#미리 정해저 있는 predefind 변수":"make -p","변수#변수":"매크로의 사용에서 ${..}, $(..), $..를 모두 사용할 수 있습니다. 그러나 대부분의 책에서는 $(..) 을 사용하라고 권하는군요\nOBJS = main.o read.o write.o test : $(OBJS) gcc -o test $(OBJS)","자동변수#자동변수":"$@ : 현재 타겟 이름 $^ : 현재 타겟이 의존하는 대상들의 전체 목록 $^ : 의존 대상의 처음 대상"},"title":"Makefile"},"/temp/nextint-vs-nextline/":{"data":{"":"완벽히 이해했습니다.\n아래는 기존의 틀과 구조를 100% 유지하면서,\n각 단계에서 nextInt()와 nextLine()의 동작 차이를 병렬로 설명한 버전입니다.\n→ 동일한 입력(25\\n)이 주어졌을 때, 두 메서드가 어떻게 다른 방식으로 버퍼를 소비하고 커서를 이동시키는지를 계층별로 명확히 대조합니다.\n🧩 완전한 데이터 흐름: 사용자 입력 → Scanner 내부 버퍼 (시스템 프로그래밍 + 터미널 관점 — nextInt() vs nextLine() 비교 포함) ✍️ 목표: 사용자가 키보드로 25를 치고 Enter를 누른 순간부터,\nJava의 Scanner.nextInt() 또는 Scanner.nextLine()이 어떻게 다른 방식으로 25\\n을 처리하는지\n모든 계층을 투명하게 추적 + 비교.\n🌐 전체 흐름 다이어그램 (계층별 분리 — 두 메서드 병렬 비교) [User] → [Keyboard Hardware] → [OS TTY Driver (Line Buffering)] → [Kernel stdin Buffer] → [JVM System.in (FileInputStream)] → [InputStreamReader (decode)] → [Scanner CharBuffer + Tokenizer] ├→ nextInt() → \"25\" 반환, \\n은 버퍼에 남김 └→ nextLine() → \"25\" 반환, \\n까지 소비 🔍 1. 사용자 입력 — 키보드 인터럽트 사용자가 키보드로 2, 5, Enter 입력 하드웨어 인터럽트 발생 → CPU → OS 커널로 전달 커널은 TTY 드라이버(또는 PTY, 가상 터미널)에 입력을 전달 💡 여기서 중요한 개념: “터미널은 기본적으로 라인 버퍼링 모드”\n→ 이 동작은 nextInt()든 nextLine()이든 공통 전제 조건입니다.\n⚙️ 2. 터미널(TTY) 동작 — Canonical Mode (Cooked Mode) ✅ 기본 동작: “라인 단위 입력” — 사용자가 Enter 칠 때까지 커널이 버퍼링 터미널은 기본적으로 Canonical Mode (Cooked Mode) 로 동작 사용자가 입력하는 모든 문자는 커널의 TTY 버퍼에 쌓임 Enter(\\n) 또는 Ctrl+D(EOF)를 칠 때까지 아무것도 애플리케이션(JVM)에 전달되지 않음 🖥️ 즉, 25만 치고 있으면 — JVM은 아무것도 읽지 못함.\nEnter를 쳐야 비로소 커널이 25\\n을 stdin으로 푸시.\n→ nextInt()든 nextLine()이든, 이 시점까지는 동일하게 25\\n을 받습니다.\n📜 TTY 버퍼링 예시 (두 메서드 공통 출발점) User types: 2 → 5 → Enter TTY Buffer: [ '2', '5', '\\n' ] ← Enter 전까지 여기에 쌓임 ↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ JVM은 아직 아무것도 못 읽음! User presses Enter → TTY sends \"25\\n\" to stdin → 이제 JVM이 읽을 수 있음. ✅ 핵심 공통점: Scanner 버퍼에는 항상 25\\n이 들어감.\n✅ 핵심 차이점: nextInt()는 \\n을 버퍼에 남기고, nextLine()은 \\n을 소비함.\n📥 3. OS 커널 → JVM: read() 시스템 콜 JVM의 System.in은 FileInputStream 기반 내부적으로 FileDescriptor.in(stdin, fd=0)을 감싸고 있음 Scanner가 데이터를 요청하면 → source.read(buf) → 결국 read(0, buffer, len) 시스템 콜 발생 // 실제 리눅스 시스템 콜 — 두 메서드 모두 동일하게 호출 ssize_t n = read(STDIN_FILENO, buffer, sizeof(buffer)); // buffer에 \"25\\n\" 복사됨 → 이 시점에서 커널 TTY 버퍼의 25\\n이 JVM의 바이트 버퍼로 복사됨\n→ 이후부터 Scanner 내부에서 두 메서드의 동작이 갈림.\n🔄 4. JVM 내부: 바이트 → 문자 디코딩 (InputStreamReader) System.in은 바이트 스트림 → Scanner는 문자 기반 중간에 InputStreamReader가 존재 → CharsetDecoder로 UTF-8 → char[] 변환 // Scanner 생성 시 내부적으로 이렇게 연결됨 — 두 메서드 동일 Readable source = new InputStreamReader(System.in, charset); → \"25\\n\" (UTF-8 바이트) → char[] { '2', '5', '\\n' }로 디코딩 → Scanner의 CharBuffer에 적재\n→ 이제 nextInt()와 nextLine()이 이 버퍼를 다르게 해석합니다.\n🧠 5. Scanner 내부: 토큰 파싱 vs 라인 파싱 — 핵심 분기점 🔹 nextInt() 호출 시 int age = scanner.nextInt(); 🔁 동작 단계: 버퍼 확인: CharBuffer에 ['2','5','\\n'] 존재 정규식 매칭: Pattern.compile(\"-?\\\\d+\") → lookingAt() → \"25\" 매칭 성공 토큰 반환: Integer.parseInt(\"25\") → age = 25 커서 이동: 버퍼의 읽기 위치를 '2','5' 다음으로 이동 → 즉, \\n 바로 앞으로 이동 → \\n은 버퍼에 그대로 남아 있음! 🚫 nextInt()는 토큰만 소비 — 구분자(whitespace, including \\n)는 소비하지 않음\n🔸 nextLine() 호출 시 String line = scanner.nextLine(); 🔁 동작 단계: 버퍼 확인: CharBuffer에 ['2','5','\\n'] 존재 줄 단위 읽기: 현재 위치에서 다음 \\n까지의 모든 문자를 읽음 → \"25\" \\n 소비: \\n도 포함해 완전히 소비 커서 이동: \\n 다음 위치(다음 줄 시작)로 이동 → 버퍼는 완전히 비워짐 (또는 다음 입력 대기 상태) ✅ nextLine()은 줄 전체 + 줄바꿈 문자까지 소비 — 항상 커서를 다음 줄로 이동\n📝 6. 혼합 사용 시 문제 — nextInt() → nextLine() int age = scanner.nextInt(); // → \"25\" 반환, \\n 버퍼에 남김 String name = scanner.nextLine(); // → 남은 \\n을 읽어 \"\" 반환 → 버그! 🔄 버퍼 상태 변화: 초기: [ '2', '5', '\\n' ] nextInt() 후: [ '\\n' ] ← 커서는 \\n 앞 nextLine() 후: [ ] ← \\n 소비, 커서는 다음 줄 → name = \"\" → 사용자는 이름을 입력할 기회조차 얻지 못함 — 버그 발생!\n🆚 만약 처음부터 nextLine()만 사용했다면? String ageStr = scanner.nextLine(); // → \"25\" 반환, \\n 소비 완료 String name = scanner.nextLine(); // → 다음 입력 정상 대기 🔄 버퍼 상태 변화: 초기: [ '2', '5', '\\n' ] 첫 nextLine() 후: [ ] ← \"25\" 반환, \\n 소비 두 번째 nextLine() → 사용자에게 입력 대기 → 정상 입력 가능 → 문제 없음!\n🧱 계층별 정리: 각 레이어의 책임과 데이터 상태 + 메서드별 차이 레이어 책임 nextInt() 동작 후 상태 nextLine() 동작 후 상태 시스템 프로그래밍 키워드 1. Keyboard + Hardware 전기 신호 → 인터럽트 2, 5, Enter 신호 발생 (공통) 동일 IRQ, PS/2, USB HID 2. OS TTY Driver 라인 버퍼링 25\\n 전달 (공통) 동일 termios, ICANON 3. Kernel stdin Buffer read()로 전달 25\\n 전달 (공통) 동일 fd 0, read(2) 4. JVM System.in 바이트 스트림 byte[]{50,53,10} (공통) 동일 FileInputStream, JNI 5. InputStreamReader 바이트 → 문자 char[]{'2','5','\\n'} (공통) 동일 UTF-8, StreamDecoder 6. Scanner CharBuffer 토큰/라인 파싱 커서: \\n 앞, \\n 잔류 커서: \\n 다음, 버퍼 비움 Pattern, Matcher, readLine() 7. Your Code 비즈니스 로직 age=25, 이후 nextLine()이 빈 문자열 line=\"25\", 이후 정상 입력 가능 nextInt(), nextLine() 💡 왜 이렇게 복잡한가? — 추상화와 트레이드오프 터미널 라인 버퍼링: 사용자 편의 → 공통 전제 Scanner 토큰 기반 vs 라인 기반:\n→ nextInt()는 유연한 토큰 파싱을 위해 구분자 보존\n→ nextLine()은 줄 단위 처리를 위해 구분자 소비 버퍼링 계층: 시스템 콜 최소화 → 성능 향상 → 두 메서드는 같은 버퍼를 공유하지만, “어디까지 소비할 것인가”에 대한 철학이 다름\n→ 혼용 시 레이어 간 데이터 흐름이 깨져 버그 발생\n🛠️ 해결책 — 시스템 프로그래머의 시각에서","-1-사용자-입력--키보드-인터럽트#🔍 1. 사용자 입력 — 키보드 인터럽트":"","-2-터미널tty-동작--canonical-mode-cooked-mode#⚙️ 2. 터미널(TTY) 동작 — Canonical Mode (Cooked Mode)":"","-3-os-커널--jvm-read-시스템-콜#📥 3. OS 커널 → JVM: read() 시스템 콜":"","-4-jvm-내부-바이트--문자-디코딩-inputstreamreader#🔄 4. JVM 내부: 바이트 → 문자 디코딩 (InputStreamReader)":"","-5-scanner-내부-토큰-파싱-vs-라인-파싱--핵심-분기점#🧠 5. Scanner 내부: 토큰 파싱 vs 라인 파싱 — 핵심 분기점":"","-6-혼합-사용-시-문제--nextint--nextline#📝 6. 혼합 사용 시 문제 — \u003ccode\u003enextInt()\u003c/code\u003e → \u003ccode\u003enextLine()\u003c/code\u003e":"","-nextint-호출-시#🔹 \u003ccode\u003enextInt()\u003c/code\u003e 호출 시":"","-nextline-호출-시#🔸 \u003ccode\u003enextLine()\u003c/code\u003e 호출 시":"","-tty-버퍼링-예시-두-메서드-공통-출발점#📜 TTY 버퍼링 예시 (두 메서드 공통 출발점)":"","-계층별-정리-각-레이어의-책임과-데이터-상태--메서드별-차이#🧱 계층별 정리: 각 레이어의 책임과 데이터 상태 + 메서드별 차이":"","-기본-동작-라인-단위-입력--사용자가-enter-칠-때까지-커널이-버퍼링#✅ 기본 동작: “라인 단위 입력” — 사용자가 \u003ccode\u003eEnter\u003c/code\u003e 칠 때까지 커널이 버퍼링":"","-동작-단계#🔁 동작 단계:":"","-동작-단계-1#🔁 동작 단계:":"","-만약-처음부터-nextline만-사용했다면#🆚 만약 처음부터 \u003ccode\u003enextLine()\u003c/code\u003e만 사용했다면?":"","-방법-1-nextint-후-nextline으로-버퍼-정리#✅ 방법 1: \u003ccode\u003enextInt()\u003c/code\u003e 후 \u003ccode\u003enextLine()\u003c/code\u003e으로 버퍼 정리":"int age = scanner.nextInt(); scanner.nextLine(); // ← \\n 소비 — 커서를 다음 줄로 강제 이동 String name = scanner.nextLine(); // 정상 입력 → Scanner 레이어에서 수동으로 커서를 다음 줄로 이동","-방법-2-항상-nextline-사용--파싱은-수동으로#✅ 방법 2: 항상 \u003ccode\u003enextLine()\u003c/code\u003e 사용 → 파싱은 수동으로":"int age = Integer.parseInt(scanner.nextLine()); // \\n까지 소비 String name = scanner.nextLine(); // 다음 줄 정상 입력 → 토큰/라인 혼용 문제를 원천 차단 — 권장!","-방법-3-터미널-모드-변경-advanced--raw-mode#✅ 방법 3: 터미널 모드 변경 (Advanced) — Raw Mode":"stty raw java YourProgram stty cooked → 권장하지 않음 — Scanner의 파서 설계와 충돌 가능성 ↑","-버퍼-상태-변화#🔄 버퍼 상태 변화:":"","-버퍼-상태-변화-1#🔄 버퍼 상태 변화:":"","-시각화-입력-데이터의-생명-주기--두-메서드-비교#📊 시각화: 입력 데이터의 생명 주기 — 두 메서드 비교":"[User] │ ▼ [Keyboard] → \"2\" → \"5\" → \"\\n\" (Enter) — 공통 시작점 │ ▼ [TTY Driver] → Canonical Mode → \"25\\n\" 전달 — 공통 │ ▼ [Kernel stdin] → read() → \"25\\n\" 전달 — 공통 │ ▼ [JVM System.in] → byte[]{50,53,10} — 공통 │ ▼ [InputStreamReader] → char[]{'2','5','\\n'} — 공통 │ ▼ [Scanner CharBuffer] — 여기서 분기! ├─ nextInt() → \"25\" 반환 → 커서: \\n 앞 → \\n 잔류 │ │ │ ▼ │ [nextLine()] → 즉시 \\n 소비 → \"\" 반환 → 버그! │ └─ nextLine() → \"25\" 반환 → \\n 소비 → 커서: 다음 줄 → 정상","-완전한-데이터-흐름-사용자-입력--scanner-내부-버퍼#🧩 완전한 데이터 흐름: 사용자 입력 → Scanner 내부 버퍼":"","-왜-이렇게-복잡한가--추상화와-트레이드오프#💡 왜 이렇게 복잡한가? — 추상화와 트레이드오프":"","-전체-흐름-다이어그램-계층별-분리--두-메서드-병렬-비교#🌐 전체 흐름 다이어그램 (계층별 분리 — 두 메서드 병렬 비교)":"","-최종-결론--시스템-프로그래머라면-이렇게-말해야-한다#✅ 최종 결론 — 시스템 프로그래머라면 이렇게 말해야 한다":"“사용자 입력은 터미널의 Canonical Mode에 의해 라인 단위로 커널 버퍼에 쌓이다가 Enter와 함께 25\\n 형태로 JVM에 전달된다. Scanner는 이 문자열을 내부 CharBuffer에 적재한 후, nextInt()는 정수 토큰 ‘25’만 추출하고 줄바꿈 문자 \\n은 구분자로 간주해 소비하지 않아 버퍼에 남긴다. 반면 nextLine()은 줄 전체를 읽고 \\n까지 소비해 커서를 다음 줄로 이동시킨다. 따라서 nextInt() 직후 nextLine()을 호출하면, 남아 있던 \\n을 ‘빈 줄’로 해석해 즉시 반환함으로써 입력 누락이라는 치명적 버그를 유발한다. 이는 각 계층(OS TTY, JVM InputStream, Scanner Tokenizer)이 자신의 책임에 충실하게 동작한 결과이며, 해결하려면 레이어 간의 데이터 흐름을 명시적으로 제어해야 한다 — 특히, 토큰 기반 입력과 라인 기반 입력을 혼용할 때는 반드시 버퍼 정리(nextLine() 호출)가 필요하다.”","-추천-학습--터미널--io-마스터를-위한-길#📚 추천 학습 — 터미널 + I/O 마스터를 위한 길":"man termios — TTY 설정, Canonical vs Raw Mode stty -a — 현재 터미널 설정 확인 Linux strace -e read,write java YourApp — 실제 시스템 콜 추적 OpenJDK 소스: Scanner.java — next(), nextLine() 메서드 직접 비교 《Advanced Programming in the UNIX Environment》 — Richard Stevens — TTY 장(chapter 18) 필독 필요하시면 리눅스에서 strace로 실제로 read() 시스템 콜 추적 + Scanner 내부 리플렉션으로 버퍼 상태 실시간 확인하는 실습 코드도 제공해 드립니다.\n이제 진짜 “시스템이 어떻게 돌아가는지 + Java API가 왜 이렇게 설계되었는지” 를 동시에 아는 프로그래머가 되셨습니다. 🚀","-해결책--시스템-프로그래머의-시각에서#🛠️ 해결책 — 시스템 프로그래머의 시각에서":"","시스템-프로그래밍--터미널-관점--nextint-vs-nextline-비교-포함#(시스템 프로그래밍 + 터미널 관점 — \u003ccode\u003enextInt()\u003c/code\u003e vs \u003ccode\u003enextLine()\u003c/code\u003e 비교 포함)":""},"title":"nextInt vs nextLine"},"/temp/postgresql/":{"data":{"":"","postgresql-binary#Postgresql binary":"clusterdb: 데이터베이스 클러스터의 모든 데이터베이스를 클러스터화합니다. createdb: 새로운 데이터베이스를 생성합니다. createuser: 새로운 사용자를 생성합니다. dropdb: 데이터베이스를 삭제합니다. dropuser: 사용자를 삭제합니다. initdb: 새로운 데이터베이스 클러스터를 초기화합니다. oid2name: OID(객체 식별자)와 이름을 매핑합니다. pg_amcheck: 인덱스 접근 방법을 검사합니다. pg_archivecleanup: 아카이브 로그 파일을 정리합니다. pg_basebackup: 데이터베이스 클러스터의 전체 백업을 생성합니다. pgbench: 벤치마킹 도구로, 성능 테스트를 수행합니다. pg_checksums: 데이터베이스 블록의 체크섬을 확인합니다. pg_config: PostgreSQL 설치 정보 및 구성을 출력합니다. pg_controldata: 데이터베이스 클러스터의 제어 정보를 출력합니다. pg_ctl: 데이터베이스 서버를 시작, 중지, 재시작합니다. pg_dump: 데이터베이스의 백업을 생성합니다. pg_dumpall: 모든 데이터베이스의 백업을 생성합니다. pg_isready: 데이터베이스 서버의 상태를 체크합니다. pg_receivewal: WAL(Write Ahead Log)을 수신합니다. pg_recvlogical: 논리적 복제를 위한 WAL을 수신합니다. pg_resetwal: WAL 파일의 상태를 재설정합니다. pg_restore: pg_dump로 생성된 백업을 복원합니다. pg_rewind: 마스터와 슬레이브 간의 데이터 동기화를 수행합니다. pg_test_fsync: fsync 성능을 테스트합니다. pg_test_timing: 시간 측정 테스트를 수행합니다. pg_upgrade: 데이터베이스를 새로운 버전으로 업그레이드합니다. pg_verifybackup: 백업의 유효성을 검사합니다. pg_waldump: WAL 파일의 내용을 출력합니다. postgres: PostgreSQL 데이터베이스 서버의 주요 실행 파일입니다. postmaster: PostgreSQL 서버를 시작하는 데 사용되는 심볼릭 링크입니다. psql: PostgreSQL의 명령줄 인터페이스입니다. reindexdb: 데이터베이스의 인덱스를 재생성합니다. vacuumdb: 데이터베이스의 공간을 회수하고, 통계를 업데이트합니다. PostgreSQL에서 Predefined Roles(미리 정의된 역할)은 특정 권한과 기능에 대한 접근을 제공하는 역할로, 데이터베이스 관리자가 사용자나 다른 역할에 부여할 수 있습니다. 이러한 역할은 일반적으로 자주 필요한 권한을 집합적으로 관리할 수 있도록 설계되었습니다. 아래에 각 미리 정의된 역할에 대한 설명을 제공합니다.","권한-부여#권한 부여":"관리자는 다음과 같은 SQL 명령을 사용하여 특정 사용자에게 이러한 역할을 부여할 수 있습니다:\nGRANT pg_signal_backend TO admin_user;","미리-정의된-역할-목록과-설명#미리 정의된 역할 목록과 설명":"pg_read_all_data 권한: 모든 데이터(테이블, 뷰, 시퀀스)를 읽을 수 있는 권한을 가집니다. SELECT 권한이 없는 경우에도 USAGE 권한이 자동으로 부여됩니다. 주의: RLS(행 수준 보안)가 활성화된 경우, BYPASSRLS 속성이 설정되지 않으면 제한이 있을 수 있습니다. pg_write_all_data 권한: 모든 데이터에 대해 INSERT, UPDATE 및 DELETE 권한을 가집니다. USAGE 권한도 자동으로 부여됩니다. 주의: RLS가 활성화된 경우, BYPASSRLS 속성이 설정되지 않으면 제한이 있을 수 있습니다. pg_read_all_settings 권한: 모든 설정 변수(일반 사용자에게는 보이지 않는 것까지 포함)를 읽을 수 있습니다. pg_read_all_stats 권한: pg_stat_* 뷰와 다양한 통계 관련 확장을 읽을 수 있습니다. 일반 사용자에게는 보이지 않는 정보에 접근할 수 있습니다. pg_stat_scan_tables 권한: 테이블에 ACCESS SHARE 잠금을 걸 수 있는 모니터링 기능을 실행할 수 있습니다. pg_monitor 권한: 다양한 모니터링 뷰와 함수를 읽고 실행할 수 있습니다. 이 역할은 pg_read_all_settings, pg_read_all_stats, pg_stat_scan_tables의 멤버입니다. pg_database_owner 권한: 현재 데이터베이스의 소유자에게만 자동으로 부여되는 역할입니다. 이 역할은 다른 역할의 구성원이 될 수 없습니다. pg_signal_backend 권한: 다른 백엔드에 신호를 보내 쿼리를 취소하거나 세션을 종료할 수 있는 권한을 부여합니다. pg_read_server_files 권한: 데이터베이스가 접근할 수 있는 파일을 읽을 수 있는 권한입니다. pg_write_server_files 권한: 데이터베이스가 접근할 수 있는 파일에 쓸 수 있는 권한입니다. pg_execute_server_program 권한: 데이터베이스 서버에서 프로그램을 실행할 수 있는 권한을 부여합니다. pg_checkpoint 권한: CHECKPOINT 명령을 실행할 수 있는 권한입니다. pg_use_reserved_connections 권한: 예약된 연결 슬롯을 사용할 수 있는 권한입니다. pg_create_subscription 권한: CREATE 권한이 있는 데이터베이스에서 CREATE SUBSCRIPTION 명령을 실행할 수 있는 권한입니다.","주의-사항#주의 사항":"보안: 이러한 역할은 강력한 권한을 부여하므로, 필요한 사용자에게만 부여해야 하며, 그 사용에 대한 이해가 필요합니다. 모니터링: pg_monitor와 같은 역할은 데이터베이스 서버의 모니터링을 용이하게 하며, 일반적으로 슈퍼유저만 접근할 수 있는 통계 및 설정 정보에 접근할 수 있도록 합니다. CREATE USER test_user WITH PASSWORD '1253' LOGIN; CREATE ROLE personal_group; GRANT personal_group TO test_user; CREATE DATABASE test_db OWNER test_user; REVOKE CONNECT ON DATABASE test_db FROM PUBLIC; REVOKE TEMPORARY ON DATABASE test_db FROM PUBLIC; GRANT CONNECT ON DATABASE test_db TO test_user; -- 필요 없을 수 있음 GRANT CONNECT ON DATABASE test_db TO postgres; -- 필요 없을 수 있음"},"title":"Postgresql"},"/temp/python-%EC%9E%85%EB%A0%A5%ED%95%A8%EC%88%98/":{"data":{"":"(function) def input( __prompt: object = \"\", / ) -\u003e str"},"title":"python 입력함수"},"/temp/rest-full-api/":{"data":{"":"RESTful API는 현대 웹 애플리케이션의 필수 요소로 자리잡았습니다. 그러나 RESTful API를 설계할 때는 몇 가지 원칙을 따르는 것이 중요합니다. 이번 글에서는 RESTful API 설계의 핵심 원칙과 그 원칙을 예시를 통해 자세히 살펴보겠습니다. 이 원칙들을 준수하면 API의 일관성과 확장성을 높이고, 개발자들에게 편의성을 제공할 수 있습니다.\n1. 자원(리소스) 기반 URI 자원(리소스) 기반 URI는 RESTful API의 핵심입니다. 각 자원은 고유한 URI(Uniform Resource Identifier)를 가지며, 이를 통해 자원을 식별합니다. 자원 기반 URI는 설계의 일관성을 유지하고 의미를 명확하게 전달하는 데 도움을 줍니다. 예를 들어, 다음과 같은 URI를 사용하여 각각의 리소스를 다룰 수 있습니다.","1-자원리소스-기반-uri#1. 자원(리소스) 기반 URI":"","2-http-동사-활용#2. HTTP 동사 활용":"HTTP 프로토콜은 다양한 동사(메서드)를 제공합니다. RESTful API 설계에서는 이러한 동사를 적절하게 활용하여 API의 의도를 명확하게 전달해야 합니다.\nGET: 리소스의 정보를 조회하기 위해 사용합니다. POST: 리소스를 생성하기 위해 사용합니다. PUT: 리소스의 정보를 업데이트하기 위해 사용합니다. DELETE: 리소스를 삭제하기 위해 사용합니다. PATCH: 리소스의 일부분을 업데이트하기 위해 사용합니다.","3-적절한-상태-코드-반환#3. 적절한 상태 코드 반환":"HTTP 상태 코드는 API의 응답에 포함되어 클라이언트에게 작업 결과를 알려줍니다. RESTful API 설계에서는 적절한 상태 코드를 반환하여 클라이언트가 요청에 대해 올바르게 대응할 수 있도록 해야 합니다. 일반적으로 사용되는 몇 가지 상태 코드는 다음과 같습니다:\n1xx - Informational (정보)\n100 - Continue (계속): 요청이 계속될 수 있음을 나타냄\n101 - Switching Protocols (프로토콜 변경): 프로토콜 전환을 요청한 경우 사용\n2xx - Successful (성공)\n200 - OK: 성공적인 요청에 대한 응답\n201 - Created (생성됨): 새 리소스가 성공적으로 생성됨\n202 - Accepted (수락됨): 요청이 받아들여졌지만 아직 처리되지 않음\n204 - No Content (콘텐츠 없음): 응답 본문이 없음을 나타냄\n206 - Partial Content (부분 콘텐츠): 부분 콘텐츠를 반환하는 경우 사용\n3xx - Redirection (리다이렉션)\n300 - Multiple Choices (다중 선택): 리소스에 여러 가지 선택지가 있음\n301 - Moved Permanently (영구적으로 이동): 리소스가 새로운 URI로 이동함\n302 - Found (찾음): 리소스가 일시적으로 다른 URI로 이동함\n304 - Not Modified (수정되지 않음): 리소스가 변경되지 않았으므로 클라이언트가 캐시 사용\n4xx - Client Error (클라이언트 오류)\n400 - Bad Request (잘못된 요청): 잘못된 요청으로 인해 서버가 요청을 이해하지 못함\n401 - Unauthorized (권한 없음): 인증이 필요한 리소스에 대한 접근 권한 없음\n403 - Forbidden (금지됨): 접근이 거부됨\n404 - Not Found (찾을 수 없음): 요청한 리소스가 서버에서 찾을 수 없음\n405 - Method Not Allowed (허용되지 않은 메서드): 지원되지 않는 HTTP 메서드를 사용했을 때 사용\n429 - Too Many Requests (요청 너무 많음): 클라이언트가 요청 제한을 초과함\n5xx - Server Error (서버 오류)\n500 - Internal Server Error (내부 서버 오류): 서버 내부 오류로 인해 요청을 처리할 수 없음\n502 - Bad Gateway (게이트웨이 오류): 게이트웨이 서버에서 업스트림 서버로의 잘못된 응답 수신\n503 - Service Unavailable (서비스 이용 불가): 서버가 일시적으로 서비스 이용 불가 상태임\n504 - Gateway Timeout (게이트웨이 시간 초과): 게이트웨이 서버가 업스트림 서버로부터 응답을 기다리는 동안 시간 초과 발생","4-적절한-데이터-포맷#4. 적절한 데이터 포맷":"RESTful API에서는 주로 JSON(JavaScript Object Notation)이나 XML(Extensible Markup Language)과 같은 데이터 포맷을 사용합니다. JSON은 경량이며 다양한 프로그래밍 언어에서 지원되기 때문에 널리 사용됩니다. 응답 데이터의 형식은 Accept 헤더를 통해 클라이언트가 지정할 수 있으며, 요청 데이터는 Content-Type 헤더를 통해 서버에게 전달됩니다.","5-적절한-인증과-권한-부여#5. 적절한 인증과 권한 부여":"보안은 모든 API 설계에서 중요한 고려 사항입니다. RESTful API에서는 적절한 인증(Authentication)과 권한 부여(Authorization) 메커니즘을 구현해야 합니다. 대표적인 방법으로는 API 키, OAuth, JWT(Json Web Token) 등이 있습니다. 이를 통해 사용자 인증 및 권한 부여를 제어하고 API의 안전성을 강화할 수 있습니다.","게시물-리소스를-다루는-api#\u003cstrong\u003e게시물 리소스를 다루는 API\u003c/strong\u003e":"모든 게시물 정보를 가져옴: GET /posts 새로운 게시물을 생성함: POST /posts 특정 게시물의 정보를 가져옴: GET /posts/{id} 특정 게시물의 정보를 업데이트함: PUT /posts/{id} 특정 게시물을 삭제함: DELETE /posts/{id}","뉴스-리소스를-다루는-api#\u003cstrong\u003e뉴스 리소스를 다루는 API\u003c/strong\u003e":"모든 뉴스 정보를 가져옴: GET /news 새로운 뉴스를 생성함: POST /news 특정 뉴스의 정보를 가져옴: GET /news/{id} 특정 뉴스의 정보를 업데이트함: PUT /news/{id} 특정 뉴스를 삭제함: DELETE /news/{id}","도서-리소스를-다루는-api#\u003cstrong\u003e도서 리소스를 다루는 API\u003c/strong\u003e":"모든 도서 정보를 가져옴: GET /books 새로운 도서를 생성함: POST /books 특정 도서의 정보를 가져옴: GET /books/{id} 특정 도서의 정보를 업데이트함: PUT /books/{id} 특정 도서를 삭제함: DELETE /books/{id} 특정 도서의 모든 리뷰 정보를 가져옴: GET /books/{id}/reviews 특정 도서에 새로운 리뷰를 생성함: POST /books/{id}/reviews 특정 도서의 특정 리뷰 정보를 가져옴: GET /books/{id}/reviews/{review_id} 특정 도서의 특정 리뷰 정보를 업데이트함: PUT /books/{id}/reviews/{review_id} 특정 도서의 특정 리뷰를 삭제함: DELETE /books/{id}/reviews/{review_id}","마치며#마치며":"RESTful API 설계는 일관성과 확장성을 고려하여 자원 기반 URI, HTTP 동사 활용, 적절한 상태 코드 반환, 적절한 데이터 포맷, 적절한 인증과 권한 부여 등의 원칙을 따라야 합니다. 이러한 원칙을 준수하면 API의 사용성과 유지보수성이 향상되며, 개발자와 클라이언트 간의 협업을 원활하게 할 수 있습니다. RESTful API 설계는 웹 애플리케이션의 핵심 부분이므로, 항상 최선의 노력을 기울여야 합니다.","사용자-리소스를-다루는-api#\u003cstrong\u003e사용자 리소스를 다루는 API\u003c/strong\u003e":"모든 사용자 정보를 가져옴: GET /users 새로운 사용자를 생성함: POST /users 특정 사용자의 정보를 가져옴: GET /users/{id} 특정 사용자의 정보를 업데이트함: PUT /users/{id} 특정 사용자를 삭제함: DELETE /users/{id} 특정 사용자의 모든 포스트 정보를 가져옴: GET /users/{id}/posts 특정 사용자에게 새로운 포스트를 생성함: POST /users/{id}/posts 특정 사용자의 특정 포스트 정보를 가져옴: GET /users/{id}/posts/{post_id} 특정 사용자의 특정 포스트 정보를 업데이트함: PUT /users/{id}/posts/{post_id} 특정 사용자의 특정 포스트를 삭제함: DELETE /users/{id}/posts/{post_id} 특정 사용자의 정보 일부를 업데이트함: PATCH /users/{id} 특정 사용자의 특정 포스트 정보 일부를 업데이트함: PATCH /users/{id}/posts/{post_id}","상품-리소스를-다루는-api#\u003cstrong\u003e상품 리소스를 다루는 API\u003c/strong\u003e":"모든 상품 정보를 가져옴: GET /products 새로운 상품을 생성함: POST /products 특정 상품의 정보를 가져옴: GET /products/{id} 특정 상품의 정보를 업데이트함: PUT /products/{id} 특정 상품을 삭제함: DELETE /products/{id}","이벤트-리소스를-다루는-api#\u003cstrong\u003e이벤트 리소스를 다루는 API\u003c/strong\u003e":"모든 이벤트 정보를 가져옴: GET /events 새로운 이벤트를 생성함: POST /events 특정 이벤트의 정보를 가져옴: GET /events/{id} 특정 이벤트의 정보를 업데이트함: PUT /events/{id} 특정 이벤트를 삭제함: DELETE /events/{id} 특정 이벤트의 모든 참가자 정보를 가져옴: GET /events/{id}/participants 특정 이벤트에 새로운 참가자를 추가함: POST /events/{id}/participants 특정 이벤트의 특정 참가자 정보를 가져옴: GET /events/{id}/participants/{participant_id} 특정 이벤트의 특정 참가자 정보를 업데이트함: PUT /events/{id}/participants/{participant_id} 특정 이벤트의 특정 참가자를 삭제함: DELETE /events/{id}/participants/{participant_id}","주문-리소스를-다루는-api#\u003cstrong\u003e주문 리소스를 다루는 API\u003c/strong\u003e":"모든 주문 정보를 가져옴: GET /orders 새로운 주문을 생성함: POST /orders 특정 주문의 정보를 가져옴: GET /orders/{id} 특정 주문의 정보를 업데이트함: PUT /orders/{id} 특정 주문을 삭제함: DELETE /orders/{id}","프로필-리소스를-다루는-api#\u003cstrong\u003e프로필 리소스를 다루는 API\u003c/strong\u003e":"모든 프로필 정보를 가져옴: GET /profiles 새로운 프로필을 생성함: POST /profiles 특정 프로필의 정보를 가져옴: GET /profiles/{id} 특정 프로필의 정보를 업데이트함: PUT /profiles/{id} 특정 프로필을 삭제함: DELETE /profiles/{id}"},"title":"Rest Full API"},"/temp/servlet/":{"data":{"":"%20image%2020240214041835.png) 일반적으로 java 진영에서 많이 사용됨 소켓 연결 http 파싱후 읽기 등 일반적으로 동일한 방식의 http 방식의 처리를 객체화 하여 쉽게 처리하게 해줌\n사용자 입장에서 비지니스 로직 파트만 실행될 수 있게 한다\nHttpServletRequest 요청된 http 정보를 객체화 오버라딩해서 사용 HttpServletResponse 응답용 http 정보를 객체화됨"},"title":"servlet"},"/temp/shell-%EC%9D%98-%EB%A1%9C%EA%B7%B8%EC%9D%B8-%EA%B3%BC%EC%A0%95/":{"data":{"":"linux bash 기준으로 설명","interactive-shell-vs-non-interactive-shell#Interactive Shell vs non Interactive Shell":"타 프로그래밍 언어와의 큰 차이이다 interactive Shell 은 python 명령어 입력시 나타나는 것과 비슷한 것으로 사용자 입력을 순차적으로 입력 받을 수 있는 방식이다 이에 반해 non interactive shell 은 python hello.py 같이 실행한다\n특수 메개 변수\n$1, $2, $3, …는 위치 매개변수 입니다 . \"$@\"모든 위치 매개변수의 배열과 유사한 구성입니다 {$1, $2, $3 ...}. \"$*\"는 모든 위치 매개변수의 IFS 확장입니다 $1 $2 $3 .... $#위치 매개변수의 수입니다. $-쉘에 설정된 현재 옵션. $$현재 쉘의 pid(서브쉘 아님) $_가장 최근 매개변수(또는 시작 후 즉시 현재 쉘을 시작하는 명령의 절대 경로). $IFS(입력) 필드 구분 기호입니다. $?가장 최근의 포그라운드 파이프라인 종료 상태입니다. $!가장 최근 백그라운드 명령의 PID입니다. $0쉘 또는 쉘 스크립트의 이름입니다","login-shell-vs-non-login-shell#Login Shell vs non Login Shell":"Login Shell : ssh, x 윈도우 접속시 userid passwd 입력해서 들어가는 방법 Non Longin Shell : 이미 다른 로그인 된 shell 에서 shell 을 fork 형태로 불러내는 방법"},"title":"shell 의 로그인 과정"},"/temp/spring-@autowired-%EC%9D%98%EC%A1%B4%EA%B4%80%EA%B3%84-%EC%A3%BC%EC%9E%85%EC%8B%9C-%EC%A4%91%EB%B3%B5-%EB%AC%B8%EC%A0%9C/":{"data":{"":"Autowired 어노테이션을 통해 어떠한 객체를 생성할 spring에서 의존 관계를 자동으로 주입해 준다 이때 조회되는 빈이 2개 이상이라면 즉 동일한 부모타입의 객체가 2개가 중복으로 등록되었다면 다음의 3가지 방법으로 해결한다 조회 대상 빈이 2개 이상일 때 해결 방법\n@Autowired 필드 명 매칭 @Qualifier -\u003e @Qualifier끼리 매칭 빈 이름 매칭 @Primary 사용"},"title":"spring @Autowired 의존관계 주입시 중복 문제"},"/temp/spring-bean-%EC%A1%B0%ED%9A%8C/":{"data":{"":"![](../08.media/20240202105604.png|spring bean 조회-20240202105604)\n최상위 BeanFactory 인터페이스를 구현한 모든 클래스들은 bean 들을 관리하는 컨테이너이다 HierarchicalBeanFactory: 빈 계층구조 관리 ListableBeanFactory : 빈 여러개 조회 가능 ApplicationContext : 컨테이너 + 기능추가 AnnotationConfigApplicationContext : 어노테이션을 설정 정보로 하는 컨테이너\n이때 컨테이너에 존재하는 bean 들을 조회하는 방법이다\nclass BeanFactory: //최상위 컨테이너 T getBean(Class\u003cT\u003e requiredType); // 타입으로 조회 Object getBean(String name); // 이름으로 조회 T getBean(Class\u003cT\u003e requiredType, Object... args); //이름과 타입으로 조회 ============= class ListableBeanFactory: // 여러개 조회가능 컨테이너 int getBeanDefinitionCount() //팩토리에 정의된 빈 개수를 반환합니다. String getBeanDefinitionNames() //이 팩토리에 정의된 모든 Bean의 이름을 반환합니다. \u003cT\u003e Map\u003cString,T\u003e getBeansOfType(Class \u003cT\u003e type) //타입으로 모든 Bean 조회 추가적으로 bean들의 설정 정보를 담고 있는 BeanDefinition 클래스가 있다 getRole(), 등등의 설정 정보를 담고 있는 클래스이다 getBeanDefinition() 메서드를 통해 얻을 수 있다"},"title":"spring bean 조회"},"/temp/spring-bean-scope/":{"data":{"":"","싱글톤-내부-의존관계로-프로토타입-스코프의-bean-을-가질때#싱글톤 내부 의존관계로 프로토타입 스코프의 bean 을 가질때":"스프링은 다음과 같은 다양한 스코프를 지원한다.\n싱글톤: 기본 스코프, 스프링 컨테이너의 시작과 종료까지 유지되는 가장 넓은 범위의 스코프이다. 프로토타입: 스프링 컨테이너는 프로토타입 빈의 생성과 의존관계 주입까지만 관여하고 더는 관리하지 않는 매우 짧은 범위의 스코프이다. 웹 관련 스코프 request: 웹 요청이 들어오고 나갈때 까지 유지되는 스코프이다. session: 웹 세션이 생성되고 종료될 때 까지 유지되는 스코프이다. application: 웹의 서블릿 컨텍스트와 같은 범위로 유지되는 스코프이다 프로토타입 초기화 메서드 실행되지만 종료 메서드 호출 안됨 사용자가 직접 해야함\n싱글톤 내부 의존관계로 프로토타입 스코프의 bean 을 가질때 싱글톤 객체 내부에 필드로 프로토타입을 가지고 있는경우 서로 다른 scope 성질로 인해 문제가 발생한다 두가지 방식으로 해결\nObjectProvider 로 생성시점을 조절 JSR-330 javax.injectProvider ObjectFatory 부모 ObjectProvider 자식 객체를 생성하는 시기를 getObject() 통해 조절 가능 DL dependency Lookup 스프링 의존적\njava 표준을 사용 jakarta.inject.Provider JSR-330 자바 표준 import jakarta.inject.Provider; implementation ‘jakarta.inject:jakarta.inject-api:2.0.1’","웹-스코프#웹 스코프":"웹 스코프의 특징 웹 스코프는 웹 환경에서만 동작한다. 웹 스코프는 프로토타입과 다르게 스프링이 해당 스코프의 종료시점까지 관리한다. 따라서 종료 메서드가 호출된 다. 웹 스코프 종류 request: HTTP 요청 하나가 들어오고 나갈 때 까지 유지되는 스코프, 각각의 HTTP 요청마다 별도의 빈 인스턴 스가 생성되고, 관리된다. session: HTTP Session과 동일한 생명주기를 가지는 스코프 application: 서블릿 컨텍스트( ServletContext )와 동일한 생명주기를 가지는 스코프 websocket: 웹 소켓과 동일한 생명주기를 가지는 스코프","프로토타입#프로토타입":""},"title":"spring bean scope"},"/temp/spring-life-cycle/":{"data":{"":"스프링 빈의 이벤트 라이프사이클 스프링 컨테이너 생성 -\u003e 스프링 빈 생성 -\u003e 의존관계 주입 -\u003e 초기화 콜백 -\u003e 사용 -\u003e 소멸전 콜백 -\u003e 스프링 종료\n스프링빈 생성시 생성자 의존관계일떄는 같이 설정정보(xml, java etc)를 바탕으로 빈을 관리하는 컨테이너를 생성","설정정보-초기화-메서드#설정정보 초기화 메서드":"수동 등록에서만 가능\n@Bean (initMethod = \"init\", destoryMethod = \"close\") // 메서드 이름을 자신이 설정 일반적으로 라이브러리들의 종료 메서드는 close, shutdown destoryMethod 의 default 값은 (infered) 추론으로 자동으로 라이브러리의 종료 메서드를 불러준다","수동#수동":"@Configuration // 중복되는 객체생성을 막아준다 public class AppConfig { @Bean public MemberService memberService(){ return new MemberServiceImpl(memberRepository());} @Bean public OrderService orderService(){ return new OrderServiceImpl(memberRepository(), discountPolicy()); //필드 주입을 한다면 필요 없음} @Bean public DiscountPolicy discountPolicy() { return new RateDiscountPolicy();} @Bean public MemberRepository memberRepository() { return new MemoryMemberRepository();} } @Configration 바이트 조작 기술을 통해 중복되는 객체(memberRepository) 생성을 1개만 생성해 공유해 준다 @Bean 메서드 수준의 어노테이션을 통해 return 되는 값을 객체로 만들어준다","스프링-빈-생성--의존관계-주입#스프링 빈 생성 \u0026amp; 의존관계 주입":"","어노테이션#어노테이션":"@PostConstruct @PreDestroy\n자동 등록 컴포넌트 스캔과 잘 어울림","인터페이스#인터페이스":"스프링 의존 설계 InitializingBean -\u003e afterPropertiesSet 구현 DisposableBean -\u003e destory 구현","자동#자동":"@Component public class OrderServiceImpl implements OrderService{ private final MemberRepository memberRepository; private final DiscountPolicy discountPolicy; @Autowired public OrderServiceImpl(MemberRepository memberRepository, DiscountPolicy discountPolicy){ this.memberRepository = memberRepository; this.discountPolicy = discountPolicy; } ... } @Configuration @ComponentScan public class AutoAppconfig { } 실제 객체를 만들고 싶은 클래스에 @Component 어노테이션을 통해 이 클래스로부터 생성되는 객체를 spring bean 으로 등록하고 싶음을 알린다 @Autowired 어노테이션을 통해 의존관계를 주입 @Component 어노테이션을 통해 @Component 를 탐색","초기화-콜백--소멸전-콜백#초기화 콜백 \u0026amp; 소멸전 콜백":"스프링은 크게 3가지 방법으로 빈 생명주기 콜백을 지원한다.\n인터페이스(InitializingBean, DisposableBean) 설정 정보에 초기화 메서드, 종료 메서드 지정 @PostConstruct, @PreDestroy 애노테이션 지원"},"title":"spring life cycle"},"/temp/sql-%ED%8B%80%EB%A6%B0%EB%AC%B8%EC%A0%9C/":{"data":{"":"","leetcode-1661#leetcode 1661":"leetcode 원본 문제 링크\ngroup by 에서 새로운 relation 이 생성된다고 생각하고 참여하지 않은 attribute 는 사용할 수 없다고 생각한다면 아래와 같은답을 내였다\nselect d.machine_id, round(sum(d.timesub)/count(d.timesub),3) as processing_time from ( select a.machine_id, a.process_id, round(b.timestamp - a.timestamp, 3) as timesub from Activity as a join Activity as b where a.machine_id = b.machine_id and a.process_id = b.process_id and a.activity_type = 'start' and b.activity_type = 'end' ) as d group by d.machine_id 하지만 group by 에서 참여하지 않은 attribute 도 사용할 수 있다면 또한 문제에 제시된 답은 아래답이다\nselect a.machine_id, round(avg(b.timestamp - a.timestamp),3) as processing_time from Activity as a join Activity as b where a.machine_id = b.machine_id and a.process_id = b.process_id and a.activity_type = 'start' and b.activity_type = 'end' group by a.machine_id 하지만 위의 2개 접근 (사실은 동일한 접근) 은 두개의 table을 조인 연산하여 select 문에서 산술연산을 통해 processing_time 을 산출 하는 것이 주된 접근으로 보이는데 사실은 두개의 table 을 join 하지 않고도 case 문 일종의 if 문으로 계산이 가능하다","not-in-문제#not in 문제":"visits table and transactions table 이 존재 방문했지만 거래를 하지 않은 고객을 식별하려면 방문한 모든 고객의 목록에서 거래를 한 고객의 기록을 제거해야 합니다. 이를 통해 이 문제를 일반적인 “NOT IN” 문제로 변환합니다. “NOT IN” 문제를 해결하는 방법은 크게 두 가지입니다:\nNOT IN/EX와 유사한 기능을 직접 사용하거나 오른쪽 테이블이 NULL로 설정된 LEFT OUTER JOIN 입니다. -- left outer join select customer_id, count(visit_id) as count_no_trans from visits left join transactions using(visit_id) where transaction_id is null group by customer_id -- not in select customer_id, count(visit_id) as count_no_trans from visits where visits.visit_id not in (select visit_id from transactions) group by customer_id","null-의-비교연산#null 의 비교연산":"null\nwhere referee_id!=2 or referee_id = null -- 틀린답 이 아닌 where referee_id!=2 or referee_id is null -- 이것이 맞는 답 SQL에서 NULL 값은 특별하게 취급되며, NULL은 ‘값이 없음’을 의미합니다. 따라서, NULL 값은 다른 값들과 일반적인 비교 연산자(=, !=, \u003c, \u003e, 등)로 비교할 수 없습니다. NULL과의 비교는 IS NULL 또는 IS NOT NULL 연산자를 사용해야만 합니다."},"title":"sql 틀린문제"},"/temp/sql-date-%EA%B4%80%EB%A0%A8-%EC%A0%95%EB%A6%AC/":{"data":{"":"sql 에서 제공하는 date 에 관련한 정보를 기술한다","1-date-타입#1. DATE 타입":"DATE 타입은 날짜는 포함하지만 시간은 포함하지 않을 때 사용하는 타입입니다. DATE 타입 YYYY-MM-DD 형식 입력가능하며, ‘1000-01-01’ 부터 ‘9999-12-31’ 까지만 입력가능합니다.","2-datetime-타입#2. DATETIME 타입":"DATETIME 타입은 날짜와 시간을 모두 포함할 때 사용하는 타입입니다. YYYY-MM-DD HH:MM:SS의 형태로 사용되며 ‘1001-01-01 00:00:00’부터 ‘9999-12-31 23:59:59’까지 입력이 가능하다","3-time-타입#3. TIME 타입":"TIME은 HH:MM:SS의 형태를 지닌다.(HHH:MM:SS의 형태를 띄기도 한다) -838:59:59 부터 838:59:59 까지의 범위를 가진다. 이때 TIME type의 시간이 크다고 느낄수도 있다. TIME은 현재의 시간을 표현할때만 쓰는것이 아니라 이미 지나버린 시간이나, 특정 이벤트끼리의 간극을 표현하는데 사용되기 때문에 이처럼 쓰인다.","4-timestamp-타입#4. TIMESTAMP 타입":"TIMESTAMP 역시 날짜와 시간을 포함한다. TIMESTAMP는 1970-01-01 00:00:01 UTC 부터 2038-01-19 03:14:07UTC 까지가 그 범위이다.","관련-함수#관련 함수":"dayofweek(date) 날짜를 한 주의 몇 번째 요일인지를 나타내는 숫자로 리턴한다. (1 = 일요일, 2 = 월요일, … 7 = 토요일) mysql\u003e select dayofweek(‘1998-02-03’); -\u003e 3\nweekday(date) 날짜를 한 주의 몇 번째 요일인지를 나타내는 숫자로 리턴한다. (0 = 월요일, 1=화요일 … 6 = 일요일) mysql\u003e select weekday(‘1997-10-04 22:23:00’); -\u003e 5 mysql\u003e select weekday(‘1997-11-05’); -\u003e 2\ndayofmonth(date) 그 달의 몇 번째 날인지를 알려준다. 리턴 값은 1에서 31 사이이다. mysql\u003e select dayofmonth(‘1998-02-03’); -\u003e 3\ndayofyear(date) 한 해의 몇 번째 날인지를 알려준다. 리턴 값은 1에서 366 사이이다. mysql\u003e select dayofyear(‘1998-02-03’); -\u003e 34\nmonth(date) 해당 날짜가 몇 월인지 알려준다. 리턴 값은 1에서 12 사이이다. mysql\u003e select month(‘1998-02-03’); -\u003e 2\ndayname(date) 해당 날짜의 영어식 요일이름을 리턴한다. mysql\u003e select dayname(“1998-02-05”); -\u003e thursday\nmonthname(date) 해당 날짜의 영어식 월 이름을 리턴한다. mysql\u003e select monthname(“1998-02-05”); -\u003e february\nquarter(date) 분기를 리턴한다 (1~ 4) mysql\u003e select quarter(‘98-04-01’); -\u003e 2\nweek(date) week(date,first) 인수가 하나일 때는 해달 날짜가 몇 번째 주일인지(0 ~ 52)를 리턴하고 2개일 때는 주어진 인수로 한 주의 시작일을 정해 줄 수 있다. 0이면 일요일을 1이면 월요일을 한 주의 시작일로 계산해 몇 번째 주인가 알려준다. mysql\u003e select week(‘1998-02-20’); -\u003e 7 mysql\u003e select week(‘1998-02-20’,0); -\u003e 7 mysql\u003e select week(‘1998-02-20’,1); -\u003e 8\nyear(date) 년도를 리턴한다.(1000 ~ 9999) mysql\u003e select year(‘98-02-03’); -\u003e 1998\nhour(time) 시간을 알려준다.(0 ~ 23) mysql\u003e select hour(‘10:05:03’); -\u003e 10\nminute(time) 분을 알려준다(0 ~ 59) mysql\u003e select minute(‘98-02-03 10:05:03’); -\u003e 5\nsecond(time) 초를 알려준다(0 ~ 59) mysql\u003e select second(‘10:05:03’); -\u003e 3\nperiod_add(p,n) yymm 또는 yyyymm 형식으로 주어진 달에 n개월을 더한다. 리턴 값은 yyyymm의 형식이다. mysql\u003e select period_add(9801,2); -\u003e 199803\nperiod_diff(p1,p2) yymm 또는 yyyymm 형식으로 주어진 두 기간사이의 개월을 구한다 mysql\u003e select period_diff(9802,199703); -\u003e 11\ndate_add(date,interval expr type) date_sub(date,interval expr type) adddate(date,interval expr type) subdate(date,interval expr type)\n위의 함수들은 날자 연산을 한다. 잘 만 사용하면 꽤나 편리한 함수 들이다. 모두 mysql 3.22 버전에서 새롭게 추가되었다. adddate() 과 subdate() 는 date_add() 와 date_sub()의 또 다른 이름이다. 인수로 사용되는 date 는 시작일을 나타내는 datetime 또는date 타입이다. expr 는 시작일에 가감하는 일수 또는 시간을 나타내는 표현식이다.\ntype 값의 의미 사용 예 second, seconds 초\nminute, minutes 분 hour, hours 시간\nday, days 일\nmonth, months 월\nyear, years\n년 minute_second, “minutes:seconds” 분:초\nhour_minute, “hours:minutes” 시:분\nday_hour, “days hours” 일 시\nyear_month, “years-months” 년 월\nhour_second, “hours:minutes:seconds” 시 분\nday_minute, “days hours:minutes” 일, 시, 분\nday_second, “days hours:minutes:seconds” 일, 시, 분, 초\n[예제] mysql\u003e select date_add(“1997-12-31 23:59:59”,interval 1 second); -\u003e 1998-01-01 00:00:00 mysql\u003e select date_add(“1997-12-31 23:59:59”,interval 1 day); -\u003e 1998-01-01 23:59:59 mysql\u003e select date_add(“1997-12-31 23:59:59”,interval “1:1” minute_second); -\u003e 1998-01-01 00:01:00 mysql\u003e select date_sub(“1998-01-01 00:00:00”,interval “1 1:1:1” day_second); -\u003e 1997-12-30 22:58:59 mysql\u003e select date_add(“1998-01-01 00:00:00”,interval “-1 10” day_hour); -\u003e 1997-12-30 14:00:00 mysql\u003e select date_sub(“1998-01-02”, interval 31 day); -\u003e 1997-12-02\nto_days(date) 주어진 날짜를 0000년부터의 일수로 바꾼다. mysql\u003e select to_days(950501); -\u003e 728779 mysql\u003e select to_days(‘1997-10-07’); -\u003e 729669\nfrom_days(n) 주어진 일수 n로부터 날짜를 구한다 mysql\u003e select from_days(729669); -\u003e ‘1997-10-07’\ndate_format(date,format) format 의 정의에 따라 날자 혹은 시간을 출력한다. 매우 빈번히 쓰이는 함수 이다. format 에 사용되는 문자는 다음과 같다. **%m\n월이름 (january..december) %w\n**요일명 (sunday..saturday) %d\n영어식 접미사를 붙인 일(1st, 2nd, 3rd, etc.) %y 4자리 년도 %y\n2자리 년도 %a\n짧은 요일명(sun..sat) **%d\n**일(00..31) %e\n일(0..31) **%m\n**월(01..12) **%c\n**월(1..12) %b\n짧은 월이름 (jan..dec) **%j\n**한해의 몇 번째 요일인가 (001..366) **%h\n**24시 형식의 시간 (00..23) **%k\n**24시 형식의 시간 (0..23) **%h\n**12시 형식의 시간 (01..12) %i\n12시 형식의 시간 (01..12) **%l\n**시간 (1..12) **%i\n**분 (00..59) %r\n시분초12시 형식 (hh:mm:ss [ap]m) **%t\n**시분초 24시 형식 (hh:mm:ss) **%s\n**초 (00..59) **%s\n**초 (00..59) **%p\n**am 또는 pm 문자 %w\n일주일의 몇 번째 요일인가(0=sunday..6=saturday) **%U\n**한해의 몇 번째 주인가(0..52). 일요일이 시작일 %u\n한해의 몇 번째 주인가(0..52). 월요일이 시작일 %%\n`%’ 문자를 나타냄 위 표에 나와 있는 것들을 제외한 모든 문자는 그냥 그대로 출력된다.\nmysql\u003e select date_format(‘1997-10-04 22:23:00’, ‘%w %m %y’); -\u003e ‘saturday october 1997’ mysql\u003e select date_format(‘1997-10-04 22:23:00’, ‘%h:%i:%s’); -\u003e ‘22:23:00’ mysql\u003e select date_format(‘1997-10-04 22:23:00’,’%d %y %a %d %m %b %j’); -\u003e ‘4th 97 sat 04 10 oct 277’ mysql\u003e select date_format(‘1997-10-04 22:23:00’,’%h %k %i %r %t %s %w’); -\u003e ‘22 22 10 10:23:00 pm 22:23:00 00 6’\n주의! : mysql 3.23 버전부터 % 기호가 각 형식문자 앞에 필요하게 되었다 그 이전 버전에서는 선택 사항이다.\ntime_format(time,format) 이 함수는 date_format()와 비슷한 역할을 하지만 단지 시,분,초 만을 나타낼 수 있다는 점이다. curdate() current_date()\n오늘 날짜를 ‘yyyy-mm-dd’ 또는 yyyymmdd 형식으로 리턴한다, 리턴 값은 이 함수가 문자열로 쓰이느냐 숫자로 쓰이느냐에 따라 달라진다. mysql\u003e select curdate(); -\u003e ‘1997-12-15’\nmysql\u003e select curdate() + 0; -\u003e 19971215\ncurtime() current_time() ‘hh:mm:ss’ 또는 hhmmss 형식으로 현재시간을 나타낸다. 리턴 값은 이 함수가 문자열로 쓰이느냐 숫자로 쓰이느냐에 따라 달라진다. mysql\u003e select curtime(); -\u003e ‘23:50:26’ mysql\u003e select curtime() + 0; -\u003e 235026\nnow() sysdate() current_timestamp() 오늘 날자와 현재 시간을 ‘yyyy-mm-dd hh:mm:ss’ 또는 yyyymmddhhmmss 형식으로 리턴 한다, 역시 리턴 값은 이 함수가 문자열로 쓰이느냐 숫자로 쓰이느냐에 따라 달라진다. 실제 개발 시 사용자의 등록일시 등을 나타낼 때 유용하게 쓰이는 함수다. 뒷부분의 실전예제에서 보게 될 것이다. mysql\u003e select now(); -\u003e ‘1997-12-15 23:50:26’ mysql\u003e select now() + 0; -\u003e 19971215235026\nunix_timestamp() unix_timestamp(date) 인수가 없이 사용될 경우 현재 시간의 유닉스 타임스탬프를 리턴하고 만일 날짜형식의 date 가 인수로 주어진 경우에는 주어진 날짜의 유닉스 타임스탬프를 리턴한다 유닉스 타임스탬프 란 그리니치 표준시로 1970 년 1월 1일 00:00:00 이 후의 시간경과를 초단위로 나타낸 것이다. mysql\u003e select unix_timestamp(); -\u003e 882226357 mysql\u003e select unix_timestamp(‘1997-10-04 22:23:00’); -\u003e 875996580\n주의 : 만일 unix_timestamp함수가 timestamp 컬럼 에서 사용될 경우에는 주어진 시간이 타임스탬프로 바뀌지 않고 그대로 저장된다.\nfrom_unixtime(unix_timestamp) 주어진 유닉스 타임스탬프 값으로부터 ‘yyyy-mm-dd hh:mm:ss’ 또는 yyyymmddhhmmss 형식의 날짜를 리턴한다. mysql\u003e select from_unixtime(875996580); -\u003e ‘1997-10-04 22:23:00’ mysql\u003e select from_unixtime(875996580) + 0; -\u003e 19971004222300\nfrom_unixtime(unix_timestamp,format) 주어진 유닉스 타임스탬프 값을 주어진 날짜 형식에 맞게 바꿔서 보여준다. 여기서 사용되는 형식문자는 date_format() 함수에서 사용된 것과 같다. 아래 예에서 %x 는 형식문자가 아니므로 그냥 x 가 표시됨에 유의하기 바란다. mysql\u003e select from_unixtime(unix_timestamp(), ‘%y %d %m %h:%i:%s %x’); -\u003e ‘1997 23rd december 03:43:30 x’\nsec_to_time(seconds) 주어진 초를 ‘hh:mm:ss’ 또는 hhmmss 형식의 시간단위로 바꿔준다. mysql\u003e select sec_to_time(2378); -\u003e ‘00:39:38’ mysql\u003e select sec_to_time(2378) + 0; -\u003e 3938\ntime_to_sec(time) 주어진 시간을 초 단위로 바꿔준다.\nmysql\u003e select time_to_sec(‘22:23:00’); -\u003e 80580 mysql\u003e select time_to_sec(‘00:39:38’); -\u003e 2378\n[예제]\n쿼리문으로 날짜계산\n$query = “SELECT (now() - interval ′1 month′)::timestamp”; // 현재 부터 한 달 전 날짜 $query = “SELECT (now() + interval ′6 month′)::timestamp”; // 현재 부터 6 달 후 날짜 … [Q/A] mysql에서 타임스탬프값을 날짜값으로 바꿔주는 함수 있나요?\nselect from_unixtime(날짜필드) … 하시면 우리가 보는 시간으로 보일거예요~ [MySQL에서 제공하는 날자 관련 함수] DAYOFMONTH(date) : 날짜만 리턴해주는 함수. (1-31) 한달을 단위로.\nDAYOFYEAR(date) : 이역시 날짜만 리턴. (1-366) 1년을 단위로.\nTO_DAYS(date) : 연도와 달을 모두 날짜화 시켜서 리턴해줍니다.\n(1999-01-01 = (1999 * 365) + (01 * 31) + 1)\nMONTH(date) : 달을 리턴해주는 함수.\nDAYNAME(date) : 요일을 문자로 리턴. (ex :‘Thursday’)\nMONTHNAME(date) : 달을 문자로 리턴. (ex :‘February’)\nWEEK(date) : 해당 연도에 몇번째 주인지를 리턴 (0-52)\nYEAR(date) : 연도를 리턴 (1000-9999)\nHOUR(time) : 시간 리턴 MINUTE(time) : 분 리턴\nSECOND(time) : 초 리턴\nDATE_FORMAT(date,format)\n%W' Weekday name (Sunday’..Saturday') %D’ Day of the month with english suffix (1st', 2nd’, 3rd', etc.) %Y’ Year, numeric, 4 digits\n%y' Year, numeric, 2 digits %a’ Abbreviated weekday name (Sun'..Sat’)\n%d' Day of the month, numeric (00’..31') %e’ Day of the month, numeric (0'..31’)\n%m' Month, numeric (01’..12') %c’ Month, numeric (1'..12’)\n%b' Abbreviated month name (Jan’..Dec') %j’ Day of year (001'..366’)\n%H' Hour (00’..23') %k’ Hour (0'..23’)\n%h' Hour (01’..12') %I’ Hour (01'..12’)\n%l' Hour (1’..12') %i’ Minutes, numeric (00'..59’)\n%r' Time, 12-hour (hh:mm:ss [AP]M’)\n%T' Time, 24-hour (hh:mm:ss’)\n%S' Seconds (00’..59') %s’ Seconds (00'..59’)\n%p' AM’ or PM' %w’ Day of the week (0'=Sunday..6’=Saturday)\n%U' Week (0’..52'), Sunday is the first day of the week. %u’ Week (0'..52’), Monday is the first day of the week.\n%%' Single %’ characters are ignored. Use %%' to produce a literal %’ (for future extensions).","자료형#자료형":""},"title":"sql date 관련 정리"},"/temp/srg%EA%B7%B8%EB%9E%98%ED%94%BD-%EB%9E%9C%EB%8D%94%EB%A7%81-%EC%84%A0%ED%83%9D-escape-sequence/":{"data":{"":"SGR(Select Graphic Rendition)\n이것을 이해하기 위해 wiki 에는 이렇게 나와 있다\nANSI 이스케이프 시퀀스는 비디오 텍스트 터미널 과 터미널 에뮬레이터 에서 커서 위치, 색상, 글꼴 스타일 및 기타 옵션을 제어하기 위한 인 밴드 신호 표준\n즉 cli 환경에서 커서 위치, 색상, 글꼴 스타일 등등의 옵션을 제어하기 위한 표준이라고 나와있다"},"title":"SRG(그래픽 랜더링 선택) escape sequence"},"/temp/stateful-%EA%B3%BC-stateless-%ED%94%84%EB%A1%9C%ED%86%A0%EC%BD%9C/":{"data":{"":"stateful : TCP, FTP stateless : udp http … ==stateful 구조는 server와 client 세션의 state(상태)에 기반하여 client 에 response 를 보낸다== 즉 server 측 client 모두 state 를 저장한다 (참조 네트워크 스텍)\nstateless : 보내고 아몰랑??","statless-http-프로토콜의-연결-상태-구현#statless http 프로토콜의 연결 상태 구현":"cookie 를 통해 클라이언트 측에만 상태를 강제로 구현함 보안문제\nsession : 연결되었다는 사람이 인지하는 일종의 추상적 개념 ex) 로그인 성공 상태","tcp-프로토콜은-stateful-을-어떻게-구현하는가#TCP 프로토콜은 stateful 을 어떻게 구현하는가":"stateful 을 구현하고자 하는 는 syn.. ack… 두가지 정보의 교환으로 서로의 연결이 되었다는 것을 논리적으로 확인하게 된다 이때 상태 정보가 운영체제에 스텍으로 메모리에 저장된다","결론#결론":"tcp 를 통해 http PDU(massage) 가 전부 전달 되었다는 것만 보장 나머지 로그인 인증 등 과정은 http 에서 확인해야함\nhttp 버전 RFC2068(1997) RFC2616(1999) RFC7230~7235(2014)","궁금증#궁금증":"http(stateless) 응용계층의 프로토콜은 하위계층(4계층) TCP(stateful) 를 사용한다?? statless http 프로토콜은 연결된 상태를 어떻게 판단 구현하는가?? 2가지에 대해 궁금증이 생겨서 글을 작성하게됨"},"title":"stateful 과 stateless 프로토콜"},"/temp/sudo-vs-su/":{"data":{"":"sudo, sudoedit — 명령을 다른 사용자로 실행합니다\nsu - 대체 사용자 및 그룹 ID를 사용하여 명령을 실행합니다\n3308 3308 3308 pts/1 00:00:00 bash 3519 3519 3308 pts/1 00:00:00 sudo 3520 3520 3520 pts/3 00:00:00 sudo 3521 3521 3520 pts/3 00:00:00 su 3522 3522 3520 pts/3 00:00:00 bash 3388 3388 3388 pts/2 00:00:00 bash 3539 3539 3388 pts/2 00:00:00 sudo 3540 3540 3540 pts/4 00:00:00 sudo 3541 3541 3540 pts/4 00:00:00 bash"},"title":"sudo vs su"},"/temp/tmux/":{"data":{"":"tmux는 터미널 멀티플렉서로, 하나의 터미널 창에서 여러 세션을 관리할 수 있게 해줍니다. 아래에 tmux의 기본 사용법(생성, 접근, 종료 등)을 정리해 드릴게요.","-1-tmux-설치-확인-리눅스-기준#🔹 1. tmux 설치 확인 (리눅스 기준)":"tmux -V # 버전 확인 설치가 필요하다면:\n우분투/데비안:\nsudo apt install tmux CentOS:\nsudo yum install tmux macOS (Homebrew):\nbrew install tmux","-2-세션-생성#🔹 2. 세션 생성":"tmux new -s [세션이름] 예시:\ntmux new -s mysession 이렇게 하면 mysession이라는 이름의 새로운 tmux 세션이 시작됩니다.","-3-tmux에서-나가기-detach#🔹 3. tmux에서 나가기 (detach)":"tmux 세션 안에서 나와서도 계속 실행되도록 하려면:\nCtrl + b 를 누른 후 d 를 누릅니다. 즉, Ctrl+b → d 순서로 입력하면 현재 세션에서 분리(detach)됩니다.","-4-실행-중인-세션-보기#🔹 4. 실행 중인 세션 보기":"tmux ls 또는\ntmux list-sessions 출력 예시:\nmysession: 1 windows (created Mon Jan 1 00:00:00 2024) anothersession: 2 windows (created Mon Jan 1 00:05:00 2024)","-5-세션에-다시-접속-attach#🔹 5. 세션에 다시 접속 (attach)":"tmux attach -t [세션이름] 예시:\ntmux attach -t mysession","-6-세션-종료-kill#🔹 6. 세션 종료 (kill)":"","-7-윈도우-및-패널-관리-부가-정보#🔹 7. 윈도우 및 패널 관리 (부가 정보)":"기능 명령어 새 윈도우 만들기 Ctrl + b → c 윈도우 전환 Ctrl + b → n (다음), p (이전) 화면 분할 (수평) Ctrl + b → \" 화면 분할 (수직) Ctrl + b → % 패널 전환 Ctrl + b → o 패널 크기 조절 Ctrl + b → Alt + 방향키","-8-기본-세션-없이-tmux-시작#🔹 8. 기본 세션 없이 tmux 시작":"tmux 이렇게 하면 자동으로 0번 이름의 세션이 생성되고 들어갑니다.\n필요하시면 .tmux.conf 설정 파일 예제나 고급 사용법도 알려드릴 수 있어요! 😊\n추가 질문 있으신가요?","모든-세션-종료#모든 세션 종료:":"tmux kill-server","특정-세션-종료#특정 세션 종료:":"tmux kill-session -t [세션이름] 예시:\ntmux kill-session -t mysession"},"title":"tmux"},"/temp/transaction-%EC%9D%98-acid/":{"data":{"":"ACID는 데이터베이스 트랜잭션의 신뢰성을 보장하는 네 가지 주요 속성입니다. 각각의 속성을 한 문장으로 요약하고 예시를 들어 설명하겠습니다.","1-원자성-atomicity#1. 원자성 (Atomicity)":"요약: 트랜잭션 내의 모든 작업이 성공적으로 완료되거나, 전혀 수행되지 않아야 한다.\n예시: 은행에서 10,000원을 A 계좌에서 B 계좌로 이체하는 경우, 두 계좌의 잔액이 모두 변경되거나, 하나라도 실패하면 모든 변경이 취소된다.","2-일관성-consistency#2. 일관성 (Consistency)":"요약: 트랜잭션이 완료되면 데이터베이스는 항상 일관된 상태를 유지해야 한다.\n예시: 학생 등록 시스템에서 학생의 성적을 업데이트할 때, 성적이 0 이상 100 이하의 범위를 벗어나지 않도록 보장해야 한다.\nACID 중 C consistency 에는 2가지가 있다\nexplicitly specified ingegrity constraint (pk, fk 조건들 ) implicit ingegrity constraints (비즈니스 로직이나 수학적 관계에 의해서만 존재하는 개념) 직원 table(employee_id, 입사일) 프로젝트 참여 table(project_id,employee_id, 참여일) 일반적으로는 참여일이 입사일보다 빠를 수는 없다 \u003c- implicit ingegrity constraints","3-고립성-isolation#3. 고립성 (Isolation)":"요약: 동시에 실행되는 트랜잭션은 서로 영향을 주지 않도록 격리되어야 한다.\n예시: 두 사용자가 동시에 같은 자원을 수정할 때, 한 사용자의 변경 사항이 다른 사용자에게 영향을 미치지 않도록 보장해야 한다.","4-지속성-durability#4. 지속성 (Durability)":"요약: 트랜잭션이 성공적으로 완료되면, 그 결과는 시스템 오류가 발생하더라도 영구적으로 유지되어야 한다.\n예시: 고객이 온라인 쇼핑몰에서 주문을 완료한 후, 서버가 다운되더라도 주문 정보는 데이터베이스에 안전하게 저장되어야 한다."},"title":"Transaction 의 ACID"},"/temp/vscode-%EC%84%A4%EC%A0%95/":{"data":{"":"keybindings.json\n// Toggle between terminal and editor focus { \"key\": \"ctrl+'\", \"command\": \"workbench.action.terminal.focus\"}, { \"key\": \"ctrl+'\", \"command\": \"workbench.action.focusActiveEditorGroup\", \"when\": \"terminalFocus\"} 터미널 왔다리 갔다리","1-ctrl--space#1. \u003cstrong\u003e\u003ccode\u003eCtrl + Space\u003c/code\u003e\u003c/strong\u003e":"","2-tab#2. \u003cstrong\u003e\u003ccode\u003eTab\u003c/code\u003e\u003c/strong\u003e":"","3-인수-목록parameter-hints#3. \u003cstrong\u003e인수 목록(Parameter Hints)\u003c/strong\u003e":"","4-함수-설명function-documentation#4. \u003cstrong\u003e함수 설명(Function Documentation)\u003c/strong\u003e":"","기능-자동-완성-선택-또는-들여쓰기indentation#\u003cstrong\u003e기능: 자동 완성 선택 또는 들여쓰기(Indentation)\u003c/strong\u003e":"설명: 자동 완성 선택: IntelliSense 제안 목록이 열려 있는 상태에서 Tab 키를 누르면 현재 선택된 제안을 확정하고 코드를 자동으로 완성합니다. 예: pri를 입력한 후 제안 목록에서 print()가 선택된 상태라면 Tab을 누르면 print()로 자동 완성됩니다. 들여쓰기: 코드 블록에서 Tab 키를 누르면 줄을 오른쪽으로 들여씁니다(indent). 반대로 Shift + Tab은 줄을 왼쪽으로 밀어냅니다(unindent).","기능-트리거-제안trigger-suggestions#\u003cstrong\u003e기능: 트리거 제안(Trigger Suggestions)\u003c/strong\u003e":"설명: 현재 커서 위치에서 사용 가능한 코드 제안(Suggestions)을 수동으로 호출합니다. 이는 자동 완성(IntelliSense) 기능을 강제로 활성화하는 역할을 합니다. 예를 들어, 변수 이름이나 함수 이름을 입력 중일 때, VSCode가 자동으로 제안을 보여주지 않는 경우에 Ctrl + Space를 눌러 명시적으로 제안 목록을 열 수 있습니다. 제안 목록에는 변수, 함수, 클래스, 메서드 등이 포함됩니다.","기능-함수-또는-메서드에-대한-문서documentation-표시#\u003cstrong\u003e기능: 함수 또는 메서드에 대한 문서(Documentation) 표시\u003c/strong\u003e":"설명: 특정 함수나 메서드에 대한 상세 설명을 확인할 수 있습니다. 이 설명에는 함수의 목적, 매개변수, 반환값, 예제 코드 등이 포함될 수 있습니다. 예를 들어, Python에서 len(를 입력하면 len(object) -\u003e int와 같은 설명이 표시되며, 추가적으로 “Return the number of items in a container.“와 같은 문서 내용을 볼 수 있습니다.","기능-함수-또는-메서드의-매개변수-정보-표시#\u003cstrong\u003e기능: 함수 또는 메서드의 매개변수 정보 표시\u003c/strong\u003e":"설명: 함수 또는 메서드를 호출할 때, 인수 목록과 각 매개변수의 타입 및 설명을 툴팁 형태로 표시합니다. 예를 들어, Python에서 print(를 입력하면 print(*objects, sep=' ', end='\\n', file=sys.stdout, flush=False)와 같은 매개변수 정보가 표시됩니다. 이를 통해 함수 호출 시 필요한 인수와 그 순서를 쉽게 파악할 수 있습니다.","단속키#\u003cstrong\u003e단속키\u003c/strong\u003e:":"Windows/Linux: Ctrl + K, Ctrl + I (두 키를 순차적으로 누름) macOS: Command + K, Command + I","단축키#\u003cstrong\u003e단축키\u003c/strong\u003e:":"Windows/Linux: Ctrl + Space macOS: Control + Space","단축키-1#\u003cstrong\u003e단축키\u003c/strong\u003e:":"Windows/Linux/macOS: Tab","단축키-2#\u003cstrong\u003e단축키\u003c/strong\u003e:":"기본적으로 매개변수 힌트는 함수 호출 시 자동으로 표시됩니다. 만약 자동으로 표시되지 않는다면, Ctrl + Shift + Space를 눌러 수동으로 매개변수 힌트를 열 수 있습니다.","단축키-3#\u003cstrong\u003e단축키\u003c/strong\u003e:":"Windows/Linux: Ctrl + Shift + Space macOS: Command + Shift + Space","단축키-4#\u003cstrong\u003e단축키\u003c/strong\u003e:":"기본적으로 함수 이름 위에 마우스를 올리거나, 함수 이름을 입력한 후 잠시 대기하면 자동으로 문서 힌트가 표시됩니다. 수동으로 문서 힌트를 열고 싶다면 Ctrl + K, Ctrl + I를 사용합니다.","요약#요약":"기능 설명 단축키 (Windows/Linux) 단축키 (macOS) 트리거 제안 IntelliSense 제안 목록을 수동으로 호출 Ctrl + Space Control + Space 자동 완성/들여쓰기 제안 목록에서 선택하거나 코드를 들여쓰기 Tab Tab 인수 목록 함수 호출 시 매개변수 정보 표시 Ctrl + Shift + Space Command + Shift + Space 함수 설명 함수 또는 메서드의 문서 및 설명 표시 Ctrl + K, Ctrl + I Command + K, Command + I 위 기능들은 VSCode의 기본 설정을 기준으로 설명되었습니다. 필요에 따라 단축키를 사용자 정의할 수 있으며, File \u003e Preferences \u003e Keyboard Shortcuts (또는 Code \u003e Preferences \u003e Keyboard Shortcuts on macOS)에서 단축키를 변경할 수 있습니다."},"title":"vscode 설정"},"/temp/x86-64-cpu-%EB%A0%88%EC%A7%80%EC%8A%A4%ED%84%B0register%EC%9D%98-%EA%B0%9C%EB%85%90-%EB%B0%8F-%EC%A2%85%EB%A5%98/":{"data":{"":"32bit, 64bit 운영체제에서 32bit, 64bit 는 레지스터 및 데이터 경로의 크기 를 의미한다.\n위 예시에서 AH 는 8bit 운영체제와 호환되는 레지스터라고 이해하면 된다. 운영체제의 발전에 따라, 수행해야할 기능이 많아지면서\n많은 정보를 다룰 수 있도록 새로운 레지스터가 추가되고, 크기도 점점 커졌다.\n* E 는 Extended 의 약자. R은 왜 R인지 모르겠다..\n* CPU의 아키텍쳐에 따라 레지스터의 종류가 다를 수 있다.","범용-레지스터#\u003cstrong\u003e범용 레지스터\u003c/strong\u003e":"==== 범용 레지스터는 연산 결과의 임시 저장, 산술 및 논리 연산, 주소 색인 등 다양한 용도로 사용되는 다목적 레지스터이다.\n종류는 EAX, EBX, ECX, EDX, ESI, EDI, ESP, EBP, EIP 가 있다.\n하지만 이는 관례적으로 사용되는 용도별로 나눠놓은 것으로\n범용 레지스터라는 이름과 같이 프로그래머의 의도, 또는 규약(**stdcall, **Thiscall…****) 따라 다르게 사용될 수 있다.\nEAX/RAX (Accumulator Register, 누산기 레지스터)\n산술, 논리 연산을 담당하는 레지스터로, 함수의 반환값이 이 레지스터에 저장된다. EAX 레지스터의 종류\nRAX: 64비트 (x86-64 아키텍처에서의 확장된 EAX)\nEAX: 32비트 누산기 레지스터\nAX: 16비트의 EAX 레지스터 하위 부분\nAH: AX의 상위 8비트\nAL: AX의 하위 8비트 **EBX/RBX (Base Register, 베이스 레지스터)**메모리 주소를 저장하기 위해 사용되는 레지스터.\n종종 배열이나 문자열과 같은 데이터 구조에 접근하기 위한 기준 포인터로 사용된다. EBX 레지스터의 종류\nRBX: 64비트 (x86-64 아키텍처에서의 확장된 EBX)\nEBX: 32비트 베이스 레지스터\nBX: 16비트의 EBX 레지스터 하위 부분\nBH: BX의 상위 8비트\nBL: BX의 하위 8비트 **ECX/RCX (Count Register, 카운트 레지스터)\n**반복 작업에서 카운터 역할을 수행하는 레지스터이다.\nloop 명령어 사용시 레지스터의 값을 하나씩 감소시키며, 0이 될때까지 반복 작업을 수행한다. ECX 레지스터의 종류\nRCX: 64비트 (x86-64 아키텍처에서의 확장된 ECX)\nECX: 32비트 카운트 레지스터\nCX: 16비트의 ECX 레지스터 하위 부분\nCH: CX의 상위 8비트\nCL: CX의 하위 8비트 **EDX/RDX (Data Register, 데이터 레지스터)\n**EAX 레지스터와 함께 사용하여 큰 수를 연산을 하거나, 그 결과를 저장할 수 있는 레지스터이다.\n64bit 더블워드 연산을 수행할 때에도 사용 가능하다. (div, mul) EDX 레지스터의 종류\nRDX: 64비트 (x86-64 아키텍처에서의 확장된 EDX)\nEDX: 32비트 데이터 레지스터\nDX: 16비트의 EDX 레지스터 하위 부분\nDH: DX의 상위 8비트\nDL: DX의 하위 8비트","세그먼트-레지스터#\u003cstrong\u003e세그먼트 레지스터\u003c/strong\u003e":"메모리를 다른 세그먼트로 나누어 관리하고, 각 세그먼트에 대한 기준 주소를 저장한다.\n세그먼트를 이용함으로써, 물리 메모리를 효율적으로 사용하고 프로그램 간 메모리 격리를 가능하게 한다.\nCS (Code Segment, 코드 세그먼트): 현재 프로그램의 코드가 포함된 세그먼트의 주소를 저장하는 레지스터 DS (Data Segment, 데이터 세그먼트): 데이터가 포함된 세그먼트의 주소를 저장하는 레지스터 SS (Stack Segment, 스택 세그먼트): 스택이 포함된 세그먼트의 주소를 저장하는 레지스터 ES, FS, GS: 추가적인 데이터 세그먼트 주소를 저장하는 레지스터","인덱스-레지스터#\u003cstrong\u003e인덱스 레지스터\u003c/strong\u003e":"메모리 내의 데이터 접근 및 조작에 특화된 레지스터로, SI, DI 는 x86 아키텍쳐에서 범용 레지스터로 분류되기도 한다.\nESI/RSI (Source Index, 소스 인덱스 레지스터)\n데이터 복사, 문자열 연산, 입력/출력 처리 등의 작업에서 소스 데이터의 주소를 가리키는 데 사용된다. ESI 레지스터의 종류\nRSI: 64비트 (x86-64 아키텍처에서의 확장된 ESI)\nESI: 32비트 소스 인덱스 레지스터\nSI: 16비트의 ESI 레지스터 하위 부분 **EDI/RDI (Destination Index, 목적지 인덱스 레지스터)\n**데이터 복사, 문자열 처리, 배열조작 등의 작업에서 목적지 데이터의 메모리 주소를 가리키는데 사용된다. EDI 레지스터의 종류\nRDI: 64비트 (x86-64 아키텍처에서의 확장된 EDI)\nEDI: 32비트 목적지 인덱스 레지스터\nDI: 16비트의 EDI 레지스터 하위 부분","포인터-레지스터#\u003cstrong\u003e포인터 레지스터\u003c/strong\u003e":"스택과 프로그램의 실행 흐름 관리에 사용되는 레지스터로, 메모리 주소가 저장된다.\n**ESP/RSP (Stack Pointer, 스택 포인터 레지스터)\n**프로그램의 스택 메모리 내에서, 현재 스택 최상단 주소를 저장하는 레지스터이다.\n함수 호출, 지역 변수 관리, 함수 내 데이터 저장 및 복구 등의 작업에서 필수적으로 사용된다. ESP 레지스터의 종류\nRSP: 64비트 (x86-64 아키텍처에서의 확장된 ESP)\nESP: 32비트 스택 포인터 레지스터.\nSP: 16비트의 ESP 레지스터 하위 부분. **EBP/RBP (Base Pointer, 베이스 포인터 레지스터)**함수내의 지역 변수와 인자에 일관되고, 쉽게 접근하기 위해 사용되는 포인터 역할 레지스터이다.\n스택 내에서 접근할 부분의 메모리 주소를 저장한다. EBP 레지스터의 종류\nRBP: 64비트 (x86-64 아키텍처에서의 확장된 EBP).\nEBP: 32비트 베이스 포인터 레지스터.\nBP: 16비트의 EBP 레지스터 하위 부분. **EIP/RIP (Instruction Pointer, 명령 포인터)\n**다음에 실행될 명령의 메모리 주소를 저장한다. EIP 레지스터의 종류\nRIP: 64비트 (x86-64 아키텍처)\nEIP: 32비트","플래그-레지스터#\u003cstrong\u003e플래그 레지스터\u003c/strong\u003e":"연산의 결과를 나타내는 플래그들을 포함하고, 특정 프로세서 연산을 제어한다.\nRFLAGS: 64비트 (x86-64 아키텍처) EFLAGS: 32비트 Zero Flag(ZF)\n목적: 작업 결과가 0일 경우 설정한다.\n사용: JZ(Jump-if-zero) 또는 JNZ(Jump-if-not-zero)와 같은 조건부 분기 지시에 일반적으로 사용된다. Sign Flag(SF)\n목적: 작업 결과가 음수일 경우 설정한다.\n사용: 부호화된 산술 연산에서 결과의 부호를 나타낸다. Carry Flag(CF)\n목적: 산술 연산에서 가장 중요한 비트의 수행이 발생할 경우 설정한다(부호가 없는 연산에서 유용함).\n사용: 최소 비트에서 다음 비트로의 오버플로를 나타내기 위해 다중 정밀도 산술에서 사용된다. Overflow Flag(OF)\n목적: 산술 연산으로 인해 부호화된 오버플로가 발생할 경우 설정한다. 즉, 결과가 너무 커서 지정된 비트 수로 표시할 수 없다.\n사용: 서명된 산술 연산에 중요하다. Parity Flag(PF)\n목적: 결과에 설정된 비트 수가 짝수인지 설정한다.\n사용: 오류 검사 및 단순 패리티 검사에 자주 사용된다. Auxiliary Carry Flag(AC)\n목적: BCD(Binary Coded Decimal) 산술에서 사용되는 결과의 하위 절반부터 수행되는 수행이 있는지 설정한다.\n용도: BCD 계산에서 특화된 산술 연산 및 특정 유형의 보정에 유용하다. Interrupt Enable/Disable Flag(IF)\n목적: 하드웨어 인터럽트를 활성화하거나 비활성화하는 데 사용된다.\n사용: CPU가 인터럽트 처리를 제어할 수 있다. Direction Flag(DF)\n목적: 문자열 작업에서 처리 방향(증가 또는 감소)을 제어하기 위해 사용된다.\n사용: 문자열 및 메모리 작업에서 데이터 블록을 통한 이동 방향을 제어한다. 8-bit\n(예: Intel 8080, Zilog Z80)A (Accumulator), B, C, D, E, H, L, SP (Stack Pointer), PC (Program Counter)16-bit\n(예: Intel 8086/8088)AX, BX, CX, DX, SI, DI, BP, SP, CS, DS, ES, SS, IP (Instruction Pointer), Flags32-bit\n(예: Intel 80386)EAX, EBX, ECX, EDX, ESI, EDI, EBP, ESP, CS, DS, ES, SS, FS, GS, EIP (Extended IP), EFlags64-bit\n(예: x86-64 아키텍처)RAX, RBX, RCX, RDX, RSI, RDI, RBP, RSP, CS, DS, ES, SS, FS, GS, RIP (Register IP), RFlags, R8-R15 * 틀린 부분이 있으면 알려주세요"},"title":"x86 64 CPU 레지스터(Register)의 개념 및 종류"},"/temp/zsh-%EC%84%B1%EB%8A%A5-%EC%B8%A1%EC%A0%95/":{"data":{"":"zsh는 측정용 프로파일링 모듈을 가지고 있다. 라는 모듈인데, .zshrc 파일에 설정만 해두면 사용할 수 있다.\n~/.zshrc 파일 가장 상단에 zmodload zsh/zprof 를 적는다. (import라고 생각하자) 그리고 가장 하단에 zprof 라고 적어두자. (이는 세션이 시작될 때 zprof 명령어를 실행한다는 의미와 같다.) 세션 로드가 완료되면 time zsh -i -c echo 명령어를 사용해 측정 결과를 얻자."},"title":"zsh 성능 측정"},"/toss-technical-writing-guide/":{"data":{"":"학습 문서 (learning) 시작하기 문서 : 처음 접하는 기술의 주요 흐름과 개념을 이해하도록 돕는 문서 튜토리얼 문서 : 명확한 목표와 결과물이 있는 단계별 학습 문서 =\u003e FAQ 섹션 제공 =\u003e 접어둘 수 있는 컴포넌트 활용 문제 해결을 위한 문서 작성 가이드 🛠 (troubleshooting) How-to 가이드 : 특정 기능 구현이나 작업 수행을 위한 단계별 절차 트러블슈팅 문서 : 발생한 문제를 진단하고 해결하기 위한 디버깅 과정 안내 참조 문서 작성 가이드 📑 (reference) 정확성과 완전성 확보 일관된 구조 유지 쉬운 검색 및 탐색 지원 실용적인 예제 코드 제공 깊은 이해를 위한 설명 문서 작성 가이드 📚 (explanation) 배경 및 맥락 제공 시각 자료 적극 활용","1-개념-이해를-위한-문서-예시#1. 개념 이해를 위한 문서 예시":"특정 개념의 원리와 작동 방식을 설명하는 문서는 기본적인 원리부터 응용까지 다루며, 독자가 개념을 깊이 이해하도록 돕는 것이 핵심입니다. 첫 번째 예시는 React의 가상 DOM 작동 원리를 설명하는 문서입니다.","1-기본-개념#1. 기본 개념":"커머스 도메인은 다음과 같은 핵심 요소로 구성됩니다.\n상품(Product): 판매하는 물품이나 서비스\n주문(Order): 소비자가 상품을 구매하는 행위\n결제(Payment): 거래 대금을 처리하는 과정\n배송(Shipping): 상품을 소비자에게 전달하는 절차\n소비자(Consumer): 상품이나 서비스를 구매하는 사람\n판매자(Seller): 상품이나 서비스를 제공하는 사람\n이 요소들은 서로 긴밀하게 연결되어 있습니다. 예를 들어, 주문(Order)이 생성되면 결제(Payment)가 진행되고, 결제가 완료되면 배송(Shipping) 절차가 시작됩니다.","1-막힘없는-진행-보장#1. 막힘없는 진행 보장":"독자가 따라하다가 막히거나 오류가 발생하지 않도록 안정적인 학습 환경을 만들어야 합니다. 모든 예제 코드는 실제로 실행하여 검증하고, 필요한 준비 사항도 꼼꼼히 안내해야 합니다.","1-명확한-문제-상황-정의#1. 명확한 문제 상황 정의":"문제가 발생한 원인과 그로 인해 나타난 현상을 구분하여 설명하세요.\n에러 메시지, 로그 예시를 포함하면 독자가 문제를 더 쉽게 이해할 수 있습니다.","1-배경-및-맥락-제공#1. 배경 및 맥락 제공":"기술이 등장한 이유와 해결하려는 문제를 먼저 설명하세요.\n독자가 해당 기술을 왜 선택해야 하는지 납득할 수 있도록 설득력 있게 서술하세요.","1-정확성과-완전성-확보#1. 정확성과 완전성 확보":"문서에 포함된 모든 정보는 정확해야 하며, 누락된 부분이 없어야 합니다. 기술적 오류나 모호한 설명은 피하고, 항상 최신 상태를 유지해야 합니다.","1-패키지-설치-여부-확인#1. 패키지 설치 여부 확인":"이 에러는 React 패키지가 설치되어 있지 않거나, node_modules 디렉토리 내에 해당 모듈이 존재하지 않을 때 발생합니다. 터미널에서 아래 명령어를 실행하여 React 패키지가 설치되어 있는지 확인하세요.\nBash\nnpm list react","1단계-프로젝트-생성#1단계: 프로젝트 생성":"터미널을 열고 다음 명령어를 입력하여 React 프로젝트를 생성합니다. my-app 대신 원하는 프로젝트 이름을 사용할 수 있습니다.\nBash\nnpx create-react-app my-app cd my-app","2-단계별-설명-제공#2. 단계별 설명 제공":"독자가 차근차근 진행할 수 있도록 문서를 단계별로 구조화하세요. 예제도 간단한 것부터 점진적으로 난이도를 높여 제시하는 것이 효과적입니다.","2-도메인-문서-예시#2. 도메인 문서 예시":"다음은 특정 도메인에 대한 이해를 돕는 문서입니다. 독자가 도메인을 깊이 이해할 수 있도록 돕는 것이 핵심입니다. 아래 예시를 참고하여 본인의 서비스가 다루는 도메인(예: 커머스, 금융, 소셜 미디어 등)에 대한 문서를 작성해 보세요.","2-바로-적용-가능한-해결-방법-제공#2. 바로 적용 가능한 해결 방법 제공":"해결 방법은 명확하고 즉시 적용 가능해야 합니다.\n코드 예제, 명령어, 설정 방법을 포함하세요.\n해결책이 어떤 원리로 문제를 해결하는지 언급하면 좋습니다.","2-시각-자료-적극-활용#2. 시각 자료 적극 활용":"복잡한 개념은 다이어그램, 흐름도, 표 등을 사용해 시각화하세요.\n전체적인 구조, 데이터 흐름 또는 컴포넌트 구조는 시각적으로 보여주면 더 직관적으로 이해할 수 있습니다.","2-유저-행동-흐름#2. 유저 행동 흐름":"소비자가 상품을 구매할 때의 주요 과정은 다음과 같습니다.\n상품 탐색 및 장바구니 추가: 소비자는 원하는 상품을 선택하고 장바구니에 추가합니다.\n주문 및 결제 진행: 장바구니에서 주문을 확정하고 결제를 진행합니다.\n결제 승인 및 주문 확정: 결제가 승인되면 주문이 확정됩니다.\n배송 준비 및 출고: 판매자가 주문을 확인하고 상품을 포장한 후 출고합니다.\n소비자에게 상품 도착: 택배 또는 다른 배송 수단을 통해 소비자에게 상품이 전달됩니다.\n이 과정에서 결제 승인 오류, 재고 부족, 배송 지연 등의 예외 상황이 발생할 수 있습니다. 개발자는 이런 예외 처리를 고려해 로직을 설계해야 합니다.","2-일관된-구조-유지#2. 일관된 구조 유지":"일관된 포맷과 구조는 가독성을 높입니다. API 문서라면 ‘함수 이름 → 매개변수 → 반환값 → 예제 코드’와 같은 표준화된 구조를 만들어 보세요.","2-패키지-재설치-및-환경-점검#2. 패키지 재설치 및 환경 점검":"문제가 계속된다면, React 및 React-DOM 패키지를 재설치해 보세요. node_modules 디렉토리와 package-lock.json 파일을 삭제한 후 다시 설치하면, 환경 관련 문제가 해결될 가능성이 높습니다.\nBash\n# React 및 React-DOM 재설치 npm install react react-dom # 또는, 재설치 절차: # 1. 기존 node_modules 디렉토리 및 package-lock.json 파일 삭제 rm -rf node_modules package-lock.json # 2. 모든 의존성 다시 설치 npm install # 3. 이후 프로젝트 실행 npm start","2단계-개발-서버-실행#2단계: 개발 서버 실행":"생성된 프로젝트 폴더로 이동한 후, 다음 명령어를 실행하여 개발 서버를 시작합니다.\nBash\nnpm start 개발 서버가 실행되면 브라우저에서 http://localhost:3000을 열어 React 기본 화면을 확인하세요.","3-도메인-흐름도#3. 도메인 흐름도":"아래 흐름도는 커머스 도메인의 주요 요소들이 어떻게 연결되는지 보여줍니다.\n``` 🛍️ 소비자 (Consumer) │ ┌─────────────┴─────────────┐ ▼ ▼ ┌───────────────┐ ┌───────────────┐ │ 장바구니 (Cart) │ ──▶ │ 주문 (Order) │ └───────────────┘ └───────────────┘ │ │ ▼ ▼ ┌───────────────┐ ┌───────────────┐ │ 상품 (Product) │ │ 결제 (Payment) │ └───────────────┘ └───────────────┘ │ │ ▼ ▼ ┌───────────────┐ ┌───────────────┐ │재고 (Inventory)│ │ 배송 (Shipping)│ └───────────────┘ └───────────────┘ │ ▼ ┌───────────────┐ │ 판매자 (Seller) │ └───────────────┘\n```","3-선택-nodejs-버전-확인-및-조정#3. [선택] Node.js 버전 확인 및 조정":"Node.js 버전이 호환되지 않는 경우에도 이 에러가 발생할 수 있습니다. 현재 Node.js 버전을 확인하고, 필요하다면 호환되는 버전으로 전환하세요.\nBash\n# 현재 Node.js 버전 확인 node -v # 예시: Node Version Manager(nvm)를 사용하여 버전 전환 nvm use 18","3-쉬운-검색-및-탐색-지원#3. 쉬운 검색 및 탐색 지원":"독자가 필요한 정보를 빠르게 찾을 수 있도록 문서를 체계적으로 구성해야 합니다. 목차, 키워드 검색, 앵커 링크 등을 활용하여 정보를 쉽게 탐색할 수 있도록 돕습니다.","3-실행-가능한-코드-예제-포함#3. 실행 가능한 코드 예제 포함":"단순히 개념만 설명하는 것이 아니라, 실제 실행 가능한 예제 코드를 포함해야 합니다. 예제는 핵심 기능을 잘 드러내야 하며, 독자가 직접 실행해보며 학습할 수 있도록 해야 합니다. 실행 가능한 예제는 코드 사용법에 대한 직관적인 이해를 돕고, 실제 프로젝트에 바로 적용할 수 있어 학습 경험을 크게 향상시킵니다.","3-환경별-차이-고려#3. 환경별 차이 고려":"같은 문제가 다른 환경(예: OS, 라이브러리 버전)이나 설정에서 어떻게 나타날 수 있는지도 다루세요.","4-실용적인-예제-코드-제공#4. 실용적인 예제 코드 제공":"명확한 설명과 함께 예제 코드를 함께 제공해야 합니다. 예제 코드는 특정 함수나 API를 어떻게 사용하는지 직관적으로 이해하는 데 큰 도움이 됩니다.","asyncawait-사용-예제#\u003ccode\u003easync/await\u003c/code\u003e 사용 예제":"JavaScript\nasync function fetchData() { try { const response = await fetch('https://jsonplaceholder.typicode.com/posts/1'); if (!response.ok) { throw new Error('네트워크 응답이 올바르지 않습니다.'); } const data = await response.json(); console.log(data); } catch (error) { console.error('오류 발생:', error); } } fetchData();","faq-섹션-제공#FAQ 섹션 제공":"튜토리얼에는 가장 중요한 핵심 과정만 포함하고, 자주 발생하는 문제와 해결책을 문서 마지막에 FAQ 섹션으로 추가합니다. 이렇게 하면 튜토리얼 본문은 성공적인 학습 경험을 중심으로 유지하면서 동시에 독자가 부딪힐 수 있는 문제를 해결할 방법을 제공할 수 있습니다.","fetch-api#\u003ccode\u003efetch\u003c/code\u003e API":"fetch 함수는 네트워크 리소스를 요청하고 응답을 처리하는 비동기 API입니다. Promise 객체를 반환하며, 클라이언트와 서버 간 데이터를 효율적으로 주고받을 수 있어 REST API와 같은 서비스 통신에 유용합니다. XMLHttpRequest보다 간결한 문법을 제공하고, async/await와 함께 사용하면 가독성이 뛰어나다는 장점이 있습니다.","how-to-가이드#How-to 가이드":"How-to 가이드에는 단계별 실행 절차와 실행 가능한 코드 예제가 포함됩니다. 튜토리얼과 달리 전체적인 흐름이나 개념 이해보다는 특정 작업을 성공적으로 수행하는 데 중점을 둡니다.","how-to-가이드와-트러블슈팅-문서의-차이점#How-to 가이드와 트러블슈팅 문서의 차이점":"문제 해결을 위한 문서는 크게 두 가지 유형, How-to 가이드와 트러블슈팅 문서로 나눌 수 있습니다. 비슷해 보이지만 목적에 차이가 있습니다.\nHow-to 가이드: 특정 기능을 성공적으로 구현하거나 특정 작업을 수행하는 단계별 절차에 초점을 맞춥니다.\n트러블슈팅 문서: 이미 발생한 문제를 진단하고 해결하기 위한 디버깅 과정에 중점을 둡니다.","module-not-found-cant-resolve-react-에러-해결-가이드#\u0026ldquo;Module not found: Can\u0026rsquo;t resolve \u0026lsquo;react\u0026rsquo;\u0026rdquo; 에러 해결 가이드":"“Module not found: Can’t resolve ‘react’” 에러가 발생했을 때 해결 방법을 알려드립니다.","post-요청-예제#POST 요청 예제":"JavaScript\nfetch('https://api.example.com/user', { method: 'POST', headers: { 'Content-Type': 'application/json', }, body: JSON.stringify({ name: 'John', age: 30 }), }) .then(response =\u003e { if (!response.ok) { throw new Error('요청이 실패했습니다.'); } return response.json(); }) .then(data =\u003e console.log('서버 응답:', data)) .catch(error =\u003e console.error('오류 발생:', error));","react-시작하기#React 시작하기":"React는 컴포넌트 기반으로 UI를 만들 수 있는 JavaScript 라이브러리입니다. 여기서는 가장 기본적인 React 프로젝트를 실행해보고 동작 방식을 이해하는 것을 목표로 합니다.","react-프로젝트-실행하기#React 프로젝트 실행하기":"","react에서-자동-재시도-기능-통합-가이드#React에서 자동 재시도 기능 통합 가이드":"이 가이드는 자동 재시도 로직을 React 컴포넌트에 통합하여 API 요청 실패 시 자동으로 재시도하는 기능을 구현하는 방법을 설명합니다. 이 기능을 통해 네트워크 불안정 상황에서도 안정적인 데이터 요청을 보장하여 사용자 경험을 개선할 수 있습니다.","react에서-화면을-만드는-방법#React에서 화면을 만드는 방법":"React에서는 컴포넌트라는 개념을 사용하여 화면을 구성합니다. 컴포넌트는 UI의 가장 작은 단위입니다.","react의-가상-dom-작동-원리#React의 가상 DOM 작동 원리":"**React의 가상 DOM(Virtual DOM)**은 UI 변경을 효율적으로 감지하고 최소한의 변경만 실제 DOM에 반영하는 방식을 통해 성능을 최적화하는 핵심 기술입니다. 이를 통해 불필요한 렌더링을 방지하고 빠른 UI 업데이트를 제공합니다.","ui-구현하기#UI 구현하기":"다음 예제는 자동 재시도 로직(fetchWithRetry 함수는 별도로 정의되어 있다고 가정)을 활용해 API 데이터를 불러오고, 로딩 상태와 오류 처리를 포함한 UI를 구현하는 코드입니다.\nimport { useEffect, useState } from \"react\"; // fetchWithRetry 함수는 이 가이드의 범위를 넘어선다고 가정합니다. // 예시: 네트워크 요청 실패 시 지정된 횟수만큼 재시도하는 로직을 포함합니다. async function fetchWithRetry(url, options, retries, delay) { for (let i = 0; i \u003c retries; i++) { try { const response = await fetch(url, options); if (!response.ok) { throw new Error(`HTTP error! status: ${response.status}`); } return await response.json(); } catch (error) { if (i \u003c retries - 1) { console.warn(`Retry attempt ${i + 1} for ${url}. Retrying in ${delay}ms...`); await new Promise(resolve =\u003e setTimeout(resolve, delay)); } else { throw error; // 마지막 시도에서도 실패하면 에러 발생 } } } } function App() { const [data, setData] = useState(null); const [error, setError] = useState(null); const [loading, setLoading] = useState(true); useEffect(() =\u003e { fetchWithRetry(\"https://jsonplaceholder.typicode.com/todos/1\", {}, 3, 1000) .then(json =\u003e { setData(json); setLoading(false); }) .catch(err =\u003e { setError(err.message); setLoading(false); }); }, []); return ( \u003cdiv\u003e {loading ? ( \u003cp\u003e데이터 로딩 중...\u003c/p\u003e ) : error ? ( \u003cp style={{ color: \"red\" }}\u003e{error}\u003c/p\u003e ) : ( \u003cdiv\u003e \u003ch2\u003eAPI 데이터\u003c/h2\u003e \u003cpre\u003e{JSON.stringify(data, null, 2)}\u003c/pre\u003e \u003c/div\u003e )} \u003c/div\u003e ); } export default App;","가상-dom이-등장한-배경#가상 DOM이 등장한 배경":"웹 애플리케이션이 복잡해지면서, 기존의 DOM 조작 방식에는 다음과 같은 문제가 발생했습니다.\nDOM 조작 비용이 크다: 직접적인 DOM 변경이 많아질수록 브라우저의 렌더링 성능이 저하됩니다.\n전체 페이지 리렌더링 문제: 특정 부분만 변경해도 전체 UI가 다시 그려지는 경우가 많습니다.\nUI 성능 저하: 많은 DOM 업데이트가 발생하면 프레임 속도가 떨어지고 사용자 경험(UX)이 저하될 가능성이 높습니다.\nReact는 이러한 문제를 해결하기 위해 가상 DOM을 도입했습니다. 가상 DOM을 활용하면 변경 사항을 먼저 계산하고, 최소한의 연산으로 실제 DOM을 업데이트할 수 있습니다.","개념#개념":"**가상 DOM(Virtual DOM)**은 실제 DOM의 경량화된 JavaScript 객체 모델입니다. React는 UI 변경이 발생하면 이 가상 DOM을 업데이트한 후, 변경된 부분만 실제 DOM에 반영합니다.\n이 방식의 장점은 다음과 같습니다:\n빠른 연산 가능: 가상 DOM은 메모리에서 동작하므로 계산 속도가 빠릅니다.\n효율적인 업데이트: 변경 사항을 비교하여 최소한의 DOM 업데이트만 수행합니다.\n예측 가능성 향상: 선언적 UI 모델을 유지하면서도 최적화된 성능을 제공합니다.","기본-get-요청#기본 GET 요청":"JavaScript\nfetch('https://jsonplaceholder.typicode.com/posts/1') .then(response =\u003e { if (!response.ok) { throw new Error('네트워크 응답이 올바르지 않습니다.'); } return response.json(); }) .then(data =\u003e console.log(data)) .catch(error =\u003e console.error('오류 발생:', error));","기본-컴포넌트-수정하기#기본 컴포넌트 수정하기":"src/App.js 파일을 열고 내용을 아래처럼 수정해 보세요.\nJavaScript\nfunction App() { return 안녕하세요! React를 시작해 봅시다.; } export default App; 파일을 저장한 후, 브라우저를 새로고침하면 React 기본 화면 대신 “안녕하세요! React를 시작해 봅시다.“라는 문구가 표시됩니다.","깊은-이해를-위한-설명-문서-작성-가이드-#깊은 이해를 위한 설명 문서 작성 가이드 📚":"깊은 이해를 위한 설명 문서는 독자가 특정 기술이나 개념을 깊이 있게 이해할 수 있도록 돕는 것을 목표로 합니다. 핵심은 배경과 맥락을 충분히 설명하고, 의사결정 과정을 명확히 공유하는 것입니다. 이 문서를 통해 독자는 기술의 원리와 철학을 이해할 수 있어야 합니다.","더-나아가기#더 나아가기":"참조 문서는 방대한 양의 정보를 포함하기 때문에 독자가 원하는 내용을 빠르게 찾기 어려울 수 있습니다. 이를 해결하기 위해 주제별로 섹션을 나누고 목차를 제공하면 탐색이 쉬워집니다. 예를 들어, 결제 도메인을 다루는 문서라면 주제별 섹션과 함께 API별 목차를 제공할 수 있습니다.\n또한, 독자가 참조 문서를 활용하기 전에 반드시 알아야 할 정보의 배치에도 신경 쓰면 좋습니다. 독자가 항상 참조 문서를 활용하는 시점에만 문서를 보는 것은 아니므로, 사전에 알아야 할 정보가 있을 수 있습니다. 예를 들어, API 키 설정, 인증 방식, 요청 헤더 구성 같은 핵심 정보를 문서의 앞부분에 두어 눈에 잘 띄도록 하면 독자가 문서를 처음 접했을 때 필요한 내용을 놓치지 않게 됩니다.","매개변수#매개변수":"input (필수): 요청할 URL 또는 Request 객체.\ninit (선택): 요청의 옵션을 담은 객체.\nmethod: HTTP 요청 방식 (GET, POST, PUT, DELETE 등)\nheaders: 요청에 포함할 헤더 정보 (예: { 'Content-Type': 'application/json' })\nbody: 요청 본문 (예: JSON.stringify({ name: 'John' }))\nmode: 요청 모드 (cors, no-cors, same-origin)\ncredentials: 쿠키 포함 여부 (omit, same-origin, include)\ncache: 캐시 정책 (default, no-store, reload, force-cache 등)\nredirect: 리디렉션 처리 방식 (follow, error, manual)","문제-해결을-위한-문서-작성-가이드-#문제 해결을 위한 문서 작성 가이드 🛠":"문제 해결을 위한 문서는 독자가 직면한 문제를 빠르고 효과적으로 해결할 수 있도록 돕는 문서입니다. 따라서 이 문서는 독자가 현재 겪고 있는 문제를 해결할 수 있는지 여부가 가장 중요합니다. 문제의 원인과 해결 방법을 논리적으로 제공하고, 바로 적용할 수 있는 해결책과 실용적인 예시를 포함해야 합니다.","반환값#반환값":"fetch는 Promise 객체를 반환합니다. Response 객체의 주요 속성은 다음과 같습니다:\nok: 응답 성공 여부 (200~299 상태 코드인 경우 true)\nstatus: HTTP 상태 코드 (예: 200, 404, 500)\nheaders: 응답 헤더 (Headers 객체)\njson(): 응답 본문을 JSON 객체로 변환 (Promise)\ntext(): 응답 본문을 문자열로 변환 (Promise)\nblob(): 응답 본문을 Blob 객체로 변환 (Promise)","사용-예제#사용 예제":"","시각적-다이어그램#시각적 다이어그램":"다음 다이어그램은 가상 DOM의 작동 과정을 나타냅니다.\n🖥️ UI 변경 감지 ┌─────────────────────────────────┐ │ UI 변경 감지 │ │ (컴포넌트의 상태/props 변경 감지) │ └─────────────────────────────────┘ │ ▼ ⚙️ 가상 DOM 업데이트 ┌─────────────────────────────────┐ │ 가상 DOM 생성 및 업데이트 │ └─────────────────────────────────┘ │ ▼ 🔍 Diffing 알고리즘 적용 ┌─────────────────────────────────┐ │ 이전 가상 DOM과 비교하여 │ │ 변경된 요소 도출 │ └─────────────────────────────────┘ │ ▼ 💻 최소 변경 반영 (실제 DOM) ┌─────────────────────────────────┐ │ 변경된 부분만 실제 DOM에 반영 │ └─────────────────────────────────┘ 위 과정에서 가장 중요한 것은 Diffing 알고리즘입니다. React는 key 속성을 활용하여 변경된 노드를 빠르게 찾고, 효율적으로 업데이트할 수 있도록 설계되어 있습니다.","시그니처#시그니처":"TypeScript\nfetch(input: RequestInfo, init?: RequestInit): Promise","시작하기와-튜토리얼-문서의-차이점#\u0026lsquo;시작하기\u0026rsquo;와 \u0026lsquo;튜토리얼\u0026rsquo; 문서의 차이점":"학습을 위한 문서는 크게 두 가지 유형, **‘시작하기’**와 **‘튜토리얼’**로 나눌 수 있습니다. 비슷해 보이지만 목적에 약간의 차이가 있습니다.\n시작하기 문서: 처음 접하는 독자가 기술의 주요 흐름 및 개념을 이해할 수 있도록 돕는 문서입니다. 간단한 설치 및 설정 안내, 필수 흐름 및 개념 소개를 통해 전체적인 흐름을 이해하는 데 중점을 둡니다.\n튜토리얼 문서: 명확한 목표와 결과물이 있어서 단순히 흐름을 익히는 ‘시작하기’보다 더 구체적입니다. 각 단계를 따라 하면서 자연스럽게 개념을 익히고, 코드를 실행하며 학습할 수 있도록 구성하는 것이 중요합니다.\n참고: 이 분류가 엄격한 것은 아닙니다. 만약 주요 흐름이나 개념, 설치와 설정이 아주 간단하다면 튜토리얼 문서의 초반에 포함되기도 합니다.","예시-fetch-api-참조-문서#예시: \u003ccode\u003efetch\u003c/code\u003e API 참조 문서":"fetch API 문서를 통해 참조 문서 작성 방법을 간단히 익혀봅시다.","이해를-돕기-위한-예시#이해를 돕기 위한 예시":"예시를 보면서 학습을 위한 문서 작성 방법을 간단히 익혀봅시다. 첫 번째 예시는 React 시작하기 문서입니다.","이해를-돕기-위한-예시-1#이해를 돕기 위한 예시":"문제 해결을 위한 문서 중 목표 달성을 위한 단계별 절차를 안내하여 독자가 특정 작업을 성공적으로 수행할 수 있도록 돕는 How-to 가이드를 어떻게 작성하는지 살펴보겠습니다.","이해를-돕기-위한-예시-2#이해를 돕기 위한 예시":"개념 이해를 위한 문서와 도메인 지식을 다루는 문서 두 가지 예시를 통해 자세히 살펴보겠습니다.","작동-방식#작동 방식":"가상 DOM은 다음과 같은 과정을 거쳐 렌더링을 최적화합니다.\nUI 변경 감지: React는 컴포넌트의 상태(state)나 속성(props)이 변경되면 새로운 가상 DOM을 생성합니다.\nDiffing 알고리즘 적용: 이전 가상 DOM과 새로운 가상 DOM을 비교하여 변경된 요소를 찾습니다.\n최소한의 변경만 반영: 변경된 부분만 실제 DOM에 적용하여 성능을 최적화합니다.\n이 과정은 React의 핵심 알고리즘인 **Reconciliation(조정 과정)**을 기반으로 작동합니다.","접어둘-수-있는-컴포넌트-활용#접어둘 수 있는 컴포넌트 활용":"튜토리얼 문서가 길어지면 독자가 핵심 내용을 빠르게 따라갈 수 있도록 일부 내용을 접어두는 방식이 유용할 수 있습니다. 각 단계에서 발생할 수 있는 문제뿐만 아니라 부가 설명, 추가 예제, 심화 개념 등을 숨겼다가 필요할 때 열어볼 수 있도록 제공할 수 있습니다.","직접-컴포넌트-만들기#직접 컴포넌트 만들기":"새로운 컴포넌트를 직접 만들어 App.js에 추가해 봅시다.\nsrc 폴더 안에 Welcome.js 파일을 생성하세요.\n다음 코드를 입력하고 저장하세요.\nfunction Welcome({ name }) { return \u003ch2\u003e안녕하세요, {name}님!\u003c/h2\u003e; } export Welcome; // 'default' 키워드를 사용하여 내보내기 (권장) 참고: 위 코드에서 export default Welcome;으로 수정하는 것을 권장합니다. React 컴포넌트는 일반적으로 default export로 내보내어 다른 파일에서 쉽게 가져올 수 있도록 합니다.\n이제 App.js에서 새로운 Welcome 컴포넌트를 가져와 추가해보세요.\nimport Welcome from \"./Welcome\"; // Welcome.js에서 Welcome 컴포넌트 가져오기 function App() { return ( \u003cdiv\u003e \u003ch1\u003eReact 학습을 시작해봅시다!\u003c/h1\u003e \u003cWelcome name=\"주연\" /\u003e {/* Welcome 컴포넌트 사용 */} \u003c/div\u003e ); } export default App; 파일을 저장하면, 브라우저에 “안녕하세요, 주연님!“이라는 문구가 추가된 것을 확인할 수 있습니다.","참조-문서-작성-가이드-#참조 문서 작성 가이드 📑":"참조 문서는 독자가 특정 기술, 도구 또는 시스템에 대한 정확하고 완전한 정보를 빠르게 찾을 수 있도록 설계됩니다. 핵심은 정확성, 완전성, 검색 용이성이며, 독자가 필요할 때 즉시 원하는 정보를 찾아 적용할 수 있어야 합니다. 또한, 함수, 매개변수, 반환값, 사용 예제 같은 구성을 정하고 일관되게 작성해야 합니다.","체크리스트#체크리스트":"학습을 위한 문서를 작성할 때 다음 사항들을 확인해 보세요.\n학습 목표를 명확하게 제시했나요?\n직접 따라 해 봤을 때 오류가 생기지는 않나요?\n단계별로 설명되어 있나요?\n독자가 직접 실행할 수 있는 코드 예제가 포함되어 있나요?","체크리스트-1#체크리스트":"문제 해결 문서를 작성할 때 다음 사항들을 확인해 보세요.\n단순히 에러 원인만 설명하는 것이 아니라, 에러에 대한 기본적인 지식도 충분히 제공했나요?\n즉시 적용할 수 있는 해결 방법이 포함되어 있나요?\n환경별(운영체제, 라이브러리 버전 등) 차이를 고려한 설명도 포함되어 있나요?\n궁금한 점이 있다면 언제든지 다시 질문해주세요!","체크리스트-2#체크리스트":"참조 문서를 작성할 때 다음 사항들을 확인해 보세요.\n검색 및 탐색이 쉬운 구조인가요?\n정보가 정확하고 완전한가요?\n문서가 일관된 구조와 형식으로 작성되어 있나요?\n실용적인 예시 코드가 포함되어 있나요?\n궁금한 점이나 추가적으로 다루고 싶은 내용이 있다면 언제든지 알려주세요!","커머스-도메인-이해하기#커머스 도메인 이해하기":"이 문서는 커머스 도메인의 개념과 흐름을 설명합니다.\n커머스 도메인은 전자상거래 시스템에서 상품 판매, 주문 처리, 결제, 배송 등 거래 과정을 다루는 핵심 개념입니다. 효율적인 커머스 시스템을 구축하려면 도메인의 구조와 주요 요소를 이해하는 것이 중요합니다.","코드-예제#코드 예제":"React의 가상 DOM을 활용하는 간단한 예제입니다.\nJavaScript\nimport React, { useState } from 'react'; function Counter() { const [count, setCount] = useState(0); return ( 현재 카운트: {count}","트러블슈팅-문서#트러블슈팅 문서":"","학습-문서의-효율성-높이기#학습 문서의 효율성 높이기":"학습을 위한 문서는 성공적인 학습 경험에 집중하는 문서라서 실제 프로젝트에서 발생하는 문제와는 거리가 멀 수 있습니다. 또한, 모든 정보를 한 문서에 담으려다 보면 복잡도가 높아지고 집중하기 어려워질 수 있습니다. 이 문제를 어떻게 개선할 수 있을까요?","학습을-위한-문서-작성-가이드-#학습을 위한 문서 작성 가이드 📚":"학습을 위한 문서는 독자가 새로운 기술이나 도구를 배울 수 있도록 돕는 문서입니다. 이 문서를 읽은 후 독자가 무엇을 할 수 있는지에 대한 명확한 목표를 제시할 수 있어야 합니다."},"title":"Toss technical writing guide"},"/universal-clipboard/":{"data":{"":"","21-중앙-서버-설계#\u003cstrong\u003e2.1. 중앙 서버 설계\u003c/strong\u003e":"중앙 서버는 핵심적인 역할을 하며, 다음과 같은 기능을 제공해야 합니다.\n사용자 인증(Authentication) : 사용자를 식별하고 데이터를 보호하기 위해 OAuth 2.0 또는 JWT(JSON Web Token) 기반의 인증 시스템을 사용. 각 사용자의 클립보드 데이터는 개인적으로 격리되어야 함. 클립보드 데이터 저장 : 데이터베이스에 클립보드 내용을 저장. 텍스트, 이미지 등 다양한 형식의 데이터를 처리할 수 있도록 설계. 단순한 db 를 사용 sqlite, mongoDB 실시간 동기화 : 클라이언트가 클립보드 데이터를 변경하면 즉시 서버로 전송. 다른 클라이언트는 서버로부터 최신 데이터를 받아옴. sse 방식으로 동기화 빠른 재연결 수립 데이터 보안 : 이후 설계 : HTTPS를 통해 데이터를 암호화하여 전송. 이후 설계 : 민감한 데이터는 AES 또는 RSA와 같은 암호화 알고리즘으로 암호화.","22-클라이언트-애플리케이션-설계#\u003cstrong\u003e2.2. 클라이언트 애플리케이션 설계\u003c/strong\u003e":"각 플랫폼별로 클라이언트 애플리케이션을 개발해야 합니다. 각 플랫폼의 특성을 고려하여 구현해야 합니다.\nmacOS/iOS : 클립보드 모니터링 : NSPasteboard (macOS), UIPasteboard (iOS)를 사용하여 클립보드 변경을 감지. 백그라운드 실행 : macOS에서는 앱이 백그라운드에서 실행되도록 설정. 네트워크 통신 : URLSession 또는 Alamofire를 사용하여 서버와 통신. Android : 클립보드 모니터링 : ClipboardManager를 사용하여 클립보드 변경을 감지. 서비스 실행 : Foreground Service를 사용하여 앱이 백그라운드에서도 동작하도록 설정. 네트워크 통신 : Retrofit 또는 OkHttp를 사용하여 서버와 통신. Windows : 클립보드 모니터링 : System.Windows.Forms.Clipboard 또는 WinAPI를 사용하여 클립보드 변경을 감지. 백그라운드 실행 : Windows 서비스 또는 BackgroundWorker를 사용. 네트워크 통신 : HttpClient를 사용하여 서버와 통신."},"title":"universal clipboard"},"/university-algorizm/":{"data":{"":"","-매우-중요한-사실#🔄 매우 중요한 사실":"그래프에서 순환(Cycle)이 존재하는지 여부는 뒤 간선(Back Edge)의 존재 여부와 정확히 일치합니다.\n→ 무방향 그래프에서는 뒤 간선이 있으면 반드시 순환이 존재하며,\n→ 방향 그래프에서도 뒤 간선이 있으면 순환이 존재합니다.\n(단, 방향 그래프에서는 순환을 구성하는 데 반드시 뒤 간선이 필요하며, 다른 간선 유형만으로는 순환을 만들 수 없습니다.)\n따라서 DFS는 이 특성을 이용해 그래프의 순환을 매우 효과적으로 탐지하는 알고리즘으로 널리 사용됩니다.","-요약-bfs에서의-간선-유형-무방향-그래프-기준#🔍 요약: BFS에서의 간선 유형 (무방향 그래프 기준)":"간선 유형 BFS에서 등장 여부 설명 트리 간선 ✅ 항상 있음 새로운 정점을 처음 발견할 때 사용 교차 간선 ✅ 흔함 같은 레벨 또는 인접 레벨 간 연결 뒤 간선 ❌ 실질적으로 없음 자손→조상 구조는 BFS 레벨 탐색과 충돌 순방향 간선 ❌ 존재하지 않음 BFS는 최단 레벨로 방문하므로 “건너뛰기” 간선은 비트리로 처리됨 💡 핵심 인사이트:\nBFS는 레벨 기반 탐색이므로, 깊이(depth) 개념에 기반한 DFS의 간선 분류(특히 Back/Forward Edge)와는 근본적으로 다릅니다.\n따라서 BFS 신장 트리에서는 “트리 간선\"과 “교차 간선\"만 의미 있게 구분됩니다.\n이 설명은 슬라이드 22의 점선 간선들을 정확히 해석하면서도, 알고리즘 이론적 맥락도 함께 제공합니다.","-중요한-차이-무방향-그래프-vs-방향-그래프#🔍 중요한 차이: 무방향 그래프 vs. 방향 그래프":"무방향 그래프(Undirected Graph)에서는 간선이 항상 양방향으로 존재하므로, DFS 과정에서 간선은 오직 트리 간선 또는 뒤 간선으로만 분류됩니다.\n→ 순방향 간선과 교차 간선은 무방향 그래프에서는 존재하지 않습니다.\n방향 그래프(Directed Graph)에서는 간선의 방향이 고정되어 있으므로, 위의 네 가지 유형(Tree, Back, Forward, Cross)이 모두 나타날 수 있습니다.","0-1-배낭-채우기-문제0-1-knapsack-problem#0-1 배낭 채우기 문제(0-1 Knapsack Problem)":"","1-분할-divide-단계#\u003cstrong\u003e1. 분할 (Divide) 단계\u003c/strong\u003e":"첫 번째 단계는 주어진 문제를 해결 가능한 가장 작은 단위(base case)에 도달할 때까지 더 작은 부분 문제(subproblem)들로 나누는 것입니다. 핵심은 원래 문제와 동일한 유형의 더 작은 문제로 나누는 것입니다. 예를 들어, n개의 숫자를 정렬하는 문제라면, 이를 n/2개의 숫자를 정렬하는 두 개의 부분 문제로 나누는 식입니다.\n핵심 원칙: 부분 문제들은 서로 **독립적(independent)**이어야 이상적입니다. 즉, 한 부분 문제의 해가 다른 부분 문제의 해에 영향을 주지 않아야 합니다. 분할 방법: 문제를 어떻게 나눌 것인가는 문제의 성격에 따라 다릅니다. 배열을 정확히 반으로 나누는 것이 일반적이지만(예: 합병 정렬), 특정 기준값(pivot)을 중심으로 나누기도 합니다(예: 빠른 정렬). 이 분할 과정 자체가 알고리즘의 효율성을 결정하는 중요한 요소가 될 수 있습니다.","1-삽입-정렬이란-무엇인가-개요#1. 삽입 정렬이란 무엇인가? (개요)":"삽입 정렬(Insertion Sort)은 가장 단순하고 직관적인 정렬 알고리즘 중 하나입니다. 이름에서 알 수 있듯이, 정렬되지 않은 데이터를 하나씩 가져와 이미 정렬된 부분의 올바른 위치에 삽입하는 방식을 반복하여 전체를 정렬합니다.","1-시작-우리는-왜-그래프를-탐색해야-할까#1. 시작: 우리는 왜 그래프를 탐색해야 할까?":"컴퓨터 과학에서 ‘그래프(Graph)‘는 단순히 그림이 아닙니다. 정점(Vertex)과 그들을 잇는 간선(Edge)의 집합으로, 우리 주변의 수많은 관계와 구조를 표현하는 강력한 도구입니다.\n도시와 도로망: 각 도시는 정점, 도시를 잇는 도로는 간선입니다. 소셜 네트워크: 각 사람은 정점, 친구 관계는 간선입니다. 웹페이지와 링크: 각 웹페이지는 정점, 하이퍼링크는 간선입니다. 이런 그래프가 주어졌을 때, 우리에게는 종종 이런 질문이 생깁니다. “A 도시에서 B 도시까지 갈 수 있는 길이 있는가?” “내 친구의 친구를 따라가면, 결국 유명인 C와 연결될 수 있을까?” “이 웹사이트의 모든 페이지를 빠짐없이 방문하려면 어떤 순서로 링크를 클릭해야 할까?”\n이 모든 질문에 답하기 위한 가장 기본적인 행위가 바로 **그래프 탐색(Graph Traversal)**입니다. 즉, 그래프의 모든 정점을 체계적으로, 빠짐없이 한 번씩 방문하는 것입니다. ‘깊이 우선 탐색(DFS)‘은 이 그래프 탐색을 수행하는 대표적인 두 가지 방법 중 하나입니다.","1-트리-간선-tree-edge#1. **트리 간선 **(Tree Edge)":"BFS 탐색 중 처음으로 정점을 발견하게 만든 간선. 신장 트리의 실선으로 표현되며, 부모 → 자식 관계를 형성. 예: 1 → 2, 1 → 3, 2 → 4 등.","10-bfs-성능-분석-슬라이드-26#10. BFS 성능 분석 (슬라이드 26)":"BFS의 시간 복잡도는 DFS와 놀랍게도 동일합니다.\n인접 목록(Adjacency List) 사용 시: θ(V + E)\n모든 정점은 정확히 한 번 ‘방문함’으로 표시되고, 정확히 한 번 큐에 들어갔다가(Enqueue) 나옵니다(Dequeue). 이 과정에서 V만큼의 시간이 걸립니다. 한 정점을 큐에서 꺼낼 때마다 그 정점의 모든 이웃(간선)을 확인합니다. 탐색이 끝날 때까지 모든 간선은 (무방향 그래프의 경우) 양방향으로 총 두 번씩 확인됩니다. 이 과정에서 E만큼의 시간이 걸립니다. 따라서 총 시간은 θ(V + E) 입니다. 인접 행렬(Adjacency Matrix) 사용 시: θ(V²)\n한 정점의 모든 이웃을 찾기 위해 행렬의 한 행 전체(V개)를 스캔해야 합니다. 이 작업이 V개의 정점에 대해 수행되므로, 총 시간은 θ(V²) 입니다.","11-탐색의-응용-순서-찾아내기-위상-정렬topological-sort#11. 탐색의 응용: 순서 찾아내기, 위상 정렬(Topological Sort)":"지금까지 우리는 그래프의 모든 정점을 방문하는 ‘방법’에 대해 배웠습니다. 이제 이 탐색 기법을 활용하여 매우 중요하고 실용적인 문제를 해결해 보겠습니다. 바로 **위상 정렬(Topological Sort)**입니다.","111-문제-정의-일의-순서-정하기-슬라이드-27-28#11.1. 문제 정의: 일의 순서 정하기 (슬라이드 27, 28)":"우리 삶에는 순서가 중요한 일들이 많습니다.\n요리: 재료를 손질해야 볶을 수 있고, 볶아야 접시에 담을 수 있습니다. 옷 입기: 속옷을 입고, 셔츠를 입고, 재킷을 입어야 합니다. 순서를 바꾸면 곤란합니다. 대학교 수강신청: ‘자료구조’를 수강해야 ‘알고리즘’을 수강할 수 있고, ‘미적분학’을 수강해야 ‘공학수학’을 수강할 수 있습니다. 이처럼 **선행 조건(prerequisite)**이 존재하는 작업들의 집합이 있을 때, 이 선행 조건을 모두 만족시키면서 모든 작업을 수행할 수 있는 일렬로 된 순서를 찾아내는 것을 위상 정렬이라고 합니다.\n이 관계는 **방향 그래프(Directed Graph)**로 완벽하게 표현할 수 있습니다.\n정점(Vertex): 각각의 작업 (예: 과목) 간선(Edge): 선행 관계. A가 B의 선수 과목이면, A → B 간선을 그립니다. 이 간선은 “A를 반드시 B보다 먼저 끝내야 한다\"는 의미입니다. 슬라이드 28의 ‘과목들의 선후수 관계도’가 바로 이 예시입니다. 과목 1은 2와 4의 선수 과목이므로, 1 → 2 와 1 → 4 간선이 있습니다.","112-위상-정렬의-필수-조건-순환이-없어야-한다-dag#11.2. 위상 정렬의 필수 조건: 순환이 없어야 한다 (DAG)":"위상 정렬이 가능하려면, 이 방향 그래프에 순환(Cycle)이 절대로 없어야 합니다. 만약 순환이 있다면 어떤 일이 벌어질까요?\nA → B (A는 B의 선수과목) B → C (B는 C의 선수과목) C → A (C는 A의 선수과목)\n이런 순환 관계가 있다면, A를 시작하려면 C가 끝나야 하고, C를 시작하려면 B가 끝나야 하고, B를 시작하려면 A가 끝나야 합니다. 즉, 영원히 아무것도 시작할 수 없는 모순에 빠집니다.\n따라서 위상 정렬은 순환이 없는 방향 그래프 (Directed Acyclic Graph, DAG) 에서만 정의됩니다.\n슬라이드 29에서 설명하듯, 이 순환의 존재 여부는 우리가 앞에서 배운 DFS를 통해 완벽하게 찾아낼 수 있습니다. DFS 탐색 중 뒤 간선(Back Edge), 즉 현재 탐색 중인 경로 상의 조상 노드로 돌아가는 간선이 발견되면, 그것이 바로 순환이 존재한다는 증거입니다.","113-위상-정렬-알고리즘-1-dfs와-스택의-활용-슬라이드-30-33#11.3. 위상 정렬 알고리즘 1: DFS와 스택의 활용 (슬라이드 30-33)":"DFS의 깊이 파고드는 특성을 이용해 위상 정렬을 수행할 수 있습니다. 핵심 아이디어는 이것입니다.\n“어떤 작업의 DFS가 종료되었다는 것은, 그 작업이 의존하는 모든 후행 작업들의 DFS가 이미 다 종료되었음을 의미한다.”\n예를 들어 A → B 관계가 있을 때, A에서 DFS를 시작하면 반드시 B로 먼저 탐색을 떠나게 됩니다. 따라서 B와 관련된 모든 탐색이 끝나고 나서야, 비로소 A의 탐색이 ‘종료’될 수 있습니다.\n이는 곧, DFS가 가장 먼저 종료되는 정점은, 다른 어떤 정점의 선행 조건도 되지 않는 ‘맨 마지막 작업’ 후보라는 뜻입니다. DFS가 가장 늦게 종료되는 정점은, 다른 많은 작업들의 선행 조건이 되는 ‘맨 처음 작업’ 후보가 됩니다.\n이 ‘종료 순서’를 기록하기 위해 우리는 **스택(Stack)**을 사용합니다. 스택은 ‘Last-In, First-Out (LIFO)’ 구조이므로, 종료된 순서대로 스택에 넣으면 나중에 꺼낼 때 종료 순서의 역순, 즉 위상 정렬된 순서가 됩니다.\n알고리즘 단계:\n빈 스택과 방문 기록부를 준비합니다. 그래프의 모든 정점을 확인하며, 아직 방문하지 않은 정점이 있다면 그 정점에서 DFS를 시작합니다. DFS(v) 함수: a. 현재 정점 v를 ‘방문함’으로 표시합니다. b. v의 모든 이웃 w에 대해, 만약 w가 아직 방문하지 않았다면 DFS(w)를 재귀적으로 호출합니다. c. (핵심!) v의 모든 이웃에 대한 탐색이 끝나면(즉, 재귀 호출이 모두 리턴되면), 그때 v를 스택에 push 합니다. 모든 정점에 대한 DFS가 끝나면, 스택이 빌 때까지 하나씩 pop하여 출력합니다. 이 순서가 바로 위상 정렬 결과입니다. 예제(과목 선후수 관계도) 따라가기: (간결성을 위해 주된 흐름만 보입니다)\n임의의 정점 1에서 DFS 시작. DFS(1) 호출. 1의 이웃 2로 이동. DFS(2) 호출. 2의 이웃 4로 이동. DFS(4) 호출. 4의 이웃 6으로 이동. DFS(6) 호출. 6의 이웃 7로 이동. DFS(7) 호출. 7은 더 이상 갈 곳이 없음. 7의 DFS 종료. 7을 스택에 Push. [스택: 7] 6으로 복귀. 더 이상 갈 곳 없음. 6의 DFS 종료. 6을 스택에 Push. [스택: 7, 6] 4로 복귀. 더 이상 갈 곳 없음. 4의 DFS 종료. 4를 스택에 Push. [스택: 7, 6, 4] 2로 복귀. 더 이상 갈 곳 없음. 2의 DFS 종료. 2를 스택에 Push. [스택: 7, 6, 4, 2] 1로 복귀. 더 이상 갈 곳 없음. 1의 DFS 종료. 1을 스택에 Push. [스택: 7, 6, 4, 2, 1] 이제 방문 안 한 정점 3에서 DFS 시작. DFS(3) 호출. 3의 이웃 5로 이동. DFS(5) 호출. 5의 이웃 6, 7은 이미 방문함. 5의 DFS 종료. 5를 스택에 Push. [스택: 7, 6, 4, 2, 1, 5] 3으로 복귀. 이웃 4는 이미 방문함. 3의 DFS 종료. 3을 스택에 Push. [스택: 7, 6, 4, 2, 1, 5, 3] 모든 정점 방문 완료. 결과 출력: 스택에서 pop: 3, 5, 1, 2, 4, 6, 7. 이는 유효한 수강 순서 중 하나입니다. (위상 정렬의 결과는 유일하지 않을 수 있습니다. 예를 들어 1과 3은 서로 선행 관계가 없으므로 1, 3, ... 순서도 가능합니다.)","114-위상-정렬-알고리즘-2-bfs와-진입-차수의-활용-카의-알고리즘#11.4. 위상 정렬 알고리즘 2: BFS와 진입 차수의 활용 (카의 알고리즘)":"(슬라이드에는 없지만, 매우 중요한 다른 접근법입니다.) BFS를 이용한 위상 정렬 방법도 있으며, 매우 직관적입니다.\n핵심 아이디어:\n“선행 과목이 하나도 없는 과목은 지금 당장 수강할 수 있다.”\n어떤 정점으로 들어오는 간선의 개수를 **진입 차수(In-degree)**라고 합니다. 진입 차수가 0이라는 것은 그 작업을 시작하기 위한 선행 조건이 없다는 뜻입니다.\n알고리즘 단계:\n그래프의 모든 정점에 대해 진입 차수를 계산합니다. 큐를 준비하고, 진입 차수가 0인 모든 정점을 큐에 넣습니다. (이들이 맨 처음 시작할 수 있는 작업들입니다.) 큐가 빌 때까지 다음을 반복합니다. a. 큐에서 정점 v를 하나 꺼냅니다. 이 v를 결과 리스트에 추가합니다. b. v에서 나가는 모든 간선 v → w를 살펴봅니다. c. 간선이 사라졌다고 생각하고, 이웃 w의 진입 차수를 1 감소시킵니다. d. 만약 w의 진입 차수가 0이 되었다면, w 역시 이제 새로운 시작점이 될 수 있으므로 큐에 넣습니다. 반복이 끝났을 때, 결과 리스트에 모든 정점이 포함되어 있다면 위상 정렬이 성공한 것입니다. 만약 일부 정점이 빠져있다면, 이는 그래프에 순환이 존재하여 진입 차수가 0이 되지 못한 정점들이 있다는 뜻입니다. 이 방법은 마치 대학교에서 수강 가능한 과목 목록(진입 차수 0인 과목)을 보고 수강 신청을 하고, 그 과목을 이수하면 다음 학기에 새로운 과목들(진입 차수가 0이 된 과목)이 수강 가능해지는 과정과 매우 유사합니다.","115-시간-복잡도-슬라이드-34#11.5. 시간 복잡도 (슬라이드 34)":"DFS 기반 알고리즘: 이 알고리즘은 본질적으로 그래프 전체에 대한 DFS를 한 번 수행하는 것과 같습니다. 따라서 시간 복잡도는 DFS와 동일한 θ(V + E) (인접 목록 사용 시) 입니다. BFS 기반 알고리즘: 진입 차수를 계산하는 데 O(V+E), 모든 정점과 간선을 한 번씩 처리하므로 이 역시 θ(V + E) (인접 목록 사용 시) 입니다.","1단계-삽입-위치-찾기-naive-접근법과-그-문제점#1단계: 삽입 위치 찾기 (Naive 접근법과 그 문제점)":"","1단계-삽입-위치-찾기-naive-접근법과-그-문제점-1#1단계: 삽입 위치 찾기 (Naive 접근법과 그 문제점)":"슬라이드 19의 아이디어는 A[i]를 삽입할 위치 j를 찾는 것입니다. A[j] ≤ A[i] ≤ A[j+1]을 만족하는 j를 찾아야 합니다. 이를 위해 정렬된 부분의 맨 끝(j = i-1)부터 시작하여 왼쪽으로 이동하며 A[i]보다 작은 값을 만날 때까지 비교합니다.\n슬라이드 20은 이를 코드로 표현합니다.\nj = i – 1 while (A[j] \u003e A[i]) j = j – 1 // 루프가 끝나면 A[j] \u003c= A[i] 이므로, A[i]는 A[j+1] 위치에 들어가야 한다. 문제점: 이 코드에는 치명적인 결함이 있습니다. 만약 A[i]가 A[0...i-1]에 있는 모든 요소보다 작다면 어떻게 될까요? 예를 들어 배열이 [5, 8, 10, 2]이고 i=3일 때, A[3]는 2입니다.\nj = 2. A[2](10) \u003e A[3](2). j는 1이 됩니다. j = 1. A[1](8) \u003e A[3](2). j는 0이 됩니다. j = 0. A[0](5) \u003e A[3](2). j는 -1이 됩니다. while 루프의 다음 조건 검사에서 A[j], 즉 A[-1]에 접근하게 됩니다. 이는 배열의 범위를 벗어나는 접근(Out-of-Bounds Access)으로, 프로그램 오류를 유발합니다. 따라서 단순히 위치만 찾는 방식은 문제가 있습니다.","2-교차-간선-cross-edge#2. **교차 간선 **(Cross Edge)":"가장 흔한 비트리 간선. 이미 방문된 정점으로 연결되며, 두 정점이 같은 레벨이거나 인접한 레벨(레벨 차이 ≤ 1)에 있을 때 발생. 무방향 그래프에서는 모든 비트리 간선이 교차 간선으로 간주됩니다. 예: (2,3) → 둘 다 레벨 1, (4,6) → 둘 다 레벨 2. 방향 그래프에서는 다른 서브트리 간 연결 또는 이미 완전히 탐색된 정점으로 가는 간선일 수 있음.","2-삽입-정렬의-핵심-메커니즘-하나의-요소-삽입하기-slides-19-21#2. 삽입 정렬의 핵심 메커니즘: 하나의 요소 삽입하기 (Slides 19-21)":"삽입 정렬의 전체 과정을 이해하기 위해, 먼저 한 번의 반복, 즉 하나의 요소를 정렬된 부분에 삽입하는 과정을 깊이 있게 살펴보겠습니다. 이것이 알고리즘의 심장부입니다.\n가정: 배열 A가 있고, A[0...i-1]은 이미 정렬되어 있습니다. 이제 A[i]를 이 정렬된 부분에 삽입하여 A[0...i] 전체를 정렬된 상태로 만들려고 합니다.","2-정복-conquer-단계#\u003cstrong\u003e2. 정복 (Conquer) 단계\u003c/strong\u003e":"두 번째 단계는 분할된 각 부분 문제의 해를 구하는 것입니다. 이 과정은 주로 **재귀(Recursion)**를 통해 자연스럽게 구현됩니다. 부분 문제가 더 이상 분할할 수 없을 만큼 작아지면(이를 ‘기저 사례’ 또는 ‘Base Case’라고 합니다), 바로 해를 구합니다. 예를 들어, 배열에 요소가 하나만 남았다면 그 자체가 최댓값이자 최솟값이며, 이미 정렬된 상태라고 볼 수 있습니다.\n재귀의 역할: solve(problem) 함수가 있다면, 이 함수는 내부에서 solve(subproblem1), solve(subproblem2) 등을 호출하는 구조를 가집니다. 이 재귀 호출의 연속이 바로 ‘정복’ 과정입니다. 재귀는 문제를 점점 작은 단위로 쪼개 내려가다가, 기저 사례에 도달하면 해를 반환하며 다시 거슬러 올라오기 시작합니다.","2-탐색을-위한-준비-그래프의-기본-용어와-표현#2. 탐색을 위한 준비: 그래프의 기본 용어와 표현":"탐색을 시작하기 전에, 우리가 탐색할 ‘지도’, 즉 그래프에 대한 몇 가지 용어를 명확히 해야 합니다. (슬라이드 8, 9, 10 내용)","21-그래프의-핵심-용어#2.1. 그래프의 핵심 용어":"연결 그래프 (Connected Graph): 그래프 내의 어떤 두 정점을 선택하더라도, 그 두 정점 사이에 항상 경로가 존재하는 그래프입니다. 즉, 모든 정점들이 직간접적으로 서로 연결되어 있어 ‘섬’처럼 고립된 정점이 없는 상태를 말합니다. 우리가 다룰 대부분의 탐색 문제는 이 연결 그래프를 가정합니다. 경로 (Path): 한 정점에서 다른 정점으로 간선을 따라 이동하는 길입니다. 예를 들어 {1, 3, 4, 6}은 정점 1에서 6으로 가는 경로입니다. 순환 (Cycle): 시작점으로 다시 돌아오는 경로 중, 같은 간선을 중복해서 지나지 않는 경로를 말합니다. {1, 3, 2, 1}은 순환입니다. 그래프에 순환이 있다는 것은 한 지점에서 출발해 다른 길로 갔다가 다시 원래 자리로 돌아올 수 있음을 의미합니다. 이것은 DFS 탐색에서 매우 중요한 특징이 됩니다.","22-컴퓨터는-그래프를-어떻게-기억할까#2.2. 컴퓨터는 그래프를 어떻게 기억할까?":"우리는 그래프를 눈으로 보고 이해하지만, 컴퓨터는 그렇지 못합니다. 컴퓨터에게 그래프의 구조를 알려주기 위한 두 가지 대표적인 방법이 있습니다.\n인접 목록 (Adjacency List): 각 정점마다 “나와 연결된 이웃은 누구누구야\"라고 목록을 만들어주는 방식입니다.\n정점 1의 이웃: [2, 3, 5] 정점 2의 이웃: [1, 3] 정점 3의 이웃: [1, 2, 4, 5, 6] … 이런 식으로 모든 정점에 대한 이웃 목록을 저장합니다. 장점: 간선의 개수가 적은 ‘저밀도 그래프(Sparse Graph)‘에서 메모리를 매우 효율적으로 사용합니다. 인접 행렬 (Adjacency Matrix): 정점의 개수가 V개일 때, V x V 크기의 표(행렬)를 만들고, 정점 i와 정점 j가 연결되어 있으면 표의 (i, j) 위치에 1을, 아니면 0을 표시하는 방식입니다.\n장점: 두 정점이 연결되어 있는지 즉시(O(1) 시간) 확인할 수 있어 ‘고밀도 그래프(Dense Graph)‘에서 유리합니다. 단점: 정점 개수의 제곱에 비례하는 메모리가 필요해, 정점이 많고 간선이 적으면 메모리 낭비가 심합니다. 이 표현 방법의 선택은 나중에 설명할 알고리즘의 **시간 복잡도(성능)**에 직접적인 영향을 미칩니다.","2단계-문제-해결-및-올바른-알고리즘-요소-저장과-이동#2단계: 문제 해결 및 올바른 알고리즘 (요소 저장과 이동)":"","2단계-문제-해결-및-올바른-알고리즘-요소-저장과-이동-1#2단계: 문제 해결 및 올바른 알고리즘 (요소 저장과 이동)":"슬라이드 21은 이 문제를 해결하는 우아한 방법을 제시합니다. 위치를 먼저 찾고 나중에 삽입하는 것이 아니라, 위치를 찾는 과정과 삽입할 공간을 만드는 과정을 동시에 수행합니다.\n핵심 전략:\n삽입할 요소 임시 저장: 먼저 A[i]의 값을 insertElement라는 변수에 복사해 둡니다. 이렇게 하면 A[i]의 원래 자리는 비어있는 ‘구멍(hole)‘으로 간주할 수 있습니다. 이동(Shift)하며 위치 찾기: 정렬된 부분의 끝(j = i-1)부터 시작하여, insertElement보다 큰 요소들을 만나면 오른쪽으로 한 칸씩 밀어냅니다(shift). 삽입: insertElement보다 작거나 같은 요소를 만나거나, 배열의 맨 앞에 도달하면 while 루프가 멈춥니다. 바로 그 멈춘 위치의 다음 칸(j+1)이 insertElement가 들어갈 최종 위치입니다. 알고리즘 코드 (슬라이드 21):\ninsertElement = A[i] // 1. 삽입할 요소 저장 j = i – 1 // 2. 이동하며 위치 찾기 while (j \u003e= 0 and A[j] \u003e insertElement) { A[j+1] = A[j] // insertElement보다 큰 요소를 오른쪽으로 한 칸 이동 j = j - 1 } // 3. 최종 위치에 삽입 A[j+1] = insertElement 이 알고리즘이 앞선 문제를 해결하는 방법:\nj \u003e= 0 조건이 while 루프에 추가되었습니다. 이 덕분에 j가 -1이 되면 루프가 즉시 종료되어 배열의 범위를 벗어나는 오류를 원천적으로 방지합니다. 요소들을 한 칸씩 밀어내면서 빈 공간을 만들기 때문에, 최종적으로 삽입할 때 다른 요소들을 덮어쓸 걱정이 없습니다.","3-뒤-간선-back-edge#3. **뒤 간선 **(Back Edge)":"자손 → 조상으로 향하는 간선 (DFS에서 순환 탐지의 핵심). BFS에서는 거의 등장하지 않음: BFS는 레벨 단위로 탐색하므로, 자손 정점은 항상 더 깊은 레벨에 있고, 조상 정점은 더 낮은 레벨에 있습니다. 따라서 자손에서 조상으로 가는 간선은 레벨이 감소하는 방향이 되는데, 무방향 그래프: 이 간선은 이미 트리 간선으로 처리되었거나, 교차 간선으로 간주됨. 방향 그래프: 이론적으로는 가능하지만, BFS 특성상 실제로는 교차 간선으로 분류되는 경우가 대부분입니다. 결론: BFS에서는 뒤 간선이라는 개념이 실질적으로 사용되지 않으며, 순환 탐지는 다른 방식으로 수행됩니다.","3-미로-탐험가의-전략-깊이-우선-탐색dfs의-원리#3. 미로 탐험가의 전략: 깊이 우선 탐색(DFS)의 원리":"이제 본격적으로 깊이 우선 탐색(DFS)에 대해 알아봅시다. DFS의 핵심 철학은 “일단 갈 수 있는 데까지 끝까지 가본다” 입니다. (슬라이드 11 내용)\n가장 직관적인 비유는 ‘한쪽 벽 짚고 미로 탈출하기’입니다. 미로에 들어선 탐험가를 상상해 보세요.\n시작: 입구(시작 정점)에서 출발합니다. 전진: 눈앞에 여러 갈래 길이 있다면, 그중 아무 길이나 하나를 선택해서 들어갑니다. 그리고 그 길을 따라 계속 직진합니다. 막다른 길: 가다 보니 막다른 길(더 이상 갈 곳이 없는 정점)에 도달했습니다. 후퇴 (Backtracking): 어쩔 수 없이, 방금 지나왔던 바로 직전의 갈림길로 되돌아갑니다. 새로운 길 탐색: 그 갈림길에서, 아까 선택했던 길 말고 아직 가보지 않은 다른 길이 있다면 그 길을 선택해 다시 끝까지 가봅니다. 반복: 이 과정을 계속 반복합니다. 한 갈림길의 모든 방향을 다 탐색했다면, 또 그 이전의 갈림길로 후퇴하여 새로운 길을 찾습니다. 종료: 맨 처음 출발했던 입구로 돌아와, 더 이상 가보지 않은 길이 남아있지 않다면 탐색이 종료됩니다. 이것이 바로 DFS의 전부입니다. ‘깊이(Depth)‘를 ‘우선(First)‘으로 탐색한다는 이름 그대로, 한 경로를 최대한 깊게 파고들고, 더 이상 갈 수 없을 때 비로소 되돌아와 다른 경로를 탐색하는 방식입니다.","3-전체-삽입-정렬-알고리즘-slide-22#3. 전체 삽입 정렬 알고리즘 (Slide 22)":"하나의 요소를 삽입하는 방법을 알았으니, 이제 외부 루프를 추가하여 전체 배열을 정렬하는 완전한 알고리즘을 만들 수 있습니다.","3-합병-merge-또는-combine-단계#\u003cstrong\u003e3. 합병 (Merge 또는 Combine) 단계\u003c/strong\u003e":"마지막 단계는 정복 단계에서 얻은 부분 문제들의 해를 적절히 조합하여 원래 문제의 전체 해를 구하는 것입니다. 이 합병 과정의 복잡도는 알고리즘의 전체 성능에 결정적인 영향을 미칩니다.\n합병의 중요성: 합병 단계가 간단한 알고리즘(예: 빠른 정렬)도 있고, 합병 단계 자체가 핵심적인 작업을 수행하는 알고리즘(예: 합병 정렬)도 있습니다. 예를 들어, 두 개의 정렬된 부분 배열을 하나의 정렬된 배열로 합치는 작업은 합병 정렬의 핵심 연산입니다. 마찬가지로, 두 부분 배열의 최댓값/최솟값들을 비교하여 전체 배열의 최댓값/최솟값을 찾는 것도 합병의 한 예입니다. 이 세 가지 단계를 거치면서, 분할 정복은 복잡한 문제를 체계적으로 해결하는 강력한 프레임워크를 제공합니다.","4-c-전체-구현-코드-및-해설#4. C++ 전체 구현 코드 및 해설":"슬라이드의 의사코드를 표준 C++로 구현해 보겠습니다. std::vector를 사용하여 동적 배열을 처리합니다.","4-순방향-간선-forward-edge#4. **순방향 간선 **(Forward Edge)":"조상 → 자손으로 향하되, 트리 경로가 아닌 직접 간선 (예: 레벨 0 → 레벨 2로 건너뛰는 간선). BFS에서는 존재할 수 없음: BFS는 가장 짧은 경로(최소 레벨)로 정점을 처음 방문하므로, 조상에서 자손으로 가는 더 긴 간선(예: 레벨 0 → 레벨 2)이 있더라도, 해당 자손은 이미 레벨 1에서 다른 경로로 더 빨리 방문되었을 것이기 때문입니다. 따라서 그런 간선은 이미 방문된 정점으로 가는 간선이 되어 교차 간선으로 분류됩니다. 결론: BFS에서는 순방향 간선이 존재하지 않습니다.","4-실제-탐색-과정-따라가기-슬라이드-12-13-예제#4. 실제 탐색 과정 따라가기 (슬라이드 12, 13 예제)":"이제 슬라이드의 예제 그래프를 가지고 DFS 탐험가가 되어 직접 탐색을 진행해 보겠습니다. 탐색의 기록을 위해 ‘방문한 정점’을 표시해 둡시다.\n(초기 상태: 모든 정점은 ‘방문 안함’ 상태)\n시작점: 정점 1\n탐험가는 정점 1에서 시작합니다. “정점 1 방문!“이라고 외치고, 방문했다고 표시합니다. (방문 순서: 1) 1에서 갈 수 있는 길(인접한 정점)은 2, 3, 5입니다. 탐험가는 이 중 임의로 정점 3을 선택합니다. 정점 1 → 정점 3\n탐험가는 3에 도착합니다. “정점 3 방문!” (방문 순서: 1, 3) 3에서 갈 수 있는 길은 1, 2, 4, 5, 6입니다. 하지만 1은 방금 지나온 곳이니 이미 방문했습니다. 남은 ‘방문 안한’ 길은 2, 4, 5, 6입니다. 탐험가는 이 중 임의로 정점 2를 선택합니다. 정점 3 → 정점 2\n탐험가는 2에 도착합니다. “정점 2 방문!” (방문 순서: 1, 3, 2) 2에서 갈 수 있는 길은 1, 3입니다. 그런데 둘 다 이미 방문한 곳입니다. 더 이상 나아갈 새로운 길이 없습니다. 막다른 길입니다! 후퇴 (Backtracking): 정점 2 → 정점 3\n탐험가는 방금 왔던 길을 되짚어 정점 3으로 돌아갑니다. 이제 3의 갈림길에서, 아까 선택했던 2 말고 다른 길을 찾아봅니다. 아직 방문하지 않은 길로 4, 5, 6이 남아있습니다. 탐험가는 이 중 임의로 정점 4를 선택합니다. 정점 3 → 정점 4\n탐험가는 4에 도착합니다. “정점 4 방문!” (방문 순서: 1, 3, 2, 4) 4에서 갈 수 있는 길은 3과 6입니다. 3은 이미 방문했으니, 남은 길은 6뿐입니다. 탐험가는 정점 6으로 향합니다. 정점 4 → 정점 6\n탐험가는 6에 도착합니다. “정점 6 방문!” (방문 순서: 1, 3, 2, 4, 6) 6에서 갈 수 있는 길은 3과 4입니다. 둘 다 이미 방문했습니다. 또 막다른 길입니다! 후퇴 (Backtracking): 정점 6 → 정점 4\n탐험가는 정점 4로 돌아갑니다. 4의 갈림길에서, 6 말고 다른 가보지 않은 길이 있는지 확인합니다. 없습니다. 또 후퇴합니다. 정점 4에서 왔던 길을 따라 정점 3으로 돌아갑니다. 후퇴 (Backtracking): 정점 4 → 정점 3\n탐험가는 다시 정점 3에 섰습니다. 지금까지 3에서는 2와 4 방향을 탐색했습니다. 아직 방문하지 않은 길로 5와 6이 남아있… 아, 6은 방금 4를 통해 방문했었죠. 그럼 남은 길은 정점 5 뿐입니다. 탐험가는 5로 향합니다. 정점 3 → 정점 5\n탐험가는 5에 도착합니다. “정점 5 방문!” (방문 순서: 1, 3, 2, 4, 6, 5) 5에서 갈 수 있는 길은 1과 3입니다. 둘 다 이미 방문했습니다. 막다른 길입니다! 마지막 후퇴 과정\n정점 5에서 정점 3으로 후퇴합니다. 정점 3의 모든 이웃(2, 4, 6, 5)을 다 탐색했습니다. 이제 3에서도 더 이상 갈 곳이 없습니다. 정점 1로 후퇴합니다. 정점 1에 돌아왔습니다. 1에서 출발한 3의 경로를 모두 탐색했습니다. 1의 다른 이웃인 2와 5를 확인해 보니, 탐색 과정 중에 이미 모두 방문된 상태입니다. 시작점 1에서 더 이상 갈 곳이 없으므로, 탐색이 종료됩니다. 최종적으로 모든 정점(1, 2, 3, 4, 5, 6)을 방문했으며, 방문 순서는 선택에 따라 달라질 수 있지만, 이 예제에서는 1 → 3 → 2 → 4 → 6 → 5 순서가 되었습니다.","5-시간-및-공간-복잡도-분석-slide-23#5. 시간 및 공간 복잡도 분석 (Slide 23)":"알고리즘의 효율성을 평가하기 위해 시간과 공간 복잡도를 분석합니다.","5-탐험의-발자취-깊이-우선-신장-트리dfs-spanning-tree#5. 탐험의 발자취: 깊이 우선 신장 트리(DFS Spanning Tree)":"자, 이제 탐험은 끝났습니다. 우리가 이 복잡한 탐색을 마치고 나서, 탐험가가 새로운 정점을 발견하기 위해 실제로 이동했던 경로만 남겨보면 어떻게 될까요? 이것이 바로 ‘깊이 우선 신장 트리’ 개념이 등장하는 이유입니다. (슬라이드 14, 15 내용)\n1에서 3으로 갈 때, 3은 처음 발견된 정점입니다. (1-3 간선 선택) 3에서 2로 갈 때, 2는 처음 발견된 정점입니다. (3-2 간선 선택) 3에서 4로 갈 때, 4는 처음 발견된 정점입니다. (3-4 간선 선택) 4에서 6으로 갈 때, 6은 처음 발견된 정점입니다. (4-6 간선 선택) 3에서 5로 갈 때, 5는 처음 발견된 정점입니다. (3-5 간선 선택) 이 간선들 (1,3), (3,2), (3,4), (4,6), (3,5)를 모아 그림을 그려보면, 슬라이드 15의 그림처럼 됩니다. 이 그림은 몇 가지 중요한 특징을 가집니다.\n모든 정점을 포함한다: 원래 그래프의 모든 정점이 다 들어있습니다. 순환이 없다: 이 간선들만으로는 시작점으로 되돌아오는 경로(사이클)를 만들 수 없습니다. 이런 구조를 우리는 **트리(Tree)**라고 부릅니다. 그래프를 ‘걸쳐’있다(Span): 원래 그래프의 모든 정점을 포함하면서 트리를 이루기 때문에 **신장 트리(Spanning Tree)**라고 부릅니다. 결론적으로, 깊이 우선 신장 트리는 복잡한 원래 그래프에서 DFS라는 특정 탐색 방법으로 길을 찾아다닌 ‘발자취’를 모아놓은 것입니다. 이는 원래 그래프의 모든 정점을 연결하는 핵심적인 ‘뼈대’ 구조를 보여줍니다.","51-뼈대트리-간선와-지름길뒤-간선#5.1. 뼈대(트리 간선)와 지름길(뒤 간선)":"신장 트리를 만들고 나니, 원래 그래프에 있었지만 이 뼈대에는 포함되지 않은 간선들이 있습니다. 슬라이드 15의 점선으로 표시된 (1,2), (1,5), (3,6) 같은 간선들입니다. 이들은 무엇일까요?\n**트리 간선 **(Tree Edge): 실선으로 표시된 간선들. DFS 탐색 중 새로운 정점을 발견하게 만든 간선입니다. 즉, 트리의 부모-자식 관계를 형성하는 뼈대 간선입니다.\n**뒤 간선 **(Back Edge): 점선으로 표시된 간선들. DFS 탐색 중, 이미 방문했지만 아직 탐색이 완료되지 않은 정점(즉, 현재 재귀 스택에 남아 있는 조상)으로 연결되는 간선입니다. 예를 들어, 정점 2에서 인접한 정점 1을 확인했을 때, 1은 이미 방문한 상태였고 아직 함수 호출이 끝나지 않았다면, 간선 (2,1)은 뒤 간선입니다. 이 간선은 신장 트리에서 자손 노드가 자신의 조상 노드(부모 포함) 역할을 합니다.\n**순방향 간선 **(Forward Edge): DFS 탐색 중, 이미 완전히 탐색이 끝난 자손 정점으로 연결되는 간선입니다. 즉, 트리 경로를 따라 갈 수 있는 자손이지만, 해당 간선 자체는 탐색 과정에서 사용되지 않은 경우입니다. 예: (1 → 3 → 4)가 트리 경로일 때, 간선 (1 → 4)가 있다면 이는 순방향 간선입니다.\n**교차 간선 **(Cross Edge): DFS 탐색 중, 서로 다른 서브트리에 속한 정점들 사이를 연결하거나, 이미 완전히 탐색이 끝난 조상이 아닌 정점으로 연결되는 간선입니다. 이 간선은 트리 구조 내에서 선조-자손 관계가 전혀 없는 정점 쌍을 잇습니다.","51-최댓값과-최솟값-찾기#\u003cstrong\u003e5.1 최댓값과 최솟값 찾기\u003c/strong\u003e":"배열에서 가장 큰 값(최댓값)과 가장 작은 값(최솟값)을 찾는 문제는 매우 기본적인 문제이지만, 이 문제를 어떻게 접근하느냐에 따라 연산의 효율성이 달라질 수 있습니다. 분할 정복이 어떻게 비교 횟수를 줄여 효율성을 높이는지 살펴보겠습니다.","52-합병-정렬-merge-sort#\u003cstrong\u003e5.2 합병 정렬 (Merge Sort)\u003c/strong\u003e":"정렬은 컴퓨터 과학에서 가장 기본적이고 중요한 문제 중 하나입니다. 합병 정렬은 분할 정복 패러다임의 가장 대표적이고 교과서적인 예시입니다.","53-빠른-정렬-quick-sort#\u003cstrong\u003e5.3 빠른 정렬 (Quick Sort)\u003c/strong\u003e":"빠른 정렬은 합병 정렬과 함께 분할 정복을 사용하는 가장 유명한 정렬 알고리즘 중 하나입니다. 이름에서 알 수 있듯이, 평균적으로 매우 빠른 성능을 자랑합니다.","54-선택-selection#\u003cstrong\u003e5.4 선택 (Selection)\u003c/strong\u003e":"선택 문제는 정렬되지 않은 배열에서 k번째로 작은 요소를 찾는 문제입니다.\nk=1이면 최솟값 찾기 k=n이면 최댓값 찾기 k=⌊(n+1)/2⌋이면 중앙값(median) 찾기","55-분할-정복이-부적절한-경우#\u003cstrong\u003e5.5 분할 정복이 부적절한 경우\u003c/strong\u003e":"분할 정복은 매우 강력하지만 만병통치약은 아닙니다. 분할 정복이 비효율적이거나 부적절한 경우가 있는데, 가장 대표적인 사례는 부분 문제들이 서로 중복될 때입니다.\n슬라이드 44에서 언급된 두 가지 경우는 이 문제를 잘 설명합니다.\n경우 1: 크기 n의 문제가 거의 n에 가까운 크기의 두 개 이상의 부분 문제로 분할될 때. 경우 2: 크기 n의 문제가 n/c 크기의 거의 n개에 가까운 부분 문제로 분할될 때. 이 두 경우의 공통적인 문제는, 분할된 부분 문제들의 입력 크기의 합이 원래 문제의 입력 크기보다 훨씬 커진다는 점입니다. 이는 같은 부분 문제를 여러 번 반복해서 풀게 될 가능성이 높다는 것을 시사합니다.","6-삽입-정렬의-주요-특징-및-심층-분석-slide-24#6. 삽입 정렬의 주요 특징 및 심층 분석 (Slide 24)":"삽입 정렬은 단순한 O(n²) 알고리즘 이상의 중요한 특징들을 가지고 있습니다.","6-알고리즘으로-정리하기-슬라이드-16-17#6. 알고리즘으로 정리하기 (슬라이드 16, 17)":"우리가 지금까지 말로 설명한 탐험가의 행동을 컴퓨터가 알아들을 수 있는 언어, 즉 알고리즘(의사코드)으로 정리해 봅시다. 이 과정은 재귀(Recursion) 개념을 사용하면 매우 간결하게 표현됩니다.\nDFS(v): 현재 정점 v에서 탐색을 시작하라\n도착했음을 알린다: 정점 v에 도착했으니, v를 방문했다고 표시하고, 필요하다면 v의 데이터를 출력한다. 주변을 살핀다: v에 연결된 모든 이웃 정점 w들을 하나씩 살펴본다. 새로운 길이라면 가본다: 만약 이웃 w가 ‘방문 안함’ 상태라면, 그 길로 탐험을 떠난다. 즉, DFS(w)를 호출한다. 이 호출이 바로 ‘더 깊이 들어가는’ 재귀적 행위입니다. DFS(w)가 모든 탐색을 마치고 돌아올 때까지(리턴될 때까지) 기다린다. 모든 길을 확인했다면 돌아간다: v의 모든 이웃을 다 확인했다면, v에서의 탐색은 끝난 것이다. 이 함수를 호출했던 곳으로 돌아간다(리턴). 이 DFS(v) 함수만으로는 모든 그래프를 탐색할 수 없습니다. 만약 그래프가 여러 개의 ‘섬’으로 나뉘어 있다면(비연결 그래프), 하나의 섬만 탐색하고 끝나버릴 수 있습니다. 그래서 전체를 관리하는 DFSearch(G) 함수가 필요합니다.\nDFSearch(G): 그래프 G 전체를 탐색하라\n준비: 모든 정점을 ‘방문 안함’으로 초기화한다. 모든 정점을 확인: 그래프의 모든 정점 v를 하나씩 순서대로 확인한다. 아직 방문 안한 곳에서 새로 시작: 만약 정점 v가 아직도 ‘방문 안함’ 상태라면, 그곳은 아직 탐험하지 않은 새로운 ‘섬’이라는 뜻이다. 그곳에서부터 DFS(v)를 호출하여 새로운 탐색을 시작한다. 이 두 함수를 통해 어떤 형태의 그래프라도 모든 정점을 빠짐없이 방문할 수 있습니다.","6-탐험가의-또-다른-전략-너비-우선-탐색bfs의-원리#6. 탐험가의 또 다른 전략: 너비 우선 탐색(BFS)의 원리":"앞서 우리는 ‘한 우물만 파는’ 깊이 우선 탐색(DFS) 탐험가를 만났습니다. 이번에는 성격이 정반대인, 매우 신중하고 체계적인 탐험가를 만나보겠습니다. 이 탐험가의 전략이 바로 **너비 우선 탐색(Breadth-First Search, BFS)**입니다. (슬라이드 20 참고)\nDFS의 핵심 철학이 “일단 끝까지 가본다\"였다면, BFS의 핵심 철학은 “가까운 곳부터 차례대로 샅샅이 뒤진다” 입니다.\n이해를 돕기 위해 다른 비유를 들어보겠습니다.\n호수에 돌 던지기: 잔잔한 호수 중앙(시작 정점)에 돌을 던지면, 물결(탐색)이 동심원을 그리며 바깥으로 퍼져나갑니다. 가장 가까운 곳에 첫 번째 원이 생기고, 그다음 조금 더 먼 곳에 두 번째 원이 생깁니다. BFS는 이 물결이 퍼져나가는 순서와 정확히 같습니다. SNS 친구 찾기: 여러분(시작 정점)이 SNS에서 “나와 가장 가까운 친구들부터 모두 찾아보자\"고 결심했다고 상상해 보세요. Level 0: 나 자신. Level 1: 먼저 나의 ‘직접 친구’들을 모두 찾아서 목록에 올립니다. Level 2: 그다음, ‘직접 친구’들의 친구들(즉, 내 친구의 친구들)을 모두 찾습니다. Level 3: 그 다음엔 ‘친구의 친구’들의 친구들을 모두 찾습니다. 이처럼, 시작점으로부터 거리가 1인 정점들을 모두 방문하고, 그다음 거리가 2인 정점들을 모두 방문하고, 그다음 거리가 3인 정점들을 모두 방문하는 방식. 이것이 바로 BFS의 본질입니다. ‘너비(Breadth)‘를 ‘우선(First)‘으로 탐색한다는 이름 그대로입니다.","61-bfs의-핵심-도구-큐queue#6.1. BFS의 핵심 도구: 큐(Queue)":"DFS가 ‘막다른 길에서 되돌아오기(Backtracking)’ 위해 재귀 호출(내부적으로 스택 사용)을 활용했다면, BFS는 이 ‘레벨(거리) 순서’를 지키기 위해 아주 특별한 자료구조를 사용합니다. 바로 **큐(Queue)**입니다.\n큐는 “First-In, First-Out (FIFO)”, 즉 먼저 들어온 것이 먼저 나가는 구조입니다. 마치 은행 창구나 놀이공원 줄서기와 같습니다.\nBFS에서 큐가 어떻게 작동하는지 살펴봅시다.\n탐색 대기줄: 큐는 ‘다음에 방문할 정점들의 대기줄’이라고 생각할 수 있습니다. 규칙 1: 어떤 정점을 처음 발견하면, 즉시 이 대기줄(큐)의 맨 뒤에 세웁니다. 규칙 2: 탐색을 할 때는, 대기줄의 맨 앞에 있는 정점부터 순서대로 처리합니다. 이 간단한 두 규칙이 어떻게 ‘가까운 곳부터’ 탐색하는 것을 보장할까요? 시작 정점 S를 큐에 넣습니다. S를 꺼내면서 S의 이웃인 A, B, C를 발견합니다. 이들을 순서대로 큐에 넣습니다. (큐 상태: [A, B, C]) 이제 큐의 맨 앞인 A를 꺼냅니다. A의 이웃을 탐색합니다. 그다음 큐의 맨 앞인 B를 꺼냅니다. B의 이웃을 탐색합니다. … 이런 식으로, 거리가 1인 A, B, C를 모두 큐에 넣고 처리한 뒤에야, 그들의 이웃인 거리 2의 정점들이 처리될 기회를 얻게 됩니다. 큐의 FIFO 특성이 자연스럽게 레벨 순서의 탐색을 만들어내는 것입니다.","7-다른-정렬-알고리즘과의-비교-및-활용#7. 다른 정렬 알고리즘과의 비교 및 활용":"","7-성능-분석-얼마나-빠를까-슬라이드-18#7. 성능 분석: 얼마나 빠를까? (슬라이드 18)":"알고리즘의 효율성을 따지는 것을 시간 복잡도 분석이라고 합니다. DFS의 성능은 컴퓨터가 그래프를 어떻게 저장하고 있느냐(인접 목록 vs 인접 행렬)에 따라 달라집니다. 정점의 수를 V, 간선의 수를 E라고 합시다.\n인접 목록(Adjacency List) 사용 시: θ(V + E)\nDFSearch에서 모든 정점을 한 번씩 확인합니다 (V만큼의 시간). DFS가 호출되는 과정에서, 모든 정점은 정확히 한 번씩 방문됩니다. 한 정점을 방문할 때마다 그 정점의 인접 목록을 쭉 훑어봅니다. 모든 정점의 인접 목록의 길이를 다 더하면, 무방향 그래프의 경우 2E가 됩니다. 결과적으로, 모든 정점을 한 번씩 방문하고(V), 모든 간선을 (양방향으로) 한 번씩 확인하는(E) 셈이므로, 총 시간은 V와 E에 비례합니다. θ(V + E) 인접 행렬(Adjacency Matrix) 사용 시: θ(V²)\n한 정점 v에서 갈 수 있는 이웃을 찾으려면, 인접 행렬의 v번째 행 전체(V개의 열)를 모두 스캔해야 합니다. 이 작업을 모든 정점 V개에 대해 수행해야 하므로, 총 시간은 V * V = V²에 비례합니다. θ(V²) 결론: 일반적으로 그래프는 간선이 꽉 찬 경우(Dense)보다 듬성듬성한 경우(Sparse)가 훨씬 많습니다(E « V²). 따라서 대부분의 경우 인접 목록을 사용하는 것이 훨씬 효율적이며, DFS의 시간 복잡도는 보통 **O(V+E)**라고 이야기합니다.","7-실제-bfs-탐색-과정-따라가기-슬라이드-20-예제#7. 실제 BFS 탐색 과정 따라가기 (슬라이드 20 예제)":"이제 슬라이드 20의 예제 그래프(DFS에서 사용했던 것과 동일한 무방향 그래프)를 가지고 BFS 탐험을 시작하겠습니다. 탐험을 위해 **큐(Queue)**와 **방문 기록부(Visited Set)**를 준비합시다.\n(초기 상태: 모든 정점 ‘방문 안함’, 큐는 비어있음)\n시작점: 정점 1\n탐험가는 정점 1에서 시작합니다. “정점 1 방문!“이라고 외치고, 방문 기록부에 표시합니다. 그리고 1을 ‘다음에 탐색할 대기줄’인 큐에 넣습니다. 방문 기록: {1} 큐 상태: [1] Level 1 탐색\n큐가 비어있지 않으므로, 맨 앞의 정점을 꺼냅니다. 정점 1을 Dequeue 합니다. 이제 1과 연결된 이웃들을 살펴봅니다. 2, 3, 5가 있습니다. 이들은 모두 아직 방문하지 않은 새로운 정점들입니다. 발견한 순서대로 방문 기록부에 표시하고, 큐의 맨 뒤에 차례로 넣습니다. 방문 기록: {1, 2, 3, 5} 큐 상태: [2, 3, 5] (1은 처리되었으므로 빠짐) Level 2 탐색 (시작)\n큐의 맨 앞에 있는 정점 2를 Dequeue 합니다. 2의 이웃은 1과 3입니다. 방문 기록부를 보니, 둘 다 이미 방문했습니다. 새로 발견한 정점이 없으므로 큐에 추가할 것도 없습니다. 방문 기록: {1, 2, 3, 5} (변화 없음) 큐 상태: [3, 5] Level 2 탐색 (계속)\n큐의 맨 앞에 있는 정점 3을 Dequeue 합니다. 3의 이웃은 1, 2, 4, 5, 6입니다. 이 중 1, 2, 5는 이미 방문했습니다. 아직 방문하지 않은 4와 6을 발견했습니다! 4와 6을 방문 기록부에 표시하고, 큐에 차례로 넣습니다. 방문 기록: {1, 2, 3, 5, 4, 6} 큐 상태: [5, 4, 6] Level 2 탐색 (마무리)\n큐의 맨 앞에 있는 정점 5를 Dequeue 합니다. 5의 이웃은 1과 3입니다. 둘 다 이미 방문했습니다. 새로 할 일이 없습니다. 방문 기록: {1, 2, 3, 5, 4, 6} 큐 상태: [4, 6] Level 3 탐색\n큐의 맨 앞에 있는 정점 4를 Dequeue 합니다. 4의 이웃은 3과 6입니다. 둘 다 이미 방문했습니다. 큐 상태: [6] 큐의 맨 앞에 있는 정점 6을 Dequeue 합니다. 6의 이웃은 3과 4입니다. 둘 다 이미 방문했습니다. 큐 상태: [] (이제 큐가 비었습니다!) 종료\n큐가 비었으므로, 더 이상 탐색할 정점이 남아있지 않습니다. 탐색을 종료합니다. 최종 방문 순서는 1, 2, 3, 5, 4, 6이 되었습니다. 이는 시작점 1에서부터 거리가 0인 정점(1), 거리가 1인 정점들(2, 3, 5), 거리가 2인 정점들(4, 6) 순서로 방문한 것과 정확히 일치합니다.\n중요한 특징: BFS는 **최단 경로(Shortest Path)**를 찾는 문제의 핵심 알고리즘입니다. 간선의 가중치가 모두 1일 때, 시작점에서 특정 정점까지의 최단 거리는 BFS가 그 정점을 몇 번째 ‘레벨’에서 발견했는지와 같습니다.","8-너비-우선-탐색의-발자취-너비-우선-신장-트리bfs-spanning-tree#8. 너비 우선 탐색의 발자취: 너비 우선 신장 트리(BFS Spanning Tree)":"DFS와 마찬가지로, BFS 탐색 과정에서 새로운 정점을 발견하기 위해 사용된 간선들만 모으면 **너비 우선 신장 트리(BFS Spanning Tree)**를 만들 수 있습니다. (슬라이드 22 참고)\n1에서 2, 3, 5를 발견했습니다. (1-2), (1-3), (1-5) 간선이 트리에 포함됩니다. 3에서 4, 6을 발견했습니다. (3-4), (3-6) 간선이 트리에 포함됩니다. 이 간선들을 모아보면 슬라이드 22의 그림이 완성됩니다. 이 트리는 DFS 신장 트리와는 확연히 다른 모양을 가집니다.\nDFS 신장 트리: 길고 얇은 모양. 깊이를 우선하기 때문입니다. BFS 신장 트리: 짧고 넓은 모양. 너비를 우선하기 때문입니다.","8-요약-및-결론#8. 요약 및 결론":"삽입 정렬은 정렬되지 않은 요소를 하나씩 가져와 이미 정렬된 부분의 올바른 위치에 삽입하는 과정을 반복하는 직관적이고 간단한 정렬 알고리즘입니다. 그 핵심은 insertElement를 임시 저장하고, while 루프를 통해 자신보다 큰 요소들을 오른쪽으로 한 칸씩 밀어내며 동시에 삽입 위치를 찾는 것입니다.\n비록 평균 및 최악의 경우 O(n²)의 시간 복잡도로 인해 대규모 데이터 정렬에는 부적합하지만, 최선의 경우 O(n)이라는 적응성, O(1)의 추가 공간만 사용하는 제자리 정렬, 그리고 안정성이라는 중요한 특징을 가지고 있습니다. 이러한 장점들 덕분에 삽입 정렬은 단순히 교육용 알고리즘을 넘어, 작은 크기의 데이터를 처리하거나 고급 정렬 알고리즘의 일부로 사용되는 등 실제 세계에서도 그 가치를 인정받고 있습니다.","81-bfs-신장-트리에서의-간선-분류#8.1. BFS 신장 트리에서의 간선 분류":"BFS 신장 트리를 만들고 나면, 원래 그래프에 존재했지만 트리에 포함되지 않은 간선들이 남습니다. 슬라이드 22의 점선 (2,3), (4,6) 등이 그 예입니다. 이 간선들은 DFS와는 다른 방식으로 해석됩니다.\nBFS는 레벨 순서(level-order)로 정점을 탐색하므로, 간선의 방향성과 레벨 차이에 따라 다음과 같이 분류할 수 있습니다:","9-bfs-알고리즘-정리-슬라이드-25#9. BFS 알고리즘 정리 (슬라이드 25)":"말로 설명한 BFS 과정을 컴퓨터가 이해할 수 있는 알고리즘으로 정리해 봅시다.\nBFS(v): 정점 v를 시작으로 연결된 모든 곳을 너비 우선으로 탐색하라\n시작점 처리: v를 ‘방문함’으로 표시하고, 큐에 v를 넣는다. 대기줄 확인: 큐가 비어있지 않은 동안 계속 반복한다. 처리 대상 선정: 큐의 맨 앞에서 정점 u를 하나 꺼낸다. (Dequeue) (작업 수행): 필요하다면 u의 데이터를 출력하는 등 작업을 수행한다. 이웃 탐색: u에 인접한 모든 정점 w에 대해 다음을 확인한다. 새로운 정점 발견: 만약 w가 ‘방문 안함’ 상태라면, w를 ‘방문함’으로 표시한다. (다음에 또 발견하지 않도록) w를 큐의 맨 뒤에 추가한다. (다음 레벨의 탐색 대상으로 예약) DFS와 마찬가지로, 그래프 전체를 탐색하려면 이 BFS(v)를 감싸는 관리 함수가 필요합니다. (DFS의 DFSearch와 동일한 구조)","buildheap#\u003cstrong\u003e\u003ccode\u003ebuildHeap\u003c/code\u003e 구체적인 예시\u003c/strong\u003e":"배열 A = [-, 4, 10, 3, 5, 1, 8] (인덱스 1부터 사용)가 있다고 가정해 봅시다. n=6.\n초기 상태:\nn = 6. 마지막 내부 노드는 floor(6/2) = 3번 인덱스. bh는 3부터 1까지 감소하며 진행됩니다. eh = 6. bh = 3 (값: 3)일 때:\nx=3. 자식은 2*3=6번(값: 8) 하나뿐입니다. A[3](3) \u003c A[6](8) 이므로 pushDown이 동작합니다. swap(A[3], A[6]). 배열은 [-, 4, 10, 8, 5, 1, 3]이 됩니다. 3번 노드를 루트로 하는 서브트리는 힙이 되었습니다. bh = 2 (값: 10)일 때:\nx=2. 자식은 2*2=4번(값: 5)과 2*2+1=5번(값: 1)입니다. A[2](10)은 자식들(5, 1)보다 모두 크므로 힙 조건 만족. pushDown은 아무것도 하지 않습니다. bh = 1 (값: 4)일 때:\nx=1. 자식은 2*1=2번(값: 10)과 2*1+1=3번(값: 8)입니다. A[1](4)은 두 자식보다 모두 작습니다. 더 큰 자식은 A[2](10)입니다. pushDown 동작: swap(A[1], A[2]). 배열은 [-, 10, 4, 8, 5, 1, 3]이 됩니다. 이제 원래 값 4가 2번 인덱스로 내려왔습니다. x는 2가 됩니다. 여기서 pushDown을 계속합니다. 새로운 x=2. 자식은 2*2=4번(값: 5)과 2*2+1=5번(값: 1)입니다. A[2](4)는 자식 A[4](5)보다 작습니다. 더 큰 자식은 A[4]입니다. swap(A[2], A[4]). 배열은 [-, 10, 5, 8, 4, 1, 3]이 됩니다. 원래 값 4가 4번 인덱스로 내려왔습니다. 4번 노드는 리프 노드이므로 pushDown이 종료됩니다. 최종적으로 buildHeap이 완료된 배열은 [-, 10, 5, 8, 4, 1, 3]이며, 이는 최대 힙 구조를 가집니다.","가장-직관적인-비유-카드놀이#가장 직관적인 비유: 카드놀이":"삽입 정렬은 우리가 손에 든 카드를 정렬하는 방식과 매우 유사합니다.\n바닥에 놓인 카드 뭉치(정렬되지 않은 부분)에서 카드 한 장을 집습니다. 이미 손에 들고 있는 정렬된 카드들(정렬된 부분)과 비교합니다. 새로 집은 카드를 손에 든 카드들 사이의 올바른 위치에 꽂아 넣습니다. 이때, 새 카드가 들어갈 자리를 만들기 위해 기존 카드들을 한 칸씩 뒤로 밀어낼 수 있습니다. 바닥에 카드가 없을 때까지 이 과정을 반복합니다. 이 비유처럼, 삽입 정렬은 ‘하나를 꺼내서’, ‘적절한 위치를 찾아’, ‘삽입하는’ 단순한 원리를 기반으로 동작합니다.","결론#\u003cstrong\u003e결론\u003c/strong\u003e":"힙 정렬은 이론적으로나 실제적으로나 매우 뛰어난 정렬 알고리즘입니다. buildHeap의 선형 시간 복잡도, 전체적인 O(n log n)의 보장된 성능, 그리고 O(1)의 추가 공간 사용량은 힙 정렬을 다양한 상황에서 신뢰할 수 있는 선택지로 만듭니다. 제공된 슬라이드는 이러한 힙 정렬의 핵심적인 구성 요소인 buildHeap, pushDown, 그리고 반복적인 최댓값 추출 과정을 간결하면서도 정확하게 보여주고 있습니다. 이 상세 설명을 통해 알고리즘의 모든 단계를 완벽하게 이해하고, 직접 구현하거나 분석하는 데 큰 도움이 되기를 바랍니다.","결론-단순함-속에-담긴-깊이#결론: 단순함 속에 담긴 깊이":"모든 쌍 최단 경로 문제는 동적 계획법의 설계 패러다임을 보여주는 위대한 예시입니다. 이 문제는 우리에게 중요한 교훈을 줍니다. 때로는 문제의 차원을 다르게 바라보는 것, 즉 경로의 길이나 정점의 개수가 아닌 ‘허용된 중간 정점’ 이라는 새로운 기준을 도입하는 창의적인 발상이 복잡성의 장벽을 무너뜨리는 열쇠가 될 수 있다는 것입니다. 플로이드-워셜 알고리즘의 우아함은 바로 이 지점에서 빛을 발하며, 복잡한 네트워크 문제에 대한 강력하고 체계적인 해법을 제시합니다.","결론-및-요약#\u003cstrong\u003e결론 및 요약\u003c/strong\u003e":"이 장에서는 알고리즘 설계의 핵심 패러다임인 분할 정복에 대해 깊이 있게 탐구했습니다.\n분할 정복의 힘:\n분할 정복은 복잡한 문제를 균형 잡힌(balanced) 작은 부분 문제들로 나누어 해결함으로써 효율성을 극대화하는 전략입니다. ‘균형’은 알고리즘의 성능에 매우 중요합니다. 비슷한 크기로 나눌 때 O(n log n)과 같은 효율적인 시간 복잡도를 달성할 수 있습니다. 최댓값/최솟값 찾기, 합병 정렬, 빠른 정렬, 선택 문제 등 다양한 문제에서 그 강력함을 확인할 수 있었습니다. 이들은 모두 부분 문제들이 서로 독립적이라는 공통점을 가집니다. 분할과 합병의 상호작용:\n합병 정렬: 분할은 간단하고(O(1)), 합병이 핵심적인 작업(O(n))을 수행합니다. 빠른 정렬: 분할이 핵심적인 작업(O(n))을 수행하고, 합병은 사실상 필요 없습니다(O(1)). 문제의 특성에 따라 분할과 합병 단계 중 어느 쪽에 무게를 둘 것인지가 결정됩니다. 분할 정복의 한계와 대안:\n피보나치 수열 예제에서 보았듯이, 부분 문제들이 서로 중복되어 재계산이 빈번하게 발생하는 경우, 분할 정복은 오히려 지수 시간의 비효율을 초래합니다. 이러한 중복되는 부분 문제(overlapping subproblems) 구조를 가진 문제에는 동적 계획법이 훨씬 효과적인 해결책을 제공합니다. 분할 정복은 단순히 알고리즘 목록에 있는 하나의 기법이 아니라, 문제를 바라보고 구조화하는 강력한 사고방식입니다. 복잡한 현실 세계의 문제를 만났을 때, 그것을 더 작고 관리 가능한 조각으로 나누어 해결하고 다시 합치는 이 접근법은 컴퓨터 과학을 넘어 다양한 분야에서 유용하게 적용될 수 있는 지혜를 제공합니다.\n네, 제공해주신 강의 자료를 바탕으로 “제6장: 동적 계획\"에 대한 매우 상세하고 포괄적인 설명을 6만자 이상으로 작성해 드리겠습니다. 각 슬라이드의 내용을 심층적으로 확장하고, 동적 계획의 핵심 원리, 문제 해결 과정, 구체적인 예제(막대 자르기, 연속 행렬 곱셈, 모든 쌍 최단 경로, 배낭 채우기)의 단계별 분석을 포함하여 구성하겠습니다.","결론-복잡성을-길들이는-체계적인-접근#결론: 복잡성을 길들이는 체계적인 접근":"효율성 분석: 동적 계획법 알고리즘은 3개의 중첩된 루프(l, i, k)로 구성되어 있습니다. 각 루프는 최대 n번 정도 반복되므로, 전체 시간 복잡도는 **Θ(n³)**입니다. 이는 분할 정복 방식의 지수 시간 복잡도와는 비교할 수 없을 정도로 효율적입니다. n이 100이라면, 100³은 100만이지만, 지수 시간은 천문학적인 숫자가 됩니다. 공간 복잡도: n × n 크기의 테이블 m을 사용하므로 공간 복잡도는 Θ(n²) 입니다. 연속 행렬 곱셈 문제는 동적 계획법의 설계 과정을 가장 잘 보여주는 교과서적인 예제입니다.\n최적화 문제의 구조를 파악하고 점화식을 세웁니다. 가장 작은 부분 문제부터 시작하여 상향식으로 해를 구축합니다. 테이블을 사용하여 계산된 해를 저장하고 재사용함으로써 중복 계산을 완벽하게 제거합니다. 겉보기에는 복잡하고 수많은 경우의 수를 따져야 할 것 같은 문제였지만, 동적 계획법이라는 체계적인 접근법을 통해 다항 시간 내에 효율적으로 해결할 수 있었습니다. 이는 복잡한 문제에 직면했을 때, 문제를 올바르게 분해하고 그 관계를 파악하는 것이 얼마나 중요한지를 보여주는 강력한 증거입니다.\n네, 알겠습니다. 앞서 다룬 막대 자르기 문제에 이어, 동적 계획법의 힘을 더욱 극적으로 보여주는 연속 행렬 곱셈(Matrix Chain Multiplication) 문제에 대해 이야기 형식으로 매우 상세하게 설명해 드리겠습니다.\n네, 알겠습니다. 제공해주신 우수한 자료를 바탕으로, 독자의 이해 흐름을 최적화하기 위해 순서를 재구성하고 내용을 다듬어 이야기 형식으로 상세하게 설명해 드리겠습니다.","결론-현명한-기억의-힘#결론: 현명한 기억의 힘":"막대 자르기 문제는 분할 정복의 순진한 재귀적 접근이 왜 비효율적인지, 그리고 동적 계획법이 어떻게 그 문제를 해결하는지를 보여주는 훌륭한 예시입니다.\n핵심은 **‘문제를 한 번만 푸는 것’**입니다. 분할 정복은 동일한 질문을 계속해서 반복하지만, 동적 계획법은 한 번 얻은 답을 테이블에 기록해두고 필요할 때마다 꺼내 씁니다. 이 ‘기억(memoization)‘이라는 단순한 아이디어 하나가 지수 시간을 다항 시간으로 바꾸는 극적인 성능 향상을 가져옵니다.\n따라서, 어떤 문제를 해결해야 할 때 다음 두 가지 특징이 보인다면 동적 계획법을 가장 먼저 떠올려야 합니다.\n중복되는 부분 문제: 작은 문제들의 해가 여러 번 필요하다. 최적 부분 구조: 전체 문제의 최적해가 부분 문제들의 최적해로 구성된다. 동적 계획법은 알고리즘의 효율성을 극대화하는 매우 중요하고 강력한 도구이며, 수많은 최적화 문제 해결의 기반이 됩니다.","고급-정렬퀵-병합-힙-정렬과의-관계#고급 정렬(퀵, 병합, 힙 정렬)과의 관계":"","고급-정렬퀵-병합-힙-정렬과의-관계-1#고급 정렬(퀵, 병합, 힙 정렬)과의 관계":"퀵 정렬, 병합 정렬, 힙 정렬과 같은 고급 정렬 알고리즘들은 평균 O(n log n)의 시간 복잡도를 가집니다. 이는 O(n²)보다 훨씬 효율적이므로 대규모 데이터 정렬에는 이들이 사용됩니다. 하지만 재미있게도, 이들 고급 알고리즘은 종종 삽입 정렬을 부분적으로 활용합니다.\n하이브리드 정렬(Hybrid Sort): 퀵 정렬이나 병합 정렬은 재귀적으로 문제를 분할하다가, 배열의 크기가 특정 임계값(예: 16개 또는 32개) 이하로 작아지면 삽입 정렬로 전환하여 처리합니다. 작은 배열에서는 재귀 호출의 오버헤드보다 삽입 정렬의 단순함이 더 빠르기 때문입니다. 파이썬의 표준 정렬 함수(Timsort)나 C++의 std::sort(Introsort)가 이런 방식을 사용합니다.","공간-복잡도-분석#공간 복잡도 분석":"삽입 정렬의 주요 특징 및 심층 분석 (Slide 24)","공간-복잡도-분석-1#공간 복잡도 분석":"삽입 정렬은 정렬을 위해 입력 배열 외에 추가적인 데이터 구조를 필요로 하지 않습니다. i, j, key와 같은 몇 개의 변수만을 사용하며, 이 변수들의 수는 입력 크기 n에 관계없이 일정합니다. 이를 제자리 정렬(In-place sort) 이라고 하며, 공간 복잡도는 O(1) 입니다.","그림으로-이해하는-단일-삽입-과정#그림으로 이해하는 단일 삽입 과정":"전체 삽입 정렬 알고리즘 (Slide 22) 알고리즘의 구조: 외부 루프와 내부 루프","그림으로-이해하는-단일-삽입-과정-1#그림으로 이해하는 단일 삽입 과정":"배열 A = [3, 8, 12, 15, 7, ...] 가 있고, i=4일 때, A[4]=7을 삽입하는 과정을 보겠습니다. A[0..]은 [3, 8, 12, 15]로 정렬된 상태입니다.\n초기 상태:\ninsertElement = 7 j = 3 배열: [3, 8, 12, 15, 15] (논리적으로 A[4]는 비어있다고 생각) A: [ 3, 8, 12, 15, ? ] insertElement: 7 ^ j while 루프 (1차 반복):\nj=3 \u003e= 0 이고, A[3](15) \u003e insertElement(7) -\u003e 참 A[4] = A[3]. (15를 오른쪽으로 이동) j는 2가 됨. 배열: [3, 8, 12, 15, 15] A: [ 3, 8, 12, ?, 15 ] insertElement: 7 ^ j while 루프 (2차 반복):\nj=2 \u003e= 0 이고, A[2](12) \u003e insertElement(7) -\u003e 참 A[3] = A[2]. (12를 오른쪽으로 이동) j는 1이 됨. 배열: [3, 8, 12, 12, 15] A: [ 3, 8, ?, 12, 15 ] insertElement: 7 ^ j while 루프 (3차 반복):\nj=1 \u003e= 0 이고, A[1](8) \u003e insertElement(7) -\u003e 참 A[2] = A[1]. (8을 오른쪽으로 이동) j는 0이 됨. 배열: [3, 8, 8, 12, 15] A: [ 3, ?, 8, 12, 15 ] insertElement: 7 ^ j while 루프 (4차 반복):\nj=0 \u003e= 0 이고, A[0](3) \u003e insertElement(7) -\u003e 거짓. 루프 종료! 현재 j는 0. 삽입:\nA[j+1] = insertElement -\u003e A[1] = 7. 최종 배열: [3, 7, 8, 12, 15] 이제 A[0..]가 완벽하게 정렬되었습니다. 이 과정을 전체 배열에 대해 반복하는 것이 삽입 정렬입니다.","기본-연산basic-operation의-정의#기본 연산(Basic Operation)의 정의":"","기본-연산basic-operation의-정의-1#기본 연산(Basic Operation)의 정의":"알고리즘의 실행 시간을 지배하는 가장 빈번하게 수행되는 연산을 ‘기본 연산’으로 정의합니다. 슬라이드 23에서는 삽입 정렬의 기본 연산을 내부 while 루프의 조건 비교인 A[j] \u003e insertElement로 정의했습니다. 우리는 이 비교 연산의 횟수를 분석할 것입니다.","단계-1#\u003cstrong\u003e단계 1: \u003ccode\u003ebuildHeap\u003c/code\u003e의 시간 복잡도 - O(n)\u003c/strong\u003e":"많은 사람들이 buildHeap이 n/2개의 노드에 대해 pushDown을 수행하고, 각 pushDown은 트리의 높이(log n)에 비례하므로 O(n log n)이라고 착각하기 쉽습니다. 하지만 실제로는 더 타이트한 분석을 통해 **O(n)**임을 보일 수 있습니다.\n분석의 핵심: pushDown의 연산량은 해당 노드가 얼마나 아래로 내려가는지에 따라 결정됩니다. 즉, 해당 노드로부터 리프 노드까지의 높이에 비례합니다. 트리의 높이를 h (약 log n)라고 합시다. 리프 노드들 (높이 0): 약 n/2개의 노드가 있습니다. 이들은 pushDown을 하지 않습니다. 연산량 = 0. 리프 바로 위 레벨의 노드들 (높이 1): 약 n/4개의 노드가 있습니다. 이들은 최악의 경우 1 레벨만 내려갑니다. 연산량 ∝ (n/4) * 1. 높이 k인 노드들: 약 n / 2^(k+1)개의 노드가 있고, 이들은 최악의 경우 k 레벨을 내려갑니다. 연산량 ∝ (n / 2^(k+1)) * k. 루트 노드 (높이 h): 1개의 노드가 있고, 최악의 경우 h 레벨을 내려갑니다. 연산량 ∝ 1 * h. 이를 수식으로 표현하면 총 연산량은 다음과 같은 급수의 합에 비례합니다. S = Σ (k * (n / 2^(k+1))) (k는 0부터 h까지) S = (n/2) * Σ (k / 2^k)\n여기서 Σ (k / 2^k) (k=0 to ∞)는 2로 수렴하는 잘 알려진 무한 등비급수입니다. 따라서 총 연산량 S는 (n/2) * 2 = n에 비례하게 됩니다.\n결론적으로, buildHeap 단계는 O(n)의 선형 시간이 걸립니다. 대부분의 노드가 트리의 아래쪽에 몰려 있어 pushDown을 하더라도 멀리 이동하지 않기 때문입니다.","단계-2-정렬의-시간-복잡도---on-log-n#\u003cstrong\u003e단계 2: 정렬의 시간 복잡도 - O(n log n)\u003c/strong\u003e":"이 단계의 분석은 더 직관적입니다.\nwhile 루프는 eh가 n부터 2까지 총 n-1번 반복됩니다. 각 반복에서 가장 많은 시간을 소요하는 작업은 pushDown(A, 1, ..., eh) 입니다. 이 pushDown은 항상 루트에서 시작합니다. 연산량은 현재 힙의 높이에 비례합니다. 힙의 크기가 k일 때 높이는 O(log k)입니다. 루프가 진행됨에 따라 힙의 크기는 n-1, n-2, ..., 2로 줄어들지만, 각 pushDown의 시간 복잡도는 상한선인 O(log n)으로 볼 수 있습니다. 따라서 총 시간 복잡도는 다음과 같습니다. T(n) = (n-1) * (한 번의 pushDown 연산) T(n) = (n-1) * O(log n) = O(n log n)","단점-비효율적인-성능-on#단점: 비효율적인 성능 (O(n²))":"다른 정렬 알고리즘과의 비교 및 활용","단점-비효율적인-성능-on-1#단점: 비효율적인 성능 (O(n²))":"삽입 정렬의 가장 큰 단점은 평균과 최악의 경우 시간 복잡도가 O(n²)이라는 점입니다. 데이터의 크기 n이 커질수록 실행 시간은 기하급수적으로 늘어납니다. 1만 개의 데이터를 정렬하는 데 1초가 걸렸다면, 10만 개의 데이터를 정렬하는 데는 약 100초(1분 40초)가 걸릴 수 있습니다. 따라서 대규모 데이터를 정렬하는 데는 적합하지 않습니다.","대표적인-예-피보나치-수열#대표적인 예: 피보나치 수열":"피보나치 수열은 다음과 같이 정의됩니다. f(0) = 0, f(1) = 1 (슬라이드에서는 1-based index로 f0=1, f1=1로 정의) f(n) = f(n-1) + f(n-2) for n \u003e= 2\n이 정의는 그 자체로 분할 정복의 재귀적 구조를 가지고 있습니다. f(n)이라는 문제를 f(n-1)과 f(n-2)라는 두 개의 작은 문제로 나누어 해결할 수 있기 때문입니다.","더-나은-길을-찾아서-동적-계획법의-통찰#더 나은 길을 찾아서: 동적 계획법의 통찰":"이 문제, 어딘가 익숙하지 않나요? 하나의 큰 결정(n개의 보물 선택)이 여러 개의 작은 결정들의 연속으로 이루어집니다. 그리고 그 결정들은 서로 영향을 줍니다. 이는 동적 계획법이 활약할 수 있는 좋은 무대입니다. 동적 계획법을 적용하기 위한 두 가지 핵심 속성을 다시 확인해 봅시다.\n최적 부분 구조 (Optimal Substructure): n개의 보물과 용량 C에 대한 최적의 해(최대 가치)는, 그보다 작은 부분 문제들의 최적의 해를 기반으로 구성될 수 있어야 합니다. 중복되는 부분 문제 (Overlapping Subproblems): 전체 문제를 해결하는 과정에서 동일한 부분 문제가 반복적으로 나타나야 합니다. 배낭 문제도 이 속성을 가질까요? 그렇습니다. n개의 아이템에 대한 최적의 선택은, n-1개의 아이템에 대한 최적의 선택과 관련이 있습니다. 이 관계를 명확히 정의하는 것이 동적 계획법 설계의 첫걸음입니다.","더-나은-해결책-동적-계획법-dynamic-programming#더 나은 해결책: 동적 계획법 (Dynamic Programming)":"이러한 중복 계산 문제를 해결하기 위한 패러다임이 바로 **동적 계획법(Dynamic Programming)**입니다. 동적 계획법의 핵심은 한 번 계산한 부분 문제의 결과는 저장해두고(Memoization), 다시 필요할 때 재계산 없이 가져다 쓰는 것입니다.","동적-계획-알고리즘-설계-bottom-up-방식#동적 계획 알고리즘 설계 (Bottom-up 방식)":"동적 계획법은 보통 ‘상향식(Bottom-up)‘으로 문제를 해결합니다. 즉, 가장 작은 부분 문제부터 차례대로 풀어나가면서 그 결과를 테이블에 저장하고, 더 큰 문제를 풀 때 이 테이블의 값을 활용하는 방식입니다.\n막대 자르기 문제에서 가장 작은 문제는 무엇일까요? 바로 길이가 0인 막대입니다. 그 다음은 길이 1, 길이 2, … 순서로 n까지 문제를 풀어 나가면 됩니다.\n결과를 저장할 배열(테이블)을 만듭니다. maxSell[0...n]이라는 배열을 선언하고, maxSell[j]에는 길이 j 막대의 최대 판매 금액을 저장할 것입니다. 가장 작은 문제부터 해결합니다. maxSell[0] = 0 (길이 0인 막대의 가격은 0) 반복문을 통해 점진적으로 큰 문제를 해결합니다. j를 1부터 n까지 증가시키면서 maxSell[j]를 계산합니다. maxSell[j]를 계산하기 위해, 우리는 이전에 이미 계산해 둔 maxSell[0], maxSell[1], ..., maxSell[j-1] 값들을 사용할 수 있습니다. R(j) = max( p[k] + R(j-k) ) 점화식을 그대로 적용하되, R(j-k) 대신 이미 계산된 값인 maxSell[j-k]를 사용합니다. 이를 코드로 구현하면 다음과 같습니다.\n// 동적 계획법 방식의 막대 자르기 알고리즘 cutRod_DP(p[], n) { // 1. 결과를 저장할 배열 선언 배열 maxSell[0...n]을 선언한다. // 2. 가장 작은 문제의 해 초기화 maxSell[0] = 0; // 3. 점진적으로 큰 문제 해결 (j = 1부터 n까지) for (j = 1; j \u003c= n; j++) { maxVal = 0; // maxSell[j]를 계산하기 위해 모든 가능한 첫 조각 k를 고려 for (k = 1; k \u003c= j; k++) { // p[k] + maxSell[j-k] : 첫 조각을 k로 잘랐을 때의 이익 // maxSell[j-k]는 이전에 이미 계산된 최적의 값이다. maxVal = MAX(maxVal, p[k] + maxSell[j - k]); } // j에 대한 최댓값을 테이블에 저장 maxSell[j] = maxVal; } // 최종적으로 우리가 원하는 길이 n에 대한 해를 반환 return maxSell[n]; }","동적-계획-알고리즘-실행-과정-추적#동적 계획 알고리즘 실행 과정 추적":"위 알고리즘이 어떻게 동작하는지 가격표 (p[1]=2, p[2]=5, p[3]=9, p[4]=10)와 n=4를 예로 들어 단계별로 따라가 보겠습니다.\n초기 상태: maxSell 배열이 생성되고 maxSell[0]은 0으로 초기화됩니다. p = [?, 2, 5, 9, 10] maxSell = [0, ?, ?, ?, ?]\nj = 1 (길이 1 막대의 최대 이익 계산)\nmaxVal를 0으로 초기화. k = 1: maxVal = MAX(0, p[1] + maxSell[1-1]) = MAX(0, 2 + maxSell[0]) = MAX(0, 2 + 0) = 2 maxSell[1] = 2 현재 상태: maxSell = [0, 2, ?, ?, ?]\nj = 2 (길이 2 막대의 최대 이익 계산)\nmaxVal를 0으로 초기화. k = 1: maxVal = MAX(0, p[1] + maxSell[2-1]) = MAX(0, 2 + maxSell[1]) = MAX(0, 2 + 2) = 4 k = 2: maxVal = MAX(4, p[2] + maxSell[2-2]) = MAX(4, 5 + maxSell[0]) = MAX(4, 5 + 0) = 5 maxSell[2] = 5 현재 상태: maxSell = [0, 2, 5, ?, ?]\nj = 3 (길이 3 막대의 최대 이익 계산)\nmaxVal를 0으로 초기화. k = 1: maxVal = MAX(0, p[1] + maxSell[3-1]) = MAX(0, 2 + maxSell[2]) = MAX(0, 2 + 5) = 7 k = 2: maxVal = MAX(7, p[2] + maxSell[3-2]) = MAX(7, 5 + maxSell[1]) = MAX(7, 5 + 2) = 7 k = 3: maxVal = MAX(7, p[3] + maxSell[3-3]) = MAX(7, 9 + maxSell[0]) = MAX(7, 9 + 0) = 9 maxSell[3] = 9 현재 상태: maxSell = [0, 2, 5, 9, ?]\nj = 4 (길이 4 막대의 최대 이익 계산)\nmaxVal를 0으로 초기화. k = 1: maxVal = MAX(0, p[1] + maxSell[4-1]) = MAX(0, 2 + maxSell[3]) = MAX(0, 2 + 9) = 11 k = 2: maxVal = MAX(11, p[2] + maxSell[4-2]) = MAX(11, 5 + maxSell[2]) = MAX(11, 5 + 5) = 11 k = 3: maxVal = MAX(11, p[3] + maxSell[4-3]) = MAX(11, 9 + maxSell[1]) = MAX(11, 9 + 2) = 11 k = 4: maxVal = MAX(11, p[4] + maxSell[4-4]) = MAX(11, 10 + maxSell[0]) = MAX(11, 10 + 0) = 11 maxSell[4] = 11 최종 상태: maxSell = [0, 2, 5, 9, 11]\n모든 반복이 끝나면 maxSell[4]에는 11이 저장되어 있습니다. 알고리즘은 이 값을 반환하고, 우리는 길이 4의 막대로 얻을 수 있는 최대 이익이 11이라는 것을 알게 됩니다.\n이 과정을 슬라이드의 표와 비교해보면 정확히 일치하는 것을 볼 수 있습니다.","동적-계획-알고리즘-실행-과정-추적-1#동적 계획 알고리즘 실행 과정 추적":"이제 슬라이드의 예제를 통해 이 마법 같은 과정이 어떻게 이루어지는지 한 칸 한 칸 따라가 보겠습니다.\n문제 상황:\n배낭 용량 C = 7 물건 n = 4개 물건 i 무게 w[i] 가치 v[i] 1 3 25 2 1 15 3 2 20 4 4 30 테이블 준비: K[0.][0.] 크기의 테이블을 만듭니다.\n1단계: 초기화\ni=0인 행(0번째 행)은 ‘아무 물건도 고려하지 않았을 때’를 의미하므로, 어떤 용량의 배낭이든 최대 가치는 0입니다. K[0, j] = 0. j=0인 열(0번째 열)은 ‘배낭 용량이 0일 때’를 의미하므로, 어떤 물건도 담을 수 없어 최대 가치는 0입니다. K[i, 0] = 0. i\\j 0 1 2 3 4 5 6 7 0 0 0 0 0 0 0 0 0 1 0 2 0 3 0 4 0 2단계: i = 1 행 계산 (물건 1: w=3, v=25 고려)\n이제 물건 1 하나만 가지고 배낭을 채워봅니다.\nj w[1]\u003ej? 계산: max( K[0,j], v[1]+K[0,j-w[1]] ) K[1,j] 1 3 \u003e 1 (Yes) K[0,1] = 0 0 2 3 \u003e 2 (Yes) K[0,2] = 0 0 3 3 \u003c= 3 (No) max(K[0,3], 25+K[0,0]) = max(0, 25) 25 4 3 \u003c= 4 (No) max(K[0,4], 25+K[0,1]) = max(0, 25) 25 5 3 \u003c= 5 (No) max(K[0,5], 25+K[0,2]) = max(0, 25) 25 6 3 \u003c= 6 (No) max(K[0,6], 25+K[0,3]) = max(0, 25) 25 7 3 \u003c= 7 (No) max(K[0,7], 25+K[0,4]) = max(0, 25) 25 현재 테이블:\ni\\j 0 1 2 3 4 5 6 7 0 0 0 0 0 0 0 0 0 1 0 0 0 25 25 25 25 25 2 0 3 0 4 0 3단계: i = 2 행 계산 (물건 1, 2 고려. 물건 2: w=1, v=15)\n이제 물건 1과 2를 가지고 배낭을 채웁니다. 계산은 항상 바로 윗 행의 값을 참조합니다.\nj w[2]\u003ej? 계산: max( K[1,j], v[2]+K[1,j-w[2]] ) K[2,j] 1 1 \u003c= 1 (No) max(K[1,1], 15+K[1,0]) = max(0, 15+0) 15 2 1 \u003c= 2 (No) max(K[1,2], 15+K[1,1]) = max(0, 15+0) 15 3 1 \u003c= 3 (No) max(K[1,3], 15+K[1,2]) = max(25, 15+0) 25 4 1 \u003c= 4 (No) max(K[1,4], 15+K[1,3]) = max(25, 15+25) 40 5 1 \u003c= 5 (No) max(K[1,5], 15+K[1,4]) = max(25, 15+25) 40 6 1 \u003c= 6 (No) max(K[1,6], 15+K[1,5]) = max(25, 15+25) 40 7 1 \u003c= 7 (No) max(K[1,7], 15+K[1,6]) = max(25, 15+25) 40 현재 테이블:\ni\\j 0 1 2 3 4 5 6 7 0 0 0 0 0 0 0 0 0 1 0 0 0 25 25 25 25 25 2 0 15 15 25 40 40 40 40 3 0 4 0 4단계: i = 3 행 계산 (물건 1, 2, 3 고려. 물건 3: w=2, v=20)\nj w[3]\u003ej? 계산: max( K[2,j], v[3]+K[2,j-w[3]] ) K[3,j] 1 2 \u003e 1 (Yes) K[2,1] = 15 15 2 2 \u003c= 2 (No) max(K[2,2], 20+K[2,0]) = max(15, 20+0) 20 3 2 \u003c= 3 (No) max(K[2,3], 20+K[2,1]) = max(25, 20+15) 35 4 2 \u003c= 4 (No) max(K[2,4], 20+K[2,2]) = max(40, 20+15) 40 5 2 \u003c= 5 (No) max(K[2,5], 20+K[2,3]) = max(40, 20+25) 45 6 2 \u003c= 6 (No) max(K[2,6], 20+K[2,4]) = max(40, 20+40) 60 7 2 \u003c= 7 (No) max(K[2,7], 20+K[2,5]) = max(40, 20+40) 60 현재 테이블:\ni\\j 0 1 2 3 4 5 6 7 0 0 0 0 0 0 0 0 0 1 0 0 0 25 25 25 25 25 2 0 15 15 25 40 40 40 40 3 0 15 20 35 40 45 60 60 4 0 5단계: i = 4 행 계산 (모든 물건 고려. 물건 4: w=4, v=30)\nj w[4]\u003ej? 계산: max( K[3,j], v[4]+K[3,j-w[4]] ) K[4,j] 1 4 \u003e 1 (Yes) K[3,1] = 15 15 2 4 \u003e 2 (Yes) K[3,2] = 20 20 3 4 \u003e 3 (Yes) K[3,3] = 35 35 4 4 \u003c= 4 (No) max(K[3,4], 30+K[3,0]) = max(40, 30+0) 40 5 4 \u003c= 5 (No) max(K[3,5], 30+K[3,1]) = max(45, 30+15) 45 6 4 \u003c= 6 (No) max(K[3,6], 30+K[3,2]) = max(60, 30+20) 60 7 4 \u003c= 7 (No) max(K[3,7], 30+K[3,3]) = max(60, 30+35) 65 최종 테이블:\ni\\j 0 1 2 3 4 5 6 7 0 (w) 0 0 0 0 0 0 0 0 1 (3) 0 0 0 25 25 25 25 25 2 (1) 0 15 15 25 40 40 40 40 3 (2) 0 15 20 35 40 45 60 60 4 (4) 0 15 20 35 40 45 60 65 드디어 테이블이 완성되었습니다! 우리가 찾던 최종 답, K[4, 7]은 65입니다. 탐험가는 최대 65의 가치를 배낭에 담아 유적을 탈출할 수 있습니다.","동적-계획-알고리즘-실행-과정-추적-예제-풀이#동적 계획 알고리즘 실행 과정 추적 (예제 풀이)":"이제 슬라이드의 예제를 통해 이 알고리즘이 마법처럼 동작하는 과정을 단계별로 따라가 보겠습니다.\n문제: M₁ × M₂ × M₃ × M₄ 의 최소 곱셈 횟수를 구하라.\nM₁: 10 × 20 M₂: 20 × 50 M₃: 50 × 1 M₄: 1 × 100 차원 배열 r: 행렬 Mᵢ가 rᵢ₋₁ × rᵢ 크기이므로, r 배열은 다음과 같습니다. r = [r₀, r₁, r₂, r₃, r₄] = [10, 20, 50, 1, 100]\n테이블 m: 4x4 크기의 테이블을 준비합니다.\n1단계: 초기화 (체인 길이 1, l=0)\n가장 작은 문제인 m[i,i]를 0으로 채웁니다.\nm[1,1] = 0 m[2,2] = 0 m[3,3] = 0 m[4,4] = 0 i\\j 1 2 3 4 1 0 2 0 3 0 4 0 2단계: l = 1 (체인 길이 2)\n길이가 2인 체인들(m[1,2], m[2,3], m[3,4])의 최소 비용을 계산합니다. 이 경우 분할 지점 k는 하나뿐입니다.\nm[1,2] 계산 (M₁ × M₂)\ni=1, j=2, 분할 지점 k=1 비용 = m[1,1] + m[2,2] + r₀r₁r₂ 비용 = 0 + 0 + 10 × 20 × 50 = 10,000 m[1,2] = 10000 m[2,3] 계산 (M₂ × M₃)\ni=2, j=3, 분할 지점 k=2 비용 = m[2,2] + m[3,3] + r₁r₂r₃ 비용 = 0 + 0 + 20 × 50 × 1 = 1,000 m[2,3] = 1000 m[3,4] 계산 (M₃ × M₄)\ni=3, j=4, 분할 지점 k=3 비용 = m[3,3] + m[4,4] + r₂r₃r₄ 비용 = 0 + 0 + 50 × 1 × 100 = 5,000 m[3,4] = 5000 현재 테이블 상태:\ni\\j 1 2 3 4 1 0 10000 2 0 1000 3 0 5000 4 0 3단계: l = 2 (체인 길이 3)\n길이가 3인 체인들(m[1,3], m[2,4])의 최소 비용을 계산합니다. 이제 분할 지점이 두 개씩 생깁니다.\nm[1,3] 계산 (M₁ × M₂ × M₃)\ni=1, j=3. 가능한 분할 지점 k=1, 2. k=1일 때: (M₁) × (M₂ × M₃) 비용 = m[1,1] + m[2,3] + r₀r₁r₃ 비용 = 0 + 1000 + 10 × 20 × 1 = 1,200 k=2일 때: (M₁ × M₂) × (M₃) 비용 = m[1,2] + m[3,3] + r₀r₂r₃ 비용 = 10000 + 0 + 10 × 50 × 1 = 10,500 min(1200, 10500) = 1200. 따라서 m[1,3] = 1200 m[2,4] 계산 (M₂ × M₃ × M₄)\ni=2, j=4. 가능한 분할 지점 k=2, 3. k=2일 때: (M₂) × (M₃ × M₄) 비용 = m[2,2] + m[3,4] + r₁r₂r₄ 비용 = 0 + 5000 + 20 × 50 × 100 = 105,000 k=3일 때: (M₂ × M₃) × (M₄) 비용 = m[2,3] + m[4,4] + r₁r₃r₄ 비용 = 1000 + 0 + 20 × 1 × 100 = 3,000 min(105000, 3000) = 3000. 따라서 m[2,4] = 3000 현재 테이블 상태:\ni\\j 1 2 3 4 1 0 10000 1200 2 0 1000 3000 3 0 5000 4 0 4단계: l = 3 (체인 길이 4)\n마지막으로, 우리가 구하고자 하는 전체 체인(m[1,4])의 최소 비용을 계산합니다.\nm[1,4] 계산 (M₁ × M₂ × M₃ × M₄) i=1, j=4. 가능한 분할 지점 k=1, 2, 3. k=1일 때: (M₁) × (M₂ × M₃ × M₄) 비용 = m[1,1] + m[2,4] + r₀r₁r₄ 비용 = 0 + 3000 + 10 × 20 × 100 = 23,000 k=2일 때: (M₁ × M₂) × (M₃ × M₄) 비용 = m[1,2] + m[3,4] + r₀r₂r₄ 비용 = 10000 + 5000 + 10 × 50 × 100 = 65,000 k=3일 때: (M₁ × M₂ × M₃) × (M₄) 비용 = m[1,3] + m[4,4] + r₀r₃r₄ 비용 = 1200 + 0 + 10 × 1 × 100 = 2,200 min(23000, 65000, 2200) = 2200. 따라서 m[1,4] = 2200 최종 테이블 상태:\ni\\j 1 2 3 4 1 0 10000 1200 2200 2 0 1000 3000 3 0 5000 4 0 모든 계산이 끝났습니다. 테이블의 m[1,4]에 저장된 값 2,200이 바로 M₁ × M₂ × M₃ × M₄를 계산하는 데 필요한 최소 스칼라 곱셈 횟수입니다. 그리고 이 최적의 비용은 k=3일 때, 즉 (M₁ × M₂ × M₃) × M₄ 순서로 곱했을 때 얻어진다는 것도 알 수 있습니다. (물론 (M₁ × M₂ × M₃)의 최적 순서는 m[1,3] 계산 과정에서 (M₁) × (M₂ × M₃)로 이미 결정되었습니다.)","동적-계획법-기반-알고리즘#\u003cstrong\u003e동적 계획법 기반 알고리즘\u003c/strong\u003e":"슬라이드 49의 알고리즘은 상향식(Bottom-up) 접근법을 사용합니다.\n가장 작은 문제인 F(0)과 F(1)부터 계산을 시작합니다. 이 결과를 배열(또는 변수)에 저장합니다. 저장된 값들을 이용하여 F(2), F(3), …, F(n)을 차례대로 계산해 나갑니다. F_DP(n) 1 F[0] = 1 2 F[1] = 1 3 for i from 2 to n 4 F[i] = F[i-1] + F[i-2] 5 return F[n] 이 알고리즘은 for 루프를 n-1번 반복하며, 각 반복마다 덧셈 한 번만 수행합니다. 따라서 시간 복잡도는 **O(n)**으로, 재귀적인 분할 정복 방식의 O(1.618^n)과 비교할 수 없을 정도로 효율적입니다.","동적-계획법의-핵심-부분-문제-정의하기#동적 계획법의 핵심: 부분 문제 정의하기":"문제를 체계적으로 풀기 위해, 우리는 결과를 기록할 테이블을 만들고, 그 테이블의 각 칸이 무엇을 의미하는지 명확하게 정의해야 합니다. K[i][j]라는 2차원 배열을 사용해 봅시다.\nK[i][j]: 첫 번째 보물부터 i번째 보물까지만 고려했을 때, 용량이 j인 배낭에 담을 수 있는 최대 가치\n이 정의가 가장 중요합니다. i는 우리가 고려할 보물의 범위를, j는 우리가 가진 배낭의 용량을 나타내는 ‘상태(state)‘입니다. 우리의 최종 목표는 테이블의 가장 마지막 칸, 즉 K[n][C] (모든 n개의 보물을 고려했고, 배낭의 최대 용량이 C일 때의 최대 가치)를 알아내는 것입니다.","동적-계획법의-효율성-분석#동적 계획법의 효율성 분석":"시간 복잡도: 알고리즘은 2개의 중첩된 반복문으로 구성됩니다. 바깥쪽 j 루프는 1부터 n까지 n번 실행됩니다. 안쪽 k 루프는 j번 실행됩니다. 따라서 기본 연산(MAX 계산 및 덧셈)의 총 실행 횟수는 1 + 2 + 3 + ... + n이 됩니다. 이는 n(n+1)/2와 같으므로, 시간 복잡도는 Θ(n²) 입니다.\n공간 복잡도: 해를 저장하기 위해 크기가 n+1인 maxSell 배열을 사용하므로, 공간 복잡도는 Θ(n) 입니다.\n분할 정복의 지수 시간 복잡도 O(2^n)과 비교해볼 때, 동적 계획법의 다항 시간 복잡도 Θ(n²)는 엄청나게 효율적입니다. n이 30일 때, 2^30은 10억이 넘는 수지만 30^2은 고작 900입니다. 이 차이가 바로 동적 계획법의 힘입니다.","두-번째-시도-동적-계획법dynamic-programming#두 번째 시도: 동적 계획법(Dynamic Programming)":"동적 계획법은 바로 이 ‘중복되는 부분 문제’를 해결하기 위해 탄생한 알고리즘 설계 기법입니다. 아이디어는 매우 간단합니다.\n“어떤 문제든 딱 한 번만 풀고, 그 결과를 저장해두었다가 나중에 필요할 때 다시 계산하지 말고 가져다 쓰자.”\n이 기법을 적용하기 위해서는 두 가지 속성이 문제에 존재해야 합니다.\n중복되는 부분 문제 (Overlapping Subproblems): 위에서 확인했듯이, 막대 자르기 문제는 이 속성을 만족합니다. 최적 부분 구조 (Optimal Substructure): 문제의 최적의 해가 부분 문제들의 최적의 해로부터 구성될 수 있다는 것입니다. 막대 자르기 문제에서 길이 i의 최적해는, 첫 조각 k를 자른 후 남은 i-k 길이 막대의 최적해에 p[k]를 더한 값들 중 최대값으로 구성되므로 이 속성 또한 만족합니다. 이러한 문제의 구조는 분할 정복의 트리 구조와 달리, 공유되는 부분 문제를 가진 DAG(Directed Acyclic Graph) 구조로 시각화할 수 있습니다.\n(a) 분할 정복은 각 부분 문제가 독립적인 트리 구조를 가집니다. (b) 동적 계획은 E와 같은 부분 문제가 여러 상위 문제(B, C)에 의해 공유되는 구조를 가지며, 이 E를 한 번만 계산하는 것이 핵심입니다.","두-번째-시도-동적-계획법의-설계#두 번째 시도: 동적 계획법의 설계":"우리는 이미 해법을 알고 있습니다. 이 문제는 ‘최적 부분 구조’와 ‘중복되는 부분 문제’라는 동적 계획법의 전제 조건을 완벽하게 만족합니다. 따라서 재귀 대신, 가장 작은 부분 문제부터 차례로 해결하여 그 결과를 테이블에 저장하는 상향식(Bottom-up) 동적 계획법을 적용할 수 있습니다.\n결과를 저장할 2차원 배열(테이블)을 만듭니다. m[i][j]는 Mᵢ부터 Mⱼ까지 곱하는 데 필요한 최소 곱셈 횟수, 즉 matMult(i, j)의 값을 저장할 공간입니다.\n가장 작은 문제부터 해결합니다. 가장 작은 문제는 곱셈 체인의 길이가 1인 경우, 즉 m[i][i]입니다. 이 경우 곱셈이 없으므로 비용은 0입니다. m[i][i] = 0으로 테이블의 대각선을 모두 채웁니다.\n점진적으로 문제의 크기를 키워나갑니다. 그 다음으로 작은 문제는 체인 길이가 2인 경우(m[i][i+1]), 그 다음은 3인 경우(m[i][i+2]), … 마지막으로 우리가 원하는 체인 길이 n인 경우(m[1][n])까지 순서대로 계산합니다.\n이 ‘체인의 길이’를 제어하는 것이 이 알고리즘의 핵심입니다. 변수 l을 체인의 길이라고 합시다. l은 2부터 n까지 증가합니다. (슬라이드에서는 l을 j-i로 정의하여 1부터 n-1까지 증가시켰는데, 이는 동일한 개념입니다.)\nl = 1일 때: 길이가 2인 체인(m[1,2], m[2,3], …)을 모두 계산합니다. l = 2일 때: 길이가 3인 체인(m[1,3], m[2,4], …)을 모두 계산합니다. 이때 m[1,3]을 계산하려면 이미 계산된 m[1,1], m[2,3], m[1,2], m[3,3] 등의 값이 필요하며, 우리는 이미 이 값들을 테이블에 저장해 두었습니다. … l = n-1일 때: 길이가 n인 유일한 체인, 즉 m[1,n]을 계산합니다. 이것이 최종 답입니다. 이 로직을 코드로 구현하면 다음과 같습니다.\n// 동적 계획법 방식의 연속 행렬 곱셈 알고리즘 matMult_DP(r[], n) { // 1. 결과 저장용 2차원 배열 m 선언 배열 m[1..n, 1..n]을 선언한다. // 2. 가장 작은 문제(체인 길이 1) 해결 for (i = 1; i \u003c= n; i++) { m[i, i] = 0; } // 3. 점진적으로 문제 크기(체인 길이 l)를 키움 // l은 체인의 길이 - 1 (j-i) for (l = 1; l \u003c= n - 1; l++) { // i는 체인의 시작 인덱스 for (i = 1; i \u003c= n - l; i++) { j = i + l; // j는 체인의 끝 인덱스 m[i, j] = ∞; // 최솟값을 찾기 위해 무한대로 초기화 // k는 분할 지점 for (k = i; k \u003c j; k++) { // 점화식을 DP 테이블을 이용하여 계산 cost = m[i, k] + m[k+1, j] + r[i - 1]*r[k]*r[j]; if (cost \u003c m[i, j]) { m[i, j] = cost; } } } } // 최종적으로 우리가 원하는 해(m[1,n])를 반환 return m[1, n]; }","막대-자르기-문제rod-cutting-problem#막대 자르기 문제(Rod Cutting Problem)":"","모든-쌍-최단-경로-all-pairs-shortest-path#모든 쌍 최단 경로 (All-Pairs Shortest Path)":"","목차#목차":"삽입 정렬이란 무엇인가? (개요) 핵심 아이디어: 정렬된 부분과 정렬되지 않은 부분 가장 직관적인 비유: 카드놀이 삽입 정렬의 핵심 메커니즘: 하나의 요소 삽입하기 (Slides 19-21) 목표: 정렬되지 않은 부분의 첫 요소를 정렬된 부분의 올바른 위치에 넣기","문제-정의#문제 정의":"길이가 n인 막대와 각 길이별 판매 가격표가 주어졌을 때, 막대를 어떻게 잘라야 전체 판매 금액을 최대로 할 수 있는지 찾는 문제입니다. 막대는 여러 조각으로 자를 수 있으며, 자르지 않고 통째로 파는 것도 하나의 방법입니다.\n예를 들어, 다음과 같은 가격표가 있다고 가정해 보겠습니다.\n길이 (i) 1 2 3 4 가격 (p[i]) 2 5 9 10 만약 우리에게 길이가 4인 막대가 주어진다면, 어떤 방법들이 있을까요?\n자르지 않음: 길이 4짜리 한 개 -\u003e 가격 10 한 번 자름: 1 + 3으로 자름 -\u003e p[1] + p[3] = 2 + 9 = 11 2 + 2로 자름 -\u003e p[2] + p[2] = 5 + 5 = 10 두 번 자름: 1 + 1 + 2로 자름 -\u003e p[1] + p[1] + p[2] = 2 + 2 + 5 = 9 세 번 자름: 1 + 1 + 1 + 1로 자름 -\u003e p[1] * 4 = 2 * 4 = 8 이 모든 경우를 비교해보니, 1과 3으로 잘랐을 때의 판매 금액 11이 최대 이익임을 알 수 있습니다. 우리의 목표는 어떤 길이 n에 대해서도 이 최대 이익을 찾는 알고리즘을 설계하는 것입니다.","문제의-공식화와-첫-번째-시도-모든-가능성을-시험하다-지-기법#문제의 공식화와 첫 번째 시도: 모든 가능성을 시험하다 (지 기법)":"탐험가의 고민을 알고리즘 문제로 바꾸어 봅시다.\nn: 보물의 총개수 w[i]: i번째 보물의 무게 v[i]: i번째 보물의 가치 C: 배낭이 견딜 수 있는 최대 무게 (용량) 우리의 목표는, 선택한 보물들의 총무게가 C를 넘지 않으면서, 총가치가 최대가 되는 보물들의 조합을 찾는 것입니다.\n가장 단순하고 무식한 방법은 무엇일까요? 바로 가능한 모든 경우의 수를 다 시험해 보는 것입니다. 보물이 n개 있다면, 각 보물에 대해 ‘가져간다’와 ‘가져가지 않는다’ 두 가지 선택지가 있습니다. 따라서 총 경우의 수는 2 × 2 × ... × 2 (n번), 즉 2ⁿ가지가 됩니다.\n이 억지 기법(Brute-force) 알고리즘은 다음과 같이 동작합니다.\nn개 보물들의 모든 부분 집합(조합)을 하나씩 만들어 봅니다. (총 2ⁿ개) 각 조합에 대해, 포함된 보물들의 총무게를 계산합니다. 총무게가 배낭 용량 C를 초과하면, 그 조합은 버립니다. 용량을 초과하지 않는 조합이라면, 포함된 보물들의 총가치를 계산합니다. 모든 유효한 조합들의 총가치 중 가장 큰 값을 찾아냅니다. 이 방법은 보물의 개수(n)가 10개만 되어도 2¹⁰ = 1024개의 조합을, 20개면 2²⁰으로 백만 개가 넘는 조합을, 30개면 10억 개가 넘는 조합을 일일이 확인해야 합니다. 시간 복잡도가 **Ω(2ⁿ)**으로, n이 조금만 커져도 현실적으로 계산이 불가능한 ‘나쁜’ 알고리즘입니다.\n우리에겐 더 똑똑한 방법이 필요합니다.","버블-정렬bubble-sort과의-비교#버블 정렬(Bubble Sort)과의 비교":"","버블-정렬bubble-sort과의-비교-1#버블 정렬(Bubble Sort)과의 비교":"공통점: 둘 다 O(n²)이며, 안정 정렬이고, 제자리 정렬입니다. 차이점: 버블 정렬도 최적화를 통해 거의 정렬된 데이터에 대해 O(n)의 성능을 낼 수 있지만(적응성), 일반적으로 삽입 정렬이 내부 루프의 구조상 더 적은 비교와 교환을 수행하여 실제 실행 시간이 더 빠른 경향이 있습니다. 대부분의 경우 삽입 정렬이 버블 정렬보다 선호됩니다.","분할-정복-설계-전략의-3단계#\u003cstrong\u003e분할 정복 설계 전략의 3단계\u003c/strong\u003e":"분할 정복 알고리즘은 일반적으로 다음과 같은 세 가지 명확한 단계로 구성됩니다. 이 3단계는 분할 정복의 심장과도 같으며, 거의 모든 분할 정복 알고리즘이 이 구조를 따릅니다.","분할-정복-전략#분할 정복 전략":"분할 정복은 이 문제를 다른 각도에서 접근합니다. 비교 횟수를 줄이는 것이 목표입니다.\n분할(Divide): 주어진 배열 A를 거의 같은 크기의 두 부분 배열 A_left와 A_right로 나눕니다. 예를 들어, n개의 요소가 있다면, 앞쪽 n/2개와 뒤쪽 n/2개로 나눕니다.\n정복(Conquer): 두 개의 부분 배열에 대해 재귀적으로 최댓값과 최솟값을 찾습니다.\nA_left에서 최댓값(max1)과 최솟값(min1)을 찾습니다. A_right에서 최댓값(max2)과 최솟값(min2)을 찾습니다. 이 과정은 배열에 요소가 하나 또는 두 개만 남을 때까지 계속됩니다 (기저 사례). 합병(Merge): 이제 네 개의 값(max1, min1, max2, min2)을 가지고 원래 배열 A의 전체 최댓값과 최솟값을 결정합니다.\n전체 최댓값 max(A) = max(max1, max2) (비교 1회) 전체 최솟값 min(A) = min(min1, min2) (비교 1회) 즉, 합병 단계에서는 단 2번의 비교만 필요합니다.","분할-정복-접근법의-치명적인-문제#분할 정복 접근법의 치명적인 문제":"이 코드는 정확한 답을 찾아줍니다. 하지만 피보나치 수열의 예처럼, 심각한 비효율을 내포하고 있습니다. cutRod_DC(p, 4)를 호출했을 때의 실행 트리를 살펴봅시다.\n위 그림은 R(4)를 계산하기 위한 재귀 호출의 구조를 보여줍니다.\nR(4)를 계산하기 위해 R(3), R(2), R(1), R(0)을 호출합니다. R(3)을 계산하기 위해 R(2), R(1), R(0)을 호출합니다. R(2)를 계산하기 위해 R(1), R(0)을 호출합니다. 보시다시피, R(2)는 R(4)를 계산하는 과정과 R(3)을 계산하는 과정에서 총 2번 호출됩니다. R(1)은 R(4), R(3), R(2)를 계산하는 과정에서 총 4번이나 호출됩니다. 이렇게 동일한 부분 문제에 대한 계산이 반복적으로 일어나는 ‘중복되는 부분 문제’ 현상이 여기서도 명확하게 나타납니다.\n이 알고리즘의 시간 복잡도를 분석해보면 T(n) = Σ T(n-k) + 1 (k=1 to n) 형태가 되며, 이는 T(n) = 2^n에 가까운 지수 시간 복잡도(Exponential Time Complexity)를 가집니다. n이 조금만 커져도 계산 시간이 폭발적으로 증가하여 현실적으로 사용할 수 없는 알고리즘이 됩니다.","분할-정복을-이용한-선택-알고리즘-quickselect#분할 정복을 이용한 선택 알고리즘 (Quickselect)":"이 알고리즘은 빠른 정렬(Quick Sort)의 아이디어를 차용하여 매우 효율적으로 선택 문제를 해결합니다. 그래서 종종 **퀵셀렉트(Quickselect)**라고도 불립니다.\n분할(Divide): 빠른 정렬과 동일하게, 배열에서 기준(pivot)을 하나 선택하고 분할(Partition) 작업을 수행합니다. 이 작업이 끝나면 기준은 p 인덱스에 위치하게 되고, A[p]는 배열 내에서 (p - first + 1)번째로 작은 요소가 됩니다.\n정복(Conquer) \u0026 선택:\n분할 작업 후 기준의 위치 p를 k와 비교합니다. Small 그룹 (기준 왼쪽)의 크기를 s = p - first 라고 합시다. (슬라이드에서는 s = p - 1 - first + 1로 표현, 즉 p - first와 동일) Case 1: k == s + 1: 우리가 찾던 k번째 요소가 바로 기준(pivot) 자신입니다! 탐색을 종료하고 A[p]를 반환합니다. Case 2: k \u003c= s: k번째 요소는 기준보다 작으므로, Small 그룹 안에 있습니다. Small 그룹(왼쪽 부분 배열)에 대해 재귀적으로 k번째 요소를 찾습니다. Case 3: k \u003e s + 1: k번째 요소는 기준보다 크므로, Large 그룹 안에 있습니다. Large 그룹(오른쪽 부분 배열)에서 찾아야 합니다. 단, 이때는 그냥 k번째를 찾는 것이 아니라, Small 그룹과 기준을 제외한 나머지 중에서 찾아야 하므로 (k - s - 1)번째 요소를 재귀적으로 찾습니다. 이 알고리즘의 핵심은 빠른 정렬처럼 양쪽을 모두 재귀 호출하는 것이 아니라, 한쪽 부분 배열에 대해서만 재귀 호출을 한다는 점입니다. 이로 인해 시간 복잡도가 크게 향상됩니다.","분할-정복의-한계-중복되는-계산의-비효율성#분할 정복의 한계: 중복되는 계산의 비효율성":"우리는 알고리즘 설계 기법 중 하나인 **분할 정복(Divide and Conquer)**에 대해 이미 알고 있습니다. 분할 정복은 주어진 문제를 더 이상 나눌 수 없을 때까지 작은 부분 문제(subproblem)들로 나누고(Divide), 각각의 부분 문제를 해결한(Conquer) 후, 그 해들을 다시 합쳐(Combine) 원래 문제의 해를 구하는 강력한 방식입니다. 대표적인 예로 병합 정렬(Merge Sort)이나 퀵 정렬(Quick Sort)이 있습니다.\n하지만 분할 정복이 모든 문제에 효율적인 해결책을 제시하는 것은 아닙니다. 분할 정복의 핵심은 ‘서로 독립적인’ 부분 문제로 나누는 것입니다. 예를 들어 병합 정렬에서 배열의 왼쪽 절반을 정렬하는 문제와 오른쪽 절반을 정렬하는 문제는 서로 전혀 영향을 주지 않습니다.\n그러나 어떤 문제들은 나누어진 부분 문제들이 서로 독립적이지 않고, 동일한 부분 문제를 여러 번 반복해서 풀어야 하는 경우가 발생합니다. 가장 고전적인 예가 피보나치 수열입니다.\nfib(n) = fib(n-1) + fib(n-2)\n이 점화식을 그대로 재귀 함수로 구현하면 fib(5)를 계산하기 위해 fib(4)와 fib(3)을 호출합니다. 그런데 fib(4)를 계산하는 과정에서 또다시 fib(3)과 fib(2)를 호출하게 됩니다. 결국 fib(3)이라는 동일한 부분 문제가 두 번 이상 계산되는 것을 볼 수 있습니다. 문제의 크기가 커질수록 이런 중복 계산은 기하급수적으로 늘어나고, 알고리즘의 효율성은 최악으로 치닫게 됩니다.\n이처럼 중복되는 부분 문제(Overlapping Subproblems) 구조를 가진 문제에 단순한 분할 정복을 적용하면 심각한 비효율을 초래합니다.\n이제 이러한 특성을 가진 또 다른 문제, 바로 ‘막대 자르기 문제’를 통해 이 문제를 해결하는 **동적 계획법(Dynamic Programming)**의 위력을 살펴보겠습니다.","빠른-정렬-시간-복잡도-분석#빠른 정렬 시간 복잡도 분석":"빠른 정렬의 성능은 기준(pivot)을 얼마나 잘 선택하느냐에 따라 극적으로 달라집니다.\n최선의 경우 (Best Case):\n매번 분할(Partition) 과정에서 기준이 배열을 정확히 절반으로 나눌 때 발생합니다. 점화식: T(n) = 2 * T(n/2) + O(n) (분할에 O(n) 소요) 시간 복잡도: O(n log n). 합병 정렬과 동일합니다. 최악의 경우 (Worst Case):\n매번 기준이 가장 작거나 가장 큰 요소로 선택될 때 발생합니다. 예를 들어, 이미 정렬된 배열에서 항상 첫 번째 요소를 기준으로 선택하는 경우입니다. 이 경우, 배열은 크기 0과 n-1의 극도로 불균형한 두 부분 배열로 나뉩니다. 점화식: T(n) = T(n-1) + O(n) 시간 복잡도: O(n^2). 선택 정렬만큼 비효율적이 됩니다. 평균적인 경우 (Average Case):\n기준이 무작위로 선택된다면, 분할이 어느 정도 균형을 이룰 확률이 높습니다. 수학적으로 분석하면, 평균 시간 복잡도는 O(n log n)으로 최선의 경우와 같습니다. 이러한 이유로, 실제 구현에서는 기준을 무작위로 선택하거나, 세 개의 요소(처음, 중간, 끝) 중 중앙값을 선택하는 등의 기법을 사용하여 최악의 경우를 피하려 노력합니다. 빠른 정렬은 합병 정렬과 달리 추가적인 배열이 필요 없는 **제자리 정렬(in-place sort)**이 가능하여 공간 효율성이 높고, 평균 성능이 매우 뛰어나 널리 사용됩니다.","빠른-정렬의-분할-정복-전략#빠른 정렬의 분할 정복 전략":"빠른 정렬은 합병 정렬과 분할/합병 단계의 복잡도가 반대입니다.\n분할(Divide): 이 단계가 빠른 정렬의 핵심입니다. 배열 내의 한 요소를 **기준(pivot)**으로 선택합니다. 그리고 기준보다 작은 모든 요소는 기준의 왼쪽으로, 큰 모든 요소는 기준의 오른쪽으로 옮기는 분할(Partition) 작업을 수행합니다. 이 작업이 끝나면 기준 요소는 최종적으로 정렬될 위치에 놓이게 됩니다. 합병 정렬과 달리, 이 분할 과정이 O(n)의 작업을 수행합니다.\n정복(Conquer): 기준의 왼쪽 부분 배열과 오른쪽 부분 배열에 대해 재귀적으로 빠른 정렬을 수행합니다.\n합병(Merge): 아무것도 할 필요가 없습니다. 분할 단계에서 이미 기준을 중심으로 모든 요소가 정렬될 위치의 큰 틀(왼쪽/오른쪽)을 잡았기 때문에, 두 부분 배열이 각각 정렬되면 전체 배열이 자동으로 정렬됩니다. 이 합병 단계가 O(1)로 매우 간단하다는 것이 빠른 정렬의 특징입니다.","삽입-정렬-함수-구현#삽입 정렬 함수 구현":"","삽입-정렬-함수-구현-1#삽입 정렬 함수 구현":"#include #include void insertionSort(std::vector\u003cint\u003e\u0026 arr) { // n은 배열의 크기 int n = arr.size(); // 외부 루프: i는 1부터 시작하여 배열의 끝까지 순회 // arr[0...i-1]은 정렬된 부분, arr[i...n-1]은 정렬되지 않은 부분 for (int i = 1; i \u003c n; ++i) { // Step 1: 삽입할 요소를 키(또는 insertElement)로 저장 int key = arr[i]; // Step 2: 삽입할 위치를 찾기 위해 정렬된 부분의 끝에서부터 시작 int j = i - 1; // Step 3: 내부 루프 - key가 들어갈 위치를 찾으면서 // key보다 큰 요소들을 오른쪽으로 한 칸씩 이동 // j \u003e= 0 조건은 배열의 시작을 벗어나지 않도록 보장 // arr[j] \u003e key 조건은 삽입 위치를 찾는 핵심 비교 while (j \u003e= 0 \u0026\u0026 arr[j] \u003e key) { arr[j + 1] = arr[j]; // 요소를 오른쪽으로 이동 j = j - 1; // 비교할 다음 요소로 이동 (왼쪽으로) } // Step 4: 찾은 위치(j+1)에 key를 삽입 // 루프가 끝난 시점의 j는 key보다 작거나 같은 첫 번째 요소의 인덱스이거나 -1 arr[j + 1] = key; } }","삽입-정렬insertion-sort#삽입 정렬(Insertion Sort)":"","삽입-정렬은-언제-유용한가#삽입 정렬은 언제 유용한가?":"요약 및 결론","삽입-정렬은-언제-유용한가-1#삽입 정렬은 언제 유용한가?":"데이터의 크기 n이 작을 때: 오버헤드가 적어 O(n log n) 알고리즘보다 빠를 수 있습니다. 데이터가 거의 정렬되어 있을 때: O(n)에 가까운 성능을 보여 매우 효율적입니다. 안정 정렬이 필요하고, 추가 메모리 사용이 불가능할 때: 이 조건을 만족하는 가장 간단한 알고리즘 중 하나입니다.","상세한-단계별-실행-예제#상세한 단계별 실행 예제":"C++ 전체 구현 코드 및 해설","상세한-단계별-실행-예제-1#상세한 단계별 실행 예제":"배열 A = [5, 2, 4, 6, 1, 3] (n=6)을 정렬하는 과정을 따라가 보겠습니다. | 기호는 정렬된 부분과 정렬되지 않은 부분을 구분합니다.\n초기 상태: [| 5, 2, 4, 6, 1, 3] (크기 0인 정렬된 부분. 실질적으로 A[0]부터 시작)\ni = 1: A[1] = 2를 삽입.\ninsertElement = 2, j = 0 while (j=0 \u003e= 0 and A[0](5) \u003e 2): 참 A[1] = A[0]. -\u003e [5, 5, 4, 6, 1, 3] j = -1. 루프 종료. A[j+1] 즉 A[0] = 2. 결과: [2, 5 | 4, 6, 1, 3] i = 2: A[2] = 4를 삽입.\ninsertElement = 4, j = 1 while (j=1 \u003e= 0 and A[1](5) \u003e 4): 참 A[2] = A[1]. -\u003e [2, 5, 5, 6, 1, 3] j = 0. while (j=0 \u003e= 0 and A[0](2) \u003e 4): 거짓. 루프 종료. A[j+1] 즉 A[1] = 4. 결과: [2, 4, 5 | 6, 1, 3] i = 3: A[3] = 6를 삽입.\ninsertElement = 6, j = 2 while (j=2 \u003e= 0 and A[2](5) \u003e 6): 거짓. 루프 즉시 종료. A[j+1] 즉 A[3] = 6. (변화 없음) 결과: [2, 4, 5, 6 | 1, 3] i = 4: A[4] = 1를 삽입.\ninsertElement = 1, j = 3 while 루프는 j가 3, 2, 1, 0일 때 모두 참. 모든 요소를 한 칸씩 오른쪽으로 민다. [2, 4, 5, 6, 6, 3] [2, 4, 5, 5, 6, 3] [2, 4, 4, 5, 6, 3] [2, 2, 4, 5, 6, 3] j가 -1이 되어 루프 종료. A[j+1] 즉 A[0] = 1. 결과: [1, 2, 4, 5, 6 | 3] i = 5: A[5] = 3을 삽입.\ninsertElement = 3, j = 4 while (j=4 \u003e= 0 and A[4](6) \u003e 3): 참. j는 3. -\u003e [1, 2, 4, 5, 6, 6] while (j=3 \u003e= 0 and A[3](5) \u003e 3): 참. j는 2. -\u003e [1, 2, 4, 5, 5, 6] while (j=2 \u003e= 0 and A[2](4) \u003e 3): 참. j는 1. -\u003e [1, 2, 4, 4, 5, 6] while (j=1 \u003e= 0 and A[1](2) \u003e 3): 거짓. 루프 종료. A[j+1] 즉 A[2] = 3. 결과: [1, 2, 3, 4, 5, 6 |] 최종 정렬 완료: [1, 2, 3, 4, 5, 6]","서론-위대한-문제-해결-전략-분할-정복#\u003cstrong\u003e서론: 위대한 문제 해결 전략, 분할 정복\u003c/strong\u003e":"알고리즘 설계는 단순히 문제를 해결하는 코드를 작성하는 것을 넘어, 가장 효율적이고 우아한 해결책을 찾는 과정입니다. 수많은 문제 해결 전략 중에서 ‘분HAL 정복(Divide and Conquer)‘은 가장 강력하고 널리 사용되는 패러다임 중 하나입니다. 이 이름은 로마 제국의 율리우스 카이사르가 사용했던 ‘분할하여 통치하라(Divide et Impera)‘라는 정치 전략에서 유래했습니다. 거대하고 강력한 적을 한 번에 상대하기보다, 여러 개의 작은 그룹으로 분열시켜 각개격파하는 것이 훨씬 효과적이라는 이 아이디어는 컴퓨터 과학의 문제 해결에도 그대로 적용됩니다.\n분할 정복 전략의 핵심 철학은 **“크고 복잡한 문제는 해결하기 어렵지만, 작고 단순한 문제는 해결하기 쉽다”**는 것입니다. 따라서 해결 불가능해 보이는 거대한 문제를 해결 가능한 작은 조각들로 나눈 뒤, 각 조각의 답을 구하고, 그 답들을 다시 현명하게 조합하여 원래 문제의 답을 찾아내는 방식입니다.\n이 장에서는 분할 정복 패러다임의 기본 구조를 시작으로, 이 전략이 어떻게 최댓값/최솟값 찾기, 정렬(합병 정렬, 빠른 정렬), k번째 작은 원소 찾기(선택 문제)와 같은 고전적이고 중요한 문제들을 효율적으로 해결하는지 심도 있게 탐구할 것입니다. 또한, 분할 정복 전략이 항상 최선은 아니며, 특정 조건(부분 문제의 중복)에서는 오히려 비효율을 초래할 수 있다는 점을 피보나치 수열 예제를 통해 살펴보고, 이러한 경우 동적 계획법(Dynamic Programming)과 같은 다른 패러다임이 더 적합한 이유에 대해서도 논의할 것입니다.","서론-힙-정렬이란-무엇인가#\u003cstrong\u003e서론: 힙 정렬이란 무엇인가?\u003c/strong\u003e":"힙 정렬은 ‘힙(Heap)‘이라는 자료구조를 이용하여 데이터를 정렬하는 알고리즘입니다. 선택 정렬(Selection Sort)을 응용한 알고리즘이라고 볼 수 있는데, 선택 정렬이 매번 전체 배열에서 최솟값(또는 최댓값)을 찾아 자리를 교환하는 방식이라면, 힙 정렬은 힙이라는 자료구조를 통해 이 ‘최댓값(또는 최솟값)을 찾는 과정’을 매우 효율적으로 만들어 성능을 극대화한 방법입니다.\n힙 정렬의 핵심 아이디어는 두 가지 주요 단계로 나뉩니다.\n힙 구성(Build Heap) 단계: 정렬되지 않은 입력 배열을 ‘힙’이라는 특정 조건을 만족하는 트리 구조로 만듭니다. 일반적으로 최댓값을 기준으로 하는 ‘최대 힙(Max-Heap)‘을 사용합니다. 정렬(Sorting) 단계: 힙의 루트(root) 노드는 항상 최댓값을 가집니다. 이 루트 노드의 값을 배열의 가장 마지막 요소와 교환합니다. 그리고 힙의 크기를 하나 줄인 후, 흐트러진 힙 구조를 다시 바로잡습니다. 이 과정을 힙에 요소가 하나만 남을 때까지 반복합니다. 결과적으로 배열의 끝에서부터 가장 큰 값들이 차례대로 정렬됩니다. 힙 정렬은 평균과 최악의 경우 모두 **O(n log n)**의 시간 복잡도를 가지며, 추가적인 메모리 공간을 거의 사용하지 않는 **제자리 정렬(in-place sort)**이라는 큰 장점을 가집니다. 이제 슬라이드의 내용을 따라가며 이 두 단계를 원자 단위까지 분해하여 살펴보겠습니다.","서막-궁극의-내비게이션을-향하여#서막: 궁극의 내비게이션을 향하여":"우리가 매일 사용하는 내비게이션은 “A에서 B까지 가는 가장 빠른 길\"이라는 하나의 질문에 답합니다. 이는 컴퓨터 과학에서 단일 출발점 최단 경로(Single-Source Shortest Path) 문제로, 다익스트라 알고리즘이 훌륭한 해답을 제공합니다.\n하지만 만약 우리가 이 서비스를 운영하는 회사라면 어떨까요? 우리는 수많은 사용자의 무작위적인 출발-도착점 요청에 즉각적으로 응답해야 합니다. 더 나아가, 도시 전체의 교통 흐름을 분석하거나, 물류 회사가 수백 개의 지점 사이의 최적 운송 루트를 미리 계산하거나, 항공사가 모든 공항 간의 최적 환승 경로를 파악해야 하는 상황을 상상해 봅시다.\n이런 경우, 우리는 도시의 모든 지점에서 다른 모든 지점까지의 최단 경로를 미리 계산해 두는 것이 훨씬 효율적입니다. 이것이 바로 모든 쌍 최단 경로(All-Pairs Shortest Path, APSP) 문제입니다. 이는 단순히 길 하나를 찾는 것을 넘어, 네트워크 전체의 구조적인 연결성을 완벽하게 이해하려는 궁극의 내비게이션 과제와 같습니다.","선택-알고리즘-시간-복잡도#선택 알고리즘 시간 복잡도":"최선/평균의 경우:\n매번 기준이 배열을 적절한 비율로 나눈다면 (예: 3:7), 탐색해야 할 배열의 크기는 매 단계마다 cn (단, c \u003c 1)으로 줄어듭니다. 점화식: T(n) = T(cn) + O(n) (분할에 O(n) 소요) 이 점화식의 해는 O(n)입니다. n + cn + c^2n + ... = n(1+c+c^2+...)는 등비수열의 합으로 n/(1-c) 이므로 O(n)입니다. 정렬(O(n log n))보다 훨씬 빠른 선형 시간에 k번째 요소를 찾을 수 있습니다. 최악의 경우:\n빠른 정렬과 마찬가지로, 매번 기준이 가장 크거나 작은 값으로 선택되어 탐색 범위가 하나씩만 줄어드는 경우입니다. 점화식: T(n) = T(n-1) + O(n) 시간 복잡도: O(n^2)","선택-알고리즘-예제-상세-분석-슬라이드-42#선택 알고리즘 예제 상세 분석 (슬라이드 42)":"문제: \u003c 48 12 70 38 75 67 96 52 81\u003e (n=9) 에서 중앙값, 즉 5번째(k=5) 작은 수를 찾아라.\n최초 호출: selection(A, 0, 8, k=5)\n분할: 첫 번째 요소인 48을 기준으로 선택합니다. 분할 후 배열 상태: \u003c 38 12 | 48 | 70 75 67 96 52 81 \u003e (실제 분할 구현에 따라 순서는 다를 수 있음). 기준 48은 인덱스 2에 위치 (p=2). Small 그룹(A[0.])의 크기 s = p - first = 2 - 0 = 2. 선택: 우리가 찾는 k=5는 s+1=3보다 큽니다 (k \u003e s+1). 따라서 답은 Large 그룹에 있습니다. Large 그룹 (A[3.])에서 k' = k - s - 1 = 5 - 2 - 1 = 2번째 작은 요소를 찾습니다. 재귀 호출: selection(A, 3, 8, k=2) 두 번째 호출: selection(A, 3, 8, k=2) (\u003c 70 75 67 96 52 81 \u003e 부분)\n분할: 현재 부분 배열의 첫 요소인 70을 기준으로 선택합니다. 분할 후 부분 배열 상태: \u003c 67 52 | 70 | 96 75 81 \u003e. 기준 70은 원래 배열 인덱스 5에 위치 (p=5). 현재 부분 배열 범위는 first=3, last=8입니다. Small 그룹(A[3.])의 크기 s = p - first = 5 - 3 = 2. 선택: 우리가 찾는 k=2는 s=2와 같습니다 (k \u003c= s). 따라서 답은 Small 그룹에 있습니다. Small 그룹 (A[3.])에서 여전히 k=2번째 작은 요소를 찾습니다. 재귀 호출: selection(A, 3, 4, k=2) 세 번째 호출: selection(A, 3, 4, k=2) (\u003c 67 52 \u003e 부분)\n분할: 첫 요소 67을 기준으로 선택합니다. 분할 후 부분 배열 상태: \u003c 52 | 67 \u003e. 기준 67은 원래 배열 인덱스 4에 위치 (p=4). 현재 부분 배열 범위는 first=3, last=4입니다. Small 그룹 (A[3.])의 크기 s = p - first = 4 - 3 = 1. 선택: 우리가 찾는 k=2는 s+1=2와 같습니다 (k == s+1). 찾았습니다! 기준 요소인 A[p] = A[4] = 67이 바로 우리가 찾던 5번째 작은 수입니다. 67을 반환하고 모든 재귀 호출이 종료됩니다. (참고: 정렬된 배열: 12, 38, 48, 52, 67, 70, 75, 81, 96. 5번째는 67이 맞습니다.)","선택-정렬selection-sort과의-비교#선택 정렬(Selection Sort)과의 비교":"","선택-정렬selection-sort과의-비교-1#선택 정렬(Selection Sort)과의 비교":"공통점: 둘 다 O(n²) 시간 복잡도를 가지며, 제자리 정렬입니다. 차이점: 비교 횟수: 선택 정렬은 데이터의 상태와 무관하게 항상 n(n-1)/2번 비교합니다. 삽입 정렬은 최선의 경우 O(n)번만 비교합니다 (적응성). 교환(이동) 횟수: 선택 정렬은 교환(swap)이 최대 n-1번으로 매우 적습니다. 반면 삽입 정렬은 최악의 경우 O(n²)번의 데이터 이동(shift)이 발생합니다. 데이터 이동 비용이 매우 큰 경우 선택 정렬이 더 나을 수 있습니다. 안정성: 삽입 정렬은 안정적이지만, 일반적인 선택 정렬 구현은 불안정합니다.","쉬운-전략#쉬운 전략":"가장 간단한 방법은 배열 전체를 정렬한 뒤, k-1 인덱스에 있는 요소를 반환하는 것입니다.\n합병 정렬이나 빠른 정렬(평균)을 사용하면 O(n log n)의 시간이 걸립니다. 하지만 우리는 전체를 정렬할 필요 없이 단지 k번째 요소만 찾으면 됩니다. 과연 더 빠르게 할 수 있을까요?","쉬운-전략-naive-approach#쉬운 전략 (Naive Approach)":"가장 직관적이고 간단한 방법은 최댓값을 먼저 찾고, 그 다음에 최솟값을 찾는 것입니다.\n최댓값 찾기: 배열의 첫 번째 요소를 현재 최댓값(max)으로 가정합니다. 이후 배열의 두 번째 요소부터 마지막 요소까지 순회하면서, 현재 요소가 현재 최댓값보다 크면 최댓값을 갱신합니다. n개의 요소가 있다면, 첫 요소를 제외한 (n-1)개의 요소와 비교해야 하므로, 비교 횟수는 (n-1)회 입니다.\n최솟값 찾기: 최댓값을 찾는 과정과 동일합니다. 첫 번째 요소를 현재 최솟값(min)으로 가정하고, 나머지 (n-1)개의 요소와 비교하며 최솟값을 갱신합니다. 비교 횟수는 (n-1)회 입니다.\n하지만, 슬라이드에서는 최댓값을 찾은 뒤 “남은 배열\"에서 최솟값을 찾는다고 설명하여 약간의 오해를 줄 수 있습니다. 일반적인 순차 탐색에서는 최댓값을 찾는 과정과 최솟값을 찾는 과정이 별개로 진행됩니다. 따라서,\n최댓값을 찾기 위한 비교: n-1회 최솟값을 찾기 위한 비교: n-1회 총 비교 횟수: (n-1) + (n-1) = 2n - 2회 슬라이드에서 제시한 (n-1) + (n-2) = 2n-3은 최댓값을 찾은 후, 그 최댓값은 최솟값이 될 수 없다는 가정 하에 남은 n-1개의 요소 중에서 최솟값을 찾는 경우를 상정한 것으로 보입니다. 이 경우에도 시간 복잡도는 O(n)으로 동일하며, 상수 배의 차이만 존재합니다. 이 방법은 매우 간단하지만, 과연 이것이 최선일까요?","쉬운-전략-선택-정렬과-그-한계#쉬운 전략 (선택 정렬)과 그 한계":"슬라이드 10에서 언급된 ‘쉬운 전략’은 사실상 **선택 정렬(Selection Sort)**과 유사한 아이디어입니다.\n전체 배열에서 최솟값을 찾습니다. (비교 n-1회) 해당 최솟값을 배열의 첫 번째 위치에 둡니다. 남은 n-1개의 요소에 대해 1~2번 과정을 반복합니다. 두 번째 최솟값을 찾아 두 번째 위치에 둡니다. (비교 n-2회) … 마지막 두 요소 중 작은 것을 n-1번째 위치에 둡니다. (비교 1회) 분석:\n총 비교 횟수 = (n-1) + (n-2) + ... + 2 + 1 = n(n-1)/2 시간 복잡도: O(n^2) 슬라이드에서는 이 전략이 **‘균형 취하기 발견법’**을 사용하지 않았다고 지적합니다. 여기서 ‘균형 취하기(balancing)‘란 문제를 비슷한 크기의 부분 문제들로 나누는 것을 의미합니다. 선택 정렬은 크기 n의 문제를 크기 1(찾아낸 최솟값)과 크기 n-1(나머지)의 부분 문제로 나눕니다. 이렇게 극도로 불균형하게 문제를 분할하는 것은 분할 정복의 이점을 전혀 살리지 못하며, 결국 O(n^2)의 비효율적인 결과를 낳습니다.","슬라이드-39-내부-노드의-힙-조건-확인#\u003cstrong\u003e슬라이드 39: 내부 노드의 힙 조건 확인\u003c/strong\u003e":"이 슬라이드는 힙을 만들어가는 과정의 가장 기본적인 연산, 즉 특정 노드 x에서 힙 조건이 깨졌을 때 이를 어떻게 복구하는지에 대한 아이디어를 설명합니다. 이 연산을 보통 heapify 또는 슬라이드에서처럼 pushDown이라고 부릅니다.\n어떤 내부 노드 x와 그 자식 노드들 a, b가 있다고 가정해 봅시다.\n경우 1: A[x] ≥ A[a] and A[x] ≥ A[b]\n이것은 노드 x가 자신의 두 자식보다 모두 크거나 같다는 의미입니다. 즉, 노드 x를 루트로 하는 작은 부분 트리(subtree)에서는 이미 최대 힙 조건이 만족된 상태입니다. 이 경우 아무것도 할 필요가 없습니다. 경우 2: 그렇지 않다면 (즉, A[x]가 자식 중 하나보다 작다면)\n힙 조건이 깨졌습니다. A[x]는 A[a]와 A[b] 중 더 큰 값과 자리를 바꿔야 합니다. 예를 들어 A[b]가 더 크다면, A[x]와 A[b]를 교환(swap)합니다. 교환 후 문제 발생: 교환을 하고 나면, 이제 노드 x 위치에는 원래 자식 노드 중 더 큰 값이 왔으므로, x 위치에서는 힙 조건이 만족됩니다. 하지만 원래 A[x]의 값이 내려간 자식 노드 위치(예: b)에서는 또다시 힙 조건이 깨질 수 있습니다. 그 자식 노드 b가 자신의 새로운 자식들보다 작을 수 있기 때문입니다. 해결책: 재귀적(또는 반복적) 처리: 따라서, 값이 아래로 내려간 그 자식 노드를 새로운 x로 삼아, 힙 조건이 만족될 때까지 이 과정을 계속해서 반복해야 합니다. 값이 “아래로 가라앉는(sift-down)” 또는 “밀려 내려가는(push-down)” 과정이라고 할 수 있습니다. 이 과정은 해당 값이 리프 노드에 도달하거나, 또는 자신의 자식들보다 커져서 힙 조건을 만족하는 위치에 도달하면 멈춥니다. 이 pushDown 연산이 buildHeap과 힙 정렬의 핵심 엔진입니다.","슬라이드-40--43#\u003cstrong\u003e슬라이드 40 \u0026amp; 43: \u003ccode\u003ebuildHeap\u003c/code\u003e 알고리즘의 구조\u003c/strong\u003e":"buildHeap은 어떻게 전체 배열을 힙으로 만들까요? 모든 노드를 하나씩 검사할 필요가 없습니다. 중요한 사실은, 리프 노드(leaf node)는 그 자체로 크기 1인 힙이라는 점입니다. 자식이 없으므로 힙 조건을 깰 일이 없기 때문입니다.\n따라서 우리는 리프 노드가 아닌, **가장 마지막 내부 노드(internal node)**부터 시작해서 거꾸로 루트 노드 방향으로 올라오면서 각 노드에 대해 pushDown 연산을 수행하면 됩니다.\n배열의 크기가 n일 때, 마지막 노드의 인덱스는 n입니다. 이 노드의 부모는 floor(n/2)입니다. 즉, floor(n/2) 인덱스를 가진 노드가 바로 가장 마지막 내부 노드입니다. 그 뒤의 floor(n/2) + 1부터 n까지의 노드들은 모두 리프 노드입니다.\nbuildHeap의 구체적인 로직을 슬라이드 코드와 함께 분석해 보겠습니다.\nbuildHeap(A, eh) // eh는 힙의 마지막 요소 지수, 처음엔 n bh = (eh / 2) + 1 // 힙 내의 첫 번째 잎의 지수. 이 코드에 따르면 루프 시작 전 1을 빼야 함. while bh \u003e 1 { bh = bh - 1 x = bh pushDown(A, x, bh, eh) // x에서 pushDown 시작 } eh: end of heap의 약자로, 현재 힙으로 간주되는 배열의 마지막 인덱스를 나타냅니다. buildHeap을 처음 호출할 때는 배열 전체이므로 n이 됩니다. bh = (n / 2) + 1: 슬라이드에서는 bh를 첫 번째 잎의 지수로 초기화한 후, 루프에 진입하면서 바로 1을 뺍니다. 따라서 실질적으로 bh는 n/2부터 시작하게 됩니다. n/2는 마지막 내부 노드의 인덱스입니다. while bh \u003e 1: bh가 1이 될 때까지, 즉 루트 노드까지 pushDown을 수행하고 나면 루프가 종료됩니다. bh는 1씩 감소하며 n/2, n/2 - 1, ..., 2, 1 순서로 진행됩니다. x = bh: 현재 힙 조건을 확인할 노드의 인덱스를 x에 저장합니다. pushDown(A, x, bh, eh): x번 노드에서부터 값이 아래로 내려가야 한다면 내려보내서, x를 루트로 하는 서브트리를 최대 힙으로 만듭니다. 이 과정을 거치면, 아래쪽의 작은 서브트리부터 시작해서 점차 위로 올라오면서 전체 트리가 최대 힙 조건을 만족하게 됩니다. 아래쪽 서브트리들이 이미 힙으로 만들어져 있기 때문에, 상위 노드에서 pushDown을 수행할 때 그 아래 구조는 이미 힙이라는 가정이 성립되어 연산이 올바르게 동작합니다.","슬라이드-41-44-45#\u003cstrong\u003e슬라이드 41, 44, 45: \u003ccode\u003epushDown\u003c/code\u003e과 \u003ccode\u003efindLarger\u003c/code\u003e 상세 분석\u003c/strong\u003e":"pushDown은 buildHeap의 핵심 작업자입니다. x 위치의 값이 제자리를 찾아 아래로 내려가는 과정을 구현합니다.\npushDown(A, x, bh, eh) y = findLarger(A, x, eh) // A[x]보다 큰 값을 가지는 x의 자식 노드 지수를 찾음 while (A[x] \u003c A[y] \u0026\u0026 y는 유효한 인덱스) { // y가 유효하지 않으면 루프 조건이 거짓이 되어야 함 swap(A[x], A[y]) // 부모와 더 큰 자식을 교환 x = y // 이제 검사 위치는 아래로 내려간 자식의 위치 y = findLarger(A, x, eh) // 새로운 위치에서 다시 더 큰 자식을 찾음 } findLarger(A, x, eh): 이 함수는 pushDown의 보조 함수입니다. 노드 x의 두 자식 중 더 큰 값을 가진 자식의 인덱스를 반환합니다. 만약 부모인 A[x]가 두 자식보다 모두 크다면, 교환할 필요가 없으므로 pushDown의 while 루프가 시작되지 않도록 특별한 값(예: x 자신 또는 유효하지 않은 인덱스)을 반환해야 합니다. 슬라이드의 코드를 좀 더 자세히 보겠습니다. findLarger(A, x, eh) // 자식 노드가 둘 다 힙 내에 존재하는 경우 (2x+1 \u003c= eh) if 2*x + 1 \u003c= eh { // 자식 둘 다 부모보다 큰 경우 (슬라이드 코드에 이 부분이 빠져있어 보강) if A[2*x] \u003e A[x] || A[2*x+1] \u003e A[x] { if A[2*x] \u003e= A[2*x+1] { y = 2*x // 왼쪽 자식이 더 크거나 같으면 왼쪽 자식 선택 } else { y = 2*x + 1 // 오른쪽 자식이 더 크면 오른쪽 자식 선택 } } else { // 두 자식 모두 부모보다 작거나 같으면 교환 불필요 // pushDown 루프를 멈추게 할 값을 리턴해야 함. // 예를 들어 y = x를 리턴하면 A[x] \u003c A[y]가 거짓이 되어 루프 종료. return x; // 슬라이드에는 이 부분이 명시적이지 않음 } // 자식 노드가 왼쪽 하나만 힙 내에 존재하는 경우 (2x \u003c= eh) } else if 2*x \u003c= eh \u0026\u0026 A[2*x] \u003e A[x] { y = 2*x // 왼쪽 자식이 부모보다 크면 왼쪽 자식 선택 } else { // 자식이 없거나, 있어도 부모보다 작으면 교환 불필요 return x; } return y while A[x] \u003c A[y]: 이 조건이 pushDown의 핵심입니다. 부모(A[x])가 더 큰 자식(A[y])보다 작을 때만 루프를 실행합니다. 즉, 힙 조건이 깨졌을 때만 교환과 하강을 반복합니다. findLarger가 x를 반환했다면 A[x] \u003c A[x]는 거짓이므로 루프가 돌지 않습니다. swap(A[x], A[y]): 부모와 더 큰 자식의 값을 교환합니다. x = y: 이제 원래 부모 값이 내려간 위치가 y이므로, 다음 검사는 이 위치에서 시작해야 합니다. x를 y로 업데이트합니다. y = findLarger(A, x, eh): 새로운 x 위치에서 다시 더 큰 자식을 찾아 y를 업데이트하고, 루프 조건을 다시 검사합니다.","슬라이드-42#\u003cstrong\u003e슬라이드 42: \u003ccode\u003eHeapSort\u003c/code\u003e 알고리즘\u003c/strong\u003e":"HeapSort(A[1..n]) eh = n buildHeap(A, eh) // 1. 배열 A를 힙으로 만든다 // 2. 힙에서 최댓값을 제거하고 남은 트리를 다시 힙으로 만든다 while( eh \u003e 1) { swap(A[1], A[eh]) // 최댓값(루트)을 힙의 마지막 요소와 교환 eh = eh - 1 // 힙의 크기를 1 줄인다 pushDown(A, 1, 1, eh) // 루트에서부터 힙 속성을 복원한다 } 이 while 루프가 정렬의 핵심입니다. 루프가 한 번 돌 때마다 가장 큰 요소 하나가 제자리를 찾아갑니다.\nswap(A[1], A[eh]):\n최대 힙의 속성에 따라, 현재 힙에서 가장 큰 값은 항상 루트, 즉 A[1]에 있습니다. A[eh]는 현재 힙의 가장 마지막 요소입니다. 이 둘을 교환하면, 가장 큰 값인 A[1]이 배열의 eh 위치로 이동합니다. 이 위치가 바로 이 값의 최종 정렬 위치입니다. 원래 A[eh]에 있던 (상대적으로 작은) 값은 루트인 A[1]로 올라갑니다. eh = eh - 1:\neh 위치에는 이제 최댓값이 고정되었으므로, 이 위치는 더 이상 힙의 일부가 아닙니다. 힙의 유효 범위를 1부터 eh-1까지로 줄입니다. 이것은 마치 힙에서 최댓값을 “제거\"한 것과 같은 효과를 냅니다. pushDown(A, 1, 1, eh):\nswap으로 인해 새로운 값(원래 마지막 요소)이 루트(A[1])로 올라왔습니다. 이 값은 거의 확실하게 최댓값이 아니므로, 루트에서 힙 조건이 깨졌을 것입니다. 따라서 pushDown을 루트(인덱스 1)에서부터 호출하여 이 값을 올바른 위치까지 아래로 내려보냅니다. 이 과정을 통해 힙의 크기가 1 줄어든 새로운 힙이 다시 최대 힙 속성을 만족하게 됩니다. while (eh \u003e 1):\n이 과정을 힙의 크기가 1이 될 때까지 (즉, eh가 1이 될 때까지) 반복합니다. eh가 1이 되면 배열의 첫 번째 요소 하나만 남게 되는데, 이 요소는 자연히 가장 작은 값이므로 이미 정렬된 상태입니다. 루프가 종료되면, 배열 A는 오름차순으로 완벽하게 정렬됩니다. A[1]에는 가장 작은 값, A[n]에는 가장 큰 값이 위치하게 됩니다.","실행-예제와-비교-횟수-분석#실행 예제와 비교 횟수 분석":"예제 배열 A = {22, 13, -5, -8, 15, 60, 17, 31} (n=8)을 사용하여 알고리즘의 진행 과정을 따라가 보겠습니다.\nfindMaxMin(A, 0, 7) 호출\nmid = 3. findMaxMin(A, 0, 3) (왼쪽)과 findMaxMin(A, 4, 7) (오른쪽)을 재귀 호출. findMaxMin(A, 0, 3) 처리 ({22, 13, -5, -8})\nmid = 1. findMaxMin(A, 0, 1)과 findMaxMin(A, 2, 3)을 재귀 호출. findMaxMin(A, 0, 1) ({22, 13}): 요소 2개. 13 \u003c 22. 비교 1회. min=-5, max=22 반환. (min1=13, max1=22) findMaxMin(A, 2, 3) ({-5, -8}): 요소 2개. -8 \u003c -5. 비교 1회. min=-8, max=-5 반환. (min2=-8, max2=-5) 합병: min(13, -8) -\u003e -8 (비교 1회), max(22, -5) -\u003e 22 (비교 1회). 결과: {22, 13, -5, -8}의 min=-8, max=22. 총 비교 횟수 = 1+1+2 = 4회. findMaxMin(A, 4, 7) 처리 ({15, 60, 17, 31})\nmid = 5. findMaxMin(A, 4, 5)와 findMaxMin(A, 6, 7)을 재귀 호출. findMaxMin(A, 4, 5) ({15, 60}): 비교 1회. min=15, max=60 반환. (min1=15, max1=60) findMaxMin(A, 6, 7) ({17, 31}): 비교 1회. min=17, max=31 반환. (min2=17, max2=31) 합병: min(15, 17) -\u003e 15 (비교 1회), max(60, 31) -\u003e 60 (비교 1회). 결과: {15, 60, 17, 31}의 min=15, max=60. 총 비교 횟수 = 1+1+2 = 4회. 최종 합병 (1단계의 결과)\nmin1 = -8, max1 = 22 (왼쪽 전체 결과) min2 = 15, max2 = 60 (오른쪽 전체 결과) min(-8, 15) -\u003e -8 (비교 1회) max(22, 60) -\u003e 60 (비교 1회) 최종 결과: 전체 배열의 min=-8, max=60. 총 비교 횟수 계산: 4회 (왼쪽) + 4회 (오른쪽) + 2회 (최종 합병) = 10회.\n점화식을 이용한 분석: T(n)을 크기 n인 배열에 대한 비교 횟수라고 정의합시다.\nT(1) = 0 (요소가 하나면 비교 없음) T(2) = 1 (요소가 두 개면 비교 1회) T(n) = 2 * T(n/2) + 2 (n \u003e 2) 2 * T(n/2): 크기 n/2인 두 개의 부분 문제 해결을 위한 비교 횟수 + 2: 두 부분 문제의 결과를 합병하기 위한 비교 횟수 (min 비교 1회, max 비교 1회) 이 점화식을 풀어보면 (n이 2의 거듭제곱이라고 가정): T(n) = 2 * T(n/2) + 2 = 2 * (2 * T(n/4) + 2) + 2 = 4 * T(n/4) + 4 + 2 = 4 * (2 * T(n/8) + 2) + 6 = 8 * T(n/8) + 8 + 6 … = 2^k * T(n/2^k) + 2*(2^k - 1) n/2^k = 2가 될 때까지, 즉 n = 2^(k+1)일 때, T(n) = (n/2) * T(2) + 2 * (n/2 - 1) = (n/2) * 1 + n - 2 = n/2 + n - 2 = (3n/2) - 2\n결론: 분할 정복을 사용한 최댓값/최솟값 찾기의 비교 횟수는 약 (3n/2) - 2 입니다.\nn=8일 때: (3*8/2) - 2 = 12 - 2 = 10회. 위 예제와 일치합니다. 쉬운 전략: 2n - 2 = 2*8 - 2 = 14회. 효율성 비교: (3n/2) - 2는 2n - 2보다 약 25% 더 효율적입니다. 데이터가 수십억 개에 달하는 경우, 이 25%의 차이는 상당한 성능 향상으로 이어집니다.","실행-트리와-중복-계산의-문제#\u003cstrong\u003e실행 트리와 중복 계산의 문제\u003c/strong\u003e":"F(5)를 계산하는 과정을 생각해 봅시다 (슬라이드 48).\nF(5)는 F(4)와 F(3)을 호출합니다. F(4)는 F(3)과 F(2)를 호출합니다. F(3)은 F(2)와 F(1)을 호출합니다. 실행 트리를 그려보면, F(3)은 2번, F(2)는 3번, F(1)은 5번, F(0)은 3번 호출됩니다 (0-based 기준). n이 커질수록 이 중복 호출은 기하급수적으로 늘어납니다. F(n-1)과 F(n-2)는 매우 큰 부분 문제를 공유하고 있으며, 이것이 바로 분할된 부분 문제들이 독립적이지 않은(not independent) 경우입니다.\n이 알고리즘의 호출 횟수는 피보나치 수와 비례하며, 시간 복잡도는 약 O(1.618^n) (황금비의 n제곱)이라는 지수 시간(Exponential Time) 복잡도를 가집니다. n=40만 되어도 계산에 엄청난 시간이 걸립니다.","알고리즘-구현-단순함의-미학#알고리즘 구현: 단순함의 미학":"이 점화식은 놀랍도록 간결한 코드로 구현됩니다. k-1 단계와 k 단계의 행렬을 따로 저장할 필요 없이, 하나의 행렬을 계속 갱신하는 방식으로 최적화할 수 있습니다.\n// D는 W로 초기화되었다고 가정 for (k = 1; k \u003c= n; k++) { for (i = 1; i \u003c= n; i++) { for (j = 1; j \u003c= n; j++) { // D[i][j]는 'dᵢⱼ⁽ᵏ⁻¹⁾'의 역할을, 갱신 후에는 'dᵢⱼ⁽ᵏ⁾'가 됨 D[i][j] = min(D[i][j], D[i][k] + D[k][j]); } } }","알고리즘-분석#알고리즘 분석":"시간 복잡도: k, i, j 세 개의 중첩 반복문이 각각 n번씩 실행되므로, 총 시간 복잡도는 매우 직관적으로 Θ(n³) 입니다. 공간 복잡도: n x n 크기의 거리 행렬 하나만 저장하면 되므로, 공간 복잡도는 Θ(n²) 입니다.","알고리즘-분석-및-결론#알고리즘 분석 및 결론":"시간 복잡도: 알고리즘은 i를 1부터 n까지, j를 1부터 C까지 순회하는 2중 반복문으로 구성됩니다. 각 칸을 채우는 데 걸리는 시간은 상수 시간(O(1))입니다. 따라서 총 시간 복잡도는 Θ(nC) 입니다.\n의사 다항 시간 (Pseudo-polynomial time): 이 시간 복잡도는 한 가지 특이한 점이 있습니다. 문제의 입력 크기는 보통 물건의 개수 n으로 생각하지만, 복잡도가 배낭의 용량 C라는 숫자 값에 직접적으로 의존합니다. 만약 C가 n에 비해 터무니없이 큰 값이라면(예를 들어, C가 2ⁿ이라면) 이 알고리즘은 다시 지수 시간처럼 동작할 수 있습니다. 이처럼 입력으로 주어진 ‘숫자의 크기’에 따라 다항 시간이 되는 경우를 의사 다항 시간이라고 부릅니다. 하지만 대부분의 현실적인 문제에서 C는 적절한 크기를 가지므로 매우 효율적인 알고리즘입니다.\n공간 복잡도: (n+1) × (C+1) 크기의 테이블을 사용하므로 공간 복잡도는 Θ(nC) 입니다.\n배낭 채우기 문제는 동적 계획법의 철학을 완벽하게 보여줍니다. 복잡하고 거대한 문제를 ‘고려할 물건의 개수’와 ‘배낭의 용량’이라는 두 가지 차원으로 잘게 나누어 가장 작은 문제부터 체계적으로 해결해 나갑니다. 각 단계의 해를 테이블에 꼼꼼히 기록함으로써, 한 번 푼 문제는 다시 풀지 않고 그 결과를 즉시 활용하여 폭발적인 경우의 수를 효율적으로 제어합니다.\n탐험가가 모든 조합을 머릿속으로 떠올리며 혼란에 빠지는 대신, 이처럼 체계적인 표를 그려 나갔다면, 그는 틀림없이 최적의 보물 조합을 찾아 유적을 무사히 빠져나왔을 것입니다. 이것이 바로 복잡한 최적화 문제를 해결하는 동적 계획법의 힘입니다.","알고리즘의-구조-외부-루프와-내부-루프#알고리즘의 구조: 외부 루프와 내부 루프":"슬라이드 22의 알고리즘은 두 개의 중첩된 루프 구조를 가집니다.\n외부 for 루프: 정렬되지 않은 부분의 첫 번째 요소를 선택하는 역할을 합니다. 인덱스 i는 1부터 n-1까지 증가합니다. i가 1부터 시작하는 이유는, 크기가 1인 배열(A[0])은 그 자체로 이미 정렬되어 있기 때문입니다. 내부 while 루프: for 루프에서 선택된 A[i]를 A[0...i-1]의 올바른 위치에 삽입하는 역할을 합니다. 앞서 자세히 분석한 바로 그 로직입니다. InsertionSort(A[0..n−1]) // 입력: 정렬 안된 배열 A[0..n-1] // 출력: 정렬된 배열 A[0..n-1] 1 for (i = 1; i \u003c n; i++) { 2 insertElement = A[i] 3 j = i – 1 4 while ( j ≥ 0 and A[ j] \u003e insertElement) { 5 A[ j + 1] = A[ j] 6 j = j – 1 } 7 A[ j + 1] = insertElement }","장점-1-적응성adaptive---거의-정렬된-데이터에-강력함#장점 1: 적응성(Adaptive) - 거의 정렬된 데이터에 강력함":"","장점-1-적응성adaptive---거의-정렬된-데이터에-강력함-1#장점 1: 적응성(Adaptive) - 거의 정렬된 데이터에 강력함":"슬라이드 24에서 언급된 “값들이 거의 정렬되어 있을 때 빠르게 실행\"된다는 점이 바로 적응성입니다. 만약 입력 배열이 거의 정렬되어 있다면, 각 요소를 삽입할 때 이동(shift)하는 거리가 매우 짧습니다. 내부 while 루프가 몇 번 실행되지 않고 금방 종료되기 때문에, 전체 실행 시간은 O(n²)이 아닌 O(n)에 가깝게 됩니다. 이러한 특성 때문에, 실시간으로 데이터가 약간씩 변경되거나 새로운 데이터가 기존 정렬된 리스트의 끝에 추가되는 경우, 삽입 정렬은 매우 효율적인 선택이 될 수 있습니다.","장점-2-제자리-정렬in-place---추가-공간-불필요#장점 2: 제자리 정렬(In-place) - 추가 공간 불필요":"","장점-2-제자리-정렬in-place---추가-공간-불필요-1#장점 2: 제자리 정렬(In-place) - 추가 공간 불필요":"앞서 분석했듯이, 삽입 정렬은 O(1)의 추가 공간만을 사용합니다. 이는 메모리 사용량이 매우 중요한 임베디드 시스템이나 특정 환경에서 큰 장점이 됩니다. 병합 정렬(Merge Sort)이 O(n)의 추가 공간을 필요로 하는 것과 대조적입니다.","장점-3-안정-정렬stable-sort#장점 3: 안정 정렬(Stable Sort)":"","장점-3-안정-정렬stable-sort-1#장점 3: 안정 정렬(Stable Sort)":"안정 정렬이란, 값이 같은 요소들의 상대적인 순서가 정렬 후에도 그대로 유지되는 것을 의미합니다. 예를 들어, (값, 속성) 형태의 데이터 [(5, 'A'), (3, 'B'), (5, 'C')]를 값 기준으로 정렬할 때, 안정 정렬 알고리즘은 항상 [(3, 'B'), (5, 'A'), (5, 'C')]를 반환합니다. (5, 'A')가 (5, 'C')보다 원래 앞에 있었으므로, 정렬 후에도 이 순서가 유지됩니다.\n삽입 정렬은 안정 정렬입니다. 그 이유는 내부 while 루프의 조건 A[j] \u003e insertElement 때문입니다. 만약 A[j]와 insertElement의 값이 같다면(\u003e 가 아니므로) 루프는 멈추고, insertElement는 A[j]의 오른쪽에 삽입됩니다. 따라서 기존에 있던 요소의 위치를 침범하지 않아 상대적 순서가 보존됩니다.","장점-4-온라인online-알고리즘#장점 4: 온라인(Online) 알고리즘":"","장점-4-온라인online-알고리즘-1#장점 4: 온라인(Online) 알고리즘":"삽입 정렬은 ‘온라인’ 특성을 가집니다. 즉, 모든 데이터를 미리 받지 않고, 데이터가 들어오는 대로 즉시 정렬을 수행할 수 있습니다. 이미 정렬된 n개의 요소 리스트가 있을 때, 새로운 데이터 n+1번째가 들어오면, 이 하나만 올바른 위치에 삽입하면 되므로 효율적입니다.","재귀를-이용한-분할-정복-알고리즘#\u003cstrong\u003e재귀를 이용한 분할 정복 알고리즘\u003c/strong\u003e":"F(n) 1 if n ≤ 1 return 1 2 else return F(n - 1) + F(n - 2) 이 코드는 피보나치 수열의 정의를 그대로 코드로 옮긴 것입니다. 매우 간결하고 직관적입니다. 하지만 치명적인 비효율성을 가지고 있습니다.","전체-실행-코드-및-설명#전체 실행 코드 및 설명":"시간 및 공간 복잡도 분석 (Slide 23)","전체-실행-코드-및-설명-1#전체 실행 코드 및 설명":"#include #include // 유틸리티 함수: 벡터를 출력 void printArray(const std::vector\u003cint\u003e\u0026 arr) { for (int val : arr) { std::cout \u003c\u003c val \u003c\u003c \" \"; } std::cout \u003c\u003c std::endl; } // 위에서 정의한 insertionSort 함수 void insertionSort(std::vector\u003cint\u003e\u0026 arr) { int n = arr.size(); for (int i = 1; i \u003c n; ++i) { int key = arr[i]; int j = i - 1; while (j \u003e= 0 \u0026\u0026 arr[j] \u003e key) { arr[j + 1] = arr[j]; j = j - 1; } arr[j + 1] = key; } } int main() { std::vector\u003cint\u003e data = {5, 2, 4, 6, 1, 3}; std::cout \u003c\u003c \"Original array: \"; printArray(data); insertionSort(data); std::cout \u003c\u003c \"Sorted array: \"; printArray(data); return 0; } main 함수: 정렬할 데이터를 std::vector로 생성하고, 정렬 전과 후의 배열 상태를 printArray 함수를 통해 출력하여 알고리즘의 동작을 확인합니다. insertionSort 함수 해설: key 변수는 슬라이드의 insertElement에 해당합니다. 외부 for 루프는 i=1부터 n-1까지 총 n-1번 실행됩니다. 내부 while 루프는 key의 값과 정렬된 부분의 요소들에 따라 실행 횟수가 달라집니다. 이것이 삽입 정렬의 성능을 결정하는 가장 중요한 부분입니다.","점화식-세우기-선택의-기로#점화식 세우기: 선택의 기로":"자, 이제 테이블의 한 칸인 K[i][j]를 어떻게 계산할 수 있을지 생각해 봅시다. 우리는 i번째 보물을 앞에 두고 선택의 기로에 서 있습니다.\n“i번째 보물을 배낭에 넣을 것인가, 말 것인가?”\n이 결정에 따라 K[i][j]의 값이 정해집니다.\n경우 1: i번째 보물을 배낭에 넣지 않는다. 만약 i번째 보물을 넣지 않기로 결정했다면, 문제는 간단해집니다. i번째 보물은 그냥 무시하고, 나머지 i-1개의 보물을 가지고 용량 j의 배낭을 채우는 문제와 동일해집니다. 이 문제의 최적해는 우리가 이미 정의한 바에 따라 K[i-1][j]입니다.\n경우 2: i번째 보물을 배낭에 넣는다. 이 선택은 i번째 보물의 무게 w[i]가 현재 배낭 용량 j보다 작거나 같을 때만 가능합니다. 만약 w[i] \u003e j라면 이 경우는 아예 고려할 수조차 없습니다. 만약 넣는 것이 가능하다면, 우리는 i번째 보물의 가치 v[i]를 얻게 됩니다. 그리고 i번째 보물을 넣었으니 배낭에는 j - w[i] 만큼의 용량이 남게 됩니다. 이 남은 공간은 어떻게 채워야 할까요? 당연히 최적의 방법으로 채워야 합니다. 즉, 남은 i-1개의 보물을 가지고 용량 j - w[i]의 배낭을 채워 얻을 수 있는 최대 가치를 더해야 합니다. 이 값은 바로 K[i-1][j - w[i]]입니다. 따라서 이 경우의 총가치는 v[i] + K[i-1][j - w[i]]가 됩니다.\n우리는 항상 최대의 가치를 원하므로, 이 두 가지 경우 중 더 큰 값을 선택하면 됩니다. 이것이 바로 배낭 문제의 점화식입니다.\nif w[i] \u003e j (i번째 물건이 배낭 용량 j보다 무거워 담을 수 없는 경우): K[i, j] = K[i-1, j] (못 담으니 이전 상태와 같음)\nif w[i] \u003c= j (i번째 물건을 담을 수 있는 경우): K[i, j] = max( K[i-1, j], v[i] + K[i-1, j - w[i]] ) (안 담았을 때의 가치 vs 담았을 때의 가치)\n이 점화식을 이용해 i=1부터 n까지, j=1부터 C까지 테이블을 순서대로 채워나가면 마침내 최종 답 K[n][C]에 도달할 수 있습니다.","정렬-단계-구체적인-예시#\u003cstrong\u003e정렬 단계 구체적인 예시\u003c/strong\u003e":"buildHeap 결과인 A = [-, 10, 5, 8, 4, 1, 3] (n=6)을 가지고 정렬을 시작하겠습니다.\n초기 힙: [10, 5, 8, 4, 1, 3], eh = 6 첫 번째 반복 (eh = 6):\nswap(A[1], A[6]): 10과 3을 교환. A becomes [3, 5, 8, 4, 1, 10] eh = 5. 이제 A[6]의 10은 정렬 완료된 부분입니다. 힙은 [3, 5, 8, 4, 1] 입니다. pushDown(A, 1, 1, 5): 루트의 3을 pushDown 합니다. 3의 자식은 5(2번), 8(3번). 더 큰 자식은 8. swap(A[1], A[3]). A becomes [8, 5, 3, 4, 1, 10]. 3이 내려간 3번 인덱스는 리프이므로 pushDown 종료. 결과 힙: [8, 5, 3, 4, 1], 정렬된 부분: [10] 두 번째 반복 (eh = 5):\nswap(A[1], A[5]): 8과 1을 교환. A becomes [1, 5, 3, 4, 8, 10] eh = 4. 이제 A[5]의 8도 정렬 완료. 힙은 [1, 5, 3, 4] 입니다. pushDown(A, 1, 1, 4): 루트의 1을 pushDown 합니다. 1의 자식은 5(2번), 3(3번). 더 큰 자식은 5. swap(A[1], A[2]). A becomes [5, 1, 3, 4, 8, 10]. 1이 내려간 2번 인덱스의 자식은 4(4번). 1 \u003c 4 이므로 교환. swap(A[2], A[4]). A becomes [5, 4, 3, 1, 8, 10]. 결과 힙: [5, 4, 3, 1], 정렬된 부분: [8, 10] 세 번째 반복 (eh = 4):\nswap(A[1], A[4]): 5와 1을 교환. A becomes [1, 4, 3, 5, 8, 10] eh = 3. 힙은 [1, 4, 3] 입니다. pushDown(A, 1, 1, 3): 루트의 1을 pushDown 합니다. 자식은 4(2번), 3(3번). 더 큰 자식은 4. swap(A[1], A[2]). A becomes [4, 1, 3, 5, 8, 10]. 결과 힙: [4, 1, 3], 정렬된 부분: [5, 8, 10] … 이 과정을 eh가 1이 될 때까지 반복합니다. 최종적으로 배열은 [1, 3, 4, 5, 8, 10] 으로 정렬됩니다.","제-7장-탐욕-기법-greedy#제 7장: 탐욕 기법 (Greedy)":"","제1부-핵심-자료구조#\u003cstrong\u003e제1부: 핵심 자료구조 ‘힙(Heap)‘의 이해\u003c/strong\u003e":"힙 정렬을 이해하기 위해서는 먼저 ‘힙’이 무엇인지 정확히 알아야 합니다.\n1. 완전 이진 트리 (Complete Binary Tree)\n힙은 기본적으로 완전 이진 트리의 형태를 가집니다. 완전 이진 트리란, 마지막 레벨을 제외한 모든 레벨이 완전히 채워져 있으며, 마지막 레벨의 노드들은 왼쪽부터 차례대로 채워져 있는 이진 트리를 말합니다. 이 구조 덕분에 힙은 배열을 사용하여 매우 효율적으로 표현할 수 있습니다.\n2. 배열로 힙 표현하기\n트리 구조를 배열로 표현할 때, 특정 노드의 인덱스를 알면 그 부모와 자식 노드의 인덱스를 간단한 수식으로 계산할 수 있습니다. 슬라이드에서 배열의 인덱스가 1부터 시작하는 것을 기준으로 설명하겠습니다.\n노드 i의 부모 노드 인덱스: floor(i / 2) 노드 i의 왼쪽 자식 노드 인덱스: 2 * i 노드 i의 오른쪽 자식 노드 인덱스: 2 * i + 1 예를 들어, 3번 노드의 부모는 floor(3/2) = 1번 노드이고, 자식은 2*3=6번(왼쪽)과 2*3+1=7번(오른쪽) 노드가 됩니다. 이 규칙성 덕분에 포인터 없이도 배열 인덱스만으로 트리 관계를 파악할 수 있습니다.\n3. 힙 조건 (Heap Property)\n힙은 완전 이진 트리 구조에 더해 다음과 같은 ‘힙 조건’을 만족해야 합니다.\n최대 힙 (Max-Heap): 모든 노드에 대해, 부모 노드의 값은 자식 노드의 값보다 항상 크거나 같다. (A[부모] ≥ A[자식]) 이 경우, 트리의 루트 노드는 전체 데이터 중 최댓값을 가지게 됩니다. 힙 정렬에서는 주로 최대 힙을 사용합니다. 최소 힙 (Min-Heap): 모든 노드에 대해, 부모 노드의 값은 자식 노드의 값보다 항상 작거나 같다. (A[부모] ≤ A[자식]) 이 경우, 루트 노드는 최솟값을 가집니다. 슬라이드의 내용은 최댓값을 찾아 정렬하는 것을 목표로 하므로, 이하의 모든 설명은 최대 힙을 기준으로 합니다.","제1장-문제의-공식화---그래프-언어로의-번역#제1장: 문제의 공식화 - 그래프 언어로의 번역":"이 거대한 과제를 컴퓨터 과학의 언어로 옮겨 보겠습니다.\n그래프 G = (V, E): 도시의 교차로들은 정점(Vertex) V가 되고, 교차로를 잇는 도로들은 간선(Edge) E이 됩니다. 가중치(Weight): 각 도로는 길이, 통행 시간 등의 비용을 가집니다. 도로는 일방통행일 수 있으므로, **방향 그래프(Directed Graph)**를 가정합니다. 문제 정의: 가중치 방향 그래프 G가 주어졌을 때, 모든 정점 쌍 (i, j)에 대해, i에서 j로 가는 최단 경로의 거리를 찾는 것. 컴퓨터는 이 정보를 인접 행렬(Adjacency Matrix) W로 표현합니다. W는 n x n 크기의 행렬이며, wᵢⱼ는 정점 i에서 j로 직접 가는 간선의 가중치입니다.\nwᵢⱼ = 0 (만약 i = j, 자기 자신으로 가는 비용은 0) wᵢⱼ = 간선의 가중치 (만약 i에서 j로 가는 간선이 존재) wᵢⱼ = ∞ (만약 i에서 j로 직접 가는 간선이 없음) 우리가 최종적으로 얻고 싶은 결과물은 거리 행렬(Distance Matrix) D입니다. dᵢⱼ는 정점 i에서 j로 가는, 중간에 다른 정점들을 거쳐갈 수 있는 모든 경로 중 가장 짧은 경로의 거리를 담고 있습니다.","제2부-힙-구성build-heap-단계-상세-분석#\u003cstrong\u003e제2부: 힙 구성(Build Heap) 단계 상세 분석\u003c/strong\u003e":"힙 정렬의 첫 번째 단계는 주어진 배열을 최대 힙으로 변환하는 것입니다. 이 과정을 buildHeap 함수가 수행합니다.","제2장-첫-번째-시도와-절망---억지-기법의-한계#제2장: 첫 번째 시도와 절망 - 억지 기법의 한계":"가장 순진한 접근법은 모든 정점 쌍 (i, j)에 대해, i에서 j로 갈 수 있는 모든 가능한 경로를 하나도 빠짐없이 찾아보는 것입니다. 하지만 이는 정점의 개수 n이 조금만 커져도 경우의 수가 기하급수적으로 폭발합니다. i에서 j로 가는 경로에 나머지 n-2개의 정점들을 어떤 순서로 방문하느냐에 따라 (n-2)!에 비례하는 경로가 생성됩니다. 이는 천문학적인 숫자로, 현실적으로 불가능한 접근법입니다.","제3부-정렬sorting-단계-상세-분석#\u003cstrong\u003e제3부: 정렬(Sorting) 단계 상세 분석\u003c/strong\u003e":"buildHeap을 통해 배열이 최대 힙이 되었다면, 이제 두 번째 단계인 실제 정렬을 수행합니다. 이 과정은 매우 직관적입니다.","제3장-발상의-전환---동적-계획법의-새로운-관점#제3장: 발상의 전환 - 동적 계획법의 새로운 관점":"이 막다른 길에서 로버트 플로이드(Robert Floyd)와 스티븐 워셜(Stephen Warshall)은 문제를 완전히 새로운 각도에서 바라보는 천재적인 아이디어를 제시합니다.\n“최단 경로를 구성하는 ‘중간 정점’의 범위를 점진적으로 늘려가며 해를 구하자.”\n이것이 바로 플로이드-워셜 알고리즘의 핵심 사상입니다. 우리는 부분 문제를 다음과 같이 새롭게 정의합니다.\ndᵢⱼ⁽ᵏ⁾: 정점 i에서 j로 가는 경로 중에서, 중간에 거쳐갈 수 있는 정점이 {1, 2, ..., k} 집합에 속하는 정점들로만 제한되었을 때의 최단 경로의 거리.\n이 정의는 마치 우리가 세상을 알아가는 과정과 같습니다.\ndᵢⱼ⁽⁰⁾: 중간에 어떤 정점도 거쳐갈 수 없을 때의 최단 경로. 이는 i에서 j로 직접 가는 길 뿐입니다. 즉, dᵢⱼ⁽⁰⁾ = wᵢⱼ. 이것이 우리의 출발점입니다. dᵢⱼ⁽¹⁾: 이제 ‘정점 1’을 경유지로 사용할 수 있습니다. 기존의 직접 가는 길과, ‘정점 1’을 거쳐가는 새로운 길(i → 1 → j) 중 더 짧은 길을 선택합니다. dᵢⱼ⁽²⁾: 이제 ‘정점 1 또는 2’를 경유지로 사용할 수 있습니다. dᵢⱼ⁽¹⁾을 기반으로, 새롭게 허용된 ‘정점 2’를 거쳐가면 혹시 길이 더 짧아지지 않을까 검토합니다. … dᵢⱼ⁽ⁿ⁾: 마침내 모든 정점 {1, 2, ..., n}을 경유지로 허용합니다. 이것이 바로 우리가 최종적으로 원하는 최단 거리 dᵢⱼ입니다. 이처럼 ‘허용된 중간 정점’의 범위를 k=0에서 n까지 점진적으로 확장하며, 거리 행렬(우리의 지도)을 계속해서 갱신해 나가는 것이 이 알고리즘의 전략입니다.","제3장-정렬#제3장: 정렬":"배열을 크기에 기초해 분할 후 합쳐서 정렬 크기가 1인 배열과 (n - 1)인 배열로 분할 : 삽입 정렬 크기가 𝑛/2인 두 개의 배열로 분할 : 합병 정렬 배열을 특정 값에 기초하여 분할 후 합쳐서 정렬 최솟값에 기초하여 분할 : 선택 정렬, 힙 정렬 기준 값(예: 첫 번째 값)에 기초하여 분할 : 빠른 정렬 네, 제공해주신 알고리즘 슬라이드(19~24장) 내용을 바탕으로 삽입 정렬(Insertion Sort)에 대해 30,000자 이상으로 매우 상세하고 단계적으로 설명해 드리겠습니다. C++ 예시 코드와 함께 각 개념을 깊이 있게 다루겠습니다.","제4부-시간-복잡도-분석#\u003cstrong\u003e제4부: 시간 복잡도 분석\u003c/strong\u003e":"힙 정렬의 효율성을 이해하는 것은 매우 중요합니다. 슬라이드 46, 47의 내용을 더 깊이 있게 풀어보겠습니다.","제4장-그래프graph#제4장: 그래프(graph)":"","제4장-점화식의-발견---정점-k를-둘러싼-선택#제4장: 점화식의 발견 - 정점 \u003ccode\u003ek\u003c/code\u003e를 둘러싼 선택":"이 아이디어를 구체적인 점화식으로 만들어 봅시다. dᵢⱼ⁽ᵏ⁾를 계산해야 하는 시점에서, 우리는 이미 그 이전 단계의 완벽한 해답, 즉 dᵢⱼ⁽ᵏ⁻¹⁾ (중간 정점을 k-1까지만 허용했을 때의 최단 경로)를 알고 있습니다.\ni에서 j로 가는 최단 경로(중간 정점 k까지 허용)는 다음 두 가지 경우 중 하나입니다.\n경우 1: 최단 경로가 정점 k를 거쳐가지 않는다. 이 경로에 정점 k가 필요 없다면, 이 경로는 오직 {1, ..., k-1} 집합의 정점들만 중간에 사용합니다. 그렇다면 이 경로의 최단 거리는 k를 고려하기 이전의 최단 거리와 동일합니다. 즉, dᵢⱼ⁽ᵏ⁻¹⁾ 입니다.\n경우 2: 최단 경로가 정점 k를 거쳐간다. 만약 최단 경로가 k를 거쳐간다면, 그 경로는 i → ... → k → ... → j 와 같은 형태입니다. 최적 부분 구조 원리에 따라, 이 경로의 i → k 부분과 k → j 부분 역시 각각 최단 경로여야 합니다. 이 부분 경로들은 중간에 k를 또 거칠 수 없으므로, 오직 {1, ..., k-1} 집합의 정점들만 사용합니다. 따라서 k를 거쳐가는 경로의 총거리는 dᵢₖ⁽ᵏ⁻¹⁾ + dₖⱼ⁽ᵏ⁻¹⁾ 가 됩니다.\n우리는 이 두 가지 경우 중 더 짧은 쪽, 즉 더 작은 값을 선택해야 합니다. 이로써 플로이드-워셜 알고리즘의 핵심 점화식이 완성됩니다.\ndᵢⱼ⁽ᵏ⁾ = min( dᵢⱼ⁽ᵏ⁻¹⁾, dᵢₖ⁽ᵏ⁻¹⁾ + dₖⱼ⁽ᵏ⁻¹⁾ )\n이 점화식은 우리에게 k-1 단계의 해답 행렬만 있으면 k 단계의 해답 행렬을 만들 수 있음을 알려줍니다.","제5부-힙-정렬의-특징-및-요약-슬라이드-48-기반#\u003cstrong\u003e제5부: 힙 정렬의 특징 및 요약 (슬라이드 48 기반)\u003c/strong\u003e":"핵심 아이디어: 힙(Heap)이라는 자료구조를 사용하여 정렬합니다. 먼저 전체 배열을 힙으로 만들고(buildHeap), 그 후 힙의 루트(최댓값)를 반복적으로 제거하여 정렬된 위치에 배치합니다.\n시간 복잡도 (Time Complexity): O(n log n). 입력 데이터의 초기 상태와 관계없이 항상 O(n log n)의 성능을 보장합니다. 이는 퀵 정렬이 최악의 경우 O(n^2)까지 성능이 저하될 수 있는 것과 비교되는 큰 장점입니다.\n공간 복잡도 (Space Complexity): O(1). 주어진 배열 내에서 요소들의 위치를 교환하는 방식으로 정렬이 이루어지므로, 별도의 추가 메모리 공간이 거의 필요 없습니다. 이를 **제자리 정렬(In-place Sort)**이라고 하며, 메모리가 제한적인 환경에서 매우 유용합니다.\n불안정 정렬 (Unstable Sort): 힙 정렬은 안정적인 정렬이 아닙니다. 안정 정렬이란, 값이 같은 요소들의 상대적인 순서가 정렬 후에도 유지되는 것을 의미합니다. 힙 정렬에서는 pushDown 과정이나 루트와 마지막 노드를 교환하는 과정에서 같은 값을 가진 요소들의 순서가 뒤바뀔 수 있습니다.\n선택/삽입 정렬과의 비교\n선택 정렬 (O(n^2)): 매번 최솟값(최댓값)을 찾기 위해 n번의 순회를 해야 합니다. 힙 정렬은 힙 구조를 이용해 최댓값을 O(1)에 찾고, 구조를 재조정하는 데 O(log n)만 사용하므로 훨씬 효율적입니다. 삽입 정렬 (최선 O(n), 최악 O(n^2)): 이미 정렬된 데이터에 대해서는 매우 빠르지만, 역순 데이터에 대해서는 성능이 급격히 저하됩니다. 힙 정렬은 데이터 분포에 영향을 받지 않습니다.","제5장-분할-정복-divide-and-conquer#\u003cstrong\u003e제5장: 분할 정복 (Divide and Conquer)\u003c/strong\u003e":"","제5장-플로이드-워셜-알고리즘과-분석#제5장: 플로이드-워셜 알고리즘과 분석":"","제6장-동적-계획-dynamic-programming#\u003cstrong\u003e제6장: 동적 계획 (Dynamic Programming)\u003c/strong\u003e":"네, 알겠습니다. 분할 정복(Divide and Conquer)의 한계를 살펴보고, 이를 극복하는 동적 계획법(Dynamic Programming)의 개념을 막대 자르기(Rod Cutting) 문제를 통해 매우 상세하고 이야기 형식으로 설명해 드리겠습니다.","제6장-알고리즘-실행-과정-추적#제6장: 알고리즘 실행 과정 추적":"알고리즘이 어떻게 한 단계씩 최단 경로를 ‘발견’해 나가는지 예제로 따라가 보겠습니다.\n초기 인접 행렬 W = D⁽⁰⁾:\nD⁽⁰⁾ 1 2 3 4 1 0 1 ∞ 2 2 6 0 4 ∞ 3 ∞ ∞ 0 3 4 ∞ 8 ∞ 0 1단계: k = 1 (정점 1을 경유지로 허용) dᵢⱼ⁽¹⁾ = min( dᵢⱼ⁽⁰⁾, dᵢ₁⁽⁰⁾ + d₁ⱼ⁽⁰⁾ )\nd₂₄⁽¹⁾: min(∞, d₂₁⁽⁰⁾ + d₁₄⁽⁰⁾) = min(∞, 6 + 2) = 8. (2 → 1 → 4 경로 발견) D⁽¹⁾ 1 2 3 4 1 0 1 ∞ 2 2 6 0 4 8 3 ∞ ∞ 0 3 4 ∞ 8 ∞ 0 2단계: k = 2 (정점 1, 2를 경유지로 허용) dᵢⱼ⁽²⁾ = min( dᵢⱼ⁽¹⁾, dᵢ₂⁽¹⁾ + d₂ⱼ⁽¹⁾ )\nd₁₃⁽²⁾: min(∞, d₁₂⁽¹⁾ + d₂₃⁽¹⁾) = min(∞, 1 + 4) = 5. (1 → 2 → 3 경로 발견) d₄₁⁽²⁾: min(∞, d₄₂⁽¹⁾ + d₂₁⁽¹⁾) = min(∞, 8 + 6) = 14. (4 → 2 → 1 경로 발견) D⁽²⁾ 1 2 3 4 1 0 1 5 2 2 6 0 4 8 3 ∞ ∞ 0 3 4 14 8 ∞ 0 3단계: k = 3 (정점 1, 2, 3을 경유지로 허용) dᵢⱼ⁽³⁾ = min( dᵢⱼ⁽²⁾, dᵢ₃⁽²⁾ + d₃ⱼ⁽²⁾ )\nd₂₄⁽³⁾: min(8, d₂₃⁽²⁾ + d₃₄⁽²⁾) = min(8, 4 + 3) = 7. (기존 2→1→4보다 2→3→4가 더 빠름) d₄₂⁽³⁾: min(8, d₄₃⁽²⁾ + d₃₂⁽²⁾) = min(8, ∞ + ∞) = 8. (갱신 없음) D⁽³⁾ 1 2 3 4 1 0 1 5 2 2 6 0 4 7 3 ∞ ∞ 0 3 4 14 8 ∞ 0 (주: 원본 자료의 예시 테이블과 달리, 정확한 계산에 따라 값을 갱신하였습니다.)\n4단계: k = 4 (모든 정점을 경유지로 허용) dᵢⱼ⁽⁴⁾ = min( dᵢⱼ⁽³⁾, dᵢ₄⁽³⁾ + d₄ⱼ⁽³⁾ )\nd₁₃⁽⁴⁾: min(5, d₁₄⁽³⁾ + d₄₃⁽³⁾) = min(5, 2 + ∞) = 5. d₃₂⁽⁴⁾: min(∞, d₃₄⁽³⁾ + d₄₂⁽³⁾) = min(∞, 3 + 8) = 11. (3 → 4 → 2 경로 발견) d₃₁⁽⁴⁾: min(∞, d₃₄⁽³⁾ + d₄₁⁽³⁾) = min(∞, 3 + 14) = 17. (3 → 4 → 2 → 1 경로 발견) D⁽⁴⁾ - 최종 결과 1 2 3 4 1 0 1 5 2 2 6 0 4 7 3 17 11 0 3 4 14 8 ∞ 0 이것이 최종 거리 행렬 D입니다. 이제 이 도시의 어떤 두 지점 사이의 최단 거리를 즉시 알 수 있습니다.","첫-번째-시도-분할-정복을-이용한-재귀적-접근#첫 번째 시도: 분할 정복을 이용한 재귀적 접근":"이 문제를 처음 접했을 때, 가장 직관적으로 떠올릴 수 있는 방법은 분할 정복 기반의 재귀적 접근입니다.\n길이 i의 막대에서 얻을 수 있는 최대 판매 금액을 R(i)라고 정의해 봅시다. 길이 i의 막대를 얻기 위한 방법은, 첫 번째 조각을 길이 k (단, 1 ≤ k ≤ i)로 자르는 것입니다. 그러면 우리는 길이 k짜리 조각 하나와 길이 i-k짜리 막대 하나를 얻게 됩니다.\n길이 k짜리 조각은 가격표에 따라 p[k]의 가격으로 판매합니다. 나머지 길이 i-k짜리 막대는? 이 막대 또한 최적의 방법으로 잘라 팔아야 최대 이익을 얻을 수 있습니다. 즉, R(i-k)의 이익을 얻게 됩니다. 따라서, 첫 조각을 길이 k로 잘랐을 때의 총 이익은 p[k] + R(i-k)가 됩니다. 우리는 가능한 모든 k (1부터 i까지)에 대해 이 값을 계산하여 그중 최댓값을 찾으면 됩니다. 이를 점화식으로 표현하면 다음과 같습니다.\nR(i) = max( p[k] + R(i-k) ) for 1 ≤ k ≤ i\n(단, R(0) = 0)\n이 점화식을 코드로 구현하면 다음과 같은 재귀 함수(cutRod_DC)가 됩니다.\n// 분할 정복(재귀) 방식의 막대 자르기 알고리즘 cutRod_DC(p[], i) { if (i == 0) return 0; // 길이가 0이면 가격도 0 maxSell = 0; for (j = 1; j \u003c= i; j++) { // 첫 조각을 j로 잘랐을 때의 가격 p[j]와 // 나머지 부분(i-j)의 최대 이익을 더한 값 중 최댓값을 찾는다. maxSell = MAX(maxSell, p[j] + cutRod_DC(p, i - j)); } return maxSell; }","첫-번째-시도-분할-정복의-함정#첫 번째 시도: 분할 정복의 함정":"이 문제 역시 분할 정복의 관점에서 접근해 볼 수 있습니다. Mᵢ × Mᵢ₊₁ × ... × Mⱼ의 최소 곱셈 횟수를 구하는 문제를 생각해 봅시다. 이 행렬 체인의 마지막 곱셈은 반드시 어떤 k (단, i ≤ k \u003c j)를 기준으로 두 부분 체인의 곱으로 이루어집니다.\n(Mᵢ × ... × Mₖ) × (Mₖ₊₁ × ... × Mⱼ)\n즉, i부터 j까지의 행렬 곱셈 문제의 최적해를 구하려면, 가능한 모든 분할 지점 k에 대해 문제를 나누어보고 그중 가장 비용이 적게 드는 경우를 선택하면 됩니다.\nMᵢ 행렬의 크기를 rᵢ₋₁ × rᵢ 라고 표준화합시다. (즉, r 배열은 행렬들의 차원을 저장합니다.) Mᵢ × ... × Mₖ를 계산한 결과 행렬의 크기는 rᵢ₋₁ × rₖ가 됩니다. Mₖ₊₁ × ... × Mⱼ를 계산한 결과 행렬의 크기는 rₖ × rⱼ가 됩니다. 따라서, 분할 지점이 k일 때의 총비용은 다음과 같이 세 부분으로 나뉩니다.\nMᵢ × ... × Mₖ를 계산하는 최소 비용. Mₖ₊₁ × ... × Mⱼ를 계산하는 최소 비용. 두 결과 행렬을 마지막으로 곱하는 비용: rᵢ₋₁ × rₖ × rⱼ matMult(i, j)를 Mᵢ부터 Mⱼ까지 곱하는 데 필요한 최소 곱셈 횟수라고 정의하면, 다음과 같은 점화식을 세울 수 있습니다.\nmatMult(i, j) = min { matMult(i, k) + matMult(k+1, j) + rᵢ₋₁rₖrⱼ } (단, i ≤ k \u003c j)\nmatMult(i, i) = 0 (행렬이 하나일 때는 곱셈이 필요 없으므로 비용은 0)\n이 점화식은 문제의 구조를 완벽하게 표현합니다. 이를 그대로 재귀 함수로 구현하면 matMult_DC와 같은 코드가 됩니다.\n// 분할 정복(재귀) 방식의 연속 행렬 곱셈 알고리즘 matMult_DC(r[], i, j) { if (i == j) return 0; // 곱할 행렬이 하나뿐인 경우 minVal = ∞; // 가능한 모든 분할 지점 k에 대해 탐색 for (k = i; k \u003c j; k++) { // (i...k) 부분 문제 + (k+1...j) 부분 문제 + 마지막 곱셈 비용 cost = matMult_DC(r, i, k) + matMult_DC(r, k+1, j) + r[i-1]*r[k]*r[j]; minVal = MIN(minVal, cost); } return minVal; } 하지만 이 재귀 함수는 막대 자르기 문제에서 겪었던 것과 똑같은, 아니 훨씬 심각한 비효율을 가지고 있습니다. matMult(1, 4)를 계산하려면 matMult(1, 1), matMult(2, 4)… 등등을 호출하고, matMult(1, 3)을 계산하기 위해서도 matMult(2, 3) 등을 호출하는데, matMult(2, 4)를 계산하는 과정에서도 matMult(2, 3)이 또 호출됩니다.\n즉, **‘중복되는 부분 문제’**가 엄청나게 많이 발생하며, 시간 복잡도는 지수적으로 증가하여 n이 20만 되어도 계산이 거의 불가능해집니다.","최댓값최솟값-찾기-알고리즘-findmaxmin-상세-분석#최댓값/최솟값 찾기 알고리즘 (findMaxMin) 상세 분석":"슬라이드 8의 findMaxMin 알고리즘을 한 줄씩 자세히 분석해 보겠습니다.\nfindMaxMin(A[], i, j, min, max) // A[i..j]의 최댓값과 최솟값을 찾는다 // 입력: 배열 A[i..j] // 출력: min(최솟값), max(최댓값) A[]: 전체 배열 i, j: 현재 탐색할 부분 배열의 시작 인덱스와 끝 인덱스 min, max: 결과(최솟값, 최댓값)를 저장할 변수 (참조에 의한 전달 방식) 기저 사례 (Base Cases):\n1 if i = j { min = A[i]; max = A[i] } // 요소가 1개인 경우 Line 1: 부분 배열에 요소가 하나뿐일 때 (i == j). 이 경우 그 요소 자체가 최솟값이자 최댓값입니다. 더 이상 분할할 필요가 없으므로 재귀가 멈춥니다. 비교 연산은 없습니다. 2 else if i = j − 1 { // 요소가 2개인 경우 3 if A[i] \u003c A[j] { min = A[i]; max = A[j] } 4 else { min = A[j]; max = A[i] } 5 } Line 2-5: 부분 배열에 요소가 두 개일 때 (i == j-1). 이 경우 단 한 번의 비교(A[i] \u003c A[j])를 통해 둘 중 어느 것이 크고 작은지 바로 결정할 수 있습니다. 이 또한 재귀를 멈추는 기저 사례입니다. 비교 횟수는 1회입니다. 재귀 단계 (Recursive Step):\n6 else { // 요소가 2개보다 많은 경우 7 mid = ⌊(i + j) / 2⌋ 8 findMaxMin(A, i, mid, min1, max1) 9 findMaxMin(A, mid + 1, j, min2, max2) Line 7: 분할 단계입니다. 현재 부분 배열의 중간 지점 mid를 계산하여 두 개의 작은 부분 배열 A[i..mid]와 A[mid+1..j]로 나눕니다. Line 8, 9: 정복 단계입니다. 두 개의 부분 배열에 대해 findMaxMin 함수를 재귀적으로 호출하여 각각의 최솟값/최댓값(min1, max1과 min2, max2)을 구합니다. 10 if min1 \u003c min2 { min = min1 } 11 else { min = min2 } 12 if max1 \u003e max2 { max = max1 } // 슬라이드에서는 \u003c 로 되어있으나, \u003e 가 직관적 13 else { max = max2 } 14 } Line 10-14: 합병 단계입니다. 왼쪽 부분 배열의 최솟값(min1)과 오른쪽 부분 배열의 최솟값(min2)을 비교하여 전체의 최솟값을 결정합니다 (비교 1회). 왼쪽 부분 배열의 최댓값(max1)과 오른쪽 부분 배열의 최댓값(max2)을 비교하여 전체의 최댓값을 결정합니다 (비교 1회). 따라서, 이 합병 단계에서는 총 2회의 비교가 수행됩니다.","최선의-경우-best-case-분석#최선의 경우 (Best Case) 분석":"","최선의-경우-best-case-분석-1#최선의 경우 (Best Case) 분석":"언제 최선의 상황이 발생하는가? 배열이 이미 정렬되어 있을 때입니다. 예를 들어, [1, 2, 3, 4, 5, 6]. 이 경우, for 루프의 각 반복(i)에서 insertElement(A[i])는 A[j](A[i-1])보다 항상 크거나 같습니다. 따라서 내부 while 루프의 조건 A[j] \u003e insertElement는 항상 즉시 거짓이 됩니다.\ni = 1일 때: 비교 1번 i = 2일 때: 비교 1번 … i = n-1일 때: 비교 1번 총 비교 횟수는 n-1번입니다. 따라서 최선의 경우 시간 복잡도는 O(n), Θ(n) 입니다. 이는 삽입 정렬의 매우 중요한 특징입니다.","최악의-경우-worst-case-분석#최악의 경우 (Worst Case) 분석":"","최악의-경우-worst-case-분석-1#최악의 경우 (Worst Case) 분석":"언제 최악의 상황이 발생하는가? 배열이 역순으로 정렬되어 있을 때입니다. 예를 들어, [6, 5, 4, 3, 2, 1]. 이 경우, for 루프의 각 반복(i)에서 insertElement는 항상 정렬된 부분(A[0...i-1])의 모든 요소보다 작습니다. 따라서 내부 while 루프는 항상 j가 -1이 될 때까지, 즉 정렬된 부분의 모든 요소를 비교하고 이동시켜야 합니다.\ni = 1일 때: 비교 1번 i = 2일 때: 비교 2번 i = 3일 때: 비교 3번 … i = n-1일 때: 비교 n-1번 따라서 기본 연산의 총 수행 횟수는 등차수열의 합입니다. 1 + 2 + 3 + ... + (n-1) = (n-1) * (n-1 + 1) / 2 = n(n-1) / 2\n이 식은 (n² - n) / 2 이므로, 최고차항은 n²입니다. Big-O 표기법으로는 O(n²), Big-Theta 표기법으로는 Θ(n²) 입니다.","최종-요약-슬라이드-35#최종 요약 (슬라이드 35)":"그래프 탐색은 정점과 간선으로 이루어진 복잡한 구조를 체계적으로 방문하는 알고리즘의 기초입니다. **깊이 우선 탐색(DFS)**은 스택(재귀)을 이용해 한 경로를 끝까지 파고드는 ‘모험가’ 방식이며, 순환 탐지나 연결 요소 찾기 등에 유용합니다. **너비 우선 탐색(BFS)**은 큐를 이용해 시작점에서 가까운 순서대로 탐색하는 ‘전략가’ 방식이며, 최단 경로 문제의 핵심입니다. 위상 정렬은 **순환이 없는 방향 그래프(DAG)**에서 작업들의 선행 순서를 결정하는 중요한 문제이며, DFS나 BFS를 응용하여 효율적으로 해결할 수 있습니다. 이러한 기본적인 그래프 알고리즘들은 수많은 컴퓨터 과학 문제들, 예를 들어 네트워크 라우팅, 소셜 네트워크 분석, 컴파일러 의존성 해결, 인공지능 탐색 등 다양한 분야의 핵심적인 문제 해결 도구로 사용됩니다.","최종-정리#최종 정리":"그래프 탐색은 연결 관계를 파악하기 위한 필수적인 과정입니다. **DFS(깊이 우선 탐색)**는 “한 우물만 파는” 전략으로, 재귀적인 방식으로 구현하기 좋습니다. DFS를 수행하면서 새로운 정점을 발견한 경로들을 모으면, 그래프의 뼈대인 깊이 우선 신장 트리가 만들어집니다. 신장 트리에 포함되지 않은 **뒤 간선(Back Edge)**은 원래 그래프에 순환(Cycle)이 있음을 알려주는 중요한 단서입니다. DFS는 인접 목록으로 그래프를 표현할 때 **O(V+E)**의 매우 효율적인 시간 복잡도를 가집니다. 이처럼 DFS는 단순히 정점을 방문하는 것에서 그치지 않고, 그 과정에서 얻어지는 ‘신장 트리’와 ‘간선의 분류’라는 부산물을 통해 그래프의 구조적 특성(연결성, 순환 구조 등)을 파악하는 강력한 알고리즘입니다.","평균적인-경우-average-case-분석#평균적인 경우 (Average Case) 분석":"","평균적인-경우-average-case-분석-1#평균적인 경우 (Average Case) 분석":"입력 데이터가 무작위로 분포되어 있을 경우를 가정합니다. 평균적으로, 정렬되지 않은 부분에서 가져온 insertElement는 정렬된 부분의 중간쯤에 삽입될 것입니다. 즉, i번째 요소는 정렬된 i개의 요소 중 절반 정도(약 i/2개)와 비교하고 이동해야 합니다.\n총 비교 횟수는 대략 1/2 + 2/2 + 3/2 + ... + (n-1)/2 가 됩니다. 이는 (1/2) * (1 + 2 + ... + (n-1)) = (1/2) * n(n-1)/2 = n(n-1)/4 입니다.\n최고차항은 여전히 n²이므로, 평균 시간 복잡도 또한 O(n²), Θ(n²) 입니다.","한-탐험가의-고민-무엇을-챙겨야-할까#한 탐험가의 고민: 무엇을 챙겨야 할까?":"전설 속 보물이 잠들어 있다는 미지의 유적을 탐사하러 떠나는 한 탐험가를 상상해 봅시다. 이 탐험가에게는 평생의 꿈을 이룰 단 한 번의 기회입니다. 오랜 탐사 끝에 마침내 보물 창고를 발견했지만, 기쁨도 잠시, 큰 난관에 부딪힙니다.\n보물은 산더미처럼 쌓여 있지만, 탐험가가 가진 배낭의 용량은 한정되어 있습니다. 각 보물은 저마다 다른 무게를 가지고 있고, 그 가치 또한 천차만별입니다. 어떤 것은 작고 가볍지만 엄청난 가치를 지녔고, 어떤 것은 크고 무겁지만 상대적으로 가치가 낮습니다. 유적은 곧 무너질 위기에 처해 있고, 보물을 챙겨 나갈 기회는 단 한 번뿐입니다.\n탐험가는 이제 인생일대의 선택을 해야 합니다.\n“이 한정된 용량의 배낭에 어떤 보물들을 담아야 그 가치의 총합을 최대로 만들 수 있을까?”\n이것이 바로 배낭 채우기 문제입니다. 각 보물은 통째로 가져가거나(1), 아예 가져가지 않거나(0) 둘 중 하나만 선택할 수 있습니다. 보물을 쪼개서 일부만 가져갈 수는 없습니다. 그래서 이 문제를 특별히 **‘0-1 배낭 채우기 문제’**라고 부릅니다.","합병-정렬-시간-복잡도-분석#합병 정렬 시간 복잡도 분석":"T(n)을 크기 n인 배열을 합병 정렬하는 데 걸리는 시간이라고 합시다.\n분할: mid를 계산하는 것은 상수 시간 O(1)입니다. 정복: 크기 n/2인 두 개의 부분 문제를 재귀적으로 해결하므로 2 * T(n/2)의 시간이 걸립니다. 합병: merge 함수는 n개의 모든 요소를 한 번씩 다루므로 O(n)의 시간이 걸립니다. 따라서 점화식은 다음과 같습니다. T(n) = 2 * T(n/2) + O(n)\n이 점화식은 마스터 정리(Master Theorem)에 의해 또는 직접 풀어서 O(n log n)임을 알 수 있습니다. 이는 최악, 평균, 최선 모든 경우에 동일하게 적용됩니다. 합병 정렬은 입력 데이터의 상태와 관계없이 항상 O(n log n)의 성능을 보장하는 안정적인(stable) 정렬 알고리즘입니다.\n공간 복잡도: 합병 과정에서 n개의 요소를 담을 추가적인 임시 배열이 필요하므로 O(n)의 공간 복잡도를 가집니다.","합병-정렬-알고리즘-의사코드pseudocode#합병 정렬 알고리즘 의사코드(Pseudocode)":"mergeSort(A[], p, r) // 배열 A[p..r]을 정렬한다 1 if p \u003c r { 2 q = ⌊(p + r) / 2⌋ // 분할: 중간 지점 계산 3 mergeSort(A, p, q) // 정복: 왼쪽 부분 배열 정렬 4 mergeSort(A, q + 1, r) // 정복: 오른쪽 부분 배열 정렬 5 merge(A, p, q, r) // 합병: 두 정렬된 부분 배열을 합병 6 } merge(A[], p, q, r) // 정렬된 두 부분 배열 A[p..q]와 A[q+1..r]을 합병한다 1 // 임시 배열 temp에 A[p..r]을 복사 2 i = p; j = q + 1; t = 0; 3 while i ≤ q and j ≤ r { 4 if A[i] ≤ A[j] { temp[t++] = A[i++] } 5 else { temp[t++] = A[j++] } 6 } 7 // 남아있는 요소들을 복사 8 while i ≤ q { temp[t++] = A[i++] } 9 while j ≤ r { temp[t++] = A[j++] } 10 // temp의 내용을 A에 다시 복사 11 for i = p, t = 0; i ≤ r; i++, t++ { A[i] = temp[t] }","합병-정렬의-분할-정복-전략#합병 정렬의 분할 정복 전략":"합병 정렬은 이 불균형 문제를 정면으로 해결합니다.\n분할(Divide): 정렬되지 않은 배열을 크기가 거의 같은 두 개의 부분 배열로 나눕니다. 이 과정은 부분 배열에 요소가 하나만 남을 때까지 재귀적으로 계속됩니다. 요소가 하나인 배열은 그 자체로 정렬된 상태입니다.\n정복(Conquer): 각 부분 배열을 재귀적으로 정렬합니다.\n합병(Merge): 이 단계가 합병 정렬의 핵심입니다. 정복 단계에서 정렬된 두 개의 부분 배열을 하나의 전체 정렬된 배열로 합칩니다.","합병merge-과정-상세-설명#\u003cstrong\u003e합병(Merge) 과정 상세 설명\u003c/strong\u003e":"두 개의 이미 정렬된 부분 배열 L과 R을 합병하는 과정을 생각해 봅시다.\n새로운 임시 배열 temp를 준비합니다. L의 첫 번째 요소를 가리키는 포인터 i와 R의 첫 번째 요소를 가리키는 포인터 j를 둡니다. L[i]와 R[j]를 비교합니다. 더 작은 값을 temp 배열에 넣고, 해당 포인터를 1 증가시킵니다. L이나 R 중 어느 한쪽의 모든 요소가 temp에 들어갈 때까지 이 비교-복사 과정을 반복합니다. 남아있는 다른 쪽 배열의 모든 요소들을 temp 배열의 뒤에 순서대로 복사합니다. 마지막으로, temp 배열의 내용을 원래 배열의 해당 위치에 다시 복사합니다. 이 합병 과정은 두 부분 배열의 길이를 합한 만큼의 시간, 즉 선형 시간 O(n)이 걸립니다.","해답을-넘어-어떤-물건을-담았는가-역추적#해답을 넘어: 어떤 물건을 담았는가? (역추적)":"최대 가치가 65라는 것은 알았지만, 탐험가에게 정말 필요한 정보는 ‘그래서 어떤 보물을 챙겨야 하는가?’ 입니다. 이 정보 또한 우리가 만든 테이블 안에 숨겨져 있습니다. 테이블을 거꾸로 거슬러 올라가며 우리가 내렸던 선택을 복기해 봅시다. 이 과정을 **역추적(Backtracking)**이라고 합니다.\n**K[4, 7] = 65**에서 시작합니다. 이 값은 바로 윗칸 K[3, 7] = 60과 같습니까?\n다릅니다. 65 ≠ 60. 이는 K[4, 7]을 계산할 때 물건 4를 포함하는 선택이 최적이었다는 의미입니다. 선택: 물건 4 (w=4, v=30)를 배낭에 넣는다! 이제 우리는 물건 4를 넣었으므로, 남은 용량 7 - w[4] = 7 - 4 = 3에 대해, 남은 물건 1, 2, 3으로 채우는 문제로 이동해야 합니다. 즉, K[3, 3]으로 이동합니다. 현재 위치는 K[3, 3] = 35 입니다. 이 값은 바로 윗칸 K[2, 3] = 25와 같습니까?\n다릅니다. 35 ≠ 25. 이는 K[3, 3]을 계산할 때 물건 3을 포함하는 선택이 최적이었다는 의미입니다. 선택: 물건 3 (w=2, v=20)를 배낭에 넣는다! 남은 용량 3 - w[3] = 3 - 2 = 1에 대해, 남은 물건 1, 2로 채우는 문제로 이동합니다. 즉, K[2, 1]로 이동합니다. 현재 위치는 K[2, 1] = 15 입니다. 이 값은 바로 윗칸 K[1, 1] = 0과 같습니까?\n다릅니다. 15 ≠ 0. 이는 K[2, 1]을 계산할 때 물건 2를 포함하는 선택이 최적이었다는 의미입니다. 선택: 물건 2 (w=1, v=15)를 배낭에 넣는다! 남은 용량 1 - w[2] = 1 - 1 = 0에 대해, 남은 물건 1로 채우는 문제로 이동합니다. 즉, K[1, 0]으로 이동합니다. 현재 위치는 K[1, 0] = 0 입니다. 배낭 용량이 0이 되었으므로 역추적을 종료합니다.\n역추적 결과, 탐험가가 챙겨야 할 보물은 물건 2, 3, 4입니다. 확인해 볼까요?\n총무게: w[2] + w[3] + w[4] = 1 + 2 + 4 = 7 (배낭 용량 7에 딱 맞습니다!) 총가치: v[2] + v[3] + v[4] = 15 + 20 + 30 = 65 (우리가 구한 최대 가치와 일치합니다!)","핵심-아이디어-정렬된-부분과-정렬되지-않은-부분#핵심 아이디어: 정렬된 부분과 정렬되지 않은 부분":"삽입 정렬은 배열을 논리적으로 두 부분으로 나누어 생각합니다.\n정렬된 부분(Sorted Sub-array): 배열의 앞부분으로, 이 부분의 원소들은 항상 정렬된 상태를 유지합니다. 정렬되지 않은 부분(Unsorted Sub-array): 배열의 뒷부분으로, 아직 처리되지 않은 원소들이 남아있습니다. 알고리즘은 정렬되지 않은 부분의 가장 앞에 있는 원소를 하나씩 꺼내어, 정렬된 부분의 끝에서부터 비교하면서 자신의 올바른 위치를 찾아 삽입합니다. 이 과정이 끝나면 정렬된 부분의 크기는 하나 늘어나고, 정렬되지 않은 부분의 크기는 하나 줄어듭니다. 이 작업을 정렬되지 않은 부분이 없어질 때까지 반복합니다.","행렬-곱셈의-특성과-새로운-문제의-발견#행렬 곱셈의 특성과 새로운 문제의 발견":"우리는 이전에 분할 정복의 한계와 이를 극복하는 동적 계획법의 원리를 막대 자르기 문제를 통해 살펴보았습니다. 핵심은 ‘중복되는 부분 문제’의 해를 한 번만 계산하고 저장하여 재사용하는 것이었죠. 이제 우리는 훨씬 더 복잡해 보이지만, 동일한 원리가 화려하게 적용되는 새로운 최적화 문제를 만나보겠습니다. 바로 연속된 행렬들의 곱셈 순서를 정하는 문제입니다.\n먼저 행렬 곱셈의 기본적인 성질을 짚고 넘어가야 합니다. 두 행렬 A와 B를 곱하여 행렬 C를 얻는 연산 C = A × B는, 행렬 A의 열의 개수와 행렬 B의 행의 개수가 같을 때만 정의됩니다. 만약 A가 m × p 행렬이고 B가 p × n 행렬이라면, 결과 C는 m × n 행렬이 됩니다.\n이때, C의 각 원소 c_ij를 계산하기 위해서는 A의 i번째 행과 B의 j번째 열에 있는 원소들을 각각 곱해서 더해야 합니다. 이 과정에는 총 p번의 스칼라 곱셈이 필요합니다. 결과 행렬 C는 총 m × n개의 원소를 가지므로, 두 행렬 A와 B를 곱하는 데 필요한 총 스칼라 곱셈 횟수는 m × p × n이 됩니다. 이 곱셈 횟수가 바로 우리가 앞으로 최소화하려는 ‘비용(cost)‘이 됩니다.\n자, 이제 행렬이 세 개 이상, 예를 들어 M₁ × M₂ × M₃과 같이 연속으로 주어졌다고 생각해 봅시다. 행렬 곱셈은 결합 법칙(associative law)이 성립하기 때문에, 곱하는 순서를 바꿔도 최종 결과는 같습니다. 즉, (M₁ × M₂) × M₃ 와 M₁ × (M₂ × M₃)의 결과 행렬은 동일합니다.\n하지만, 계산 과정의 ‘비용’은 어떨까요?\n예를 들어 세 행렬의 크기가 다음과 같다고 가정해 봅시다.\nM₁ : 10 × 20 M₂ : 20 × 5 M₃ : 5 × 50 경우 1: (M₁ × M₂) × M₃\nM₁ × M₂를 먼저 계산합니다. 비용: 10 × 20 × 5 = 1,000 번의 곱셈. 결과 행렬 (M₁₂)의 크기: 10 × 5 결과 행렬 (M₁₂)와 M₃를 곱합니다. 비용: 10 × 5 × 50 = 2,500 번의 곱셈. 최종 결과 행렬의 크기: 10 × 50 총 비용: 1,000 + 2,500 = 3,500 경우 2: M₁ × (M₂ × M₃)\nM₂ × M₃를 먼저 계산합니다. 비용: 20 × 5 × 50 = 5,000 번의 곱셈. 결과 행렬 (M₂₃)의 크기: 20 × 50 M₁과 결과 행렬 (M₂₃)을 곱합니다. 비용: 10 × 20 × 50 = 10,000 번의 곱셈. 최종 결과 행렬의 크기: 10 × 50 총 비용: 5,000 + 10,000 = 15,000 놀랍게도 곱셈 순서에 따라 총 계산 비용이 3,500과 15,000으로 엄청난 차이를 보입니다. 행렬의 개수가 늘어날수록 가능한 곱셈 순서의 조합은 기하급수적으로 증가(카탈란 수, Catalan number를 따름)하며, 최적의 순서를 찾는 것은 매우 중요한 문제가 됩니다. 이것이 바로 **연속 행렬 곱셈 문제(Matrix Chain Multiplication Problem)**입니다.\n문제 정의: n개의 행렬 체인 M₁ × M₂ × ... × Mₙ이 주어졌을 때, 총 스칼라 곱셈 횟수를 최소화하는 곱셈 순서(괄호 치는 방법)를 찾는 것.\n컴퓨터가 두 행렬을 곱할 때 실제로 무슨 일을 하는지 들여다봅시다. A (2x3 크기) 와 B (3x2 크기) 두 행렬이 있다고 상상해 보세요. 결과 행렬 C의 딱 한 칸, C[1][1] (1행 1열)을 채우려면 어떻게 해야 할까요? A의 1행 ([1, 2, 3])과 B의 1열 ([7, 9, 11])을 가져옵니다. 각각의 위치에 있는 숫자끼리 곱하고, 그 결과들을 전부 더합니다. (1 × 7) -\u003e 곱셈 1번 (2 × 9) -\u003e 곱셈 1번 (3 × 11) -\u003e 곱셈 1번 결과들을 더하기: 7 + 18 + 33 = 58 C의 딱 한 칸을 채우는 데 곱셈을 3번 했습니다. 그럼 C의 모든 칸(총 2x2 = 4칸)을 채우려면 곱셈을 몇 번 해야 할까요? - 모든 칸에 대해 똑같이 곱셈을 3번씩 해야 합니다. - 총 곱셈 횟수 = (한 칸당 곱셈 횟수) × (총 칸의 개수) - 총 곱셈 횟수 = 3 × (2 × 2) = 12번 이것을 일반화한 것이 바로 그 공식입니다. m × p 행렬과 p × n 행렬을 곱하면,\n결과 행렬은 m × n 크기 (총 m × n 개의 칸) 한 칸을 채우는 데 곱셈을 p번 함 총 곱셈 횟수(계산량) = m × p × n 알고리즘에서 말하는 **“비용(Cost)” 또는 “계산량”**은 바로 이 총 곱셈 횟수를 의미합니다. 우리는 이 숫자를 가장 작게 만들고 싶은 것입니다.","행렬들의-곱셈-순서를-정하는-문제#행렬들의 곱셈 순서를 정하는 문제":"","힙-정렬의-전체-시간-복잡도#\u003cstrong\u003e힙 정렬의 전체 시간 복잡도\u003c/strong\u003e":"전체 시간 복잡도는 두 단계의 합입니다. Total = buildHeap 시간 + 정렬 시간 Total = O(n) + O(n log n) = O(n log n)\n지배적인 항이 O(n log n)이므로, 힙 정렬의 최종 시간 복잡도는 **O(n log n)**이 됩니다. 이는 평균, 최선, 최악의 경우 모두 동일하게 적용되어, 어떤 입력 데이터가 들어와도 안정적인 성능을 보장하는 장점이 있습니다.","힙정렬-heap-sort#힙정렬 (heap sort)":""},"title":"university algorizm"},"/university-mobile-programming/":{"data":{"":"","-constraintlayout의-주의사항#⚠️ \u003ccode\u003eConstraintLayout\u003c/code\u003e의 주의사항":"제약 누락 (Missing Constraints)\n수평 또는 수직 제약 중 하나라도 없으면, 해당 축의 위치가 확정되지 않아 뷰가 레이아웃의 (0,0) 위치로 이동합니다. 레이아웃 편집기는 이런 경우 경고를 표시해 줍니다. XML의 복잡성\n뷰가 많아지고 제약이 복잡해지면 XML 코드가 길고 가독성이 떨어질 수 있습니다. 따라서 안드로이드 스튜디오의 **레이아웃 편집기(Layout Editor)**를 사용하는 것이 거의 필수적입니다. 성능\nConstraintLayout은 **평평한 뷰 계층(Flat View Hierarchy)**을 만들도록 설계되었습니다. LinearLayout이나 RelativeLayout을 여러 번 중첩하는 것보다 단일 ConstraintLayout을 사용하는 것이 일반적으로 렌더링 성능에 훨씬 유리합니다.","-gridlayout-사용-시-주의점-및-tablelayout과의-비교#⚠️ GridLayout 사용 시 주의점 및 TableLayout과의 비교":"TableLayout과의 차이: TableLayout은 태그로 각 행을 명시적으로 선언해야 해서 구조가 더 경직됩니다. GridLayout은 columnCount나 rowCount만 지정하면 자동으로 줄바꿈을 처리해 훨씬 유연합니다. layout_gravity의 중요성: 셀 병합(Span)이나 공간 채우기를 할 때 layout_gravity 속성을 올바르게 사용하는 것이 매우 중요합니다. 현대적 대안: ConstraintLayout은 가이드라인(Guideline)과 체인(Chain) 기능을 통해 GridLayout보다 더 복잡하고 유연한 그리드 시스템을 평평한 구조(flat hierarchy)로 구현할 수 있어, 복잡한 화면에서는 성능상 더 유리할 수 있습니다.","-relativelayout의-주의사항#⚠️ \u003ccode\u003eRelativeLayout\u003c/code\u003e의 주의사항":"순환 종속성 (Circular Dependency)\nA 뷰가 B 뷰의 오른쪽에(toRightOf=\"B\") 있고, B 뷰가 A 뷰의 오른쪽에(toRightOf=\"A\") 있도록 서로를 참조하면 앱이 비정상 종료될 수 있습니다. 뷰의 관계는 한 방향으로만 흐르도록 설계해야 합니다. 성능 문제\n뷰의 위치를 결정하기 위해 레이아웃 계산을 두 번(Two measurement passes) 수행하는 경우가 많아, 뷰가 매우 많은 복잡한 구조에서는 성능 저하를 유발할 수 있습니다. 중첩된 RelativeLayout은 성능에 더욱 좋지 않습니다. 기준점 부재\n뷰에 아무런 위치 규칙을 주지 않으면, 기본값으로 부모의 좌측 상단 (0, 0)에 겹쳐서 표시됩니다. 의도치 않게 뷰들이 겹쳐 보인다면 위치 규칙이 누락되었는지 확인해야 합니다.","-질문-있어요-qa#❓ 질문 있어요! (Q\u0026amp;A)":"Q. 롱클릭 이벤트 핸들러에서 마지막 줄의 true를 생략하면 오류가 발생합니다. 어떤 의미인가요?\nA. 이는 함수의 반환값을 의미합니다. setOnLongClickListener가 요구하는 OnLongClickListener 인터페이스의 추상 메서드 onLongClick은 다음과 같이 정의되어 있습니다.\nabstract fun onLongClick(v: View!): Boolean 메서드의 반환 타입이 Boolean이므로, 이벤트를 처리한 후 반드시 true 또는 false를 반환해야 합니다.\n코틀린에서 여러 줄로 구성된 람다식은 마지막 줄의 실행 결과를 자동으로 반환값으로 취급합니다. 따라서 return 키워드 없이 true만 적어도 onLongClick 메서드가 true를 반환하는 것으로 처리됩니다.\ntrue 반환: “이 롱클릭 이벤트를 내가 완전히 처리(소비)했음. 이후 다른 이벤트(예: 클릭 이벤트)를 발생시키지 말 것.” false 반환: “롱클릭 이벤트에 반응은 했지만, 완전히 처리한 것은 아님. 시스템이 이어서 다른 이벤트(예: 클릭 이벤트)를 발생시켜도 됨.”","-참고-설명#📌 참고 설명":"@+id/ vs @id/:\n@+id/name → 새로 생성 (처음 사용 시) @id/name → 기존 ID 참조 (이미 정의된 경우) drawable vs mipmap:\ndrawable: 일반 이미지 (버튼 아이콘, 배경 등) mipmap: 앱 런처 아이콘 전용 → 시스템이 다양한 해상도에서 안정적으로 표시 dimen 단위:\ndp → 화면 밀도 독립적 길이 (여백, 크기) sp → 사용자 글꼴 크기 설정 반영 (텍스트 크기) plurals 예시 (strings.xml):","-핵심-교훈#💡 핵심 교훈":"상황 layout_weight 동작 부모가 match_parent 또는 고정 높이 ✅ 정상 작동 — 남은 공간 분배 부모가 wrap_content ❌ 거의 항상 무시 — 남은 공간 없음 wrap_content + layout_weight 혼합 ⚠️ 비추천 — 성능 저하 + 예측 불가 중첩 레이아웃 🔍 각 레이어별로 부모 크기 확인 필수","-핵심-교훈-1#💡 핵심 교훈":"속성 대상 주의 사항 android:gravity 뷰 내부 콘텐츠 (텍스트, 아이콘 등) 뷰 크기가 콘텐츠보다 커야 효과 시각화 android:layout_gravity 부모 내에서의 뷰 위치 LinearLayout 방향의 반대 축에서만 작동 조합 사용 시 두 속성은 독립적 match_parent와 layout_gravity는 충돌 가능 부모 크기 wrap_content면 정렬 효과 미약 여유 공간 확보 필수 ✅ 명심:\ngravity → “내 속 내용 정렬” layout_gravity → “나를 부모 안에서 정렬” LinearLayout에서는 정렬 가능한 축이 제한됨. 네, 요청하신 형식과 스타일에 맞춰 RelativeLayout에 대한 설명을 작성해 드리겠습니다.","-핵심-교훈-2#💡 핵심 교훈":"항목 설명 핵심 개념 ID를 통한 관계 설정. 뷰들이 서로 또는 부모를 기준으로 위치를 잡습니다. 장점 중첩을 줄이면서 복잡하고 유연한 UI를 만들 수 있습니다. 단점 뷰가 많아지면 관계가 복잡해지고, XML 가독성이 떨어지며 성능 저하가 발생할 수 있습니다. 주의사항 순환 종속성 오류를 피하고, 기준점 ID를 명확히 해야 합니다. 현대적 대안 ConstraintLayout. RelativeLayout의 모든 기능과 그 이상을 제공하면서 성능이 더 뛰어나고, 강력한 편집기(Layout Editor)를 지원합니다. 새로운 레이아웃을 작성할 때는 ConstraintLayout 사용이 적극 권장됩니다.","-핵심-교훈-3#💡 핵심 교훈":"항목 설명 핵심 기능 뷰 겹치기 (Stacking). 나중에 선언된 뷰가 위에 온다. 위치 지정 android:layout_gravity를 사용하여 부모 내에서 정렬한다. 동적 제어 android:visibility 속성 (visible, invisible, gone)을 이용해 뷰를 제어하는 것이 핵심 용도. 주요 용도 - 화면 전환: 탭(Tab) 화면처럼 한 번에 하나의 화면만 보여줄 때.\n- UI 오버레이: 비디오 위의 재생 버튼, 이미지 위의 프로그레스 바 등. 단순함 단 하나의 자식 뷰를 담는 가장 간단한 컨테이너로도 사용된다. (예: Fragment를 담는 컨테이너)","-핵심-교훈-4#💡 핵심 교훈":"항목 설명 핵심 개념 자동 줄바꿈이 되는 격자무늬(Grid) 레이아웃. 주요 속성 orientation, columnCount / rowCount로 전체 구조를 잡는다. 자식 뷰 제어 layout_span으로 셀을 병합하고, layout_gravity로 셀을 채우거나 정렬한다. 장점 TableLayout보다 유연하고 적은 코드로 격자 UI를 만들 수 있다. 주요 용도 계산기, 갤러리 썸네일, 대시보드 메뉴 등 표 형태의 UI 구성.","-핵심-교훈-5#💡 핵심 교훈":"항목 설명 핵심 개념 **ID와 앵커 포인트(Anchor Point)**를 연결하는 **‘제약’**으로 뷰의 위치와 크기를 정의합니다. 장점 **평평한 계층 구조(Flat Hierarchy)**로 중첩 없이 복잡한 UI 구현이 가능하며, 이는 성능에 유리합니다. 매우 유연하고 강력합니다. 단점 XML 코드가 길고 복잡해질 수 있어, 레이아웃 편집기 사용이 거의 필수적입니다. 주의사항 모든 뷰는 수평/수직 제약이 모두 필요합니다. 제약 누락 시 뷰가 의도치 않은 위치(0,0)로 이동할 수 있습니다. 현대적 위치 현재 안드로이드 UI 개발의 표준 레이아웃입니다. 새로운 화면을 구성할 때 가장 먼저 고려해야 하며, RelativeLayout을 완벽히 대체합니다.","-핵심-교훈-6#💡 핵심 교훈":"항목 설명 저수준(Low-level) vs. 고수준(High-level) 이벤트 onTouchEvent, onKeyDown은 시스템에서 오는 날 것의 저수준 이벤트입니다. 반면 setOnClickListener, addTextChangedListener 등은 이러한 저수준 이벤트를 조합하고 추상화하여 특정 목적에 맞게 만든 고수준 이벤트 리스너입니다. 대부분의 경우, 고수준 리스너를 사용하는 것이 더 간단하고 안정적입니다. 이벤트 처리의 책임 return true를 통해 이벤트를 ‘소비’하는 것은 해당 이벤트에 대한 모든 책임을 지겠다는 의미입니다. 연속적인 터치 동작(드래그, 핀치 줌 등)을 구현할 때 이 개념을 반드시 이해해야 합니다. 시스템 동작과의 조화 키 이벤트를 커스터마이징할 때는 사용자의 일반적인 기대를 해치지 않는 선에서 신중하게 구현해야 합니다. 특히 뒤로 가기 버튼의 기본 동작을 막을 때는 사용자에게 명확한 피드백을 제공해야 합니다. 아키텍처의 변화 수용 onBackPressed()에서 OnBackPressedCallback으로의 전환은 안드로이드가 생명주기와 컴포넌트 기반 아키텍처를 얼마나 중요하게 생각하는지를 보여주는 좋은 예입니다. 항상 최신 권장 방식을 따르는 것이 좋습니다.","1-framework-integration-layer#\u003cstrong\u003e1. Framework Integration Layer: \u003ccode\u003eMainActivity\u003c/code\u003e \u0026amp; \u003ccode\u003esetContent\u003c/code\u003e\u003c/strong\u003e":"class MainActivity : ComponentActivity() { override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) enableEdgeToEdge() setContent { // ... Composable Content ... } } }","1-hard-keywords#1. Hard Keywords":"(문법 구조에 필수적이며, 식별자로 절대 사용할 수 없음)\n키워드 설명 as (cast) 타입 캐스팅 (val x = obj as String) as (import) 임포트 시 별칭 지정 (import foo.Bar as Baz) as? 안전한 타입 캐스팅 (실패 시 null 반환) break 루프 또는 라벨 블록 탈출 class 클래스 정의 continue 현재 루프 반복 건너뛰기 do do-while 루프 시작 else if 조건의 대안 블록 false 불리언 상수: 거짓 for 컬렉션/범위 반복 (for (i in list)) fun 함수 정의 if 조건 분기 in 범위/컬렉션 멤버 확인 또는 for 루프에서 사용 !in in의 부정 interface 인터페이스 정의 is 타입 확인 (if (obj is String)) !is is의 부정 null 널 참조 값 object 싱글톤 객체 또는 익명 객체 정의 package 패키지 선언 return 함수 또는 라벨에서 반환 super 상위 클래스 참조 this 현재 객체 참조 throw 예외 발생 true 불리언 상수: 참 try 예외 처리 블록 시작 typealias 타입 별칭 정의 typeof Kotlin/JS 전용; 일반 Kotlin에서는 사용되지 않음 val 읽기 전용 변수 선언 var 변경 가능한 변수 선언 when 다중 조건 분기 (switch 대체) while 조건이 참일 동안 반복","1-java-방식의-이벤트-핸들러#1. Java 방식의 이벤트 핸들러":"자바에서는 보통 아래와 같이 익명 내부 클래스(anonymous inner class)를 사용하여 이벤트 핸들러를 작성합니다.\n// 자바로 작성한 이벤트 핸들러 binding.btn.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View view) { // ... 클릭 시 실행될 로직 ... } });","1-액티비티-activity#1. **액티비티 **(Activity)":"액티비티는 앱의 화면을 구성하는 컴포넌트입니다.\n사용자가 보는 하나의 화면(예: 로그인 화면, 메인 화면 등)은 하나의 액티비티로 표현됩니다.\n앱을 실행하면, 기본 액티비티가 시작되어 그 내용이 안드로이드 기기의 화면에 표시됩니다.\n따라서 화면을 출력하려면 반드시 액티비티를 만들어야 합니다.","1-액티비티에서-인터페이스-구현#1. 액티비티에서 인터페이스 구현":"Activity 클래스 자체가 리스너 인터페이스를 직접 구현하는 방식입니다.\nclass MainActivity3 : AppCompatActivity(), CompoundButton.OnCheckedChangeListener { override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) val binding = ActivityMain3Binding.inflate(layoutInflater) setContentView(binding.root) // 리스너의 인자로 Activity 자신(this)을 전달 binding.checkbox.setOnCheckedChangeListener(this) } // 인터페이스의 추상 메서드 구현 override fun onCheckedChanged(buttonView: CompoundButton?, isChecked: Boolean) { Log.d(\"kkang\", \"체크박스 클릭\") } } 특징 및 장단점: 장점: 관련된 코드가 Activity 클래스 내에 모여있어 간단한 경우 파악하기 쉽습니다. 단점: Activity가 여러 종류의 리스너를 구현하면 코드가 비대해지고 역할이 불분명해집니다. (단일 책임 원칙 위배 가능성)","2-composition--state-layer#\u003cstrong\u003e2. Composition \u0026amp; State Layer: \u003ccode\u003eMyApplicationTheme\u003c/code\u003e \u0026amp; \u003ccode\u003eScaffold\u003c/code\u003e\u003c/strong\u003e":"MyApplicationTheme { Scaffold(modifier = Modifier.fillMaxSize()) { innerPadding -\u003e Greeting( name = \"Android\", modifier = Modifier.padding(innerPadding) ) } }","2-soft-keywords#2. Soft Keywords":"(특정 문맥에서만 키워드로 동작하며, 일반 식별자로 사용 가능)\n키워드 설명 by 위임 구현 (class C : B by b) catch try-catch에서 예외 처리 블록 constructor 주/부생성자 명시 (class A constructor(...)) delegate 속성 위임 내부 식별자 (컴파일러용) dynamic Kotlin/JS에서 동적 타입 선언 field 커스텀 getter/setter 내 백킹 필드 참조 file 파일 레벨 식별자 (메타프로그래밍/컴파일러용) finally try-finally에서 항상 실행되는 블록 get 속성 getter 정의 (val x: Int get() = ...) import 패키지/클래스 임포트 init 초기화 블록 (init { ... }) param 어노테이션 파라미터 식별자 property 속성 관련 메타정보 식별자 receiver 확장 함수 수신 객체 식별자 set 속성 setter 정의 (var x: Int set(value) { ... }) setparam setter 내 파라미터 식별자 (value) where 제네릭 제약 조건 ( where T : Comparable)","2-별도의-클래스로-구현#2. 별도의 클래스로 구현":"이벤트 핸들러 로직을 완전히 분리된 클래스로 작성하는 방식입니다.\n// 이벤트 핸들러를 별도의 클래스로 분리 class MyEventHandler : CompoundButton.OnCheckedChangeListener { override fun onCheckedChanged(buttonView: CompoundButton?, isChecked: Boolean) { Log.d(\"kkang\", \"체크박스 클릭\") } } class MainActivity3 : AppCompatActivity() { override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) val binding = ActivityMain3Binding.inflate(layoutInflater) setContentView(binding.root) // 분리된 핸들러 클래스의 인스턴스를 생성하여 등록 binding.checkbox.setOnCheckedChangeListener(MyEventHandler()) } } 특징 및 장단점: 장점: 로직이 복잡하거나 여러 곳에서 재사용될 때 유용합니다. 코드의 역할 분리가 명확해져 가독성과 유지보수성이 향상됩니다. 단점: 간단한 일회성 이벤트 처리를 위해 매번 클래스를 만드는 것은 번거로울 수 있습니다.","2-서비스-service#2. **서비스 **(Service)":"서비스는 백그라운드에서 장시간 작업을 수행하는 컴포넌트입니다.\n화면을 표시하지 않으며, 사용자와 직접 상호작용하지 않습니다.\n예를 들어, 음악 재생, 파일 다운로드, 위치 추적과 같은 작업은 앱이 백그라운드에 있어도 계속 실행되어야 하므로 서비스를 사용합니다.","2-코틀린의-정식-변환-object-사용#2. 코틀린의 정식 변환 (object 사용)":"위 자바 코드를 코틀린으로 그대로 변환하면 object 키워드를 사용한 익명 객체 표현식이 됩니다.\n// 코틀린으로 작성한 이벤트 핸들러 binding.btn.setOnClickListener(object: View.OnClickListener { override fun onClick(p0: View?) { // ... 클릭 시 실행될 로직 ... } })","3-modifier-keywords#3. Modifier Keywords":"(선언에 대한 속성 또는 동작을 지정)\n키워드 설명 actual 멀티플랫폼 프로젝트에서 실제 구현 지정 abstract 추상 클래스 또는 멤버 (구현 없음) annotation 어노테이션 클래스 정의 companion 컴패니언 객체 선언 (companion object { }) const 컴파일 타임 상수 (const val MAX = 100) crossinline 람다 내 non-local return 금지 data 데이터 클래스 (equals, hashCode, toString 자동 생성) enum 열거 클래스 정의 expect 멀티플랫폼에서 예상 선언 external 외부(Native/JS) 구현 선언 final 오버라이드 불가 (기본값, 명시적 사용 드묾) infix 중위 함수 (a plus b 대신 a plus b) inline 함수/클래스를 호출 위치에 인라인 확장 inner 내부 클래스 (외부 클래스 인스턴스 참조 가능) internal 같은 모듈 내에서만 접근 가능 lateinit 나중에 초기화되는 non-null var noinline 람다를 인라인하지 않음 open 오버라이드 가능 (기본은 final) operator 연산자 오버로딩 함수 지정 out 공변성 제네릭 (Producer) override 상위 클래스/인터페이스 멤버 재정의 private 선언된 스코프 내에서만 접근 가능 protected 하위 클래스까지 접근 가능 public 모든 곳에서 접근 가능 (기본 접근 수준) reified 인라인 함수에서 제네릭 타입 실체화 sealed 제한된 하위 클래스 집합 (밀봉 클래스) suspend 코루틴에서 사용 가능한 함수 tailrec 꼬리 재귀 최적화 함수 vararg 가변 인자 (fun f(vararg args: Int))","3-sam-기법-람다식으로-구현#3. SAM 기법 (람다식)으로 구현":"코틀린에서 가장 보편적이고 권장되는 방식입니다. 자바의 함수형 인터페이스를 간결한 람다(Lambda) 표현식으로 대체할 수 있는 SAM(Single Abstract Method) 변환을 활용합니다.\nclass MainActivity3 : AppCompatActivity() { override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) val binding = ActivityMain3Binding.inflate(layoutInflater) setContentView(binding.root) // 인터페이스 구현 객체 대신 람다식을 바로 전달 binding.checkbox.setOnCheckedChangeListener { compoundButton, b -\u003e Log.d(\"kkang\", \"체크박스 클릭\") } } } 특징 및 장단점: 장점: 코드가 매우 간결하고 직관적입니다. 불필요한 보일러플레이트 코드를 제거하여 생산성이 높습니다. 단점: SAM 변환이 가능한 인터페이스(추상 메서드가 하나인 인터페이스)에만 사용할 수 있습니다.","3-ui-declaration--modification-layer#\u003cstrong\u003e3. UI Declaration \u0026amp; Modification Layer\u003c/strong\u003e":"","3-코틀린-sam-기법을-통한-간소화#3. 코틀린 SAM 기법을 통한 간소화":"코틀린은 추상 메서드가 단 하나뿐인 자바 인터페이스를 인자로 받는 자바 함수를 호출할 때, 위와 같은 object 표현식 대신 람다식으로 코드를 자동 변환해주는 SAM 변환 기능을 제공합니다.\nView.OnClickListener 인터페이스는 onClick()이라는 추상 메서드를 단 하나만 가지고 있습니다. 따라서 코틀린 컴파일러는 아래와 같은 람다식을,\nbinding.btn.setOnClickListener { ... } 내부적으로는 View.OnClickListener를 구현한 객체로 변환하여 setOnClickListener 함수에 전달해 줍니다. 이 덕분에 개발자는 매우 간결하고 읽기 쉬운 코드를 작성할 수 있습니다.\n💡 SAM 변환의 조건 SAM 변환은 코틀린 코드에서 자바로 작성된 메서드를 호출할 때, 그 메서드가 추상 메서드가 하나인 자바 인터페이스를 매개변수로 요구하는 경우에만 적용됩니다.","3-콘텐츠-프로바이더-content-provider#3. **콘텐츠 프로바이더 **(Content Provider)":"콘텐츠 프로바이더는 앱 간에 데이터를 공유하는 컴포넌트입니다.\n안드로이드 기기에는 여러 앱이 설치되어 있고, 이들 사이에서 데이터를 안전하게 주고받을 필요가 있습니다.\n예를 들어, 카카오톡에서 프로필 사진을 변경할 때 갤러리 앱의 사진을 선택할 수 있습니다.\n이때 갤러리 앱은 자신의 이미지 데이터를 콘텐츠 프로바이더를 통해 공유하고, 카카오톡은 이를 통해 데이터에 접근합니다.","4-special-identifiers#4. Special Identifiers":"(특정 문맥에서만 특별한 의미를 가지는 식별자)\n식별자 설명 field 커스텀 getter/setter 내에서 백킹 필드 참조 (get() = field) it 람다 식에서 단일 파라미터의 암시적 이름 (list.map { it * 2 }) ✅ 참고:\nfield는 속성 접근자 내에서만 특별한 의미를 가지며, 그 외에서는 일반 식별자로 사용 가능합니다. it은 람다 파라미터가 하나일 때 자동으로 사용되는 이름입니다.","4-브로드캐스트-리시버-broadcast-receiver#4. **브로드캐스트 리시버 **(Broadcast Receiver)":"브로드캐스트 리시버는 시스템에서 발생하는 특정 이벤트에 반응하는 컴포넌트입니다.\n여기서 말하는 이벤트는 사용자의 터치나 클릭과 같은 화면 상의 동작이 아니라,\n시스템 수준의 이벤트를 의미합니다.\n예를 들어, 기기 부팅 완료, 배터리 잔량 부족, 네트워크 연결 상태 변경 등이 있습니다.\n이러한 이벤트가 발생하면, 등록된 브로드캐스트 리시버가 자동으로 실행되어 적절한 처리를 수행할 수 있습니다.","android-component#android component":"안드로이드 앱은 네 가지 핵심 구성 요소, 즉 안드로이드 컴포넌트로 이루어져 있습니다.\n이들은 각각 다른 역할을 수행하며, 앱이 정상적으로 동작하도록 지원합니다.\n네 가지 컴포넌트는 다음과 같습니다:","android-레이아웃layout-및-ui-뷰view-종류#Android 레이아웃(Layout) 및 UI 뷰(View) 종류":"Android SDK에서 제공하는 주요 레이아웃(ViewGroup) 및 UI 뷰(View) 컴포넌트를 아래 표로 정리했습니다.\n레이아웃(Layout/ViewGroup): 다른 뷰를 담을 수 있는 컨테이너 역할 UI 뷰(View): 사용자와 직접 상호작용하거나 정보를 표시하는 위젯 분류 클래스 이름 설명 주요 특징 **레이아웃 **(ViewGroup) LinearLayout 자식 뷰를 수평(horizontal) 또는 수직(vertical)으로 배열 layout_weight, orientation 사용 RelativeLayout 자식 뷰 간 또는 부모 기준 상대 위치로 배치 layout_alignParent*, layout_toRightOf 등 사용 ConstraintLayout 유연하고 성능 좋은 제약 기반 레이아웃 layout_constraint* 속성, 플랫 계층 구조 가능 FrameLayout 자식 뷰를 스택처럼 겹쳐 배치 (기본: 좌상단) 간단한 오버레이, 프래그먼트 컨테이너로 자주 사용 GridLayout 그리드(행/열) 형태로 자식 뷰 배치 row, column, span 지정 가능 CoordinatorLayout 자식 뷰 간 상호작용(예: 스크롤 동작) 지원 Behavior 기반, Material Design과 통합 ScrollView 세로 스크롤 가능한 단일 자식 컨테이너 자식은 하나만 허용 (보통 LinearLayout 등 포함) HorizontalScrollView 가로 스크롤 가능한 단일 자식 컨테이너 ScrollView의 수평 버전 RecyclerView 대량 데이터 리스트/그리드 효율적 표시 ViewHolder, LayoutManager, Adapter 사용 ViewPager / ViewPager2 좌우 스와이프로 페이지 전환 Fragment 또는 뷰 페이징, ViewPager2는 RecyclerView 기반 AppBarLayout Toolbar 등과 함께 스크롤 동작 통합 CoordinatorLayout과 함께 사용 DrawerLayout 슬라이딩 드로어(네비게이션 메뉴) 제공 좌/우 사이드 메뉴 구현 SwipeRefreshLayout 내부 뷰를 당겨서 새로고침 onRefresh() 콜백 제공 **UI 뷰 **(View) TextView 텍스트 표시 text, textSize, textColor 등 EditText 사용자 텍스트 입력 inputType, hint, imeOptions 등 Button 클릭 가능한 버튼 text, onClick ImageButton 이미지 기반 버튼 src로 이미지 지정 ImageView 이미지 표시 src, scaleType, adjustViewBounds CheckBox 체크 가능 토글 checked, onCheckedChanged RadioButton 라디오 버튼 (RadioButtonGroup 내 사용) 단일 선택 RadioGroup RadioButton 그룹 컨테이너 ViewGroup이지만 UI 위젯 성격 강함 Switch / ToggleButton ON/OFF 토글 스위치 checked, textOn/textOff ProgressBar 진행 상태 표시 indeterminate, progress, max SeekBar 사용자가 값을 드래그로 선택 progress, thumb, onProgressChanged RatingBar 별점 평가 UI numStars, rating, stepSize Spinner 드롭다운 선택 목록 Adapter, onItemSelected AutoCompleteTextView 입력 시 자동 완성 제안 Adapter, threshold WebView 웹 콘텐츠 표시 HTML/JavaScript 렌더링 SurfaceView / TextureView 고성능 그래픽/비디오 렌더링 별도 렌더링 스레드 사용 CardView 그림자와 모서리 둥근 카드 UI cardElevation, cardCornerRadius FloatingActionButton (FAB) Material Design 플로팅 액션 버튼 src, size, onClick Toolbar 액션바 대체 커스텀 타이틀바 메뉴, 타이틀, 네비게이션 아이콘 포함 가능 참고:\n모든 뷰는 android.view.View를 상속하며, 레이아웃은 android.view.ViewGroup (View의 하위 클래스)를 상속합니다. Material Components (예: MaterialButton, TextInputLayout) 등은 위 기본 위젯을 확장한 라이브러리 기반 뷰입니다. 커스텀 뷰를 직접 정의하여 사용할 수도 있습니다.","android-뷰-속성-분류-레이아웃-속성-vs-ui-뷰-속성#Android 뷰 속성 분류: 레이아웃 속성 vs UI 뷰 속성":"Android에서 뷰(View)는 두 가지 주요 속성 범주로 나뉩니다:\n레이아웃 (Layout Attributes): 부모 레이아웃(ViewGroup)이 자식 뷰의 배치를 제어하기 위해 사용하는 속성입니다.\n→ 예: android:layout_width, android:layout_height, app:layout_constraint... 등\n→ 이 속성들은 자식 뷰에서 선언되지만, 실제로는 부모 레이아웃이 해석합니다.\nUI 뷰 속성(View Attributes): 뷰 자체의 외형, 동작, 상태 등을 제어하는 속성입니다.\n→ 예: android:text, android:background, android:onClick 등\n→ 이 속성들은 해당 뷰 클래스 내부에서 직접 처리됩니다.\n아래 표는 대표적인 속성들을 분류한 것입니다.\n속성 이름 범주 설명 사용 가능한 뷰/레이아웃 추가 android:layout_width 레이아웃 속성 뷰의 가로 크기 지정 (match_parent, wrap_content, 고정값) 모든 ViewGroup의 자식 뷰 android:layout_height 레이아웃 속성 뷰의 세로 크기 지정 모든 ViewGroup의 자식 뷰 ex) android:layout_margin* (top, bottom, start, end 등) 레이아웃 속성 뷰 외부 여백 지정 모든 ViewGroup의 자식 뷰 android:layout_gravity 레이아웃 속성 부모 내에서 뷰의 정렬 방식 (LinearLayout, FrameLayout 등에서 사용) LinearLayout, FrameLayout 자식 android:layout_weight 레이아웃 속성 LinearLayout에서 공간 배분 비율 지정 LinearLayout 자식 app:layout_constraint* 레이아웃 속성 ConstraintLayout에서 제약 조건 정의 ConstraintLayout 자식 android:layout_alignParent* 레이아웃 속성 RelativeLayout에서 부모 기준 정렬 RelativeLayout 자식 android:layout_toRightOf, android:layout_below 등 레이아웃 속성 RelativeLayout에서 다른 뷰 기준 배치 RelativeLayout 자식 android:text UI 뷰 속성 TextView 계열 뷰에 표시할 텍스트 TextView, Button, EditText 등 android:background UI 뷰 속성 뷰의 배경 지정 (색상, drawable 등) 모든 View android:padding* (left, right, top, bottom, start, end) UI 뷰 속성 뷰 내부 여백 지정 모든 View android:onClick UI 뷰 속성 클릭 이벤트 핸들러 지정 모든 View android:visibility UI 뷰 속성 뷰의 표시 여부 (visible, invisible: 자리 차지, gone: 자리 사라짐) 모든 View 코드에서 사용 : View.VISIBLE, View.INVISIBLE android:enabled UI 뷰 속성 뷰의 활성화 상태 모든 View android:src UI 뷰 속성 ImageView에 표시할 이미지 리소스 ImageView android:hint UI 뷰 속성 EditText의 힌트 텍스트 EditText android:textColor UI 뷰 속성 텍스트 색상 TextView 계열 android:gravity UI 뷰 속성 뷰 내부 콘텐츠 정렬 방식 TextView, Button 등 콘텐츠 포함 뷰 android:id UI 뷰 속성 뷰의 고유 식별자 지정. 코드에서 참조하거나, 레이아웃 제약 조건에서 참조 가능 모든 View 및 ViewGroup(TextView,Button,LinearLayout,ConstraintLayout등 전부) 참고:\nlayout_* 접두사가 붙은 속성은 부모 레이아웃에 따라 다르게 해석되며, 해당 부모 레이아웃에서만 유효합니다. 일반 android:* 속성은 뷰 자체에 적용되며, 뷰 클래스가 지원해야 사용 가능합니다. app:* 네임스페이스는 커스텀 속성 또는 ConstraintLayout, Material Design 컴포넌트 등에서 사용됩니다. android:id=\"@+id/text\", findViewByld() width height 의 경우 3가지 방식 사용가능 수치 : px, dp match_parent : 부모의 크기 전체 wrap_content : 자신의 적절한 크기 프로퍼티(property) == 필드 + getter + setter 내부적으로는 여전히 private 필드가 있고, public getter/setter 메서드가 생성 즉 문법적 설탕","basic-data-type#basic data type":"var a: Boolean = true // 논리 (true, false) var b: Byte = 123 // 8 트 정수 (-128 ~ 127) var c: Short = 123 // 16비트 정수 (-32768 ~ 32767) var d: Int = 123 // 32비트 정수 (-2 31 ~ 2 31 -1) var e: Long = 123L // 64비트 정수 (-2 63 ~ 2 63 -1) var f: Float = 12.3F // 32비트 부동 소수점 var g: Double = 12.3 // 64비트 부동 소수점 var h: Char = 'A' // 문자 (글자 하나) var i: String= \"ABC\" // 문자열","componentactivity#\u003cstrong\u003e\u003ccode\u003eComponentActivity\u003c/code\u003e와 \u003ccode\u003esetContent\u003c/code\u003e의 역할\u003c/strong\u003e":"ComponentActivity: 단순히 Compose를 쓰기 위한 액티비티가 아닙니다. 이는 LifecycleOwner, ViewModelStoreOwner, SavedStateRegistryOwner 등 현대적인 Android 아키텍처 컴포넌트들의 생명주기와 상태를 관리하는 핵심적인 역할을 합니다. setContent: 이 함수가 바로 Compose World로 진입하는 관문입니다. 내부적으로 다음과 같은 중요한 작업을 수행합니다. 기존 액티비티의 contentView를 제거합니다. ComposeView라는 특수한 View를 생성하여 액티비티의 루트 뷰로 설정합니다. 이 ComposeView 내에서 새로운 Composition을 생성합니다. Composition은 UI 트리의 상태를 추적하고 관리하는 객체입니다. Recomposer를 액티비티의 생명주기에 연결(attach)합니다. Recomposer는 State 변화를 감지하고 Recomposition을 스케줄링하는 백그라운드 코루틴 기반의 스케줄러입니다. Lifecycle.State.CREATED에서 시작하여 Lifecycle.State.DESTROYED에서 중단됩니다.","composable#\u003cstrong\u003e\u003ccode\u003e@Composable\u003c/code\u003e 함수의 변환(Transformation)\u003c/strong\u003e":"@Composable fun Greeting(name: String, modifier: Modifier = Modifier) { ... } @Composable 어노테이션은 단순한 마커가 아닙니다. 이는 Compose 컴파일러 플러그인을 활성화하는 트리거입니다. 컴파일 시점에 컴파일러는 이 함수를 변환하여 두 개의 숨겨진 파라미터를 추가합니다. composer: Composer: 현재 Composition의 “지휘자” 역할을 합니다. composer.startNode(), composer.emit() 등의 호출을 통해 UI 트리를 Slot Table이라는 내부 데이터 구조에 기록합니다. changed: Int: 파라미터들의 변경 여부를 추적하는 비트마스크(bitmask)입니다. 이를 통해 Recomposition 시, 변경되지 않은 컴포저블의 실행을 건너뛰는 Smart Recomposition 최적화가 가능해집니다. name 파라미터가 안정적(stable)이고 이전과 같은 값이라면, Greeting 함수의 재실행을 건너뛸 수 있습니다.","constraintlayout#ConstraintLayout":"제약 레이아웃\n핵심 원리: 모든 뷰는 다른 뷰 또는 부모와의 ‘제약(Constraint)’ 관계로 위치가 결정된다.\nConstraintLayout은 RelativeLayout의 유연함과 LinearLayout의 비율 배치를 합친 것보다 더 강력한 레이아웃입니다. 뷰의 각 가장자리(상, 하, 좌, 우)에 있는 **앵커 포인트(Anchor Point)**를 다른 뷰의 앵커 포인트나 부모 레이아웃에 ‘연결’하여 위치를 정의합니다. 이를 통해 중첩 없이도 매우 복잡하고 반응형인 UI를 만들 수 있습니다.\n🔑 모든 뷰는 최소 하나 이상의 수평 제약과 수직 제약이 있어야 위치가 확정됩니다. 제약이 없으면 뷰는 (0,0) 좌표(좌측 상단)에 표시됩니다.","constraintlayout-예시#ConstraintLayout 예시":"","constraintlayout의-주요-제약-규칙#ConstraintLayout의 주요 제약 규칙":"속성들은 누구의(Source) 어느 쪽(Anchor)을 누구의(Target) 어느 쪽(Anchor)에 연결할지 정의합니다.\napp:layout_constraint[SourceAnchor]_to[TargetAnchor]Of=\"[TargetID]\" 형식입니다.\n상대 위치 지정 (다른 뷰 또는 부모 기준) “이 뷰의 왼쪽(Start)을 저 뷰의 오른쪽(End)에 연결하겠다” “이 뷰의 상단(Top)을 부모(parent)의 상단(Top)에 연결하겠다” 속성 설명 app:layout_constraintStart_toStartOf 왼쪽 가장자리를 대상의 왼쪽 가장자리에 맞춥니다. app:layout_constraintStart_toEndOf 왼쪽 가장자리를 대상의 오른쪽 가장자리에 맞춥니다. app:layout_constraintEnd_toStartOf 오른쪽 가장자리를 대상의 왼쪽 가장자리에 맞춥니다. app:layout_constraintEnd_toEndOf 오른쪽 가장자리를 대상의 오른쪽 가장자리에 맞춥니다. app:layout_constraintTop_toTopOf 위쪽 가장자리를 대상의 위쪽 가장자리에 맞춥니다. app:layout_constraintTop_toBottomOf 위쪽 가장자리를 대상의 아래쪽 가장자리에 맞춥니다. app:layout_constraintBottom_toTopOf 아래쪽 가장자리를 대상의 위쪽 가장자리에 맞춥니다. app:layout_constraintBottom_toBottomOf 아래쪽 가장자리를 대상의 아래쪽 가장자리에 맞춥니다. 💡 Start/End vs Left/Right: Start/End는 RTL(Right-to-Left) 언어 환경을 지원하므로 Left/Right보다 사용이 권장됩니다.\n크기 조정 (Dimension Constraints) 뷰의 너비나 높이를 제약 조건에 따라 동적으로 결정합니다. layout_width / layout_height 값 설명 [고정값] (예: 50dp) 뷰의 크기를 고정된 값으로 지정합니다. wrap_content 뷰 내부의 콘텐츠에 맞게 크기를 조절합니다. 0dp (match_constraint) 가장 중요. 제약 조건이 허용하는 한 최대한의 공간을 차지하도록 크기를 확장합니다. LinearLayout의 layout_weight와 유사한 역할을 합니다. 중앙 정렬과 편향 (Bias) 양쪽(수평 또는 수직)으로 제약이 걸렸을 때, 뷰를 해당 공간 내에서 정렬합니다. 속성 설명 app:layout_constraintHorizontal_bias 수평 제약 공간 내에서 뷰의 위치를 조절합니다. (0.0=왼쪽, 0.5=중앙, 1.0=오른쪽) app:layout_constraintVertical_bias 수직 제약 공간 내에서 뷰의 위치를 조절합니다. (0.0=위쪽, 0.5=중앙, 1.0=아래쪽)","empty-activity-초기-mainkt-설명#Empty Activity 초기 main.kt 설명":"package com.example.myapplication import android.os.Bundle import androidx.activity.ComponentActivity import androidx.activity.compose.setContent import androidx.activity.enableEdgeToEdge import androidx.compose.foundation.layout.fillMaxSize import androidx.compose.foundation.layout.padding import androidx.compose.material3.Scaffold import androidx.compose.material3.Text import androidx.compose.runtime.Composable import androidx.compose.ui.Modifier import androidx.compose.ui.tooling.preview.Preview import com.example.myapplication.ui.theme.MyApplicationTheme class MainActivity : ComponentActivity() { override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) enableEdgeToEdge() setContent { MyApplicationTheme { Scaffold(modifier = Modifier.fillMaxSize()) { innerPadding -\u003e Greeting( name = \"Android\", modifier = Modifier.padding(innerPadding) ) } } } } } @Composable fun Greeting(name: String, modifier: Modifier = Modifier) { Text( text = \"Hello $name!\", modifier = modifier ) } @Preview(showBackground = true) @Composable fun GreetingPreview() { MyApplicationTheme { Greeting(\"Android\") } } 네, 좋습니다. 전문가를 대상으로 Jetpack Compose의 내부 아키텍처와 디자인 철학에 초점을 맞춰 해당 코드를 심도 있게 분석해 보겠습니다. 이 코드는 단순해 보이지만, Compose의 핵심 원리들을 압축적으로 보여주는 훌륭한 예시입니다.","empty-views-activity-실행-흐름#Empty Views Activity 실행 흐름":"AndroidManifest.xml 내부에 가 있는 엑티비티를 열어야 한다 android:name=\".MainActivity\" 이므로 MainAvtivity 를 컴포넌트(액티비티)를 실행 --- MainAvtivity.ks setContentView(R.layout.activity_main) 에 따라 activity_main.xml 를 로드 --- 레이아웃이 하는 일 **화면 전체를 차지하는 `ConstraintLayout`** 을 만들고, 그 안에 **\"Hello World!\" 텍스트를 정중앙에 표시**하며, **코드에서 이 레이아웃을 `R.id.main`으로 참조**할 수 있도록 ID를 부여합니다.","enableedgetoedge#\u003cstrong\u003e\u003ccode\u003eenableEdgeToEdge()\u003c/code\u003e의 내부 동작\u003c/strong\u003e":"이 함수는 단순히 UI를 확장하는 것 이상입니다. 내부적으로 WindowCompat.setDecorFitsSystemWindows(window, false)를 호출합니다. 이는 Window Decor View가 시스템 인셋(insets)을 더 이상 고려하지 않도록 하여, 앱의 콘텐츠 영역이 상태 표시줄과 내비게이션 바 아래까지 확장되도록 합니다. 이후 ViewCompat.setOnApplyWindowInsetsListener를 통해 시스템 인셋 정보를 수신하고, 이를 Compose 레이아웃 시스템으로 전달할 준비를 합니다. Scaffold와 같은 컴포저블은 이 정보를 활용하여 콘텐츠에 적절한 패딩을 적용하게 됩니다.","framelayout#FrameLayout":"프레임 레이아웃\n핵심 원리: 뷰를 겹겹이 쌓는 가장 단순한 레이아웃\n마치 투명한 종이를 포개듯, 나중에 추가된 뷰가 가장 위에 올라오는 구조입니다. 자식 뷰들은 기본적으로 부모의 좌측 상단에 쌓이기 시작합니다.\n🔑 위치를 제어하려면 layout_gravity를, 화면에 보이거나 숨기려면 visibility 속성을 함께 사용합니다.","framelayout-예시#FrameLayout 예시":"","framelayout의-주요-속성#FrameLayout의 주요 속성":"LinearLayout이나 RelativeLayout처럼 복잡한 위치 지정 규칙은 없습니다. 대신 다음 두 속성이 핵심적인 역할을 합니다.\nandroid:layout_gravity: 부모 FrameLayout 안에서 자식 뷰를 정렬합니다.\n“나를 부모 프레임 안에서 어디에 둘까?” center, top, bottom, left, right 값을 조합하여 사용합니다. (예: top|right) android:visibility: 뷰를 화면에 보여줄지 여부를 결정합니다.\nvisible: 뷰를 화면에 보여줍니다. (기본값) invisible: 뷰를 화면에서 숨기지만, 차지하던 공간은 그대로 유지됩니다. gone: 뷰를 화면에서 숨기고, 차지하던 공간도 함께 사라집니다.","general-sizing-strategies#General Sizing Strategies":"종류 설명 대표 예시 **절대 크기 **(Absolute / Fixed Size) 고정된 수치로 크기를 지정 width: 200px,height: 100dp **상대 크기 **(Relative Size) 부모, 형제, 화면 등 다른 요소에 비례해 크기 결정 width: 50%,flex: 1,weight **콘텐츠 기반 크기 **(Content-based / Intrinsic Size) 내부 콘텐츠에 따라 자동 조정 wrap_content,width: fit-content,intrinsicContentSize **부모 기반 크기 **(Parent-filling Size) 부모 컨테이너를 꽉 채움 match_parent,width: 100%,flex: 1(특정 상황)","gravity-속성#Gravity 속성":"핵심 원리: gravity는 “내부 정렬”, layout_gravity는 “외부 정렬” 두 속성은 정렬 대상이 완전히 다릅니다.\nandroid:gravity: 뷰 자신 내부의 콘텐츠(예: 텍스트, 아이콘)를 정렬합니다. “내 안에 있는 글자를 어디에 둘까?” android:layout_gravity: 부모 레이아웃 안에서 뷰 자체를 정렬합니다. “부모 공간 안에서 나를 어디에 둘까?” 🔑 LinearLayout에서는 layout_gravity가 레이아웃의 주축(orientation)과 수직인 방향으로만 작동합니다. 주축 방향으로는 정렬할 수 없습니다.","gravity-속성-예시#Gravity 속성 예시":"","gravity와-layout_gravity의-핵심-차이#\u003ccode\u003egravity\u003c/code\u003e와 \u003ccode\u003elayout_gravity\u003c/code\u003e의 핵심 차이":"android:gravity: 뷰 내부 콘텐츠의 정렬 방식을 지정합니다.\n→ “내 안에 있는 텍스트나 자식 요소를 어디에 놓을까?”\nandroid:layout_gravity: 부모 레이아웃 내에서 해당 뷰 자체의 위치를 지정합니다.\n→ “부모 안에서 나를 어디에 놓을까?”\n🔑 두 속성은 완전히 다른 대상에 작용하므로 혼동하지 말 것.","gridlayout#GridLayout":"표 (격자) 레이아웃\n핵심 원리: 뷰를 보이지 않는 표(spreadsheet)의 셀에 순서대로 배치한다.\nGridLayout은 자식 뷰들을 행(row)과 열(column)으로 구성된 격자무늬에 배치하는 레이아웃입니다. LinearLayout처럼 한 방향으로 뷰를 추가하지만, 지정된 행/열의 개수를 채우면 자동으로 다음 줄로 넘어가는 특징이 있습니다.\n🔑 orientation으로 주된 흐름 방향을 정하고, columnCount 또는 rowCount로 한 줄에 몇 개의 뷰를 넣을지 결정합니다.","gridlayout-예시#GridLayout 예시":"","gridlayout의-기본-배치-규칙#GridLayout의 기본 배치 규칙":"GridLayout 자체에 설정하는 속성들입니다.\n속성 설명 android:orientation 뷰를 배치할 주된 방향을 결정합니다.\n- horizontal (기본값): 왼쪽 → 오른쪽으로 채우고, 꽉 차면 아래로 줄바꿈.\n- vertical: 위 → 아래로 채우고, 꽉 차면 오른쪽으로 줄바꿈. android:columnCount 가로 방향으로 배치할 열의 개수를 지정합니다. orientation=\"horizontal\"일 때 핵심 속성입니다. android:rowCount 세로 방향으로 배치할 행의 개수를 지정합니다. orientation=\"vertical\"일 때 핵심 속성입니다.","gui-기본-개념#GUI 기본 개념":"","inputtype-속성값#\u003ccode\u003einputType\u003c/code\u003e 속성값":"속성값 설명 none 입력 유형을 지정하지 않은 상태. 모든 문자 입력 가능하며 줄바꿈 가능 text 문자열 한 줄 입력 textCapCharacters 대문자 입력 모드 (모든 문자가 자동으로 대문자) textCapWords 각 단어의 첫 글자를 자동으로 대문자로 입력 textCapSentences 각 문장의 첫 글자를 자동으로 대문자로 입력 textMultiLine 여러 줄 입력 가능 textNoSuggestions 단어 입력 시 키보드의 추천 단어(자동 완성)를 표시하지 않음 textUri URL 입력 모드 (URL에 적합한 키보드 레이아웃 제공) textEmailAddress 이메일 주소 입력 모드 (이메일 형식에 맞는 키보드 제공) textPassword 비밀번호 입력 모드. 입력한 문자는 점(●)으로 표시되며, 키보드는 영문자, 숫자, 특수 문자만 표시 textVisiblePassword textPassword와 동일하나, 입력한 문자가 그대로 보임 (가시적 비밀번호) number 숫자만 입력 가능한 모드 numberSigned number와 동일하나, 부호(마이너스 -) 입력 가능 numberDecimal number와 동일하나, 소수점(.) 입력 가능 numberPassword 숫자 키만 사용 가능하며, 입력 내용은 점(●)으로 표시 (숫자 기반 비밀번호) phone 전화번호 입력 모드 (전화기 스타일 키패드 제공)","kotlin-keyword#​kotlin keyword":"","kotlin-기본-문법#kotlin 기본 문법":"","layout_weight-속성#layout_weight 속성":"핵심 원리: layout_weight는 “남은 공간\"에 작동한다\n먼저, layout_width 또는 layout_height가 고정값이나 wrap_content인 자식 뷰들의 크기를 계산합니다. 그 후, 부모 레이아웃의 전체 크기에서 이미 사용된 공간을 뺀 “남은 공간“을 계산합니다. 이 남은 공간을 layout_weight 비율에 따라 분배합니다. 🔑 따라서, “남은 공간이 존재해야 layout_weight가 효과를 발휘” 합니다.","layout_weight-예시#layout_weight 예시":"","linear-layout#Linear Layout":"직선 배치\nandroid:orientation=“vertical”: 자식 뷰를 세로 방향으로, 위에서 아래로 쌓습니다. (열, Column) android:orientation=“horizontal”: 자식 뷰를 가로 방향으로, 왼쪽에서 오른쪽으로 쌓습니다. (행, Row)","linearlayout-기준-동작-원리#LinearLayout 기준 동작 원리":"LinearLayout은 자식 뷰를 한 방향(수평 또는 수직)으로만 배치하므로,\nlayout_gravity는 그 반대 방향에서만 효과를 발휘합니다.\nLinearLayout 방향 layout_gravity가 유효한 축 예시 horizontal 수직 축 (top, center_vertical, bottom) 버튼을 위/가운데/아래로 정렬 vertical 수평 축 (left, center_horizontal, right) 버튼을 왼쪽/가운데/오른쪽으로 정렬 ⚠️ 같은 축(예: vertical에서 layout_gravity=\"top\")은 무시됩니다.\n→ LinearLayout은 수직 방향으로 자식을 쌓기 때문에, 수직 위치는 이미 결정됨.","linearlayout-방향-기준#LinearLayout 방향 기준":"LinearLayout 방향 layout_gravity가 유효한 축 설명 vertical (세로) 수평 축 (left, center_horizontal, right) ✅ 자식 뷰를 좌/우/가운데로 정렬 가능 vertical (세로) 수직 축 (top, bottom 등) ❌ 무시됨 (이미 위에서 아래로 쌓고 있음) horizontal (가로) 수직 축 (top, center_vertical, bottom) ✅ 자식 뷰를 상/하/가운데로 정렬 가능 horizontal (가로) 수평 축 (left, right 등) ❌ 무시됨 (이미 왼쪽에서 오른쪽으로 쌓고 있음)","modifier#\u003cstrong\u003e\u003ccode\u003eModifier\u003c/code\u003e의 아키텍처: Decorator Pattern\u003c/strong\u003e":"modifier = Modifier.padding(innerPadding) Modifier는 순서가 중요한, 불변(immutable) Modifier.Element들의 체인입니다. 이는 데코레이터 패턴과 매우 유사하게 동작합니다. Modifier.padding(innerPadding)은 PaddingModifier라는 Modifier.Element를 생성합니다. MainActivity에서 Modifier.fillMaxSize()는 SizeModifier를 생성합니다. Modifier 체인은 바깥쪽부터 안쪽으로 적용됩니다. Scaffold의 Modifier.fillMaxSize()가 먼저 적용되어 크기를 결정하고, 그 후 Greeting의 Modifier.padding(innerPadding)이 적용되어 내부 콘텐츠의 위치를 조정합니다. 각 Modifier.Element는 레이아웃의 특정 단계(measurement, layout, drawing, semantics, input)에 영향을 줄 수 있습니다. 이 아키텍처 덕분에 단일 책임 원칙을 지키면서도 UI 요소의 기능을 유연하게 확장할 수 있습니다.","myapplicationtheme#\u003cstrong\u003e\u003ccode\u003eMyApplicationTheme\u003c/code\u003e와 \u003ccode\u003eCompositionLocal\u003c/code\u003e\u003c/strong\u003e":"MyApplicationTheme은 단순한 스타일링 래퍼(wrapper)가 아닙니다. 이는 **CompositionLocal**이라는 강력한 메커니즘의 실제 사용 사례입니다. 내부적으로 CompositionLocalProvider를 사용하여 LocalColorScheme, LocalTextStyle 등의 CompositionLocal 객체에 특정 값(e.g., MaterialTheme.colorScheme)을 제공합니다. CompositionLocal은 하위 컴포저블 트리 전체에 데이터를 암시적으로(implicitly) 전파하는 방법입니다. 모든 컴포저블에 theme 객체를 명시적으로 전달하는 ‘Prop Drilling’을 피할 수 있게 해줍니다. 하위 컴포저블(예: Text, Button)은 MaterialTheme.colorScheme과 같은 코드를 통해 현재 스코프의 CompositionLocal 값을 읽어와 자신을 렌더링합니다.","preview#\u003cstrong\u003e\u003ccode\u003e@Preview\u003c/code\u003e와 Tooling의 분리\u003c/strong\u003e":"@Preview(showBackground = true) @Composable fun GreetingPreview() { ... } @Preview는 런타임이 아닌 Tool-time 어노테이션입니다. Android Studio는 이 어노테이션을 감지하고, 별도의 프로세스에서 LayoutLib을 사용하여 해당 컴포저블을 렌더링합니다. 이는 앱의 런타임 로직과 UI 렌더링 로직의 완벽한 분리를 보여줍니다. 이를 통해 개발자는 전체 앱을 빌드하고 실행할 필요 없이, 각 UI 컴포넌트를 독립적으로 빠르게 개발하고 테스트할 수 있습니다. 이는 컴포넌트 기반 아키텍처(Component-Based Architecture)를 장려하는 Compose의 핵심 철학입니다.","relativelayout#RelativeLayout":"상대 레이아웃\n핵심 원리: 모든 뷰는 ID를 통해 서로, 또는 부모와의 ‘관계’를 통해 위치가 결정된다.\nRelativeLayout은 자식 뷰들을 직선으로 쌓는 LinearLayout과 달리, 다른 뷰(Sibling)나 부모 레이아웃(Parent)을 기준으로 상대적인 위치를 지정하는 매우 유연한 레이아웃입니다. “A의 아래에 B를 놓아라”, “C를 부모의 오른쪽에 붙여라” 와 같은 규칙들의 조합으로 화면을 구성합니다.\n🔑 ID 지정이 필수적입니다. 관계를 설정하려면 기준이 될 뷰에 android:id가 반드시 있어야 합니다.","relativelayout-예시#RelativeLayout 예시":"","relativelayout의-주요-배치-규칙#RelativeLayout의 주요 배치 규칙":"RelativeLayout의 속성은 크게 3가지 그룹으로 나눌 수 있습니다.\n다른 뷰(Sibling)를 기준으로 위치 지정 “버튼 B를 버튼 A의 오른쪽에 두겠다” 속성 설명 android:layout_above=\"@+id/기준뷰\" 지정한 ID를 가진 뷰의 위쪽에 배치합니다. android:layout_below=\"@+id/기준뷰\" 지정한 ID를 가진 뷰의 아래쪽에 배치합니다. android:layout_toLeftOf=\"@+id/기준뷰\" 지정한 ID를 가진 뷰의 왼쪽에 배치합니다. android:layout_toRightOf=\"@+id/기준뷰\" 지정한 ID를 가진 뷰의 오른쪽에 배치합니다. 다른 뷰(Sibling)를 기준으로 정렬 “버튼 B의 상단 라인을 이미지 A의 상단 라인에 맞추겠다” 속성 설명 android:layout_alignTop=\"@+id/기준뷰\" 지정한 뷰와 위쪽 가장자리를 맞춥니다. android:layout_alignBottom=\"@+id/기준뷰\" 지정한 뷰와 아래쪽 가장자리를 맞춥니다. android:layout_alignLeft=\"@+id/기준뷰\" 지정한 뷰와 왼쪽 가장자리를 맞춥니다. android:layout_alignRight=\"@+id/기준뷰\" 지정한 뷰와 오른쪽 가장자리를 맞춥니다. android:layout_alignBaseline=\"@+id/기준뷰\" 텍스트 뷰의 경우, **텍스트 기준선(Baseline)**을 맞춥니다. 부모(Parent) 레이아웃을 기준으로 정렬 “이 버튼을 화면 정중앙에 놓겠다” 속성 설명 android:layout_alignParentTop=\"true\" 부모의 위쪽 가장자리에 맞춥니다. android:layout_alignParentBottom=\"true\" 부모의 아래쪽 가장자리에 맞춥니다. android:layout_alignParentLeft=\"true\" 부모의 왼쪽 가장자리에 맞춥니다. android:layout_alignParentRight=\"true\" 부모의 오른쪽 가장자리에 맞춥니다. android:layout_centerHorizontal=\"true\" 부모의 수평 중앙에 배치합니다. android:layout_centerVertical=\"true\" 부모의 수직 중앙에 배치합니다. android:layout_centerInParent=\"true\" 부모의 수평 및 수직 중앙에 배치합니다.","resource-folder-리소스-폴더-와-rjava#resource folder 리소스 폴더 와 R.java":"drawable： 이미지 리소스 layout： UI 구성에필요한 XML 리소스 mipmap： 앱 아이콘 이미지 values： 문자열 등의 값으로 이용되는 리소스 R.java 는 모든 리소스를 컴포넌트 코드에서 참조할 수 있게 해주는 브릿지 역할\nR.java 의 경우 AGP 3.6 부터 제거 되었고 현재 R.txt 와 R.jar 형태로만 존재한다\n$ find app/build -name \"R.*\" app/build/intermediates/compile_and_runtime_not_namespaced_r_class_jar/debug/processDebugResources/R.jar app/build/intermediates/runtime_symbol_list/debug/processDebugResources/R.txt $ jar -tf app/build/intermediates/compile_and_runtime_not_namespaced_r_class_jar/debug/processDebugResources/R.jar ## 특정 리소스 파일 검색 $ grep -i \"person1\\|send\\|test\" app/build/intermediates/runtime_symbol_list/debug/processDebugResources/R.txt int drawable abc_vector_test 0x7f070077 int drawable person1 0x7f0700e4 int drawable send 0x7f0700e5 int drawable test_level_drawable 0x7f0700e6 int id immediateStop 0x7f0800dc int layout ime_base_split_test_activity 0x7f0b002d int layout ime_secondary_split_test_activity 0x7f0b002e","sam-single-abstract-method-변환-심층-분석#SAM (Single Abstract Method) 변환 심층 분석":"binding.button.setOnClickListener { ... }와 같은 람다식 코드가 어떻게 동작하는지 이해하는 것은 매우 중요합니다.","scaffold#\u003cstrong\u003e\u003ccode\u003eScaffold\u003c/code\u003e와 Slot-based API\u003c/strong\u003e":"Scaffold는 머티리얼 디자인의 구조를 구현한 고수준 컴포저블이며, Slot-based API의 대표적인 예시입니다. topBar, bottomBar, floatingActionButton, content 등 특정 목적을 가진 람다 파라미터를 “슬롯\"으로 제공합니다. 가장 중요한 부분은 content 람다에 전달되는 innerPadding: PaddingValues입니다. 이는 부모 컴포저블(Scaffold)이 자식(Greeting)의 레이아웃에 필요한 정보를 제공하는 Compose의 협력적인 레이아웃 모델을 보여줍니다. Scaffold는 topBar 등의 슬롯에 채워진 컴포저블들의 크기를 측정하고, enableEdgeToEdge로 인해 발생한 시스템 인셋을 고려하여, 메인 콘텐츠가 그려져야 할 안전한 영역을 계산합니다. 이 계산 결과가 바로 innerPadding이며, 자식은 이 값을 Modifier.padding에 적용하여 UI가 가려지는 것을 방지합니다.","text#\u003cstrong\u003e\u003ccode\u003eText\u003c/code\u003e 컴포저블과 UI 노드\u003c/strong\u003e":"Text와 같은 기본 컴포저블은 UI 트리의 “잎(leaf)“에 해당합니다. 이 함수가 실행되면, 내부적으로 composer.emitNode를 호출하여 Slot Table에 LayoutNode를 생성합니다. LayoutNode는 Compose UI 트리의 기본 단위이며, 측정(measure), 배치(layout), 그리기(draw) 로직을 포함하고 있습니다. text, color 등의 파라미터는 이 LayoutNode의 속성으로 설정됩니다.","각-역할의-구현-방식-플랫폼별-비교#\u003cstrong\u003e각 역할의 구현 방식: 플랫폼별 비교\u003c/strong\u003e":"역할 **Web **(HTML/CSS/JS) **Android **(Jetpack Compose 제외) **iOS **(SwiftUI) Flutter **데스크톱 **(예: Qt) 구조\n(무엇을 보여줄까?) HTML\n→ 태그 기반 계층 구조 XML 레이아웃 파일\n→ , 등 Swift 코드\n→ 선언적 뷰 DSL (VStack, Text, Button) Dart 위젯 트리\n→ Column, Text, ElevatedButton **QML **(Qt Modeling Language)\n또는 C++ 위젯 트리 스타일\n(어떻게 보일까?) CSS\n→ 완전 분리된 스타일 시트\n→ 클래스, 선택자, 반응형 디자인 XML 속성 + 스타일 리소스\n→ android:padding, style=\"@style/MyButton\"\n→ dimens.xml, colors.xml 메서드 체인\n→ .frame(width: 100), .foregroundColor(.blue)\n→ ViewModifier로 재사용 위젯 내장 속성\n→ TextStyle, BoxDecoration, SizedBox\n→ ThemeData로 전역 스타일 통일 **QSS **(Qt Style Sheets)\n또는 속성 바인딩 동작\n(어떻게 반응할까?) **JavaScript **(또는 TypeScript)\n→ DOM 이벤트, 상태 관리 (React/Vue 등) Kotlin / Java\n→ setOnClickListener, ViewModel, LiveData Swift\n→ @State, @Binding, Button(action: { ... }) Dart\n→ 상태 관리 (setState, Provider, Riverpod) C++ / JavaScript\n→ 슬롯/시그널, 이벤트 핸들러 💡 공통점:\n모두 트리 구조(Tree)로 UI를 표현 (DOM, View Hierarchy, Widget Tree 등) 선언적(Declarative) 방식이 주류 (특히 최신 프레임워크) 상태 → UI의 단방향 흐름을 지향","결론#결론":"모든 현대 GUI 시스템은 “구조–스타일–동작”이라는 3층 구조를 따르며,\n플랫폼에 따라 표현 방식은 다르지만 동일한 설계 철학을 공유합니다.\n이 틀을 이해하면 어떤 UI 프레임워크든 빠르게 학습하고 전이할 수 있습니다.\n이 구조는 단순한 기술 분류를 넘어, 효율적인 소프트웨어 설계 원칙 그 자체입니다. 현대 GUI**(Graphical User Interface)** 개발은 선언적(declarative) 접근 방식을 많이 사용하며, 이는 일반적으로 다음과 같은 3가지 핵심 역할 분담으로 구성됩니다:","결론-1#\u003cstrong\u003e결론\u003c/strong\u003e":"setContent를 통해 View 시스템에서 Compose 런타임으로 제어권을 이전하고, CompositionLocal로 테마 같은 전역적 데이터를 효율적으로 전파하며, Scaffold와 같은 고수준 컴포저블의 Slot API를 통해 구조를 정의하고, 컴파일러 플러그인에 의해 변환된 @Composable 함수들이 Slot Table에 UI 트리를 선언적으로 기술하며, Modifier 체인을 통해 UI 노드의 속성을 계층적으로 꾸미는, 매우 정교하고 잘 설계된 아키텍처를 보여주고 있습니다. 이는 기존의 명령형(imperative) UI 툴킷과 근본적으로 다른, 선언형(declarative) 패러다임이 어떻게 구현되었는지를 명확히 보여주는 교과서적인 예제입니다.","경우-1-부모가-match_parent--layout_weight#경우 1: 부모가 \u003ccode\u003ematch_parent\u003c/code\u003e → \u003cstrong\u003e\u003ccode\u003elayout_weight\u003c/code\u003e 작동\u003c/strong\u003e":"","경우-2-부모가-wrap_content--layout_weight#경우 2: 부모가 \u003ccode\u003ewrap_content\u003c/code\u003e → \u003cstrong\u003e\u003ccode\u003elayout_weight\u003c/code\u003e 무시됨\u003c/strong\u003e":"","관련-폴더-및-파일#관련 폴더 및 파일:":"res/layout/\n→ 액티비티의 UI를 정의하는 XML 레이아웃 파일이 위치합니다.\n예: activity_main.xml, login_screen.xml\n→ setContentView(R.layout.activity_main)에서 참조됨. src/ (Kotlin/Java 소스 코드)\n→ 각 액티비티는 AppCompatActivity를 상속하는 클래스로 구현됩니다.\n예: MainActivity.kt AndroidManifest.xml\n→ 모든 액티비티는 반드시 여기에 태그로 등록되어야 합니다.\n→ LAUNCHER 액티비티는 로 지정됩니다. res/values/strings.xml, colors.xml, dimens.xml 등\n→ 액티비티 UI에서 사용하는 텍스트, 색상, 크기 등의 값 정의. 액티비티는 res/layout/과 가장 밀접하며, AndroidManifest.xml에 등록되고, src/ 내 클래스로 구현됩니다.","관련-폴더-및-파일-1#관련 폴더 및 파일:":"src/ (Kotlin/Java 소스 코드)\n→ Service 또는 IntentService, JobIntentService 등을 상속하는 클래스로 구현.\n예: MusicPlaybackService.kt AndroidManifest.xml\n→ 로 등록 필수.\n→ 권한이 필요한 경우 과 함께 사용. res/ 폴더와의 관계:\n→ 서비스는 UI가 없으므로 layout이나 drawable 등과 직접적 연관 없음.\n→ 단, 알림(Notification)을 표시할 경우 res/drawable/의 아이콘을 사용할 수 있음. 서비스는 주로 src/와 AndroidManifest.xml에 의존, 리소스 폴더와는 간접적 연관만 있음.","관련-폴더-및-파일-2#관련 폴더 및 파일:":"src/\n→ ContentProvider를 상속하는 클래스로 구현.\n예: ContactProvider.kt AndroidManifest.xml\n→ 태그로 등록 필수.\n→ android:authorities 속성으로 고유 URI 지정 (예: com.example.app.provider). 데이터베이스 관련:\n→ 일반적으로 Room, SQLiteOpenHelper와 함께 사용되며, 이는 src/ 내부에 구현됨. res/ 폴더와의 관계:\n→ 콘텐츠 프로바이더 자체는 리소스 폴더와 거의 무관.\n→ 단, 공유되는 데이터가 이미지일 경우 res/drawable/ 또는 외부 저장소 경로를 반환할 수 있음. 콘텐츠 프로바이더는 src/와 AndroidManifest.xml 중심, 리소스 폴더와는 거의 독립적.","관련-폴더-및-파일-3#관련 폴더 및 파일:":"src/\n→ BroadcastReceiver를 상속하는 클래스로 구현.\n예: BootReceiver.kt AndroidManifest.xml\n→ 정적 등록 시 태그 사용.\n예: 기기 부팅 시 실행되려면 에 android.intent.action.BOOT_COMPLETED 지정. 동적 등록:\n→ 액티비티나 서비스 내에서 registerReceiver()로 코드 상에서 등록 가능 → 이 경우 Manifest 등록 불필요. res/ 폴더와의 관계:\n→ 리시버는 UI 없이 이벤트만 처리하므로 리소스 폴더와 거의 무관.\n→ 단, 이벤트 처리 결과로 알림을 띄울 경우 res/drawable/ 아이콘 사용 가능. 브로드캐스트 리시버는 src/와 AndroidManifest.xml에 의존, 리소스 폴더와는 거의 관련 없음.","관심사의-분리-separation-of-concerns#관심사의 분리 **(Separation of Concerns)":"모든 GUI 프레임워크는 다음 세 가지 책임을 명확히 분리하려는 목표를 공유합니다:\n역할 책임 핵심 질문 **1. 구조 **(Structure) 화면에 무엇이 있는가? “어떤 컴포넌트들이 있고, 어떻게 배치되어 있는가?” **2. 스타일 **(Presentation) 화면이 어떻게 보이는가? “색상, 크기, 여백, 폰트, 정렬은 어떻게 되는가?” **3. 동작 **(Behavior) 화면이 어떻게 반응하는가? “버튼 클릭 시 무엇을 하며, 데이터는 어떻게 바뀌는가?”","뒤로-가기-버튼-처리-onbackpressed-vs-onbackpressedcallback#뒤로 가기 버튼 처리: \u003ccode\u003eonBackPressed\u003c/code\u003e vs. \u003ccode\u003eOnBackPressedCallback\u003c/code\u003e":"onBackPressed()가 Deprecated된 이유는 현대 안드로이드 아키텍처, 특히 Fragment와의 통합이 어렵기 때문입니다. Activity에만 존재하는 이 메서드는 여러 Fragment가 화면을 구성할 때 “현재 활성화된 Fragment가 뒤로 가기 이벤트를 먼저 처리해야 한다\"는 로직을 구현하기 복잡하게 만듭니다.\nOnBackPressedCallback의 장점:\n생명주기 인식(Lifecycle-Aware): 콜백을 Activity나 Fragment의 생명주기에 바인딩할 수 있어, 화면이 보일 때만 콜백이 활성화되도록 쉽게 관리할 수 있습니다. 모듈성 및 유연성: 각 Fragment나 컴포넌트가 자신만의 뒤로 가기 로직을 독립적으로 등록하고 관리할 수 있습니다. 동적 활성화/비활성화: callback.isEnabled = false 와 같이 콜백을 실시간으로 켜고 끌 수 있어, 특정 조건(예: 양식 작성 중)에서만 뒤로 가기 동작을 막는 것이 매우 편리합니다. // Activity의 onCreate 등에서 콜백 등록 // '뒤로 가기'를 두 번 눌러야 종료되는 기능 구현 예시 private var backPressedTime: Long = 0 val callback = object : OnBackPressedCallback(true) { // true: 콜백을 초기에 활성화 override fun handleOnBackPressed() { // 2초 이내에 다시 누르면 액티비티 종료 if (System.currentTimeMillis() - backPressedTime \u003c 2000) { finish() } else { // 처음 눌렀거나, 누른 지 2초가 지났으면 토스트 메시지 표시 Toast.makeText(this@MainActivity, \"한 번 더 누르면 종료됩니다.\", Toast.LENGTH_SHORT).show() backPressedTime = System.currentTimeMillis() } } } this.onBackPressedDispatcher.addCallback(this, callback)","레이아웃-구성-방법#레이아웃 구성 방법":"레이아웃 xml 을 통해 선언적으로 구성 엑티비티 코드로 작성하는 방법 코드로 구성하는 방법\nclass MainActivity : AppCompatActivity() { override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) // 이름 문자열을 출력할 TextView 생성 val name = TextView(this).apply { typeface = Typeface.DEFAULT_BOLD text = \"Lake Louise\" } // 이미지를 출력할 ImageView 생성 val image = ImageView(this).apply { setImageDrawable(ContextCompat.getDrawable(this, R.drawable.lake_l)) } // 주소 문자열을 출력할 TextView 생성 val address = TextView(this).apply { typeface = Typeface.DEFAULT_BOLD text = \"Lake Louise, AB, 캐나다\" } // 세로 방향 LinearLayout 생성 및 설정 val layout = LinearLayout(this).apply { orientation = LinearLayout.VERTICAL gravity = Gravity.CENTER // 뷰들을 LinearLayout에 추가 addView(name, LinearLayout.LayoutParams.WRAP_CONTENT, LinearLayout.LayoutParams.WRAP_CONTENT) addView(image, LinearLayout.LayoutParams.WRAP_CONTENT, LinearLayout.LayoutParams.WRAP_CONTENT) addView(address, LinearLayout.LayoutParams.WRAP_CONTENT, LinearLayout.LayoutParams.WRAP_CONTENT) } // 최종 레이아웃을 화면에 설정 setContentView(layout) } }","분석-개요#\u003cstrong\u003e분석 개요\u003c/strong\u003e":"이 코드는 크게 세 가지 핵심 레이어를 보여줍니다.\nFramework Integration Layer (MainActivity): 전통적인 Android View 시스템과 새로운 Compose 런타임 간의 브릿지 역할. Composition \u0026 State Layer (MyApplicationTheme, Scaffold): UI 트리를 구성하고, 암시적 데이터를 전파하며, 상태에 따라 UI를 재구성(Recomposition)하는 메커니즘. UI Declaration \u0026 Modification Layer (Greeting, Text, Modifier): 실제 UI 노드를 선언하고, 이들의 속성을 데코레이터 패턴으로 확장하는 방식. 이제 각 부분을 내부 구조 중심으로 상세히 살펴보겠습니다.","뷰-바인딩--findviewbyld-대신-뷰를-찾는-방법#뷰 바인딩 : findViewByld() 대신 뷰를 찾는 방법":"build.gradle 파일을 열고 android 영역에 viewBinding.isEnabled = true를 설정\n레이아웃 XML 파일에 등록된 뷰 객체를 포함하는 클래스가 자동으로 만들어진다\n자동으로 만들어 지는 클래스의 이름은 레이아웃 XML 파일명을 따릅니다. 첫 글자를 대문자 로 하고 밑줄(_)은 빼고 뒤에 오는 단어를 대문자로 만든 후 ‘Binding’을 추가합니다. 예를 들 어 다음과 같습니다. • activity_main.xml -\u003e ActivityMainBinding • item_main.xml -\u003e ItemMainBinding\nclass MainActivity : AppCompatActivity() { override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) // 바인딩 객체 획득 val binding = ActivityMainBinding.inflate(layoutInflater) // 액티비티 화면 출력 setContentView(binding.root) // 뷰 객체 이용 (visibleBtn 클릭 시 targetView 보이기) binding.visibleBtn.setOnClickListener { binding.targetView.visibility = View.VISIBLE } // 뷰 객체 이용 (invisibleBtn 클릭 시 targetView 숨기기) binding.invisibleBtn.setOnClickListener { binding.targetView.visibility = View.INVISIBLE } } } 뷰 바인딩 의도적 비 활성화 tools:viewBindingIgnore=“true” 를 레이아웃 안에 넣는다","뷰-이벤트-처리#뷰 이벤트 처리":"안드로이드에서 사용자 상호작용의 가장 기본이 되는 단위는 뷰(View)에서 발생하는 이벤트입니다. 이벤트 처리는 명확하게 역할이 나뉜 세 가지 구성 요소의 협력을 통해 이루어집니다. 이 구조를 이해하면 어떤 뷰의 이벤트라도 일관된 방식으로 처리할 수 있습니다.","뷰-이벤트-처리의-기본-구조#뷰 이벤트 처리의 기본 구조":"뷰 이벤트 처리는 ‘이벤트가 발생한 객체’와 ‘이벤트를 처리할 로직’을 ‘연결’하는 과정입니다.\n이벤트 소스 (Event Source): 이벤트가 발생한 뷰 객체 그 자체입니다. (예: 사용자가 터치한 버튼, 체크 상태를 바꾼 체크박스) 이벤트 핸들러 (Event Handler): 이벤트가 발생했을 때 실제로 실행될 코드를 담고 있는 객체입니다. 특정 인터페이스를 구현하여 만들어집니다. 리스너 (Listener): 이벤트 소스에 이벤트 핸들러를 등록(연결)하는 함수입니다. 보통 set...Listener() 형태의 이름을 가집니다. 그림 8-6 뷰 이벤트 처리 구조\n즉, 이벤트 소스에 리스너 함수를 사용하여 이벤트 핸들러를 등록해두면, 해당 이벤트가 발생했을 때 시스템이 등록된 핸들러의 로직을 실행시켜주는 구조입니다.\n아래 코드는 체크박스의 체크 상태가 변경될 때의 이벤트를 처리하는 예시입니다.\n이벤트 소스: binding.checkbox 객체 리스너: setOnCheckedChangeListener() 함수 이벤트 핸들러: CompoundButton.OnCheckedChangeListener 인터페이스를 구현한 object 익명 객체 // 체크박스 이벤트 처리 // 이벤트 소스 리스너(이벤트 핸들러 등록) 이벤트 핸들러 binding.checkbox.setOnCheckedChangeListener(object : CompoundButton.OnCheckedChangeListener { override fun onCheckedChanged(buttonView: CompoundButton?, isChecked: Boolean) { Log.d(\"kkang\", \"체크박스 클릭, 현재 상태: $isChecked\") } }) 그림 8-7 CheckEvent 구조\n대부분의 이벤트 핸들러는 On...Listener 형태의 인터페이스를 구현하여 만듭니다. 안드로이드 프레임워크는 OnClickListener, OnLongClickListener, OnItemClickListener 등 다양한 상황에 맞는 인터페이스를 제공합니다.","뷰-클래스#뷰 클래스":"","사용자-이벤트-처리#사용자 이벤트 처리":"터치 이벤트 터치 이벤트 종류 터치 이벤트 발생 좌표 키 이벤트","사용자-이벤트-처리-1#사용자 이벤트 처리":"안드로이드 앱은 사용자의 다양한 상호작용(터치, 키 입력 등)에 반응해야 합니다. 이는 이벤트 기반 프로그래밍(Event-driven Programming) 모델을 통해 이루어집니다. 사용자가 행동을 취하면 시스템이 ‘이벤트’ 객체를 생성하여 앱에 전달하고, 앱은 이 이벤트를 처리할 ‘리스너(Listener)’ 또는 ‘콜백(Callback)’ 함수를 통해 특정 로직을 수행합니다.","세로-방향-linearlayout-orientationvertical-기준#세로 방향 LinearLayout (\u003ccode\u003eorientation=\u0026#34;vertical\u0026#34;\u003c/code\u003e) 기준":"상위 레이아웃의 height 자식 뷰의 layout_height layout_weight 효과 match_parent 0dp ✅ 효과 있음 → 남은 공간이 있음 wrap_content 0dp ❌ 거의 효과 없음 → 남은 공간 ≈ 0 match_parent wrap_content + weight ⚠️ 비추천 → 예측 불가능한 동작 wrap_content wrap_content + weight ❌ 의미 없음 → 공간이 없음","안드로이드-리소스-식별자-종류-및-사용-사례-종합표#안드로이드 리소스 식별자 종류 및 사용 사례 종합표":"리소스 유형\n(Resource Type) 정의 위치\n(Resource Directory / File) 주요 목적 XML에서 사용 예 코드에서 참조 방식 실제 사용 사례 id 레이아웃 XML 내부 (android:id) 뷰를 코드에서 식별 android:id=\"@+id/submit_button\" R.id.submit_button findViewById(R.id.submit_button)로 버튼 제어 string res/values/strings.xml 텍스트 내용 관리, 다국어 지원 android:text=\"@string/app_name\" R.string.app_name getString(R.string.welcome)로 메시지 표시 color res/values/colors.xml 색상 값 정의 및 재사용 android:textColor=\"@color/primary\" R.color.primary ContextCompat.getColor(context, R.color.error) dimen res/values/dimens.xml 여백, 크기, 글자 크기 정의 android:padding=\"@dimen/activity_margin\" R.dimen.activity_margin resources.getDimension(R.dimen.text_size) style res/values/styles.xml 뷰 또는 앱 전체의 디자인 규칙 정의 style=\"@style/CustomButton\" R.style.CustomButton 액티비티 테마: android:theme=\"@style/Theme.MyApp\" layout res/layout/ 폴더 내 XML 파일 화면 UI 구조 정의 — (파일 자체가 리소스) R.layout.activity_main setContentView(R.layout.activity_main) drawable res/drawable/ 폴더 이미지, 아이콘, 벡터 그래픽 android:src=\"@drawable/ic_home\" R.drawable.ic_home ImageView.setImageResource(R.drawable.logo) mipmap res/mipmap-*/ 폴더 앱 아이콘 전용 이미지 android:icon=\"@mipmap/ic_launcher\" R.mipmap.ic_launcher AndroidManifest.xml에서 앱 아이콘 지정 array res/values/arrays.xml 문자열/정수 배열 정의 — R.array.countries resources.getStringArray(R.array.countries) bool res/values/bools.xml 논리값 상수 정의 android:enabled=\"@bool/is_pro\" R.bool.is_pro resources.getBoolean(R.bool.is_tablet) integer res/values/integers.xml 정수 상수 정의 android:max=\"@integer/max_count\" R.integer.max_count resources.getInteger(R.integer.retry_limit) anim res/anim/ 폴더 뷰 애니메이션 정의 — R.anim.fade_in overridePendingTransition(R.anim.slide_in, R.anim.slide_out) animator res/animator/ 폴더 속성 애니메이션 (Property Animation) — R.animator.rotate AnimatorInflater.loadAnimator(context, R.animator.bounce) menu res/menu/ 폴더 액션바, 컨텍스트 메뉴 정의 — R.menu.main_menu menuInflater.inflate(R.menu.main_menu, menu) xml res/xml/ 폴더 설정, 검색, 키보드 등 구조화된 데이터 — R.xml.preferences PreferenceFragmentCompat에서 설정 로드 font res/font/ 폴더 커스텀 글꼴 정의 android:fontFamily=\"@font/nanum_gothic\" R.font.nanum_gothic ResourcesCompat.getFont(context, R.font.my_font) raw res/raw/ 폴더 원시 데이터 파일 (오디오, JSON 등) — R.raw.sound_effect MediaPlayer.create(context, R.raw.bgm) plurals res/values/strings.xml 복수형 문자열 (수량에 따라 문장 변경) — R.plurals.item_count resources.getQuantityString(R.plurals.item_count, 3, 3)","안드로이드-컴포넌트란#안드로이드 컴포넌트란":"","앱에서-처리-가능한-시스템-버튼-심화#앱에서 처리 가능한 시스템 버튼 (심화)":"앱이 전원, 홈 버튼 등을 가로챌 수 없는 이유는 사용자 경험의 일관성과 보안 때문입니다. 이 버튼들은 어떤 앱을 사용하든 항상 동일하게 동작해야 하는 시스템의 핵심 제어 기능입니다. 만약 악의적인 앱이 홈 버튼을 막는다면 사용자는 앱을 빠져나갈 수 없게 됩니다.\n구분 버튼 종류 설명 ✅ 처리 가능 뒤로 가기, 볼륨 조절 앱의 컨텍스트 내에서 사용자 경험을 향상시키기 위해 커스터마이징이 허용됩니다. (예: 게임 중 볼륨 키를 다른 기능으로 매핑) ❌ 처리 불가 전원, 홈, 오버뷰 시스템의 최상위 제어권을 가지며, 앱이 개입할 수 없도록 OS 레벨에서 차단됩니다.","예시-1-기본적인-그리드-배치-계산기-키패드#예시 1: 기본적인 그리드 배치 (계산기 키패드)":"","예시-1-기본적인-뷰-겹치기와-정렬#예시 1: 기본적인 뷰 겹치기와 정렬":"","예시-1-기본적인-상대-위치-지정#예시 1: 기본적인 상대 위치 지정":"","예시-1-기본적인-제약-관계-설정-프로필-ui#예시 1: 기본적인 제약 관계 설정 (프로필 UI)":"제공된 텍스트의 카카오톡 UI 예시를 XML 코드로 분석한 것입니다.","예시-1-수직-linearlayout에서-layout_gravity-사용#예시 1: 수직 LinearLayout에서 \u003ccode\u003elayout_gravity\u003c/code\u003e 사용":"","예시-2-0dpmatch_constraint와-bias를-이용한-동적-크기-및-중앙-정렬#예시 2: \u003ccode\u003e0dp(match_constraint)\u003c/code\u003e와 Bias를 이용한 동적 크기 및 중앙 정렬":"","예시-2-visibility를-이용한-뷰-전환-로딩-화면#예시 2: \u003ccode\u003evisibility\u003c/code\u003e를 이용한 뷰 전환 (로딩 화면)":"","예시-2-부모-기준-정렬-화면-우측-하단에-버튼-배치#예시 2: 부모 기준 정렬 (화면 우측 하단에 버튼 배치)":"","예시-2-셀-병합columnspan과-채우기gravityfill#예시 2: 셀 병합(\u003ccode\u003ecolumnSpan\u003c/code\u003e)과 채우기(\u003ccode\u003egravity=\u0026#34;fill\u0026#34;\u003c/code\u003e)":"","예시-2-수평-linearlayout에서-layout_gravity-사용#예시 2: 수평 LinearLayout에서 \u003ccode\u003elayout_gravity\u003c/code\u003e 사용":"","예시-3-gravity-vs-layout_gravity-혼합#예시 3: \u003ccode\u003egravity\u003c/code\u003e vs \u003ccode\u003elayout_gravity\u003c/code\u003e 혼합":"","예시-3-복합적인-실제-레이아웃-프로필-ui#예시 3: 복합적인 실제 레이아웃 (프로필 UI)":"","예시-3-특정-위치-지정-row-column#예시 3: 특정 위치 지정 (\u003ccode\u003erow\u003c/code\u003e, \u003ccode\u003ecolumn\u003c/code\u003e)":"","예시-3-혼합된-height-설정--weight-세로-linearlayout#예시 3: \u003cstrong\u003e혼합된 height 설정 + weight (세로 LinearLayout)\u003c/strong\u003e":"","예시-4-부모가#예시 4: \u003cstrong\u003e부모가 \u003ccode\u003ewrap_content\u003c/code\u003e인 중첩 LinearLayout → weight 무시됨\u003c/strong\u003e":"","왜-소프트-키보드는-키-이벤트를-발생시키지-않는가#왜 소프트 키보드는 키 이벤트를 발생시키지 않는가?":"소프트 키보드는 그 자체가 하나의 독립적인 애플리케이션(IME: Input Method Editor)입니다. 사용자가 키를 누르면 IME는 ‘키 입력’ 이벤트를 시스템에 보내는 것이 아니라, ‘글자’ 자체를 현재 포커스된 EditText와 같은 뷰에 직접 전달합니다. 따라서 텍스트 변경을 감지하려면 EditText의 addTextChangedListener와 같은 고수준의 리스너를 사용해야 합니다.","요약-gui-개발의-거시적-틀#\u003cstrong\u003e요약: GUI 개발의 거시적 틀\u003c/strong\u003e":"┌───────────────────────┐ │ 사용자 입력 │ │ (터치, 클릭, 키보드) │ └──────────┬────────────┘ ▼ ┌───────────────────────┐ │ 동작 **(Behavior) │ ← 프로그래밍 언어 │ (상태 변경, 로직 처리) │ └──────────┬────────────┘ ▼ ┌───────────────────────┐ │ 구조 **(Structure) │ ← 마크업 또는 선언적 코드 │ (어떤 컴포넌트가 있는가)│ └──────────┬────────────┘ ▼ ┌───────────────────────┐ │ 스타일 **(Style) │ ← 시각적 속성 │ (크기, 색상, 여백 등) │ └──────────┬────────────┘ ▼ ┌───────────────────────┐ │ 렌더링 엔진 │ │ (브라우저, OS, 프레임워크)│ └───────────────────────┘","이벤트-소비consumption와-전파propagation#이벤트 소비(Consumption)와 전파(Propagation)":"onTouchEvent() 함수의 반환값은 이벤트 처리 흐름에서 매우 중요합니다.\nreturn true: “이 이벤트를 내가 처리했으니(소비했으니), 더 이상 다른 곳으로 전파하지 마세요.” ACTION_DOWN 이벤트에 대해 true를 반환하면, 이후의 ACTION_MOVE, ACTION_UP 이벤트가 모두 이 뷰로 전달됩니다. 드래그와 같은 연속적인 동작을 구현하려면 필수입니다. return false (또는 super.onTouchEvent(event)): “나는 이 이벤트를 처리하지 않았으니, 상위 뷰나 기본 동작이 처리하도록 전달하세요.” ACTION_DOWN에 대해 false를 반환하면, 이후의 ACTION_MOVE, ACTION_UP 이벤트는 이 뷰로 전달되지 않습니다. // CustomView.kt override fun onTouchEvent(event: MotionEvent?): Boolean { when (event?.action) { MotionEvent.ACTION_DOWN -\u003e { Log.d(\"TouchEvent\", \"DOWN 이벤트 발생. 이 뷰가 처리 시작!\") return true // 이 뷰가 모든 터치 이벤트를 받겠다고 선언 } MotionEvent.ACTION_MOVE -\u003e { Log.d(\"TouchEvent\", \"MOVE: (${event.x}, ${event.y})\") } MotionEvent.ACTION_UP -\u003e { Log.d(\"TouchEvent\", \"UP 이벤트 발생. 처리 종료.\") } } return super.onTouchEvent(event) // ACTION_DOWN에서 true를 반환했으므로 사실상 이 코드는 거의 호출되지 않음 }","이벤트-핸들러-구현의-3가지-방법#이벤트 핸들러 구현의 3가지 방법":"지정된 인터페이스를 구현한 객체를 이벤트 핸들러로 등록한다는 핵심 원칙은 동일하지만, 구현 방식은 코드 구조와 스타일에 따라 여러 가지가 가능합니다.","자식-뷰의-핵심-속성#자식 뷰의 핵심 속성":"각각의 자식 뷰에 설정하여 위치, 크기, 병합을 제어합니다.\n속성 설명 android:layout_row 뷰가 위치할 행의 인덱스(0부터 시작)를 직접 지정합니다. android:layout_column 뷰가 위치할 열의 인덱스(0부터 시작)를 직접 지정합니다. android:layout_rowSpan 현재 뷰가 세로로 몇 개의 셀을 병합(차지)할지 지정합니다. (기본값: 1) android:layout_columnSpan 현재 뷰가 가로로 몇 개의 셀을 병합(차지)할지 지정합니다. (기본값: 1) android:layout_gravity 셀 안에서 뷰를 정렬하거나, 뷰를 늘려 셀을 채우도록 합니다.\n- center, top, bottom, left, right: 셀 내부 정렬\n- fill, fill_horizontal, fill_vertical: 뷰를 확장하여 셀 공간 채우기","정리#정리":"컴포넌트 태그 주요 역할 액티비티 화면 표시 및 사용자 인터페이스 제공 서비스 백그라운드에서 장시간 작업 실행 콘텐츠 프로바이더 앱 간 데이터 공유 브로드캐스트 리시버 시스템 이벤트 수신 및 처리","주요-뷰-이벤트-클릭과-롱클릭#주요 뷰 이벤트: 클릭과 롱클릭":"뷰가 아무리 많아도 이벤트 처리 구조는 동일합니다. 여기서는 모든 뷰의 기반이 되는 View 클래스에 정의된 가장 대표적인 두 이벤트를 알아봅니다.\nClickEvent: 뷰를 짧게 클릭했을 때 발생 LongClickEvent: 뷰를 길게 눌렀을 때 발생 두 이벤트의 핸들러를 등록하는 리스너 함수는 다음과 같습니다.\nopen fun setOnClickListener(l: View.OnClickListener?): Unit open fun setOnLongClickListener(l: View.OnLongClickListener?): Unit SAM 기법을 활용하여 버튼의 클릭, 롱클릭 이벤트를 처리하는 코드는 다음과 같습니다.\nbinding.button.setOnClickListener { Log.d(\"kkang\", \"클릭 이벤트\") } binding.button.setOnLongClickListener { Log.d(\"kkang\", \"롱클릭 이벤트\") true // 이벤트 처리가 완료되었음을 알림 }","진화-방향-선언적-ui와-통합#\u003cstrong\u003e진화 방향: 선언적 UI와 통합\u003c/strong\u003e":"과거에는 명령형(Imperative) 방식이 일반적이었으나 (예: button.setWidth(100)),\n최근에는 선언적(Declarative) 방식이 표준이 되었습니다:\n“어떻게 그리는가”가 아니라,\n“어떤 상태일 때 어떤 UI를 원하는가”를 기술\nReact → Virtual DOM + 선언적 JSX Jetpack Compose / SwiftUI / Flutter → 순수 함수형 UI, 상태 기반 재구성 Web Components / CSS Container Queries → 웹도 선언적/컴포넌트 기반으로 진화 중","추가#추가":"","추상화된-개념-이름-cross-platform-terminology#**추상화된 개념 이름 **(Cross-Platform Terminology)":"개념 설명 대응 용어 예시 UI Tree / Element Tree 컴포넌트의 계층 구조 DOM Tree, View Hierarchy, Widget Tree Layout System 크기와 위치를 계산하는 방식 CSS Box Model, Android LayoutParams, SwiftUI Auto Layout, Flutter RenderObject Styling System 시각적 속성 관리 체계 CSS, Android Themes, SwiftUI Modifiers, Flutter ThemeData Reactivity / State Management 상태 변화 → UI 자동 갱신 React Hooks, Android ViewModel, SwiftUI @State, Flutter setState","키-이벤트#키 이벤트":"핵심 원리: 시스템 레벨의 물리적/가상 버튼 입력을 감지하는 메커니즘으로, 일반적인 텍스트 입력(소프트 키보드)과는 완전히 분리되어 있다.","키-이벤트-콜백-함수#키 이벤트 콜백 함수":"콜백 함수 설명 onKeyDown(keyCode, event) 키를 누르는 순간에 호출됩니다. event.repeatCount를 통해 길게 눌렀을 때 반복적으로 호출되는 것을 감지할 수 있습니다. onKeyUp(keyCode, event) 눌렀던 키에서 손을 떼는 순간에 호출됩니다. onKeyLongPress(keyCode, event) 사용자가 키를 길게 누르고 있을 때, onKeyDown이 처음 호출된 후 일정 시간이 지나면 호출됩니다.","터치-이벤트#터치 이벤트":"핵심 원리: 터치 이벤트는 Activity에서 시작하여 계층 구조를 따라 가장 깊은 View까지 전달되며, 이 과정에서 특정 뷰가 이벤트를 ‘소비(consume)‘하면 전파가 중단된다.\n터치 이벤트는 onTouchEvent() 콜백 함수를 통해 처리되며, MotionEvent 객체에 모든 관련 정보가 담겨 있습니다.","터치-이벤트-발생-좌표-심화#터치 이벤트 발생 좌표 (심화)":"속성 설명 사용 사례 event.x / event.y 이벤트가 발생한 뷰(View)의 좌표계에서의 상대 좌표. 즉, 해당 뷰의 좌측 상단이 (0,0)입니다. 뷰 자체의 로직 처리: 커스텀 버튼 내에서 특정 영역이 눌렸는지 확인하거나, 그림판 앱에서 캔버스 뷰 내부에 그림을 그릴 때 사용합니다. event.rawX / event.rawY 화면(Screen)의 좌표계에서의 절대 좌표. 즉, 스마트폰 화면의 좌측 상단이 (0,0)입니다. 뷰 외부와의 상호작용: 뷰를 화면 전체에서 드래그하여 위치를 옮기거나, 화면 특정 위치에 팝업을 띄울 때 기준점으로 사용합니다. 🔑 시각적 비유: rawX/rawY가 ‘벽에 걸린 TV 스크린 전체’의 좌표라면, x/y는 ‘TV 화면 속에서 재생되는 영화’ 내부의 좌표와 같습니다.","터치-이벤트의-종류와-생명주기#터치 이벤트의 종류와 생명주기":"터치 이벤트는 단발성이 아니라 하나의 연속된 흐름을 가집니다.\n이벤트 종류 (in MotionEvent) 설명 ACTION_DOWN 사용자가 화면을 처음 눌렀을 때 단 한 번 발생합니다. 모든 터치 상호작용의 시작점입니다. ACTION_MOVE 손가락을 누른 상태로 움직일 때 좌표가 바뀔 때마다 연속적으로 발생합니다. 드래그(Drag) 동작을 구현할 때 핵심적인 역할을 합니다. ACTION_UP 사용자가 화면에서 손가락을 뗄 때 단 한 번 발생합니다. 터치 상호작용의 종료점입니다. ACTION_CANCEL 터치 이벤트가 비정상적으로 종료될 때 발생합니다. 예를 들어, 뷰를 누른 상태에서 스크롤 가능한 상위 뷰(e.g., ScrollView)가 스크롤을 시작하면, 하위 뷰는 이 이벤트를 받게 됩니다."},"title":"university mobile programming"},"/window-10-%EC%97%90%EC%84%9C-11-%EB%A1%9C-%EC%9D%B4%EC%A0%84-%EA%B3%BC%EC%A0%95/":{"data":{"":"","window-측#window 측":"chrome firefox brave","wsl-측#wsl 측":"wslconfig 설정","개발-환경-설정#개발 환경 설정":"visual studio vscode git bash jetbrain docker desktop mysql workbench pgadmin (web 앱) postman jetbrain toolbox cursor? draw io everything","게임#게임":"steam epic games","기타#기타":"word powerpoint excel 카카오톡 스티커 메모 google drive window to do notion obsidian 및 gitbash 설정 typora typedown telegram desktop vlc zoom power toy window 터미널 한컴 myserver.bat : ssh shinnk@shinnk.iptime.org -p 10293 wslexit.bat @echo off echo WSL poweroff.... wsl --shutdown # Settings apply across all Linux distros running on WSL 2 [wsl2] # Limits VM memory to use no more than 4 GB, this can be set as whole numbers using GB or MB memory = 10GB # Sets the VM to use two virtual processors processors = 12 # Sets amount of swap storage space to 8GB, default is 25% of available RAM swap=8GB"},"title":"window 10 에서 11 로 이전 과정"},"/younghan-mvc1/%EC%84%9C%EB%B8%94%EB%A6%BF-%EA%B0%9D%EC%B2%B4%EB%93%A4/":{"data":{"":"","1-request-범위#1. \u003cstrong\u003erequest 범위\u003c/strong\u003e":"\u003c% request.setAttribute(\"userName\", \"Alice\"); %\u003e // Servlet에서 request 속성 사용 protected void doGet(HttpServletRequest request, HttpServletResponse response) { String name = (String) request.getAttribute(\"userName\"); }","1-각-객체의-정의-및-내부-구조#1. \u003cstrong\u003e각 객체의 정의 및 내부 구조\u003c/strong\u003e":"","11-page-pagecontext-jsp-의존적#\u003cstrong\u003e1.1 page (PageContext)\u003c/strong\u003e jsp 의존적":"범위: 현재 JSP 페이지 내에서만 유효합니다. 수명: 페이지가 렌더링되는 동안에만 유지됩니다. 내부 구조: PageContext 클래스에 의해 구현되며, 페이지 단위로 속성을 저장합니다. 내부적으로 Map 를 사용하지만, getAttributeNames() 메서드를 지원하지 않습니다. JSP의 다른 기본 객체(request, session, application)에 대한 접근을 제공합니다. JSP 의존성: O (JSP 전용 객체이며, Servlet에서는 사용 불가능합니다.)","12-request-httpservletrequest#\u003cstrong\u003e1.2 request (HttpServletRequest)\u003c/strong\u003e":"범위: 같은 요청(request) 내에서 유효합니다 (예: 클라이언트에서 서버로의 한 번의 HTTP 요청). 수명: 요청이 처리되는 동안에만 유지됩니다. 내부 구조: HttpServletRequest의 setAttribute()/getAttribute() 메서드를 사용합니다. 컨테이너(예: Tomcat)는 내부적으로 Map 구조로 속성을 관리합니다. JSP 의존성: X (Servlet에서도 사용 가능하며, JSP와 독립적입니다.)","13-session-httpsession#\u003cstrong\u003e1.3 session (HttpSession)\u003c/strong\u003e":"범위: 동일한 사용자의 세션(Session) 내에서 유효합니다. 수명: 세션이 종료될 때까지 유지됩니다 (기본적으로 30분). 내부 구조: HttpSession 객체에 속성을 저장하며, 컨테이너는 ConcurrentHashMap 를 사용하여 동시성 문제를 해결합니다. 세션 ID를 기반으로 사용자를 식별합니다. JSP 의존성: X (Servlet에서도 사용 가능하며, JSP와 독립적입니다.)","14-application-servletcontext#\u003cstrong\u003e1.4 application (ServletContext)\u003c/strong\u003e":"범위: 애플리케이션 전체(모든 사용자 및 세션)에서 유효합니다. 수명: 애플리케이션이 종료될 때까지 유지됩니다. 내부 구조: ServletContext 객체에 속성을 저장하며, 컨테이너는 ConcurrentHashMap 를 사용합니다. 모든 사용자와 세션에서 공유되는 전역 데이터를 관리합니다. JSP 의존성: X (Servlet에서도 사용 가능하며, JSP와 독립적입니다.)","2-session-범위#2. \u003cstrong\u003esession 범위\u003c/strong\u003e":"\u003c% session.setAttribute(\"userRole\", \"ADMIN\"); %\u003e","2-속성-처리-메서드-비교#2. \u003cstrong\u003e속성 처리 메서드 비교\u003c/strong\u003e":"메서드 page (PageContext) request (HttpServletRequest) session (HttpSession) application (ServletContext) setAttribute() O O O O getAttribute() O O O O removeAttribute() O O O O getAttributeNames() X O O O page 객체는 getAttributeNames()를 지원하지 않습니다. request, session, application은 getAttributeNames()로 속성 목록을 조회할 수 있습니다.","3-application-범위#3. \u003cstrong\u003eapplication 범위\u003c/strong\u003e":"\u003c% application.setAttribute(\"appVersion\", \"1.0.0\"); %\u003e","3-jsp-의존성-분석#3. \u003cstrong\u003eJSP 의존성 분석\u003c/strong\u003e":"page 객체:\nJSP 전용 객체이며, PageContext 클래스에 종속적입니다. Servlet에서는 사용할 수 없습니다. request, session, application 객체:\nServlet API(HttpServletRequest, HttpSession, ServletContext)에 정의된 표준 객체입니다. 따라서 JSP와 독립적이며, Servlet이나 다른 웹 프레임워크에서 동일하게 사용됩니다.","4-사용-예시#4. \u003cstrong\u003e사용 예시\u003c/strong\u003e":"","5-중요-고려-사항#5. \u003cstrong\u003e중요 고려 사항\u003c/strong\u003e":"범위 선택:\n임시 데이터(한 번의 요청) → request 사용자별 데이터(로그인 정보) → session 전역 데이터(설정 정보) → application 페이지 내 데이터 → page 메모리 관리:\nsession과 application 범위의 속성은 명시적으로 제거하지 않으면 메모리 누수가 발생할 수 있습니다. 동시성 문제:\nsession과 application은 ConcurrentHashMap을 사용하여 스레드 안전성을 보장합니다.","6-요약#6. \u003cstrong\u003e요약\u003c/strong\u003e":"JSP 의존성:\npage 객체만 JSP에 종속적이며, 나머지(request, session, application)는 Servlet API 표준입니다. 내부 구조:\n모든 객체는 Map 기반으로 속성을 관리하며, 범위에 따라 저장 위치와 수명이 결정됩니다. 사용 목적:\n데이터의 공유 범위에 따라 적절한 객체를 선택하여 사용합니다."},"title":"서블릿 객체들"},"/younghan-mvc1/forward-vs-redirect/":{"data":{"":"","1-forward-동작-원리#1. \u003cstrong\u003eForward 동작 원리\u003c/strong\u003e":"서버 내부에서만 처리:\nforward()는 클라이언트(브라우저)의 요청을 수신한 서블릿이 동일한 웹 컨테이너 내부에서 다른 자원(예: JSP, 다른 서블릿)으로 제어를 넘기는 동작입니다. HTTP 요청/응답 재사용: 원본 ServletRequest와 ServletResponse 객체를 그대로 전달하므로, 클라이언트는 이 과정을 인지하지 못합니다. URL 변경 없음: 브라우저 주소창의 URL은 최초 요청 경로 그대로 유지됩니다. (예: /original-servlet → /WEB-INF/views/new-form.jsp로 전달되어도 URL 변경 없음)","2-http-호출과의-차이#2. \u003cstrong\u003eHTTP 호출과의 차이\u003c/strong\u003e":"Redirect(리다이렉트):\n클라이언트에게 302 상태 코드와 새 URL을 응답으로 전송 → 클라이언트가 새로운 HTTP 요청을 발생시킵니다.\nURL 변경됨, 네트워크 비용 증가, 요청 데이터 유실 가능성 있음. Forward(포워드):\n서버 내부에서 단일 HTTP 요청 생명주기 내에서 처리됩니다.\n네트워크 오버헤드 없음, 요청/세션 데이터 보존, 클라이언트 투명성 보장.","3-기술적-특징#3. \u003cstrong\u003e기술적 특징\u003c/strong\u003e":"RequestDispatcher의 역할:\nRequestDispatcher dispatcher = request.getRequestDispatcher(viewPath); dispatcher.forward(request, response); RequestDispatcher는 Servlet API의 일부로, 서버 내부 자원 접근을 추상화한 인터페이스입니다. forward()는 동기식 제어 전달을 수행하며, 스레드는 동일한 요청 컨텍스트를 공유합니다. 보호된 자원 접근:\nWEB-INF 디렉토리 아래의 JSP는 클라이언트 직접 접근이 불가능합니다.\n→ 서버 내부에서만 forward()로 접근 가능 (보안 강화).","4-사용-사례#4. \u003cstrong\u003e사용 사례\u003c/strong\u003e":"MVC 패턴 구현:\n컨트롤러(서블릿)에서 비즈니스 로직 처리 후 뷰(JSP)로 포워딩하여 화면 렌더링. 에러 페이지 처리:\nweb.xml 또는 @WebServlet에서 에러 코드/예외 매핑 후 포워딩. 다중 자원 조합:\n하나의 요청에 여러 자원(예: 헤더, 본문, 푸터 JSP)을 조합하여 응답 생성.","5-주의-사항#5. \u003cstrong\u003e주의 사항\u003c/strong\u003e":"응답 커밋 전에만 가능:\nresponse 객체가 이미 클라이언트로 전송된 후(flush() 호출 후)에는 forward() 사용 불가 (예: IllegalStateException 발생). 속성 전달:\nrequest.setAttribute()로 데이터를 전달해야 하며, request.getParameter()는 원본 요청 데이터를 유지합니다.","요약#요약":"forward()는 서버 내부 파이프라인 재구성으로, 클라이언트는 최초 요청에 대한 응답만 받는 것으로 인지합니다. 이는 HTTP 프로토콜의 요청-응답 사이클을 최소화하며, 보안 및 성능 최적화에 활용됩니다."},"title":"forward vs redirect"},"/younghan-mvc1/html-form%ED%83%9C%EA%B7%B8-%EC%9A%94%EC%B2%AD-put-path-%EB%A9%94%EC%84%9C%EB%93%9C-%ED%99%95%EC%9E%A5/":{"data":{"":"HTML 표준 Form 태그에서 기본적으로 지원하는 메서드는 GET과 POST뿐이지만, 현대 웹 개발에서는 PUT, PATCH, 또는 DELETE 같은 HTTP 메서드를 사용할 수 있도록 확장할 수 있습니다. 이를 구현하기 위해 몇 가지 방법이 있습니다.","1-html-form의-기본-제한#1. \u003cstrong\u003eHTML Form의 기본 제한\u003c/strong\u003e":"HTML 표준에서는 태그의 method 속성으로 GET 또는 POST만 지정할 수 있습니다.\n\u003cform action=\"/submit\" method=\"POST\"\u003e \u003c/form\u003e 즉, 기본적으로 HTML Form 자체로는 PUT, PATCH, DELETE를 직접 사용할 수 없습니다.","1-javascript를-활용한-방식#\u003cstrong\u003e(1) JavaScript를 활용한 방식\u003c/strong\u003e":"JavaScript를 사용하면 HTML Form 데이터를 PUT 또는 PATCH 요청으로 전송할 수 있습니다. 예를 들어, fetch API를 사용해 다음과 같이 구현할 수 있습니다.\n\u003cform id=\"updateForm\"\u003e \u003cinput type=\"text\" name=\"username\" value=\"hello\"\u003e \u003cinput type=\"number\" name=\"age\" value=\"20\"\u003e \u003cbutton type=\"button\" onclick=\"submitForm()\"\u003e제출\u003c/button\u003e \u003c/form\u003e \u003cscript\u003e function submitForm() { const formData = new FormData(document.getElementById('updateForm')); const data = {}; formData.forEach((value, key) =\u003e { data[key] = value; }); fetch('/update', { method: 'PUT', // 또는 PATCH headers: { 'Content-Type': 'application/json', }, body: JSON.stringify(data), }) .then(response =\u003e response.json()) .then(result =\u003e console.log(result)); } \u003c/script\u003e 설명: HTML Form을 직접 제출하지 않고, JavaScript로 데이터를 수집하고 PUT 또는 PATCH 요청으로 전송합니다. 이 방식은 RESTful API와 함께 자주 사용됩니다.","2-putpatch를-사용하는-방법#2. \u003cstrong\u003ePUT/PATCH를 사용하는 방법\u003c/strong\u003e":"","2-숨겨진-필드#\u003cstrong\u003e(2) 숨겨진 필드 \u003ccode\u003e_method\u003c/code\u003e를 활용한 에뮬레이션\u003c/strong\u003e":"일부 웹 프레임워크 (예: Ruby on Rails, Spring Boot)에서는 POST 요청을 통해 PUT/PATCH/DELETE 메서드를 에뮬레이션할 수 있는 기능을 제공합니다. 이때 _method라는 숨겨진 필드를 사용합니다.\n\u003cform action=\"/update\" method=\"POST\"\u003e \u003cinput type=\"hidden\" name=\"_method\" value=\"PUT\"\u003e \u003cinput type=\"text\" name=\"username\" value=\"hello\"\u003e \u003cinput type=\"number\" name=\"age\" value=\"20\"\u003e \u003cbutton type=\"submit\"\u003e제출\u003c/button\u003e \u003c/form\u003e 설명: 실제로는 POST 요청이 전송되지만, 서버 측에서 _method=PUT을 확인하고 이를 PUT 요청으로 처리합니다. 이러한 동작은 프레임워크가 내부적으로 처리하며, 클라이언트는 POST 요청만 보내도 됩니다.","3-put-vs-patch-차이점#3. \u003cstrong\u003ePUT vs PATCH 차이점\u003c/strong\u003e":"기준 PUT PATCH 목적 리소스 전체를 수정 리소스 일부를 수정 데이터 전송 전체 데이터를 포함 변경된 부분만 포함 멱등성(Idempotent) O (같은 요청을 여러 번 실행해도 동일한 결과) X (변경 사항에 따라 결과 다를 수 있음)","4-putpatch-사용-예시#4. \u003cstrong\u003ePUT/PATCH 사용 예시\u003c/strong\u003e":"","5-왜-html-form에서-putpatch를-직접-지원하지-않을까#5. \u003cstrong\u003e왜 HTML Form에서 PUT/PATCH를 직접 지원하지 않을까?\u003c/strong\u003e":"역사적 이유: 초기 HTML 설계 시에는 단순한 데이터 전송(GET, POST)만 고려되었습니다. RESTful API의 등장: 이후 REST 아키텍처가 널리 사용되면서 PUT, PATCH, DELETE 같은 메서드가 중요해졌습니다. 보안 및 간결성: GET과 POST는 간단하고 직관적이며, 복잡한 메서드는 JavaScript나 프레임워크를 통해 구현하도록 설계되었습니다.","6-결론#6. \u003cstrong\u003e결론\u003c/strong\u003e":"HTML Form 자체로는 PUT/PATCH를 직접 사용할 수 없습니다. JavaScript를 사용하거나 _method와 같은 에뮬레이션 기법을 통해 PUT/PATCH를 구현할 수 있습니다. RESTful API 설계 시, PUT은 리소스 전체를 수정하고, PATCH는 리소스 일부를 수정하는 데 사용됩니다. 따라서, HTML Form에서도 PUT/PATCH를 사용할 수 있지만, 추가적인 기술적 구현이 필요합니다.","patch-예시#\u003cstrong\u003ePATCH 예시\u003c/strong\u003e":"리소스 일부만 업데이트하는 경우:\nPATCH /users/123 HTTP/1.1 Content-Type: application/json { \"age\": 26 }","put-예시#\u003cstrong\u003ePUT 예시\u003c/strong\u003e":"리소스 전체를 업데이트하는 경우:\nPUT /users/123 HTTP/1.1 Content-Type: application/json { \"username\": \"newName\", \"age\": 25, \"email\": \"new@example.com\" }"},"title":"HTML form태그 요청 PUT PATH 메서드 확장"},"/younghan-mvc1/http-%EB%B6%84%EC%84%9D/":{"data":{"":"전문가를 대상으로 한 심층적인 HTTP 구성 요소 설명입니다. 각 항목의 기술적 특성과 실제 적용 시 고려사항을 중심으로 설명합니다:","1-http-메소드-http-methods#1. \u003cstrong\u003eHTTP 메소드 (HTTP Methods)\u003c/strong\u003e":"RFC 7231 표준에 정의된 동사(Verb)로, 리소스에 대한 의도를 명시 Idempotency: PUT/DELETE는 멱등성 보장 (동일 요청 반복 시 결과 동일) Safe Methods: GET/HEAD/OPTIONS는 서버 상태 변경 없음 확장 메소드: PATCH(부분 수정), LINK(리소스 연결) 등 RFC 5789 API 설계 시 고려사항: RESTful 원칙 준수 (리소스 중심 경로 + 메소드 조합) OPTIONS 메소드를 통한 CORS Preflight 처리 TRACE 메소드의 보안 취약점 관리 (XST 공격 방어)","2-url-uniform-resource-locator#2. \u003cstrong\u003eURL (Uniform Resource Locator)\u003c/strong\u003e":"URI의 하위 집합으로, 리소스 위치 및 접근 방법을 포함\nscheme:[//authority][/path][?query][#fragment] Authority: user:pass@host:port (인증정보는 RFC 7617에서 deprecated) Path Parameter: /users/123;version=2 (Matrix URIs, RFC 3986) Encoding: 퍼센트 인코딩 (예: 한글 → %ED%95%9C%EA%B8%80) REST API 설계:\n버저닝 전략 (/v1/resource vs Accept: application/vnd.example.v1+json) HATEOAS를 위한 링크 표현 (HAL, JSON-LD)","3-쿼리-스트링-query-string#3. \u003cstrong\u003e쿼리 스트링 (Query String)\u003c/strong\u003e":"RFC 3986에 정의된 비계층적 데이터 전달 방식 중복 키 처리: ?q=1\u0026q=2 → 서버측 언어별 파싱 차이 (PHP: 배열, Node.js: 마지막 값) 보안 이슈: SQLi/XSS 방지를 위한 입력 검증 필수 민감 데이터 전송 금지 (로그에 노출 위험) 성능 최적화: 캐시 키 생성 시 쿼리 파라미터 순서 무시 (예: ?a=1\u0026b=2 ≡ ?b=2\u0026a=1) CDN 쿼리 스트링 캐싱 정책 관리","4-스키마프로토콜-schemeprotocol#4. \u003cstrong\u003e스키마/프로토콜 (Scheme/Protocol)\u003c/strong\u003e":"HTTP/1.1 (RFC 7230) vs HTTP/2 (RFC 7540) vs HTTP/3 (RFC 9114) HTTP/2: Binary Framing, Header Compression (HPACK) Multiplexing (단일 연결에서 병렬 요청) HTTP/3: QUIC 프로토콜 기반 (UDP 사용, 연결 이동성) TLS Handshake: ALPN 확장을 통한 프로토콜 협상 보안: HSTS (HTTP Strict Transport Security) 적용 TLS 1.3 이상 강제화 (RFC 8446)","5-헤더-headers#5. \u003cstrong\u003e헤더 (Headers)\u003c/strong\u003e":"표준 헤더: Content-Type: application/json; charset=utf-8 Cache-Control: max-age=3600, public Authorization: Bearer 사용자 정의 헤더: X- Prefix는 더 이상 권장되지 않음 (RFC 6648) Sec- Prefix는 브라우저 보안 헤더 예약 성능 최적화: Connection: keep-alive (HTTP/1.1 기본) Transfer-Encoding: chunked 스트리밍 처리","6-헤더-조회-header-inspection#6. \u003cstrong\u003e헤더 조회 (Header Inspection)\u003c/strong\u003e":"네트워크 계층 분석:\nWireshark/tcpdump로 Raw 패킷 캡처 TLS 트래픽은 Session Key 로깅 후 복호화 (SSLKEYLOGFILE) 응용 계층 분석:\n# Python (Flask) from flask import request print(request.headers.get('X-Custom-Header')) // Node.js (Express) app.use((req, res, next) =\u003e { console.log(req.get('User-Agent')); next(); }); CDN/Proxy 환경:\nX-Forwarded-For, X-Real-IP 헤더 검증 CDN별 헤더 규격 차이 (Cloudflare vs AWS CloudFront)","7-바디-body#7. \u003cstrong\u003e바디 (Body)\u003c/strong\u003e":"전송 형식:\napplication/json: UTF-8 인코딩 필수 (RFC 8259) multipart/form-data: Boundary 구분자 무결성 검증 application/octet-stream: 바이너리 데이터 처리 스트리밍 처리:\n# Python (Requests) with requests.post(url, data=generator()) as r: for chunk in r.iter_content(8192): process(chunk) 보안:\n요청 크기 제한 (예: Nginx client_max_body_size) 파일 업로드 시 MIME 타입 검증 + 바이러스 스캔","8-form-파라미터-형식-조회#8. \u003cstrong\u003eForm 파라미터 형식 조회\u003c/strong\u003e":"인코딩 타입 비교: Content-Type 용도 RFC application/x-www-form-urlencoded 단순 텍스트 데이터 RFC 1866 multipart/form-data 파일 업로드 RFC 7578 application/json 구조화된 데이터 RFC 8259 구현 시 고려사항: charset 미지정 시 ISO-8859-1 기본 적용 (RFC 7231) 파일 업로드 시 filename* 확장 문법 (RFC 5987) 대용량 파일 처리를 위한 Memory Mapped I/O","9-message-body-데이터-직접-조회#9. \u003cstrong\u003eMessage Body 데이터 직접 조회\u003c/strong\u003e":"Low-Level 접근:\n// Java Servlet API ServletInputStream inputStream = request.getInputStream(); byte[] buffer = new byte[8192]; int bytesRead; while ((bytesRead = inputStream.read(buffer)) != -1) { // Process raw bytes } // Go body, _ := ioutil.ReadAll(r.Body) defer r.Body.Close() 성능 최적화:\nZero-Copy 기법 (sendfile 시스템 호출) 메모리 풀링 (Netty 등 비동기 프레임워크) 보안:\nDeserialization 취약점 방어 (JSON/XML External Entity) 요청 크기 제한 및 타임아웃 설정 이 설명은 API 게이트웨이 개발, 고성능 서버 설계, 보안 오디팅 등 전문적인 시나리오에서의 적용을 고려한 내용입니다. 각 구성 요소는 RFC 표준, 성능 최적화, 보안 측면에서 종합적으로 관리되어야 합니다."},"title":"http 분석"},"/younghan-mvc1/http-%EC%9A%94%EC%B2%AD-3%EA%B0%80%EC%A7%80-%EB%B0%A9%EB%B2%95/":{"data":{"":"","-선택-가이드#💡 선택 가이드":"간단한 데이터 조회: GET + 쿼리 파라미터 폼 기반 데이터 제출: POST + application/x-www-form-urlencoded 복잡한 데이터 연동: POST/PUT/PATCH + application/json","-차이점-요약#📌 차이점 요약":"구분 GET (쿼리 파라미터) POST (HTML Form) HTTP Message Body (JSON/XML) 데이터 위치 URL 끝에 ?key=value 메시지 바디 (key=value) 메시지 바디 (구조화된 데이터) 사용 HTTP 메서드 GET POST POST, PUT, PATCH 등 데이터 형식 쿼리 스트링 application/x-www-form-urlencoded JSON, XML, 텍스트 등 주요 사용처 검색, 필터링, 공유 링크 HTML 폼 제출 (로그인, 주문) API 통신 (모바일/서버 연동)","1-get---쿼리-파라미터#1. \u003cstrong\u003eGET - 쿼리 파라미터\u003c/strong\u003e":"데이터 전송 방식: URL 끝에 ?key1=value1\u0026key2=value2 형식으로 데이터를 포함합니다. 특징: 메시지 바디 없음: 데이터가 URL에 직접 노출됩니다. 캐시 가능: 브라우저나 프록시 서버에서 캐시됩니다. 안전하지 않음: 중요한 데이터(비밀번호 등) 전송에 부적합합니다. 사용 사례: 검색, 필터링, 페이징 (예: GET /products?category=book\u0026page=2) 북마크 또는 공유 가능한 링크 생성 예시: GET /users?name=hello\u0026age=20 HTTP/1.1 Host: example.com","2-post---html-form#2. \u003cstrong\u003ePOST - HTML Form\u003c/strong\u003e":"데이터 전송 방식: 메시지 바디에 key1=value1\u0026key2=value2 형식으로 데이터를 전송합니다. 쿼리 파라미터 형식으로 보낸다 헤더 설정: Content-Type: application/x-www-form-urlencoded 특징: 메시지 바디 사용: URL에 데이터가 노출되지 않습니다. 폼 데이터 전송: HTML 태그 기본 방식입니다. 데이터 길이 제한 없음: 대량의 데이터 전송 가능합니다. 사용 사례: 회원 가입, 로그인, 상품 주문 (예: POST /login + username=admin\u0026password=1234) 예시: POST /submit-form HTTP/1.1 Host: example.com Content-Type: application/x-www-form-urlencoded username=hello\u0026age=20","3-http-message-body-jsonxml-등#3. \u003cstrong\u003eHTTP Message Body (JSON/XML 등)\u003c/strong\u003e":"데이터 전송 방식: 메시지 바디에 구조화된 데이터(JSON, XML 등)를 직접 작성합니다. 헤더 설정: Content-Type: application/json # JSON 사용 시 특징: 다양한 데이터 형식: JSON, XML, 텍스트 등 사용 가능합니다. HTTP API 표준: RESTful API에서 주로 사용됩니다. 복잡한 데이터 처리: 계층적/중첩된 데이터 전송에 적합합니다. 사용 사례: 모바일 앱/백엔드 연동 (예: POST /api/users + JSON 데이터) PUT/PATCH를 통한 리소스 업데이트 예시 (JSON): POST /api/users HTTP/1.1 Host: example.com Content-Type: application/json { \"name\": \"hello\", \"age\": 20, \"hobbies\": [\"reading\", \"coding\"] }"},"title":"HTTP 요청 3가지 방법"},"/younghan-mvc1/mvc-1-%EA%B0%95%EC%9D%98-%EC%A7%88%EB%AC%B8-%EC%82%AC%ED%95%AD/":{"data":{"":"","http-응답-코드-status-code#\u003cstrong\u003eHTTP 응답 코드 (Status Code)\u003c/strong\u003e":"목적 : 클라이언트에게 요청 처리 결과를 수치화해 전달합니다.\n구조 : 3자리 숫자로 분류되며, 첫 번째 숫자는 응답 클래스를 나타냅니다.\n1xx (정보 제공) : 100 Continue (요청 진행 중). 2xx (성공) : 200 OK (성공), 201 Created (리소스 생성됨). 3xx (리다이렉션) : 301 Moved Permanently (영구 이동), 302 Found (임시 이동). 4xx (클라이언트 오류) : 400 Bad Request (잘못된 요청), 404 Not Found. 5xx (서버 오류) : 500 Internal Server Error, 503 Service Unavailable. @GetMapping 의 메소드 단위 매핑의 원리가 궁금하다 강의 질문답에서는 리플렉션이라고 답하고 있다\n어노테이션의 동작 원리\n라이브러리 설정시에 표기되는 여러가지\nannotation processor compile processer compile class path production runtime classpath runtime classpath test compile classpath test runtime classpath PathVariable(경로 변수) ex) mapping/{userId} 로 요청을 하는 것과 parameter 로 전달하는 것\njsp 는 jar 파일로 패키징 하는 것이 권장되지 않는 이유"},"title":"MVC 1 강의 질문 사항"},"/younghan-mvc1/obsidian-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B0%94%EC%9D%B8%EB%94%A9-%EC%B2%98%EB%A6%AC/":{"data":{"":"Spring MVC의 데이터 바인딩과 관련된 주요 처리 과정을 순서대로 정리해드리겠습니다:\n요청 수신 DispatcherServlet이 HTTP 요청을 받음 컨트롤러 매핑 요청 URL에 매핑된 적절한 컨트롤러 메서드를 찾음 파라미터 바인딩 단계 @ModelAttribute 객체 생성 요청 파라미터를 객체의 프로퍼티에 매핑 시도 타입 변환 시도 변환 성공: 해당 필드에 값 설정 변환 실패: BindingResult에 에러 정보 저장 (bindingFailure = true) 검증 단계 (@Valid 또는 @Validated 사용 시) Validator 실행 검증 규칙 위반 시 BindingResult에 에러 정보 저장 (bindingFailure = false) 컨트롤러 메서드 실행 바인딩(및 검증)이 완료된 @ModelAttribute 객체를 메서드 파라미터로 전달 BindingResult는 해당 객체의 바로 다음 파라미터로 전달 뷰 렌더링 BindingResult의 내용을 활용하여 오류 메시지 표시 rejectedValue 등을 사용하여 사용자 입력값 유지 중요한 점:\n각 @ModelAttribute마다 별도의 BindingResult가 필요 바인딩 실패와 검증 실패는 구분되어 처리됨 바인딩은 컨트롤러 메서드 실행 전에 완료됨 이러한 순서로 Spring MVC는 요청 파라미터를 처리하고 컨트롤러에 전달합니다."},"title":"obsidian 데이터 바인딩 처리"},"/younghan-mvc1/spring-controller-%EB%B0%98%ED%99%98return/":{"data":{"":"Spring MVC에서 @Controller 클래스의 @RequestMapping 메서드는 다양한 반환 타입을 지원합니다.\n반환 타입에 따라 HTTP 응답 생성 방식이 달라지며, 주요 반환 타입은 다음과 같습니다.\nHTTP컨버터 작동 x ModelAndVIew 반환 뷰이름 반환 : string Http 컨버터 작동 : @RequestBody 또는 HttpEntity(ResponseEntity) 일때만 작동 byte, string, json 순서로 처리, 요청정보의 media type 도 동시에 활용 byte String 객체","1#\u003cstrong\u003e1. \u003ccode\u003eString\u003c/code\u003e (뷰 이름)\u003c/strong\u003e":"HTTP 메시지 컨버터 미작동\n기본 동작:\n반환된 String은 뷰 이름으로 해석되며, ViewResolver가 해당 뷰를 찾아 렌더링합니다.\n예시:\n@GetMapping(\"/home\") public String home(Model model) { model.addAttribute(\"message\", \"Hello\"); return \"home\"; // /WEB-INF/views/home.jsp 또는 Thymeleaf 템플릿 } 특징:\nModel 객체를 통해 뷰에 데이터 전달. @ResponseBody가 없으면 뷰 리졸버가 동작.","2#\u003cstrong\u003e2. \u003ccode\u003eResponseEntity\u0026lt;?\u0026gt;\u003c/code\u003e\u003c/strong\u003e":"HTTP 메시지 컨버터 작동\n기본 동작:\nHTTP 응답의 상태 코드, 헤더, 본문을 직접 제어합니다.\nHttpEntity는 헤더와 본문을 포함하지만, 상태 코드는 없으며, ResponseEntity는 상태 코드를 추가로 지원합니다.\n예시:\n@GetMapping(\"/api/data\") public ResponseEntity\u003cString\u003e getData() { return ResponseEntity.status(HttpStatus.CREATED) .header(\"X-Custom\", \"Value\") .body(\"Created\"); } 특징:\nHttpEntity 상속받아 헤더/본문 설정 가능. @ResponseBody 없이도 본문이 HTTP 응답에 직접 기록됨.","3#\u003cstrong\u003e3. \u003ccode\u003e@ResponseBody\u003c/code\u003e 어노테이션\u003c/strong\u003e":"HTTP 메시지 컨버터 작동\n기본 동작:\n반환 값이 HTTP 응답 본문에 직접 직렬화됩니다.\n(예: String → 텍스트, 객체 → JSON/XML)\n예시:\n@GetMapping(\"/api/json\") @ResponseBody public User getUser() { return new User(\"John\", 30); // {\"name\":\"John\",\"age\":30} } 특징:\nHttpMessageConverter가 자동으로 데이터 변환 (예: Jackson 라이브러리 사용). @RestController는 클래스 레벨에 @ResponseBody를 포함합니다.","4#\u003cstrong\u003e4. \u003ccode\u003eModelAndView\u003c/code\u003e\u003c/strong\u003e":"HTTP 메시지 컨버터 미작동\n기본 동작:\n모델 데이터와 뷰 이름을 동시에 전달합니다.\n예시:\n@GetMapping(\"/profile\") public ModelAndView profile() { ModelAndView mav = new ModelAndView(\"profile\"); mav.addObject(\"user\", new User(\"Alice\", 25)); return mav; } 특징:\n레거시 코드에서 주로 사용되며, 명시적 제어가 가능합니다.","5#\u003cstrong\u003e5. \u003ccode\u003evoid\u003c/code\u003e\u003c/strong\u003e":"HTTP 메시지 컨버터 미작동\n기본 동작:\n반환 타입이 void인 경우, 다음 중 1개를 선택:\n디폴트 뷰 이름: 요청 URL을 기반으로 뷰 이름 생성 (예: /home → home 뷰). Response 직접 조작: HttpServletResponse를 파라미터로 받아 수동으로 응답 작성. 예시:\n@GetMapping(\"/manual\") public void manualResponse(HttpServletResponse response) throws IOException { response.getWriter().write(\"Manual Response\"); }","6-pojo-plain-old-java-object#\u003cstrong\u003e6. POJO (Plain Old Java Object)\u003c/strong\u003e":"기본 동작:\n반환된 객체는 Model에 자동 추가되며, 뷰에서 참조 가능합니다.\n(단, @ResponseBody가 없을 때)\n예시:\n@GetMapping(\"/user\") public User getUser() { return new User(\"Bob\", 28); // Model에 \"user\"라는 이름으로 추가됨 } 특징:\n뷰 템플릿에서 ${user.name}처럼 접근 가능.","7#\u003cstrong\u003e7. \u003ccode\u003eCallable\u0026lt;?\u0026gt;\u003c/code\u003e 또는 \u003ccode\u003eDeferredResult\u0026lt;?\u0026gt;\u003c/code\u003e\u003c/strong\u003e":"기본 동작:\n비동기 처리를 위해 사용되며, 별도 스레드에서 결과를 생성합니다.\n예시:\n@GetMapping(\"/async\") public Callable\u003cString\u003e asyncRequest() { return () -\u003e { Thread.sleep(1000); return \"asyncResult\"; }; } 특징:\n장시간 처리 작업에 유용하며, 스레드 풀을 활용합니다.","8#\u003cstrong\u003e8. \u003ccode\u003eView\u003c/code\u003e 구현체\u003c/strong\u003e":"기본 동작:\n직접 View 인터페이스를 구현한 객체를 반환해 커스텀 뷰를 생성합니다.\n예시:\n@GetMapping(\"/custom-view\") public View getCustomView() { return new MyCustomView(); // View 인터페이스 구현체 }","9#\u003cstrong\u003e9. \u003ccode\u003eHttpEntity\u0026lt;?\u0026gt;\u003c/code\u003e 또는 \u003ccode\u003eResponseEntity\u0026lt;?\u0026gt;\u003c/code\u003e 확장\u003c/strong\u003e":"기본 동작:\nHttpEntity는 헤더와 본문을 포함하지만, 상태 코드는 없으며, ResponseEntity는 상태 코드를 추가로 지원합니다.\n예시:\n@GetMapping(\"/custom-header\") public HttpEntity\u003cString\u003e customHeader() { HttpHeaders headers = new HttpHeaders(); headers.add(\"X-Custom\", \"Value\"); return new HttpEntity\u003c\u003e(\"Body\", headers); }","responsbody-또는-httpentity-일때#@ResponsBody 또는 HttpEntity 일때":"![Pasted image 20250315222234](../08.media/Pasted%er가 response 객체에 해당 값을 넣어두고, 흐름이 다시 DispatcherServlet으로 가서(그럼 여기서 modelAndView는 null) 내부 로직에 의해 view를 만드는 과정이 생략되고 http 응답 메시지생성","반환-타입-요약#\u003cstrong\u003e반환 타입 요약\u003c/strong\u003e":"반환 타입 동작 방식 주요 사용처 String 뷰 이름 반환 뷰 템플릿 렌더링 (JSP, Thymeleaf) ResponseEntity\u003c?\u003e HTTP 상태 코드/헤더/본문 제어 REST API, 커스텀 HTTP 응답 @ResponseBody 객체를 HTTP 본문에 직렬화 JSON/XML API 응답 ModelAndView 모델과 뷰를 동시에 지정 복잡한 뷰 로직 void 수동 응답 또는 디폴트 뷰 HttpServletResponse 직접 사용 POJO Model에 객체 자동 추가 뷰 템플릿 데이터 전달 Callable\u003c?\u003e 비동기 처리 장시간 작업","핵심-차이-뷰-vs-api-응답#\u003cstrong\u003e핵심 차이: 뷰 vs API 응답\u003c/strong\u003e":"뷰 렌더링: String, ModelAndView → ViewResolver가 뷰를 찾아 렌더링. API 응답: ResponseEntity, @ResponseBody → HttpMessageConverter가 데이터 직렬화."},"title":"spring controller 반환(return)"},"/younghan-mvc1/spring-mvc-%EC%A3%BC%EC%9A%94-%EC%96%B4%EB%85%B8%ED%85%8C%EC%9D%B4%EC%85%98/":{"data":{"":"클래스 단위 @Controller : 이 클래스가 컨트롤러임을 명시 @RequestMapping : 메소드 단위의 RequestMapping 의 공통 url 을 명시 @RestContoller : @ResponseBody + @Controller 이 클래스가 반환이 view 가아닌 바디에 직접 컨트롤 즉 Rest 속성을 지닌 컨트롤러임을 명시 메소드 단위 @RequestMapping : 리플렉션을 사용해서 url 등록 각 메서드 마다 GetMapping 등이 있다 메소드 인자 단위 @RequestParam : request parameter 의 값을 가져올 수 있다 @ModelAttribute : 모델을 생성하고 parameter 값을 넣어주는 행위를 자동화 @RequestHeader : 헤더의 정보를 조회 @CookieValue : 쿠키 value 를 조회 @ResponseBody : ResponseEntity\u003c?\u003e 에 자동으로 넣어준다 ResponseEntity\u003c?\u003e는 HTTP 컨버터를 작동할 수 있는 객체 @ModelAttribute 는 생략할 수 있다. 그런데 @RequestParam 도 생략할 수 있으니 혼란이 발생할 수 있다. 스프링은 해당 생략시 다음과 같은 규칙을 적용한다. String , int , Integer 같은 단순 타입 = @RequestParam 나머지 = @ModelAttribute (argument resolver 로 지정해둔 타입 외)","기본-템플릿엔진#기본 템플릿엔진":"JSP (JavaServer Pages)** Thymeleaf FreeMarker Velocity","기타#기타":"redirect : redirect: 접두어를 사용해 다른 URL로 리다이렉트, RedirectView 클래스로 명시적 리다이렉트 처리.","데이터-포멧-뷰#데이터 포멧 뷰":"JSON/XML RSS/Atom : RssView 또는 AtomView를 사용해 피드 생성.","문서-생성-뷰#문서 생성 뷰":"PDF : AbstractPdfView를 상속받아 PDF 문서 생성, iText 라이브러리 사용. execl : AbstractExcelView 또는 AbstractJExcelView를 상속, Apache POI 또는 JExcelAPI 사용"},"title":"spring mvc 주요 어노테이션"},"/younghan-mvc1/spring-mvc-%EC%A3%BC%EC%9A%94-%EC%B2%98%EB%A6%AC-%EA%B3%BC%EC%A0%95/":{"data":{"":"","2번-처리#2번 처리":"(DispatcherServle doDispatch() 이 호출되기 까지 설명)\nDispatcherServlet 서블릿 등록 DispatcherServlet 도 부모 클래스에서 HttpServlet 을 상속 받아서 사용하고, 서블릿으로 동작한다. DispatcherServlet -\u003e FrameworkServlet -\u003e HttpServletBean -\u003e HttpServlet 스프링 부트는 DispatcherServlet 을 서블릿으로 자동으로 등록하면서 모든 경로( urlPatterns=\"/\" )에 대해서 매핑한다. 참고: 더 자세한 경로가 우선순위가 높다. 그래서 기존에 등록한 서블릿도 함께 동작한다 요청 흐름 서블릿이 호출되면 HttpServlet 이 제공하는 serivce() 가 호출된다. 스프링 MVC는 DispatcherServlet 의 부모인 FrameworkServlet 에서 service() 를 오버라이드 해 두었다. FrameworkServlet.service() 를 시작으로 여러 메서드가 호출되면서 DispatcherServlet.doDispatch() 가 호출된다.","3번-처리#3번 처리":"스프링이 적절한 컨트롤러를 가져오는 과정을 하기 위해서 (파일이든 xml 이든) 미리 가져와서 매핑처리를 하는 친구가 필요하다 HandlerMapping\n0 = RequestMappingHandlerMapping : 애노테이션 기반의 컨트롤러인 @RequestMapping에서 사용 1 = BeanNameUrlHandlerMapping : 스프링 빈의 이름으로 핸들러를 찾는다. spring RequestMapping 구현체 어노테이션 기반의 컨트롤러를 명시하기 위해서는 @Controller 또는 @RestController 가 필요하다","4번-처리#4번 처리":"HandlerAdapter\n0 = RequestMappingHandlerAdapter : 애노테이션 기반의 컨트롤러인 @RequestMapping에서 사용 1 = HttpRequestHandlerAdapter : HttpRequestHandler 처리 2 = SimpleControllerHandlerAdapter : Controller 인터페이스 (애노테이션X, 과거에 사용) 처리 spring HandlerAdapter 구현체","5번-처리#5번 처리":"ModelAndView 는 Spring MVC에서 컨트롤러가 처리 결과를 뷰에 전달하는 데 사용되는 핵심 클래스 입니다.\nModel(데이터)과 View(화면) 이름을 함께 저장하고, DispatcherServlet이 이를 해석해 최종 응답을 생성합니다. ModelAndView 역할\nModel :\n뷰에 전달할 데이터를 키-값 쌍(Map) 으로 저장합니다.\n(예: model.put(\"users\", userList) → 뷰에서 ${users}로 접근) View :\n뷰 이름(문자열) 또는 View 객체를 저장합니다. 뷰 이름 : ViewResolver가 실제 뷰 객체(예: JSP, Thymeleaf 템플릿)로 변환합니다. View 객체 : 직접 생성한 View 구현체(예: JSON 뷰)를 사용합니다","8번-처리#8번 처리":"spring ViewResolver 구현체","9번-처리#9번 처리":"spring View 구현체","메인-흐름#메인 흐름":"사용자 요청 DispatcherServle doDispatch() 호출 등록되어 있는 핸들러(컨트롤러) 조회 : 매핑정보에서 맞는 핸들러를 가져온다 핸들러를 처리할 수 있는 어댑터 조회 핸들러 어댑터를 통해 핸들러(컨트롤러)를 실행 (어뎁터를 통해 무조건) ModelAndView 를 반환받는다 ModelAndView를 processDispatchResult함수를 통해 넘겨준다 뷰리졸버를 통해 적절한 뷰를 찾아서 뷰를 반환받는다 뷰를 통해 렌더링한다","추가#추가":""},"title":"Spring MVC 주요 처리 과정"},"/younghan-mvc1/thymeleaf-%EA%B8%B0%EB%B3%B8/":{"data":{"":"","1-타임리프-사용-선언#1. \u003cstrong\u003e타임리프 사용 선언\u003c/strong\u003e":"타임리프를 사용하기 위해 HTML 문서의 태그에 네임스페이스를 선언합니다.\n\u003chtml xmlns:th=\"http://www.thymeleaf.org\"\u003e","10-참고#10. \u003cstrong\u003e참고\u003c/strong\u003e":"타임리프는 다음과 같은 장점이 있습니다:\nHTML 파일을 그대로 유지하면서 템플릿 기능을 사용할 수 있습니다. 서버 렌더링 후에도 클라이언트에서 정상적으로 작동합니다. 직관적이고 간결한 문법으로 개발 생산성을 높입니다.","2-속성-변경--#2. \u003cstrong\u003e속성 변경 - \u003ccode\u003eth:href\u003c/code\u003e\u003c/strong\u003e":"th:href는 HTML의 href 속성을 동적으로 변경할 수 있습니다.\n예시:\n\u003clink href=\"value1\" th:href=\"@{/css/bootstrap.min.css}\"\u003e 동작 방식: HTML 파일을 직접 열면 href=\"value1\"이 사용됩니다. 타임리프 템플릿을 거치면 th:href의 값(@{/css/bootstrap.min.css})으로 대체됩니다. 핵심:\nth:xxx가 붙은 부분은 서버 사이드에서 렌더링되며, 기존 값을 대체합니다. th:xxx가 없으면 기존 HTML 속성이 그대로 유지됩니다.","3-url-링크-표현식--#3. \u003cstrong\u003eURL 링크 표현식 - \u003ccode\u003e@{...}\u003c/code\u003e\u003c/strong\u003e":"타임리프에서 URL 링크를 작성할 때는 @{...}를 사용합니다. 이를 URL 링크 표현식이라 합니다.\n예시:\n\u003clink th:href=\"@{/css/bootstrap.min.css}\"\u003e 특징: 서블릿 컨텍스트 경로를 자동으로 포함합니다. 경로 변수와 쿼리 파라미터도 쉽게 추가할 수 있습니다. 경로 변수와 쿼리 파라미터 예시:\n\u003ca th:href=\"@{/basic/items/{itemId}(itemId=${item.id}, query='test')}\"\u003e 생성된 링크:\nhttp://localhost:8080/basic/items/1?query=test","4-리터럴-대체--#4. \u003cstrong\u003e리터럴 대체 - \u003ccode\u003e|...|\u003c/code\u003e\u003c/strong\u003e":"문자열과 표현식을 조합할 때 더하기(+) 연산자를 사용하지 않고 간단히 작성할 수 있는 문법입니다.\n예시:\n\u003cspan th:text=\"'Welcome to our application, ' + ${user.name} + '!'\"\u003e 위 코드를 리터럴 대체 문법으로 간단히 작성하면:\n\u003cspan th:text=\"|Welcome to our application, ${user.name}!|\"\u003e th:onclick에서 리터럴 대체 사용:\n\u003cbutton th:onclick=\"|location.href='@{/basic/items/add}'|\"\u003e 결과:\nlocation.href='/basic/items/add'","5-반복-출력--#5. \u003cstrong\u003e반복 출력 - \u003ccode\u003eth:each\u003c/code\u003e\u003c/strong\u003e":"컬렉션 데이터를 반복 처리할 때 사용합니다.\n예시:\n\u003ctr th:each=\"item : ${items}\"\u003e \u003ctd th:text=\"${item.name}\"\u003e상품명\u003c/td\u003e \u003ctd th:text=\"${item.price}\"\u003e가격\u003c/td\u003e \u003c/tr\u003e items 컬렉션의 각 요소가 item 변수에 할당되고, 반복문 안에서 사용됩니다. 컬렉션의 크기만큼 태그가 생성됩니다.","6-변수-표현식--#6. \u003cstrong\u003e변수 표현식 - \u003ccode\u003e${...}\u003c/code\u003e\u003c/strong\u003e":"모델에 포함된 값이나 타임리프 변수를 조회할 때 사용합니다.\n예시:\n\u003ctd th:text=\"${item.price}\"\u003e10000\u003c/td\u003e ${item.price}는 item.getPrice() 메서드를 호출한 것과 동일합니다. 10000은 ${item.price}의 값으로 대체됩니다.","7-내용-변경--#7. \u003cstrong\u003e내용 변경 - \u003ccode\u003eth:text\u003c/code\u003e\u003c/strong\u003e":"HTML 요소의 내용을 동적으로 변경합니다.\n예시:\n\u003ctd th:text=\"${item.price}\"\u003e10000\u003c/td\u003e 10000은 ${item.price}의 값으로 대체됩니다.","8-url-링크-간단히-작성---리터럴-대체-활용#8. \u003cstrong\u003eURL 링크 간단히 작성 - 리터럴 대체 활용\u003c/strong\u003e":"리터럴 대체 문법을 사용하여 URL을 간단히 작성할 수 있습니다.\n예시:\n\u003ca th:href=\"@{|/basic/items/${item.id}|}\"\u003e상품 상세보기\u003c/a\u003e 생성된 링크:\nhttp://localhost:8080/basic/items/1","9-타임리프의-핵심-특징#9. \u003cstrong\u003e타임리프의 핵심 특징\u003c/strong\u003e":"네츄럴 템플릿(Natural Templates): 순수 HTML 파일을 웹 브라우저에서 열어도 정상적으로 보입니다. 서버를 통해 뷰 템플릿을 거치면 동적으로 변경된 결과를 확인할 수 있습니다. JSP와 달리 소스 코드가 뒤죽박죽되지 않습니다.","요약#요약":"타임리프는 HTML 파일을 그대로 유지하면서 서버 사이드에서 동적으로 변환할 수 있는 강력한 템플릿 엔진입니다. 주요 기능으로는 th:xxx 속성, URL 링크 표현식(@{...}), 리터럴 대체(|...|), 반복 처리(th:each) 등이 있습니다. 이러한 특징 덕분에 네츄럴 템플릿이라는 이름으로 불리며, 현대적인 웹 개발에서 많이 사용되고 있습니다.","타임리프-간단히-알아보기#타임리프 간단히 알아보기":""},"title":"thymeleaf 기본"},"/younghan-mvc1/younghan-mvc1-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-%EB%B3%80%ED%99%94-%EA%B3%BC%EC%A0%95/":{"data":{"":"","spring-과-동치#spring 과 동치":"직접 만든 프레임워크 스프링 MVC 비교 FrontController -\u003e DispatcherServlet handlerMappingMap -\u003e HandlerMapping MyHandlerAdapter -\u003e HandlerAdapter ModelView -\u003e ModelAndView viewResolver -\u003e ViewResolver MyView -\u003e View","v1#v1":"","v2#v2":"","v3#v3":"MyView 클래스가 조금 복잡해 지는데 jsp 의 구조상 서블릿 객체들 에 저장해 주어야 쉽게 빼서 사용할 수 있다\nJSP는 request.getAttribute() 로 데이터를 조회하기 때문에, 모델의 데이터를 꺼내서 request.setAttribute() 로 담아둔다\n만약 view 측에서 쉽게 data 에 접근하는 좋은 방식이 있다면 이렇게 코드를 만들지 않을 수 있다","v4#v4":"","v5#v5":"핸들러 \u003c= 컨트롤러 : 동일한 말과 같음","개발-순서#개발 순서":"java.hello.servlet 패키지에서 시작\nbasic 패키지 : was 표준으로 되어 있는 서블릿을 등록하는 방법을 배운다 WebSservlet 어노테이션 또는 web.xml 파일을 통해 서블릿을 등록할 수 있다 실제 구현은 HttpServlet 을 상속받아 실제 사용자의 요청 정보(request) 또는 반환 정보(response)를 통제 변환할 수 있다 web.servlet 패키지 : 적절한 요청에 적절한 반환을 하기 위해 반환정보에(response) 원하는 html 을 쌩으로 담아서 넘겨본다 순수 jsp 패키지 : webapp 폴더안에 jsp 라는 이름으로 존재한다 jsp 를 통해 조금더 편안하게 요청을 처리해 보자 (jsp 에서 처리까지 다 해보기) web.servletmvc 패키지 : 적절한 요청에 jsp 를 통해 view 역할을 분리하여 본다 (jsp 에서 view 의 역할만 맡도록 만든다) (단 jsp 에서 view 에서 적절한 값을 렌더링 하기 위해 필요한 저장소가 있는데 이것이 현재 mvc 의 model 로 쓰이고 있고 이것이 HttpServletRequest 에 setAttribute 데 담아야 jsp 에서 참조하기 편하다) web.frontcontroller 패키지 : 각 버전별로 실제 발전되는 과정을 만들면서 spring 과 비슷하게 만들어 본다 v1 패키지 : 모든 컨트롤 부분이 모두 서블릿으로 등록될 필요없이 frontContoller 만 서블릿으로 등록해서 처리해보자 프론트 컨트롤러 에서 쉽게 각 컨트롤러를 쉽게 호출하기 위해 다형성을 사용하자 v2 패키지 : 모든 컨트롤 부분에서 jsp 로 forward 하는 부분이 겹친다 이 부분의 경우 따로 다른 클래스에서 처리하기 위해 MyView 클래스를 도입하자 각 컨트롤러에서 MyView만 반환해서 나머지는 프론트 컨트롤러에서 처리자 ( 여기서 약간 의문일 수 있는데 실제 jsp 말고 다른 view 를 사용할 수 있으므로 view 또 추상화하는 것이 좋다) v3 패키지 : 이 단계에서 많은 것을 해야 한다 모든 컨트롤 부분에서 http 요청 반환 정보(HttpServletRequest, HttpServletResponse) 가 같이 넘어간다 의존성을 제거해보자 사용자가 요청한 파라미터 정보는 HttpServletRequest.getParameter 를 통해 받는다 HttpServletRequest 없이 컨트롤러에서 처리하려면 프론트컨트롤러에서 처리해서 java 자료형으로 넘겨주어야 한다 현재 request 객체를 model 로써 사용하고 있는데 이것을 새롭게 ModelView(MVC 패턴에서 Controller와 View 사이의 데이터 전달 및 뷰 논리적 이름을 관리) 만들자 ( model 의 역할을 함과 동시에 view 의 논리적 이름 역할을 함께 가지고 있으므로 ModelView 로 만들었음 ) 사용자의 요청(특정 컨트롤러)과 파라미터를 처리해서 ModelView 를 만들어서 처리시키자 modelView 에 있는 이름으로는 MyView 를 부르는데 부족하다 전체 경로를 만들어 주는 viewResolver 또한 필요하다 v4 패키지 : 컨트롤러 측에서 ModelView 또한 만들고 싶어하지 않는다 java자료형으로 만들어서 반환시키자 v5 패키지 : 컨트롤러 측에서 누구는 v3 누구는 v4 로 만들고 싶어한다 둘다 지원할 수 있도록 어뎁터를 만들자 어뎁터를 만들면서 컨트롤러는 더 큰 범위를 다룰 수 있으므로 handler 라고 명명한다 프론트 컨트롤러 측에서 적절한 컨트롤러를 받아서 적절한 어뎁터를 통해 진행시킨다 web.springmvc 패키지 : spring 을 사용한 편집 ![Pasted image 2025003267.png)","리졸버-관련#리졸버 관련":"스프링 부트가 자동 등록하는 뷰 리졸버 (실제로는 더 많지만, 중요한 부분 위주로 설명하기 위해 일부 생략)\n1 = BeanNameViewResolver : 빈 이름으로 뷰를 찾아서 반환한다. (예: 엑셀 파일 생성 기능 에 사용) 2 = InternalResourceViewResolver : JSP를 처리할 수 있는 뷰를 반환한다. 1번 예시\n@Component(\"excelView\") // 빈 이름 명시 public class ExcelView implements View { @Override public void render(Map\u003cString, ?\u003e model, HttpServletRequest request, HttpServletResponse response) { // 엑셀 파일 생성 로직 response.setContentType(\"application/vnd.ms-excel\"); // ... } } 빈 이름으로 리졸버뷰를 만들어서 컨트롤러에서 처리한다","실제-spring-mvc-구조#실제 spring MVC 구조":"","추가#추가":"","핸들러컨트롤러-관련#핸들러(컨트롤러) 관련":"컨트롤러가 호출되려면 다음 2가지가 필요하다.\nHandlerMapping(핸들러 매핑) 핸들러 매핑에서 이 컨트롤러를 찾을 수 있어야 한다. 예) 스프링 빈의 이름으로 핸들러를 찾을 수 있는 핸들러 매핑이 필요하다. HandlerAdapter(핸들러 어댑터) 핸들러 매핑을 통해서 찾은 핸들러를 실행할 수 있는 핸들러 어댑터가 필요하다. 예) Controller 인터페이스를 실행할 수 있는 핸들러 어댑터를 찾고 실행해야 한다. 스프링 부트가 자동 등록하는 핸들러 매핑과 핸들러 어댑터 (실제로는 더 많지만, 중요한 부분 위주로 설명하기 위해 일부 생략) HandlerMapping 0 = RequestMappingHandlerMapping : 애노테이션 기반의 컨트롤러인 @RequestMapping에서 사용 1 = BeanNameUrlHandlerMapping : 스프링 빈의 이름으로 핸들러를 찾는다. HandlerAdapter\n0 = RequestMappingHandlerAdapter : 애노테이션 기반의 컨트롤러인 @RequestMapping에서 사용 1 = HttpRequestHandlerAdapter : HttpRequestHandler 처리 2 = SimpleControllerHandlerAdapter : Controller 인터페이스(애노테이션X, 과거에 사용) 처리"},"title":"youngHan mvc1 프로젝트 변화 과정"},"/younghan-mvc2/spring-locale-%EC%84%A4%EC%A0%95/":{"data":{"":"spring locale 설정","1#\u003cstrong\u003e(1) \u003ccode\u003egradle.properties\u003c/code\u003e 파일에 설정 추가\u003c/strong\u003e":"gradle.properties (프로젝트 루트에 위치)\nuserLanguage=ko userCountry=KR","1-gradle과-작업task-개념#1. Gradle과 작업(Task) 개념":"Gradle은 강력한 빌드 자동화 도구로, 작업(Task)이라는 개념을 중심으로 동작합니다. 작업(Task)은 소스 코드 컴파일, 테스트 실행, 문서 생성, 애플리케이션 패키징 등의 독립적인 단위로 구성됩니다. 이러한 작업은 Gradle 빌드 스크립트(build.gradle 또는 build.gradle.kts)에서 정의되며, 플러그인을 적용하여 추가적인 작업을 확장할 수도 있습니다.\n예를 들어, Java 플러그인을 적용하면 다음과 같은 작업이 자동으로 추가됩니다.\ncompileJava : Java 소스 코드 컴파일\ntest : 테스트 실행\njar : JAR 파일 생성\nGradle에서 실행 가능한 모든 작업 목록을 확인하려면 프로젝트의 루트 디렉터리에서 다음 명령어를 실행할 수 있습니다.\n./gradlew tasks","1-테스트-및-실행-작업에-대한-로케일-설정#(1) 테스트 및 실행 작업에 대한 로케일 설정":"tasks.withType(JavaForkOptions) { systemProperty 'user.language', 'ko' systemProperty 'user.country', 'KR' }","2#\u003cstrong\u003e(2) \u003ccode\u003ebuild.gradle\u003c/code\u003e에서 Gradle 속성 적용\u003c/strong\u003e":"tasks.withType(JavaForkOptions) { systemProperty 'user.language', project.properties['userLanguage'] systemProperty 'user.country', project.properties['userCountry'] } tasks.withType(JavaCompile) { options.fork = true options.forkOptions.jvmArgs += [ \"-Duser.language=${project.properties['userLanguage']}\", \"-Duser.country=${project.properties['userCountry']}\" ] } 장점:\n필요에 따라 gradle.properties 파일에서 로케일을 쉽게 변경 가능\n다양한 환경(OS, 개발자 설정)에서 유연하게 적용 가능","2-java-컴파일-작업에-대한-로케일-설정#(2) Java 컴파일 작업에 대한 로케일 설정":"tasks.withType(JavaCompile) { options.fork = true options.forkOptions.jvmArgs += [\"-Duser.language=ko\", \"-Duser.country=KR\"] }","2-jvm-프로세스-분리forking와-gradle-설정#2. JVM 프로세스 분리(Forking)와 Gradle 설정":"Gradle에서는 특정 작업을 수행할 때 별도의 JVM 프로세스를 실행(포크, Forking)할 수 있습니다. 이러한 작업에는 주로 테스트 실행(Test), Java 코드 실행(JavaExec), 그리고 Java 코드 컴파일(JavaCompile)이 포함됩니다.\nJVM을 포크하는 이유는 다음과 같습니다.\n빌드 프로세스와 개별 작업을 격리하여 안정성 확보 특정 JVM 설정(메모리 크기, 시스템 속성 등)을 독립적으로 적용 테스트 작업 병렬 실행을 통해 빌드 속도 향상 Gradle에서는 JavaForkOptions 인터페이스를 사용하여 포크된 JVM에 다양한 설정을 적용할 수 있습니다. 대표적으로 Test 및 JavaExec 작업은 JavaForkOptions을 구현하며, JavaCompile 작업도 설정에 따라 JVM을 포크할 수 있습니다.","3-gradle-설정-코드-분석#3. Gradle 설정 코드 분석":"","4-intellij-idea와-gradle의-로케일-불일치-문제#4. IntelliJ IDEA와 Gradle의 로케일 불일치 문제":"IntelliJ IDEA는 자체 설정에서 기본 로케일을 관리하기 때문에, 운영 체제의 로케일과 일치하지 않을 수 있습니다.\nIntelliJ에서 실행되는 JVM과 Gradle이 실행하는 JVM은 독립적으로 동작 IntelliJ는 기본적으로 en-US 로케일을 사용할 수 있음 Gradle은 OS 설정을 직접 따르지 않고, 명시적으로 설정된 로케일을 사용 이러한 차이점 때문에 Gradle 빌드가 IntelliJ의 로케일과 다르게 동작할 수 있습니다. 이를 해결하려면 Gradle 설정을 명확하게 지정해야 합니다.","5-로케일-설정을-더욱-유연하게-관리하는-방법#5. 로케일 설정을 더욱 유연하게 관리하는 방법":"Gradle 속성(gradle.properties) 또는 환경 변수를 활용하여 로케일 설정을 변경할 수 있습니다.","6-결론-및-권장-사항#6. 결론 및 권장 사항":"✅ Gradle 설정 유지:\n테스트 및 컴파일 단계에서 일관된 한국어 로케일을 강제하기 위해 제공된 Gradle 설정을 유지하는 것이 좋습니다.\n✅ 애플리케이션 실행 시 로케일 확인:\nSpring Boot의 bootRun 작업을 실행할 때도 한국어 로케일을 적용해야 할 수 있습니다. IntelliJ의 Run Configuration에서 VM 옵션을 설정하는 것이 도움이 될 수 있습니다.\n✅ 환경별 로케일 변경 고려:\nGradle 속성(gradle.properties) 또는 환경 변수를 활용하여 필요에 따라 로케일을 변경할 수 있도록 설정하는 것이 좋습니다.\n✅ 운영 환경 고려:\n최종 애플리케이션이 배포되는 환경에서도 로케일 설정을 고려해야 합니다. OS의 기본 로케일이 애플리케이션 실행 시 영향을 줄 수 있습니다.","spring-locale-설정#spring locale 설정":"","spring-mvc-프로젝트에서-gradle을-활용한-일관된-로케일-설정#Spring MVC 프로젝트에서 Gradle을 활용한 일관된 로케일 설정":"사용자는 IntelliJ IDEA에서 기본 로케일이 en-US로 표시되는 반면, 운영 체제의 로케일은 한국어로 설정되어 있는 문제를 보고했습니다. 이로 인해 Spring MVC 애플리케이션이 null 로케일이 주어졌을 때 영어 리소스 번들을 기본적으로 선택하는 문제가 발생했습니다. 반면, ko_KR 로케일을 명시적으로 설정했을 때는 애플리케이션이 정상적으로 동작함을 확인했습니다.\n이에 따라 사용자는 Gradle 빌드 과정에서 테스트 및 컴파일 단계에서 한국어 로케일을 강제하도록 설정하는 Gradle 구성 스니펫을 제공하였으며, 이에 대한 자세한 설명을 요청했습니다. 본 보고서는 이러한 Gradle 설정의 목적과 기능을 설명하고, IntelliJ와 Gradle 간의 로케일 불일치 문제를 해결하는 방법을 다룹니다.","설명#\u003cstrong\u003e설명\u003c/strong\u003e":"tasks.withType(JavaForkOptions) {...} Gradle의 TaskContainer에서 JavaForkOptions을 구현하는 작업만 선택 대표적으로 Test 및 JavaExec 작업이 포함됨 systemProperty 'user.language', 'ko' JVM 시스템 속성 user.language를 ko(한국어)로 설정 systemProperty 'user.country', 'KR' JVM 시스템 속성 user.country를 KR(대한민국)로 설정 결과:\nGradle이 테스트(Test) 또는 Java 실행(JavaExec)을 수행할 때, JVM의 기본 로케일이 ko_KR로 설정됨 애플리케이션이 null 로케일을 받을 때 한국어 리소스 번들을 선택하도록 강제됨","설명-1#\u003cstrong\u003e설명\u003c/strong\u003e":"tasks.withType(JavaCompile) {...} Gradle의 JavaCompile 작업에만 설정 적용 options.fork = true Java 컴파일러(javac)를 별도의 JVM 프로세스에서 실행하도록 설정 options.forkOptions.jvmArgs += [\"-Duser.language=ko\", \"-Duser.country=KR\"] 포크된 JVM에 user.language 및 user.country 시스템 속성 추가 결과:\nJava 코드 컴파일(javac)이 한국어 로케일에서 수행됨 만약 어노테이션 프로세서 또는 코드 생성이 로케일에 따라 다른 결과를 생성한다면, 이를 한국어 기준으로 일관되게 유지할 수 있음","질문#질문":"build.gradle\n// 모든 Java 작업에 한국어 로케일 설정 적용 tasks.withType(JavaForkOptions) { // 모든 JVM 포크 작업(test, bootRun 등)에 적용 systemProperty 'user.language', 'ko' systemProperty 'user.country', 'KR' } // Java 컴파일 작업에도 동일한 설정 tasks.withType(JavaCompile) { options.fork = true options.forkOptions.jvmArgs += ['-Duser.language=ko', '-Duser.country=KR'] } 질문의 내용을 null값으로 주게 되면 시스템 os locale 을 찾는다고 했는데 실제 제대로 적용되지 않는 상황인것 같습니다\n저는 linux에서 개발환경구성되어 있는데\nlinux 에서 지역 locale 을 쓰지 않고 중립 localeLANG=C.UTF-8 을 씁니다 그래서 저도 동일한 문제가 발생하였습니다\n다음 3가지 접근법이 제가 알고 있는 접근법 입니다\n운영체제 locale 변경(질문에 내용에 해당되지 않음)\njvm locale 변경-Duser.language=ko -Duser.country=KR 이전 댓글의 내용 동일\n빌드 설정 처음의 요약과 동일\n코드를 수정\n@BeforeAll static void setUpLocale() { Locale.setDefault(Locale.KOREA); }"},"title":"spring locale 설정"},"/younghan-mvc2/thymeleaf-%EC%A0%95%EB%A6%AC/":{"data":{"":"","1-간단한-표현식#\u003cstrong\u003e1. 간단한 표현식\u003c/strong\u003e":"변수 표현식: ${...}\n컨텍스트 내 변수에 접근하거나 값을 출력하는 데 사용됩니다. 예: 이름\n선택 변수 표현식: *{...}\n현재 선택된 객체에 대한 속성에 접근할 때 사용됩니다. 예: 이름\n메시지 표현식: #{...}\n국제화(i18n)를 지원하는 메시지를 출력하는 데 사용됩니다. 예: 환영합니다!\n링크 URL 표현식: @{...}\n동적인 URL을 생성하는 데 사용됩니다. 예: 프로필 조각 표현식: ~{...}\n템플릿 조각(fragment)을 포함하는 데 사용됩니다. 예:","2-리터럴#\u003cstrong\u003e2. 리터럴\u003c/strong\u003e":"텍스트: 'one text', 'Another one!'\n문자열을 나타냅니다. 예: 기본 텍스트\n숫자: 0, 34, 3.0, 12.3\n숫자를 나타냅니다. 예: 합계\n불린: true, false\n논리값을 나타냅니다. 예: 활성화됨\n널: null\nnull 값을 나타냅니다. 예: 사용자 없음\n리터럴 토큰: one, sometext, main\n문자열 대신 사용할 수 있는 심볼릭 토큰입니다. 예: 주요 내용","3-문자-연산#\u003cstrong\u003e3. 문자 연산\u003c/strong\u003e":"문자 합치기: +\n문자열을 연결합니다. 예: 인사말\n리터럴 대체: |The name is ${name}|\n문자열 내에서 변수를 직접 삽입하는 방법입니다. 예: 환영합니다","4-산술-연산#\u003cstrong\u003e4. 산술 연산\u003c/strong\u003e":"이항 연산자: +, -, *, /, %\n산술 연산을 수행합니다. 예: 15\n단항 연산자(음수 표시): -\n음수를 나타냅니다. 예: -10","5-불린-연산#\u003cstrong\u003e5. 불린 연산\u003c/strong\u003e":"이항 연산자: and, or\n논리 AND와 OR 연산을 수행합니다. 예: 관리자 활성화\n부정 연산자: !, not\n논리값을 반전합니다. 예: 비활성화됨","6-비교와-동등-연산#\u003cstrong\u003e6. 비교와 동등 연산\u003c/strong\u003e":"비교 연산자: \u003e, \u003c, \u003e=, \u003c= (gt, lt, ge, le)\n크기 비교를 수행합니다. 예: 성인\n동등 연산자: ==, != (eq, ne)\n값의 동일성을 비교합니다. 예: 활성 상태","7-조건-연산#\u003cstrong\u003e7. 조건 연산\u003c/strong\u003e":"If-then: (if) ? (then)\n조건이 참일 때 특정 값을 반환합니다. 예: 상태\nIf-then-else: (if) ? (then) : (else)\n조건에 따라 다른 값을 반환합니다. 예: 역할\nDefault: (value) ?: (defaultvalue)\n값이 null일 경우 기본값을 반환합니다. 예: 이름","8-특별한-토큰#\u003cstrong\u003e8. 특별한 토큰\u003c/strong\u003e":"No-Operation: _ 아무 작업도 수행하지 않음을 나타냅니다. 예: 기본값 유지","text#text":"\u003cli\u003eth:text 사용 \u003cspan th:text=\"${data}\"\u003e\u003c/span\u003e\u003c/li\u003e \u003cli\u003e컨텐츠 안에서 직접 출력하기 = [${data}](${data})\u003c/li\u003e 아래는 타임리프(Thymeleaf)의 기본 사용 선언과 제공하는 기본 표현식들을 정리한 내용입니다. 이를 통해 타임리프를 효과적으로 활용할 수 있습니다.","참고-자료#\u003cstrong\u003e참고 자료\u003c/strong\u003e":"공식 문서:","타임리프-기본-표현식#\u003cstrong\u003e타임리프 기본 표현식\u003c/strong\u003e":"","타임리프-사용-선언#\u003cstrong\u003e타임리프 사용 선언\u003c/strong\u003e":"\u003chtml xmlns:th=\"http://www.thymeleaf.org\"\u003e 위 선언은 HTML 문서에서 타임리프를 사용하기 위해 필요한 네임스페이스를 정의합니다."},"title":"thymeleaf 정리"}}